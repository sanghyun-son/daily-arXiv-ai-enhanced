#!/bin/bash

# Local testing script
# Main workflow has been migrated to GitHub Actions (.github/workflows/run.yml)

# Environment variables check and prompt
echo "=== Local Debug Environment Check ==="

# Check required environment variables
if [ -z "$OPENAI_API_KEY" ]; then
    echo "âš ï¸  Warning: OPENAI_API_KEY not set"
    echo "ğŸ“ For complete local debugging, please set the following environment variables:"
    echo ""
    echo "ğŸ”‘ Required variables:"
    echo "   export OPENAI_API_KEY=\"your-api-key-here\""
    echo ""
    echo "ğŸ”§ Optional variables:"
    echo "   export OPENAI_BASE_URL=\"https://api.openai.com/v1\"  # API base URL"
    echo "   export LANGUAGE=\"Korean\"                           # Language setting"
    echo "   export CATEGORIES=\"cs.CV, cs.CL\"                    # Categories of interest"
    echo "   export MODEL_NAME=\"gpt-4o-mini\"                     # Model name"
    echo "   export INTERESTS=\"machine learning, deep learning\"   # Research interests for relevance filtering"
    echo ""
    echo "ğŸ’¡ After setting, rerun this script for complete testing"
    echo "ğŸš€ Or continue with partial workflow (crawl + dedup check)"
    echo ""
    read -p "Continue with partial workflow? (y/N): " continue_partial
    if [[ ! $continue_partial =~ ^[Yy]$ ]]; then
        echo "Exiting script"
        exit 0
    fi
    PARTIAL_MODE=true
else
    echo "âœ… OPENAI_API_KEY is set"
    PARTIAL_MODE=false
    
    # Set default values
    export LANGUAGE="${LANGUAGE:-Korean}"
    export CATEGORIES="${CATEGORIES:-cs.CV, cs.CL}"
    export MODEL_NAME="${MODEL_NAME:-gpt-4o-mini}"
    export OPENAI_BASE_URL="${OPENAI_BASE_URL:-https://api.openai.com/v1}"
    export INTERESTS="${INTERESTS:-}"
    
    echo "ğŸ”§ Current configuration:"
    echo "   LANGUAGE: $LANGUAGE"
    echo "   CATEGORIES: $CATEGORIES"
    echo "   MODEL_NAME: $MODEL_NAME"
    echo "   OPENAI_BASE_URL: $OPENAI_BASE_URL"
    echo "   INTEREST: $INTEREST"
fi

echo ""
echo "=== Starting Local Debug Workflow ==="

# Get current date
today=`date -u "+%Y-%m-%d"`

echo "Local test: Crawling $today arXiv papers..."

# Step 1: Crawl data
echo "Step 1: Starting crawl..."

# Check if today's file exists, delete if found
if [ -f "data/${today}.jsonl" ]; then
    echo "ğŸ—‘ï¸ Found existing today's file, deleting for fresh start..."
    rm "data/${today}.jsonl"
    echo "âœ… Deleted existing file: data/${today}.jsonl"
else
    echo "ğŸ“ Today's file doesn't exist, ready to create new one..."
fi

cd daily_arxiv
scrapy crawl arxiv -o ../data/${today}.jsonl

if [ ! -f "../data/${today}.jsonl" ]; then
    echo "Crawling failed, no data file generated"
    exit 1
fi

# Step 2: Check duplicates  
echo "Step 2: Performing intelligent deduplication check..."
python daily_arxiv/check_stats.py
dedup_exit_code=$?

case $dedup_exit_code in
    0)
        # check_stats.py already output success info, continue processing
        ;;
    1)
        # check_stats.py already output no new content info, stop processing
        exit 1
        ;;
    2)
        # check_stats.py already output error info, stop processing
        exit 2
        ;;
    *)
        echo "âŒ Unknown exit code, stopping..."
        exit 1
        ;;
esac

cd ..

# Step 3: AI processing
if [ "$PARTIAL_MODE" = "false" ]; then
    echo "Step 3: AI enhancement processing..."
    cd ai
    
    # Submit batch job
    echo "ğŸ“¤ Submitting batch job for AI processing..."
    python submit_batch.py --data ../data/${today}.jsonl
    
    if [ $? -ne 0 ]; then
        echo "âŒ Batch job submission failed"
        exit 1
    fi
    echo "âœ… Batch job submitted successfully"
    
    # Process batch results (wait for completion)
    echo "â³ Processing batch results..."
    python process_batch.py --data ../data/${today}.jsonl --wait
    
    if [ $? -ne 0 ]; then
        echo "âŒ Batch processing failed"
        exit 1
    fi
    echo "âœ… AI enhancement processing completed"
    cd ..
else
    echo "â­ï¸  Skipping AI processing (partial mode)"
fi

# Step 4: Convert to Markdown
echo "Step 4: Converting to Markdown..."
cd to_md

if [ "$PARTIAL_MODE" = "false" ] && [ -f "../data/${today}_AI_enhanced_${LANGUAGE}.jsonl" ]; then
    echo "ğŸ“„ Using AI enhanced data for conversion..."
    python convert.py --data ../data/${today}_AI_enhanced_${LANGUAGE}.jsonl
    
    if [ $? -ne 0 ]; then
        echo "âŒ Markdown conversion failed"
        exit 1
    fi
    echo "âœ… AI enhanced Markdown conversion completed"
    
else
    if [ "$PARTIAL_MODE" = "true" ]; then
        echo "â­ï¸  Skipping Markdown conversion (partial mode, requires AI enhanced data)"
    else
        echo "âŒ Error: AI enhanced file not found"
        echo "AI file: ../data/${today}_AI_enhanced_${LANGUAGE}.jsonl"
        exit 1
    fi
fi

cd ..

# Step 5: Update file list
echo "Step 5: Updating file list..."
ls data/*.jsonl | sed 's|data/||' > assets/file-list.txt
echo "âœ… File list updated"

# Completion summary
echo ""
echo "=== Local Debug Completed ==="
if [ "$PARTIAL_MODE" = "false" ]; then
    echo "ğŸ‰ Complete workflow finished:"
    echo "   âœ… Data crawling"
    echo "   âœ… Smart duplicate check"
    echo "   âœ… AI enhancement"
    echo "   âœ… Markdown conversion"
    echo "   âœ… File list update"
else
    echo "ğŸ”„ Partial workflow finished:"
    echo "   âœ… Data crawling"
    echo "   âœ… Smart duplicate check"
    echo "   â­ï¸  Skipped AI enhancement and Markdown conversion"
    echo "   âœ… File list update"
    echo ""
    echo "ğŸ’¡ Tip: Set OPENAI_API_KEY to enable full functionality"
fi
