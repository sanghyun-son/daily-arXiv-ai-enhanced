<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 107]
- [cs.CL](#cs.CL) [Total: 58]
- [cs.LG](#cs.LG) [Total: 108]
- [eess.IV](#eess.IV) [Total: 2]
- [cs.DC](#cs.DC) [Total: 12]
- [cs.AI](#cs.AI) [Total: 56]
- [cs.IR](#cs.IR) [Total: 27]
- [cs.MA](#cs.MA) [Total: 7]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [YOLO11-CR: a Lightweight Convolution-and-Attention Framework for Accurate Fatigue Driving Detection](https://arxiv.org/abs/2508.13205)
*Zhebin Jin,Ligang Dong*

Main category: cs.CV

TL;DR: YOLO11-CR은 운전자 졸음 감지를 위해 고안된 경량 실시간 객체검출 모델로, CAFM(Convolution-and-Attention Fusion Module)과 RCM(Rectangular Calibration Module)을 도입해 작은 객체·가려진 객체·다중 스케일 특성 문제를 개선한다. DSM 데이터셋에서 Precision 87.17%, Recall 83.86%, mAP@50 88.09%, mAP@50-95 55.93%를 달성하며 베이스라인보다 성능이 우수하고, 약체 분석으로 두 모듈의 유효성이 확인되었다.


<details>
  <summary>Details</summary>
Motivation: 운전자 졸음 검출은 교통사고 예방에 중요하나, 생체·차량 동역학 기반 방법은 침습적이고 하드웨어 의존적이며 실제 환경에서 견고성이 떨어진다. 비전 기반 방법은 비침습적이고 확장성이 있으나 작은/가려진 객체 검출과 다중 스케일 특성 모델링에 한계가 있다.

Method: YOLO11-CR 설계: (1) CAFM — CNN의 로컬 특성과 Transformer 기반의 글로벌 컨텍스트를 융합해 특징 표현력을 향상; (2) RCM — 수평·수직 컨텍스트를 포착하여 위치추정 성능을 개선(특히 측면 얼굴·작은 물체 예: 휴대폰). 경량화와 실시간성에 최적화된 객체검출 아키텍처.

Result: DSM 데이터셋 실험에서 Precision 87.17%, Recall 83.86%, mAP@50 88.09%, mAP@50-95 55.93%를 기록하며 베이스라인 모델들을 유의미하게 상회. 약체 연구에서 CAFM과 RCM이 민감도와 위치정확도 향상에 기여함을 확인.

Conclusion: YOLO11-CR은 차량 내 졸음 모니터링을 위한 실용적이고 성능 좋은 솔루션을 제시하며, 실제 배치 가능성이 높다. 향후에는 시공간(temporal) 모델링, 다중 모달 데이터 통합, 임베디드 최적화 등의 확장이 제안된다.

Abstract: Driver fatigue detection is of paramount importance for intelligent
transportation systems due to its critical role in mitigating road traffic
accidents. While physiological and vehicle dynamics-based methods offer
accuracy, they are often intrusive, hardware-dependent, and lack robustness in
real-world environments. Vision-based techniques provide a non-intrusive and
scalable alternative, but still face challenges such as poor detection of small
or occluded objects and limited multi-scale feature modeling. To address these
issues, this paper proposes YOLO11-CR, a lightweight and efficient object
detection model tailored for real-time fatigue detection. YOLO11-CR introduces
two key modules: the Convolution-and-Attention Fusion Module (CAFM), which
integrates local CNN features with global Transformer-based context to enhance
feature expressiveness; and the Rectangular Calibration Module (RCM), which
captures horizontal and vertical contextual information to improve spatial
localization, particularly for profile faces and small objects like mobile
phones. Experiments on the DSM dataset demonstrated that YOLO11-CR achieves a
precision of 87.17%, recall of 83.86%, mAP@50 of 88.09%, and mAP@50-95 of
55.93%, outperforming baseline models significantly. Ablation studies further
validate the effectiveness of the CAFM and RCM modules in improving both
sensitivity and localization accuracy. These results demonstrate that YOLO11-CR
offers a practical and high-performing solution for in-vehicle fatigue
monitoring, with strong potential for real-world deployment and future
enhancements involving temporal modeling, multi-modal data integration, and
embedded optimization.

</details>


### [2] [MIRAGE: Towards AI-Generated Image Detection in the Wild](https://arxiv.org/abs/2508.13223)
*Cheng Xia,Manxi Lin,Jiexiang Tan,Xiaoxiong Du,Yang Qiu,Junjun Zheng,Xiangheng Kong,Yuning Jiang,Bo Zheng*

Main category: cs.CV

TL;DR: AI 생성 이미지(AIGI)의 확산은 정보 보안과 신뢰 위협을 가져온다. 기존 탐지기는 실험실 환경에서는 성능이 좋지만 실제 환경에서는 일반화에 실패한다. 이를 해결하기 위해 저자들은 Mirage라는 현실적 벤치마크와 Mirage-R1이라는 비전-언어 모델(휴리스틱-분석적 및 반사적 추론 포함)을 제안한다. Mirage-R1은 감독-파인튜닝 후 강화학습으로 학습되며, 추론 시 적응적 사고 전략으로 속도와 정확도를 균형시킨다. 실험에서 기존 방법보다 Mirage에서 5%, 공개 벤치마크에서 10% 우수한 성능을 보였다.


<details>
  <summary>Details</summary>
Motivation: 생성 AI의 발전으로 AI가 만든 이미지(AIGI)가 널리 퍼지며 정보 보안과 공공 신뢰를 위협한다. 기존 탐지 모델들은 실험실 환경에서는 잘 작동하지만 실제 환경(다양한 생성 모델, 후처리 등)에서는 일반화되지 못한다. 따라서 실제 환경을 제대로 반영하는 벤치마크와 강건한 탐지 모델이 필요하다.

Method: (1) 현실적 벤치마크 Mirage 구성: 인터넷에서 수집된 인간 전문가가 검증한 AIGI와 다수의 전문 생성기들이 협력해 만든 합성 데이터로 구성. (2) Mirage-R1 제안: 비전-언어 모델로 휴리스틱-분석적(hueristic-to-analytic) 추론과 반사적(reflective) 추론 메커니즘 도입. 학습은 감독-파인튜닝(cold start) 후 강화학습 단계로 진행. 추론 시에는 적응적 사고(adaptive thinking) 전략을 사용해 빠른 판단 또는 정확한 결론 선택 가능.

Result: 제안한 모델은 Mirage 벤치마크에서 기존 최첨단 탐지기보다 5% 우수하고, 공개 벤치마크에서는 10% 더 우수한 성능을 보였다. 벤치마크와 코드 공개 예정.

Conclusion: 현실 세계의 다양한 AIGI를 반영하는 Mirage 벤치마크와 휴리스틱-분석적 반사적 추론을 결합한 Mirage-R1 모델은 AIGI 탐지에서 강건성과 일반화 성능을 크게 향상시킨다. 공개 데이터와 코드로 연구 재현 가능성을 높일 예정.

Abstract: The spreading of AI-generated images (AIGI), driven by advances in generative
AI, poses a significant threat to information security and public trust.
Existing AIGI detectors, while effective against images in clean laboratory
settings, fail to generalize to in-the-wild scenarios. These real-world images
are noisy, varying from ``obviously fake" images to realistic ones derived from
multiple generative models and further edited for quality control. We address
in-the-wild AIGI detection in this paper. We introduce Mirage, a challenging
benchmark designed to emulate the complexity of in-the-wild AIGI. Mirage is
constructed from two sources: (1) a large corpus of Internet-sourced AIGI
verified by human experts, and (2) a synthesized dataset created through the
collaboration between multiple expert generators, closely simulating the
realistic AIGI in the wild. Building on this benchmark, we propose Mirage-R1, a
vision-language model with heuristic-to-analytic reasoning, a reflective
reasoning mechanism for AIGI detection. Mirage-R1 is trained in two stages: a
supervised-fine-tuning cold start, followed by a reinforcement learning stage.
By further adopting an inference-time adaptive thinking strategy, Mirage-R1 is
able to provide either a quick judgment or a more robust and accurate
conclusion, effectively balancing inference speed and performance. Extensive
experiments show that our model leads state-of-the-art detectors by 5% and 10%
on Mirage and the public benchmark, respectively. The benchmark and code will
be made publicly available.

</details>


### [3] [DianJin-OCR-R1: Enhancing OCR Capabilities via a Reasoning-and-Tool Interleaved Vision-Language Model](https://arxiv.org/abs/2508.13238)
*Qian Chen,Xianyin Zhang,Lifan Guo,Feng Chen,Chi Zhang*

Main category: cs.CV

TL;DR: Proposes DianJin-OCR-R1, a reasoning-enhanced vision-language model that interleaves its own OCR with calls to expert OCR tools and a final re-reasoning step to reduce hallucinations and improve OCR accuracy.


<details>
  <summary>Details</summary>
Motivation: Large vision-language models excel at end-to-end document parsing but suffer from hallucinations and underperform specialist OCR models on domain tasks; leveraging expert models can reduce errors and is cost-effective.

Method: Train VLMs with reasoning-and-tool interleaving: the model first performs its own OCR, queries expert OCR tools for their outputs as references, then re-examines the image and rethinks to produce the final recognized content.

Result: On ReST and OmniDocBench, DianJin-OCR-R1 consistently outperforms both non-reasoning VLM counterparts and standalone expert OCR models.

Conclusion: Interleaving internal reasoning with external expert-tool calls effectively mitigates hallucinations and improves OCR performance, offering a practical way to boost LVLMs using smaller expert models.

Abstract: Recent advances in large vision-language models (LVLMs) have enabled a new
paradigm of end-to-end document image parsing, excelling in Optical Character
Recognition (OCR) tasks such as text, table, and formula recognition. However,
generative LVLMs, similarly to large language models (LLMs), are prone to
hallucinations--generating words that do not exist in input images.
Furthermore, LVLMs are designed for general purposes and tend to be less
effective on OCR tasks compared to expert models that are trained on
domain-specific datasets. In this paper, we propose DianJin-OCR-R1, a
reasoning-enhanced framework designed to address these limitations through
training reasoning-and-tool interleaved VLMs. Given a recognition instruction,
our DianJin-OCR-R1 model first recognizes the content in the input image by its
own OCR capabilities, and then calls other tools (i.e., other expert models) to
obtain their results as references, finally looks again the image and rethinks
about the reasoning process to provide the final recognized content. Since
architectures of expert models are tailored for specific OCR tasks, which makes
them less prone to hallucinations, their results can help VLMs mitigate
hallucinations. Additionally, expert models are typically smaller in scale and
easy to iterate, enabling performance improvements for VLMs at a lower cost. We
evaluate our model on ReST and OmniDocBench, and experimental results show that
our DianJin-OCR-R1 models consistently outperform their non-reasoning
counterparts and expert OCR models, which proves the effectiveness of our
method.

</details>


### [4] [Exploration of Deep Learning Based Recognition for Urdu Text](https://arxiv.org/abs/2508.13245)
*Sumaiya Fazal,Sheeraz Ahmed*

Main category: cs.CV

TL;DR: Component-based Urdu OCR using convolutional neural network (CNN). Dataset generated by permuting three-character combinations and extracting ligatures via connected component analysis. A two-level hierarchical neural network classifies components; reported component classification performance is 0.99% (likely a typo).


<details>
  <summary>Details</summary>
Motivation: Urdu is a cursive, context-sensitive script with complex geometrical and morphological structure, making segmentation-based OCR error-prone; need for segmentation-robust recognition.

Method: Automatic feature learning with CNN trained on a synthetic Urdu ligature dataset created by permuting three characters; connected component analysis is used to discard background/unnecessary images and isolate ligatures; a hierarchical (two-level) neural network handles three degrees of character permutations and performs component classification.

Result: The model reportedly achieved 0.99% for component classification (the abstract likely means 99% accuracy but reports 0.99%).

Conclusion: A component-based, CNN-driven, hierarchical approach appears effective for Urdu component classification, but the abstract omits critical evaluation details (dataset size, splits, metrics, baselines), so claims need substantiation.

Abstract: Urdu is a cursive script language and has similarities with Arabic and many
other South Asian languages. Urdu is difficult to classify due to its complex
geometrical and morphological structure. Character classification can be
processed further if segmentation technique is efficient, but due to context
sensitivity in Urdu, segmentation-based recognition often results with high
error rate. Our proposed approach for Urdu optical character recognition system
is a component-based classification relying on automatic feature learning
technique called convolutional neural network. CNN is trained and tested on
Urdu text dataset, which is generated through permutation process of three
characters and further proceeds to discarding unnecessary images by applying
connected component technique in order to obtain ligature only. Hierarchical
neural network is implemented with two levels to deal with three degrees of
character permutations and component classification Our model successfully
achieved 0.99% for component classification.

</details>


### [5] [CLoE: Curriculum Learning on Endoscopic Images for Robust MES Classification](https://arxiv.org/abs/2508.13280)
*Zeynep Ozdemir,Hacer Yalim Keles,Omer Ozgur Tanriover*

Main category: cs.CV

TL;DR: 이 논문은 궤양성 대장염(Ulcerative Colitis) 내시경 이미지에서 Mayo Endoscopic Subscore(MES)를 추정하는 문제에서 라벨 노이즈와 점수의 순서성(ordinality)을 고려한 커리큘럼 학습 프레임워크 CLoE를 제안한다. 이미지 품질(BBPS 기반)을 어노테이션 신뢰도의 프록시로 사용해 쉬운 샘플부터 어려운 샘플 순으로 학습하고, ResizeMix 증강을 결합해 강건성을 높인다. LIMUC와 HyperKvasir 데이터셋에서 CNN 및 Transformer에 적용해 기존 감독/자기지도 기법보다 성능 향상을 보였다.


<details>
  <summary>Details</summary>
Motivation: MES 분류는 관찰자 간 변동성으로 인한 라벨 노이즈와 점수의 순서성을 무시하는 기존 모델의 한계 때문에 어렵다. 라벨 신뢰도를 고려한 학습 및 순서성을 반영하는 방법이 필요하다.

Method: CLoE는 (1) BBPS(장 준비 상태) 레이블로 학습한 경량 모델을 이용해 이미지 품질을 추정하고 이를 어노테이션 신뢰도의 프록시로 사용해 샘플을 쉬운(품질 높음)에서 어려운(품질 낮음) 순으로 정렬하는 커리큘럼 학습을 수행한다. (2) ResizeMix라는 데이터 증강을 커리큘럼 학습과 결합해 모델의 강건성을 향상시킨다. CNN(ConvNeXt-Tiny 등)과 Transformer 기반 모델에서 실험했다.

Result: LIMUC 데이터셋에서 ConvNeXt-Tiny는 82.5% 정확도와 QWK 0.894를 달성했으며, CLoE는 강한 감독 및 자기지도 학습 기반 최강치 대비 일관된 성능 향상을 보였다. 계산 비용이 낮음도 강조됨.

Conclusion: 어려움 인지 기반(난이도-인지) 학습 전략과 이미지 품질을 이용한 라벨 신뢰도 추정은 라벨 불확실성이 있는 순서형 분류 문제에서 성능을 향상시킨다. CLoE는 효과적이고 계산 효율적인 방법이며 향후 의료 영상의 등급 판정에 유용할 수 있다.

Abstract: Estimating disease severity from endoscopic images is essential in assessing
ulcerative colitis, where the Mayo Endoscopic Subscore (MES) is widely used to
grade inflammation. However, MES classification remains challenging due to
label noise from inter-observer variability and the ordinal nature of the
score, which standard models often ignore. We propose CLoE, a curriculum
learning framework that accounts for both label reliability and ordinal
structure. Image quality, estimated via a lightweight model trained on Boston
Bowel Preparation Scale (BBPS) labels, is used as a proxy for annotation
confidence to order samples from easy (clean) to hard (noisy). This curriculum
is further combined with ResizeMix augmentation to improve robustness.
Experiments on the LIMUC and HyperKvasir datasets, using both CNNs and
Transformers, show that CLoE consistently improves performance over strong
supervised and self-supervised baselines. For instance, ConvNeXt-Tiny reaches
82.5\% accuracy and a QWK of 0.894 on LIMUC with low computational cost. These
results highlight the potential of difficulty-aware training strategies for
improving ordinal classification under label uncertainty. Code will be released
at https://github.com/zeynepozdemir/CLoE.

</details>


### [6] [GaitCrafter: Diffusion Model for Biometric Preserving Gait Synthesis](https://arxiv.org/abs/2508.13300)
*Sirshapan Mitra,Yogesh S. Rawat*

Main category: cs.CV

TL;DR: GaitCrafter는 실루엣 기반의 비디오 확산 모델로, 보행 시퀀스를 시간적으로 일관되게, 신원 보존하면서 생성하고 의복·소지품·시점 등 조건 제어가 가능하다. 합성 샘플을 학습에 포함하면 보행인식 성능이 특히 어려운 조건에서 향상되며, 신원 임베딩 보간으로 새로운(실제 데이터에 없는) 신원을 생성해 개인정보 보호를 높인다.


<details>
  <summary>Details</summary>
Motivation: 대규모 라벨된 보행 데이터 부족과 다양한 보행 샘플 수집의 어려움(프라이버시 문제 포함)을 해결하고자 함.

Method: 실루엣 데이터만으로 처음부터 학습한 비디오 확산 모델(GaitCrafter)을 제안. 시간적 일관성과 신원 보존을 목표로 하며, 의복·휴대물·카메라 시점 등 여러 공변량(condition)에 따라 생성 과정을 제어. 또한 신원 임베딩을 보간해 새로운 신원 생성 메커니즘을 도입.

Result: GaitCrafter로 생성한 합성 시퀀스를 보행인식 파이프라인에 포함하면 인식 성능이 향상되며, 특히 어려운 조건에서 유의한 개선을 보임. 생성된 새로운 신원은 일관된 고유 보행 패턴을 가지며 실제 피험자 프라이버시를 침해하지 않음.

Conclusion: 확산 모델을 이용한 실루엣 기반 보행 시퀀스 생성은 고품질·제어 가능·프라이버시 친화적인 데이터 보강 수단으로 유용하며, 보행인식의 데이터 제약 문제를 완화할 수 있는 효과적인 접근법임.

Abstract: Gait recognition is a valuable biometric task that enables the identification
of individuals from a distance based on their walking patterns. However, it
remains limited by the lack of large-scale labeled datasets and the difficulty
of collecting diverse gait samples for each individual while preserving
privacy. To address these challenges, we propose GaitCrafter, a diffusion-based
framework for synthesizing realistic gait sequences in the silhouette domain.
Unlike prior works that rely on simulated environments or alternative
generative models, GaitCrafter trains a video diffusion model from scratch,
exclusively on gait silhouette data. Our approach enables the generation of
temporally consistent and identity-preserving gait sequences. Moreover, the
generation process is controllable-allowing conditioning on various covariates
such as clothing, carried objects, and view angle. We show that incorporating
synthetic samples generated by GaitCrafter into the gait recognition pipeline
leads to improved performance, especially under challenging conditions.
Additionally, we introduce a mechanism to generate novel identities-synthetic
individuals not present in the original dataset-by interpolating identity
embeddings. These novel identities exhibit unique, consistent gait patterns and
are useful for training models while maintaining privacy of real subjects.
Overall, our work takes an important step toward leveraging diffusion models
for high-quality, controllable, and privacy-aware gait data generation.

</details>


### [7] [RED.AI Id-Pattern: First Results of Stone Deterioration Patterns with Multi-Agent Systems](https://arxiv.org/abs/2508.13872)
*Daniele Corradetti,José Delgado Rodrigues*

Main category: cs.CV

TL;DR: Id-Pattern 시스템은 석재 열화 패턴 진단을 위해 전문가 역할을 하는 다중 에이전트 AI(암석학자, 병리학자, 환경전문가, 보존수복가, 진단조정관)를 구성한 인지 아키텍처를 제안한다. 28개 어려운 이미지로 평가한 결과, 기반 모델 대비 모든 지표에서 크게 향상되었다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 전문가 직접 관찰 방식은 정확하지만 시간·비용이 많이 든다. 전문가 협업을 시뮬레이션하고 시각적 증거로부터 석재 병리를 자동 진단해 비용과 시간을 줄이고 확장성을 확보하려는 목적.

Method: 인지 아키텍처로 여러 특화 AI 에이전트를 팀으로 구성(5종의 역할). 각 에이전트가 전문적 관점을 제공하고 진단조정관이 종합해 최종 진단을 도출하는 협업 프로세스를 설계. 성능 평가는 다중 열화 패턴을 포함한 28개 어려운 이미지 집합에서 수행.

Result: 제안한 다중 에이전트 시스템은 선택한 28개 이미지에 대해 기반(파운데이셔널) 모델과 비교하여 모든 성능 지표에서 큰 향상을 보였다. (구체적 수치·지표는 초록에 없음)

Conclusion: 전문가 역할의 에이전트 협업을 통한 자동 진단 접근이 석재 열화 판별에 유망함을 보였다. 다만 데이터 수·평가 세부항목·실제 현장 적용성 검증 등 추가 연구가 필요하다.

Abstract: The Id-Pattern system within the RED.AI project (Reabilita\c{c}\~ao
Estrutural Digital atrav\'es da AI) consists of an agentic system designed to
assist in the identification of stone deterioration patterns. Traditional
methodologies, based on direct observation by expert teams, are accurate but
costly in terms of time and resources. The system developed here introduces and
evaluates a multi-agent artificial intelligence (AI) system, designed to
simulate collaboration between experts and automate the diagnosis of stone
pathologies from visual evidence. The approach is based on a cognitive
architecture that orchestrates a team of specialized AI agents which, in this
specific case, are limited to five: a lithologist, a pathologist, an
environmental expert, a conservator-restorer, and a diagnostic coordinator. To
evaluate the system we selected 28 difficult images involving multiple
deterioration patterns. Our first results showed a huge boost on all metrics of
our system compared to the foundational model.

</details>


### [8] [Prune2Drive: A Plug-and-Play Framework for Accelerating Vision-Language Models in Autonomous Driving](https://arxiv.org/abs/2508.13305)
*Minhao Xiong,Zichen Wen,Zhuangcheng Gu,Xuyang Liu,Rui Zhang,Hengrui Kang,Jiabing Yang,Junyuan Zhang,Weijia Li,Conghui He,Yafei Wang,Linfeng Zhang*

Main category: cs.CV

TL;DR: Prune2Drive is a plug-and-play visual token pruning framework for multi-view vision-language models in autonomous driving. It uses diversity-aware token selection (inspired by farthest point sampling) and a view-adaptive pruning controller to reduce the number of visual tokens without retraining or using attention maps. On benchmarks DriveLM and DriveLMM-o1, retaining 10% of tokens yields 6.40× prefilling speedup, 13.4% FLOPs, and only ~3% performance drop.


<details>
  <summary>Details</summary>
Motivation: High-resolution, multi-view camera setups in autonomous driving generate many visual tokens, causing high latency and memory use due to quadratic self-attention. Existing VLM deployments struggle with this computational overhead, so a method is needed to reduce tokens while preserving performance and compatibility with efficient attention implementations.

Method: Prune2Drive introduces (i) diversity-aware token selection that prioritizes semantic and spatial coverage across views rather than relying solely on attention scores, inspired by farthest point sampling; and (ii) a view-adaptive pruning controller that learns optimal per-view pruning ratios according to their downstream importance. The design is plug-and-play: it requires no model retraining and no access to attention maps, making it compatible with modern efficient attention implementations.

Result: Extensive experiments on DriveLM and DriveLMM-o1 show significant speed and memory gains with minimal performance loss. Specifically, keeping 10% of visual tokens leads to a 6.40× speedup in the prefilling phase, reduces FLOPs to 13.4% of original, and incurs only a ~3% drop on DriveLM benchmark. Overall, Prune2Drive maintains or improves task performance while saving compute.

Conclusion: Prune2Drive effectively reduces computational cost of multi-view VLMs for autonomous driving by pruning tokens in a diversity- and view-aware manner. Its plug-and-play nature (no retraining, no attention map requirement) makes it practical for real-world VLM deployments, offering large speedups and memory savings with small performance degradation.

Abstract: Vision-Language Models (VLMs) have emerged as a promising paradigm in
autonomous driving (AD), offering a unified framework for perception,
reasoning, and decision-making by jointly modeling visual inputs and natural
language instructions. However, their deployment is hindered by the significant
computational overhead incurred when processing high-resolution, multi-view
images, a standard setup in AD systems with six or more synchronized cameras.
This overhead stems from the large number of visual tokens generated during
encoding, increasing inference latency and memory consumption due to the
quadratic complexity of self-attention. To address these challenges, we propose
Prune2Drive, a plug-and-play visual token pruning framework for multi-view VLMs
in autonomous driving. Prune2Drive introduces two core innovations: (i) a
diversity-aware token selection mechanism inspired by farthest point sampling,
which prioritizes semantic and spatial coverage across views rather than
relying solely on attention scores, and (ii) a view-adaptive pruning controller
that learns optimal pruning ratios for each camera view based on their
importance to downstream driving tasks. Unlike prior methods, Prune2Drive does
not require model retraining or access to attention maps, making it compatible
with modern efficient attention implementations. Extensive experiments on two
large-scale multi-view driving benchmarks, DriveLM and DriveLMM-o1, show that
Prune2Drive achieves significant speedups and memory savings while maintaining
or improving task performance. When retaining only 10% of the visual tokens,
our method achieves a 6.40$\times$ speedup in the prefilling phase and consumes
13.4% of the original FLOPs, with only a 3% performance drop on the DriveLM
benchmark.

</details>


### [9] [DAASH: A Meta-Attack Framework for Synthesizing Effective and Stealthy Adversarial Examples](https://arxiv.org/abs/2508.13309)
*Abdullah Al Nomaan Nafi,Habibur Rahaman,Zafaryab Haider,Tanzim Mahfuz,Fnu Suya,Swarup Bhunia,Prabuddha Chakraborty*

Main category: cs.CV

TL;DR: DAASH는 여러 Lp-기반 공격을 단계적으로 조합하고 학습된 가중치와 메타 손실(오분류+지각적 왜곡)을 사용해 시각적으로 타당하면서 강한 적대적 예제를 생성하는 완전 미분 가능한 메타-어택 프레임워크다.


<details>
  <summary>Details</summary>
Motivation: 기존 Lp-노름 제약 기반 공격은 인간 지각과 잘 맞지 않아 시각적으로 현실성 있는(지각 정렬된) 적대적 예제를 만들기 어렵다. 최근 일부 연구가 지각적 공격을 다루기 시작했지만, Lp 기반 공격들의 통찰을 지각적 효능 개선에 효과적으로 활용할 수 있는지 불분명하다.

Method: DAASH는 다중 단계로 작동한다. 각 단계에서 여러 기본 Lp 공격으로부터 후보 예제를 모으고, 학습 가능한 적응 가중치로 이들을 집계한 뒤 다음 단계로 전달한다. 메타 손실은 오분류 손실과 지각적 왜곡(예: LPIPS 등)을 함께 최소화하도록 설계되어 각 기본 공격의 기여도를 동적으로 조절한다. 프레임워크는 완전 미분 가능해 엔드-투-엔드 학습이 가능하다.

Result: CIFAR-10/100 및 ImageNet의 적대적 학습(robust) 모델에서 평가했을 때, 단순히 Lp 기반 방법만 조합했음에도 AdvAD 등 기존 지각적 공격을 능가했다. 공격 성공률(예: 약 20.63% 포인트 향상) 및 시각 품질 지표(SSIM 약 +11, LPIPS 약 -0.015, FID 약 -5.7 개선)에서 우수한 성능을 보였다. 또한 미지의 방어에도 일반화되어 각 방어에 맞춘 수작업 적응 공격이 필요 없음을 보였다.

Conclusion: Lp-제약 기반 공격을 메타-학습 방식으로 전략적으로 조합하면 지각적으로 정렬된 강력한 적대적 예제를 만들 수 있다. DAASH는 실용적이고 강력한 평가용 기준선으로 사용될 수 있다.

Abstract: Numerous techniques have been proposed for generating adversarial examples in
white-box settings under strict Lp-norm constraints. However, such norm-bounded
examples often fail to align well with human perception, and only recently have
a few methods begun specifically exploring perceptually aligned adversarial
examples. Moreover, it remains unclear whether insights from Lp-constrained
attacks can be effectively leveraged to improve perceptual efficacy. In this
paper, we introduce DAASH, a fully differentiable meta-attack framework that
generates effective and perceptually aligned adversarial examples by
strategically composing existing Lp-based attack methods. DAASH operates in a
multi-stage fashion: at each stage, it aggregates candidate adversarial
examples from multiple base attacks using learned, adaptive weights and
propagates the result to the next stage. A novel meta-loss function guides this
process by jointly minimizing misclassification loss and perceptual distortion,
enabling the framework to dynamically modulate the contribution of each base
attack throughout the stages. We evaluate DAASH on adversarially trained models
across CIFAR-10, CIFAR-100, and ImageNet. Despite relying solely on
Lp-constrained based methods, DAASH significantly outperforms state-of-the-art
perceptual attacks such as AdvAD -- achieving higher attack success rates
(e.g., 20.63\% improvement) and superior visual quality, as measured by SSIM,
LPIPS, and FID (improvements $\approx$ of 11, 0.015, and 5.7, respectively).
Furthermore, DAASH generalizes well to unseen defenses, making it a practical
and strong baseline for evaluating robustness without requiring handcrafted
adaptive attacks for each new defense.

</details>


### [10] [Automated Assessment of Aesthetic Outcomes in Facial Plastic Surgery](https://arxiv.org/abs/2508.13363)
*Pegah Varghaei,Kiran Abraham-Aggarwal,Manoj T. Abraham,Arun Ross*

Main category: cs.CV

TL;DR: 이 논문은 전후 안면 사진을 이용해 얼굴성형 수술의 미적 결과를 정량적으로 평가하는 확장 가능하고 해석 가능한 컴퓨터 비전 파이프라인을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 수술 결과 평가의 주관성 문제를 해소하고, 수술 계획·환자 상담·성과 비교를 위해 재현 가능한 정량적 벤치마크와 대규모 데이터셋이 필요하다.

Method: (추가) 엄격한 필터링으로 전면 뷰 코 수술 서브셋(366명, 732장)과 전반적 전면 뷰 코호트(989명)를 구성하여 통계적 유의성 검증을 수행함.

Result: 코 성형군에서 알라 폭/얼굴 폭 비율, 코 길이/얼굴 높이 비율, 알라 폭/내안각 비율에서 각각 77.0%, 41.5%, 39.3%의 유의한 개선(p<0.001)을 관찰. 전면 코호트의 71.3%는 전체 얼굴 대칭 또는 인지 연령에서 유의미한 개선(p<0.01)을 보임. 개인 식별 일관성은 FMR 0.01% 기준 TMR 99.5% 및 99.6%로 유지.

Conclusion: 제시된 파이프라인과 대규모 공개 가능한(또는 재현 가능한) 데이터셋은 객관적, 재현 가능한 수술 결과 평가를 가능하게 하여 수술 계획·환자 상담·의사 간 성과 비교에 실용적 기여를 한다.

Abstract: We introduce a scalable, interpretable computer-vision framework for
quantifying aesthetic outcomes of facial plastic surgery using frontal
photographs. Our pipeline leverages automated landmark detection, geometric
facial symmetry computation, deep-learning-based age estimation, and nasal
morphology analysis. To perform this study, we first assemble the largest
curated dataset of paired pre- and post-operative facial images to date,
encompassing 7,160 photographs from 1,259 patients. This dataset includes a
dedicated rhinoplasty-only subset consisting of 732 images from 366 patients,
96.2% of whom showed improvement in at least one of the three nasal
measurements with statistically significant group-level change. Among these
patients, the greatest statistically significant improvements (p < 0.001)
occurred in the alar width to face width ratio (77.0%), nose length to face
height ratio (41.5%), and alar width to intercanthal ratio (39.3%). Among the
broader frontal-view cohort, comprising 989 rigorously filtered subjects, 71.3%
exhibited significant enhancements in global facial symmetry or perceived age
(p < 0.01). Importantly, our analysis shows that patient identity remains
consistent post-operatively, with True Match Rates of 99.5% and 99.6% at a
False Match Rate of 0.01% for the rhinoplasty-specific and general patient
cohorts, respectively. Additionally, we analyze inter-practitioner variability
in improvement rates. By providing reproducible, quantitative benchmarks and a
novel dataset, our pipeline facilitates data-driven surgical planning, patient
counseling, and objective outcome evaluation across practices.

</details>


### [11] [Applications of Small Language Models in Medical Imaging Classification with a Focus on Prompt Strategies](https://arxiv.org/abs/2508.13378)
*Yiting Wang,Ziwei Wang,Jiachen Zhong,Di Zhu,Weiyi Li*

Main category: cs.CV

TL;DR: 작은 언어 모델(SLM)들이 잘 설계된 프롬프트를 사용하면 흉부 X선(AP vs PA) 뷰 분류에서 대형 언어 모델에 비해 경쟁력 있는 정확도를 보이며, 자원 제약이 있는 의료 환경에서도 실용적일 수 있음을 보임.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLM)은 성능이 뛰어나지만 계산 비용, 접근성, 데이터 프라이버시 문제로 의료 현장 적용에 제약이 있다. 이러한 제약을 해결하기 위해 계산·자원 요구가 낮은 SLM의 실무 적합성을 평가하려 함.

Method: NIH Chest X-ray 데이터셋을 사용해 여러 SLM을 비교 평가. 분류 과제는 흉부 X선 촬영 위치(AP vs PA). 세 가지 프롬프트 전략(기본 지시, 점진적 요약 프롬프트, 정정 기반 반영 프롬프트)을 적용하여 각 모델의 정확도와 사용성 차이를 분석.

Result: 일부 SLM은 적절히 설계된 프롬프트 하에서 경쟁력 있는 정확도를 달성했으며, 프롬프트 엔지니어링이 SLM 성능을 상당히 향상시킴. 이는 최종 사용자에게 깊은 AI 전문지식 없이도 활용 가능함을 시사.

Conclusion: 프롬프트 설계만으로도 SLM을 의료 영상 분류에 실용적으로 적용할 수 있으며, 비용·프라이버시 제약이 있는 환경에서 대안이 될 수 있음. 추가로 모델별 성능 비교, 통계적 검정, 실제 임상 적용성 검증이 필요함.

Abstract: Large language models (LLMs) have shown remarkable capabilities in natural
language processing and multi-modal understanding. However, their high
computational cost, limited accessibility, and data privacy concerns hinder
their adoption in resource-constrained healthcare environments. This study
investigates the performance of small language models (SLMs) in a medical
imaging classification task, comparing different models and prompt designs to
identify the optimal combination for accuracy and usability. Using the NIH
Chest X-ray dataset, we evaluate multiple SLMs on the task of classifying chest
X-ray positions (anteroposterior [AP] vs. posteroanterior [PA]) under three
prompt strategies: baseline instruction, incremental summary prompts, and
correction-based reflective prompts. Our results show that certain SLMs achieve
competitive accuracy with well-crafted prompts, suggesting that prompt
engineering can substantially enhance SLM performance in healthcare
applications without requiring deep AI expertise from end users.

</details>


### [12] [AIM 2025 Rip Current Segmentation (RipSeg) Challenge Report](https://arxiv.org/abs/2508.13401)
*Andrei Dumitriu,Florin Miron,Florin Tatui,Radu Tudor Ionescu,Radu Timofte,Aakash Ralhan,Florin-Alexandru Vasluianu,Shenyang Qian,Mitchell Harley,Imran Razzak,Yang Song,Pu Luo,Yumei Li,Cong Xu,Jinming Chai,Kexin Zhang,Licheng Jiao,Lingling Li,Siqi Yu,Chao Zhang,Kehuan Song,Fang Liu,Puhua Chen,Xu Liu,Jin Hu,Jinyang Xu,Biao Liu*

Main category: cs.CV

TL;DR: The paper reports on AIM 2025 RipSeg Challenge for automatic rip current segmentation in still images, using the RipVIS dataset. 75 teams registered, 5 valid submissions; top methods used deep learning, domain adaptation, pretrained models and domain generalization. Evaluation used a composite score (F1, F2, AP50, AP[50:95]). The report describes dataset, challenge setup, metrics, results, challenges and future directions.


<details>
  <summary>Details</summary>
Motivation: Rip currents are dangerous and visual detection in images is underexplored; accurate instance segmentation is critical for safety and monitoring.

Method: Built on RipVIS dataset covering diverse locations and camera setups; focused on single-class instance segmentation. Evaluation used composite metrics (F1, F2, AP50, AP[50:95]). Participants applied deep learning architectures, pretrained models, domain adaptation and generalization strategies.

Result: 75 registered participants, 5 valid test submissions. Top-performing teams used advanced deep learning plus domain adaptation/generalization and pretrained backbones to handle variability. Rankings based on composite score.

Conclusion: The challenge provided a realistic, challenging benchmark highlighting current capabilities and gaps in rip current segmentation. The report discusses key challenges, lessons learned and directions to expand RipSeg and improve robustness across diverse conditions.

Abstract: This report presents an overview of the AIM 2025 RipSeg Challenge, a
competition designed to advance techniques for automatic rip current
segmentation in still images. Rip currents are dangerous, fast-moving flows
that pose a major risk to beach safety worldwide, making accurate visual
detection an important and underexplored research task. The challenge builds on
RipVIS, the largest available rip current dataset, and focuses on single-class
instance segmentation, where precise delineation is critical to fully capture
the extent of rip currents. The dataset spans diverse locations, rip current
types, and camera orientations, providing a realistic and challenging
benchmark.
  In total, $75$ participants registered for this first edition, resulting in
$5$ valid test submissions. Teams were evaluated on a composite score combining
$F_1$, $F_2$, $AP_{50}$, and $AP_{[50:95]}$, ensuring robust and
application-relevant rankings. The top-performing methods leveraged deep
learning architectures, domain adaptation techniques, pretrained models, and
domain generalization strategies to improve performance under diverse
conditions.
  This report outlines the dataset details, competition framework, evaluation
metrics, and final results, providing insights into the current state of rip
current segmentation. We conclude with a discussion of key challenges, lessons
learned from the submissions, and future directions for expanding RipSeg.

</details>


### [13] [Mitigating Easy Option Bias in Multiple-Choice Question Answering](https://arxiv.org/abs/2508.13428)
*Hao Zhang,Chen Li,Basura Fernando*

Main category: cs.CV

TL;DR: 이 논문은 일부 다지선다형 시각질문응답(VQA) 벤치마크에서 질문 없이도 시각+옵션(V+O)만으로 정답을 맞출 수 있는 Easy-Options Bias(EOB)를 발견하고, 이를 시정하기 위해 시각적으로 그럴듯한 하드 네거티브 옵션을 자동으로 생성하는 GroundAttack 도구를 제안한다. 수정된 데이터셋에서 기존 VLM들은 V+O 설정에서 우연 수준의 정확도를 보이며, V+Q+O 설정에서도 성능이 떨어져 보다 현실적인 평가가 가능해진다.


<details>
  <summary>Details</summary>
Motivation: 현재 다지선다형 VQA 벤치마크들은 옵션들 간 시각적 관련성 불균형 때문에 모델이 질문을 무시하고 비전-옵션 유사도만으로 정답을 고르는 쉬운 지름길(EOB)을 허용한다. 이는 모델의 실제 질의응답 능력을 과대평가하므로, 더 견고하고 현실적인 평가가 필요하다.

Method: 저자들은 시각-옵션 유사도 기반의 정답 편향을 규명하기 위해 그라운딩 실험을 수행하고, 이를 해소하기 위해 시각적으로 정답과 유사한 하드 네거티브 옵션을 자동으로 생성하는 GroundAttack 툴킷을 개발했다. 이 도구를 NExT-QA와 MMStar 데이터셋에 적용해 EOB-free 어노테이션을 생성했다.

Result: EOB-free 어노테이션에서 기존 VLM들은 (V+O) 입력만으로는 우연 수준의 정확도를 보이며, (V+Q+O)에서도 포화된 높은 정확도를 내지 못해 모델의 실제 QA 능력이 더 엄밀하게 드러난다.

Conclusion: EOB는 다지선다형 VQA 벤치마크의 신뢰도를 해치며, 시각적으로 그럴듯한 하드 네거티브 생성을 통해 이를 효과적으로 완화할 수 있다. GroundAttack과 수정된 데이터셋은 VLM 평가의 현실성을 높인다.

Abstract: In this early study, we observe an Easy-Options Bias (EOB) issue in some
multiple-choice Visual Question Answering (VQA) benchmarks such as MMStar,
RealWorldQA, SEED-Bench, Next-QA, STAR benchmark and Video-MME. This bias
allows vision-language models (VLMs) to select the correct answer using only
the vision (V) and options (O) as inputs, without the need for the question
(Q). Through grounding experiments, we attribute the bias to an imbalance in
visual relevance: the correct answer typically aligns more closely with the
visual contents than the negative options in feature space, creating a shortcut
for VLMs to infer the answer via simply vision-option similarity matching. To
fix this, we introduce GroundAttack, a toolkit that automatically generates
hard negative options as visually plausible as the correct answer. We apply it
to the NExT-QA and MMStar datasets, creating new EOB-free annotations. On these
EOB-free annotations, current VLMs approach to random accuracies under (V+O)
settings, and drop to non-saturated accuracies under (V+Q+O) settings,
providing a more realistic evaluation of VLMs' QA ability. Codes and new
annotations will be released soon.

</details>


### [14] [Structured Prompting and Multi-Agent Knowledge Distillation for Traffic Video Interpretation and Risk Inference](https://arxiv.org/abs/2508.13439)
*Yunxiang Yang,Ningning Xu,Jidong J. Yang*

Main category: cs.CV

TL;DR: 이 논문은 구조화된 체인-오브-생각(CoT) 기반의 프롬프트와 지식 증류를 결합해, 대형 VLM(GPT-4o, o3-mini)으로부터 고품질의 교통 장면 주석과 위험 평가를 자동 생성한다. 이를 학생 VLM(3B 규모, VISTA)으로 지도학습하여, 경량화된 모델이 저해상도 교통 비디오에서 의미론적이고 위험 인식 캡션을 생성할 수 있도록 한다. 실험에서 VISTA는 여러 캡션 지표(BLEU-4, METEOR, ROUGE-L, CIDEr)에서 교사 모델 대비 우수한 성능을 보이며 엣지 디바이스 실시간 모니터링에 적합하다.


<details>
  <summary>Details</summary>
Motivation: 기존 방법은 확장성과 일반화 문제로 실제 교통 환경의 복잡한 상황을 처리하기 어렵다. 대형 VLM의 추론 능력을 경량 모델로 이전해 엣지 배포 가능하면서도 위험 인식이 가능한 교통 장면 이해 모델을 만들고자 함.

Method: GPT-4o와 o3-mini의 다중 에이전트를 구조화된 CoT 전략으로 오케스트레이션하여 다각적 설명과 위험 평가를 생성한다. 생성된 출력은 지식이 풍부한 의사-주석(pseudo-annotations)으로 사용되어 3B 규모의 학생 VLM(VISTA)을 지도-파인튜닝한다. 핵심은 구조화된 프롬프트, 체인-오브-생각 흐름, 그리고 지식 증류로 경량 모델에 복잡한 추론 능력을 전달하는 것이다.

Result: VISTA는 BLEU-4, METEOR, ROUGE-L, CIDEr 등 표준 캡션 지표에서 교사 모델을 상회하거나 근접한 성능을 달성했다. 또한 저해상도 교통 비디오에 대해 의미론적으로 충실하고 위험 인식이 가능한 캡션을 생성하며, 파라미터가 훨씬 적음에도 강한 추론능력을 보였다.

Conclusion: 구조화된 멀티-에이전트 감독과 지식 증류는 경량 VLM이 복잡한 장면 이해와 위험 추론 능력을 획득하도록 하는 데 효과적이다. VISTA의 소형화된 아키텍처는 엣지 디바이스에서의 실시간 배포를 가능하게 하여 ITS와 자율주행 시스템에 실용적 이점을 제공한다.

Abstract: Comprehensive highway scene understanding and robust traffic risk inference
are vital for advancing Intelligent Transportation Systems (ITS) and autonomous
driving. Traditional approaches often struggle with scalability and
generalization, particularly under the complex and dynamic conditions of
real-world environments. To address these challenges, we introduce a novel
structured prompting and knowledge distillation framework that enables
automatic generation of high-quality traffic scene annotations and contextual
risk assessments. Our framework orchestrates two large Vision-Language Models
(VLMs): GPT-4o and o3-mini, using a structured Chain-of-Thought (CoT) strategy
to produce rich, multi-perspective outputs. These outputs serve as
knowledge-enriched pseudo-annotations for supervised fine-tuning of a much
smaller student VLM. The resulting compact 3B-scale model, named VISTA (Vision
for Intelligent Scene and Traffic Analysis), is capable of understanding
low-resolution traffic videos and generating semantically faithful, risk-aware
captions. Despite its significantly reduced parameter count, VISTA achieves
strong performance across established captioning metrics (BLEU-4, METEOR,
ROUGE-L, and CIDEr) when benchmarked against its teacher models. This
demonstrates that effective knowledge distillation and structured multi-agent
supervision can empower lightweight VLMs to capture complex reasoning
capabilities. The compact architecture of VISTA facilitates efficient
deployment on edge devices, enabling real-time risk monitoring without
requiring extensive infrastructure upgrades.

</details>


### [15] [EDTalk++: Full Disentanglement for Controllable Talking Head Synthesis](https://arxiv.org/abs/2508.13442)
*Shuai Tan,Bin Ji*

Main category: cs.CV

TL;DR: EDTalk++는 입 모양, 머리 포즈, 눈 움직임, 표정의 네 가지 잠재 공간으로 얼굴 동작을 완전히 분리해 제어 가능한 토킹헤드 생성을 목표로 한다. 각 공간은 학습 가능한 기저들의 선형 조합으로 모션을 표현하며, 기저들 간 직교성 제약과 효율적 학습 전략으로 상호간섭을 줄이고 학습을 가속한다. 학습된 기저는 뱅크에 저장되어 오디오 입력과도 시각적 프라이어를 공유할 수 있으며, 오디오 기반 합성을 위한 Audio-to-Motion 모듈을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 다양한 입력 모달리티(비디오, 오디오)를 수용하면서 입, 포즈, 눈, 표정 등 얼굴의 여러 동작을 서로 간섭 없이 독립적으로 제어할 수 있는 분리된 표현 학습의 필요성. 기존 방법들이 이 두 측면(독립성, 모달 간 공유)을 충분히 다루지 못함.

Method: 네 개의 경량 모듈을 사용하여 얼굴 동적 특성을 각각 입, 포즈, 눈, 표정의 잠재 공간으로 분해. 각 잠재 공간은 학습 가능한 기저 집합을 가지며 특정 모션은 이들의 선형 조합으로 표현된다. 기저들 사이에 직교성 제약(orthogonality)을 부과해 독립성 보장 및 학습 가속. 외부 지식 없이도 각 공간에 모션 책임을 배분하는 효율적 학습 전략을 설계. 학습된 기저는 뱅크에 저장되어 오디오 입력과도 공유 가능. 또한 공간 특성에 맞춘 Audio-to-Motion 모듈을 제안.

Result: 실험을 통해 EDTalk++가 제안한 완전 분리 프레임워크가 다양한 입력(비디오/오디오)에 대해 입, 포즈, 눈, 표정 등을 개별적으로 조작하고 자연스러운 토킹헤드 합성을 달성함을 보임.

Conclusion: EDTalk++는 얼굴 동작을 네 개의 독립된 잠재 공간으로 완전히 분리하여 서로 간섭 없이 제어 가능하게 하며, 학습된 모션 기저를 공유해 오디오 기반 합성까지 지원. 직교성 제약과 효율적 학습 전략으로 분해 품질과 학습 효율을 개선한다.

Abstract: Achieving disentangled control over multiple facial motions and accommodating
diverse input modalities greatly enhances the application and entertainment of
the talking head generation. This necessitates a deep exploration of the
decoupling space for facial features, ensuring that they a) operate
independently without mutual interference and b) can be preserved to share with
different modal inputs, both aspects often neglected in existing methods. To
address this gap, this paper proposes EDTalk++, a novel full disentanglement
framework for controllable talking head generation. Our framework enables
individual manipulation of mouth shape, head pose, eye movement, and emotional
expression, conditioned on video or audio inputs. Specifically, we employ four
lightweight modules to decompose the facial dynamics into four distinct latent
spaces representing mouth, pose, eye, and expression, respectively. Each space
is characterized by a set of learnable bases whose linear combinations define
specific motions. To ensure independence and accelerate training, we enforce
orthogonality among bases and devise an efficient training strategy to allocate
motion responsibilities to each space without relying on external knowledge.
The learned bases are then stored in corresponding banks, enabling shared
visual priors with audio input. Furthermore, considering the properties of each
space, we propose an Audio-to-Motion module for audio-driven talking head
synthesis. Experiments are conducted to demonstrate the effectiveness of
EDTalk++.

</details>


### [16] [Revisiting MLLM Token Technology through the Lens of Classical Visual Coding](https://arxiv.org/abs/2508.13460)
*Jinming Liu,Junyan Lin,Yuntao Wei,Kele Shao,Keda Tao,Jianguo Huang,Xudong Yang,Zhibo Chen,Huan Wang,Xin Jin*

Main category: cs.CV

TL;DR: This paper connects Multimodal Large Language Model (MLLM) token techniques with classical visual coding, providing a unified formulation and module-by-module comparison to transfer insights both ways and to outline future research directions.


<details>
  <summary>Details</summary>
Motivation: Both visual coding and MLLM token technology aim to maximize information fidelity while minimizing computational cost. The paper reexamines MLLM tokenization, compression, and reasoning using long-established principles from visual coding to find synergies and gaps.

Method: (1) Propose a unified mathematical/formulation bridging token technology and visual coding; (2) Perform a systematic, module-by-module comparative analysis (tokenization, token compression, token reasoning); (3) Synthesize bidirectional insights on how each field can inform the other; (4) Identify open challenges and future research directions.

Result: A structured mapping between MLLM token components and visual coding modules, concrete insights for improving MLLM token efficiency/robustness using visual-coding principles, and proposals for using token paradigms to design semantic visual codecs. The paper also lists promising future directions and unsolved problems.

Conclusion: This is the first comprehensive, structured comparison of MLLM token technology and visual coding, aiming to guide development of more efficient multimodal models and more capable semantic visual codecs.

Abstract: Classical visual coding and Multimodal Large Language Model (MLLM) token
technology share the core objective - maximizing information fidelity while
minimizing computational cost. Therefore, this paper reexamines MLLM token
technology, including tokenization, token compression, and token reasoning,
through the established principles of long-developed visual coding area. From
this perspective, we (1) establish a unified formulation bridging token
technology and visual coding, enabling a systematic, module-by-module
comparative analysis; (2) synthesize bidirectional insights, exploring how
visual coding principles can enhance MLLM token techniques' efficiency and
robustness, and conversely, how token technology paradigms can inform the
design of next-generation semantic visual codecs; (3) prospect for promising
future research directions and critical unsolved challenges. In summary, this
study presents the first comprehensive and structured technology comparison of
MLLM token and visual coding, paving the way for more efficient multimodal
models and more powerful visual codecs simultaneously.

</details>


### [17] [Vision Transformers for Kidney Stone Image Classification: A Comparative Study with CNNs](https://arxiv.org/abs/2508.13461)
*Ivan Reyes-Amezcua,Francisco Lopez-Tiro,Clement Larose,Andres Mendez-Vazquez,Gilberto Ochoa-Ruiz,Christian Daul*

Main category: cs.CV

TL;DR: ViT 기반 모델(ImageNet-21k로 사전학습)이 ResNet50보다 신장 결석 내시경 이미지 분류에서 전반적으로 우수하며, 특히 시각적 복잡도가 높은 부분에서 큰 성능 격차를 보임.


<details>
  <summary>Details</summary>
Motivation: 신장 결석의 유형 분류는 맞춤 치료와 재발 방지에 중요하지만, 기존 CNN은 장거리 의존성 포착에 한계가 있어 다양한 촬영 조건에서 성능이 저하될 수 있음.

Method: (중요 지점) 섹션 패치 등 시각적 복잡도가 높은 하위집합과 CCD 혼합뷰 하위집합을 포함한 다양한 조건에서 실험.

Result: ViT-base가 모든 조건에서 ResNet50을 능가. 예: 섹션 패치 하위집합에서 ViT 95.2% 정확도/95.1% F1 vs ResNet50 64.5%/59.3%. CCD 혼합뷰에서는 ViT 87.1% vs CNN 78.4%. 정밀도·재현율에서도 향상 보고.

Conclusion: ViT 계열 아키텍처가 내시경 신장 결석 이미지 분류에 대해 CNN보다 우수하며, 확장성 있는 대안으로 제시됨.

Abstract: Kidney stone classification from endoscopic images is critical for
personalized treatment and recurrence prevention. While convolutional neural
networks (CNNs) have shown promise in this task, their limited ability to
capture long-range dependencies can hinder performance under variable imaging
conditions. This study presents a comparative analysis between Vision
Transformers (ViTs) and CNN-based models, evaluating their performance on two
ex vivo datasets comprising CCD camera and flexible ureteroscope images. The
ViT-base model pretrained on ImageNet-21k consistently outperformed a ResNet50
baseline across multiple imaging conditions. For instance, in the most visually
complex subset (Section patches from endoscopic images), the ViT model achieved
95.2% accuracy and 95.1% F1-score, compared to 64.5% and 59.3% with ResNet50.
In the mixed-view subset from CCD-camera images, ViT reached 87.1% accuracy
versus 78.4% with CNN. These improvements extend across precision and recall as
well. The results demonstrate that ViT-based architectures provide superior
classification performance and offer a scalable alternative to conventional
CNNs for kidney stone image analysis.

</details>


### [18] [STER-VLM: Spatio-Temporal With Enhanced Reference Vision-Language Models](https://arxiv.org/abs/2508.13470)
*Tinh-Anh Nguyen-Nhu,Triet Dao Hoang Minh,Dat To-Thanh,Phuc Le-Gia,Tuan Vo-Lan,Tien-Huy Nguyen*

Main category: cs.CV

TL;DR: STER-VLM은 교통 분석을 위한 연산 효율적인 비전-언어 모델 프레임워크로, 공간·시간 정보를 분리해 처리하는 캡션 분해, 베스트뷰 필터를 포함한 프레임 선택, 레퍼런스 기반 동작 이해, 그리고 시각/텍스트 프롬프트 기법을 결합해 의미적 풍부성과 장면 해석을 크게 향상시킨다. WTS·BDD 데이터셋에서 성능 향상을 보였고, AI City Challenge 2025 Track 2에서 테스트 점수 55.655를 기록했다.


<details>
  <summary>Details</summary>
Motivation: 기존 VLM 기반 교통 분석은 계산 비용이 크고, 미세한 시공간(spatio-temporal) 정보(예: 움직임의 세부, 동적 문맥)를 충분히 포착하지 못한다는 한계가 있다. 따라서 저자들은 연산 효율을 유지하면서 시공간 이해를 개선할 방법이 필요하다고 보았다.

Method: (1) 캡션 분해: 공간 정보와 시간 정보를 별도로 처리해 각각에 특화된 설명 생성. (2) 시간 프레임 선택 + 베스트뷰 필터링: 핵심 시점만 골라 충분한 시간적 정보를 확보하고 최적 시야를 선택. (3) 레퍼런스 기반 이해: 기준 이미지/프레임을 활용해 미세한 동작과 동적 문맥을 포착. (4) 선별된 시각·텍스트 프롬프트 기법을 적용해 VLM 응답의 품질을 높임. 전반적으로 연산 효율성을 고려한 설계.

Result: WTS와 BDD 데이터셋 실험에서 의미적 풍부성과 교통 장면 해석 능력이 크게 개선됨. 실제 대회 성과로 AI City Challenge 2025 Track 2에서 테스트 점수 55.655를 달성해 실용성을 입증.

Conclusion: STER-VLM은 연산 자원이 제한된 환경에서도 정밀한 시공간 교통 분석을 가능하게 하는 실용적 접근이다. 실세계 적용 가능성이 높으며, 향후 멀티카메라 확장이나 실시간 처리 등으로 발전시킬 여지가 있다.

Abstract: Vision-language models (VLMs) have emerged as powerful tools for enabling
automated traffic analysis; however, current approaches often demand
substantial computational resources and struggle with fine-grained
spatio-temporal understanding. This paper introduces STER-VLM, a
computationally efficient framework that enhances VLM performance through (1)
caption decomposition to tackle spatial and temporal information separately,
(2) temporal frame selection with best-view filtering for sufficient temporal
information, and (3) reference-driven understanding for capturing fine-grained
motion and dynamic context and (4) curated visual/textual prompt techniques.
Experimental results on the WTS \cite{kong2024wts} and BDD \cite{BDD} datasets
demonstrate substantial gains in semantic richness and traffic scene
interpretation. Our framework is validated through a decent test score of
55.655 in the AI City Challenge 2025 Track 2, showing its effectiveness in
advancing resource-efficient and accurate traffic analysis for real-world
applications.

</details>


### [19] [MINR: Efficient Implicit Neural Representations for Multi-Image Encoding](https://arxiv.org/abs/2508.13471)
*Wenyong Zhou,Taiqiang Wu,Zhengwu Liu,Yuxin Cheng,Chen Zhang,Ngai Wong*

Main category: cs.CV

TL;DR: 여러 이미지를 각기 다른 MLP로 표현하는 대신, 중간층을 공유해 파라미터를 최대 60% 절감하면서 성능을 유지하는 방법(MINR). 100장 규모에서도 평균 PSNR 34 dB를 보임.


<details>
  <summary>Details</summary>
Motivation: INR은 이미지를 연속 함수로 표현하지만, 각 이미지를 별도의 MLP로 표현하면 다중 이미지 인코딩에서 연산·저장 비용이 급증함. 효율적인 다중 이미지 표현 방법이 필요함.

Method: 여러 학습된 INR의 층별 가중치 분포를 비교해 중간층들이 유사한 분포 패턴을 보인 것을 관찰. 이를 바탕으로 입력·출력층은 이미지별로 두고, 중간층은 여러 이미지에서 공유하도록 네트워크를 설계. 각 이미지에 고유한 특징을 잡기 위한 투영(projection) 레이어를 추가함.

Result: 이미지 복원 및 초해상도 실험에서 파라미터를 최대 60%까지 줄이면서 성능 저하를 거의 억제. 특히 100장 규모로 확장해도 평균 PSNR 34 dB를 유지. 다양한 백본에서도 견고한 성능을 보임.

Conclusion: 중간층 공유와 이미지별 투영 레이어 조합으로 다중 이미지 INR의 저장·연산 효율을 크게 개선함. 확장성과 백본 독립성이 입증되었으나, 표현력 한계나 투영층 설계에 따른 품질-효율 트레이드오프는 추가 연구가 필요함.

Abstract: Implicit Neural Representations (INRs) aim to parameterize discrete signals
through implicit continuous functions. However, formulating each image with a
separate neural network~(typically, a Multi-Layer Perceptron (MLP)) leads to
computational and storage inefficiencies when encoding multi-images. To address
this issue, we propose MINR, sharing specific layers to encode multi-image
efficiently. We first compare the layer-wise weight distributions for several
trained INRs and find that corresponding intermediate layers follow highly
similar distribution patterns. Motivated by this, we share these intermediate
layers across multiple images while preserving the input and output layers as
input-specific. In addition, we design an extra novel projection layer for each
image to capture its unique features. Experimental results on image
reconstruction and super-resolution tasks demonstrate that MINR can save up to
60\% parameters while maintaining comparable performance. Particularly, MINR
scales effectively to handle 100 images, maintaining an average peak
signal-to-noise ratio (PSNR) of 34 dB. Further analysis of various backbones
proves the robustness of the proposed MINR.

</details>


### [20] [Distribution-Aware Hadamard Quantization for Hardware-Efficient Implicit Neural Representations](https://arxiv.org/abs/2508.13478)
*Wenyong Zhou,Jiachen Ren,Taiqiang Wu,Yuxin Cheng,Zhengwu Liu,Ngai Wong*

Main category: cs.CV

TL;DR: 이 논문은 INRs(Implicit Neural Representations)의 가중치와 활성화를 모두 양자화하는 분포-인지 Hadamard 양자화(DHQ)를 제안한다. Hadamard 변환으로 서로 다른 분포를 종 모양으로 표준화한 뒤 표준 양자화를 적용하여 하드웨어 효율을 크게 개선하고, FPGA 구현에서 지연 32.7% 감소, 에너지 40.1% 절감, 자원 사용 최대 98.3% 절약을 보였다.


<details>
  <summary>Details</summary>
Motivation: INRs는 높은 성능을 보이지만, 정확한 계산을 위해 고정밀(풀 프리시전) 수치 표현에 의존해 하드웨어 비용이 크다. 기존 연구는 주로 가중치 양자화에만 집중해 활성화가 여전히 풀 프리시전을 사용함으로써 하드웨어 이득이 제한적이었다.

Method: DHQ는 가중치와 활성화를 모두 양자화하는 분포-인지 방법이다. 분석을 통해 첫 번째 및 마지막 레이어의 가중치 분포와 마지막 레이어의 활성화 분포가 중간 레이어와 다르다는 점을 확인했다. Hadamard 변환을 적용해 다양한 분포를 종(가우시안) 형태로 표준화한 뒤, 단일 표준 양자화기를 적용한다. 이론적 분석과 실험적 증거를 통해 변환 후 분포 정규화가 정당화된다. 또한 FPGA 상에서 DHQ를 구현해 하드웨어 효율을 실증했다.

Result: 다양한 이미지 복원(task) 실험에서 DHQ는 기존 양자화 방법들보다 우수했다. FPGA 구현 결과: 지연 32.7% 감소, 에너지 소모 40.1% 절감, 자원 사용 최대 98.3% 절약. 전반적으로 하드웨어 효율과 성능 측면에서 개선이 관찰되었다.

Conclusion: Hadamard 변환을 이용해 분포 차이를 표준화하고 가중치·활성화를 모두 양자화함으로써 INRs의 하드웨어 효율을 크게 향상시킬 수 있다. DHQ는 실질적인 FPGA 이득을 보여주며, INRs의 저전력·저지연 응용에 유용하다.

Abstract: Implicit Neural Representations (INRs) encode discrete signals using
Multi-Layer Perceptrons (MLPs) with complex activation functions. While INRs
achieve superior performance, they depend on full-precision number
representation for accurate computation, resulting in significant hardware
overhead. Previous INR quantization approaches have primarily focused on weight
quantization, offering only limited hardware savings due to the lack of
activation quantization. To fully exploit the hardware benefits of
quantization, we propose DHQ, a novel distribution-aware Hadamard quantization
scheme that targets both weights and activations in INRs. Our analysis shows
that the weights in the first and last layers have distributions distinct from
those in the intermediate layers, while the activations in the last layer
differ significantly from those in the preceding layers. Instead of customizing
quantizers individually, we utilize the Hadamard transformation to standardize
these diverse distributions into a unified bell-shaped form, supported by both
empirical evidence and theoretical analysis, before applying a standard
quantizer. To demonstrate the practical advantages of our approach, we present
an FPGA implementation of DHQ that highlights its hardware efficiency.
Experiments on diverse image reconstruction tasks show that DHQ outperforms
previous quantization methods, reducing latency by 32.7\%, energy consumption
by 40.1\%, and resource utilization by up to 98.3\% compared to full-precision
counterparts.

</details>


### [21] [AIM 2025 challenge on Inverse Tone Mapping Report: Methods and Results](https://arxiv.org/abs/2508.13479)
*Chao Wang,Francesco Banterle,Bin Ren,Radu Timofte,Xin Lu,Yufeng Peng,Chengjie Ge,Zhijing Sun,Ziang Zhou,Zihao Li,Zishun Liao,Qiyu Kang,Xueyang Fu,Zheng-Jun Zha,Zhijing Sun,Xingbo Wang,Kean Liu,Senyan Xu,Yang Qiu,Yifan Ding,Gabriel Eilertsen,Jonas Unger,Zihao Wang,Ke Wu,Jinshan Pan,Zhen Liu,Zhongyang Li,Shuaicheng Liu,S. M Nadim Uddin*

Main category: cs.CV

TL;DR: AIM 2025의 Inverse Tone Mapping 챌린지(단일 LDR로부터 HDR 복원)에 대한 종합 리뷰로, 67명의 참가자가 319개의 유효 결과를 제출했으며 상위 5팀의 방법과 성능을 분석해 퍼셉추얼 및 수치적 일관성을 중시한 벤치마크를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 단일 LDR 이미지로부터 고품질 HDR을 재구성하는 ITM 알고리즘 개발을 촉진하고, 사람 인지적 품질(퍼셉추얼 충실도)과 수치적 일관성 모두를 고려한 평가 기준을 확립하기 위함.

Method: AIM 2025 ITM 챌린지를 개최해 참가자들의 알고리즘을 모집·평가(총 67명, 319개 결과). 제출 결과 중 상위 5팀을 선정해 각 팀의 방법론과 성능을 정리·비교하였고, PU21-PSNR 등 성능 지표를 통해 정량적 평가를 수행함.

Result: 상위 엔트리들의 성능을 종합한 결과, 상위 항목들 중 최저 PU21-PSNR 값이 29.22 dB에 달했으며(즉 상위권 성능이 이 수준 이상임), 참가자들이 제안한 다양한 혁신적 전략들이 HDR 복원 품질 향상에 기여함을 확인함.

Conclusion: 챌린지는 ITM 연구의 현 수준을 정리하고 강력한 성능 벤치마크를 확립했으며, 다양한 혁신적 접근법을 통해 향후 연구 방향과 개선 포인트를 제시한다.

Abstract: This paper presents a comprehensive review of the AIM 2025 Challenge on
Inverse Tone Mapping (ITM). The challenge aimed to push forward the development
of effective ITM algorithms for HDR image reconstruction from single LDR
inputs, focusing on perceptual fidelity and numerical consistency. A total of
\textbf{67} participants submitted \textbf{319} valid results, from which the
best five teams were selected for detailed analysis. This report consolidates
their methodologies and performance, with the lowest PU21-PSNR among the top
entries reaching 29.22 dB. The analysis highlights innovative strategies for
enhancing HDR reconstruction quality and establishes strong benchmarks to guide
future research in inverse tone mapping.

</details>


### [22] [Enhancing Robustness of Implicit Neural Representations Against Weight Perturbations](https://arxiv.org/abs/2508.13481)
*Wenyong Zhou,Yuxin Cheng,Zhengwu Liu,Taiqiang Wu,Chen Zhang,Ngai Wong*

Main category: cs.CV

TL;DR: INR 네트워크의 가중치 소량 변경에도 재구성 품질이 크게 떨어지는 취약성을 발견하고, 가중치 교란 유무의 손실 차이를 최소화하는 새로운 강건 손실을 도입해 재구성 손실의 가중치에 대한 그래디언트를 규제함으로써 잡음 환경에서 최대 7.5 dB PSNR 향상을 달성함.


<details>
  <summary>Details</summary>
Motivation: INR(Implicit Neural Representations)는 연속적인 방식으로 신호를 인코딩해 다양한 멀티미디어 응용에서 유용하지만, 실제 배포 시 가중치에 불가피한 교란(노이즈, 전송 오류 등)이 발생할 수 있어 재구성 성능 저하라는 중대한 문제가 있음.

Method: 가중치에 대한 교란을 고려한 강건성 문제를 "교란이 있을 때와 없을 때의 손실 차이 최소화"로 정식화하고, 재구성 손실을 가중치에 대해 미분한 그래디언트를 제어하는 새로운 강건 손실 함수를 유도하여 네트워크가 가중치 변화에 덜 민감하도록 학습함.

Result: 여러 모달리티(예: 이미지, 오디오 등) 재구성 실험에서 기존 INR 대비 노이즈 환경에서 PSNR 최대 7.5 dB 향상을 기록함.

Conclusion: 제안한 손실 설계로 INR의 가중치 교란에 대한 민감도를 효과적으로 낮춰 실전적 강건성을 크게 개선할 수 있으며, 이는 INR의 실세계 배포 가능성을 높여 줌.

Abstract: Implicit Neural Representations (INRs) encode discrete signals in a
continuous manner using neural networks, demonstrating significant value across
various multimedia applications. However, the vulnerability of INRs presents a
critical challenge for their real-world deployments, as the network weights
might be subjected to unavoidable perturbations. In this work, we investigate
the robustness of INRs for the first time and find that even minor
perturbations can lead to substantial performance degradation in the quality of
signal reconstruction. To mitigate this issue, we formulate the robustness
problem in INRs by minimizing the difference between loss with and without
weight perturbations. Furthermore, we derive a novel robust loss function to
regulate the gradient of the reconstruction loss with respect to weights,
thereby enhancing the robustness. Extensive experiments on reconstruction tasks
across multiple modalities demonstrate that our method achieves up to a 7.5~dB
improvement in peak signal-to-noise ratio (PSNR) values compared to original
INRs under noisy conditions.

</details>


### [23] [FAMNet: Integrating 2D and 3D Features for Micro-expression Recognition via Multi-task Learning and Hierarchical Attention](https://arxiv.org/abs/2508.13483)
*Liangyu Fu,Xuecheng Wu,Danlei Huang,Xinyi Yin*

Main category: cs.CV

TL;DR: 본 논문은 2D·3D CNN 결합, 다중과제 학습(미세표정 인식 + 안면행동단위 검출), 계층적 어텐션 및 파라미터 공유를 통해 미세표정 인식 성능을 높인 FAMNet을 제안한다. 다양한 데이터 로딩 방식으로 AMNet2D/AMNet3D를 학습한 뒤 합쳐 최종 성능을 향상시키며, 여러 데이터셋에서 우수한 결과를 보인다.


<details>
  <summary>Details</summary>
Motivation: 미세표정은 짧은 지속시간과 낮은 강도로 인해 특징 추출이 어렵고, 기존 딥러닝 방법들은 정적 이미지, 동적 시퀀스, 또는 두 스트림 결합의 세 가지 데이터 로딩 방식에 의존해왔다. 미세표정의 세밀하고 시공간적 특징을 효과적으로 추출하는 것이 핵심 문제이다.

Method: 제안된 방법은 2D CNN(AMNet2D)과 3D CNN(AMNet3D)을 병렬로 구성하여 ResNet18을 공유 백본으로 사용하고 계층적 어텐션 모듈을 도입한다. 서로 다른 데이터 로딩 방식을 각 네트워크에 적용해 학습하며, 미세표정 인식(MER)과 안면 행동 단위 검출(FAUD)을 다중과제로 공동학습한다. 파라미터 하드 셰어링을 통해 정보 연계를 강화하고, 최종적으로 두 네트워크를 융합한 FAMNet을 도출한다.

Result: 제안된 FAMNet은 SAMM, CASME II, MMEW 데이터셋에서 UAR 83.75% 및 UF1 84.03%를 기록했으며, 보다 어려운 CAS(ME)^3 데이터셋에서는 UAR 51% 및 UF1 43.42%를 달성했다. 이는 제안 모델이 기존 방법들보다 MER 성능을 유의하게 향상시킴을 시사한다.

Conclusion: 2D와 3D 스트림의 결합, 계층적 어텐션, 그리고 다중과제 하드 파라미터 공유는 미세표정의 세밀하고 시공간적 특징을 잘 포착하여 MER 성능을 크게 향상시킨다. FAMNet은 다양한 데이터셋에서 강건한 성능을 보이며, 특히 어려운 데이터셋에서도 개선을 달성했다.

Abstract: Micro-expressions recognition (MER) has essential application value in many
fields, but the short duration and low intensity of micro-expressions (MEs)
bring considerable challenges to MER. The current MER methods in deep learning
mainly include three data loading methods: static images, dynamic image
sequence, and a combination of the two streams. How to effectively extract MEs'
fine-grained and spatiotemporal features has been difficult to solve. This
paper proposes a new MER method based on multi-task learning and hierarchical
attention, which fully extracts MEs' omni-directional features by merging 2D
and 3D CNNs. The fusion model consists of a 2D CNN AMNet2D and a 3D CNN
AMNet3D, with similar structures consisting of a shared backbone network
Resnet18 and attention modules. During training, the model adopts different
data loading methods to adapt to two specific networks respectively, jointly
trains on the tasks of MER and facial action unit detection (FAUD), and adopts
the parameter hard sharing for information association, which further improves
the effect of the MER task, and the final fused model is called FAMNet.
Extensive experimental results show that our proposed FAMNet significantly
improves task performance. On the SAMM, CASME II and MMEW datasets, FAMNet
achieves 83.75% (UAR) and 84.03% (UF1). Furthermore, on the challenging
CAS(ME)$^3$ dataset, FAMNet achieves 51% (UAR) and 43.42% (UF1).

</details>


### [24] [CORENet: Cross-Modal 4D Radar Denoising Network with LiDAR Supervision for Autonomous Driving](https://arxiv.org/abs/2508.13485)
*Fuyang Liu,Jilin Mei,Fangyuan Mao,Chen Min,Yan Xing,Yu Hu*

Main category: cs.CV

TL;DR: CORENet은 학습 시 LiDAR를 이용한 교차-모달 소거(supervision)로 4D 레이더의 잡음 패턴을 학습해 레이더 포인트클라우드의 노이즈를 제거하고, 학습 후에는 레이더 단독으로 동작하는 플러그앤플레이형 voxel 기반 객체검출용 denoising 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 4D 레이더는 악천후에서도 강인하고 풍부한 공간 정보를 제공하지만 포인트클라우드가 매우 희소하고 잡음이 심해 기존 검출 성능이 저하된다. LiDAR의 깨끗한 신호를 활용해 레이더의 노이즈를 효과적으로 제거하고자 함.

Method: CORENet은 LiDAR로부터 얻은 신호를 감독(supervision)으로 사용해 레이더의 잡음 패턴을 식별하고 판별적 특징을 추출하는 교차-모달 denoising 네트워크를 제안한다. 구조는 voxel 기반 검출 파이프라인에 수정 없이 플러그앤플레이로 삽입 가능하며, 학습 시에만 LiDAR를 사용하고 추론 시에는 레이더 전용으로 동작한다.

Result: 잡음 수준이 높은 Dual-Radar 데이터셋에서 광범위한 실험을 통해 검출 강인성이 향상됨을 보였고, 기존 주류 접근법들보다 우수한 성능을 달성했다.

Conclusion: CORENet은 LiDAR 감독을 통해 4D 레이더 포인트의 노이즈를 효과적으로 완화하여 voxel 기반 객체검출의 성능을 향상시키며, 실제 배치에서는 레이더 전용 추론을 유지해 실용성이 높다.

Abstract: 4D radar-based object detection has garnered great attention for its
robustness in adverse weather conditions and capacity to deliver rich spatial
information across diverse driving scenarios. Nevertheless, the sparse and
noisy nature of 4D radar point clouds poses substantial challenges for
effective perception. To address the limitation, we present CORENet, a novel
cross-modal denoising framework that leverages LiDAR supervision to identify
noise patterns and extract discriminative features from raw 4D radar data.
Designed as a plug-and-play architecture, our solution enables seamless
integration into voxel-based detection frameworks without modifying existing
pipelines. Notably, the proposed method only utilizes LiDAR data for
cross-modal supervision during training while maintaining full radar-only
operation during inference. Extensive evaluation on the challenging Dual-Radar
dataset, which is characterized by elevated noise level, demonstrates the
effectiveness of our framework in enhancing detection robustness. Comprehensive
experiments validate that CORENet achieves superior performance compared to
existing mainstream approaches.

</details>


### [25] [Multi-view Clustering via Bi-level Decoupling and Consistency Learning](https://arxiv.org/abs/2508.13499)
*Shihao Dong,Yuhui Zheng,Huiying Xu,Xinzhong Zhu*

Main category: cs.CV

TL;DR: BDCL은 멀티뷰 데이터에서 특성의 군집 간 판별력(inter-cluster discriminability)과 군집 내 응집력(intra-cluster compactness)을 동시에 향상시키기 위해, 인스턴스 정렬·비공유 특징 보존, 특징·클러스터의 이중 분해(bi-level decoupling), 그리고 뷰와 이웃을 양성 쌍으로 하는 할당 일관성 학습을 결합한 새로운 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 기존 멀티뷰 클러스터링은 뷰 간 일관성(consistency)과 상보성(complementarity)을 학습해 성능을 끌어올렸지만, 클러스터 지향의 표현 학습(cluster-oriented representation learning)은 간과되는 경우가 많아 군집 간 분별성과 군집 내 응집력을 동시에 개선할 필요가 있다.

Method: BDCL은 세 모듈로 구성된다: (1) 멀티뷰 인스턴스 학습 모듈 — 재구성 오토인코더와 대조학습으로 뷰 간의 공통 정보는 정렬하고 사적(private) 특징은 보존; (2) 특징과 클러스터의 이중 분해 — 피처 공간과 클러스터 공간을 분리해 판별성 향상; (3) 일관성 학습 모듈 — 샘플의 서로 다른 뷰와 그 이웃을 양성 쌍으로 취급하여 클러스터 할당의 일관성을 학습하고 군집 내 공간을 추가로 압축.

Result: 다섯 개의 벤치마크 데이터셋에서 SOTA 대비 우수한 성능을 보였으며, 코드가 공개되어 재현 가능함.

Conclusion: 뷰 간 정렬과 사적 특징 보존, 이중 분해, 그리고 클러스터 할당 일관성 학습의 결합으로 멀티뷰 클러스터링에서 더 구별력 있는 표현과 더 응집된 군집을 얻을 수 있음을 보였다.

Abstract: Multi-view clustering has shown to be an effective method for analyzing
underlying patterns in multi-view data. The performance of clustering can be
improved by learning the consistency and complementarity between multi-view
features, however, cluster-oriented representation learning is often
overlooked. In this paper, we propose a novel Bi-level Decoupling and
Consistency Learning framework (BDCL) to further explore the effective
representation for multi-view data to enhance inter-cluster discriminability
and intra-cluster compactness of features in multi-view clustering. Our
framework comprises three modules: 1) The multi-view instance learning module
aligns the consistent information while preserving the private features between
views through reconstruction autoencoder and contrastive learning. 2) The
bi-level decoupling of features and clusters enhances the discriminability of
feature space and cluster space. 3) The consistency learning module treats the
different views of the sample and their neighbors as positive pairs, learns the
consistency of their clustering assignments, and further compresses the
intra-cluster space. Experimental results on five benchmark datasets
demonstrate the superiority of the proposed method compared with the SOTA
methods. Our code is published on https://github.com/LouisDong95/BDCL.

</details>


### [26] [AdaptiveAE: An Adaptive Exposure Strategy for HDR Capturing in Dynamic Scenes](https://arxiv.org/abs/2508.13503)
*Tianyi Xu,Fan Zhang,Boxin Shi,Tianfan Xue,Yujin Wang*

Main category: cs.CV

TL;DR: AdaptiveAE는 강화학습을 이용해 제한된 노출시간(노출 예산) 안에서 셔터 속도와 ISO 조합을 최적으로 선택해 동적 장면에서 HDR 재구성 품질을 향상시키는 방법이다. 학습 시 모션 블러와 노이즈를 합성하여 시뮬레이션하고, 시맨틱 정보와 노출 히스토그램을 활용한다. 다양한 데이터셋에서 기존 방법보다 우수한 성능을 보였다.


<details>
  <summary>Details</summary>
Motivation: HDR 영상에서는 셔터 속도와 ISO의 균형이 중요하다. 높은 ISO는 노이즈를 유발하고 긴 셔터 속도는 모션 블러를 초래한다. 기존 방법들은 셔터와 ISO의 상호작용을 충분히 고려하지 않으며 동적 장면에서의 모션 블러를 반영하지 못한다.

Method: AdaptiveAE는 강화학습 에이전트를 통해 사용자 정의 노출 예산 내에서 셔터 속도와 ISO 시퀀스를 적응적으로 선택한다. 학습을 위해 모션 블러 및 노이즈를 시뮬레이션하는 이미지 합성 파이프라인을 통합하고, 시맨틱 정보와 노출 히스토그램을 입력으로 활용한다. 에이전트는 다양한 조합을 탐색해 최적 노출 스케줄을 학습한다.

Result: 다중 데이터셋에서 평가한 결과 AdaptiveAE는 전통적 노출 스케줄과 기존 HDR 복원 기법들보다 우수한 HDR 재구성 품질을 달성했다.

Conclusion: 셧터 속도와 ISO의 복잡한 상호작용을 고려하고 모션 블러와 노이즈를 학습에 통합함으로써 AdaptiveAE는 제한된 노출 시간 상황에서 동적 장면의 HDR 재구성 성능을 향상시킨다.

Abstract: Mainstream high dynamic range imaging techniques typically rely on fusing
multiple images captured with different exposure setups (shutter speed and
ISO). A good balance between shutter speed and ISO is crucial for achieving
high-quality HDR, as high ISO values introduce significant noise, while long
shutter speeds can lead to noticeable motion blur. However, existing methods
often overlook the complex interaction between shutter speed and ISO and fail
to account for motion blur effects in dynamic scenes.
  In this work, we propose AdaptiveAE, a reinforcement learning-based method
that optimizes the selection of shutter speed and ISO combinations to maximize
HDR reconstruction quality in dynamic environments. AdaptiveAE integrates an
image synthesis pipeline that incorporates motion blur and noise simulation
into our training procedure, leveraging semantic information and exposure
histograms. It can adaptively select optimal ISO and shutter speed sequences
based on a user-defined exposure time budget, and find a better exposure
schedule than traditional solutions. Experimental results across multiple
datasets demonstrate that it achieves the state-of-the-art performance.

</details>


### [27] [Bridging the Gap: Doubles Badminton Analysis with Singles-Trained Models](https://arxiv.org/abs/2508.13507)
*Seungheon Baek,Jinhyuk Yun*

Main category: cs.CV

TL;DR: 본 논문은 싱글용으로 학습된 포즈 기반 모델을 복식 배드민턴 분석에 전이하여, ViT-Pose로 키포인트를 추출하고 ST-GCN 기반 대조학습 임베딩과 커스텀 다중객체 추적을 활용해 샷 인식을 수행함으로써 복식 분석 가능성을 입증한다.


<details>
  <summary>Details</summary>
Motivation: 국제대회에서 복식 경기가 더 빈번하지만 데이터 부족과 다중인물 추적의 어려움으로 기존 연구는 주로 싱글에 치중되어 있어 복식 전용 분석 방법과 데이터의 필요성이 존재한다.

Method: ShuttleSet 싱글 경기 데이터에서 ViT-Pose로 키포인트 추출, ST-GCN 기반 대조학습(contrastive learning)으로 포즈 임베딩 생성, 빠르고 겹치는 선수 움직임으로 인한 ID 스위칭 문제를 해결하는 커스텀 다중객체 추적 알고리즘 적용, 임베딩을 입력으로 Transformer 기반 분류기가 샷 발생 여부 판정.

Result: 싱글로 학습된 포즈 기반 모델을 복식에 전이하는 것이 실현 가능함을 보였고, 커스텀 추적 기법이 추적 안정성을 개선했으며 Transformer 분류기로 샷 인식이 가능함을 시사하는 성과를 제시함.

Conclusion: 포즈 기반 샷 인식을 복식으로 확장할 수 있음을 보여 복식 전용 데이터셋 구축과 추가 연구를 위한 기초를 마련했으며, 향후 복식 특화 데이터와 평가 지표가 개발되면 분석 능력이 크게 향상될 것으로 기대됨.

Abstract: Badminton is known as one of the fastest racket sports in the world. Despite
doubles matches being more prevalent in international tournaments than singles,
previous research has mainly focused on singles due to the challenges in data
availability and multi-person tracking. To address this gap, we designed an
approach that transfers singles-trained models to doubles analysis. We
extracted keypoints from the ShuttleSet single matches dataset using ViT-Pose
and embedded them through a contrastive learning framework based on ST-GCN. To
improve tracking stability, we incorporated a custom multi-object tracking
algorithm that resolves ID switching issues from fast and overlapping player
movements. A Transformer-based classifier then determines shot occurrences
based on the learned embeddings. Our findings demonstrate the feasibility of
extending pose-based shot recognition to doubles badminton, broadening
analytics capabilities. This work establishes a foundation for doubles-specific
datasets to enhance understanding of this predominant yet understudied format
of the fast racket sport.

</details>


### [28] [2D Gaussians Meet Visual Tokenizer](https://arxiv.org/abs/2508.13515)
*Yiang Shi,Xiaoyang Guo,Wei Yin,Mingkai Jia,Qian Zhang,Xiaolin Hu,Wenyu Liu,Xinggang Wan*

Main category: cs.CV

TL;DR: VGQ(Visual Gaussian Quantization)는 기존 VQ-GAN 등 패치 기반 토크나이저의 한계를 보완해, 이미지 잠재 표현을 2D 가우시안 분포로 인코딩하여 위치·회전·스케일 같은 구조적 정보를 명시적으로 모델링한다. 가우시안 밀도를 높이면 재구성 성능이 크게 향상되며, ImageNet 256×256에서 rFID 0.556, PSNR 24.93으로 SOTA 성능을 달성했다.


<details>
  <summary>Details</summary>
Motivation: 기존의 양자화 기반 이미지 토크나이저(VQ-GAN 등)는 패치 기반 설계로 텍스처·색상 같은 외형 정보에 치중해 기하학적 구조(위치·회전·스케일 등)를 충분히 잡아내지 못한다. AR 이미지 생성 등에서 더 풍부하고 구조적인 시각 정보를 압축 표현에 포함시킬 필요가 있다.

Method: VGQ 프레임워크: 이미지 잠재를 전통적 코드북 양자화에 2D 가우시안 분포를 통합해 인코딩. 각 토큰은 2D 가우시안의 위치·회전·스케일 등의 파라미터를 직접 모델링하며, 토큰 내에 다수의 2D 가우시안을 배치해 구조적 밀도를 조절할 수 있다. 이를 통해 패치 기반 표현의 한계를 극복하고 공간적·기하학적 정보를 보존.

Result: ImageNet 256×256 재구성에서 기본 VGQ는 rFID 1.00을 달성. 가우시안 밀도를 높이면 재구성 성능이 크게 개선되어 최고 rFID 0.556, PSNR 24.93으로 기존 방법들을 크게 앞섰다.

Conclusion: 2D 가우시안 기반 토크나이제이션은 기하학적·공간적 구조를 효율적으로 캡처해 재구성 품질을 크게 향상시킨다. 가우시안 밀도로 토큰 효율성과 시각 풍부성 간의 유연한 트레이드오프를 제공하며 AR 이미지 생성 등 구조적 정보가 중요한 응용에 유용하다.

Abstract: The image tokenizer is a critical component in AR image generation, as it
determines how rich and structured visual content is encoded into compact
representations. Existing quantization-based tokenizers such as VQ-GAN
primarily focus on appearance features like texture and color, often neglecting
geometric structures due to their patch-based design. In this work, we explored
how to incorporate more visual information into the tokenizer and proposed a
new framework named Visual Gaussian Quantization (VGQ), a novel tokenizer
paradigm that explicitly enhances structural modeling by integrating 2D
Gaussians into traditional visual codebook quantization frameworks. Our
approach addresses the inherent limitations of naive quantization methods such
as VQ-GAN, which struggle to model structured visual information due to their
patch-based design and emphasis on texture and color. In contrast, VGQ encodes
image latents as 2D Gaussian distributions, effectively capturing geometric and
spatial structures by directly modeling structure-related parameters such as
position, rotation and scale. We further demonstrate that increasing the
density of 2D Gaussians within the tokens leads to significant gains in
reconstruction fidelity, providing a flexible trade-off between token
efficiency and visual richness. On the ImageNet 256x256 benchmark, VGQ achieves
strong reconstruction quality with an rFID score of 1.00. Furthermore, by
increasing the density of 2D Gaussians within the tokens, VGQ gains a
significant boost in reconstruction capability and achieves a state-of-the-art
reconstruction rFID score of 0.556 and a PSNR of 24.93, substantially
outperforming existing methods. Codes will be released soon.

</details>


### [29] [Calibrating Biased Distribution in VFM-derived Latent Space via Cross-Domain Geometric Consistency](https://arxiv.org/abs/2508.13518)
*Yanbiao Ma,Wei Dai,Bowei Liu,Jiayi Chen,Wenke Huang,Guancheng Wan,Zhiwu Lu,Junchi Yan*

Main category: cs.CV

TL;DR: 비전 파운데이션 모델(CLP, DINOv2 등)에서 추출한 특징 공간의 기하학적 분포 형태가 도메인 및 데이터셋 간에 잘 전이된다는 사실을 이용해, 이 기하학적 지식을 기반으로 데이터 분포를 보정하여 연합학습과 롱테일 인식에서 성능을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 실제 관측된 학습 샘플과 근본적 진짜 분포 사이의 차이(샘플링 편향, 노이즈 등)가 학습 성능을 저해한다. 파운데이션 모델의 특징이형 분포의 기하학적 구조가 도메인 간 전이 가능하다는 점을 활용하면 이 격차를 줄일 수 있다.

Method: 오프더쉘프 비전 파운데이션 모델을 통해 특징을 추출하고, 특징 분포의 기하학적 형태를 추정·공유한다. 연합학습에서는 개인정보 제약 하에 글로벌 기하학적 형태를 획득하는 기법을 고안하고 이를 바탕으로 클라이언트에 새로운 샘플을 생성해 지역·전역 관측의 차이를 좁힌다. 롱테일 학습에서는 샘플 풍부(헤드) 클래스에서 전이된 기하학 지식을 이용해 샘플 희소(테일) 클래스의 진짜 분포를 복원한다.

Result: 종합적인 실험에서 제안한 기하학 지식 기반 분포 보정 기법이 데이터 이질성 및 샘플 불균형으로 인한 정보 결핍을 효과적으로 극복하며, 연합학습과 롱테일 인식의 다양한 벤치마크에서 성능 향상을 보였다.

Conclusion: 파운데이션 모델의 특징 공간 기하학을 전이·활용하는 분포 보정 프레임워크는 프라이버시 제약과 샘플 불균형 문제를 완화하며 실무적 유용성을 가진다.

Abstract: Despite the fast progress of deep learning, one standing challenge is the gap
of the observed training samples and the underlying true distribution. There
are multiple reasons for the causing of this gap e.g. sampling bias, noise etc.
In the era of foundation models, we show that when leveraging the off-the-shelf
(vision) foundation models (e.g., CLIP, DINOv2) for feature extraction, the
geometric shapes of the resulting feature distributions exhibit remarkable
transferability across domains and datasets. To verify its practical
usefulness, we embody our geometric knowledge-guided distribution calibration
framework in two popular and challenging settings: federated learning and
long-tailed recognition. In the federated setting, we devise a technique of
acquiring the global geometric shape under privacy constraints, then leverage
this knowledge to generate new samples for clients, in the aim of bridging the
gap between local and global observations. In long-tailed learning, it utilizes
the geometric knowledge transferred from sample-rich categories to recover the
true distribution for sample-scarce tail classes. Comprehensive experiments
show that our proposed geometric knowledge-guided distribution calibration
effectively overcomes information deficits caused by data heterogeneity and
sample imbalance, with boosted performance across benchmarks.

</details>


### [30] [Evaluating Open-Source Vision Language Models for Facial Emotion Recognition against Traditional Deep Learning Models](https://arxiv.org/abs/2508.13524)
*Vamsi Krishna Mulukutla,Sai Supriya Pavarala,Srinivasa Raju Rudraraju,Sridevi Bonthu*

Main category: cs.CV

TL;DR: FER-2013의 저해상도 흑백 감정 인식에서 기존 CNN 계열 모델(EfficientNet-B0, ResNet-50 등)이 오픈소스 VLM(Phi-3.5 Vision, CLIP)보다 성능이 훨씬 우수함을 보였다. GFPGAN 기반 이미지 복원 파이프라인을 도입해 VLM과 데이터 특성 간 불일치를 완화하려 했으나, VLM의 한계가 명확히 드러남.


<details>
  <summary>Details</summary>
Motivation: 저해상도·노이즈가 많은 FER 데이터에서 최근 주목받는 Vision-Language Models의 실제 성능을 전통적 딥러닝 모델과 비교하고, VLM의 학습 가정(고품질 이미지 등)과 FER 데이터의 불일치를 해결할 방법을 모색하기 위함.

Method: FER-2013 데이터셋(35,887개 흑백 이미지, 7개 감정 클래스)을 대상으로 Phi-3.5 Vision, CLIP과 VGG19, ResNet-50, EfficientNet-B0를 비교. GFPGAN 기반 이미지 복원 전처리 파이프라인을 도입하여 VLM 적용성 개선을 시도. 평가 지표로 precision, recall, F1-score, accuracy와 전처리/학습/추론/평가 단계별 계산 비용 분석을 수행.

Result: 전통적 모델이 큰 폭으로 우수: EfficientNet-B0 86.44%, ResNet-50 85.72% 대 CLIP 64.07%, Phi-3.5 Vision 51.66%. 계산 비용 측면 분석도 제공되어 실무 배포 관점의 인사이트를 제공함.

Conclusion: 현재 공개 VLM들은 저품질 FER 작업에 취약하며, VLM을 노이즈 환경에 적응시키기 위한 별도 전략(복원, 파인튜닝, 데이터 적응 등)이 필요하다. 본 연구는 재현 가능한 벤치마크와 배포 관점의 실용적 분석을 제공한다.

Abstract: Facial Emotion Recognition (FER) is crucial for applications such as
human-computer interaction and mental health diagnostics. This study presents
the first empirical comparison of open-source Vision-Language Models (VLMs),
including Phi-3.5 Vision and CLIP, against traditional deep learning models
VGG19, ResNet-50, and EfficientNet-B0 on the challenging FER-2013 dataset,
which contains 35,887 low-resolution grayscale images across seven emotion
classes. To address the mismatch between VLM training assumptions and the noisy
nature of FER data, we introduce a novel pipeline that integrates GFPGAN-based
image restoration with FER evaluation. Results show that traditional models,
particularly EfficientNet-B0 (86.44%) and ResNet-50 (85.72%), significantly
outperform VLMs like CLIP (64.07%) and Phi-3.5 Vision (51.66%), highlighting
the limitations of VLMs in low-quality visual tasks. In addition to performance
evaluation using precision, recall, F1-score, and accuracy, we provide a
detailed computational cost analysis covering preprocessing, training,
inference, and evaluation phases, offering practical insights for deployment.
This work underscores the need for adapting VLMs to noisy environments and
provides a reproducible benchmark for future research in emotion recognition.

</details>


### [31] [EAvatar: Expression-Aware Head Avatar Reconstruction with Generative Geometry Priors](https://arxiv.org/abs/2508.13537)
*Shikun Zhang,Cunjian Chen,Yiqun Wang,Qiuhong Ke,Yong Li*

Main category: cs.CV

TL;DR: 3D Gaussian Splatting 기반의 고해상도 헤드 아바타 복원에서, 소수의 핵심 가우시안을 이용해 이웃 가우시안의 변형을 유도하는 sparse expression control과, pretrained 생성 모델의 3D prior를 결합한 EAvatar를 제안하여 표정 제어력, 국소 변형 및 텍스처 연속성, 형상 정확도를 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 기존 3DGS 기반 방법들이 실시간 렌더링과 복잡한 형상 모델링에는 유리하지만, 세밀한 얼굴 표정과 변형이 큰 지역에서의 국소 텍스처 연속성 보존에 한계가 있어 고충실도 헤드 아바타 재구성 품질이 떨어진다.

Method: EAvatar라는 표현 인식(expression-aware)·변형 인식(deformation-aware) 3DGS 프레임워크를 도입한다. 핵심 아이디어는 소수의 key Gaussian이 주변 Gaussian의 변형을 유도하는 sparse expression control 메커니즘과, 사전 학습된 생성 모델로부터 얻은 고품질 3D prior를 활용해 얼굴 기하 구조를 제시하고 학습 수렴성과 형상 정확도를 개선하는 것이다.

Result: 제안 방법은 기존 3DGS 기반 접근법보다 표정 재현력과 국소 디테일 보존에서 우수한 결과를 보였으며, 더 일관된 시각적 재구성과 향상된 표정 제어성을 달성했다.

Conclusion: EAvatar는 소수의 제어 가우시안과 3D prior 결합을 통해 3DGS의 한계를 완화하고, 고품질·표정 조절 가능한 헤드 아바타 재구성 성능을 향상시킨다。

Abstract: High-fidelity head avatar reconstruction plays a crucial role in AR/VR,
gaming, and multimedia content creation. Recent advances in 3D Gaussian
Splatting (3DGS) have demonstrated effectiveness in modeling complex geometry
with real-time rendering capability and are now widely used in high-fidelity
head avatar reconstruction tasks. However, existing 3DGS-based methods still
face significant challenges in capturing fine-grained facial expressions and
preserving local texture continuity, especially in highly deformable regions.
To mitigate these limitations, we propose a novel 3DGS-based framework termed
EAvatar for head reconstruction that is both expression-aware and
deformation-aware. Our method introduces a sparse expression control mechanism,
where a small number of key Gaussians are used to influence the deformation of
their neighboring Gaussians, enabling accurate modeling of local deformations
and fine-scale texture transitions. Furthermore, we leverage high-quality 3D
priors from pretrained generative models to provide a more reliable facial
geometry, offering structural guidance that improves convergence stability and
shape accuracy during training. Experimental results demonstrate that our
method produces more accurate and visually coherent head reconstructions with
improved expression controllability and detail fidelity.

</details>


### [32] [FLAIR: Frequency- and Locality-Aware Implicit Neural Representations](https://arxiv.org/abs/2508.13544)
*Sukhun Ko,Dahyeon Kye,Kyle Min,Chanho Eom,Jihyong Oh*

Main category: cs.CV

TL;DR: FLAIR introduces frequency- and locality-aware implicit neural representations using a novel RC-GAUSS activation and Wavelet-Energy-Guided Encoding (WEGE) to overcome spectral bias and better capture high-frequency, localized signal components.


<details>
  <summary>Details</summary>
Motivation: Existing INRs lack frequency selectivity, spatial localization, and sparsity, causing spectral bias (learning low frequencies early and failing to capture high-frequency details) and redundant representations.

Method: Proposes FLAIR with two components: (1) RC-GAUSS, an activation enabling explicit frequency selection and spatial localization constrained by the time-frequency uncertainty principle (TFUP); (2) WEGE, which uses discrete wavelet transform (DWT) to compute energy scores that guide frequency information into the network.

Result: FLAIR consistently outperforms prior INR methods on 2D image representation and restoration tasks and on 3D reconstruction, demonstrating improved high-frequency detail recovery and more efficient representations.

Conclusion: By enforcing frequency-aware activations and wavelet-guided encoding, FLAIR mitigates spectral bias, yields sparser and more localized INRs, and provides better performance across image and 3D reconstruction tasks.

Abstract: Implicit Neural Representations (INRs) leverage neural networks to map
coordinates to corresponding signals, enabling continuous and compact
representations. This paradigm has driven significant advances in various
vision tasks. However, existing INRs lack frequency selectivity, spatial
localization, and sparse representations, leading to an over-reliance on
redundant signal components. Consequently, they exhibit spectral bias, tending
to learn low-frequency components early while struggling to capture fine
high-frequency details. To address these issues, we propose FLAIR (Frequency-
and Locality-Aware Implicit Neural Representations), which incorporates two key
innovations. The first is RC-GAUSS, a novel activation designed for explicit
frequency selection and spatial localization under the constraints of the
time-frequency uncertainty principle (TFUP). The second is
Wavelet-Energy-Guided Encoding (WEGE), which leverages the discrete wavelet
transform (DWT) to compute energy scores and explicitly guide frequency
information to the network. Our method consistently outperforms existing INRs
in 2D image representation and restoration, as well as 3D reconstruction.

</details>


### [33] [GazeProphet: Software-Only Gaze Prediction for VR Foveated Rendering](https://arxiv.org/abs/2508.13546)
*Farhaan Ebadulla,Chiraag Mudlapur,Gaurav BV*

Main category: cs.CV

TL;DR: GazeProphet는 전용 하드웨어 없이 VR에서 시선(foveated) 렌더링을 가능하게 하는 소프트웨어 기반 시선 예측기이다. Spherical Vision Transformer로 360° 장면을 인코딩하고 LSTM으로 시선 시퀀스의 시간적 패턴을 모델링한 뒤 멀티모달 융합으로 미래 시선 위치와 신뢰도를 예측해, 중간 각오차 3.83°를 달성하며 기존 살리언시 기반 방법보다 24% 향상되었다.


<details>
  <summary>Details</summary>
Motivation: VR의 포비에이티드 렌더링은 사용자가 주시하는 영역에 계산 자원을 집중시켜 성능을 크게 개선하지만, 현재는 고가의 하드웨어 기반 시선 추적기가 필수라 비용·보정·호환성 문제로 보급이 제한된다. 이에 추가 하드웨어 없이 소프트웨어만으로 시선을 예측해 실용적 대체를 제시하려는 동기가 있다.

Method: 입력으로 360° VR 장면을 받는 Spherical Vision Transformer로 공간적 시각 특징을 추출하고, LSTM 기반의 시간적 인코더로 사용자의 시선 시퀀스 패턴을 모델링한다. 두 모달리티를 멀티모달 융합 네트워크에서 결합해 미래 시선 좌표와 신뢰도(예측 불확실성)를 출력한다. (데이터셋 기반 학습, 신뢰도 캘리브레이션 포함)

Result: 종합 VR 데이터셋 실험에서 GazeProphet는 중간 각오차(median angular error) 3.83°를 기록했으며, 전통적 살리언시 기반 베이스라인 대비 평균 24% 개선을 보였다. 성능은 공간 영역과 장면 유형 전반에 걸쳐 안정적이었고, 예측 신뢰도도 잘 보정된 것으로 보고되었다. 모든 평가지표에서 통계적으로 유의한 향상이 확인되었다.

Conclusion: 추가 하드웨어 없이 소프트웨어만으로도 VR용 포비에이티드 렌더링에 충분한 시선 예측 성능을 달성할 수 있음을 보여준다. 이는 다양한 VR 플랫폼과 앱에서 성능 향상을 더 널리 적용할 수 있게 해 실용적 가치를 제공한다.

Abstract: Foveated rendering significantly reduces computational demands in virtual
reality applications by concentrating rendering quality where users focus their
gaze. Current approaches require expensive hardware-based eye tracking systems,
limiting widespread adoption due to cost, calibration complexity, and hardware
compatibility constraints. This paper presents GazeProphet, a software-only
approach for predicting gaze locations in VR environments without requiring
dedicated eye tracking hardware. The approach combines a Spherical Vision
Transformer for processing 360-degree VR scenes with an LSTM-based temporal
encoder that captures gaze sequence patterns. A multi-modal fusion network
integrates spatial scene features with temporal gaze dynamics to predict future
gaze locations with associated confidence estimates. Experimental evaluation on
a comprehensive VR dataset demonstrates that GazeProphet achieves a median
angular error of 3.83 degrees, outperforming traditional saliency-based
baselines by 24% while providing reliable confidence calibration. The approach
maintains consistent performance across different spatial regions and scene
types, enabling practical deployment in VR systems without additional hardware
requirements. Statistical analysis confirms the significance of improvements
across all evaluation metrics. These results show that software-only gaze
prediction can work for VR foveated rendering, making this performance boost
more accessible to different VR platforms and apps.

</details>


### [34] [A Lightweight Dual-Mode Optimization for Generative Face Video Coding](https://arxiv.org/abs/2508.13547)
*Zihan Zhang,Shanzhi Yin,Bolin Chen,Ru-Ling Liao,Shiqi Wang,Yan Ye*

Main category: cs.CV

TL;DR: 경량화된 Generative Face Video Coding(GFVC) 프레임워크를 제안하여 모델 파라미터와 연산량을 큰 폭으로 줄이면서 재구성 품질을 유지하고 VVC 대비 우수한 지각적 품질을 달성함.


<details>
  <summary>Details</summary>
Motivation: GFVC는 생성 모델의 강력한 추론 능력으로 우수한 비트율-왜곡 성능을 보이나, 모델 크기와 계산 비용이 커 실무 배포(예: 모바일 엣지)에서 제약이 있음.

Method: 이중 모드 최적화(architectural redesign + operational refinement)를 도입: (1) 아키텍처 변경으로 3x3 컨볼루션을 더 가볍고 효율적인 레이어로 대체하여 복잡도를 낮추되 표현력은 유지함; (2) 2단계 적응형 채널 프루닝을 도입: 학습 중 소프트 프루닝(학습 가능한 임계값으로 불필요 채널 식별)과 학습 후 하드 프루닝(도출된 마스크로 채널 영구 제거)을 수행하여 학습 안정성과 추론 효율을 동시에 확보함.

Result: 제안 방법은 기준 모델 대비 파라미터 90.4% 감소, 연산량 88.9% 절약을 달성했으며, 지각 수준 품질 지표에서 VVC(최신 비디오 코딩 표준)보다 우수한 성능을 보임.

Conclusion: 제안된 경량 이중 모드 최적화는 리소스 제약 환경(예: 모바일 엣지)에서 GFVC의 실용적 배포를 가능하게 할 것으로 기대됨.

Abstract: Generative Face Video Coding (GFVC) achieves superior rate-distortion
performance by leveraging the strong inference capabilities of deep generative
models. However, its practical deployment is hindered by large model parameters
and high computational costs. To address this, we propose a lightweight GFVC
framework that introduces dual-mode optimization -- combining architectural
redesign and operational refinement -- to reduce complexity whilst preserving
reconstruction quality. Architecturally, we replace traditional 3 x 3
convolutions with slimmer and more efficient layers, reducing complexity
without compromising feature expressiveness. Operationally, we develop a
two-stage adaptive channel pruning strategy: (1) soft pruning during training
identifies redundant channels via learnable thresholds, and (2) hard pruning
permanently eliminates these channels post-training using a derived mask. This
dual-phase approach ensures both training stability and inference efficiency.
Experimental results demonstrate that the proposed lightweight dual-mode
optimization for GFVC can achieve 90.4% parameter reduction and 88.9%
computation saving compared to the baseline, whilst achieving superior
performance compared to state-of-the-art video coding standard Versatile Video
Coding (VVC) in terms of perceptual-level quality metrics. As such, the
proposed method is expected to enable efficient GFVC deployment in
resource-constrained environments such as mobile edge devices.

</details>


### [35] [Color Spike Data Generation via Bio-inspired Neuron-like Encoding with an Artificial Photoreceptor Layer](https://arxiv.org/abs/2508.13558)
*Hsieh Ching-Teng,Wang Yuan-Kai*

Main category: cs.CV

TL;DR: 생물학적 뉴런 동작 원리를 모방한 Neuron-like Encoding과 인공 포토리셉터 층을 도입해 색과 명암 정보를 담는 스파이크 데이터를 생성함으로써 Integrate-and-Fire 모델 기반 SNN의 정보량과 성능을 향상시켰음을 보임.


<details>
  <summary>Details</summary>
Motivation: SNN은 스파이크 기반 데이터의 정보 용량 제한 때문에 CNN에 비해 성능이 낮고, 정적 이미지 등 비스파이크 입력으로 학습시키는 접근은 신경모픽(스파이크 중심) 철학에서 벗어남.

Method: 생물학적 뉴런의 내재적 작동 원리와 기능을 기반으로 스파이크 데이터를 생성하는 Neuron-like Encoding을 제안하고, 인공 포토리셉터 층을 추가해 색(color)과 명암(luminance)을 스파이크 신호에 포함시킴. Integrate-and-Fire 뉴런 모델로 실험을 수행.

Result: 제안한 방식이 스파이크 신호의 정보량을 유의미하게 늘리고 SNN 성능을 개선함을 실험적으로 확인함.

Conclusion: 생물학적 영감을 받은 인코딩은 신경모픽 원칙을 지키면서 SNN의 한계를 극복할 잠재력이 있으며 향후 SNN 적용 범위를 확장하는 데 기여할 수 있음.

Abstract: In recent years, neuromorphic computing and spiking neural networks (SNNs)
have ad-vanced rapidly through integration with deep learning. However, the
performance of SNNs still lags behind that of convolutional neural networks
(CNNs), primarily due to the limited information capacity of spike-based data.
Although some studies have attempted to improve SNN performance by training
them with non-spiking inputs such as static images, this approach deviates from
the original intent of neuromorphic computing, which emphasizes spike-based
information processing. To address this issue, we propose a Neuron-like
Encoding method that generates spike data based on the intrinsic operational
principles and functions of biological neurons. This method is further enhanced
by the incorporation of an artificial pho-toreceptor layer, enabling spike data
to carry both color and luminance information, thereby forming a complete
visual spike signal. Experimental results using the Integrate-and-Fire neuron
model demonstrate that this biologically inspired approach effectively
increases the information content of spike signals and improves SNN
performance, all while adhering to neuromorphic principles. We believe this
concept holds strong potential for future development and may contribute to
overcoming current limitations in neuro-morphic computing, facilitating broader
applications of SNNs.

</details>


### [36] [DictAS: A Framework for Class-Generalizable Few-Shot Anomaly Segmentation via Dictionary Lookup](https://arxiv.org/abs/2508.13560)
*Zhen Qu,Xian Tao,Xinyi Gong,ShiChen Qu,Xiaopei Zhang,Xingang Wang,Fei Shen,Zhengtao Zhang,Mukesh Prasad,Guiguang Ding*

Main category: cs.CV

TL;DR: DictAS는 몇 장의 정상 이미지(visual prompts)만으로 보지 못한 클래스의 이상을 재학습 없이 검출하는 프레임워크다. 정상 특징으로 구성한 ‘사전(dictionary)’에서 쿼리 영역을 희소 조회하여 복원 불가능한 경우 이상으로 판정하며, 대조 및 텍스트 정렬 제약으로 이상 특징을 사전에서 회수하기 어렵게 학습시킨다. 여러 산업·의료 데이터셋에서 기존 FSAS 방법들을 능가한다.


<details>
  <summary>Details</summary>
Motivation: 기존 비전–언어 모델 기반의 FSAS는 보았던(학습에 사용한) 이상 샘플에 대한 사전 지식에 크게 의존하여, 보지 못한 클래스로의 일반화가 제한된다. 따라서 재학습 없이 소수의 정상 이미지만으로도 보지 못한 범주의 이상을 검출할 수 있는 방법이 필요하다.

Method: DictAS는 (1) 정상 참조 이미지들로부터 특징을 뽑아 사전(Dictionary)을 구성하고, (2) 쿼리 지역 특징을 사전에서 희소 조회(sparse lookup)하여 복원/검색되는지를 검사하며, 조회되지 않으면 이상으로 분류한다. (3) Query Discrimination Regularization(Contrastive Query Constraint와 Text Alignment Constraint 포함)을 도입해 이상 특징이 사전에서 회수되기 어렵도록 학습하여 판별력을 향상시킨다.

Result: 7개의 산업·의료 공개 데이터셋에서 광범위한 실험을 수행해 DictAS가 기존 최첨단 FSAS 방법들보다 일관되게 우수한 성능을 보였다고 보고한다.

Conclusion: 사전 조회 개념을 자기지도 학습으로 전이함으로써, DictAS는 타깃 데이터에 대한 재학습 없이도 보지 못한 클래스의 이상을 효과적으로 검출하며 FSAS의 범용성을 증가시킨다.

Abstract: Recent vision-language models (e.g., CLIP) have demonstrated remarkable
class-generalizable ability to unseen classes in few-shot anomaly segmentation
(FSAS), leveraging supervised prompt learning or fine-tuning on seen classes.
However, their cross-category generalization largely depends on prior knowledge
of real seen anomaly samples. In this paper, we propose a novel framework,
namely DictAS, which enables a unified model to detect visual anomalies in
unseen object categories without any retraining on the target data, only
employing a few normal reference images as visual prompts. The insight behind
DictAS is to transfer dictionary lookup capabilities to the FSAS task for
unseen classes via self-supervised learning, instead of merely memorizing the
normal and abnormal feature patterns from the training set. Specifically,
DictAS mainly consists of three components: (1) **Dictionary Construction** -
to simulate the index and content of a real dictionary using features from
normal reference images. (2) **Dictionary Lookup** - to retrieve queried region
features from the dictionary via a sparse lookup strategy. When a query feature
cannot be retrieved, it is classified as an anomaly. (3) **Query Discrimination
Regularization**- to enhance anomaly discrimination by making abnormal features
harder to retrieve from the dictionary. To achieve this, Contrastive Query
Constraint and Text Alignment Constraint are further proposed. Extensive
experiments on seven public industrial and medical datasets demonstrate that
DictAS consistently outperforms state-of-the-art FSAS methods.

</details>


### [37] [Learnable SMPLify: A Neural Solution for Optimization-Free Human Pose Inverse Kinematics](https://arxiv.org/abs/2508.13562)
*Yuchen Yang,Linfeng Dong,Wei Wang,Zhihang Zhong,Xiao Sun*

Main category: cs.CV

TL;DR: Learnable SMPLify는 기존 SMPLify의 반복 최적화를 신경망 기반의 단일 패스 회귀 모델로 대체한 방법이다. 시계열 샘플링으로 초기화-목표 쌍을 생성하고, 인간 중심 정규화와 잔차 학습으로 일반화를 개선한다. 결과적으로 거의 200배 빠른 속도를 달성하며 3DPW, RICH 데이터셋에서 잘 일반화되고 다른 추정기(예: LucidAction)에도 플러그인으로 사용 가능하다.


<details>
  <summary>Details</summary>
Motivation: SMPLify는 3D 인간 포즈 및 형태 추정에서 강력한 기준이지만 반복 최적화로 인한 높은 계산 비용 때문에 실무 적용이 어렵다. 반복 최적화를 신경망으로 대체하면 속도를 크게 높이면서 정확도를 유지할 수 있다는 최근 성과에 영감을 받음.

Method: 신경망 단일 패스 회귀 모델로 SMPLify의 반복 피팅 과정을 대체. 학습을 위해 시계열 프레임에서 초기화-목표 쌍을 구성하는 temporal sampling 전략을 제안. 일반화를 위해 인간 중심(normalization) 정규화 기법과 잔차 학습(residual learning)을 도입하여 해 공간을 좁힘. 순차 추론과 이미지 기반 추정기의 포스트프로세서(플러그인)로 동작하도록 설계.

Result: SMPLify에 비해 거의 200배 빠른 런타임 속도를 달성. 3DPW와 RICH에서 좋은 일반화 성능을 보였고, LucidAction과 같은 모델에 플러그인으로 적용해도 효과적이었다.

Conclusion: Learnable SMPLify는 실무적으로 유용한 간단한 기준(baseline)으로 자리잡는다 — 빠른 속도, 좋은 일반화, 모델-애그노스틱 플러그인 가능성을 갖는다.

Abstract: In 3D human pose and shape estimation, SMPLify remains a robust baseline that
solves inverse kinematics (IK) through iterative optimization. However, its
high computational cost limits its practicality. Recent advances across domains
have shown that replacing iterative optimization with data-driven neural
networks can achieve significant runtime improvements without sacrificing
accuracy. Motivated by this trend, we propose Learnable SMPLify, a neural
framework that replaces the iterative fitting process in SMPLify with a
single-pass regression model. The design of our framework targets two core
challenges in neural IK: data construction and generalization. To enable
effective training, we propose a temporal sampling strategy that constructs
initialization-target pairs from sequential frames. To improve generalization
across diverse motions and unseen poses, we propose a human-centric
normalization scheme and residual learning to narrow the solution space.
Learnable SMPLify supports both sequential inference and plug-in
post-processing to refine existing image-based estimators. Extensive
experiments demonstrate that our method establishes itself as a practical and
simple baseline: it achieves nearly 200x faster runtime compared to SMPLify,
generalizes well to unseen 3DPW and RICH, and operates in a model-agnostic
manner when used as a plug-in tool on LucidAction. The code is available at
https://github.com/Charrrrrlie/Learnable-SMPLify.

</details>


### [38] [The 9th AI City Challenge](https://arxiv.org/abs/2508.13564)
*Zheng Tang,Shuo Wang,David C. Anastasiu,Ming-Ching Chang,Anuj Sharma,Quan Kong,Norimasa Kobori,Munkhjargal Gochoo,Ganzorig Batnasan,Munkh-Erdene Otgonbold,Fady Alnajjar,Jun-Wei Hsieh,Tomasz Kornuta,Xiaolong Li,Yilin Zhao,Han Zhang,Subhashree Radhakrishnan,Arihant Jain,Ratnesh Kumar,Vidya N. Murali,Yuxing Wang,Sameer Satish Pusegaonkar,Yizhou Wang,Sujit Biswas,Xunlei Wu,Zhedong Zheng,Pranamesh Chakraborty,Rama Chellappa*

Main category: cs.CV

TL;DR: 9th AI City Challenge (2025) ran four tracks addressing multi-class 3D multi-camera tracking, traffic video question answering with 3D gaze, fine-grained spatial reasoning in RGB-D warehouse scenes, and efficient fisheye road-object detection. Participation rose 17% to 245 teams from 15 countries; datasets were publicly released and downloaded >30,000 times. Evaluation used submission limits and a partially held-out test set to ensure fairness and reproducibility; top teams set new benchmarks.


<details>
  <summary>Details</summary>
Motivation: Advance practical computer-vision and AI for transportation, industrial automation, and public safety; create challenging multi-modal benchmarks and encourage reproducible, fair evaluation.

Method: Four specialized tracks with rich annotations (3D bounding boxes, 3D gaze, RGB-D), synthetic data generation in NVIDIA Omniverse for Tracks 1 and 3, multi-camera calibration, fisheye-specific datasets for edge deployment, and an evaluation framework with submission caps and partially held-out test data.

Result: 17% increase in participation (245 teams, 15 countries), >30k dataset downloads, multiple teams achieved top-tier results setting new benchmarks across tasks, and final rankings released to mitigate overfitting and support reproducibility.

Conclusion: The challenge pushed state-of-the-art in diverse, deployment-oriented CV tasks, produced valuable public datasets and benchmarks, and emphasized fair, reproducible evaluation practices for real-world applications.

Abstract: The ninth AI City Challenge continues to advance real-world applications of
computer vision and AI in transportation, industrial automation, and public
safety. The 2025 edition featured four tracks and saw a 17% increase in
participation, with 245 teams from 15 countries registered on the evaluation
server. Public release of challenge datasets led to over 30,000 downloads to
date. Track 1 focused on multi-class 3D multi-camera tracking, involving
people, humanoids, autonomous mobile robots, and forklifts, using detailed
calibration and 3D bounding box annotations. Track 2 tackled video question
answering in traffic safety, with multi-camera incident understanding enriched
by 3D gaze labels. Track 3 addressed fine-grained spatial reasoning in dynamic
warehouse environments, requiring AI systems to interpret RGB-D inputs and
answer spatial questions that combine perception, geometry, and language. Both
Track 1 and Track 3 datasets were generated in NVIDIA Omniverse. Track 4
emphasized efficient road object detection from fisheye cameras, supporting
lightweight, real-time deployment on edge devices. The evaluation framework
enforced submission limits and used a partially held-out test set to ensure
fair benchmarking. Final rankings were revealed after the competition
concluded, fostering reproducibility and mitigating overfitting. Several teams
achieved top-tier results, setting new benchmarks in multiple tasks.

</details>


### [39] [Generative Model-Based Feature Attention Module for Video Action Analysis](https://arxiv.org/abs/2508.13565)
*Guiqin Wang,Peng Zhao,Cong Zhao,Jing Huang,Siyan Guo,Shusen Yang*

Main category: cs.CV

TL;DR: 제안된 논문은 IoT 및 자율주행 등 고정밀 응용을 겨냥해, 특징 추출 시 'feature semantics' 관계를 학습하는 생성적(generative) 어텐션 모델(GAF)을 제안한다. 전경/배경 차이를 활용하여 프레임-레벨 및 세그먼트-레벨의 시간적 의존성을 동시에 학습하며, 행동 인식(action recognition)과 행동 검출(action detection) 벤치마크에서 유효성을 검증했다고 주장한다.


<details>
  <summary>Details</summary>
Motivation: 기존 방법들이 액션 제안(temporal proposals) 최적화에만 치중하고, 특징 추출 단계에서의 의미론적(semantic) 관계를 충분히 반영하지 못해 정밀도가 필요한 IoT 응용(예: 자율주행)에서 성능 한계가 발생한다는 문제 의식.

Method: 생성적 어텐션 기반 모델을 도입하여 특징의 의미론적 관계를 학습함. 전경(foreground)과 배경(background)의 차이를 이용해 프레임 단위와 세그먼트 단위의 시간적(feature semantics) 의존성을 동시에 모델링함으로써 특징 추출 단계에서 의미 정보를 효과적으로 반영한다. (구체적 아키텍처/학습 손실/어텐션 구조는 초록에 명시되지 않음.)

Result: 액션 검출(task: action detection)에서 널리 알려진 데이터셋들을 통해 우수성을 입증했다고 보고하며, 액션 인식(task: action recognition)으로 검증 범위를 확장했다고 주장. (수치적 성능 지표, 베이스라인 비교, 데이터셋 이름은 초록에 없음.)

Conclusion: feature semantics를 추출 단계에서 적극적으로 학습하는 것이 액션 인식·검출 성능 향상에 도움이 되며, 제안한 생성적 어텐션 모델이 이런 목적에 효과적이라고 결론. 코드 공개(GAF)로 재현성 제공.

Abstract: Video action analysis is a foundational technology within the realm of
intelligent video comprehension, particularly concerning its application in
Internet of Things(IoT). However, existing methodologies overlook feature
semantics in feature extraction and focus on optimizing action proposals, thus
these solutions are unsuitable for widespread adoption in high-performance IoT
applications due to the limitations in precision, such as autonomous driving,
which necessitate robust and scalable intelligent video analytics analysis. To
address this issue, we propose a novel generative attention-based model to
learn the relation of feature semantics. Specifically, by leveraging the
differences of actions' foreground and background, our model simultaneously
learns the frame- and segment-dependencies of temporal action feature
semantics, which takes advantage of feature semantics in the feature extraction
effectively. To evaluate the effectiveness of our model, we conduct extensive
experiments on two benchmark video task, action recognition and action
detection. In the context of action detection tasks, we substantiate the
superiority of our approach through comprehensive validation on widely
recognized datasets. Moreover, we extend the validation of the effectiveness of
our proposed method to a broader task, video action recognition. Our code is
available at https://github.com/Generative-Feature-Model/GAF.

</details>


### [40] [Temporal-Conditional Referring Video Object Segmentation with Noise-Free Text-to-Video Diffusion Model](https://arxiv.org/abs/2508.13584)
*Ruixin Zhang,Jiaqing Fan,Yifan Liao,Qian Qiao,Fanzhang Li*

Main category: cs.CV

TL;DR: 본 논문은 참조 텍스트에 따라 비디오 객체를 분할하는 RVOS 문제에서 '세그멘테이션 헤드' 설계의 중요성이 간과되어 왔음을 지적하고, 경계 분할 성능을 향상시키는 Temporal-Conditional RVOS 모델을 제안한다. 텍스트-투-비디오 확산 모델로 특징을 추출하고, 노이즈 예측 모듈을 제거해 무작위성을 줄이며, VAE의 한계를 보완하는 Temporal Context Mask Refinement(TCMR)를 도입해 네 가지 공개 벤치마크에서 SOTA를 달성했다.


<details>
  <summary>Details</summary>
Motivation: 기존 RVOS 연구들이 특징 추출과 시공간적 모델링에 치중하는 반면, 세그멘테이션 헤드 설계는 상대적으로 소홀히 다뤄져왔고, 이로 인해 경계 정확도 등에서 개선 여지가 크다고 판단됨.

Method: (1) 기존 세그멘테이션 기법들을 통합해 경계 분할 능력을 강화한 Temporal-Conditional RVOS 아키텍처 설계, (2) 텍스트-투-비디오 확산 모델을 피처 추출기로 활용, (3) 전통적 확산 모델의 노이즈 예측 모듈을 제거해 무작위성 제거 및 모델 단순화, (4) VAE의 제한된 표현력을 보완하기 위한 Temporal Context Mask Refinement(TCMR) 모듈 추가로 마스크 정제 수행.

Result: 제안 방법은 네 개의 공개 RVOS 벤치마크에서 일관되게 최첨단 성능을 기록함(논문 요약에 특이한 수치 제시는 없음). 특히 경계 품질과 전체 분할 정확도가 향상되었다고 보고.

Conclusion: 세그멘테이션 헤드 설계 개선과 확산 기반 피처 활용, TCMR 정제 모듈 조합을 통해 RVOS의 경계 분할 성능을 유의미하게 끌어올렸으며, 노이즈 예측 모듈 제거로 모델을 단순화하면서 성능을 유지·향상시켰다.

Abstract: Referring Video Object Segmentation (RVOS) aims to segment specific objects
in a video according to textual descriptions. We observe that recent RVOS
approaches often place excessive emphasis on feature extraction and temporal
modeling, while relatively neglecting the design of the segmentation head. In
fact, there remains considerable room for improvement in segmentation head
design. To address this, we propose a Temporal-Conditional Referring Video
Object Segmentation model, which innovatively integrates existing segmentation
methods to effectively enhance boundary segmentation capability. Furthermore,
our model leverages a text-to-video diffusion model for feature extraction. On
top of this, we remove the traditional noise prediction module to avoid the
randomness of noise from degrading segmentation accuracy, thereby simplifying
the model while improving performance. Finally, to overcome the limited feature
extraction capability of the VAE, we design a Temporal Context Mask Refinement
(TCMR) module, which significantly improves segmentation quality without
introducing complex designs. We evaluate our method on four public RVOS
benchmarks, where it consistently achieves state-of-the-art performance.

</details>


### [41] [Bridging Clear and Adverse Driving Conditions](https://arxiv.org/abs/2508.13592)
*Yoel Shapiro,Yahia Showgan,Koustav Mullick*

Main category: cs.CV

TL;DR: 본 논문은 맑은 날 촬영 이미지들을 안개, 비, 눈, 야간 이미지로 변환하는 도메인 적응(DA) 파이프라인을 제안하여, 합성된 악조건 데이터로 자율주행 인식 성능을 향상시킨다. 하이브리드(시뮬레이션+GAN+Diffusion) 생성 기법과 이미지 블렌딩 기법을 통해 시뮬레이션-실제 격차를 줄이고, ACDC 데이터셋에서 의미분할 성능을 개선했다.


<details>
  <summary>Details</summary>
Motivation: 자율주행 시스템은 저조도나 강수 등 악천후에서 성능이 크게 저하되지만, 그런 조건의 레이블링된 데이터가 부족해 해결이 어렵다. 악조건 데이터 수집·주석 비용이 높기 때문에 합성 기반 데이터 생성으로 문제를 완화하려는 동기가 있다.

Method: 시뮬레이션 전용, GAN 기반, 하이브리드(디퓨전-GAN) 등 여러 합성 파이프라인을 체계적으로 개발·평가함. 기존 DA GAN을 보완해 보조 입력을 지원하고, 시뮬레이션(정밀한 페어 감독)과 실제 이미지(시뮬2리얼 갭 완화)를 함께 활용하는 새로운 학습 레시피를 제안. Stable-Diffusion img2img 출력의 환각·아티팩트를 완화하기 위해 생성물과 원본 이미지를 적응적으로 블렌딩하는 기법도 도입.

Result: 합성 데이터로 다운스트림 모델을 파인튜닝한 결과 ACDC 데이터셋 평가에서 의미분할 전체 성능이 1.85% 향상되었고, 특히 야간 조건에서 4.62% 향상이 관찰되었다.

Conclusion: 하이브리드 합성 방법(시뮬레이션 + GAN/디퓨전 + 블렌딩)은 악조건에서의 자율주행 인식 강인성을 개선하는 데 효과적이며, 시뮬레이션으로 정밀한 감독을 제공하고 실제 이미지를 통해 sim2real 격차를 줄이는 설계가 중요함을 보였다.

Abstract: Autonomous Driving (AD) systems exhibit markedly degraded performance under
adverse environmental conditions, such as low illumination and precipitation.
The underrepresentation of adverse conditions in AD datasets makes it
challenging to address this deficiency. To circumvent the prohibitive cost of
acquiring and annotating adverse weather data, we propose a novel Domain
Adaptation (DA) pipeline that transforms clear-weather images into fog, rain,
snow, and nighttime images. Here, we systematically develop and evaluate
several novel data-generation pipelines, including simulation-only, GAN-based,
and hybrid diffusion-GAN approaches, to synthesize photorealistic adverse
images from labelled clear images. We leverage an existing DA GAN, extend it to
support auxiliary inputs, and develop a novel training recipe that leverages
both simulated and real images. The simulated images facilitate exact
supervision by providing perfectly matched image pairs, while the real images
help bridge the simulation-to-real (sim2real) gap. We further introduce a
method to mitigate hallucinations and artifacts in Stable-Diffusion
Image-to-Image (img2img) outputs by blending them adaptively with their
progenitor images. We finetune downstream models on our synthetic data and
evaluate them on the Adverse Conditions Dataset with Correspondences (ACDC). We
achieve 1.85 percent overall improvement in semantic segmentation, and 4.62
percent on nighttime, demonstrating the efficacy of our hybrid method for
robust AD perception under challenging conditions.

</details>


### [42] [Structured Prompting and Multi-Agent Knowledge Distillation for Traffic Video Interpretation and Risk Inference](https://arxiv.org/abs/2508.13439)
*Yunxiang Yang,Ningning Xu,Jidong J. Yang*

Main category: cs.CV

TL;DR: 이 논문은 구조화된 체인-오브-생각(CoT) 기반의 프롬프트와 지식 증류를 결합해, 대형 VLM(GPT-4o, o3-mini)으로부터 고품질의 교통 장면 주석과 위험 평가를 자동 생성한다. 이를 학생 VLM(3B 규모, VISTA)으로 지도학습하여, 경량화된 모델이 저해상도 교통 비디오에서 의미론적이고 위험 인식 캡션을 생성할 수 있도록 한다. 실험에서 VISTA는 여러 캡션 지표(BLEU-4, METEOR, ROUGE-L, CIDEr)에서 교사 모델 대비 우수한 성능을 보이며 엣지 디바이스 실시간 모니터링에 적합하다.


<details>
  <summary>Details</summary>
Motivation: 기존 방법은 확장성과 일반화 문제로 실제 교통 환경의 복잡한 상황을 처리하기 어렵다. 대형 VLM의 추론 능력을 경량 모델로 이전해 엣지 배포 가능하면서도 위험 인식이 가능한 교통 장면 이해 모델을 만들고자 함.

Method: GPT-4o와 o3-mini의 다중 에이전트를 구조화된 CoT 전략으로 오케스트레이션하여 다각적 설명과 위험 평가를 생성한다. 생성된 출력은 지식이 풍부한 의사-주석(pseudo-annotations)으로 사용되어 3B 규모의 학생 VLM(VISTA)을 지도-파인튜닝한다. 핵심은 구조화된 프롬프트, 체인-오브-생각 흐름, 그리고 지식 증류로 경량 모델에 복잡한 추론 능력을 전달하는 것이다.

Result: VISTA는 BLEU-4, METEOR, ROUGE-L, CIDEr 등 표준 캡션 지표에서 교사 모델을 상회하거나 근접한 성능을 달성했다. 또한 저해상도 교통 비디오에 대해 의미론적으로 충실하고 위험 인식이 가능한 캡션을 생성하며, 파라미터가 훨씬 적음에도 강한 추론능력을 보였다.

Conclusion: 구조화된 멀티-에이전트 감독과 지식 증류는 경량 VLM이 복잡한 장면 이해와 위험 추론 능력을 획득하도록 하는 데 효과적이다. VISTA의 소형화된 아키텍처는 엣지 디바이스에서의 실시간 배포를 가능하게 하여 ITS와 자율주행 시스템에 실용적 이점을 제공한다.

Abstract: Comprehensive highway scene understanding and robust traffic risk inference
are vital for advancing Intelligent Transportation Systems (ITS) and autonomous
driving. Traditional approaches often struggle with scalability and
generalization, particularly under the complex and dynamic conditions of
real-world environments. To address these challenges, we introduce a novel
structured prompting and knowledge distillation framework that enables
automatic generation of high-quality traffic scene annotations and contextual
risk assessments. Our framework orchestrates two large Vision-Language Models
(VLMs): GPT-4o and o3-mini, using a structured Chain-of-Thought (CoT) strategy
to produce rich, multi-perspective outputs. These outputs serve as
knowledge-enriched pseudo-annotations for supervised fine-tuning of a much
smaller student VLM. The resulting compact 3B-scale model, named VISTA (Vision
for Intelligent Scene and Traffic Analysis), is capable of understanding
low-resolution traffic videos and generating semantically faithful, risk-aware
captions. Despite its significantly reduced parameter count, VISTA achieves
strong performance across established captioning metrics (BLEU-4, METEOR,
ROUGE-L, and CIDEr) when benchmarked against its teacher models. This
demonstrates that effective knowledge distillation and structured multi-agent
supervision can empower lightweight VLMs to capture complex reasoning
capabilities. The compact architecture of VISTA facilitates efficient
deployment on edge devices, enabling real-time risk monitoring without
requiring extensive infrastructure upgrades.

</details>


### [43] [Towards Efficient Vision State Space Models via Token Merging](https://arxiv.org/abs/2508.13599)
*Jinyoung Park,Minseok Son,Changick Kim*

Main category: cs.CV

TL;DR: MaMe는 SSM 기반 비전 모델을 위한 토큰 병합(token-merging) 기법으로, 상태 전이 파라미터 Δ를 토큰 정보량 측정 지표로 활용하고 순차 정보 보존을 위해 전략적 토큰 배치를 도입한다. 이를 통해 높은 토큰 감소 상황에서도 성능 저하를 억제하며 이미지 분류뿐 아니라 비디오·오디오 등 다른 도메인으로도 잘 일반화된다.


<details>
  <summary>Details</summary>
Motivation: SSM은 시퀀스 모델링 성능이 우수하지만 연산 비용이 커 실용적 배포에 제약이 있다. 기존 토큰 축소 기법을 단순 적용하면 SSM의 고유한 순차성(시퀀셜 성질)이 손상되어 성능 저하가 발생할 수 있으므로, 토큰 중요도 측정과 순차성 보존을 동시에 다루는 방법이 필요하다.

Method: 토큰의 정보량을 측정하는 지표로 상태 전이 파라미터 Δ를 활용하여 중요도를 정량화하고, 순차 정보 흐름을 유지하도록 토큰을 전략적으로 배열·병합하는 MaMe 토큰 병합 전략을 제안한다. 이 방법은 파인튜닝된 모델뿐 아니라 오프더쉘프 모델에도 적용 가능하도록 설계되었다.

Result: 광범위한 실험에서 MaMe는 기존 방법들보다 더 우수한 효율–성능 트레이드오프를 보였다. 특히 공격적인 토큰 감소 하에서도 다른 방법들이 큰 성능 저하를 보일 때 MaMe는 강건함을 유지했다. 또한 이미지 분류를 넘어 비디오와 오디오 도메인에서도 좋은 일반화 성능을 보였다.

Conclusion: MaMe는 SSM 계열 모델의 연산 효율을 개선하면서 순차성 유지를 통해 성능 손실을 최소화하는 실용적이고 범용적인 토큰 병합 기법으로, 다양한 SSM 응용 분야에서 효율성 향상에 효과적이다.

Abstract: State Space Models (SSMs) have emerged as powerful architectures in computer
vision, yet improving their computational efficiency remains crucial for
practical and scalable deployment.While token reduction serves as an effective
approach for model efficiency, applying it to SSMs requires careful
consideration of their unique sequential modeling capabilities.In this work, we
propose MaMe, a token-merging strategy tailored for SSM-based vision
models.MaMe addresses two key challenges: quantifying token importance and
preserving sequential properties. Our approach leverages the state transition
parameter $\mathbf{\Delta}$ as an informativeness measure and introduces
strategic token arrangements to preserve sequential information flow.Extensive
experiments demonstrate that MaMe achieves superior efficiency-performance
trade-offs for both fine-tuned and off-the-shelf models. Particularly, our
approach maintains robustness even under aggressive token reduction where
existing methods undergo significant performance degradation.Beyond image
classification, MaMe shows strong generalization capabilities across video and
audio domains, establishing an effective approach for enhancing efficiency in
diverse SSM applications.

</details>


### [44] [Unleashing Semantic and Geometric Priors for 3D Scene Completion](https://arxiv.org/abs/2508.13601)
*Shiyuan Chen,Wei Sui,Bohao Zhang,Zeyd Boukhers,John See,Cong Yang*

Main category: cs.CV

TL;DR: 이 논문은 카메라 기반 3D semantic scene completion(SCC)에서 의미와 기하 정보를 분리해 처리하는 FoundationSSC를 제안한다. 소스 수준에서 파운데이션 인코더로 의미적 특징과 고품질 스테레오 비용 볼륨을 제공하고, 경로 수준에서 이들 priors를 분리된 전문 경로로 정제한다. 하이브리드 뷰 변환으로 보완적 3D 특징을 생성하고, Axis-Aware Fusion(AAF)으로 비등방성 융합을 수행한다. SemanticKITTI와 SSCBench-KITTI-360에서 SOTA 성능을 달성한다.


<details>
  <summary>Details</summary>
Motivation: 기존 방법들은 하나의 인코더로 의미와 기하 정보를 동시에 제공하려 해 두 요구 사항 간의 충돌로 성능 저하가 발생한다. 의미적 문맥과 정밀한 깊이 분포를 동시에 만족시키기 위해 두 축(소스와 경로)에서의 분리 설계가 필요하다.

Method: FoundationSSC는(1) 소스 수준 분해: 파운데이션 인코더가 의미적 특징과 스테레오 비용 볼륨을 제공, (2) 경로 수준 분해: 의미 분기와 기하 분기를 서로 다른 전문 경로로 정제, (3) 하이브리드 뷰 변환을 통해 보완적 3D 특징 생성, (4) Axis-Aware Fusion(AAF) 모듈로 특성들을 축별 비등방성 합성.

Result: SemanticKITTI에서 이전 최고 성능 대비 +0.23 mIoU, +2.03 IoU 향상을 보였고, SSCBench-KITTI-360에서 21.78 mIoU와 48.61 IoU로 SOTA 성능을 기록했다.

Conclusion: 소스 및 경로 수준의 이중 분해 설계와 AAF 융합을 통해 의미와 기하 정보를 효과적으로 분리·정제함으로써 카메라 기반 3D SSC의 의미적·기하적 성능을 동시에 향상시킨다.

Abstract: Camera-based 3D semantic scene completion (SSC) provides dense geometric and
semantic perception for autonomous driving and robotic navigation. However,
existing methods rely on a coupled encoder to deliver both semantic and
geometric priors, which forces the model to make a trade-off between
conflicting demands and limits its overall performance. To tackle these
challenges, we propose FoundationSSC, a novel framework that performs dual
decoupling at both the source and pathway levels. At the source level, we
introduce a foundation encoder that provides rich semantic feature priors for
the semantic branch and high-fidelity stereo cost volumes for the geometric
branch. At the pathway level, these priors are refined through specialised,
decoupled pathways, yielding superior semantic context and depth distributions.
Our dual-decoupling design produces disentangled and refined inputs, which are
then utilised by a hybrid view transformation to generate complementary 3D
features. Additionally, we introduce a novel Axis-Aware Fusion (AAF) module
that addresses the often-overlooked challenge of fusing these features by
anisotropically merging them into a unified representation. Extensive
experiments demonstrate the advantages of FoundationSSC, achieving simultaneous
improvements in both semantic and geometric metrics, surpassing prior bests by
+0.23 mIoU and +2.03 IoU on SemanticKITTI. Additionally, we achieve
state-of-the-art performance on SSCBench-KITTI-360, with 21.78 mIoU and 48.61
IoU. The code will be released upon acceptance.

</details>


### [45] [PersonaVlog: Personalized Multimodal Vlog Generation with Multi-Agent Collaboration and Iterative Self-Correction](https://arxiv.org/abs/2508.13602)
*Xiaolu Hou,Bing Ma,Jiaxiang Cheng,Xuhua Ren,Kai Yu,Wenyue Li,Tianxiang Zheng,Qinglin Lu*

Main category: cs.CV

TL;DR: PersonaVlog은 주제와 참조 이미지를 입력으로 받아 동영상, 배경음악, 내적 독백을 포함한 개인화된 Vlog를 자동 생성하는 MLLM 기반 멀티에이전트 협업 프레임워크이다. MLLM으로 고품질 프롬프트를 생성하고, 피드백·롤백 메커니즘으로 반복적 자기수정이 가능하며, ThemeVlogEval 벤치마크로 평가한다.


<details>
  <summary>Details</summary>
Motivation: 짧은 동영상 및 개인화 콘텐츠 수요 증가에도 기존 자동 Vlog 기법은 정형화된 스크립트에 의존해 역동성·개인성이 부족하므로, 다중 모달 협업과 높은 개인화를 지원하는 자동화 방식이 필요하다.

Method: MLLM 기반 멀티에이전트 협업 프레임워크를 도입해 사용자 입력으로부터 멀티모달 생성용 고품질 프롬프트를 만들고, MLLM을 활용한 평가·피드백·롤백 루프를 통해 생성물을 반복 개선한다. 출력물은 영상, 배경음악, 내적 독백 음성 등이다. 평가를 위해 ThemeVlogEval이라는 주제 기반 자동 벤치마크를 제안한다.

Result: 종합 실험에서 제안한 프레임워크가 여러 베이스라인에 비해 우수한 성능을 보였으며, 효율성·창의성·개인화 측면에서 유의미한 이점을 입증했다.

Conclusion: PersonaVlog는 자동화된 개인화 Vlog 생성에서 실용적 잠재력을 가지며, MLLM 기반 협업과 자기수정 메커니즘, 표준화된 평가 체계가 결합되어 향후 멀티모달 콘텐츠 생성 연구에 기여할 전망이다.

Abstract: With the growing demand for short videos and personalized content, automated
Video Log (Vlog) generation has become a key direction in multimodal content
creation. Existing methods mostly rely on predefined scripts, lacking dynamism
and personal expression. Therefore, there is an urgent need for an automated
Vlog generation approach that enables effective multimodal collaboration and
high personalization. To this end, we propose PersonaVlog, an automated
multimodal stylized Vlog generation framework that can produce personalized
Vlogs featuring videos, background music, and inner monologue speech based on a
given theme and reference image. Specifically, we propose a multi-agent
collaboration framework based on Multimodal Large Language Models (MLLMs). This
framework efficiently generates high-quality prompts for multimodal content
creation based on user input, thereby improving the efficiency and creativity
of the process. In addition, we incorporate a feedback and rollback mechanism
that leverages MLLMs to evaluate and provide feedback on generated results,
thereby enabling iterative self-correction of multimodal content. We also
propose ThemeVlogEval, a theme-based automated benchmarking framework that
provides standardized metrics and datasets for fair evaluation. Comprehensive
experiments demonstrate the significant advantages and potential of our
framework over several baselines, highlighting its effectiveness and great
potential for generating automated Vlogs.

</details>


### [46] [MIRAGE: Towards AI-Generated Image Detection in the Wild](https://arxiv.org/abs/2508.13223)
*Cheng Xia,Manxi Lin,Jiexiang Tan,Xiaoxiong Du,Yang Qiu,Junjun Zheng,Xiangheng Kong,Yuning Jiang,Bo Zheng*

Main category: cs.CV

TL;DR: AI 생성 이미지(AIGI)의 확산은 정보 보안과 신뢰 위협을 가져온다. 기존 탐지기는 실험실 환경에서는 성능이 좋지만 실제 환경에서는 일반화에 실패한다. 이를 해결하기 위해 저자들은 Mirage라는 현실적 벤치마크와 Mirage-R1이라는 비전-언어 모델(휴리스틱-분석적 및 반사적 추론 포함)을 제안한다. Mirage-R1은 감독-파인튜닝 후 강화학습으로 학습되며, 추론 시 적응적 사고 전략으로 속도와 정확도를 균형시킨다. 실험에서 기존 방법보다 Mirage에서 5%, 공개 벤치마크에서 10% 우수한 성능을 보였다.


<details>
  <summary>Details</summary>
Motivation: 생성 AI의 발전으로 AI가 만든 이미지(AIGI)가 널리 퍼지며 정보 보안과 공공 신뢰를 위협한다. 기존 탐지 모델들은 실험실 환경에서는 잘 작동하지만 실제 환경(다양한 생성 모델, 후처리 등)에서는 일반화되지 못한다. 따라서 실제 환경을 제대로 반영하는 벤치마크와 강건한 탐지 모델이 필요하다.

Method: (1) 현실적 벤치마크 Mirage 구성: 인터넷에서 수집된 인간 전문가가 검증한 AIGI와 다수의 전문 생성기들이 협력해 만든 합성 데이터로 구성. (2) Mirage-R1 제안: 비전-언어 모델로 휴리스틱-분석적(hueristic-to-analytic) 추론과 반사적(reflective) 추론 메커니즘 도입. 학습은 감독-파인튜닝(cold start) 후 강화학습 단계로 진행. 추론 시에는 적응적 사고(adaptive thinking) 전략을 사용해 빠른 판단 또는 정확한 결론 선택 가능.

Result: 제안한 모델은 Mirage 벤치마크에서 기존 최첨단 탐지기보다 5% 우수하고, 공개 벤치마크에서는 10% 더 우수한 성능을 보였다. 벤치마크와 코드 공개 예정.

Conclusion: 현실 세계의 다양한 AIGI를 반영하는 Mirage 벤치마크와 휴리스틱-분석적 반사적 추론을 결합한 Mirage-R1 모델은 AIGI 탐지에서 강건성과 일반화 성능을 크게 향상시킨다. 공개 데이터와 코드로 연구 재현 가능성을 높일 예정.

Abstract: The spreading of AI-generated images (AIGI), driven by advances in generative
AI, poses a significant threat to information security and public trust.
Existing AIGI detectors, while effective against images in clean laboratory
settings, fail to generalize to in-the-wild scenarios. These real-world images
are noisy, varying from ``obviously fake" images to realistic ones derived from
multiple generative models and further edited for quality control. We address
in-the-wild AIGI detection in this paper. We introduce Mirage, a challenging
benchmark designed to emulate the complexity of in-the-wild AIGI. Mirage is
constructed from two sources: (1) a large corpus of Internet-sourced AIGI
verified by human experts, and (2) a synthesized dataset created through the
collaboration between multiple expert generators, closely simulating the
realistic AIGI in the wild. Building on this benchmark, we propose Mirage-R1, a
vision-language model with heuristic-to-analytic reasoning, a reflective
reasoning mechanism for AIGI detection. Mirage-R1 is trained in two stages: a
supervised-fine-tuning cold start, followed by a reinforcement learning stage.
By further adopting an inference-time adaptive thinking strategy, Mirage-R1 is
able to provide either a quick judgment or a more robust and accurate
conclusion, effectively balancing inference speed and performance. Extensive
experiments show that our model leads state-of-the-art detectors by 5% and 10%
on Mirage and the public benchmark, respectively. The benchmark and code will
be made publicly available.

</details>


### [47] [Two-Factor Authentication Smart Entryway Using Modified LBPH Algorithm](https://arxiv.org/abs/2508.13617)
*Zakiah Ayop,Wan Mohamad Hariz Bin Wan Mohamad Rosdi,Looi Wei Hua,Syarulnaziah Anawar,Nur Fadzilah Othman*

Main category: cs.CV

TL;DR: Proposes a Raspberry Pi–based smart entry two-factor system combining LBPH face recognition and a modified LBPH occluded-face (mask) detector with passcode and Telegram remote; reports ~70% accuracy, ~80% precision, ~83.26% recall and positive user acceptance.


<details>
  <summary>Details</summary>
Motivation: Mask detection became critical during COVID-19; many face-detection models exist but IoT implementations for mask-aware access control are lacking. Need for secure smart entry that handles masked faces and notifies owners remotely.

Method: Two-factor authentication on Raspberry Pi: facial recognition (Local Binary Patterns Histograms, LBPH) and passcode verification; a modified LBPH for occluded-face/mask detection; automation to alert owners and activate surveillance when strangers are detected; remote control via Telegram; user registration and door lock/unlock functions implemented.

Result: System-level performance across tested users: Accuracy ≈70%, Precision ≈80%, Recall ≈83.26%. Functional demonstration: face recognition and mask detection, remote registration, door control, owner notification. High user acceptance in a user test.

Conclusion: Feasible prototype showing basic functionality but only moderate accuracy. Paper demonstrates IoT integration and automation, yet lacks details on dataset size, baseline comparisons, robustness, and scalability. Further improvements (larger/more diverse data, modern occlusion-aware models, thorough evaluation) are recommended.

Abstract: Face mask detection has become increasingly important recently, particularly
during the COVID-19 pandemic. Many face detection models have been developed in
smart entryways using IoT. However, there is a lack of IoT development on face
mask detection. This paper proposes a two-factor authentication system for
smart entryway access control using facial recognition and passcode
verification and an automation process to alert the owner and activate the
surveillance system when a stranger is detected and controls the system
remotely via Telegram on a Raspberry Pi platform. The system employs the Local
Binary Patterns Histograms for the full face recognition algorithm and modified
LBPH algorithm for occluded face detection. On average, the system achieved an
Accuracy of approximately 70%, a Precision of approximately 80%, and a Recall
of approximately 83.26% across all tested users. The results indicate that the
system is capable of conducting face recognition and mask detection, automating
the operation of the remote control to register users, locking or unlocking the
door, and notifying the owner. The sample participants highly accept it for
future use in the user acceptance test.

</details>


### [48] [RotBench: Evaluating Multimodal Large Language Models on Identifying Image Rotation](https://arxiv.org/abs/2508.13968)
*Tianyi Niu,Jaemin Cho,Elias Stengel-Eskin,Mohit Bansal*

Main category: cs.CV

TL;DR: The paper introduces RotBench, a 350-image benchmark to test Multimodal LLMs' ability to detect image rotations (0°, 90°, 180°, 270°). Many state-of-the-art models (including GPT-5, o3, Gemini-2.5-Pro) fail to reliably identify rotations: 0° is usually recognized, 180° sometimes, but 90° vs 270° is not distinguished. Auxiliary inputs and prompting give small inconsistent gains; multi-orientation display and voting help moderately; fine-tuning improves 180° detection but not 90°/270°. Overall, there is a notable spatial reasoning gap.


<details>
  <summary>Details</summary>
Motivation: To measure how well MLLMs perform basic spatial reasoning: specifically, identifying image orientation among four cardinal rotations—a seemingly simple perceptual task that probes models' ability to detect rotational cues and contextual spatial relationships.

Method: (Duplicate field corrected)

Result: Most models reliably identify upright (0°) images; some detect upside-down (180°); none reliably distinguish 90° vs 270°. Auxiliary information and chain-of-thought give small/inconsistent improvements. Showing multiple orientations improves reasoning models moderately; voting helps weaker models. Fine-tuning substantially improves 180° detection but not 90°/270° discrimination.

Conclusion: There is a significant gap between MLLMs' spatial reasoning and human perception for rotation detection. Current architectures/approaches struggle with orientation-specific cues, especially between left/right (90° vs 270°). New methods or focused training/data are needed to close this gap.

Abstract: We investigate to what extent Multimodal Large Language Models (MLLMs) can
accurately identify the orientation of input images rotated 0{\deg}, 90{\deg},
180{\deg}, and 270{\deg}. This task demands robust visual reasoning
capabilities to detect rotational cues and contextualize spatial relationships
within images, regardless of their orientation. To evaluate MLLMs on these
abilities, we introduce RotBench -- a 350-image manually-filtered benchmark
comprising lifestyle, portrait, and landscape images. Despite the relatively
simple nature of this task, we show that several state-of-the-art open and
proprietary MLLMs, including GPT-5, o3, and Gemini-2.5-Pro, do not reliably
identify rotation in input images. Providing models with auxiliary information
-- including captions, depth maps, and more -- or using chain-of-thought
prompting offers only small and inconsistent improvements. Our results indicate
that most models are able to reliably identify right-side-up (0{\deg}) images,
while certain models are able to identify upside-down (180{\deg}) images. None
can reliably distinguish between 90{\deg} and 270{\deg}. Simultaneously showing
the image rotated in different orientations leads to moderate performance gains
for reasoning models, while a modified setup using voting improves the
performance of weaker models. We further show that fine-tuning does not improve
models' ability to distinguish 90{\deg} and 270{\deg} rotations, despite
substantially improving the identification of 180{\deg} images. Together, these
results reveal a significant gap between MLLMs' spatial reasoning capabilities
and human perception in identifying rotation.

</details>


### [49] [TalkVid: A Large-Scale Diversified Dataset for Audio-Driven Talking Head Synthesis](https://arxiv.org/abs/2508.13618)
*Shunian Chen,Hejin Huang,Yexin Liu,Zihan Ye,Pengcheng Chen,Chenghao Zhu,Michael Guan,Rongsheng Wang,Junying Chen,Guanbin Li,Ser-Nam Lim,Harry Yang,Benyou Wang*

Main category: cs.CV

TL;DR: TalkVid는 7729명의 화자, 1244시간 분량의 대규모 고품질 음성-얼굴 데이터셋으로, 기존 데이터의 규모·품질·다양성 한계를 보완해 오디오 기반 토킹헤드 합성 모델의 일반화 성능을 크게 향상시킨다. 또한 인구학·언어 축을 균형있게 구성한 500클립 평가집합(TalkVid-Bench)을 제시해 하위집단별 성능 격차를 드러낸다.


<details>
  <summary>Details</summary>
Motivation: 현재 SOTA 오디오 기반 토킹헤드 합성 모델들은 인종·언어·연령 등 인간 다양성 전반에 대한 일반화 능력이 부족하다. 저자들은 이는 기존 훈련 데이터셋이 충분한 규모, 품질, 다양성을 갖추지 못했기 때문이라고 주장한다.

Method: 자동화된 다단계 파이프라인을 통해 모션 안정성, 심미적 품질, 얼굴 디테일 등을 엄격히 필터링하여 고품질 비디오를 선별하고, 인간 판단으로 검증한다. 이를 통해 7729명, 1244시간 규모의 TalkVid 데이터셋을 구축하고, 균형 잡힌 500클립의 평가셋 TalkVid-Bench도 구성·공개한다.

Result: TalkVid로 학습한 모델은 기존 데이터로 학습된 모델들보다 교차-데이터셋 일반화 성능이 우수했다. 또한 TalkVid-Bench 분석에서 전통적 집계 지표로는 가려졌던 하위집단 간 성능 격차가 관찰되었다.

Conclusion: 대규모·고품질·다양성 중심의 데이터셋은 토킹헤드 합성 모델의 일반화를 개선하며, 균형된 평가셋은 하위집단별 편향과 불균형을 드러내는 데 필수적이다. 데이터·코드 공개로 후속 연구 촉진을 기대한다.

Abstract: Audio-driven talking head synthesis has achieved remarkable photorealism, yet
state-of-the-art (SOTA) models exhibit a critical failure: they lack
generalization to the full spectrum of human diversity in ethnicity, language,
and age groups. We argue that this generalization gap is a direct symptom of
limitations in existing training data, which lack the necessary scale, quality,
and diversity. To address this challenge, we introduce TalkVid, a new
large-scale, high-quality, and diverse dataset containing 1244 hours of video
from 7729 unique speakers. TalkVid is curated through a principled, multi-stage
automated pipeline that rigorously filters for motion stability, aesthetic
quality, and facial detail, and is validated against human judgments to ensure
its reliability. Furthermore, we construct and release TalkVid-Bench, a
stratified evaluation set of 500 clips meticulously balanced across key
demographic and linguistic axes. Our experiments demonstrate that a model
trained on TalkVid outperforms counterparts trained on previous datasets,
exhibiting superior cross-dataset generalization. Crucially, our analysis on
TalkVid-Bench reveals performance disparities across subgroups that are
obscured by traditional aggregate metrics, underscoring its necessity for
future research. Code and data can be found in
https://github.com/FreedomIntelligence/TalkVid

</details>


### [50] [RCGNet: RGB-based Category-Level 6D Object Pose Estimation with Geometric Guidance](https://arxiv.org/abs/2508.13623)
*Sheng Yu,Di-Hua Zhai,Yuanqing Xia*

Main category: cs.CV

TL;DR: RGB만으로 범주 수준 물체 자세 추정을 수행하는 새로운 방법을 제안한다. 트랜스포머로 물체의 기하학적 특징을 예측·융합하고, 이를 보강하는 기하학적 특징 유도 알고리즘과 RANSAC-PnP를 결합해 깊이 정보 없이도 높은 정확도와 효율성을 달성한다.


<details>
  <summary>Details</summary>
Motivation: 대부분의 범주 수준 물체 자세 추정은 RGB-D 기반으로 높은 성능을 보이나, 실제 환경에서는 깊이 정보가 없거나 신뢰할 수 없는 경우가 많아 RGB 전용 방법의 필요성이 존재한다. 깊이 부재 상황에서 기하학적 정보를 충분히 복원·활용하는 것이 핵심 도전 과제이다.

Method: 트랜스포머 기반 신경망을 설계해 대상 물체의 기하학적 특징을 예측하고 이들을 융합한다. 예측된 기하학적 특징이 실제 물체 기하를 잘 반영하도록 ‘기하학적 특징 유도(geometric feature-guided)’ 알고리즘을 도입해 특징 표현을 강화한다. 최종 포즈 계산에는 RANSAC-PnP를 사용해 물체 크기(스케일) 변동 문제를 처리한다.

Result: 벤치마크 데이터셋 실험에서 제안 방법은 기존 RGB 기반 방법들보다 우수한 정확도와 높은 효율성을 보였다(정량적 수치 및 대상 데이터셋은 초록에 명시되지 않음).

Conclusion: 깊이 정보 없이도 범주 수준 물체 자세 추정이 가능함을 보였으며, 트랜스포머 기반 기하학적 특징 학습과 유도 알고리즘, RANSAC-PnP의 조합이 효과적이다. RGB 전용 포즈 추정 분야에서 유망한 방향을 제시한다.

Abstract: While most current RGB-D-based category-level object pose estimation methods
achieve strong performance, they face significant challenges in scenes lacking
depth information. In this paper, we propose a novel category-level object pose
estimation approach that relies solely on RGB images. This method enables
accurate pose estimation in real-world scenarios without the need for depth
data. Specifically, we design a transformer-based neural network for
category-level object pose estimation, where the transformer is employed to
predict and fuse the geometric features of the target object. To ensure that
these predicted geometric features faithfully capture the object's geometry, we
introduce a geometric feature-guided algorithm, which enhances the network's
ability to effectively represent the object's geometric information. Finally,
we utilize the RANSAC-PnP algorithm to compute the object's pose, addressing
the challenges associated with variable object scales in pose estimation.
Experimental results on benchmark datasets demonstrate that our approach is not
only highly efficient but also achieves superior accuracy compared to previous
RGB-based methods. These promising results offer a new perspective for
advancing category-level object pose estimation using RGB images.

</details>


### [51] [DiffIER: Optimizing Diffusion Models with Iterative Error Reduction](https://arxiv.org/abs/2508.13628)
*Ao Chen,Lihe Ding,Tianfan Xue*

Main category: cs.CV

TL;DR: 


<details>
  <summary>Details</summary>
Motivation: 

Method: 

Result: 

Conclusion: 

Abstract: Diffusion models have demonstrated remarkable capabilities in generating
high-quality samples and enhancing performance across diverse domains through
Classifier-Free Guidance (CFG). However, the quality of generated samples is
highly sensitive to the selection of the guidance weight. In this work, we
identify a critical ``training-inference gap'' and we argue that it is the
presence of this gap that undermines the performance of conditional generation
and renders outputs highly sensitive to the guidance weight. We quantify this
gap by measuring the accumulated error during the inference stage and establish
a correlation between the selection of guidance weight and minimizing this gap.
Furthermore, to mitigate this gap, we propose DiffIER, an optimization-based
method for high-quality generation. We demonstrate that the accumulated error
can be effectively reduced by an iterative error minimization at each step
during inference. By introducing this novel plug-and-play optimization
framework, we enable the optimization of errors at every single inference step
and enhance generation quality. Empirical results demonstrate that our proposed
method outperforms baseline approaches in conditional generation tasks.
Furthermore, the method achieves consistent success in text-to-image
generation, image super-resolution, and text-to-speech generation, underscoring
its versatility and potential for broad applications in future research.

</details>


### [52] [GaitCrafter: Diffusion Model for Biometric Preserving Gait Synthesis](https://arxiv.org/abs/2508.13300)
*Sirshapan Mitra,Yogesh S. Rawat*

Main category: cs.CV

TL;DR: GaitCrafter는 실루엣 기반의 비디오 확산 모델로, 보행 시퀀스를 시간적으로 일관되게, 신원 보존하면서 생성하고 의복·소지품·시점 등 조건 제어가 가능하다. 합성 샘플을 학습에 포함하면 보행인식 성능이 특히 어려운 조건에서 향상되며, 신원 임베딩 보간으로 새로운(실제 데이터에 없는) 신원을 생성해 개인정보 보호를 높인다.


<details>
  <summary>Details</summary>
Motivation: 대규모 라벨된 보행 데이터 부족과 다양한 보행 샘플 수집의 어려움(프라이버시 문제 포함)을 해결하고자 함.

Method: 실루엣 데이터만으로 처음부터 학습한 비디오 확산 모델(GaitCrafter)을 제안. 시간적 일관성과 신원 보존을 목표로 하며, 의복·휴대물·카메라 시점 등 여러 공변량(condition)에 따라 생성 과정을 제어. 또한 신원 임베딩을 보간해 새로운 신원 생성 메커니즘을 도입.

Result: GaitCrafter로 생성한 합성 시퀀스를 보행인식 파이프라인에 포함하면 인식 성능이 향상되며, 특히 어려운 조건에서 유의한 개선을 보임. 생성된 새로운 신원은 일관된 고유 보행 패턴을 가지며 실제 피험자 프라이버시를 침해하지 않음.

Conclusion: 확산 모델을 이용한 실루엣 기반 보행 시퀀스 생성은 고품질·제어 가능·프라이버시 친화적인 데이터 보강 수단으로 유용하며, 보행인식의 데이터 제약 문제를 완화할 수 있는 효과적인 접근법임.

Abstract: Gait recognition is a valuable biometric task that enables the identification
of individuals from a distance based on their walking patterns. However, it
remains limited by the lack of large-scale labeled datasets and the difficulty
of collecting diverse gait samples for each individual while preserving
privacy. To address these challenges, we propose GaitCrafter, a diffusion-based
framework for synthesizing realistic gait sequences in the silhouette domain.
Unlike prior works that rely on simulated environments or alternative
generative models, GaitCrafter trains a video diffusion model from scratch,
exclusively on gait silhouette data. Our approach enables the generation of
temporally consistent and identity-preserving gait sequences. Moreover, the
generation process is controllable-allowing conditioning on various covariates
such as clothing, carried objects, and view angle. We show that incorporating
synthetic samples generated by GaitCrafter into the gait recognition pipeline
leads to improved performance, especially under challenging conditions.
Additionally, we introduce a mechanism to generate novel identities-synthetic
individuals not present in the original dataset-by interpolating identity
embeddings. These novel identities exhibit unique, consistent gait patterns and
are useful for training models while maintaining privacy of real subjects.
Overall, our work takes an important step toward leveraging diffusion models
for high-quality, controllable, and privacy-aware gait data generation.

</details>


### [53] [OmniTry: Virtual Try-On Anything without Masks](https://arxiv.org/abs/2508.13632)
*Yutong Feng,Linlin Zhang,Hengyuan Cao,Yiming Chen,Xiaoduan Feng,Jian Cao,Yuxiong Wu,Bin Wang*

Main category: cs.CV

TL;DR: OmniTry는 의류를 넘어서 보석·액세서리 등 모든 착용 가능 객체에 대해 마스크 없는 실용적 가상 착용(VTON)을 수행하는 통합 프레임워크다. 대량의 비대응(unpaired) 인물을 활용한 자동 위치화(마스크 없이 객체를 그리는 인페인팅 재구성)로 초기에 학습하고, 소수의 대응(paired) 샘플로 외형 일관성 전이를 위해 미세조정하여 적은 대응 데이터로도 빠르게 수렴한다. 12개 착용물 클래스로 평가해 기존 방법보다 위치화와 ID 보존 성능이 우수하다.


<details>
  <summary>Details</summary>
Motivation: 기존 VTON 연구는 대부분 의류에 집중되어 있고, 보석·액세서리 등 다양한 착용물로 확장할 때 적절한 대응 이미지(객체 이미지와 해당 착용 결과)를 수집하기 어렵다. 마스크가 없는 실무적 설정에서 다양한 객체를 지원하는 범용 방법이 필요하다.

Method: 두 단계 파이프라인을 제안: 1) 대규모 비대응(언페어드) 인물 이미지를 이용해 마스크-프리(localization) 학습: 인페인팅 모델을 재구성해 빈 마스크에 적절한 위치와 형태로 객체를 자동으로 그리도록 학습한다. 2) 대응(페어드) 이미지로 미세조정하여 객체 외형의 일관성(appearance consistency)을 전이한다. 1단계로 얻은 모델은 소수의 페어드 샘플만으로도 빠르게 수렴한다.

Result: 12개 착용물 클래스(인샵 및 인더와일드 이미지 포함)로 구성된 종합 벤치마크에서 평가하여, 기존 방법 대비 객체 위치화(localization)와 ID-보존 성능에서 우수한 결과를 보였다.

Conclusion: OmniTry는 마스크 없는 설정에서 다양한 착용물을 지원하는 실용적 VTON 솔루션으로, 대응 데이터 부족 문제를 완화하고 적은 페어드 샘플로도 높은 성능을 달성한다. 코드·모델·벤치마크 공개 예정.

Abstract: Virtual Try-ON (VTON) is a practical and widely-applied task, for which most
of existing works focus on clothes. This paper presents OmniTry, a unified
framework that extends VTON beyond garment to encompass any wearable objects,
e.g., jewelries and accessories, with mask-free setting for more practical
application. When extending to various types of objects, data curation is
challenging for obtaining paired images, i.e., the object image and the
corresponding try-on result. To tackle this problem, we propose a two-staged
pipeline: For the first stage, we leverage large-scale unpaired images, i.e.,
portraits with any wearable items, to train the model for mask-free
localization. Specifically, we repurpose the inpainting model to automatically
draw objects in suitable positions given an empty mask. For the second stage,
the model is further fine-tuned with paired images to transfer the consistency
of object appearance. We observed that the model after the first stage shows
quick convergence even with few paired samples. OmniTry is evaluated on a
comprehensive benchmark consisting of 12 common classes of wearable objects,
with both in-shop and in-the-wild images. Experimental results suggest that
OmniTry shows better performance on both object localization and
ID-preservation compared with existing methods. The code, model weights, and
evaluation benchmark of OmniTry will be made publicly available at
https://omnitry.github.io/.

</details>


### [54] [DeH4R: A Decoupled and Hybrid Method for Road Network Graph Extraction](https://arxiv.org/abs/2508.13669)
*Dengxian Gong,Shunping Ji*

Main category: cs.CV

TL;DR: 이 논문은 원격탐사 이미지에서 도로 네트워크 그래프를 추출하는 문제를 다루며, 그래프 생성 효율성과 그래프 성장 방식의 동적 삽입 능력을 결합한 하이브리드 모델 DeH4R을 제안한다. DeH4R은 후보 정점 검출, 인접 정점 예측, 초기 그래프 구성, 그래프 확장으로 작업을 분리해 빠른 추론과 토폴로지 충실도 및 공간 일관성 향상을 이룬다. CityScale과 SpaceNet에서 SOTA 성능을 보이며 RNGDet++보다 APLS 4.62, IoU 10.18 개선 및 약 10배 빠름.


<details>
  <summary>Details</summary>
Motivation: 기존 분할 기반 방법은 벡터화 후 토폴로지 유지에 어려움이 있고, 그래프 성장 방식은 연속적인 관심영역(ROI) 자르기 때문에 계산 비용이 크며, 그래프 생성 방식은 빠르지만 정적 정점에 제약이 있어 동적 정점 삽입이 어렵다. 이 문제들을 해결하기 위해 효율성과 동적성을 모두 갖춘 방법이 필요하다.

Method: DeH4R은 작업을 후보 정점 검출(candidate vertex detection), 인접 정점 예측(adjacent vertex prediction), 초기 그래프 구성(initial graph construction), 그래프 확장(graph expansion)으로 분해한다. 먼저 글로벌 정적 후보 정점을 예측하고, 각 정점의 인접 정점을 예측해 초기 그래프를 만든 뒤, 그래프 확장을 통해 동적으로 정점(및 간선)을 삽입한다. 이 설계로 그래프 생성 방식의 빠른 추론을 유지하면서 그래프 성장 방식의 동적 삽입을 가능하게 한다.

Result: CityScale과 SpaceNet 벤치마크에서 SOTA 성능을 달성했다. 특히 CityScale에서 그래프 성장 기반 SOTA인 RNGDet++보다 APLS 지표에서 4.62, IoU에서 10.18 향상되었고, 추론 속도는 약 10배 빠르다.

Conclusion: DeH4R은 그래프 생성의 속도와 그래프 성장의 동적성을 결합해 토폴로지 충실도와 공간 일관성을 동시에 향상시키며 실제 벤치마크에서 우수한 성능을 보인다. 이 접근은 도로 네트워크 추출의 효율성과 정확도를 동시에 개선할 수 있는 유망한 방법이다.

Abstract: The automated extraction of complete and precise road network graphs from
remote sensing imagery remains a critical challenge in geospatial computer
vision. Segmentation-based approaches, while effective in pixel-level
recognition, struggle to maintain topology fidelity after vectorization
postprocessing. Graph-growing methods build more topologically faithful graphs
but suffer from computationally prohibitive iterative ROI cropping.
Graph-generating methods first predict global static candidate road network
vertices, and then infer possible edges between vertices. They achieve fast
topology-aware inference, but limits the dynamic insertion of vertices. To
address these challenges, we propose DeH4R, a novel hybrid model that combines
graph-generating efficiency and graph-growing dynamics. This is achieved by
decoupling the task into candidate vertex detection, adjacent vertex
prediction, initial graph contruction, and graph expansion. This architectural
innovation enables dynamic vertex (edge) insertions while retaining fast
inference speed and enhancing both topology fidelity and spatial consistency.
Comprehensive evaluations on CityScale and SpaceNet benchmarks demonstrate
state-of-the-art (SOTA) performance. DeH4R outperforms the prior SOTA
graph-growing method RNGDet++ by 4.62 APLS and 10.18 IoU on CityScale, while
being approximately 10 $\times$ faster. The code will be made publicly
available at https://github.com/7777777FAN/DeH4R.

</details>


### [55] [HumanPCR: Probing MLLM Capabilities in Diverse Human-Centric Scenes](https://arxiv.org/abs/2508.13692)
*Keliang Li,Hongze Shen,Hao Shi,Ruibing Hou,Hong Chang,Jie Huang,Chenghao Jia,Wen Wang,Yiling Wu,Dongmei Jiang,Shiguang Shan,Xilin Chen*

Main category: cs.CV

TL;DR: HumanPCR는 인간 관련 시각 문맥을 세 단계(Perception/Comprehension/Reasoning)로 평가하는 MLLM 평가 도구다. Human-P와 Human-C는 9개 차원에 걸친 6,000개 이상의 인간 검증 객관식 질문을 제공하고, Human-R은 시각 증거 통합과 능동적 맥락 추출을 요구하는 수작업 비디오 추론 테스트다. 각 질문에는 CoT 근거가 있고, 30개 이상의 최신 모델 평가에서 세부 공간 인지, 시간 이해, 마음 모델링 등에서 성능 한계를 보였다.


<details>
  <summary>Details</summary>
Motivation: 멀티모달 모델의 급속한 발전에도 불구하고 인간 수준의 다양한 환경에서의 시각적 인간 관련 이해 능력을 제대로 측정할 수 있는 평가 수단이 부족하다. 기존 벤치마크는 자주 간과되는 필수 능력을 충분히 다루지 못하므로, 인간 중심의 정밀한 평가가 필요하다.

Method: HumanPCR는 세 계층(Human-P, Human-C, Human-R)으로 구성된다. Human-P와 Human-C는 6,000+ 인간 검증 객관식 문항으로 9개 차원을 평가한다. Human-R은 수동으로 선별된 비디오 추론 테스트로, 질문 단서 이상의 능동적 맥락 추출과 다중 시각 증거 통합을 요구하며, 각 문항에 대해 인간 주석의 CoT(Chain-of-Thought) 근거와 핵심 시각 증거를 제공한다. 광범위한 실험으로 30개 이상 최신 모델을 평가하고, 시각 문맥 확장 및 테스트 시 사고 등 기법의 효과를 분석했다.

Result: 대부분의 모델이 인간 중심 시각 이해에서 큰 어려움을 겪었다. 특히 상세한 공간 인지, 시간적 이해, 그리고 마음 모델링(task)에서 성능 저하가 두드러졌다. Human-R 분석에서는 모델들이 다양한 인간 장면에서 필수적이고 능동적인 시각 증거를 추출하지 못하고, 질문에 유도된 검색에 과도하게 의존하는 경향이 발견되었다. 시각 문맥 확장과 테스트 시 사고도 제한된 효과만 보였다.

Conclusion: HumanPCR는 인간 관련 시각 이해의 세부적 결함을 드러내며, MLLM의 개발과 평가, 인간 중심 응용을 진전시키는 데 기여할 것이다.

Abstract: The aspiration for artificial general intelligence, fueled by the rapid
progress of multimodal models, demands human-comparable performance across
diverse environments. We propose HumanPCR, an evaluation suite for probing
MLLMs' capacity about human-related visual contexts across three hierarchical
levels: Perception, Comprehension, and Reasoning (denoted by Human-P, Human-C,
and Human-R, respectively). Human-P and Human-C feature over 6,000
human-verified multiple choice questions, assessing massive tasks of 9
dimensions, including but not limited to essential skills frequently overlooked
by existing benchmarks. Human-R offers a challenging manually curated video
reasoning test that requires integrating multiple visual evidences, proactively
extracting context beyond question cues, and applying human-like expertise.
Each question includes human-annotated Chain-of-Thought (CoT) rationales with
key visual evidence to support further research. Extensive evaluations on over
30 state-of-the-art models exhibit significant challenges in human-centric
visual understanding, particularly in tasks involving detailed space
perception, temporal understanding, and mind modeling. Moreover, analysis of
Human-R reveals the struggle of models in extracting essential proactive visual
evidence from diverse human scenes and their faulty reliance on query-guided
retrieval. Even with advanced techniques like scaling visual contexts and
test-time thinking yield only limited benefits. We hope HumanPCR and our
findings will advance the development, evaluation, and human-centric
application of multimodal models.

</details>


### [56] [Diversity-enhanced Collaborative Mamba for Semi-supervised Medical Image Segmentation](https://arxiv.org/abs/2508.13712)
*Shumeng Li,Jian Zhang,Lei Qi,Luping Zhou,Yinghuan Shi,Yang Gao*

Main category: cs.CV

TL;DR: 본 논문은 Mamba 기반 상태공간모델을 활용한 반지도 의료 영상 분할 기법 DCMamba를 제안한다. 데이터·네트워크·특징 관점에서 다양성을 증강하여 준지도 학습 성능을 크게 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 의료 영상 분할을 위한 고품질 주석 데이터 확보는 비용과 시간이 많이 든다. 준지도 학습은 비주석 데이터를 활용해 부담을 줄이지만, 장거리 의존성 처리에 강한 최신 상태공간모델(Mamba)의 가능성은 충분히 활용되지 않았다. 다양한 관점의 다양성 확보가 성능 향상에 기여할 수 있다는 점에서 출발.

Method: DCMamba 구성요소: (1) 데이터 관점: Mamba의 스캐닝 특성을 고려한 패치 수준 약강(weak-strong) 믹싱 증강, (2) 네트워크 관점: 서로 다른 스캐닝 방향에서 발생하는 예측 불일치로 이득을 얻는 diverse-scan collaboration 모듈, (3) 특징 관점: 불확실도 가중 대조학습(uncertainty-weighted contrastive learning)으로 표현 다양성 강화.

Result: 여러 준지도 의료 영상 분할 기법보다 유의미하게 우수한 성능을 보임. 예: Synapse 데이터셋에서 라벨 20% 조건에서 최신 SSM 기반 방법 대비 6.69% 향상.

Conclusion: 데이터·네트워크·특징의 다각적 다양성 증진을 통해 Mamba 기반 모델의 준지도 의료 영상 분할 성능을 크게 끌어올렸으며, 제안한 DCMamba가 실용적이고 효과적임을 실험적으로 입증했다.

Abstract: Acquiring high-quality annotated data for medical image segmentation is
tedious and costly. Semi-supervised segmentation techniques alleviate this
burden by leveraging unlabeled data to generate pseudo labels. Recently,
advanced state space models, represented by Mamba, have shown efficient
handling of long-range dependencies. This drives us to explore their potential
in semi-supervised medical image segmentation. In this paper, we propose a
novel Diversity-enhanced Collaborative Mamba framework (namely DCMamba) for
semi-supervised medical image segmentation, which explores and utilizes the
diversity from data, network, and feature perspectives. Firstly, from the data
perspective, we develop patch-level weak-strong mixing augmentation with
Mamba's scanning modeling characteristics. Moreover, from the network
perspective, we introduce a diverse-scan collaboration module, which could
benefit from the prediction discrepancies arising from different scanning
directions. Furthermore, from the feature perspective, we adopt an
uncertainty-weighted contrastive learning mechanism to enhance the diversity of
feature representation. Experiments demonstrate that our DCMamba significantly
outperforms other semi-supervised medical image segmentation methods, e.g.,
yielding the latest SSM-based method by 6.69% on the Synapse dataset with 20%
labeled data.

</details>


### [57] [Hierarchical Vision-Language Retrieval of Educational Metaverse Content in Agriculture](https://arxiv.org/abs/2508.13713)
*Ali Abdari,Alex Falcon,Giuseppe Serra*

Main category: cs.CV

TL;DR: 아그리테마(농업) 중심의 457개 가상 박물관(AgriMuseums) 데이터셋을 공개하고, 자연어 질의로 관련 메타버스 환경을 검색하는 계층적 비전–언어 표현·검색 모델을 제안한다. 제안 모델은 R@1 약 62%, MRR 약 78%를 달성하며 기존 벤치마크 대비 최대 6% R@1, 11% MRR 향상을 보인다. 코드와 데이터셋은 공개되어 있다.


<details>
  <summary>Details</summary>
Motivation: 인터넷에 업로드되는 농업·원예 등 교육 콘텐츠를 메타버스 기반의 가상 전시(virtual museum)로 구조화하면 학습 효과를 높일 수 있으나, 사용자의 관심사에 맞는 메타버스 시나리오를 찾는 검색·검색적 매칭 문제는 풀기 어렵다. 기존 데이터셋이 작아 고성능 모델 학습에 한계가 있어 더 큰 도메인별 데이터와 효과적인 표현·검색 모델이 필요하다.

Method: (1) 농업 주제의 가상 박물관 457개와 각 박물관의 텍스트 설명으로 구성된 AgriMuseums 데이터셋을 구축했다. (2) 자연어 질의로 관련 박물관을 찾기 위한 계층적 비전–언어 모델을 제안했다. 계층적 구조를 통해 박물관 내 다양한 시각·텍스트 단위(예: 전체 전시, 섹션, 개별 아이템)를 포착하고 이들 표현을 통합해 검색에 활용하는 방식으로 보인다. 실험은 검색(리트리벌) 지표(R@k, MRR)를 사용해 평가했다.

Result: 제안 모델은 실험 환경에서 R@1 최대 약 62%와 MRR 약 78%를 기록했고, 기존 벤치마크에 비해 최대 6% R@1 및 11% MRR 향상을 달성했다. 또한 설계 선택을 검증하는 광범위한 평가를 수행했다.

Conclusion: AgriMuseums 데이터셋과 계층적 비전–언어 리트리벌 모델은 농업 중심 메타버스 검색 문제에 유의미한 진전을 제공하며, 코드·데이터 공개로 후속 연구를 촉진한다.

Abstract: Every day, a large amount of educational content is uploaded online across
different areas, including agriculture and gardening. When these videos or
materials are grouped meaningfully, they can make learning easier and more
effective. One promising way to organize and enrich such content is through the
Metaverse, which allows users to explore educational experiences in an
interactive and immersive environment. However, searching for relevant
Metaverse scenarios and finding those matching users' interests remains a
challenging task. A first step in this direction has been done recently, but
existing datasets are small and not sufficient for training advanced models. In
this work, we make two main contributions: first, we introduce a new dataset
containing 457 agricultural-themed virtual museums (AgriMuseums), each enriched
with textual descriptions; and second, we propose a hierarchical
vision-language model to represent and retrieve relevant AgriMuseums using
natural language queries. In our experimental setting, the proposed method
achieves up to about 62\% R@1 and 78\% MRR, confirming its effectiveness, and
it also leads to improvements on existing benchmarks by up to 6\% R@1 and 11\%
MRR. Moreover, an extensive evaluation validates our design choices. Code and
dataset are available at
https://github.com/aliabdari/Agricultural_Metaverse_Retrieval .

</details>


### [58] [Enhancing Targeted Adversarial Attacks on Large Vision-Language Models through Intermediate Projector Guidance](https://arxiv.org/abs/2508.13739)
*Yiming Cao,Yanjie Li,Kaisheng Liang,Yuni Lai,Bin Xiao*

Main category: cs.CV

TL;DR: IPGA는 VLM의 중간 프로젝터(Q-Former) 단계의 시각 토큰을 조작해 더 세밀하고 통제된 표적 적대적 공격을 수행하는 방법이다. RQA로 관련 없는 시각 정보를 보존해 공격 정밀도를 높이며, 검은상자 환경과 상업용 VLM(Gemini, GPT 등)으로의 전이성에서 기존 기법을 능가한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 표적 적대적 공격은 이미지 전체를 하나의 글로벌 임베딩으로 압축해 공격하므로 세부 객체 수준 조작(예: 배경은 유지하면서 자동차만 변경)이 어렵고, 프로젝터 모듈(예: Q-Former)을 무시해 비전-언어 정렬 파이프라인 전체를 교란하지 못한다.

Method: Intermediate Projector Guided Attack(IPGA)은 Q-Former의 중간 출력을 직접 조작해 의미 있는 시각 토큰 단위에서 섬세한 교란을 가한다. Q-Former는 초기 비전-언어 정렬 단계에서만 사전학습된 것을 사용해 LLM 파인튜닝 없이도 공격 효과와 전이성을 향상시킨다. 또한 Residual Query Alignment(RQA)를 도입해 공격과 무관한 시각 정보를 보존, 더 통제된 조작을 가능하게 한다.

Result: 광범위한 실험에서 IPGA는 기존 전역 임베딩 기반 공격보다 표적 캡셔닝과 세부 VQA(visual question answering) 작업에서 검은상자 환경에서 일관되게 우수한 성능을 보였다. 또한 Google Gemini, OpenAI GPT 등 다수의 상업용 VLM으로의 성공적인 전이를 확인했다.

Conclusion: 프로젝터의 중간 단계(특히 Q-Former)를 이용한 공격은 VLM의 세밀한 취약점을 더 효과적으로 드러내며, RQA를 통해 무관한 시각 정보 보존으로 정밀한 조작이 가능하다. IPGA는 공격 성능 및 전이성 측면에서 실용적이며 기존 방법의 한계를 극복한다.

Abstract: Targeted adversarial attacks are essential for proactively identifying
security flaws in Vision-Language Models before real-world deployment. However,
current methods perturb images to maximize global similarity with the target
text or reference image at the encoder level, collapsing rich visual semantics
into a single global vector. This limits attack granularity, hindering
fine-grained manipulations such as modifying a car while preserving its
background. Furthermore, these methods largely overlook the projector module, a
critical semantic bridge between the visual encoder and the language model in
VLMs, thereby failing to disrupt the full vision-language alignment pipeline
within VLMs and limiting attack effectiveness. To address these issues, we
propose the Intermediate Projector Guided Attack (IPGA), the first method to
attack using the intermediate stage of the projector module, specifically the
widely adopted Q-Former, which transforms global image embeddings into
fine-grained visual features. This enables more precise control over
adversarial perturbations by operating on semantically meaningful visual tokens
rather than a single global representation. Specifically, IPGA leverages the
Q-Former pretrained solely on the first vision-language alignment stage,
without LLM fine-tuning, which improves both attack effectiveness and
transferability across diverse VLMs. Furthermore, we propose Residual Query
Alignment (RQA) to preserve unrelated visual content, thereby yielding more
controlled and precise adversarial manipulations. Extensive experiments show
that our attack method consistently outperforms existing methods in both
standard global image captioning tasks and fine-grained visual
question-answering tasks in black-box environment. Additionally, IPGA
successfully transfers to multiple commercial VLMs, including Google Gemini and
OpenAI GPT.

</details>


### [59] [Mitigating Cross-Image Information Leakage in LVLMs for Multi-Image Tasks](https://arxiv.org/abs/2508.13744)
*Yeji Park,Minyoung Lee,Sanghyuk Chun,Junsuk Choe*

Main category: cs.CV

TL;DR: FOCUS는 추가 학습·구조 변경 없이 다중 이미지 입력에서 발생하는 ‘교차 이미지 정보 누수’를 줄이는 추론 단계 디코딩 전략이다. 각 반복에서 한 장의 이미지만 깨끗하게 유지하고 나머지는 무작위 노이즈로 마스킹한 뒤, 얻은 로짓들을 집계하고 노이즈 전용 참조와 대비적으로 정제해 정확도를 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 대형 비전-언어 모델들은 단일 이미지 과제에서는 우수하지만, 다중 이미지 입력에서는 서로 다른 이미지의 시각적 단서가 출력에서 뒤섞여 성능이 크게 저하된다(교차 이미지 정보 누수 문제). 이 문제는 모델 구조 변경이나 추가 학습 없이도 해결 가능한 실용적 방법이 필요하다.

Method: FOCUS는 학습이 필요 없는 디코딩 기법으로, 목표 이미지 하나를 제외한 모든 이미지를 무작위 노이즈로 마스킹하여 모델이 해당 한 장에 집중하도록 유도한다. 이 과정을 모든 타깃 이미지에 대해 반복해 부분 마스킹된 문맥에서의 로짓을 얻고, 이 로짓들을 집계한 뒤 노이즈 전용 입력에서 얻은 참조와 대비적으로 정제하여 누수를 억제한다.

Result: FOCUS는 네 가지 다중 이미지 벤치마크와 다양한 LVLM 계열에서 일관되게 성능을 향상시켰다. 추가 학습이나 아키텍처 변경 없이도 다중 이미지 추론 능력을 개선하는 효과를 보였다.

Conclusion: FOCUS는 일반적이고 실용적인 해결책으로, 별도 훈련이나 구조 수정 없이도 다중 이미지 상황에서의 정보 누수를 줄여 LVLM의 추론 정확도를 높인다.

Abstract: Large Vision-Language Models (LVLMs) demonstrate strong performance on
single-image tasks. However, we observe that their performance degrades
significantly when handling multi-image inputs. This occurs because visual cues
from different images become entangled in the model's output. We refer to this
phenomenon as cross-image information leakage. To address this issue, we
propose FOCUS, a training-free and architecture-agnostic decoding strategy that
mitigates cross-image information leakage during inference. FOCUS sequentially
masks all but one image with random noise, guiding the model to focus on the
single clean image. We repeat this process across all target images to obtain
logits under partially masked contexts. These logits are aggregated and then
contrastively refined using a noise-only reference input, which suppresses the
leakage and yields more accurate outputs. FOCUS consistently improves
performance across four multi-image benchmarks and diverse LVLM families. This
demonstrates that FOCUS offers a general and practical solution for enhancing
multi-image reasoning without additional training or architectural
modifications.

</details>


### [60] [MR6D: Benchmarking 6D Pose Estimation for Mobile Robots](https://arxiv.org/abs/2508.13775)
*Anas Gouda,Shrutarv Awasthi,Christian Blesing,Lokeshwaran Manohar,Frank Hoffmann,Alice Kirchheim*

Main category: cs.CV

TL;DR: MR6D는 모바일 로봇 환경을 겨냥한 6D 포즈 추정용 실세계 데이터셋으로, 92개 장면과 16개 객체를 포함해 장거리 시점, 큰 객체, 복잡한(자기)차폐와 다양한 카메라 관점을 반영한다. 기존 6D 파이프라인과 2D 분할이 이 환경에서 성능 저하를 보임을 확인했다.


<details>
  <summary>Details</summary>
Motivation: 기존 6D 포즈 데이터셋은 주로 로봇 암이 다루는 작은 가정용 물체에 초점이 맞춰져 있어 모바일 로봇이 마주하는 장거리 관측, 큰 물체, 다양한 시점, 강한 자기차폐 등 실제 요구를 반영하지 못한다. 모바일 로봇 전용 평가 기준과 데이터가 필요하다.

Method: 산업 환경을 모사한 MR6D 데이터셋을 제작했다. 92개의 실제 장면에서 16종의 고유 객체를 다양한 정적·동적 상호작용으로 캡처했고, 거리 뷰포인트, 다양한 객체 구성과 큰 객체 크기, 복잡한(자기)차폐 패턴을 포함하도록 설계했다. 데이터는 포즈 레이블을 포함해 공개되었다.

Result: 초기 실험에서 최신 6D 포즈 추정 파이프라인들이 MR6D 환경에서 성능이 크게 떨어졌고, 특히 2D 세그멘테이션 단계가 또 다른 주요 병목으로 작용함을 보였다.

Conclusion: MR6D는 모바일 로봇의 요구를 반영한 6D 포즈 추정 연구의 기초를 제공하며, 관련 방법 개발과 평가를 촉진한다. 데이터셋은 공개되어 있다.

Abstract: Existing 6D pose estimation datasets primarily focus on small household
objects typically handled by robot arm manipulators, limiting their relevance
to mobile robotics. Mobile platforms often operate without manipulators,
interact with larger objects, and face challenges such as long-range
perception, heavy self-occlusion, and diverse camera perspectives. While recent
models generalize well to unseen objects, evaluations remain confined to
household-like settings that overlook these factors. We introduce MR6D, a
dataset designed for 6D pose estimation for mobile robots in industrial
environments. It includes 92 real-world scenes featuring 16 unique objects
across static and dynamic interactions. MR6D captures the challenges specific
to mobile platforms, including distant viewpoints, varied object
configurations, larger object sizes, and complex occlusion/self-occlusion
patterns. Initial experiments reveal that current 6D pipelines underperform in
these settings, with 2D segmentation being another hurdle. MR6D establishes a
foundation for developing and evaluating pose estimation methods tailored to
the demands of mobile robotics. The dataset is available at
https://huggingface.co/datasets/anas-gouda/mr6d.

</details>


### [61] [Shape-from-Template with Generalised Camera](https://arxiv.org/abs/2508.13791)
*Agniva Sengupta,Stefan Zachow*

Main category: cs.CV

TL;DR: 


<details>
  <summary>Details</summary>
Motivation: 

Method: 

Result: 

Conclusion: 

Abstract: This article presents a new method for non-rigidly registering a 3D shape to
2D keypoints observed by a constellation of multiple cameras. Non-rigid
registration of a 3D shape to observed 2D keypoints, i.e., Shape-from-Template
(SfT), has been widely studied using single images, but SfT with information
from multiple-cameras jointly opens new directions for extending the scope of
known use-cases such as 3D shape registration in medical imaging and
registration from hand-held cameras, to name a few. We represent such
multi-camera setup with the generalised camera model; therefore any collection
of perspective or orthographic cameras observing any deforming object can be
registered. We propose multiple approaches for such SfT: the first approach
where the corresponded keypoints lie on a direction vector from a known 3D
point in space, the second approach where the corresponded keypoints lie on a
direction vector from an unknown 3D point in space but with known orientation
w.r.t some local reference frame, and a third approach where, apart from
correspondences, the silhouette of the imaged object is also known. Together,
these form the first set of solutions to the SfT problem with generalised
cameras. The key idea behind SfT with generalised camera is the improved
reconstruction accuracy from estimating deformed shape while utilising the
additional information from the mutual constraints between multiple views of a
deformed object. The correspondence-based approaches are solved with convex
programming while the silhouette-based approach is an iterative refinement of
the results from the convex solutions. We demonstrate the accuracy of our
proposed methods on many synthetic and real data

</details>


### [62] [Mitigating Easy Option Bias in Multiple-Choice Question Answering](https://arxiv.org/abs/2508.13428)
*Hao Zhang,Chen Li,Basura Fernando*

Main category: cs.CV

TL;DR: 이 논문은 일부 다지선다형 시각질문응답(VQA) 벤치마크에서 질문 없이도 시각+옵션(V+O)만으로 정답을 맞출 수 있는 Easy-Options Bias(EOB)를 발견하고, 이를 시정하기 위해 시각적으로 그럴듯한 하드 네거티브 옵션을 자동으로 생성하는 GroundAttack 도구를 제안한다. 수정된 데이터셋에서 기존 VLM들은 V+O 설정에서 우연 수준의 정확도를 보이며, V+Q+O 설정에서도 성능이 떨어져 보다 현실적인 평가가 가능해진다.


<details>
  <summary>Details</summary>
Motivation: 현재 다지선다형 VQA 벤치마크들은 옵션들 간 시각적 관련성 불균형 때문에 모델이 질문을 무시하고 비전-옵션 유사도만으로 정답을 고르는 쉬운 지름길(EOB)을 허용한다. 이는 모델의 실제 질의응답 능력을 과대평가하므로, 더 견고하고 현실적인 평가가 필요하다.

Method: 저자들은 시각-옵션 유사도 기반의 정답 편향을 규명하기 위해 그라운딩 실험을 수행하고, 이를 해소하기 위해 시각적으로 정답과 유사한 하드 네거티브 옵션을 자동으로 생성하는 GroundAttack 툴킷을 개발했다. 이 도구를 NExT-QA와 MMStar 데이터셋에 적용해 EOB-free 어노테이션을 생성했다.

Result: EOB-free 어노테이션에서 기존 VLM들은 (V+O) 입력만으로는 우연 수준의 정확도를 보이며, (V+Q+O)에서도 포화된 높은 정확도를 내지 못해 모델의 실제 QA 능력이 더 엄밀하게 드러난다.

Conclusion: EOB는 다지선다형 VQA 벤치마크의 신뢰도를 해치며, 시각적으로 그럴듯한 하드 네거티브 생성을 통해 이를 효과적으로 완화할 수 있다. GroundAttack과 수정된 데이터셋은 VLM 평가의 현실성을 높인다.

Abstract: In this early study, we observe an Easy-Options Bias (EOB) issue in some
multiple-choice Visual Question Answering (VQA) benchmarks such as MMStar,
RealWorldQA, SEED-Bench, Next-QA, STAR benchmark and Video-MME. This bias
allows vision-language models (VLMs) to select the correct answer using only
the vision (V) and options (O) as inputs, without the need for the question
(Q). Through grounding experiments, we attribute the bias to an imbalance in
visual relevance: the correct answer typically aligns more closely with the
visual contents than the negative options in feature space, creating a shortcut
for VLMs to infer the answer via simply vision-option similarity matching. To
fix this, we introduce GroundAttack, a toolkit that automatically generates
hard negative options as visually plausible as the correct answer. We apply it
to the NExT-QA and MMStar datasets, creating new EOB-free annotations. On these
EOB-free annotations, current VLMs approach to random accuracies under (V+O)
settings, and drop to non-saturated accuracies under (V+Q+O) settings,
providing a more realistic evaluation of VLMs' QA ability. Codes and new
annotations will be released soon.

</details>


### [63] [VisionLaw: Inferring Interpretable Intrinsic Dynamics from Visual Observations via Bilevel Optimization](https://arxiv.org/abs/2508.13792)
*Jailing Lin,Shu Jiang,Qingyuan Zeng,Zhenzhong Wang,Min Jiang*

Main category: cs.CV

TL;DR: VisionLaw는 시각 관찰에서 해석 가능한 물체의 고유 동역학(constitution law)을 추론하는 이중 레벨 최적화 프레임워크다. 상위 레벨에서는 LLM을 물리 전문가로 활용해 구성 법칙을 생성·수정하고, 디커플링 메커니즘으로 탐색 복잡도를 낮춘다. 하위 레벨에서는 시각 시뮬레이션을 이용해 생성된 법칙의 일관성을 평가해 상위 레벨 진화를 안내한다. 합성 및 실제 데이터에서 기존 방법보다 우수한 성능과 강한 일반화 능력을 보였다.


<details>
  <summary>Details</summary>
Motivation: 시각 관찰로부터 물체의 고유 동역학을 추론해 물리적으로 그럴듯한 상호작용 시뮬레이션을 가능케 하는 것이 목표다. 기존 방법들은 수작업으로 정의한 구성(prior)에 의존해 일반화가 어렵거나, 뉴럴 네트워크 기반 모델이 해석 가능성이 낮고 일반화에 취약하다는 한계를 가진다.

Method: VisionLaw라는 bilevel 최적화 프레임워크를 제안한다. 상위 레벨: LLM을 물리 전문가로 프롬프트해 구성 법칙을 생성·수정하는 LLM-driven decoupled constitutive evolution 전략을 사용한다. 디커플링 메커니즘으로 LLM의 탐색 복잡도를 줄인다. 하위 레벨: vision-guided constitutive evaluation로 시각 시뮬레이션을 통해 생성된 법칙이 실제 동역학과 일치하는지 평가하고 상위 레벨에 피드백을 준다. 두 레벨이 상호작용하며 해석 가능한 수식 형태의 내재 동역학을 찾는다.

Result: 합성 및 실제 데이터셋 실험에서 VisionLaw는 해석 가능한 내재 동역학을 시각 관찰로부터 효과적으로 추론했다. 기존 최첨단 방법들보다 유의하게 더 높은 성능을 보였고, 새로운 시나리오에서의 대화형 시뮬레이션에도 강한 일반화 능력을 나타냈다.

Conclusion: LLM을 활용한 이중 레벨 최적화(구성 법칙 생성·평가) 접근은 수작업 prior나 순수 NN 기반 모델의 한계를 극복해, 시각 관찰만으로도 해석 가능하고 일반화 가능한 내재 동역학을 얻을 수 있음을 보여준다.

Abstract: The intrinsic dynamics of an object governs its physical behavior in the real
world, playing a critical role in enabling physically plausible interactive
simulation with 3D assets. Existing methods have attempted to infer the
intrinsic dynamics of objects from visual observations, but generally face two
major challenges: one line of work relies on manually defined constitutive
priors, making it difficult to generalize to complex scenarios; the other
models intrinsic dynamics using neural networks, resulting in limited
interpretability and poor generalization. To address these challenges, we
propose VisionLaw, a bilevel optimization framework that infers interpretable
expressions of intrinsic dynamics from visual observations. At the upper level,
we introduce an LLMs-driven decoupled constitutive evolution strategy, where
LLMs are prompted as a knowledgeable physics expert to generate and revise
constitutive laws, with a built-in decoupling mechanism that substantially
reduces the search complexity of LLMs. At the lower level, we introduce a
vision-guided constitutive evaluation mechanism, which utilizes visual
simulation to evaluate the consistency between the generated constitutive law
and the underlying intrinsic dynamics, thereby guiding the upper-level
evolution. Experiments on both synthetic and real-world datasets demonstrate
that VisionLaw can effectively infer interpretable intrinsic dynamics from
visual observations. It significantly outperforms existing state-of-the-art
methods and exhibits strong generalization for interactive simulation in novel
scenarios.

</details>


### [64] [A Fully Transformer Based Multimodal Framework for Explainable Cancer Image Segmentation Using Radiology Reports](https://arxiv.org/abs/2508.13796)
*Enobong Adahada,Isabel Sassoon,Kate Hone,Yongmin Li*

Main category: cs.CV

TL;DR: 


<details>
  <summary>Details</summary>
Motivation: 

Method: 

Result: 

Conclusion: 

Abstract: We introduce Med-CTX, a fully transformer based multimodal framework for
explainable breast cancer ultrasound segmentation. We integrate clinical
radiology reports to boost both performance and interpretability. Med-CTX
achieves exact lesion delineation by using a dual-branch visual encoder that
combines ViT and Swin transformers, as well as uncertainty aware fusion.
Clinical language structured with BI-RADS semantics is encoded by
BioClinicalBERT and combined with visual features utilising cross-modal
attention, allowing the model to provide clinically grounded, model generated
explanations. Our methodology generates segmentation masks, uncertainty maps,
and diagnostic rationales all at once, increasing confidence and transparency
in computer assisted diagnosis. On the BUS-BRA dataset, Med-CTX achieves a Dice
score of 99% and an IoU of 95%, beating existing baselines U-Net, ViT, and
Swin. Clinical text plays a key role in segmentation accuracy and explanation
quality, as evidenced by ablation studies that show a -5.4% decline in Dice
score and -31% in CIDEr. Med-CTX achieves good multimodal alignment (CLIP
score: 85%) and increased confi dence calibration (ECE: 3.2%), setting a new
bar for trustworthy, multimodal medical architecture.

</details>


### [65] [Timestep-Compressed Attack on Spiking Neural Networks through Timestep-Level Backpropagation](https://arxiv.org/abs/2508.13812)
*Donghwa Kang,Doohyun Kim,Sang-Ki Ko,Jinkyu Lee,Hyeongboo Baek,Brent ByungHoon Kang*

Main category: cs.CV

TL;DR: 


<details>
  <summary>Details</summary>
Motivation: 

Method: 

Result: 

Conclusion: 

Abstract: State-of-the-art (SOTA) gradient-based adversarial attacks on spiking neural
networks (SNNs), which largely rely on extending FGSM and PGD frameworks, face
a critical limitation: substantial attack latency from multi-timestep
processing, rendering them infeasible for practical real-time applications.
This inefficiency stems from their design as direct extensions of ANN
paradigms, which fail to exploit key SNN properties. In this paper, we propose
the timestep-compressed attack (TCA), a novel framework that significantly
reduces attack latency. TCA introduces two components founded on key insights
into SNN behavior. First, timestep-level backpropagation (TLBP) is based on our
finding that global temporal information in backpropagation to generate
perturbations is not critical for an attack's success, enabling per-timestep
evaluation for early stopping. Second, adversarial membrane potential reuse
(A-MPR) is motivated by the observation that initial timesteps are
inefficiently spent accumulating membrane potential, a warm-up phase that can
be pre-calculated and reused. Our experiments on VGG-11 and ResNet-17 with the
CIFAR-10/100 and CIFAR10-DVS datasets show that TCA significantly reduces the
required attack latency by up to 56.6% and 57.1% compared to SOTA methods in
white-box and black-box settings, respectively, while maintaining a comparable
attack success rate.

</details>


### [66] [Unsupervised Urban Tree Biodiversity Mapping from Street-Level Imagery Using Spatially-Aware Visual Clustering](https://arxiv.org/abs/2508.13814)
*Diaa Addeen Abuhani,Marco Seccaroni,Martina Mazzarello,Imran Zualkernan,Fabio Duarte,Carlo Ratti*

Main category: cs.CV

TL;DR: 감시 데이터 없이 거리 사진의 시각적 임베딩과 식재의 공간적 패턴을 비지도 클러스터링으로 통합해 도시 수목의 속 수준(biodiversity)을 추정하는 방법을 제시. 8개 북미 도시에서 샤논·심슨 지수와 공간적 자기상관을 잘 복원함.


<details>
  <summary>Details</summary>
Motivation: 대부분 지방자치단체는 도시 수관(나무) 관행과 종 분포에 대한 상세한 현장조사 자료가 부족하고, 현장조사는 비용과 시간이 많이 듦. 지도 학습 기반 AI는 라벨이 필요하고 지역간 일반화에 실패하기 쉬움. 라벨 없이 확장 가능하고 저비용의 모니터링 방법 필요.

Method: 거리 수준(street-level) 이미지에서 추출한 시각적 임베딩을 사용하고, 식재의 공간적 패턴 정보를 결합한 비지도 클러스터링 프레임워크를 개발. 클러스터를 통해 속(Genus) 수준의 그룹화를 유도하고, 이를 기반으로 샤논·심슨 다양성 지수와 공간적 자기상관을 추정.

Result: 8개 북미 도시 적용에서 속 수준 다양성 패턴을 높은 충실도로 재현. 샤논·심슨 지수의 지구간 분포가 실제 관측치와의 Wasserstein 거리 측면에서 낮은 차이를 보였고, 공간적 자기상관도 보존됨.

Conclusion: 라벨없는 스케일러블하고 세분화된 접근으로, 상세한 재고가 없는 도시에서도 생물다양성 지도를 작성하고 저비용·지속적 모니터링을 가능하게 하여 형평성 있는 녹지 접근성과 도시 생태계 적응관리 지원 가능성 제시.

Abstract: Urban tree biodiversity is critical for climate resilience, ecological
stability, and livability in cities, yet most municipalities lack detailed
knowledge of their canopies. Field-based inventories provide reliable estimates
of Shannon and Simpson diversity but are costly and time-consuming, while
supervised AI methods require labeled data that often fail to generalize across
regions. We introduce an unsupervised clustering framework that integrates
visual embeddings from street-level imagery with spatial planting patterns to
estimate biodiversity without labels. Applied to eight North American cities,
the method recovers genus-level diversity patterns with high fidelity,
achieving low Wasserstein distances to ground truth for Shannon and Simpson
indices and preserving spatial autocorrelation. This scalable, fine-grained
approach enables biodiversity mapping in cities lacking detailed inventories
and offers a pathway for continuous, low-cost monitoring to support equitable
access to greenery and adaptive management of urban ecosystems.

</details>


### [67] [Structured Prompting and Multi-Agent Knowledge Distillation for Traffic Video Interpretation and Risk Inference](https://arxiv.org/abs/2508.13439)
*Yunxiang Yang,Ningning Xu,Jidong J. Yang*

Main category: cs.CV

TL;DR: 이 논문은 구조화된 체인-오브-생각(CoT) 기반의 프롬프트와 지식 증류를 결합해, 대형 VLM(GPT-4o, o3-mini)으로부터 고품질의 교통 장면 주석과 위험 평가를 자동 생성한다. 이를 학생 VLM(3B 규모, VISTA)으로 지도학습하여, 경량화된 모델이 저해상도 교통 비디오에서 의미론적이고 위험 인식 캡션을 생성할 수 있도록 한다. 실험에서 VISTA는 여러 캡션 지표(BLEU-4, METEOR, ROUGE-L, CIDEr)에서 교사 모델 대비 우수한 성능을 보이며 엣지 디바이스 실시간 모니터링에 적합하다.


<details>
  <summary>Details</summary>
Motivation: 기존 방법은 확장성과 일반화 문제로 실제 교통 환경의 복잡한 상황을 처리하기 어렵다. 대형 VLM의 추론 능력을 경량 모델로 이전해 엣지 배포 가능하면서도 위험 인식이 가능한 교통 장면 이해 모델을 만들고자 함.

Method: GPT-4o와 o3-mini의 다중 에이전트를 구조화된 CoT 전략으로 오케스트레이션하여 다각적 설명과 위험 평가를 생성한다. 생성된 출력은 지식이 풍부한 의사-주석(pseudo-annotations)으로 사용되어 3B 규모의 학생 VLM(VISTA)을 지도-파인튜닝한다. 핵심은 구조화된 프롬프트, 체인-오브-생각 흐름, 그리고 지식 증류로 경량 모델에 복잡한 추론 능력을 전달하는 것이다.

Result: VISTA는 BLEU-4, METEOR, ROUGE-L, CIDEr 등 표준 캡션 지표에서 교사 모델을 상회하거나 근접한 성능을 달성했다. 또한 저해상도 교통 비디오에 대해 의미론적으로 충실하고 위험 인식이 가능한 캡션을 생성하며, 파라미터가 훨씬 적음에도 강한 추론능력을 보였다.

Conclusion: 구조화된 멀티-에이전트 감독과 지식 증류는 경량 VLM이 복잡한 장면 이해와 위험 추론 능력을 획득하도록 하는 데 효과적이다. VISTA의 소형화된 아키텍처는 엣지 디바이스에서의 실시간 배포를 가능하게 하여 ITS와 자율주행 시스템에 실용적 이점을 제공한다.

Abstract: Comprehensive highway scene understanding and robust traffic risk inference
are vital for advancing Intelligent Transportation Systems (ITS) and autonomous
driving. Traditional approaches often struggle with scalability and
generalization, particularly under the complex and dynamic conditions of
real-world environments. To address these challenges, we introduce a novel
structured prompting and knowledge distillation framework that enables
automatic generation of high-quality traffic scene annotations and contextual
risk assessments. Our framework orchestrates two large Vision-Language Models
(VLMs): GPT-4o and o3-mini, using a structured Chain-of-Thought (CoT) strategy
to produce rich, multi-perspective outputs. These outputs serve as
knowledge-enriched pseudo-annotations for supervised fine-tuning of a much
smaller student VLM. The resulting compact 3B-scale model, named VISTA (Vision
for Intelligent Scene and Traffic Analysis), is capable of understanding
low-resolution traffic videos and generating semantically faithful, risk-aware
captions. Despite its significantly reduced parameter count, VISTA achieves
strong performance across established captioning metrics (BLEU-4, METEOR,
ROUGE-L, and CIDEr) when benchmarked against its teacher models. This
demonstrates that effective knowledge distillation and structured multi-agent
supervision can empower lightweight VLMs to capture complex reasoning
capabilities. The compact architecture of VISTA facilitates efficient
deployment on edge devices, enabling real-time risk monitoring without
requiring extensive infrastructure upgrades.

</details>


### [68] [Self-Aware Adaptive Alignment: Enabling Accurate Perception for Intelligent Transportation Systems](https://arxiv.org/abs/2508.13823)
*Tong Xiang,Hongxia Zhao,Fenghua Zhu,Yuanyuan Chen,Yisheng Lv*

Main category: cs.CV

TL;DR: SA3는 주의(attention) 기반 정렬 모듈과 인스턴스-이미지 수준의 적응 정렬을 결합한 교차 도메인 물체 검출 기법으로, 채널 중요도 재가중치와 RPN 연계를 통해 지역-전역 적응 정렬을 수행하여 교차 도메인 성능을 크게 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 지능형 교통(ITS)에서 도메인 간 차이(예: 조명, 배경, 센서 차이 등)로 인해 학습한 모델이 다른 도메인에서 성능 저하를 보이는 문제를 해결하기 위함이다. 기존 방법들은 지역과 전역 특성 정렬이나 인스턴스 수준 적응을 효과적으로 결합하지 못하는 한계가 있다.

Method: 소스/타깃 도메인에서 학습되는 주의 기반 정렬 모듈로 이미지 수준의 특징 정렬을 유도하고, 채널 중요도를 재가중치한 특징을 RPN에 입력해 중요한 영역 특징을 획득한다. 추가로 타깃 도메인에 특화된 인스턴스-이미지 수준 정렬 모듈을 도입하여 도메인 격차를 적응적으로 완화한다.

Result: 여러 교차 도메인 물체 검출 벤치마크에서 광범위한 실험을 수행한 결과, 제안된 SA3가 기존 최첨단 기법들보다 우수한 성능을 달성했다.

Conclusion: SA3는 지역-전역 및 인스턴스 수준 정렬을 통합한 실용적이고 효과적인 교차 도메인 적응 방법으로, 지능형 교통 분야의 교차 도메인 물체 검출 문제에 대해 향상된 일반화 성능을 제공한다.

Abstract: Achieving top-notch performance in Intelligent Transportation detection is a
critical research area. However, many challenges still need to be addressed
when it comes to detecting in a cross-domain scenario. In this paper, we
propose a Self-Aware Adaptive Alignment (SA3), by leveraging an efficient
alignment mechanism and recognition strategy. Our proposed method employs a
specified attention-based alignment module trained on source and target domain
datasets to guide the image-level features alignment process, enabling the
local-global adaptive alignment between the source domain and target domain.
Features from both domains, whose channel importance is re-weighted, are fed
into the region proposal network, which facilitates the acquisition of salient
region features. Also, we introduce an instance-to-image level alignment module
specific to the target domain to adaptively mitigate the domain gap. To
evaluate the proposed method, extensive experiments have been conducted on
popular cross-domain object detection benchmarks. Experimental results show
that SA3 achieves superior results to the previous state-of-the-art methods.

</details>


### [69] [STER-VLM: Spatio-Temporal With Enhanced Reference Vision-Language Models](https://arxiv.org/abs/2508.13470)
*Tinh-Anh Nguyen-Nhu,Triet Dao Hoang Minh,Dat To-Thanh,Phuc Le-Gia,Tuan Vo-Lan,Tien-Huy Nguyen*

Main category: cs.CV

TL;DR: STER-VLM은 교통 분석을 위한 연산 효율적인 비전-언어 모델 프레임워크로, 공간·시간 정보를 분리해 처리하는 캡션 분해, 베스트뷰 필터를 포함한 프레임 선택, 레퍼런스 기반 동작 이해, 그리고 시각/텍스트 프롬프트 기법을 결합해 의미적 풍부성과 장면 해석을 크게 향상시킨다. WTS·BDD 데이터셋에서 성능 향상을 보였고, AI City Challenge 2025 Track 2에서 테스트 점수 55.655를 기록했다.


<details>
  <summary>Details</summary>
Motivation: 기존 VLM 기반 교통 분석은 계산 비용이 크고, 미세한 시공간(spatio-temporal) 정보(예: 움직임의 세부, 동적 문맥)를 충분히 포착하지 못한다는 한계가 있다. 따라서 저자들은 연산 효율을 유지하면서 시공간 이해를 개선할 방법이 필요하다고 보았다.

Method: (1) 캡션 분해: 공간 정보와 시간 정보를 별도로 처리해 각각에 특화된 설명 생성. (2) 시간 프레임 선택 + 베스트뷰 필터링: 핵심 시점만 골라 충분한 시간적 정보를 확보하고 최적 시야를 선택. (3) 레퍼런스 기반 이해: 기준 이미지/프레임을 활용해 미세한 동작과 동적 문맥을 포착. (4) 선별된 시각·텍스트 프롬프트 기법을 적용해 VLM 응답의 품질을 높임. 전반적으로 연산 효율성을 고려한 설계.

Result: WTS와 BDD 데이터셋 실험에서 의미적 풍부성과 교통 장면 해석 능력이 크게 개선됨. 실제 대회 성과로 AI City Challenge 2025 Track 2에서 테스트 점수 55.655를 달성해 실용성을 입증.

Conclusion: STER-VLM은 연산 자원이 제한된 환경에서도 정밀한 시공간 교통 분석을 가능하게 하는 실용적 접근이다. 실세계 적용 가능성이 높으며, 향후 멀티카메라 확장이나 실시간 처리 등으로 발전시킬 여지가 있다.

Abstract: Vision-language models (VLMs) have emerged as powerful tools for enabling
automated traffic analysis; however, current approaches often demand
substantial computational resources and struggle with fine-grained
spatio-temporal understanding. This paper introduces STER-VLM, a
computationally efficient framework that enhances VLM performance through (1)
caption decomposition to tackle spatial and temporal information separately,
(2) temporal frame selection with best-view filtering for sufficient temporal
information, and (3) reference-driven understanding for capturing fine-grained
motion and dynamic context and (4) curated visual/textual prompt techniques.
Experimental results on the WTS \cite{kong2024wts} and BDD \cite{BDD} datasets
demonstrate substantial gains in semantic richness and traffic scene
interpretation. Our framework is validated through a decent test score of
55.655 in the AI City Challenge 2025 Track 2, showing its effectiveness in
advancing resource-efficient and accurate traffic analysis for real-world
applications.

</details>


### [70] [SAGA: Learning Signal-Aligned Distributions for Improved Text-to-Image Generation](https://arxiv.org/abs/2508.13866)
*Paul Grimal,Michaël Soumm,Hervé Le Borgne,Olivier Ferret,Akihiro Sugimoto*

Main category: cs.CV

TL;DR: 제안한 방법은 텍스트-이미지 모델이 프롬프트에 정확히 맞는 이미지를 생성하도록, 목표 프롬프트에 조건화된 높은 성공률 분포를 학습한다. 디노이징 과정에서 신호 성분을 명시적으로 모델링해 미세한 제어와 과최적화·OOD 아티팩트 완화를 제공하며, 학습 불필요(훈련-프리)하고 기존 확산 및 플로우 매칭 아키텍처와 호환된다. 바운딩 박스 같은 추가 조건도 지원하며, 실험에서 SOTA를 능가한다.


<details>
  <summary>Details</summary>
Motivation: 최신 텍스트-이미지 모델은 시각적으로 뛰어나지만 프롬프트 정렬성이 떨어져 중요한 요소 누락이나 서로 다른 개념의 의도치 않은 혼합이 발생한다. 이러한 문제를 해결해 프롬프트에 충실한 이미지 생성을 보장할 필요가 있다.

Method: 목표 프롬프트에 조건화된 '높은 성공률 분포'를 학습하며, 디노이징 과정에서 신호(signal) 성분을 명시적으로 모델링한다. 이를 통해 미세 제어가 가능해 과최적화(over-optimization)와 분포 밖(OOD) 아티팩트 발생을 억제한다. 추가로 학습이 필요 없는(훈련-프리) 프레임워크로 설계되어 기존의 확산(diffusion) 및 플로우 매칭(flow matching) 아키텍처에 바로 통합되며, 바운딩 박스 등 공간적 조건을 지원한다.

Result: 광범위한 실험에서 제안 기법이 기존 최첨단 방법들을 능가하는 성능을 보였다. 코드가 공개되어 있어 재현 및 확장이 가능하다(https://github.com/grimalPaul/gsn-factory).

Conclusion: 훈련 없이 기존 모델에 적용할 수 있는 신호-명시적(conditioned signal) 분포 학습 기법으로, 프롬프트 정렬성 및 공간적 제어를 개선하고 과최적화·OOD 아티팩트를 줄인다. 실험적으로 SOTA 성능을 달성해 실용성이 높다.

Abstract: State-of-the-art text-to-image models produce visually impressive results but
often struggle with precise alignment to text prompts, leading to missing
critical elements or unintended blending of distinct concepts. We propose a
novel approach that learns a high-success-rate distribution conditioned on a
target prompt, ensuring that generated images faithfully reflect the
corresponding prompts. Our method explicitly models the signal component during
the denoising process, offering fine-grained control that mitigates
over-optimization and out-of-distribution artifacts. Moreover, our framework is
training-free and seamlessly integrates with both existing diffusion and flow
matching architectures. It also supports additional conditioning modalities --
such as bounding boxes -- for enhanced spatial alignment. Extensive experiments
demonstrate that our approach outperforms current state-of-the-art methods. The
code is available at https://github.com/grimalPaul/gsn-factory.

</details>


### [71] [CORENet: Cross-Modal 4D Radar Denoising Network with LiDAR Supervision for Autonomous Driving](https://arxiv.org/abs/2508.13485)
*Fuyang Liu,Jilin Mei,Fangyuan Mao,Chen Min,Yan Xing,Yu Hu*

Main category: cs.CV

TL;DR: CORENet은 학습 시 LiDAR를 이용한 교차-모달 소거(supervision)로 4D 레이더의 잡음 패턴을 학습해 레이더 포인트클라우드의 노이즈를 제거하고, 학습 후에는 레이더 단독으로 동작하는 플러그앤플레이형 voxel 기반 객체검출용 denoising 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 4D 레이더는 악천후에서도 강인하고 풍부한 공간 정보를 제공하지만 포인트클라우드가 매우 희소하고 잡음이 심해 기존 검출 성능이 저하된다. LiDAR의 깨끗한 신호를 활용해 레이더의 노이즈를 효과적으로 제거하고자 함.

Method: CORENet은 LiDAR로부터 얻은 신호를 감독(supervision)으로 사용해 레이더의 잡음 패턴을 식별하고 판별적 특징을 추출하는 교차-모달 denoising 네트워크를 제안한다. 구조는 voxel 기반 검출 파이프라인에 수정 없이 플러그앤플레이로 삽입 가능하며, 학습 시에만 LiDAR를 사용하고 추론 시에는 레이더 전용으로 동작한다.

Result: 잡음 수준이 높은 Dual-Radar 데이터셋에서 광범위한 실험을 통해 검출 강인성이 향상됨을 보였고, 기존 주류 접근법들보다 우수한 성능을 달성했다.

Conclusion: CORENet은 LiDAR 감독을 통해 4D 레이더 포인트의 노이즈를 효과적으로 완화하여 voxel 기반 객체검출의 성능을 향상시키며, 실제 배치에서는 레이더 전용 추론을 유지해 실용성이 높다.

Abstract: 4D radar-based object detection has garnered great attention for its
robustness in adverse weather conditions and capacity to deliver rich spatial
information across diverse driving scenarios. Nevertheless, the sparse and
noisy nature of 4D radar point clouds poses substantial challenges for
effective perception. To address the limitation, we present CORENet, a novel
cross-modal denoising framework that leverages LiDAR supervision to identify
noise patterns and extract discriminative features from raw 4D radar data.
Designed as a plug-and-play architecture, our solution enables seamless
integration into voxel-based detection frameworks without modifying existing
pipelines. Notably, the proposed method only utilizes LiDAR data for
cross-modal supervision during training while maintaining full radar-only
operation during inference. Extensive evaluation on the challenging Dual-Radar
dataset, which is characterized by elevated noise level, demonstrates the
effectiveness of our framework in enhancing detection robustness. Comprehensive
experiments validate that CORENet achieves superior performance compared to
existing mainstream approaches.

</details>


### [72] [RED.AI Id-Pattern: First Results of Stone Deterioration Patterns with Multi-Agent Systems](https://arxiv.org/abs/2508.13872)
*Daniele Corradetti,José Delgado Rodrigues*

Main category: cs.CV

TL;DR: Id-Pattern 시스템은 석재 열화 패턴 진단을 위해 전문가 역할을 하는 다중 에이전트 AI(암석학자, 병리학자, 환경전문가, 보존수복가, 진단조정관)를 구성한 인지 아키텍처를 제안한다. 28개 어려운 이미지로 평가한 결과, 기반 모델 대비 모든 지표에서 크게 향상되었다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 전문가 직접 관찰 방식은 정확하지만 시간·비용이 많이 든다. 전문가 협업을 시뮬레이션하고 시각적 증거로부터 석재 병리를 자동 진단해 비용과 시간을 줄이고 확장성을 확보하려는 목적.

Method: 인지 아키텍처로 여러 특화 AI 에이전트를 팀으로 구성(5종의 역할). 각 에이전트가 전문적 관점을 제공하고 진단조정관이 종합해 최종 진단을 도출하는 협업 프로세스를 설계. 성능 평가는 다중 열화 패턴을 포함한 28개 어려운 이미지 집합에서 수행.

Result: 제안한 다중 에이전트 시스템은 선택한 28개 이미지에 대해 기반(파운데이셔널) 모델과 비교하여 모든 성능 지표에서 큰 향상을 보였다. (구체적 수치·지표는 초록에 없음)

Conclusion: 전문가 역할의 에이전트 협업을 통한 자동 진단 접근이 석재 열화 판별에 유망함을 보였다. 다만 데이터 수·평가 세부항목·실제 현장 적용성 검증 등 추가 연구가 필요하다.

Abstract: The Id-Pattern system within the RED.AI project (Reabilita\c{c}\~ao
Estrutural Digital atrav\'es da AI) consists of an agentic system designed to
assist in the identification of stone deterioration patterns. Traditional
methodologies, based on direct observation by expert teams, are accurate but
costly in terms of time and resources. The system developed here introduces and
evaluates a multi-agent artificial intelligence (AI) system, designed to
simulate collaboration between experts and automate the diagnosis of stone
pathologies from visual evidence. The approach is based on a cognitive
architecture that orchestrates a team of specialized AI agents which, in this
specific case, are limited to five: a lithologist, a pathologist, an
environmental expert, a conservator-restorer, and a diagnostic coordinator. To
evaluate the system we selected 28 difficult images involving multiple
deterioration patterns. Our first results showed a huge boost on all metrics of
our system compared to the foundational model.

</details>


### [73] [RICO: Two Realistic Benchmarks and an In-Depth Analysis for Incremental Learning in Object Detection](https://arxiv.org/abs/2508.13878)
*Matthias Neuwirth-Trapp,Maarten Bieshaar,Danda Pani Paudel,Luc Van Gool*

Main category: cs.CV

TL;DR: Incremental Learning(IL)에서 현실적 성능을 평가하기 위해 도메인 변이 및 클래스 확장을 포함한 두 개의 현실적 벤치마크 RICO(D-RICO, EC-RICO)를 제안한다. 14개 데이터셋 기반으로 구성되며 기존 방법들이 실제 환경에서 적응성과 보존 능력 모두 낮음을 보이고, 소량의 리플레이 데이터가 많은 방법보다 낫지만 각각의 개별 학습에는 미치지 못한다고 결론낸다.


<details>
  <summary>Details</summary>
Motivation: 기존 IL 평가가 합성 또는 단순화된 벤치마크에 의존해 실제 환경에서의 성능을 왜곡한다. 현실 세계의 도메인 이동, 센서·조명·레이블링 차이, 그리고 클래스 확장 문제를 반영하는 벤치마크가 필요하다.

Method: 14개의 다양한 실제 및 합성 데이터셋을 조합해 두 가지 벤치마크를 구성: 도메인이 고정된 상태에서 도메인 이동을 다루는 D-RICO와 단계별로 도메인·클래스가 추가되는 EC-RICO. 다양한 조건(날씨, 시간, 센서, 시점, 라벨링 정책 등)을 포함하며 기존 IL 기법들을 평가하고 소량 리플레이 및 개별 학습과 비교 실험을 수행.

Result: 대부분의 기존 IL 방법들이 적응성 및 기억 보존에서 낮은 성능을 보였고, 소량의 과거 데이터 리플레이가 모든 기존 기법을 능가했으나 각 단계별로 개별적으로 학습한 결과(상호간섭 없는 학습)에는 미치지 못했다.

Conclusion: 현실적 상황에서 IL의 한계가 명확하며, 약한 교사 모델(증류), 단일 모델 구조의 한계, 부족한 가소성이 문제로 보인다. 향후 연구는 더 강한 증류, 모델 구조 개선, 그리고 가소성 향상에 초점을 맞춰야 함.

Abstract: Incremental Learning (IL) trains models sequentially on new data without full
retraining, offering privacy, efficiency, and scalability. IL must balance
adaptability to new data with retention of old knowledge. However, evaluations
often rely on synthetic, simplified benchmarks, obscuring real-world IL
performance. To address this, we introduce two Realistic Incremental Object
Detection Benchmarks (RICO): Domain RICO (D-RICO) features domain shifts with a
fixed class set, and Expanding-Classes RICO (EC-RICO) integrates new domains
and classes per IL step. Built from 14 diverse datasets covering real and
synthetic domains, varying conditions (e.g., weather, time of day), camera
sensors, perspectives, and labeling policies, both benchmarks capture
challenges absent in existing evaluations. Our experiments show that all IL
methods underperform in adaptability and retention, while replaying a small
amount of previous data already outperforms all methods. However, individual
training on the data remains superior. We heuristically attribute this gap to
weak teachers in distillation, single models' inability to manage diverse
tasks, and insufficient plasticity. Our code will be made publicly available.

</details>


### [74] [In-hoc Concept Representations to Regularise Deep Learning in Medical Imaging](https://arxiv.org/abs/2508.13880)
*Valentina Corbetta,Floris Six Dijkstra,Regina Beets-Tan,Hoel Kervadec,Kristoffer Wickstrøm,Wilson Silva*

Main category: cs.CV

TL;DR: LCRReg는 잠재 개념 표현(LCRs)을 활용해 의료 영상 모델이 스푸리어스 상관관계 대신 임상적으로 의미 있는 특징에 의존하도록 유도하는 정규화 기법이다. 메인 훈련세트에 개념 라벨이 없어도 작은 보조 데이터셋을 사용해 분리된 고품질 개념 예시를 합성하고, CNN의 활성화를 개념 관련 잠재 하위공간에 가깝게 유도한다. 합성 토이 데이터와 당뇨망막병증 분류에서 스푸리어스 내성 및 OOD 일반화 성능을 향상시켰다. 코드 공개.


<details>
  <summary>Details</summary>
Motivation: 의료 영상에서 딥러닝 모델은 분포 이동 시 일반화가 취약하고 스푸리어스 상관관계에 의존하는 경향이 있어 임상적으로 신뢰할 수 있는 특징 학습을 유도할 필요가 있다.

Method: 소규모 보조 데이터로부터 개념 활성화 벡터(CAV) 등 잠재 개념 표현을 추출하고, 이를 이용해 CNN의 내부 활성화가 각 개념의 잠재 하위공간을 따르도록 하는 정규화 항을 도입한다. 메인 훈련셋에는 개념 라벨이 필요 없으며, 아키텍처에 무관하게 적용 가능하다.

Result: 합성 토이 데이터에서 스푸리어스 상관 제거에 크게 기여했고 멀티개념·다중클래스 상황에서도 효과를 보였다. 당뇨망막병증 이진 분류에서 합성 스푸리어스와 OOD 상황 모두에서 성능 향상을 달성했다. 멀티태스크, 선형 프로빙, 사후 개념모델 등 기존 방법 대비 경량·아키텍처 비종속적 장점을 보였다.

Conclusion: LCRReg는 메인 데이터에 개념 레이블 없이도 소규모 보조데이터로부터 추출한 잠재 개념 표현을 활용해 모델을 더 임상적으로 의미 있는 특징에 집중시키고, 스푸리어스에 대한 강인성과 OOD 일반화를 향상시키는 실용적이고 경량화된 정규화 방법이다.

Abstract: Deep learning models in medical imaging often achieve strong in-distribution
performance but struggle to generalise under distribution shifts, frequently
relying on spurious correlations instead of clinically meaningful features. We
introduce LCRReg, a novel regularisation approach that leverages Latent Concept
Representations (LCRs) (e.g., Concept Activation Vectors (CAVs)) to guide
models toward semantically grounded representations. LCRReg requires no concept
labels in the main training set and instead uses a small auxiliary dataset to
synthesise high-quality, disentangled concept examples. We extract LCRs for
predefined relevant features, and incorporate a regularisation term that guides
a Convolutional Neural Network (CNN) to activate within latent subspaces
associated with those concepts. We evaluate LCRReg across synthetic and
real-world medical tasks. On a controlled toy dataset, it significantly
improves robustness to injected spurious correlations and remains effective
even in multi-concept and multiclass settings. On the diabetic retinopathy
binary classification task, LCRReg enhances performance under both synthetic
spurious perturbations and out-of-distribution (OOD) generalisation. Compared
to baselines, including multitask learning, linear probing, and post-hoc
concept-based models, LCRReg offers a lightweight, architecture-agnostic
strategy for improving model robustness without requiring dense concept
supervision. Code is available at the following link:
https://github.com/Trustworthy-AI-UU-NKI/lcr\_regularization

</details>


### [75] [Forecasting Smog Events Using ConvLSTM: A Spatio-Temporal Approach for Aerosol Index Prediction in South Asia](https://arxiv.org/abs/2508.13891)
*Taimur Khan*

Main category: cs.CV

TL;DR: 이 논문은 Sentinel-5P의 UV Aerosol Index(340-380 nm)를 입력으로 사용해 ConvLSTM으로 남아시아 스모그(인도-갠지스 평원) 발생을 5일 간격으로 예측한 연구이다. 2019–2023 데이터를 사용하며 MSE≈0.0018, loss≈0.3995, SSIM≈0.74의 성능을 보고한다.


<details>
  <summary>Details</summary>
Motivation: 남아시아 겨울철 반복적 스모그(높은 입자상 물질, 가시성 저하, 사회경제적 영향)를 실시간·지역단위로 예측하는 시스템이 부족하며, 에어로졸 지수는 스모그 형성과 AQI 계산에 핵심적이라 예측에 유용하다.

Method: Sentinel-5P 공기 구성 성분(2019–2023) 중 UV Aerosol Index(340–380 nm)를 예측 변수로 선택하고, 시공간 상관을 포착할 수 있는 ConvLSTM 신경망을 사용해 5일 후의 에어로졸 지수를 예측함.

Result: 모델은 5일 간격 예측에서 MSE≈0.0018, loss≈0.3995, SSIM≈0.74 성능을 보였으며, ConvLSTM이 이전 모델보다 시공간적 패턴을 더 잘 캡처함을 시사한다.

Conclusion: 제안한 접근은 에어로졸 지수 예측에 효과적이나, 기상·배출원 데이터 통합, 아키텍처 개선 등을 통해 성능 향상이 가능하다.

Abstract: The South Asian Smog refers to the recurring annual air pollution events
marked by high contaminant levels, reduced visibility, and significant
socio-economic impacts, primarily affecting the Indo-Gangetic Plains (IGP) from
November to February. Over the past decade, increased air pollution sources
such as crop residue burning, motor vehicles, and changing weather patterns
have intensified these smog events. However, real-time forecasting systems for
increased particulate matter concentrations are still not established at
regional scale. The Aerosol Index, closely tied to smog formation and a key
component in calculating the Air Quality Index (AQI), reflects particulate
matter concentrations. This study forecasts aerosol events using Sentinel-5P
air constituent data (2019-2023) and a Convolutional Long-Short Term Memory
(ConvLSTM) neural network, which captures spatial and temporal correlations
more effectively than previous models. Using the Ultraviolet (UV) Aerosol Index
at 340-380 nm as the predictor, results show the Aerosol Index can be
forecasted at five-day intervals with a Mean Squared Error of ~0.0018, loss of
~0.3995, and Structural Similarity Index of ~0.74. While effective, the model
can be improved by integrating additional data and refining its architecture.

</details>


### [76] [Calibrating Biased Distribution in VFM-derived Latent Space via Cross-Domain Geometric Consistency](https://arxiv.org/abs/2508.13518)
*Yanbiao Ma,Wei Dai,Bowei Liu,Jiayi Chen,Wenke Huang,Guancheng Wan,Zhiwu Lu,Junchi Yan*

Main category: cs.CV

TL;DR: 비전 파운데이션 모델(CLP, DINOv2 등)에서 추출한 특징 공간의 기하학적 분포 형태가 도메인 및 데이터셋 간에 잘 전이된다는 사실을 이용해, 이 기하학적 지식을 기반으로 데이터 분포를 보정하여 연합학습과 롱테일 인식에서 성능을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 실제 관측된 학습 샘플과 근본적 진짜 분포 사이의 차이(샘플링 편향, 노이즈 등)가 학습 성능을 저해한다. 파운데이션 모델의 특징이형 분포의 기하학적 구조가 도메인 간 전이 가능하다는 점을 활용하면 이 격차를 줄일 수 있다.

Method: 오프더쉘프 비전 파운데이션 모델을 통해 특징을 추출하고, 특징 분포의 기하학적 형태를 추정·공유한다. 연합학습에서는 개인정보 제약 하에 글로벌 기하학적 형태를 획득하는 기법을 고안하고 이를 바탕으로 클라이언트에 새로운 샘플을 생성해 지역·전역 관측의 차이를 좁힌다. 롱테일 학습에서는 샘플 풍부(헤드) 클래스에서 전이된 기하학 지식을 이용해 샘플 희소(테일) 클래스의 진짜 분포를 복원한다.

Result: 종합적인 실험에서 제안한 기하학 지식 기반 분포 보정 기법이 데이터 이질성 및 샘플 불균형으로 인한 정보 결핍을 효과적으로 극복하며, 연합학습과 롱테일 인식의 다양한 벤치마크에서 성능 향상을 보였다.

Conclusion: 파운데이션 모델의 특징 공간 기하학을 전이·활용하는 분포 보정 프레임워크는 프라이버시 제약과 샘플 불균형 문제를 완화하며 실무적 유용성을 가진다.

Abstract: Despite the fast progress of deep learning, one standing challenge is the gap
of the observed training samples and the underlying true distribution. There
are multiple reasons for the causing of this gap e.g. sampling bias, noise etc.
In the era of foundation models, we show that when leveraging the off-the-shelf
(vision) foundation models (e.g., CLIP, DINOv2) for feature extraction, the
geometric shapes of the resulting feature distributions exhibit remarkable
transferability across domains and datasets. To verify its practical
usefulness, we embody our geometric knowledge-guided distribution calibration
framework in two popular and challenging settings: federated learning and
long-tailed recognition. In the federated setting, we devise a technique of
acquiring the global geometric shape under privacy constraints, then leverage
this knowledge to generate new samples for clients, in the aim of bridging the
gap between local and global observations. In long-tailed learning, it utilizes
the geometric knowledge transferred from sample-rich categories to recover the
true distribution for sample-scarce tail classes. Comprehensive experiments
show that our proposed geometric knowledge-guided distribution calibration
effectively overcomes information deficits caused by data heterogeneity and
sample imbalance, with boosted performance across benchmarks.

</details>


### [77] [SCRNet: Spatial-Channel Regulation Network for Medical Ultrasound Image Segmentation](https://arxiv.org/abs/2508.13899)
*Weixin Xu,Ziliang Wang*

Main category: cs.CV

TL;DR: 제안된 SCRNet은 UNet 인코더에 통합된 Spatial-Channel Regulation Module(SCRM)과 Feature Aggregation Module(FAM)을 통해 국소와 전역 정보를 동시에 포착해 초음파 의학 영상 분할에서 SOTA 성능을 달성한다.


<details>
  <summary>Details</summary>
Motivation: CNN은 장거리 의존성 캡처에 한계가 있고, Transformer 계열은 지역적 맥락을 간과할 수 있어 두 방식의 결점을 보완하는 구조가 필요하다.

Method: 두 입력 특징을 받아 Convolution과 Cross-Attention이 병렬로 작동하는 CCAPM으로 처리해 각각의 분기에서 다른 역할을 부여하고, 이를 FAM으로 통합해 장거리 및 지역 정보 동시 포착을 시도한다. FAM을 포함하는 SCRM은 주목할 가치가 있는 공간/채널 정보를 강조하며, SCRM을 UNet 인코더에 넣어 SCRNet을 구성한다.

Result: 광범위한 실험에서 SCRNet은 기존 방법들보다 일관되게 우수한 성능을 보여 SOTA를 달성했다.

Conclusion: CCAPM 기반 FAM과 SCRM의 결합은 초음파 영상 분할에서 장거리와 국소 정보를 효과적으로 통합하여 성능 향상을 이끌며, 제안된 SCRNet은 관련 작업에서 경쟁력 있는 방법임을 입증했다.

Abstract: Medical ultrasound image segmentation presents a formidable challenge in the
realm of computer vision. Traditional approaches rely on Convolutional Neural
Networks (CNNs) and Transformer-based methods to address the intricacies of
medical image segmentation. Nevertheless, inherent limitations persist, as
CNN-based methods tend to disregard long-range dependencies, while
Transformer-based methods may overlook local contextual information. To address
these deficiencies, we propose a novel Feature Aggregation Module (FAM)
designed to process two input features from the preceding layer. These features
are seamlessly directed into two branches of the Convolution and
Cross-Attention Parallel Module (CCAPM) to endow them with different roles in
each of the two branches to help establish a strong connection between the two
input features. This strategy enables our module to focus concurrently on both
long-range dependencies and local contextual information by judiciously merging
convolution operations with cross-attention mechanisms. Moreover, by
integrating FAM within our proposed Spatial-Channel Regulation Module (SCRM),
the ability to discern salient regions and informative features warranting
increased attention is enhanced. Furthermore, by incorporating the SCRM into
the encoder block of the UNet architecture, we introduce a novel framework
dubbed Spatial-Channel Regulation Network (SCRNet). The results of our
extensive experiments demonstrate the superiority of SCRNet, which consistently
achieves state-of-the-art (SOTA) performance compared to existing methods.

</details>


### [78] [PhysGM: Large Physical Gaussian Model for Feed-Forward 4D Synthesis](https://arxiv.org/abs/2508.13911)
*Chunji Lv,Zequn Chen,Donglin Di,Weinan Zhang,Hao Li,Wei Chen,Changsheng Li*

Main category: cs.CV

TL;DR: PhysGM은 단일 이미지에서 3D Gaussian Splatting 표현과 물리 속성(질량·마찰 등)을 동시에 예측해 즉시 물리 시뮬레이션과 고품질 4D 렌더링을 생성하는 피드포워드 프레임워크다. 학습은 가우시안 재구성과 확률적 물리 예측을 공동 최적화한 후, 레퍼런스 비디오로 DPO(Direct Preference Optimization)를 이용해 렌더링·물리 정확도를 향상시킨다. PhysAssets(24k 자산) 데이터셋을 도입했고, 단일 이미지로 1분 내 고충실도 4D 시뮬레이션을 생성해 속도와 현실성에서 기존 방법을 능가한다.


<details>
  <summary>Details</summary>
Motivation: 기존 물리 기반 3D 모션 합성은 사전에 재구성된 3D Gaussian Splatting 표현에 의존하고, 물리 통합은 수동으로 정의된 속성이나 비디오 기반의 불안정하고 최적화가 많은 가이드에 의존한다. 이런 접근은 유연성과 안정성, 계산 효율성에서 한계가 있어, 단일 이미지에서 즉시 시뮬레이션 가능한 표현과 물리 속성 예측이 필요하다.

Method: PhysGM은 단일 입력 이미지로부터 3D 가우시안 표현과 물리 속성을 동시에 예측하는 피드포워드 모델을 제안한다. 초기에는 가우시안 재구성과 확률적 물리 예측을 공동 최적화해 베이스 모델을 학습하고, 이후 레퍼런스 비디오를 이용해 DPO로 시뮬레이션 출력을 정렬(정책/선호도 기반 미세조정)한다. 이렇게 함으로써 SDS처럼 시뮬레이션·래스터라이제이션을 통해 역전파할 필요를 피한다. 또한 물리 속성·비디오 주석이 포함된 PhysAssets 데이터셋(24k 자산)을 도입했다.

Result: 단일 이미지로부터 1분 내에 고충실도의 4D 시뮬레이션을 생성할 수 있었으며, 기존 방법 대비 큰 속도 향상과 현실적 렌더링을 보였다. DPO 기반 정렬로 물리 예측과 렌더링 품질이 동시에 개선되었음을 보고한다.

Conclusion: PhysGM은 단일 이미지에서 물리 시뮬레이션 가능한 3D 표현과 물리 속성을 빠르고 안정적으로 예측해 즉시 시뮬레이션·렌더링할 수 있게 하며, DPO와 대규모 주석 자산 데이터셋을 결합해 속도와 현실성 모두에서 유의미한 개선을 이룬다.

Abstract: While physics-grounded 3D motion synthesis has seen significant progress,
current methods face critical limitations. They typically rely on
pre-reconstructed 3D Gaussian Splatting (3DGS) representations, while physics
integration depends on either inflexible, manually defined physical attributes
or unstable, optimization-heavy guidance from video models. To overcome these
challenges, we introduce PhysGM, a feed-forward framework that jointly predicts
a 3D Gaussian representation and its physical properties from a single image,
enabling immediate, physical simulation and high-fidelity 4D rendering. We
first establish a base model by jointly optimizing for Gaussian reconstruction
and probabilistic physics prediction. The model is then refined with physically
plausible reference videos to enhance both rendering fidelity and physics
prediction accuracy. We adopt the Direct Preference Optimization (DPO) to align
its simulations with reference videos, circumventing Score Distillation
Sampling (SDS) optimization which needs back-propagating gradients through the
complex differentiable simulation and rasterization. To facilitate the
training, we introduce a new dataset PhysAssets of over 24,000 3D assets,
annotated with physical properties and corresponding guiding videos.
Experimental results demonstrate that our method effectively generates
high-fidelity 4D simulations from a single image in one minute. This represents
a significant speedup over prior works while delivering realistic rendering
results. Our project page is at:https://hihixiaolv.github.io/PhysGM.github.io/

</details>


### [79] [Evaluating Open-Source Vision Language Models for Facial Emotion Recognition against Traditional Deep Learning Models](https://arxiv.org/abs/2508.13524)
*Vamsi Krishna Mulukutla,Sai Supriya Pavarala,Srinivasa Raju Rudraraju,Sridevi Bonthu*

Main category: cs.CV

TL;DR: FER-2013의 저해상도 흑백 감정 인식에서 기존 CNN 계열 모델(EfficientNet-B0, ResNet-50 등)이 오픈소스 VLM(Phi-3.5 Vision, CLIP)보다 성능이 훨씬 우수함을 보였다. GFPGAN 기반 이미지 복원 파이프라인을 도입해 VLM과 데이터 특성 간 불일치를 완화하려 했으나, VLM의 한계가 명확히 드러남.


<details>
  <summary>Details</summary>
Motivation: 저해상도·노이즈가 많은 FER 데이터에서 최근 주목받는 Vision-Language Models의 실제 성능을 전통적 딥러닝 모델과 비교하고, VLM의 학습 가정(고품질 이미지 등)과 FER 데이터의 불일치를 해결할 방법을 모색하기 위함.

Method: FER-2013 데이터셋(35,887개 흑백 이미지, 7개 감정 클래스)을 대상으로 Phi-3.5 Vision, CLIP과 VGG19, ResNet-50, EfficientNet-B0를 비교. GFPGAN 기반 이미지 복원 전처리 파이프라인을 도입하여 VLM 적용성 개선을 시도. 평가 지표로 precision, recall, F1-score, accuracy와 전처리/학습/추론/평가 단계별 계산 비용 분석을 수행.

Result: 전통적 모델이 큰 폭으로 우수: EfficientNet-B0 86.44%, ResNet-50 85.72% 대 CLIP 64.07%, Phi-3.5 Vision 51.66%. 계산 비용 측면 분석도 제공되어 실무 배포 관점의 인사이트를 제공함.

Conclusion: 현재 공개 VLM들은 저품질 FER 작업에 취약하며, VLM을 노이즈 환경에 적응시키기 위한 별도 전략(복원, 파인튜닝, 데이터 적응 등)이 필요하다. 본 연구는 재현 가능한 벤치마크와 배포 관점의 실용적 분석을 제공한다.

Abstract: Facial Emotion Recognition (FER) is crucial for applications such as
human-computer interaction and mental health diagnostics. This study presents
the first empirical comparison of open-source Vision-Language Models (VLMs),
including Phi-3.5 Vision and CLIP, against traditional deep learning models
VGG19, ResNet-50, and EfficientNet-B0 on the challenging FER-2013 dataset,
which contains 35,887 low-resolution grayscale images across seven emotion
classes. To address the mismatch between VLM training assumptions and the noisy
nature of FER data, we introduce a novel pipeline that integrates GFPGAN-based
image restoration with FER evaluation. Results show that traditional models,
particularly EfficientNet-B0 (86.44%) and ResNet-50 (85.72%), significantly
outperform VLMs like CLIP (64.07%) and Phi-3.5 Vision (51.66%), highlighting
the limitations of VLMs in low-quality visual tasks. In addition to performance
evaluation using precision, recall, F1-score, and accuracy, we provide a
detailed computational cost analysis covering preprocessing, training,
inference, and evaluation phases, offering practical insights for deployment.
This work underscores the need for adapting VLMs to noisy environments and
provides a reproducible benchmark for future research in emotion recognition.

</details>


### [80] [DIME-Net: A Dual-Illumination Adaptive Enhancement Network Based on Retinex and Mixture-of-Experts](https://arxiv.org/abs/2508.13921)
*Ziang Wang,Xiaoqin Wang,Dingyi Wang,Qiang Li,Shushan Qiao*

Main category: cs.CV

TL;DR: DIME-Net은 희미한 조명과 역광 같이 다양한 조명 열화를 하나의 모델로 처리하는 이중 조명 향상 프레임워크이다. Mixture-of-Experts 기반의 조명 추정기와 Retinex 통합, 손상 복원 모듈을 통해 단일 학습으로 저조도·역광에서 경쟁력 있는 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 실제 환경에서는 저조도와 역광 등 복합적 조명 열화가 빈번하지만, 기존 방법들은 주로 한 종류의 조명 문제만 다루어 다양한 조명에 통합적으로 대응하지 못한다.

Method: DIME-Net은 Mixture-of-Experts 조명 추정 모듈을 핵심으로 하며, 희소 게이팅 메커니즘으로 입력 이미지의 조명 특성에 따라 적합한 S-curve 전문가 네트워크를 선택한다. Retinex 이론을 통합해 저조도와 역광 모두에 맞춘 향상을 수행하고, Illumination-Aware Cross Attention 및 Sequential-State Global Attention을 갖춘 손상 복원 모듈로 조명 유발 인공물과 색 왜곡을 보정한다. 또한 기존 데이터셋을 통합한 하이브리드 MixBL 데이터셋으로 단일 학습으로 다양한 조명 적응성을 확보한다.

Result: 합성 및 실제 저조도·역광 데이터셋에서 재학습 없이도 경쟁력 있는 성능을 달성하여 높은 일반화 능력을 보였다.

Conclusion: DIME-Net은 복합적 조명 조건에서 단일 모델로 실용적인 향상 성능을 제공하며, 다양한 멀티미디어 응용에서 활용 가능성이 크다.

Abstract: Image degradation caused by complex lighting conditions such as low-light and
backlit scenarios is commonly encountered in real-world environments,
significantly affecting image quality and downstream vision tasks. Most
existing methods focus on a single type of illumination degradation and lack
the ability to handle diverse lighting conditions in a unified manner. To
address this issue, we propose a dual-illumination enhancement framework called
DIME-Net. The core of our method is a Mixture-of-Experts illumination estimator
module, where a sparse gating mechanism adaptively selects suitable S-curve
expert networks based on the illumination characteristics of the input image.
By integrating Retinex theory, this module effectively performs enhancement
tailored to both low-light and backlit images. To further correct
illumination-induced artifacts and color distortions, we design a damage
restoration module equipped with Illumination-Aware Cross Attention and
Sequential-State Global Attention mechanisms. In addition, we construct a
hybrid illumination dataset, MixBL, by integrating existing datasets, allowing
our model to achieve robust illumination adaptability through a single training
process. Experimental results show that DIME-Net achieves competitive
performance on both synthetic and real-world low-light and backlit datasets
without any retraining. These results demonstrate its generalization ability
and potential for practical multimedia applications under diverse and complex
illumination conditions.

</details>


### [81] [EAvatar: Expression-Aware Head Avatar Reconstruction with Generative Geometry Priors](https://arxiv.org/abs/2508.13537)
*Shikun Zhang,Cunjian Chen,Yiqun Wang,Qiuhong Ke,Yong Li*

Main category: cs.CV

TL;DR: 3D Gaussian Splatting 기반의 고해상도 헤드 아바타 복원에서, 소수의 핵심 가우시안을 이용해 이웃 가우시안의 변형을 유도하는 sparse expression control과, pretrained 생성 모델의 3D prior를 결합한 EAvatar를 제안하여 표정 제어력, 국소 변형 및 텍스처 연속성, 형상 정확도를 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 기존 3DGS 기반 방법들이 실시간 렌더링과 복잡한 형상 모델링에는 유리하지만, 세밀한 얼굴 표정과 변형이 큰 지역에서의 국소 텍스처 연속성 보존에 한계가 있어 고충실도 헤드 아바타 재구성 품질이 떨어진다.

Method: EAvatar라는 표현 인식(expression-aware)·변형 인식(deformation-aware) 3DGS 프레임워크를 도입한다. 핵심 아이디어는 소수의 key Gaussian이 주변 Gaussian의 변형을 유도하는 sparse expression control 메커니즘과, 사전 학습된 생성 모델로부터 얻은 고품질 3D prior를 활용해 얼굴 기하 구조를 제시하고 학습 수렴성과 형상 정확도를 개선하는 것이다.

Result: 제안 방법은 기존 3DGS 기반 접근법보다 표정 재현력과 국소 디테일 보존에서 우수한 결과를 보였으며, 더 일관된 시각적 재구성과 향상된 표정 제어성을 달성했다.

Conclusion: EAvatar는 소수의 제어 가우시안과 3D prior 결합을 통해 3DGS의 한계를 완화하고, 고품질·표정 조절 가능한 헤드 아바타 재구성 성능을 향상시킨다。

Abstract: High-fidelity head avatar reconstruction plays a crucial role in AR/VR,
gaming, and multimedia content creation. Recent advances in 3D Gaussian
Splatting (3DGS) have demonstrated effectiveness in modeling complex geometry
with real-time rendering capability and are now widely used in high-fidelity
head avatar reconstruction tasks. However, existing 3DGS-based methods still
face significant challenges in capturing fine-grained facial expressions and
preserving local texture continuity, especially in highly deformable regions.
To mitigate these limitations, we propose a novel 3DGS-based framework termed
EAvatar for head reconstruction that is both expression-aware and
deformation-aware. Our method introduces a sparse expression control mechanism,
where a small number of key Gaussians are used to influence the deformation of
their neighboring Gaussians, enabling accurate modeling of local deformations
and fine-scale texture transitions. Furthermore, we leverage high-quality 3D
priors from pretrained generative models to provide a more reliable facial
geometry, offering structural guidance that improves convergence stability and
shape accuracy during training. Experimental results demonstrate that our
method produces more accurate and visually coherent head reconstructions with
improved expression controllability and detail fidelity.

</details>


### [82] [ViT-FIQA: Assessing Face Image Quality using Vision Transformers](https://arxiv.org/abs/2508.13957)
*Andrea Atzori,Fadi Boutros,Naser Damer*

Main category: cs.CV

TL;DR: ViT-FIQA는 학습 가능한 quality token을 ViT 백본에 추가해 얼굴 이미지의 인식 유틸리티(품질)를 회귀로 예측하고, 패치 토큰은 마진-페널티 소프트맥스 손실로 식별 표현을 학습하는 방식으로, 여러 벤치마크와 FR 모델에서 우수한 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 기존 FIQA 연구는 주로 CNN 기반 접근에 의존하며, Vision Transformer(ViT)의 잠재력은 충분히 탐구되지 않았다. ViT의 전역 자기주목(self-attention)이 얼굴 이미지 유틸리티 모델링에 유리할 수 있어 이를 검증하고자 함.

Method: 원래 FR에 최적화된 ViT 백본에 학습 가능한 quality token을 도입한다. 이 토큰을 표준 이미지 패치 토큰들과 결합한 뒤 ViT 인코더의 전역 self-attention으로 문맥 정보를 통합한다. 출력에서 두 분기(head)를 사용: (1) 패치 토큰은 완전연결층과 마진-페널티 소프트맥스 손실로 식별 표현 학습, (2) quality token은 회귀 헤드로 얼굴 샘플의 유틸리티(스칼라 점수)를 예측.

Result: 다양한 도전적 벤치마크와 여러 FR 모델(CNN 및 ViT 기반)을 대상으로 한 광범위한 실험에서 ViT-FIQA는 일관되게 최상위 성능을 달성했다.

Conclusion: Transformer 기반 아키텍처가 얼굴 이미지의 유틸리티 모델링에 효과적임을 입증하며, ViT는 향후 FIQA 연구를 위한 확장 가능한 기반이 될 가능성이 높다.

Abstract: Face Image Quality Assessment (FIQA) aims to predict the utility of a face
image for face recognition (FR) systems. State-of-the-art FIQA methods mainly
rely on convolutional neural networks (CNNs), leaving the potential of Vision
Transformer (ViT) architectures underexplored. This work proposes ViT-FIQA, a
novel approach that extends standard ViT backbones, originally optimized for
FR, through a learnable quality token designed to predict a scalar utility
score for any given face image. The learnable quality token is concatenated
with the standard image patch tokens, and the whole sequence is processed via
global self-attention by the ViT encoders to aggregate contextual information
across all patches. At the output of the backbone, ViT-FIQA branches into two
heads: (1) the patch tokens are passed through a fully connected layer to learn
discriminative face representations via a margin-penalty softmax loss, and (2)
the quality token is fed into a regression head to learn to predict the face
sample's utility. Extensive experiments on challenging benchmarks and several
FR models, including both CNN- and ViT-based architectures, demonstrate that
ViT-FIQA consistently achieves top-tier performance. These results underscore
the effectiveness of transformer-based architectures in modeling face image
utility and highlight the potential of ViTs as a scalable foundation for future
FIQA research https://cutt.ly/irHlzXUC.

</details>


### [83] [FLAIR: Frequency- and Locality-Aware Implicit Neural Representations](https://arxiv.org/abs/2508.13544)
*Sukhun Ko,Dahyeon Kye,Kyle Min,Chanho Eom,Jihyong Oh*

Main category: cs.CV

TL;DR: FLAIR introduces frequency- and locality-aware implicit neural representations using a novel RC-GAUSS activation and Wavelet-Energy-Guided Encoding (WEGE) to overcome spectral bias and better capture high-frequency, localized signal components.


<details>
  <summary>Details</summary>
Motivation: Existing INRs lack frequency selectivity, spatial localization, and sparsity, causing spectral bias (learning low frequencies early and failing to capture high-frequency details) and redundant representations.

Method: Proposes FLAIR with two components: (1) RC-GAUSS, an activation enabling explicit frequency selection and spatial localization constrained by the time-frequency uncertainty principle (TFUP); (2) WEGE, which uses discrete wavelet transform (DWT) to compute energy scores that guide frequency information into the network.

Result: FLAIR consistently outperforms prior INR methods on 2D image representation and restoration tasks and on 3D reconstruction, demonstrating improved high-frequency detail recovery and more efficient representations.

Conclusion: By enforcing frequency-aware activations and wavelet-guided encoding, FLAIR mitigates spectral bias, yields sparser and more localized INRs, and provides better performance across image and 3D reconstruction tasks.

Abstract: Implicit Neural Representations (INRs) leverage neural networks to map
coordinates to corresponding signals, enabling continuous and compact
representations. This paradigm has driven significant advances in various
vision tasks. However, existing INRs lack frequency selectivity, spatial
localization, and sparse representations, leading to an over-reliance on
redundant signal components. Consequently, they exhibit spectral bias, tending
to learn low-frequency components early while struggling to capture fine
high-frequency details. To address these issues, we propose FLAIR (Frequency-
and Locality-Aware Implicit Neural Representations), which incorporates two key
innovations. The first is RC-GAUSS, a novel activation designed for explicit
frequency selection and spatial localization under the constraints of the
time-frequency uncertainty principle (TFUP). The second is
Wavelet-Energy-Guided Encoding (WEGE), which leverages the discrete wavelet
transform (DWT) to compute energy scores and explicitly guide frequency
information to the network. Our method consistently outperforms existing INRs
in 2D image representation and restoration, as well as 3D reconstruction.

</details>


### [84] [RotBench: Evaluating Multimodal Large Language Models on Identifying Image Rotation](https://arxiv.org/abs/2508.13968)
*Tianyi Niu,Jaemin Cho,Elias Stengel-Eskin,Mohit Bansal*

Main category: cs.CV

TL;DR: The paper introduces RotBench, a 350-image benchmark to test Multimodal LLMs' ability to detect image rotations (0°, 90°, 180°, 270°). Many state-of-the-art models (including GPT-5, o3, Gemini-2.5-Pro) fail to reliably identify rotations: 0° is usually recognized, 180° sometimes, but 90° vs 270° is not distinguished. Auxiliary inputs and prompting give small inconsistent gains; multi-orientation display and voting help moderately; fine-tuning improves 180° detection but not 90°/270°. Overall, there is a notable spatial reasoning gap.


<details>
  <summary>Details</summary>
Motivation: To measure how well MLLMs perform basic spatial reasoning: specifically, identifying image orientation among four cardinal rotations—a seemingly simple perceptual task that probes models' ability to detect rotational cues and contextual spatial relationships.

Method: (Duplicate field corrected)

Result: Most models reliably identify upright (0°) images; some detect upside-down (180°); none reliably distinguish 90° vs 270°. Auxiliary information and chain-of-thought give small/inconsistent improvements. Showing multiple orientations improves reasoning models moderately; voting helps weaker models. Fine-tuning substantially improves 180° detection but not 90°/270° discrimination.

Conclusion: There is a significant gap between MLLMs' spatial reasoning and human perception for rotation detection. Current architectures/approaches struggle with orientation-specific cues, especially between left/right (90° vs 270°). New methods or focused training/data are needed to close this gap.

Abstract: We investigate to what extent Multimodal Large Language Models (MLLMs) can
accurately identify the orientation of input images rotated 0{\deg}, 90{\deg},
180{\deg}, and 270{\deg}. This task demands robust visual reasoning
capabilities to detect rotational cues and contextualize spatial relationships
within images, regardless of their orientation. To evaluate MLLMs on these
abilities, we introduce RotBench -- a 350-image manually-filtered benchmark
comprising lifestyle, portrait, and landscape images. Despite the relatively
simple nature of this task, we show that several state-of-the-art open and
proprietary MLLMs, including GPT-5, o3, and Gemini-2.5-Pro, do not reliably
identify rotation in input images. Providing models with auxiliary information
-- including captions, depth maps, and more -- or using chain-of-thought
prompting offers only small and inconsistent improvements. Our results indicate
that most models are able to reliably identify right-side-up (0{\deg}) images,
while certain models are able to identify upside-down (180{\deg}) images. None
can reliably distinguish between 90{\deg} and 270{\deg}. Simultaneously showing
the image rotated in different orientations leads to moderate performance gains
for reasoning models, while a modified setup using voting improves the
performance of weaker models. We further show that fine-tuning does not improve
models' ability to distinguish 90{\deg} and 270{\deg} rotations, despite
substantially improving the identification of 180{\deg} images. Together, these
results reveal a significant gap between MLLMs' spatial reasoning capabilities
and human perception in identifying rotation.

</details>


### [85] [ROVR-Open-Dataset: A Large-Scale Depth Dataset for Autonomous Driving](https://arxiv.org/abs/2508.13977)
*Xianda Guo,Ruijun Zhang,Yiqun Duan,Ruilin Wang,Keyuan Zhou,Wenzhao Zheng,Wenke Huang,Gangwei Xu,Mike Horton,Yuan Si,Hao Zhao,Long Chen*

Main category: cs.CV

TL;DR: 저자들은 동적 야외 주행 환경을 위한 대규모(20K 프레임) 프레임 단위 연속 깊이 데이터셋을 제안한다. 경량 수집 파이프라인과 희소하지만 통계적으로 충분한 GT로 저비용·다양성 확보, 기존 데이터셋보다 더 낮은 깊이 밀도와 더 큰 장면 다양성을 제공한다. 표준 단안 깊이 추정 모델의 벤치마크에서 어려운 조건에서 성능 격차를 보이며 일반화 연구를 촉진할 새 플랫폼을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 기존 깊이 데이터셋(KITTI, nuScenes, DDAD 등)은 다양성과 확장성에 한계가 있어 벤치마크 성능이 포화 상태에 이르고 있으며, 파운데이션 모델·다중모달 학습 시대에 맞춘 대규모·다양·저비용 데이터셋이 필요하다.

Method: 경량의 수집 파이프라인을 통해 동적 주행 환경에서 프레임 단위 연속 데이터 20K 프레임을 확보. 깊이 지도는 희소하지만 통계적으로 충분한 형태로 수집하여 학습에 활용할 수 있도록 함. 데이터셋은 다양한 주행 시나리오와 낮은 깊이 밀도를 특징으로 설계됨.

Result: 제안된 데이터셋은 기존 데이터셋보다 장면 다양성이 크고 깊이 밀도는 낮음. 표준 단안 깊이 추정 모델들로 벤치마크했을 때 어려운 조건에서 상당한 성능 저하(격차)를 보였으며, 이는 일반화 문제와 연구 필요성을 드러냄.

Conclusion: 새로운 대규모·다양성 중심의 저비용 깊이 데이터셋은 기존 벤치의 한계를 보완하고, 일반화와 강건성 향상을 목표로 하는 후속 연구 및 파운데이션·다중모달 모델 개발에 유용한 플랫폼을 제공한다.

Abstract: Depth estimation is a fundamental task for 3D scene understanding in
autonomous driving, robotics, and augmented reality. Existing depth datasets,
such as KITTI, nuScenes, and DDAD, have advanced the field but suffer from
limitations in diversity and scalability. As benchmark performance on these
datasets approaches saturation, there is an increasing need for a new
generation of large-scale, diverse, and cost-efficient datasets to support the
era of foundation models and multi-modal learning. To address these challenges,
we introduce a large-scale, diverse, frame-wise continuous dataset for depth
estimation in dynamic outdoor driving environments, comprising 20K video frames
to evaluate existing methods. Our lightweight acquisition pipeline ensures
broad scene coverage at low cost, while sparse yet statistically sufficient
ground truth enables robust training. Compared to existing datasets, ours
presents greater diversity in driving scenarios and lower depth density,
creating new challenges for generalization. Benchmark experiments with standard
monocular depth estimation models validate the dataset's utility and highlight
substantial performance gaps in challenging conditions, establishing a new
platform for advancing depth estimation research.

</details>


### [86] [The 9th AI City Challenge](https://arxiv.org/abs/2508.13564)
*Zheng Tang,Shuo Wang,David C. Anastasiu,Ming-Ching Chang,Anuj Sharma,Quan Kong,Norimasa Kobori,Munkhjargal Gochoo,Ganzorig Batnasan,Munkh-Erdene Otgonbold,Fady Alnajjar,Jun-Wei Hsieh,Tomasz Kornuta,Xiaolong Li,Yilin Zhao,Han Zhang,Subhashree Radhakrishnan,Arihant Jain,Ratnesh Kumar,Vidya N. Murali,Yuxing Wang,Sameer Satish Pusegaonkar,Yizhou Wang,Sujit Biswas,Xunlei Wu,Zhedong Zheng,Pranamesh Chakraborty,Rama Chellappa*

Main category: cs.CV

TL;DR: 9th AI City Challenge (2025) ran four tracks addressing multi-class 3D multi-camera tracking, traffic video question answering with 3D gaze, fine-grained spatial reasoning in RGB-D warehouse scenes, and efficient fisheye road-object detection. Participation rose 17% to 245 teams from 15 countries; datasets were publicly released and downloaded >30,000 times. Evaluation used submission limits and a partially held-out test set to ensure fairness and reproducibility; top teams set new benchmarks.


<details>
  <summary>Details</summary>
Motivation: Advance practical computer-vision and AI for transportation, industrial automation, and public safety; create challenging multi-modal benchmarks and encourage reproducible, fair evaluation.

Method: Four specialized tracks with rich annotations (3D bounding boxes, 3D gaze, RGB-D), synthetic data generation in NVIDIA Omniverse for Tracks 1 and 3, multi-camera calibration, fisheye-specific datasets for edge deployment, and an evaluation framework with submission caps and partially held-out test data.

Result: 17% increase in participation (245 teams, 15 countries), >30k dataset downloads, multiple teams achieved top-tier results setting new benchmarks across tasks, and final rankings released to mitigate overfitting and support reproducibility.

Conclusion: The challenge pushed state-of-the-art in diverse, deployment-oriented CV tasks, produced valuable public datasets and benchmarks, and emphasized fair, reproducible evaluation practices for real-world applications.

Abstract: The ninth AI City Challenge continues to advance real-world applications of
computer vision and AI in transportation, industrial automation, and public
safety. The 2025 edition featured four tracks and saw a 17% increase in
participation, with 245 teams from 15 countries registered on the evaluation
server. Public release of challenge datasets led to over 30,000 downloads to
date. Track 1 focused on multi-class 3D multi-camera tracking, involving
people, humanoids, autonomous mobile robots, and forklifts, using detailed
calibration and 3D bounding box annotations. Track 2 tackled video question
answering in traffic safety, with multi-camera incident understanding enriched
by 3D gaze labels. Track 3 addressed fine-grained spatial reasoning in dynamic
warehouse environments, requiring AI systems to interpret RGB-D inputs and
answer spatial questions that combine perception, geometry, and language. Both
Track 1 and Track 3 datasets were generated in NVIDIA Omniverse. Track 4
emphasized efficient road object detection from fisheye cameras, supporting
lightweight, real-time deployment on edge devices. The evaluation framework
enforced submission limits and used a partially held-out test set to ensure
fair benchmarking. Final rankings were revealed after the competition
concluded, fostering reproducibility and mitigating overfitting. Several teams
achieved top-tier results, setting new benchmarks in multiple tasks.

</details>


### [87] [OmViD: Omni-supervised active learning for video action detection](https://arxiv.org/abs/2508.13983)
*Aayush Rana,Akash Kumar,Vibhav Vineet,Yogesh S Rawat*

Main category: cs.CV

TL;DR: 비디오 행동 검출에서 샘플별로 필요한 주석 수준을 분석하고, 다양한 주석(비디오 태그, 포인트, 스크리블, 박스, 마스크)을 활용해 학습하는 방법을 제안한다. 능동 학습으로 각 비디오에 적절한 주석 유형을 선택하고, 시공간 3D-슈퍼픽셀로 의사 라벨을 생성해 학습하여 주석 비용을 크게 줄이면서 성능 손실을 최소화했다.


<details>
  <summary>Details</summary>
Motivation: 비디오 행동 검출은 밀집한 시공간 주석을 요구하지만, 모든 비디오가 동일한 주석 수준을 필요로 하지 않음. 샘플별로 적절한 주석 수준을 분석해 비용을 절감하고 효율적으로 학습하는 방법이 필요함.

Method: 1) 간단한 능동 학습(active learning) 전략으로 각 비디오에 필요한 주석 유형을 추정한다. 2) 비디오 수준 태그, 포인트, 스크리블, 박스, 마스크 등 다양한 주석을 사용. 3) 제안된 시공간 3D-슈퍼픽셀 방법으로 이러한 주석으로부터 의사 라벨을 생성하여 모델을 학습시킨다.

Result: UCF101-24와 JHMDB-21 데이터셋에서 제안 방법을 검증해 주석 비용을 크게 절감하면서 성능 저하를 최소화했음.

Conclusion: 샘플별로 적합한 주석 수준을 선택하고, 3D-슈퍼픽셀 기반 의사 라벨을 이용하면 행동 검출 성능을 유지하면서 주석 비용을 상당히 낮출 수 있다.

Abstract: Video action detection requires dense spatio-temporal annotations, which are
both challenging and expensive to obtain. However, real-world videos often vary
in difficulty and may not require the same level of annotation. This paper
analyzes the appropriate annotation types for each sample and their impact on
spatio-temporal video action detection. It focuses on two key aspects: 1) how
to obtain varying levels of annotation for videos, and 2) how to learn action
detection from different annotation types. The study explores video-level tags,
points, scribbles, bounding boxes, and pixel-level masks. First, a simple
active learning strategy is proposed to estimate the necessary annotation type
for each video. Then, a novel spatio-temporal 3D-superpixel approach is
introduced to generate pseudo-labels from these annotations, enabling effective
training. The approach is validated on UCF101-24 and JHMDB-21 datasets,
significantly cutting annotation costs with minimal performance loss.

</details>


### [88] [Physics-Based 3D Simulation for Synthetic Data Generation and Failure Analysis in Packaging Stability Assessment](https://arxiv.org/abs/2508.13989)
*Samuel Seligardi,Pietro Musoni,Eleonora Iotti,Gianluca Contesso,Alessandro Dal Palù*

Main category: cs.CV

TL;DR: 모든 팔레트 구성과 포장 재료, 동적 조건을 지원하는 3D 물리 시뮬레이터와, 시뮬레이터로 생성된 비디오로 팔레트 충돌(크래시) 여부를 예측하는 딥러닝 모델을 제안한다. 물리적 시험을 줄여 비용과 환경 영향을 낮추고 측정 정확도를 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 물류업에서 팔레트 적재와 포장 방식의 안전성 확보가 중요해졌고, 플라스틱 래핑의 널리 사용으로 친환경 대체재 연구 필요성과 자동화된 고정밀 시스템의 요구가 증가했다.

Method: 3D 그래픽 기반의 물리 시뮬레이터를 구축해 다양한 패키지 배치, 포장 재료, 동적 조건을 모델링하고, 시뮬레이터가 생성한 렌더링 비디오를 입력으로 받아 팔레트 크래시 여부를 예측하는 딥 뉴럴 네트워크를 훈련했다.

Result: 시뮬레이터는 물리적 테스트를 대체해 비용과 환경 영향 감소, 측정 정확도 향상을 제공하며, 딥러닝 모델은 렌더링 비디오를 통해 팔레트 구성의 안전성(크래시 가능성)을 평가할 수 있다.

Conclusion: 제안한 시스템은 팔레트 동역학 분석 및 안전성 평가에서 물리적 실험을 줄이고 효율적이고 정확한 예측을 제공해 물류 시스템 설계와 친환경 포장 연구에 도움이 된다.

Abstract: The design and analysis of pallet setups are essential for ensuring safety of
packages transportation. With rising demands in the logistics sector, the
development of automated systems utilizing advanced technologies has become
increasingly crucial. Moreover, the widespread use of plastic wrapping has
motivated researchers to investigate eco-friendly alternatives that still
adhere to safety standards. We present a fully controllable and accurate
physical simulation system capable of replicating the behavior of moving
pallets. It features a 3D graphics-based virtual environment that supports a
wide range of configurations, including variable package layouts, different
wrapping materials, and diverse dynamic conditions. This innovative approach
reduces the need for physical testing, cutting costs and environmental impact
while improving measurement accuracy for analyzing pallet dynamics.
Additionally, we train a deep neural network to evaluate the rendered videos
generated by our simulator, as a crash-test predictor for pallet
configurations, further enhancing the system's utility in safety analysis.

</details>


### [89] [Self-Supervised Sparse Sensor Fusion for Long Range Perception](https://arxiv.org/abs/2508.13995)
*Edoardo Palladin,Samuel Brucker,Filippo Ghilotti,Praveen Narayanan,Mario Bijelic,Felix Heide*

Main category: cs.CV

TL;DR: 이 논문은 장거리(최대 250m) 고속도로 주행용 자율주행 인식 문제를 다룬다. BEV 기반 방법들이 거리 확장 시 메모리·연산이 제곱으로 증가하는 한계를 해결하기 위해 희박한 3D 표현과 다중 모달(카메라·라이다) 및 시간적 특징을 효율적으로 인코딩하는 방법을 제안하고, 라벨이 없는 데이터로 대규모 학습이 가능한 자기지도 사전학습 기법을 도입했다. 결과적으로 객체 검출 mAP를 26.6% 향상시키고 라이다 예측의 Chamfer Distance를 30.5% 감소시켜 250m까지 인식 거리를 확장했다.


<details>
  <summary>Details</summary>
Motivation: 고속도로에서 100km/h 이상의 속도로 안전 주행하려면 최소 250m의 인식 거리가 필요하다. 기존의 BEV 기반 접근법은 인식 범위를 도시 주행 수준(50-100m)으로만 다루며, 거리 증가에 따라 메모리와 연산 비용이 제곱으로 증가해 장거리 확장에 부적합하다. 대형 트럭과 같이 관성으로 인해 더 긴 계획 수평면이 필요한 차량에 적용하려면 더 먼 거리의 인식이 필요하다.

Method: 희소 표현(sparse representation)을 기반으로 3D에서 다중 모달 및 시간적 특징을 효율적으로 인코딩하는 새로운 방법을 제안한다. 또한 레이블 없는 카메라-라이다 데이터에서 대규모로 학습할 수 있는 자기지도 사전학습(self-supervised pretraining) 기법을 개발했다. BEV 대신 3D 희소 인코딩을 사용하여 메모리·연산을 절감하면서 250m까지 확장한다.

Result: 제안 기법은 최대 250m의 인식 범위에서 기존 방법 대비 객체 검출 mAP가 26.6% 향상되었고, 라이다 포캐스팅(LiDAR forecasting)에서 Chamfer Distance가 30.5% 감소하는 성능 개선을 보였다.

Conclusion: 희소 3D 인코딩과 자기지도 사전학습을 결합하면 BEV 기반 방법의 한계를 극복하고, 장거리 고속도로 자율주행에 필요한 250m 수준의 인식 범위를 효율적으로 달성할 수 있다.

Abstract: Outside of urban hubs, autonomous cars and trucks have to master driving on
intercity highways. Safe, long-distance highway travel at speeds exceeding 100
km/h demands perception distances of at least 250 m, which is about five times
the 50-100m typically addressed in city driving, to allow sufficient planning
and braking margins. Increasing the perception ranges also allows to extend
autonomy from light two-ton passenger vehicles to large-scale forty-ton trucks,
which need a longer planning horizon due to their high inertia. However, most
existing perception approaches focus on shorter ranges and rely on Bird's Eye
View (BEV) representations, which incur quadratic increases in memory and
compute costs as distance grows. To overcome this limitation, we built on top
of a sparse representation and introduced an efficient 3D encoding of
multi-modal and temporal features, along with a novel self-supervised
pre-training scheme that enables large-scale learning from unlabeled
camera-LiDAR data. Our approach extends perception distances to 250 meters and
achieves an 26.6% improvement in mAP in object detection and a decrease of
30.5% in Chamfer Distance in LiDAR forecasting compared to existing methods,
reaching distances up to 250 meters. Project Page:
https://light.princeton.edu/lrs4fusion/

</details>


### [90] [ResPlan: A Large-Scale Vector-Graph Dataset of 17,000 Residential Floor Plans](https://arxiv.org/abs/2508.14006)
*Mohamed Abouagour,Eleftherios Garyfallidis*

Main category: cs.CV

TL;DR: ResPlan은 17,000개의 고해상도·구조적으로 풍부한 실제 주거 평면도로 구성된 대규모 데이터셋으로, 정밀한 건축 요소 및 공간 주석, 기하·그래프 형식 제공, 정제 파이프라인과 방 연결성 구조를 포함해 공간 AI 연구와 다양한 응용을 지원한다.


<details>
  <summary>Details</summary>
Motivation: 기존 평면도 데이터셋(RPLAN, MSD 등)은 시각적 충실도, 구조적 다양성, 현실성에서 한계를 보이며 시뮬레이션·로봇공학·생성 모델 등 차세대 공간 지능 개발에 필요한 자원이 부족했다.

Method: 실제 주거 평면도 17,000개 수집 및 정밀 주석(벽·문·창·발코니, 주방·침실·욕실 등 기능적 공간), 기하학적·그래프 기반 포맷으로 제공, 기하 정제·정렬·주석 개선을 위한 오픈소스 파이프라인 구축, 방 연결성(그래프) 구조 생성.

Result: 데이터셋은 향상된 시각적 충실도와 구조적 다양성, 시뮬레이션 엔진 직접 통합 및 빠른 3D 변환 지원, 기존 벤치마크와의 비교분석 제공, 다양한 오픈 벤치마크 과제(파싱, 그래프 추론, 생성 등) 제시.

Conclusion: ResPlan은 규모·현실성·사용성 측면에서 기존 자료들을 능가하며, 공간 지능 시스템 개발·평가를 위한 견고한 기반을 제공한다.

Abstract: We introduce ResPlan, a large-scale dataset of 17,000 detailed, structurally
rich, and realistic residential floor plans, created to advance spatial AI
research. Each plan includes precise annotations of architectural elements
(walls, doors, windows, balconies) and functional spaces (such as kitchens,
bedrooms, and bathrooms). ResPlan addresses key limitations of existing
datasets such as RPLAN (Wu et al., 2019) and MSD (van Engelenburg et al., 2024)
by offering enhanced visual fidelity and greater structural diversity,
reflecting realistic and non-idealized residential layouts. Designed as a
versatile, general-purpose resource, ResPlan supports a wide range of
applications including robotics, reinforcement learning, generative AI, virtual
and augmented reality, simulations, and game development. Plans are provided in
both geometric and graph-based formats, enabling direct integration into
simulation engines and fast 3D conversion. A key contribution is an open-source
pipeline for geometry cleaning, alignment, and annotation refinement.
Additionally, ResPlan includes structured representations of room connectivity,
supporting graph-based spatial reasoning tasks. Finally, we present comparative
analyses with existing benchmarks and outline several open benchmark tasks
enabled by ResPlan. Ultimately, ResPlan offers a significant advance in scale,
realism, and usability, providing a robust foundation for developing and
benchmarking next-generation spatial intelligence systems.

</details>


### [91] [Online 3D Gaussian Splatting Modeling with Novel View Selection](https://arxiv.org/abs/2508.14014)
*Byeonggwon Lee,Junkyu Park,Khang Truong Giang,Soohwan Song*

Main category: cs.CV

TL;DR: 온라인 RGB 프레임만으로 3D Gaussian Splatting(3DGS) 모델을 생성할 때, 키프레임만으로는 장면이 불완전하게 재구성되는 문제를 해결하기 위해, 온라인에서 재구성 품질을 분석해 최적의 비-키프레임을 적응적으로 선택하고 이를 키프레임과 함께 통합하여 부족한 영역을 보완하는 방법을 제안한다. 온라인 다중시점 스테레오(MVS)를 결합해 3D 정보의 일관성을 유지하며, 복잡한 야외 장면에서 기존 방법들보다 더 완전한 모델을 생성한다.


<details>
  <summary>Details</summary>
Motivation: 기존 온라인 3DGS 구축은 SLAM으로 추출한 키프레임에만 의존해 장면 전반을 포착하지 못해 재구성이 불완전하고, 일반화 가능한 모델을 만들려면 다양한 시점의 프레임이 필요하지만 온라인 환경에서는 많은 프레임 사용이나 긴 학습 반복이 제한된다.

Method: (1) 온라인으로 재구성 품질을 평가하는 지표를 도입하거나 계산하여 불완전한 영역을 식별한다. (2) 식별된 영역을 보완할 수 있는 최적의 비-키프레임들을 적응적으로 선택하여 추가 학습 데이터로 사용한다. (3) 키프레임과 선택된 비-키프레임을 통합해 3DGS를 추가로 학습·정제한다. (4) 전체 파이프라인에 온라인 MVS를 결합해 프레임 간 3D 정보의 일관성을 확보한다.

Result: 제안 방법은 복잡한 야외 장면에서 기존 최첨단 방법들보다 재구성 완전성이 크게 향상되었음을 보였다. 온라인 제약(프레임 수·학습 반복) 하에서도 더 넓은 시점 커버리지를 확보해 성능 우위를 달성했다.

Conclusion: 적응적 비-키프레임 선택과 온라인 MVS 통합을 통해 온라인 RGB 전용 3DGS 구축의 재구성 불완전성 문제를 효과적으로 완화하며, 실세계 복잡한 장면에서 더 완전하고 일관된 3D 모델을 생성할 수 있다.

Abstract: This study addresses the challenge of generating online 3D Gaussian Splatting
(3DGS) models from RGB-only frames. Previous studies have employed dense SLAM
techniques to estimate 3D scenes from keyframes for 3DGS model construction.
However, these methods are limited by their reliance solely on keyframes, which
are insufficient to capture an entire scene, resulting in incomplete
reconstructions. Moreover, building a generalizable model requires
incorporating frames from diverse viewpoints to achieve broader scene coverage.
However, online processing restricts the use of many frames or extensive
training iterations. Therefore, we propose a novel method for high-quality 3DGS
modeling that improves model completeness through adaptive view selection. By
analyzing reconstruction quality online, our approach selects optimal
non-keyframes for additional training. By integrating both keyframes and
selected non-keyframes, the method refines incomplete regions from diverse
viewpoints, significantly enhancing completeness. We also present a framework
that incorporates an online multi-view stereo approach, ensuring consistency in
3D information throughout the 3DGS modeling process. Experimental results
demonstrate that our method outperforms state-of-the-art methods, delivering
exceptional performance in complex outdoor scenes.

</details>


### [92] [CLoE: Curriculum Learning on Endoscopic Images for Robust MES Classification](https://arxiv.org/abs/2508.13280)
*Zeynep Ozdemir,Hacer Yalim Keles,Omer Ozgur Tanriover*

Main category: cs.CV

TL;DR: 이 논문은 궤양성 대장염(Ulcerative Colitis) 내시경 이미지에서 Mayo Endoscopic Subscore(MES)를 추정하는 문제에서 라벨 노이즈와 점수의 순서성(ordinality)을 고려한 커리큘럼 학습 프레임워크 CLoE를 제안한다. 이미지 품질(BBPS 기반)을 어노테이션 신뢰도의 프록시로 사용해 쉬운 샘플부터 어려운 샘플 순으로 학습하고, ResizeMix 증강을 결합해 강건성을 높인다. LIMUC와 HyperKvasir 데이터셋에서 CNN 및 Transformer에 적용해 기존 감독/자기지도 기법보다 성능 향상을 보였다.


<details>
  <summary>Details</summary>
Motivation: MES 분류는 관찰자 간 변동성으로 인한 라벨 노이즈와 점수의 순서성을 무시하는 기존 모델의 한계 때문에 어렵다. 라벨 신뢰도를 고려한 학습 및 순서성을 반영하는 방법이 필요하다.

Method: CLoE는 (1) BBPS(장 준비 상태) 레이블로 학습한 경량 모델을 이용해 이미지 품질을 추정하고 이를 어노테이션 신뢰도의 프록시로 사용해 샘플을 쉬운(품질 높음)에서 어려운(품질 낮음) 순으로 정렬하는 커리큘럼 학습을 수행한다. (2) ResizeMix라는 데이터 증강을 커리큘럼 학습과 결합해 모델의 강건성을 향상시킨다. CNN(ConvNeXt-Tiny 등)과 Transformer 기반 모델에서 실험했다.

Result: LIMUC 데이터셋에서 ConvNeXt-Tiny는 82.5% 정확도와 QWK 0.894를 달성했으며, CLoE는 강한 감독 및 자기지도 학습 기반 최강치 대비 일관된 성능 향상을 보였다. 계산 비용이 낮음도 강조됨.

Conclusion: 어려움 인지 기반(난이도-인지) 학습 전략과 이미지 품질을 이용한 라벨 신뢰도 추정은 라벨 불확실성이 있는 순서형 분류 문제에서 성능을 향상시킨다. CLoE는 효과적이고 계산 효율적인 방법이며 향후 의료 영상의 등급 판정에 유용할 수 있다.

Abstract: Estimating disease severity from endoscopic images is essential in assessing
ulcerative colitis, where the Mayo Endoscopic Subscore (MES) is widely used to
grade inflammation. However, MES classification remains challenging due to
label noise from inter-observer variability and the ordinal nature of the
score, which standard models often ignore. We propose CLoE, a curriculum
learning framework that accounts for both label reliability and ordinal
structure. Image quality, estimated via a lightweight model trained on Boston
Bowel Preparation Scale (BBPS) labels, is used as a proxy for annotation
confidence to order samples from easy (clean) to hard (noisy). This curriculum
is further combined with ResizeMix augmentation to improve robustness.
Experiments on the LIMUC and HyperKvasir datasets, using both CNNs and
Transformers, show that CLoE consistently improves performance over strong
supervised and self-supervised baselines. For instance, ConvNeXt-Tiny reaches
82.5\% accuracy and a QWK of 0.894 on LIMUC with low computational cost. These
results highlight the potential of difficulty-aware training strategies for
improving ordinal classification under label uncertainty. Code will be released
at https://github.com/zeynepozdemir/CLoE.

</details>


### [93] [Backdooring Self-Supervised Contrastive Learning by Noisy Alignment](https://arxiv.org/abs/2508.14015)
*Tuo Chen,Jie Gui,Minjing Dong,Ju Jia,Lanting Fang,Jian Liu*

Main category: cs.CV

TL;DR: 새로운 데이터-포이즈닝 대조학습(DPCL) 공격 'Noisy Alignment(NA)'을 제안한다. 랜덤 크롭을 전략적으로 조작해 포이즈닝 이미지의 잡음(백도어 성분)을 억제함으로써 대조학습 인코더에 표적 오작동을 야기한다. 간단한 이미지 레이아웃 최적화와 이론적 파라미터 도출로 기존 방법들보다 높은 공격성능과 정밀도를 보이며, 깨끗한 데이터 성능을 유지하고 여러 방어에 강건하다.


<details>
  <summary>Details</summary>
Motivation: 기존 DPCL은 백도어와 목표 객체의 우연한 공존에 의존하거나, 포이즈닝 이미지의 판별적 특징을 충분히 억제하지 못해 공격 효율이 낮다. 대조학습의 특성을 이용한 제어 가능한 공격이 가능함을 바탕으로 더 강력한 DPCL가 필요하다.

Method: Noisy Alignment는 포이즈닝 이미지에서 '잡음 성분'을 명시적으로 억제하는 것을 목표로 한다. 이를 위해 대조학습의 랜덤 크롭 메커니즘을 전략적으로 조작하여 백도어 신호를 일관되게 정렬시키고 표적 객체의 판별적 특징을 희석한다. 이 과정을 이미지 레이아웃 최적화 문제로 공식화하고 최적 파라미터를 이론적으로 도출해 간단하게 구현한다.

Result: 제안 방법은 기존 DPCL 기법들보다 공격 성공률(ASR)에서 우수하며, 다운스트림 태스크에서 깨끗한 데이터에 대한 정확도 감소를 최소화한다. 또한 여러 일반적인 백도어 방어 기법에 대해 강건한 성능을 보였다.

Conclusion: 랜덤 크롭 조작을 통한 잡음 정렬(Noisy Alignment)은 단순하면서도 효과적인 DPCL 전략으로, 이론적 근거와 실험적 성능을 모두 갖추어 기존 방법들을 능가하며 실전적인 방어에도 견딜 수 있다.

Abstract: Self-supervised contrastive learning (CL) effectively learns transferable
representations from unlabeled data containing images or image-text pairs but
suffers vulnerability to data poisoning backdoor attacks (DPCLs). An adversary
can inject poisoned images into pretraining datasets, causing compromised CL
encoders to exhibit targeted misbehavior in downstream tasks. Existing DPCLs,
however, achieve limited efficacy due to their dependence on fragile implicit
co-occurrence between backdoor and target object and inadequate suppression of
discriminative features in backdoored images. We propose Noisy Alignment (NA),
a DPCL method that explicitly suppresses noise components in poisoned images.
Inspired by powerful training-controllable CL attacks, we identify and extract
the critical objective of noisy alignment, adapting it effectively into
data-poisoning scenarios. Our method implements noisy alignment by
strategically manipulating contrastive learning's random cropping mechanism,
formulating this process as an image layout optimization problem with
theoretically derived optimal parameters. The resulting method is simple yet
effective, achieving state-of-the-art performance compared to existing DPCLs,
while maintaining clean-data accuracy. Furthermore, Noisy Alignment
demonstrates robustness against common backdoor defenses. Codes can be found at
https://github.com/jsrdcht/Noisy-Alignment.

</details>


### [94] [DAASH: A Meta-Attack Framework for Synthesizing Effective and Stealthy Adversarial Examples](https://arxiv.org/abs/2508.13309)
*Abdullah Al Nomaan Nafi,Habibur Rahaman,Zafaryab Haider,Tanzim Mahfuz,Fnu Suya,Swarup Bhunia,Prabuddha Chakraborty*

Main category: cs.CV

TL;DR: DAASH는 여러 Lp-기반 공격을 단계적으로 조합하고 학습된 가중치와 메타 손실(오분류+지각적 왜곡)을 사용해 시각적으로 타당하면서 강한 적대적 예제를 생성하는 완전 미분 가능한 메타-어택 프레임워크다.


<details>
  <summary>Details</summary>
Motivation: 기존 Lp-노름 제약 기반 공격은 인간 지각과 잘 맞지 않아 시각적으로 현실성 있는(지각 정렬된) 적대적 예제를 만들기 어렵다. 최근 일부 연구가 지각적 공격을 다루기 시작했지만, Lp 기반 공격들의 통찰을 지각적 효능 개선에 효과적으로 활용할 수 있는지 불분명하다.

Method: DAASH는 다중 단계로 작동한다. 각 단계에서 여러 기본 Lp 공격으로부터 후보 예제를 모으고, 학습 가능한 적응 가중치로 이들을 집계한 뒤 다음 단계로 전달한다. 메타 손실은 오분류 손실과 지각적 왜곡(예: LPIPS 등)을 함께 최소화하도록 설계되어 각 기본 공격의 기여도를 동적으로 조절한다. 프레임워크는 완전 미분 가능해 엔드-투-엔드 학습이 가능하다.

Result: CIFAR-10/100 및 ImageNet의 적대적 학습(robust) 모델에서 평가했을 때, 단순히 Lp 기반 방법만 조합했음에도 AdvAD 등 기존 지각적 공격을 능가했다. 공격 성공률(예: 약 20.63% 포인트 향상) 및 시각 품질 지표(SSIM 약 +11, LPIPS 약 -0.015, FID 약 -5.7 개선)에서 우수한 성능을 보였다. 또한 미지의 방어에도 일반화되어 각 방어에 맞춘 수작업 적응 공격이 필요 없음을 보였다.

Conclusion: Lp-제약 기반 공격을 메타-학습 방식으로 전략적으로 조합하면 지각적으로 정렬된 강력한 적대적 예제를 만들 수 있다. DAASH는 실용적이고 강력한 평가용 기준선으로 사용될 수 있다.

Abstract: Numerous techniques have been proposed for generating adversarial examples in
white-box settings under strict Lp-norm constraints. However, such norm-bounded
examples often fail to align well with human perception, and only recently have
a few methods begun specifically exploring perceptually aligned adversarial
examples. Moreover, it remains unclear whether insights from Lp-constrained
attacks can be effectively leveraged to improve perceptual efficacy. In this
paper, we introduce DAASH, a fully differentiable meta-attack framework that
generates effective and perceptually aligned adversarial examples by
strategically composing existing Lp-based attack methods. DAASH operates in a
multi-stage fashion: at each stage, it aggregates candidate adversarial
examples from multiple base attacks using learned, adaptive weights and
propagates the result to the next stage. A novel meta-loss function guides this
process by jointly minimizing misclassification loss and perceptual distortion,
enabling the framework to dynamically modulate the contribution of each base
attack throughout the stages. We evaluate DAASH on adversarially trained models
across CIFAR-10, CIFAR-100, and ImageNet. Despite relying solely on
Lp-constrained based methods, DAASH significantly outperforms state-of-the-art
perceptual attacks such as AdvAD -- achieving higher attack success rates
(e.g., 20.63\% improvement) and superior visual quality, as measured by SSIM,
LPIPS, and FID (improvements $\approx$ of 11, 0.015, and 5.7, respectively).
Furthermore, DAASH generalizes well to unseen defenses, making it a practical
and strong baseline for evaluating robustness without requiring handcrafted
adaptive attacks for each new defense.

</details>


### [95] [InfiniteTalk: Audio-driven Video Generation for Sparse-Frame Video Dubbing](https://arxiv.org/abs/2508.14033)
*Shaoshu Yang,Zhe Kong,Feng Gao,Meng Cheng,Xiangyu Liu,Yong Zhang,Zhuoliang Kang,Wenhan Luo,Xunliang Cai,Ran He,Xiaoming Wei*

Main category: cs.CV

TL;DR: Introduce 'sparse-frame video dubbing' and InfiniteTalk, a streaming audio-driven generator that enables infinite-length, full-body, audio-synchronized video dubbing by preserving key reference frames and using temporal context frames plus a sampling strategy for control strength, achieving SOTA on multiple datasets.


<details>
  <summary>Details</summary>
Motivation: Conventional video dubbing focuses only on mouth-region editing, causing mismatched facial expressions and body gestures that break immersion. There is need for holistic full-body, identity-preserving, long-sequence dubbing that maintains iconic gestures and camera trajectories.

Method: Propose sparse-frame video dubbing paradigm and InfiniteTalk architecture: a streaming generator for infinite-length dubbing that leverages temporal context frames for smooth inter-chunk transitions and a simple sampling strategy to optimize control strength via fine-grained reference frame positioning. Also analyze why image-to-video models fail due to lack of adaptive conditioning.

Result: Comprehensive evaluations on HDTF, CelebV-HQ, and EMTD show state-of-the-art performance. Quantitative metrics indicate superior visual realism, emotional coherence, and full-body motion synchronization over baselines.

Conclusion: Sparse-frame dubbing with InfiniteTalk enables holistic, audio-synchronized full-body motion editing while preserving identity and key gestures across infinite-length sequences, overcoming limitations of naive image-to-video approaches and improving viewer immersion.

Abstract: Recent breakthroughs in video AIGC have ushered in a transformative era for
audio-driven human animation. However, conventional video dubbing techniques
remain constrained to mouth region editing, resulting in discordant facial
expressions and body gestures that compromise viewer immersion. To overcome
this limitation, we introduce sparse-frame video dubbing, a novel paradigm that
strategically preserves reference keyframes to maintain identity, iconic
gestures, and camera trajectories while enabling holistic, audio-synchronized
full-body motion editing. Through critical analysis, we identify why naive
image-to-video models fail in this task, particularly their inability to
achieve adaptive conditioning. Addressing this, we propose InfiniteTalk, a
streaming audio-driven generator designed for infinite-length long sequence
dubbing. This architecture leverages temporal context frames for seamless
inter-chunk transitions and incorporates a simple yet effective sampling
strategy that optimizes control strength via fine-grained reference frame
positioning. Comprehensive evaluations on HDTF, CelebV-HQ, and EMTD datasets
demonstrate state-of-the-art performance. Quantitative metrics confirm superior
visual realism, emotional coherence, and full-body motion synchronization.

</details>


### [96] [GeoSAM2: Unleashing the Power of SAM2 for 3D Part Segmentation](https://arxiv.org/abs/2508.14036)
*Ken Deng,Yunhan Yang,Jingxiang Sun,Xihui Liu,Yebin Liu,Ding Liang,Yan-Pei Cao*

Main category: cs.CV

TL;DR: DetailGen3D는 데이터 의존적(latent-space) 플로우와 토큰 매칭을 이용해 거친 3D 출력물을 고해상도 디테일로 정제하는 효율적인 생성적 접근법이다. 대규모 3D 생성 모델을 사용하지 않고도 지역적 기하학적 디테일을 합성하면서 전역 구조를 보존한다.


<details>
  <summary>Details</summary>
Motivation: 현대의 3D 생성/재구성 기법은 희소 또는 단일 뷰에서 빠르게 형태를 만들어내지만 계산 제약 때문에 기하학적 세부가 부족하다. 이러한 출력물을 효율적으로 고해상도로 향상시킬 방법이 필요하다.

Method: 거칠게부터 정밀하게(coarse-to-fine) 변환을 잠재공간(latent space)에서 데이터 의존적 플로우로 직접 모델링한다. 정제 과정에서 공간적 대응을 보장하는 토큰 매칭 전략을 도입해 전역 구조를 유지하면서 지역 디테일을 합성한다. 또한 합성된 거친 형태의 특성에 맞춰 학습 데이터를 설계해 다양한 상위(업스트림) 생성/재구성 방법들에서 잘 동작하도록 한다.

Result: 광범위한 실험에서 높은 충실도의 기하학적 디테일 합성을 달성했으며 학습 효율성도 유지되었다. 단일 뷰부터 희소 다중 뷰까지 다양한 입력 방식으로 생성된 형태를 효과적으로 향상시켰다.

Conclusion: DetailGen3D는 큰 3D 모델을 사용하지 않고도 거친 3D 출력의 지역적 디테일을 효과적으로 합성하여 전역 구조를 보존하는 효율적인 후처리(정제) 솔루션을 제공한다.

Abstract: Modern 3D generation methods can rapidly create shapes from sparse or single
views, but their outputs often lack geometric detail due to computational
constraints. We present DetailGen3D, a generative approach specifically
designed to enhance these generated 3D shapes. Our key insight is to model the
coarse-to-fine transformation directly through data-dependent flows in latent
space, avoiding the computational overhead of large-scale 3D generative models.
We introduce a token matching strategy that ensures accurate spatial
correspondence during refinement, enabling local detail synthesis while
preserving global structure. By carefully designing our training data to match
the characteristics of synthesized coarse shapes, our method can effectively
enhance shapes produced by various 3D generation and reconstruction approaches,
from single-view to sparse multi-view inputs. Extensive experiments demonstrate
that DetailGen3D achieves high-fidelity geometric detail synthesis while
maintaining efficiency in training.

</details>


### [97] [Distilled-3DGS:Distilled 3D Gaussian Splatting](https://arxiv.org/abs/2508.14037)
*Lintao Xiang,Xinkai Chen,Jianhuang Lai,Guangcong Wang*

Main category: cs.CV

TL;DR: Distilled-3DGS는 3D Gaussian Splatting(3DGS)의 고품질 렌더링을 유지하면서 가우시안 수를 줄여 메모리·저장 효율을 개선하기 위해 고안된 지식 증류 프레임워크다. 여러 종류의 교사 모델(기본 3DGS, 노이즈 증강, 드롭아웃 정규화)을 앙상블로 사용하고, 학생 모델 학습을 위해 구조적 유사성 손실로 공간적 기하 분포를 일치시킨다. 평가 결과 렌더링 품질과 저장 효율에서 유망한 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 3DGS는 새로운 시점 합성에서 우수한 성능을 보이나, 고해상도·고충실도를 위해 많은 수의 3D 가우시안이 필요해 메모리·저장 부담이 크다. 이를 경감하면서 품질을 유지할 방법이 필요하다.

Method: 여러 타입의 교사 모델(바닐라 3DGS, 노이즈 증강 변형, 드롭아웃 정규화 변형)을 학습시켜 출력을 집계한 뒤, 경량 학생 모델을 지도 학습한다. 은닉된 기하 구조를 전이하기 위해 학생과 교사 간의 공간적 기하 분포 일치를 촉진하는 구조적 유사성 손실(structural similarity loss)을 제안한다.

Result: 다양한 데이터셋에 대한 정량·정성 평가에서 Distilled-3DGS는 단순한 구조에도 불구하고 렌더링 품질과 저장 효율 면에서 경쟁력 있는 성능을 달성했으며, 기존 최첨단 기법들과 비교해 유망한 결과를 보였다.

Conclusion: 지식 증류와 구조적 유사성 손실을 결합한 Distilled-3DGS는 복잡한 추가 기법 없이도 3DGS의 저장 요구를 낮추면서도 높은 렌더링 품질을 유지할 수 있는 실용적 접근법을 제시한다.

Abstract: 3D Gaussian Splatting (3DGS) has exhibited remarkable efficacy in novel view
synthesis (NVS). However, it suffers from a significant drawback: achieving
high-fidelity rendering typically necessitates a large number of 3D Gaussians,
resulting in substantial memory consumption and storage requirements. To
address this challenge, we propose the first knowledge distillation framework
for 3DGS, featuring various teacher models, including vanilla 3DGS,
noise-augmented variants, and dropout-regularized versions. The outputs of
these teachers are aggregated to guide the optimization of a lightweight
student model. To distill the hidden geometric structure, we propose a
structural similarity loss to boost the consistency of spatial geometric
distributions between the student and teacher model. Through comprehensive
quantitative and qualitative evaluations across diverse datasets, the proposed
Distilled-3DGS, a simple yet effective framework without bells and whistles,
achieves promising rendering results in both rendering quality and storage
efficiency compared to state-of-the-art methods. Project page:
https://distilled3dgs.github.io . Code:
https://github.com/lt-xiang/Distilled-3DGS .

</details>


### [98] [Vision Transformers for Kidney Stone Image Classification: A Comparative Study with CNNs](https://arxiv.org/abs/2508.13461)
*Ivan Reyes-Amezcua,Francisco Lopez-Tiro,Clement Larose,Andres Mendez-Vazquez,Gilberto Ochoa-Ruiz,Christian Daul*

Main category: cs.CV

TL;DR: ViT 기반 모델(ImageNet-21k로 사전학습)이 ResNet50보다 신장 결석 내시경 이미지 분류에서 전반적으로 우수하며, 특히 시각적 복잡도가 높은 부분에서 큰 성능 격차를 보임.


<details>
  <summary>Details</summary>
Motivation: 신장 결석의 유형 분류는 맞춤 치료와 재발 방지에 중요하지만, 기존 CNN은 장거리 의존성 포착에 한계가 있어 다양한 촬영 조건에서 성능이 저하될 수 있음.

Method: (중요 지점) 섹션 패치 등 시각적 복잡도가 높은 하위집합과 CCD 혼합뷰 하위집합을 포함한 다양한 조건에서 실험.

Result: ViT-base가 모든 조건에서 ResNet50을 능가. 예: 섹션 패치 하위집합에서 ViT 95.2% 정확도/95.1% F1 vs ResNet50 64.5%/59.3%. CCD 혼합뷰에서는 ViT 87.1% vs CNN 78.4%. 정밀도·재현율에서도 향상 보고.

Conclusion: ViT 계열 아키텍처가 내시경 신장 결석 이미지 분류에 대해 CNN보다 우수하며, 확장성 있는 대안으로 제시됨.

Abstract: Kidney stone classification from endoscopic images is critical for
personalized treatment and recurrence prevention. While convolutional neural
networks (CNNs) have shown promise in this task, their limited ability to
capture long-range dependencies can hinder performance under variable imaging
conditions. This study presents a comparative analysis between Vision
Transformers (ViTs) and CNN-based models, evaluating their performance on two
ex vivo datasets comprising CCD camera and flexible ureteroscope images. The
ViT-base model pretrained on ImageNet-21k consistently outperformed a ResNet50
baseline across multiple imaging conditions. For instance, in the most visually
complex subset (Section patches from endoscopic images), the ViT model achieved
95.2% accuracy and 95.1% F1-score, compared to 64.5% and 59.3% with ResNet50.
In the mixed-view subset from CCD-camera images, ViT reached 87.1% accuracy
versus 78.4% with CNN. These improvements extend across precision and recall as
well. The results demonstrate that ViT-based architectures provide superior
classification performance and offer a scalable alternative to conventional
CNNs for kidney stone image analysis.

</details>


### [99] [Beyond Simple Edits: Composed Video Retrieval with Dense Modifications](https://arxiv.org/abs/2508.14039)
*Omkar Thawakar,Dmitry Demidov,Ritesh Thawkar,Rao Muhammad Anwer,Mubarak Shah,Fahad Shahbaz Khan,Salman Khan*

Main category: cs.CV

TL;DR: 


<details>
  <summary>Details</summary>
Motivation: 

Method: 

Result: 

Conclusion: 

Abstract: Composed video retrieval is a challenging task that strives to retrieve a
target video based on a query video and a textual description detailing
specific modifications. Standard retrieval frameworks typically struggle to
handle the complexity of fine-grained compositional queries and variations in
temporal understanding limiting their retrieval ability in the fine-grained
setting. To address this issue, we introduce a novel dataset that captures both
fine-grained and composed actions across diverse video segments, enabling more
detailed compositional changes in retrieved video content. The proposed
dataset, named Dense-WebVid-CoVR, consists of 1.6 million samples with dense
modification text that is around seven times more than its existing
counterpart. We further develop a new model that integrates visual and textual
information through Cross-Attention (CA) fusion using grounded text encoder,
enabling precise alignment between dense query modifications and target videos.
The proposed model achieves state-of-the-art results surpassing existing
methods on all metrics. Notably, it achieves 71.3\% Recall@1 in visual+text
setting and outperforms the state-of-the-art by 3.4\%, highlighting its
efficacy in terms of leveraging detailed video descriptions and dense
modification texts. Our proposed dataset, code, and model are available at
:https://github.com/OmkarThawakar/BSE-CoVR

</details>


### [100] [Multi-view Clustering via Bi-level Decoupling and Consistency Learning](https://arxiv.org/abs/2508.13499)
*Shihao Dong,Yuhui Zheng,Huiying Xu,Xinzhong Zhu*

Main category: cs.CV

TL;DR: BDCL은 멀티뷰 데이터에서 특성의 군집 간 판별력(inter-cluster discriminability)과 군집 내 응집력(intra-cluster compactness)을 동시에 향상시키기 위해, 인스턴스 정렬·비공유 특징 보존, 특징·클러스터의 이중 분해(bi-level decoupling), 그리고 뷰와 이웃을 양성 쌍으로 하는 할당 일관성 학습을 결합한 새로운 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 기존 멀티뷰 클러스터링은 뷰 간 일관성(consistency)과 상보성(complementarity)을 학습해 성능을 끌어올렸지만, 클러스터 지향의 표현 학습(cluster-oriented representation learning)은 간과되는 경우가 많아 군집 간 분별성과 군집 내 응집력을 동시에 개선할 필요가 있다.

Method: BDCL은 세 모듈로 구성된다: (1) 멀티뷰 인스턴스 학습 모듈 — 재구성 오토인코더와 대조학습으로 뷰 간의 공통 정보는 정렬하고 사적(private) 특징은 보존; (2) 특징과 클러스터의 이중 분해 — 피처 공간과 클러스터 공간을 분리해 판별성 향상; (3) 일관성 학습 모듈 — 샘플의 서로 다른 뷰와 그 이웃을 양성 쌍으로 취급하여 클러스터 할당의 일관성을 학습하고 군집 내 공간을 추가로 압축.

Result: 다섯 개의 벤치마크 데이터셋에서 SOTA 대비 우수한 성능을 보였으며, 코드가 공개되어 재현 가능함.

Conclusion: 뷰 간 정렬과 사적 특징 보존, 이중 분해, 그리고 클러스터 할당 일관성 학습의 결합으로 멀티뷰 클러스터링에서 더 구별력 있는 표현과 더 응집된 군집을 얻을 수 있음을 보였다.

Abstract: Multi-view clustering has shown to be an effective method for analyzing
underlying patterns in multi-view data. The performance of clustering can be
improved by learning the consistency and complementarity between multi-view
features, however, cluster-oriented representation learning is often
overlooked. In this paper, we propose a novel Bi-level Decoupling and
Consistency Learning framework (BDCL) to further explore the effective
representation for multi-view data to enhance inter-cluster discriminability
and intra-cluster compactness of features in multi-view clustering. Our
framework comprises three modules: 1) The multi-view instance learning module
aligns the consistent information while preserving the private features between
views through reconstruction autoencoder and contrastive learning. 2) The
bi-level decoupling of features and clusters enhances the discriminability of
feature space and cluster space. 3) The consistency learning module treats the
different views of the sample and their neighbors as positive pairs, learns the
consistency of their clustering assignments, and further compresses the
intra-cluster space. Experimental results on five benchmark datasets
demonstrate the superiority of the proposed method compared with the SOTA
methods. Our code is published on https://github.com/LouisDong95/BDCL.

</details>


### [101] [Mitigating Cross-Image Information Leakage in LVLMs for Multi-Image Tasks](https://arxiv.org/abs/2508.13744)
*Yeji Park,Minyoung Lee,Sanghyuk Chun,Junsuk Choe*

Main category: cs.CV

TL;DR: FOCUS는 추가 학습·구조 변경 없이 다중 이미지 입력에서 발생하는 ‘교차 이미지 정보 누수’를 줄이는 추론 단계 디코딩 전략이다. 각 반복에서 한 장의 이미지만 깨끗하게 유지하고 나머지는 무작위 노이즈로 마스킹한 뒤, 얻은 로짓들을 집계하고 노이즈 전용 참조와 대비적으로 정제해 정확도를 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 대형 비전-언어 모델들은 단일 이미지 과제에서는 우수하지만, 다중 이미지 입력에서는 서로 다른 이미지의 시각적 단서가 출력에서 뒤섞여 성능이 크게 저하된다(교차 이미지 정보 누수 문제). 이 문제는 모델 구조 변경이나 추가 학습 없이도 해결 가능한 실용적 방법이 필요하다.

Method: FOCUS는 학습이 필요 없는 디코딩 기법으로, 목표 이미지 하나를 제외한 모든 이미지를 무작위 노이즈로 마스킹하여 모델이 해당 한 장에 집중하도록 유도한다. 이 과정을 모든 타깃 이미지에 대해 반복해 부분 마스킹된 문맥에서의 로짓을 얻고, 이 로짓들을 집계한 뒤 노이즈 전용 입력에서 얻은 참조와 대비적으로 정제하여 누수를 억제한다.

Result: FOCUS는 네 가지 다중 이미지 벤치마크와 다양한 LVLM 계열에서 일관되게 성능을 향상시켰다. 추가 학습이나 아키텍처 변경 없이도 다중 이미지 추론 능력을 개선하는 효과를 보였다.

Conclusion: FOCUS는 일반적이고 실용적인 해결책으로, 별도 훈련이나 구조 수정 없이도 다중 이미지 상황에서의 정보 누수를 줄여 LVLM의 추론 정확도를 높인다.

Abstract: Large Vision-Language Models (LVLMs) demonstrate strong performance on
single-image tasks. However, we observe that their performance degrades
significantly when handling multi-image inputs. This occurs because visual cues
from different images become entangled in the model's output. We refer to this
phenomenon as cross-image information leakage. To address this issue, we
propose FOCUS, a training-free and architecture-agnostic decoding strategy that
mitigates cross-image information leakage during inference. FOCUS sequentially
masks all but one image with random noise, guiding the model to focus on the
single clean image. We repeat this process across all target images to obtain
logits under partially masked contexts. These logits are aggregated and then
contrastively refined using a noise-only reference input, which suppresses the
leakage and yields more accurate outputs. FOCUS consistently improves
performance across four multi-image benchmarks and diverse LVLM families. This
demonstrates that FOCUS offers a general and practical solution for enhancing
multi-image reasoning without additional training or architectural
modifications.

</details>


### [102] [LongSplat: Robust Unposed 3D Gaussian Splatting for Casual Long Videos](https://arxiv.org/abs/2508.14041)
*Chin-Yang Lin,Cheng Sun,Fu-En Yang,Min-Hung Chen,Yen-Yu Lin,Yu-Lun Liu*

Main category: cs.CV

TL;DR: LongSplat은 장기간의 임의 카메라 움직임과 알려지지 않은 카메라 포즈, 넓은 장면을 가진 긴 비디오에서의 새로운 뷰 합성을 다루는 프레임워크다. 증강된 카메라 포즈 추정, 3D Gaussian Splatting의 점진적 공동 최적화, 옥트리 기반 앵커 형성으로 향상된 품질과 효율을 달성한다.


<details>
  <summary>Details</summary>
Motivation: 긴, 캐주얼하게 촬영된 비디오에서는 불규칙한 카메라 움직임과 알려지지 않은 포즈, 광범위한 장면 규모 때문에 기존 NVS(새로운 뷰 합성) 방법들이 포즈 드리프트, 부정확한 기하학 초기화, 메모리 제약 등 문제를 겪는다. 이를 해결하기 위한 강건한 방법이 필요하다.

Method: LongSplat은 세 가지 핵심 구성요소를 제안한다: (1) Incremental Joint Optimization: 카메라 포즈와 3D 가우시안을 동시에 점진적으로 최적화하여 지역 최소값을 피하고 전역 일관성을 확보한다. (2) Pose Estimation Module: 학습된 3D 프라이어를 활용한 강건한 포즈 추정. (3) Octree Anchor Formation: 공간 밀도 기반으로 조밀한 포인트 클라우드를 옥트리 앵커로 변환하여 메모리와 계산 효율을 높인다.

Result: 다양한 어려운 벤치마크에서 LongSplat은 기존 방법들보다 렌더링 품질, 포즈 정확도, 계산 효율성 면에서 유의미하게 개선된 SOTA 성능을 보였다.

Conclusion: 점진적 공동 최적화, 학습 기반 포즈 추정, 옥트리 앵커 기법의 결합으로 LongSplat은 긴 비디오에서의 unposed 3D Gaussian Splatting을 통해 보다 정확하고 효율적인 NVS를 달성한다.

Abstract: LongSplat addresses critical challenges in novel view synthesis (NVS) from
casually captured long videos characterized by irregular camera motion, unknown
camera poses, and expansive scenes. Current methods often suffer from pose
drift, inaccurate geometry initialization, and severe memory limitations. To
address these issues, we introduce LongSplat, a robust unposed 3D Gaussian
Splatting framework featuring: (1) Incremental Joint Optimization that
concurrently optimizes camera poses and 3D Gaussians to avoid local minima and
ensure global consistency; (2) a robust Pose Estimation Module leveraging
learned 3D priors; and (3) an efficient Octree Anchor Formation mechanism that
converts dense point clouds into anchors based on spatial density. Extensive
experiments on challenging benchmarks demonstrate that LongSplat achieves
state-of-the-art results, substantially improving rendering quality, pose
accuracy, and computational efficiency compared to prior approaches. Project
page: https://linjohnss.github.io/longsplat/

</details>


### [103] [A Fully Transformer Based Multimodal Framework for Explainable Cancer Image Segmentation Using Radiology Reports](https://arxiv.org/abs/2508.13796)
*Enobong Adahada,Isabel Sassoon,Kate Hone,Yongmin Li*

Main category: cs.CV

TL;DR: 


<details>
  <summary>Details</summary>
Motivation: 

Method: 

Result: 

Conclusion: 

Abstract: We introduce Med-CTX, a fully transformer based multimodal framework for
explainable breast cancer ultrasound segmentation. We integrate clinical
radiology reports to boost both performance and interpretability. Med-CTX
achieves exact lesion delineation by using a dual-branch visual encoder that
combines ViT and Swin transformers, as well as uncertainty aware fusion.
Clinical language structured with BI-RADS semantics is encoded by
BioClinicalBERT and combined with visual features utilising cross-modal
attention, allowing the model to provide clinically grounded, model generated
explanations. Our methodology generates segmentation masks, uncertainty maps,
and diagnostic rationales all at once, increasing confidence and transparency
in computer assisted diagnosis. On the BUS-BRA dataset, Med-CTX achieves a Dice
score of 99% and an IoU of 95%, beating existing baselines U-Net, ViT, and
Swin. Clinical text plays a key role in segmentation accuracy and explanation
quality, as evidenced by ablation studies that show a -5.4% decline in Dice
score and -31% in CIDEr. Med-CTX achieves good multimodal alignment (CLIP
score: 85%) and increased confi dence calibration (ECE: 3.2%), setting a new
bar for trustworthy, multimodal medical architecture.

</details>


### [104] [The 9th AI City Challenge](https://arxiv.org/abs/2508.13564)
*Zheng Tang,Shuo Wang,David C. Anastasiu,Ming-Ching Chang,Anuj Sharma,Quan Kong,Norimasa Kobori,Munkhjargal Gochoo,Ganzorig Batnasan,Munkh-Erdene Otgonbold,Fady Alnajjar,Jun-Wei Hsieh,Tomasz Kornuta,Xiaolong Li,Yilin Zhao,Han Zhang,Subhashree Radhakrishnan,Arihant Jain,Ratnesh Kumar,Vidya N. Murali,Yuxing Wang,Sameer Satish Pusegaonkar,Yizhou Wang,Sujit Biswas,Xunlei Wu,Zhedong Zheng,Pranamesh Chakraborty,Rama Chellappa*

Main category: cs.CV

TL;DR: 9th AI City Challenge (2025) ran four tracks addressing multi-class 3D multi-camera tracking, traffic video question answering with 3D gaze, fine-grained spatial reasoning in RGB-D warehouse scenes, and efficient fisheye road-object detection. Participation rose 17% to 245 teams from 15 countries; datasets were publicly released and downloaded >30,000 times. Evaluation used submission limits and a partially held-out test set to ensure fairness and reproducibility; top teams set new benchmarks.


<details>
  <summary>Details</summary>
Motivation: Advance practical computer-vision and AI for transportation, industrial automation, and public safety; create challenging multi-modal benchmarks and encourage reproducible, fair evaluation.

Method: Four specialized tracks with rich annotations (3D bounding boxes, 3D gaze, RGB-D), synthetic data generation in NVIDIA Omniverse for Tracks 1 and 3, multi-camera calibration, fisheye-specific datasets for edge deployment, and an evaluation framework with submission caps and partially held-out test data.

Result: 17% increase in participation (245 teams, 15 countries), >30k dataset downloads, multiple teams achieved top-tier results setting new benchmarks across tasks, and final rankings released to mitigate overfitting and support reproducibility.

Conclusion: The challenge pushed state-of-the-art in diverse, deployment-oriented CV tasks, produced valuable public datasets and benchmarks, and emphasized fair, reproducible evaluation practices for real-world applications.

Abstract: The ninth AI City Challenge continues to advance real-world applications of
computer vision and AI in transportation, industrial automation, and public
safety. The 2025 edition featured four tracks and saw a 17% increase in
participation, with 245 teams from 15 countries registered on the evaluation
server. Public release of challenge datasets led to over 30,000 downloads to
date. Track 1 focused on multi-class 3D multi-camera tracking, involving
people, humanoids, autonomous mobile robots, and forklifts, using detailed
calibration and 3D bounding box annotations. Track 2 tackled video question
answering in traffic safety, with multi-camera incident understanding enriched
by 3D gaze labels. Track 3 addressed fine-grained spatial reasoning in dynamic
warehouse environments, requiring AI systems to interpret RGB-D inputs and
answer spatial questions that combine perception, geometry, and language. Both
Track 1 and Track 3 datasets were generated in NVIDIA Omniverse. Track 4
emphasized efficient road object detection from fisheye cameras, supporting
lightweight, real-time deployment on edge devices. The evaluation framework
enforced submission limits and used a partially held-out test set to ensure
fair benchmarking. Final rankings were revealed after the competition
concluded, fostering reproducibility and mitigating overfitting. Several teams
achieved top-tier results, setting new benchmarks in multiple tasks.

</details>


### [105] [Unsupervised Urban Tree Biodiversity Mapping from Street-Level Imagery Using Spatially-Aware Visual Clustering](https://arxiv.org/abs/2508.13814)
*Diaa Addeen Abuhani,Marco Seccaroni,Martina Mazzarello,Imran Zualkernan,Fabio Duarte,Carlo Ratti*

Main category: cs.CV

TL;DR: 감시 데이터 없이 거리 사진의 시각적 임베딩과 식재의 공간적 패턴을 비지도 클러스터링으로 통합해 도시 수목의 속 수준(biodiversity)을 추정하는 방법을 제시. 8개 북미 도시에서 샤논·심슨 지수와 공간적 자기상관을 잘 복원함.


<details>
  <summary>Details</summary>
Motivation: 대부분 지방자치단체는 도시 수관(나무) 관행과 종 분포에 대한 상세한 현장조사 자료가 부족하고, 현장조사는 비용과 시간이 많이 듦. 지도 학습 기반 AI는 라벨이 필요하고 지역간 일반화에 실패하기 쉬움. 라벨 없이 확장 가능하고 저비용의 모니터링 방법 필요.

Method: 거리 수준(street-level) 이미지에서 추출한 시각적 임베딩을 사용하고, 식재의 공간적 패턴 정보를 결합한 비지도 클러스터링 프레임워크를 개발. 클러스터를 통해 속(Genus) 수준의 그룹화를 유도하고, 이를 기반으로 샤논·심슨 다양성 지수와 공간적 자기상관을 추정.

Result: 8개 북미 도시 적용에서 속 수준 다양성 패턴을 높은 충실도로 재현. 샤논·심슨 지수의 지구간 분포가 실제 관측치와의 Wasserstein 거리 측면에서 낮은 차이를 보였고, 공간적 자기상관도 보존됨.

Conclusion: 라벨없는 스케일러블하고 세분화된 접근으로, 상세한 재고가 없는 도시에서도 생물다양성 지도를 작성하고 저비용·지속적 모니터링을 가능하게 하여 형평성 있는 녹지 접근성과 도시 생태계 적응관리 지원 가능성 제시.

Abstract: Urban tree biodiversity is critical for climate resilience, ecological
stability, and livability in cities, yet most municipalities lack detailed
knowledge of their canopies. Field-based inventories provide reliable estimates
of Shannon and Simpson diversity but are costly and time-consuming, while
supervised AI methods require labeled data that often fail to generalize across
regions. We introduce an unsupervised clustering framework that integrates
visual embeddings from street-level imagery with spatial planting patterns to
estimate biodiversity without labels. Applied to eight North American cities,
the method recovers genus-level diversity patterns with high fidelity,
achieving low Wasserstein distances to ground truth for Shannon and Simpson
indices and preserving spatial autocorrelation. This scalable, fine-grained
approach enables biodiversity mapping in cities lacking detailed inventories
and offers a pathway for continuous, low-cost monitoring to support equitable
access to greenery and adaptive management of urban ecosystems.

</details>


### [106] [RotBench: Evaluating Multimodal Large Language Models on Identifying Image Rotation](https://arxiv.org/abs/2508.13968)
*Tianyi Niu,Jaemin Cho,Elias Stengel-Eskin,Mohit Bansal*

Main category: cs.CV

TL;DR: The paper introduces RotBench, a 350-image benchmark to test Multimodal LLMs' ability to detect image rotations (0°, 90°, 180°, 270°). Many state-of-the-art models (including GPT-5, o3, Gemini-2.5-Pro) fail to reliably identify rotations: 0° is usually recognized, 180° sometimes, but 90° vs 270° is not distinguished. Auxiliary inputs and prompting give small inconsistent gains; multi-orientation display and voting help moderately; fine-tuning improves 180° detection but not 90°/270°. Overall, there is a notable spatial reasoning gap.


<details>
  <summary>Details</summary>
Motivation: To measure how well MLLMs perform basic spatial reasoning: specifically, identifying image orientation among four cardinal rotations—a seemingly simple perceptual task that probes models' ability to detect rotational cues and contextual spatial relationships.

Method: (Duplicate field corrected)

Result: Most models reliably identify upright (0°) images; some detect upside-down (180°); none reliably distinguish 90° vs 270°. Auxiliary information and chain-of-thought give small/inconsistent improvements. Showing multiple orientations improves reasoning models moderately; voting helps weaker models. Fine-tuning substantially improves 180° detection but not 90°/270° discrimination.

Conclusion: There is a significant gap between MLLMs' spatial reasoning and human perception for rotation detection. Current architectures/approaches struggle with orientation-specific cues, especially between left/right (90° vs 270°). New methods or focused training/data are needed to close this gap.

Abstract: We investigate to what extent Multimodal Large Language Models (MLLMs) can
accurately identify the orientation of input images rotated 0{\deg}, 90{\deg},
180{\deg}, and 270{\deg}. This task demands robust visual reasoning
capabilities to detect rotational cues and contextualize spatial relationships
within images, regardless of their orientation. To evaluate MLLMs on these
abilities, we introduce RotBench -- a 350-image manually-filtered benchmark
comprising lifestyle, portrait, and landscape images. Despite the relatively
simple nature of this task, we show that several state-of-the-art open and
proprietary MLLMs, including GPT-5, o3, and Gemini-2.5-Pro, do not reliably
identify rotation in input images. Providing models with auxiliary information
-- including captions, depth maps, and more -- or using chain-of-thought
prompting offers only small and inconsistent improvements. Our results indicate
that most models are able to reliably identify right-side-up (0{\deg}) images,
while certain models are able to identify upside-down (180{\deg}) images. None
can reliably distinguish between 90{\deg} and 270{\deg}. Simultaneously showing
the image rotated in different orientations leads to moderate performance gains
for reasoning models, while a modified setup using voting improves the
performance of weaker models. We further show that fine-tuning does not improve
models' ability to distinguish 90{\deg} and 270{\deg} rotations, despite
substantially improving the identification of 180{\deg} images. Together, these
results reveal a significant gap between MLLMs' spatial reasoning capabilities
and human perception in identifying rotation.

</details>


### [107] [GeoSAM2: Unleashing the Power of SAM2 for 3D Part Segmentation](https://arxiv.org/abs/2508.14036)
*Ken Deng,Yunhan Yang,Jingxiang Sun,Xihui Liu,Yebin Liu,Ding Liang,Yan-Pei Cao*

Main category: cs.CV

TL;DR: DetailGen3D는 데이터 의존적(latent-space) 플로우와 토큰 매칭을 이용해 거친 3D 출력물을 고해상도 디테일로 정제하는 효율적인 생성적 접근법이다. 대규모 3D 생성 모델을 사용하지 않고도 지역적 기하학적 디테일을 합성하면서 전역 구조를 보존한다.


<details>
  <summary>Details</summary>
Motivation: 현대의 3D 생성/재구성 기법은 희소 또는 단일 뷰에서 빠르게 형태를 만들어내지만 계산 제약 때문에 기하학적 세부가 부족하다. 이러한 출력물을 효율적으로 고해상도로 향상시킬 방법이 필요하다.

Method: 거칠게부터 정밀하게(coarse-to-fine) 변환을 잠재공간(latent space)에서 데이터 의존적 플로우로 직접 모델링한다. 정제 과정에서 공간적 대응을 보장하는 토큰 매칭 전략을 도입해 전역 구조를 유지하면서 지역 디테일을 합성한다. 또한 합성된 거친 형태의 특성에 맞춰 학습 데이터를 설계해 다양한 상위(업스트림) 생성/재구성 방법들에서 잘 동작하도록 한다.

Result: 광범위한 실험에서 높은 충실도의 기하학적 디테일 합성을 달성했으며 학습 효율성도 유지되었다. 단일 뷰부터 희소 다중 뷰까지 다양한 입력 방식으로 생성된 형태를 효과적으로 향상시켰다.

Conclusion: DetailGen3D는 큰 3D 모델을 사용하지 않고도 거친 3D 출력의 지역적 디테일을 효과적으로 합성하여 전역 구조를 보존하는 효율적인 후처리(정제) 솔루션을 제공한다.

Abstract: Modern 3D generation methods can rapidly create shapes from sparse or single
views, but their outputs often lack geometric detail due to computational
constraints. We present DetailGen3D, a generative approach specifically
designed to enhance these generated 3D shapes. Our key insight is to model the
coarse-to-fine transformation directly through data-dependent flows in latent
space, avoiding the computational overhead of large-scale 3D generative models.
We introduce a token matching strategy that ensures accurate spatial
correspondence during refinement, enabling local detail synthesis while
preserving global structure. By carefully designing our training data to match
the characteristics of synthesized coarse shapes, our method can effectively
enhance shapes produced by various 3D generation and reconstruction approaches,
from single-view to sparse multi-view inputs. Extensive experiments demonstrate
that DetailGen3D achieves high-fidelity geometric detail synthesis while
maintaining efficiency in training.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [108] [Fair Play in the Newsroom: Actor-Based Filtering Gender Discrimination in Text Corpora](https://arxiv.org/abs/2508.13169)
*Stefanie Urchs,Veronika Thurner,Matthias Aßenmacher,Christian Heumann,Stephanie Thiemichen*

Main category: cs.CL

TL;DR: 이 논문은 대규모 텍스트 말뭉치에서 성별 불균형을 진단하고 완화하기 위한 확장된 행위자(actor)-수준 파이프라인을 제안한다. 감정, 통사적 주체성(agency), 인용 스타일의 비대칭을 측정하는 새로운 메트릭을 도입하고 이를 이용해 진단적 분석과 배제 기반 재균형(exclusion-based balancing)을 수행한다. taz2024full(1980–2024 독일 신문 기사) 말뭉치에 적용한 결과, 표면적 불균형은 필터링과 재균형으로 크게 감소하지만 감정과 프레이밍 같은 미묘한 편향은 여전히 남아있음을 보였다. 도구와 보고서를 공개한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델 및 교육 데이터에 존재하는 성별 구조적 불균형이 모델 출력에 반영되어 디지털 커뮤니케이션의 공정성에 문제를 일으키므로, 텍스트 말뭉치 수준에서의 진단과 완화가 필요하다. 기존 담화 인식 공정성 분석을 확장해 행위자 수준에서 불균형을 더 정교하게 측정하고 수정하고자 한다.

Method: 행위자 수준의 새로운 메트릭(감정의 비대칭, 통사적 주체성, 인용 스타일)을 도입하고, 이를 이용한 파이프라인을 제시한다. 파이프라인은 진단적 말뭉치 분석과 배제 기반 재균형을 지원한다. taz2024full 말뭉치(1980–2024 독일 신문 기사)를 대상으로 메트릭을 계산하고 필터링/재균형 전략을 적용하여 공정성 지표 변화를 평가한다.

Result: 여러 언어적 차원(감정, 주체성, 인용 스타일 등)에 대한 성별 불균형이 확인되었고, 표면적 지표는 필터링과 재균형으로 상당히 개선되었다. 그러나 감정과 프레이밍 등 보다 미묘한 편향은 완전히 제거되지 않았다. 도구와 분석 보고서를 공개하여 후속 연구를 지원함.

Conclusion: 행위자 수준의 담화 기반 공정성 분석 및 배제 기반 재균형은 말뭉치의 명시적 불균형을 줄이는 데 유효하지만, 감정·프레이밍과 같은 심층적 편향은 지속된다. 따라서 공정한 말뭉치 구축에는 다층적 진단 및 추가적 완화 전략이 필요하다.

Abstract: Large language models are increasingly shaping digital communication, yet
their outputs often reflect structural gender imbalances that originate from
their training data. This paper presents an extended actor-level pipeline for
detecting and mitigating gender discrimination in large-scale text corpora.
Building on prior work in discourse-aware fairness analysis, we introduce new
actor-level metrics that capture asymmetries in sentiment, syntactic agency,
and quotation styles. The pipeline supports both diagnostic corpus analysis and
exclusion-based balancing, enabling the construction of fairer corpora. We
apply our approach to the taz2024full corpus of German newspaper articles from
1980 to 2024, demonstrating substantial improvements in gender balance across
multiple linguistic dimensions. Our results show that while surface-level
asymmetries can be mitigated through filtering and rebalancing, subtler forms
of bias persist, particularly in sentiment and framing. We release the tools
and reports to support further research in discourse-based fairness auditing
and equitable corpus construction.

</details>


### [109] [MM-BrowseComp: A Comprehensive Benchmark for Multimodal Browsing Agents](https://arxiv.org/abs/2508.13186)
*Shilong Li,Xingyuan Bu,Wenjie Wang,Jiaheng Liu,Jun Dong,Haoyang He,Hao Lu,Haozhe Zhang,Chenchen Jing,Zhen Li,Chuanhao Li,Jiayi Tian,Chenchen Zhang,Tianhao Peng,Yancheng He,Jihao Gu,Yuanxing Zhang,Jian Yang,Ge Zhang,Wenhao Huang,Wangchunshu Zhou,Zhaoxiang Zhang,Ruizhe Ding,Shilei Wen*

Main category: cs.CL

TL;DR: Introduces MM-BrowseComp, a 224-question benchmark for multimodal web browsing; SOTA models perform poorly (OpenAI o3 with tools: 29.02% accuracy).


<details>
  <summary>Details</summary>
Motivation: Existing browsing benchmarks focus on text-only content and ignore images/videos on webpages that often contain crucial information; need to evaluate multimodal retrieval and reasoning.

Method: Construct 224 hand-crafted, challenging questions that include images in prompts and expect agents to retrieve and reason about multimodal content; provide verified checklist per question for fine-grained analysis of multimodal dependencies and reasoning paths; evaluate state-of-the-art models (e.g., OpenAI o3 with tools).

Result: State-of-the-art models show low performance on MM-BrowseComp; OpenAI o3 with tools achieves only 29.02% accuracy, demonstrating shortcomings in multimodal retrieval and native multimodal reasoning.

Conclusion: Current models lack robust native multimodal reasoning; MM-BrowseComp fills a gap by benchmarking multimodal web browsing and should drive development of better multimodal agents.

Abstract: AI agents with advanced reasoning and tool use capabilities have demonstrated
impressive performance in web browsing for deep search. While existing
benchmarks such as BrowseComp evaluate these browsing abilities, they primarily
focus on textual information, overlooking the prevalence of multimodal content.
To bridge this gap, we introduce MM-BrowseComp, a novel benchmark comprising
224 challenging, hand-crafted questions specifically designed to assess agents'
multimodal retrieval and reasoning capabilities. These questions often
incorporate images in prompts, and crucial information encountered during the
search and reasoning process may also be embedded within images or videos on
webpages. Consequently, methods relying solely on text prove insufficient for
our benchmark. Additionally, we provide a verified checklist for each question,
enabling fine-grained analysis of multimodal dependencies and reasoning paths.
Our comprehensive evaluation of state-of-the-art models on MM-BrowseComp
reveals that even top models like OpenAI o3 with tools achieve only 29.02\%
accuracy, highlighting the suboptimal multimodal capabilities and lack of
native multimodal reasoning in current models.

</details>


### [110] [Overcoming Latency Bottlenecks in On-Device Speech Translation: A Cascaded Approach with Alignment-Based Streaming MT](https://arxiv.org/abs/2508.13358)
*Zeeshan Ahmed,Frank Seide,Niko Moritz,Ju Lin,Ruiming Xie,Simone Merello,Zhe Liu,Christian Fuegen*

Main category: cs.CL

TL;DR: 본 논문은 온디바이스 실시간 스트리밍 음성 번역을 위해 ASR(RNN-T)과 MT를 효율적으로 통합하는 접근을 제시한다. 동시 번역 기법과 ASR의 언어적 신호를 활용한 컨텍스트 관리, 시간-아웃·강제 최종화 같은 빔 탐색 가지치기 기법을 도입하여 지연(latency)과 품질 사이의 균형을 맞춘다. 실험에서 지연과 번역 품질 면에서 기준선보다 우수하며 비스트리밍 시스템과의 품질 격차를 줄였다.


<details>
  <summary>Details</summary>
Motivation: 실시간(on-device) 스트리밍 음성 번역에서 RNN-T 기반 ASR은 실시간 전사에 강점을 보이나, 이를 번역으로 연결할 때 지연과 품질 문제로 실제 스트리밍 번역 구현이 어렵다. 따라서 낮은 지연과 높은 번역 품질을 동시에 만족시키는 통합 방법이 필요하다.

Method: 동시 번역(simultaneous translation) 프레임워크를 적용해 지연-품질 균형을 맞추고, ASR에서 생성되는 언어적 단서(예: 구문 경계, 단어 확신도 등)를 활용해 MT의 컨텍스트 관리에 도움을 준다. 또한 시간-아웃(time-out)과 강제 최종화(forced finalization) 같은 빔서치 가지치기 기법을 도입해 실시간 팩터(real-time factor)를 유지한다.

Result: 온디바이스 양방향 회화 음성 번역에 적용한 결과, 제안 기법이 기준선에 비해 지연과 품질 면에서 우수함을 보였다. 특히 비스트리밍(offline) 번역 시스템과의 품질 격차를 줄여, 실시간 정확도를 크게 향상시켰다.

Conclusion: ASR와 MT의 효율적 통합과 동시 번역 전략, 그리고 빔 탐색 최적화는 온디바이스 스트리밍 음성 번역에서 지연을 줄이면서 번역 품질을 유지·향상시킬 수 있다. 제안 기법은 실시간 음성 번역의 정확도와 효율성 향상에 기여한다.

Abstract: This paper tackles several challenges that arise when integrating Automatic
Speech Recognition (ASR) and Machine Translation (MT) for real-time, on-device
streaming speech translation. Although state-of-the-art ASR systems based on
Recurrent Neural Network Transducers (RNN-T) can perform real-time
transcription, achieving streaming translation in real-time remains a
significant challenge. To address this issue, we propose a simultaneous
translation approach that effectively balances translation quality and latency.
We also investigate efficient integration of ASR and MT, leveraging linguistic
cues generated by the ASR system to manage context and utilizing efficient
beam-search pruning techniques such as time-out and forced finalization to
maintain system's real-time factor. We apply our approach to an on-device
bilingual conversational speech translation and demonstrate that our techniques
outperform baselines in terms of latency and quality. Notably, our technique
narrows the quality gap with non-streaming translation systems, paving the way
for more accurate and efficient real-time speech translation.

</details>


### [111] [Stands to Reason: Investigating the Effect of Reasoning on Idiomaticity Detection](https://arxiv.org/abs/2508.13365)
*Dylan Phelps,Rodrigo Wilkens,Edward Gow-Smith,Thomas Pickard,Maggie Mi,Aline Villavicencio*

Main category: cs.CL

TL;DR: DeepSeek-R1(1.5B–70B)을 대상으로 chain-of-thought(CoT) 등 추론 프롬프트와 모델 크기 영향이 숙어(idiomaticity) 판별 성능에 미치는 영향을 평가했다. 전반적으로 추론의 이점은 예상보다 작고 사례별로 달랐으며, 대형 모델은 숙어 의미를 잘 파악해 정의를 산출하지만 소형 모델은 실패하는 경우가 많아, 소형 모델에는 프롬프트에 정의를 제공하면 성능이 일부 향상된다.


<details>
  <summary>Details</summary>
Motivation: 추론 능력을 지닌 LLM들이 논리적 단계가 필요한 과제에서 성능을 끌어올린다는 최근 경향을 숙어 판별 과제에 적용해, 숙어를 먼저 이해한 뒤 비유적/문자적 해석을 거치는 추론적 프레임이 실제로 도움이 되는지와 모델 크기 효과를 검증하려 함.

Method: Open‑source DeepSeek‑R1 증류 모델 군(1.5B, …, 70B)을 4개의 숙어 판별 데이터셋에서 평가. CoT(체인‑오브‑생각) 프롬프트 적용, Math‑tuned 중간 모델과 베이스 모델 비교, 출력 분석을 통해 정의 생성 능력 평가, 소형 모델에 정의를 프롬프트로 제공하는 실험 수행.

Result: 추론(특히 CoT)의 효과는 작고 다양함. 소형 모델에서는 CoT가 Math‑tuned 중간 모델보다는 성능을 올리지만 베이스 모델 수준으로는 회복시키지 못함. 14B/32B/70B 등 대형 모델은 소폭의 성능 향상을 보이고, 숙어 정의를 정확히 산출하는 경향이 강함. 소형 모델은 실제 의미를 출력하지 못하는 경우가 잦아, 프롬프트에 정의를 제공하면 일부 경우 성능이 개선됨.

Conclusion: 숙어 판별에 추론 프레임을 적용하는 것은 일관된 이득을 보장하지 않으며, 모델 크기가 핵심 변수다. 대형 모델은 숙어 이해와 정의 생성에서 우수하며, 소형 모델에는 외부 정의 제공 같은 보완 전략이 유용할 수 있음.

Abstract: The recent trend towards utilisation of reasoning models has improved the
performance of Large Language Models (LLMs) across many tasks which involve
logical steps. One linguistic task that could benefit from this framing is
idiomaticity detection, as a potentially idiomatic expression must first be
understood before it can be disambiguated and serves as a basis for reasoning.
In this paper, we explore how reasoning capabilities in LLMs affect
idiomaticity detection performance and examine the effect of model size. We
evaluate, as open source representative models, the suite of DeepSeek-R1
distillation models ranging from 1.5B to 70B parameters across four
idiomaticity detection datasets. We find the effect of reasoning to be smaller
and more varied than expected. For smaller models, producing chain-of-thought
(CoT) reasoning increases performance from Math-tuned intermediate models, but
not to the levels of the base models, whereas larger models (14B, 32B, and 70B)
show modest improvements. Our in-depth analyses reveal that larger models
demonstrate good understanding of idiomaticity, successfully producing accurate
definitions of expressions, while smaller models often fail to output the
actual meaning. For this reason, we also experiment with providing definitions
in the prompts of smaller models, which we show can improve performance in some
cases.

</details>


### [112] [Whispering Context: Distilling Syntax and Semantics for Long Speech Transcripts](https://arxiv.org/abs/2508.13376)
*Duygu Altinok*

Main category: cs.CL

TL;DR: 우리는 길고 문맥이 풍부한 오디오 전사에서 문법적·의미적 정확성을 향상시키기 위해 LLaMA의 맥락 지식을 Whisper에 증류하는 방법을 제안한다. 토큰 수준의 최적 수송 정렬과 문장 임베딩 간 표현 손실 최소화를 사용해 통사·의미 정보를 결합하며, Spoken Wikipedia 데이터셋에서 WER, NER, 대소문자, 구두점 성능을 크게 개선한다.


<details>
  <summary>Details</summary>
Motivation: 긴 오디오 전사에서 ASR은 구두점, 대소문자, 개체 인식 등 문법적·의미적 정확성을 유지하기 어렵다. 문맥을 활용한 개선이 필요하다.

Method: 두 가지 전략을 사용한다: (1) 차원과 시퀀스 길이를 맞추기 위해 최적 수송을 이용한 토큰 수준 증류; (2) Whisper와 LLaMA의 문장 임베딩 간 표현 손실을 최소화하여 통사·의미를 혼합한다.

Result: Spoken Wikipedia 데이터셋에서 WER, NER, 대소문자, 구두점 성능이 유의미하게 향상되었다. 새로운 NER 평가 지표를 도입하고 의미 인지 ASR을 탐구함.

Conclusion: 언어학적 문맥을 전사 과정에 통합하면 장시간 음성 인식에서 더욱 견고하고 문맥 인지적인 ASR을 구축할 수 있음을 보여준다.

Abstract: ASR systems often struggle with maintaining syntactic and semantic accuracy
in long audio transcripts, impacting tasks like Named Entity Recognition (NER),
capitalization, and punctuation. We propose a novel approach that enhances ASR
by distilling contextual knowledge from LLaMA models into Whisper. Our method
uses two strategies: (1) token level distillation with optimal transport to
align dimensions and sequence lengths, and (2) representation loss minimization
between sentence embeddings of Whisper and LLaMA, blending syntax and
semantics. Evaluations on the Spoken Wikipedia dataset, a benchmark with long
audios and rich entities demonstrate significant improvements in Word Error
Rate (WER), NER, capitalization, and punctuation success. By introducing novel
NER metrics and exploring semantics aware ASR, our work highlights the value of
integrating linguistic context into transcription, setting a foundation for
robust, context-aware ASR in longform speech.

</details>


### [113] [Datarus-R1: An Adaptive Multi-Step Reasoning LLM for Automated Data Analysis](https://arxiv.org/abs/2508.13382)
*Ayoub Ben Chaliah,Hela Dellagi*

Main category: cs.CL

TL;DR: Datarus-R1-14B는 Qwen 2.5-14B-Instruct에서 파인튜닝된 14B 파라미터 오픈 모델로, ReAct 스타일 노트북 형식의 전체 분석 과정을 학습하여 데이터 분석가 및 대학원 수준 문제 해결사 역할을 수행한다. 트레이닝은 합성 데이터 생성기(144,000 에피소드), 태그 기반 구조 신호와 계층적 보상 모델을 결합한 이중 보상 프레임워크, KV-cache 재사용 등 메모리 최적화를 적용한 GRPO를 포함한다. 에이전트(코드 실행)와 리플렉션(CoT)이라는 이중 추론 인터페이스를 제공하며, AIME 및 LiveCodeBench에서 더 큰 모델과 견줄만한 성능과 토큰 절약을 보였다.


<details>
  <summary>Details</summary>
Motivation: 대학원 수준의 정량적 문제(금융, 의학, 수치해석 등)에 대한 완전한 분석 궤적(추론, 코드 실행, 오류 처리, 자기수정, 결론)을 모델이 학습하게 하여 실제 데이터 분석 작업과 고난도 문제 해결에서 신뢰할 수 있고 간결한 답변을 생성하도록 하는 것.

Method: (i) ReAct 스타일의 노트북 에피소드를 합성하는 트래젝토리 중심 데이터 생성기(144k 에피소드), (ii) 태그 기반 구조 신호와 단계별 타당성 및 종합적 일관성을 평가하는 계층적 보상모델(HRM)을 결합한 듀얼 보상 프레임워크, (iii) GRPO(그룹 상대적 정책 최적화)의 메모리 최적화 구현: KV-cache 재사용, 순차 생성, 레퍼런스 모델 샤딩. 코사인 커리큘럼으로 구조적 충실도에서 의미적 깊이로 초점 이동. 이중 추론 인터페이스(Agentic: ReAct+Python 실행, Reflection: <think>/<answer> CoT).

Result: AIME 2024/2025 및 LiveCodeBench에서 유사 규모 모델을 능가하고 QwQ-32B와 같은 더 큰 모델 수준에 도달, 정확도 최대 30% 향상, 솔루션 당 토큰 18-49% 절감. 모델은 'AHA-moment' 패턴(가설 제시-수정-수렴)을 보이며 과도한 반복·토큰 팽창을 피함.

Conclusion: 트래젝토리 중심 학습, 이중 보상 설계, GRPO 기반 최적화 및 이중 추론 인터페이스의 결합이 대학원 수준의 정량적 문제 해결에서 효율적이고 정확한 오픈 소스 대안을 제공함.

Abstract: We present Datarus-R1-14B, a 14 B-parameter open-weights language model
fine-tuned from Qwen 2.5-14B-Instruct to act as a virtual data analyst and
graduate-level problem solver. Datarus is trained not on isolated
question-answer pairs but on full analytical trajectories including reasoning
steps, code execution, error traces, self-corrections, and final conclusions,
all captured in a ReAct-style notebook format spanning finance, medicine,
numerical analysis, and other quantitative domains. Our training pipeline
combines (i) a trajectory-centric synthetic data generator that yielded 144 000
tagged notebook episodes, (ii) a dual-reward framework blending a lightweight
tag-based structural signal with a Hierarchical Reward Model (HRM) that scores
both single-step soundness and end-to-end coherence, and (iii) a
memory-optimized implementation of Group Relative Policy Optimization (GRPO)
featuring KV-cache reuse, sequential generation, and reference-model sharding.
A cosine curriculum smoothly shifts emphasis from structural fidelity to
semantic depth, reducing the format collapse and verbosity that often plague
RL-aligned LLMs. A central design choice in Datarus is it dual reasoning
interface. In agentic mode the model produces ReAct-tagged steps that invoke
Python tools to execute real code; in reflection mode it outputs compact
Chain-of-Thought (CoT) traces delimited by <think> and <answer> tags. On
demanding postgraduate-level problems, Datarus exhibits an "AHA-moment"
pattern: it sketches hypotheses, revises them once or twice, and converges
avoiding the circular, token-inflating loops common to contemporary systems.
Across standard public benchmarks Datarus surpasses similar size models and
even reaches the level of larger reasoning models such as QwQ-32B achieving up
to 30% higher accuracy on AIME 2024/2025 and LiveCodeBench while emitting
18-49% fewer tokens per solution.

</details>


### [114] [ALIGN: Word Association Learning for Cross-Cultural Generalization in Large Language Models](https://arxiv.org/abs/2508.13426)
*Chunhua Liu,Kabir Manandhar Shrestha,Sukai Huang*

Main category: cs.CL

TL;DR: LLM을 영어(미국)과 중국어(중국어권) 단어 연상 규범으로 파라미터-효율적 미세조정하여 문화 정렬을 시도했다. 소수의 연상 데이터로 7–8B 모델이 70B 기본 모델을 능가하거나 동급의 성능을 보이며, 연상 정밀도·구체성·감정성 지표와 가치응답 분포가 목표 문화 방향으로 유의미하게 이동했다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어모델은 학습 코퍼스의 언어·관점 편향을 반영해 교차문화 의사소통에서 부적절하거나 비대표적인 출력을 할 수 있다. 그러나 문화 모델링·정렬은 문화 지식의 한계와 효과적 학습 방법론의 부재 때문에 어려움이 크다.

Method: 인간의 인지적 연상 규범(Free word-association norms)을 이용한 파라미터-효율적 미세조정. Small-World-of-Words의 영어(미국)·중국어 연상 데이터를 활용해 Llama-3.1-8B와 Qwen-2.5-7B를 SFT(감독 학습)와 PPO 기반 선호 최적화로 적응시켰다.

Result: SFT로 보류된 연상 Precision@5가 영어에서 +16–20%, 중국어에서 +43–165% 개선되고, 중앙 구체성(median concreteness) +0.20 상승, 인간 수준의 감성(valence)·각성(arousal) 달성. 전이성: World Values Survey 문항에서 응답 분포가 목표 문화로 이동하고, 긴장도 높은 50개 항목에서는 Qwen의 중국 정렬 응답이 2배로, Llama의 미국 편향은 1/3 감소. 7–8B 모델이 몇백만 건의 연상 데이터만으로 70B 기본 모델에 필적하거나 능가.

Conclusion: 인지 기반의 소수 데이터로 파라미터-효율적 미세조정만으로 문화적 가치 정렬이 가능하다는 것을 보이며, 비용 효율적인 대안으로 유망하다. 다만 더 넓은 문화 적용, 데이터·윤리적 한계, 세부적 평가가 필요한 후속 연구가 요구된다.

Abstract: As large language models (LLMs) increasingly mediate cross-cultural
communication, their behavior still reflects the distributional bias of the
languages and viewpoints that are over-represented in their pre-training
corpora. Yet, it remains a challenge to model and align culture due to limited
cultural knowledge and a lack of exploration into effective learning
approaches. We introduce a cost-efficient, cognitively grounded remedy:
parameter-efficient fine-tuning on native speakers' free word-association
norms, which encode implicit cultural schemas. Leveraging English-US and
Mandarin associations from the Small-World-of-Words project, we adapt
Llama-3.1-8B and Qwen-2.5-7B via supervised fine-tuning (SFT) and PPO-based
preference optimization. SFT boosts held-out association Precision at 5 by
16-20% in English and 43-165% in Mandarin, lifts median concreteness by +0.20,
and attains human-level valence and arousal. These lexical gains transfer: on
World-Values-Survey questions, fine-tuned models shift answer distributions
toward the target culture, and on a 50-item high-tension subset, Qwen's
Chinese-aligned responses double while Llama's US bias drops by one-third. Our
7-8B models rival or beat vanilla 70B baselines, showing that a few million
culture-grounded associations can instill value alignment without costly
retraining. Our work highlights both the promise and the need for future
research grounded in human cognition in improving cultural alignment in AI
models.

</details>


### [115] [ProMed: Shapley Information Gain Guided Reinforcement Learning for Proactive Medical LLMs](https://arxiv.org/abs/2508.13514)
*Hongxin Ding,Baixiang Huang,Yue Fang,Weibin Liao,Xinke Jiang,Zheng Li,Junfeng Zhao,Yasha Wang*

Main category: cs.CL

TL;DR: ProMed는 의료 LLM을 ‘반응형’에서 ‘능동적 질문’ 패러다임으로 전환하는 강화학습 프레임워크다. 핵심은 Shapley Information Gain(SIG) 보상으로, 질문이 새로 제공하는 정보량과 그 정보의 문맥적 중요도를 결합해 임상적 가치를 정량화한다. SIG를 이용한 MCTS 기반 초기화와 SIG 보강 정책 최적화를 통해 모델이 임상적으로 유용한 질문을 우선 학습하도록 한다. 실험에서 기존 기법 대비 평균 6.29% 향상, 반응형 대비 54.45% 개선을 보였고, 도메인 밖 사례에서도 강건한 일반화를 보였다.


<details>
  <summary>Details</summary>
Motivation: 실제 임상 상담에서는 의사가 환자에게 능동적으로 질문을 던져 추가 정보를 수집해야 정확한 진단과 의사결정을 내릴 수 있다. 기존 의료 LLM들은 주로 정적 질문응답(reactive) 방식으로, 추가 정보를 묻지 않고 바로 답변을 생성해 잘못된 진단 위험이 크다. 이를 보완해 모델이 임상적으로 가치 있는 질문을 스스로 제시하도록 학습시키는 것이 필요하다.

Method: 1) Shapley Information Gain(SIG) 보상 설계: 각 질문의 임상적 유용성을 ‘새로 얻은 정보량’과 그 정보의 문맥적 중요도(Shapley 값)를 결합해 정량화. 2) 두 단계 학습 파이프라인: (a) SIG-Guided Model Initialization: MCTS를 사용해 SIG 보상이 높은 상호작용 궤적을 구성하고 이를 감독 신호로 초기화; (b) SIG-Augmented Policy Optimization: SIG를 보상에 통합해 정책 최적화 수행, 특히 SIG-guided Reward Distribution Mechanism으로 정보가 많은 질문에 더 높은 보상을 할당해 목표지향적 최적화 유도.

Result: 두 개의 새로 구성한 부분정보 의료 벤치마크에서 ProMed는 최신 기법 대비 평균 6.29% 향상, 기존의 반응형 패러다임 대비 54.45%의 큰 성능 향상을 기록. 또한 도메인 외 사례에서 강한 일반화 성능을 보였음.

Conclusion: SIG 기반 보상과 이를 이용한 MCTS 초기화+보상 분배를 결합한 ProMed는 의료 LLM을 능동적 질문자(proactive)로 전환시켜 임상적 의사결정 성능을 크게 향상시킨다. 이 접근은 인터랙티브 의료 상담에서 안전하고 정확한 진단을 지원하는 방향으로 유용하게 쓰일 수 있다.

Abstract: Interactive medical questioning is essential in real-world clinical
consultations, where physicians must actively gather information from patients.
While medical Large Language Models (LLMs) have shown impressive capabilities
in static medical question answering, they predominantly operate under a
reactive paradigm: generating answers directly without seeking additional
information, which risks incorrect diagnoses in such interactive settings. To
address this limitation, we propose ProMed, a reinforcement learning (RL)
framework that transitions medical LLMs toward a proactive paradigm, equipping
them with the ability to ask clinically valuable questions before
decision-making. At the core of ProMed is the Shapley Information Gain (SIG)
reward, which quantifies the clinical utility of each question by combining the
amount of newly acquired information with its contextual importance, estimated
via Shapley values. We integrate SIG into a two-stage training pipeline: (1)
SIG-Guided Model Initialization uses Monte Carlo Tree Search (MCTS) to
construct high-reward interaction trajectories to supervise the model, and (2)
SIG-Augmented Policy Optimization, which integrates SIG and enhances RL with a
novel SIG-guided Reward Distribution Mechanism that assigns higher rewards to
informative questions for targeted optimization. Extensive experiments on two
newly curated partial-information medical benchmarks demonstrate that ProMed
significantly outperforms state-of-the-art methods by an average of 6.29% and
delivers a 54.45% gain over the reactive paradigm, while also generalizing
robustly to out-of-domain cases.

</details>


### [116] [Saudi-Dialect-ALLaM: LoRA Fine-Tuning for Dialectal Arabic Generation](https://arxiv.org/abs/2508.13525)
*Hassan Barmandah*

Main category: cs.CL

TL;DR: LoRA-tuned ALLaM-7B-Instruct-preview on a private Saudi dialect instruction dataset (5,466 pairs) improves Saudi dialect generation, with a Dialect-Token variant boosting detected Saudi dialect rate from 47.97% to 84.21% and reducing MSA leakage; fidelity metrics (chrF++, BERTScore) also improve. Code and datasheet released, but not dataset/models.


<details>
  <summary>Details</summary>
Motivation: Large Arabic LLMs focus on Modern Standard Arabic (MSA), underrepresenting Saudi dialects (Najdi, Hijazi), which limits models' ability to generate authentic dialectal language.

Method: Curated a private Saudi Dialect Instruction dataset (Hijazi & Najdi; 5,466 synthetic instruction-response pairs, 50/50 split). LoRA-tuned ALLaM-7B-Instruct-preview with two variants: (i) Dialect-Token training (explicit dialect tag prepended), (ii) No-Token training (no tag). Evaluated using an external dialect classifier, chrF++, BERTScore, and diversity metrics; compared against several strong instruction-tuned baselines.

Result: Dialect-Token model achieved best dialect control: Saudi detection rate increased from 47.97% to 84.21%, MSA leakage reduced from 32.63% to 6.21%. Fidelity improved (chrF++ +3.53, BERTScore +0.059). Both LoRA variants outperformed baseline instruction models in dialect control and fidelity and avoided metadata-tag echoing. Dataset and weights not released; training/eval/inference code and datasheet released.

Conclusion: Lightweight LoRA tuning on a modest synthetic Saudi dialect dataset substantially improves dialect-specific generation and control, especially when using explicit dialect tokens; authors provide reproducibility materials (code, datasheet) while withholding raw data and weights.

Abstract: Large language models (LLMs) for Arabic are still dominated by Modern
Standard Arabic (MSA), with limited support for Saudi dialects such as Najdi
and Hijazi. This underrepresentation hinders their ability to capture authentic
dialectal variation. Using a privately curated Saudi Dialect Instruction
dataset (Hijazi and Najdi; 5,466 synthetic instruction-response pairs; 50/50
split), we LoRA-tune ALLaM-7B-Instruct-preview, the first foundation model
developed in Saudi Arabia, for Saudi dialect generation. We investigate two
variants: (i) Dialect-Token training, which prepends an explicit dialect tag to
the instruction, and (ii) No-Token training, which omits the tag at formatting
time. Evaluation on a held-out test set combines an external dialect classifier
with text fidelity metrics (chrF++ and BERTScore) and diversity measures. The
Dialect-Token model achieves the best control, raising the Saudi rate from
47.97% to 84.21% and reducing MSA leakage from 32.63% to 6.21%; fidelity also
improves (chrF++ +3.53, BERTScore +0.059). Both LoRA variants outperform strong
generic instruction models (Falcon-7B-Instruct, Llama-3.1-8B-Instruct,
Qwen-2.5-7B-Instruct, AceGPT-v2-8B-Chat, JAIS-13B-Chat) in dialect control and
fidelity, while avoiding metadata-tag echoing that these baselines frequently
exhibit. We do not release the dataset or any model weights/adapters; instead,
we release training/evaluation/inference code and a detailed datasheet (schema
and aggregate statistics) to support independent verification.

</details>


### [117] [MATA (māta): Mindful Assessment of the Telugu Abilities of Large Language Models](https://arxiv.org/abs/2508.13526)
*Chalamalasetti Kranti,Sowmya Vajjala*

Main category: cs.CL

TL;DR: This paper presents MATA, a new evaluation dataset of 729 Telugu questions (multiple-choice and open-ended) for testing LLMs, analyses 11 models, finds reliance on superficial heuristics, and compares LLM-as-judge to human evaluation, arguing for fine-grained evaluation in low-resource languages.


<details>
  <summary>Details</summary>
Motivation: To create a fine-grained evaluation resource for Telugu—a low-resource language—to better understand LLM limitations and guide development of linguistically capable models.

Method: Curated 729 diverse questions across linguistic dimensions; evaluated 11 open and closed LLMs; analyzed performance patterns; empirically tested heuristic biases in multiple-choice (answer position/distractor patterns); compared LLM-as-judge vs human evaluation for open-ended responses.

Result: Performance results across 11 models with detailed error analysis showing reliance on heuristics and specific failure modes; discrepancies observed between LLM-as-judge and human judgments in some cases.

Conclusion: Fine-grained, language-specific benchmarks like MATA are essential to reveal model limitations and improve LLMs for low-resource languages; caution advised when using LLMs as evaluators.

Abstract: In this paper, we introduce MATA, a novel evaluation dataset to assess the
ability of Large Language Models (LLMs) in Telugu language, comprising 729
carefully curated multiple-choice and open-ended questions that span diverse
linguistic dimensions. We evaluate 11 open-weight and closed-source LLMs on our
dataset and present a fine-grained analysis of their performance. Further, we
empirically show how LLMs rely on superficial heuristics such as answer
position and distractor patterns for multiple-choice questions. Finally, we
also compare LLM-as-a-judge evaluation with human evaluation for open-ended
questions and draw some conclusions on its reliability in a low-resource
language. We argue that such fine-grained evaluation is essential for
understanding model limitations and can inform the development of more
linguistically capable LLMs, while also serving as a foundation for future
research in Telugu NLP.

</details>


### [118] [Compressed Models are NOT Trust-equivalent to Their Large Counterparts](https://arxiv.org/abs/2508.13533)
*Rohit Raj Rai,Chirag Kothari,Siddhesh Shelke,Amit Awekar*

Main category: cs.CL

TL;DR: 압축된 대형 딥러닝 모델은 정확도가 비슷해도 원본 모델과 '신뢰 동등성(trust-equivalence)'을 보장하지 못한다. 해석가능성 정렬(LIME, SHAP)과 캘리브레이션 유사도(ECE, MCE, Brier, 신뢰도 다이어그램)를 통해 평가했을 때 BERT-base와 그 압축 변형들 사이에 낮은 정렬성과 뚜렷한 캘리브레이션 불일치가 관찰되었다.


<details>
  <summary>Details</summary>
Motivation: 압축 모델이 자원 제약 환경에 배포되지만, 단순한 성능(정확도) 평등만으로 원본 모델과 동일하게 신뢰할 수 있는지(같은 근거로 예측하고, 동등한 확률적 신뢰도를 갖는지)를 평가할 필요가 있다.

Method: 신뢰 동등성 평가를 위한 2차원 프레임워크 제안: (1) 해석가능성 정렬(interpretability alignment) — LIME와 SHAP를 사용해 모델들이 동일한 입력 특징에 근거해 예측하는지 측정; (2) 캘리브레이션 유사성 — ECE, MCE, Brier Score, 신뢰도 다이어그램으로 예측 확률의 신뢰도 비교. 실험은 BERT-base와 여러 압축 변형을 대상으로 자연어 추론(NLI)과 패러프레이즈 식별 과제에서 수행.

Result: 정확도가 거의 동일한 경우에도 해석가능성 정렬이 낮았고, 캘리브레이션에서도 유의미한 불일치가 발생함. 따라서 압축 모델은 원본과 신뢰 동등하지 않음.

Conclusion: 압축 모델을 원본 모델의 대체품으로 무비판적으로 배포하면 안 되며, 성능 평행성 외에 해석가능성 및 확률적 신뢰도 관점에서 추가 평가가 필요하다.

Abstract: Large Deep Learning models are often compressed before being deployed in a
resource-constrained environment. Can we trust the prediction of compressed
models just as we trust the prediction of the original large model? Existing
work has keenly studied the effect of compression on accuracy and related
performance measures. However, performance parity does not guarantee
trust-equivalence. We propose a two-dimensional framework for trust-equivalence
evaluation. First, interpretability alignment measures whether the models base
their predictions on the same input features. We use LIME and SHAP tests to
measure the interpretability alignment. Second, calibration similarity measures
whether the models exhibit comparable reliability in their predicted
probabilities. It is assessed via ECE, MCE, Brier Score, and reliability
diagrams. We conducted experiments using BERT-base as the large model and its
multiple compressed variants. We focused on two text classification tasks:
natural language inference and paraphrase identification. Our results reveal
low interpretability alignment and significant mismatch in calibration
similarity. It happens even when the accuracies are nearly identical between
models. These findings show that compressed models are not trust-equivalent to
their large counterparts. Deploying compressed models as a drop-in replacement
for large models requires careful assessment, going beyond performance parity.

</details>


### [119] [A Comparative Study of Decoding Strategies in Medical Text Generation](https://arxiv.org/abs/2508.13580)
*Oriana Presacan,Alireza Nik,Vajira Thambawita,Bogdan Ionescu,Michael Riegler*

Main category: cs.CL

TL;DR: Deterministic decoding methods (especially beam search) generally produce higher-quality outputs than stochastic sampling in medical LLM tasks; decoding choice can affect performance more than model choice, and metric correlations vary by task.


<details>
  <summary>Details</summary>
Motivation: Decoding strategy affects LLM output quality, and in high-stakes domains like healthcare accuracy is critical, yet the impact of decoding choices on medical tasks is underexplored.

Method: Evaluate 11 decoding strategies across five open-ended medical tasks (translation, summarization, question answering, dialogue, image captioning) using medically-specialized and general-purpose LLMs of varying sizes; measure output quality with multiple automatic metrics and perform statistical analyses on performance and robustness to decoding choice.

Result: Deterministic strategies outperform stochastic ones; beam search yields highest scores while η and top-k sampling perform worst. Slower decoding tends to produce better quality. Larger models score higher but have longer inference and are not more robust to decoding choice. Medical LLMs outperform general LLMs in 2 of 5 tasks but show no overall advantage and are more sensitive to decoding. Metric correlations vary by task; MAUVE shows weak agreement with BERTScore and ROUGE and greater sensitivity to decoding.

Conclusion: Decoding method selection is crucial for medical LLM applications—its influence can exceed model choice—and evaluation metric selection also affects perceived performance; practitioners should carefully choose decoding strategies and metrics.

Abstract: Large Language Models (LLMs) rely on various decoding strategies to generate
text, and these choices can significantly affect output quality. In healthcare,
where accuracy is critical, the impact of decoding strategies remains
underexplored. We investigate this effect in five open-ended medical tasks,
including translation, summarization, question answering, dialogue, and image
captioning, evaluating 11 decoding strategies with medically specialized and
general-purpose LLMs of different sizes. Our results show that deterministic
strategies generally outperform stochastic ones: beam search achieves the
highest scores, while {\eta} and top-k sampling perform worst. Slower decoding
methods tend to yield better quality. Larger models achieve higher scores
overall but have longer inference times and are no more robust to decoding.
Surprisingly, while medical LLMs outperform general ones in two of the five
tasks, statistical analysis shows no overall performance advantage and reveals
greater sensitivity to decoding choice. We further compare multiple evaluation
metrics and find that correlations vary by task, with MAUVE showing weak
agreement with BERTScore and ROUGE, as well as greater sensitivity to the
decoding strategy. These results highlight the need for careful selection of
decoding methods in medical applications, as their influence can sometimes
exceed that of model choice.

</details>


### [120] [Who Gets the Mic? Investigating Gender Bias in the Speaker Assignment of a Speech-LLM](https://arxiv.org/abs/2508.13603)
*Dariia Puhach,Amir H. Payberah,Éva Székely*

Main category: cs.CL

TL;DR: Speech-LLM의 화자 선택을 이용해 성별 편향을 분석하는 연구. Bark(TTS)를 대상으로 직업 및 성별 연상 단어 데이터셋으로 실험한 결과, Bark는 체계적 편향은 보이지 않지만 성별 인지와 일부 성향은 나타남.


<details>
  <summary>Details</summary>
Motivation: 텍스트 기반 LLM에서 관찰된 성별 편향이 음성 기반 모델(특히 Speech-LLM 및 TTS)에 동일하게 존재하는지 확인하고, 음성 생성 과정에서의 화자 선택을 편향 분석의 명시적 신호로 활용하고자 함.

Method: 화자 할당(speaker assignment)을 분석 도구로 사용. Bark의 기본 화자 선택을 텍스트 프롬프트에 대해 관찰하고, 성별화된 연상과 화자 성별 간의 체계적 정렬 여부를 평가. 두 개의 데이터셋(Professions, Gender-Colored Words)을 구성해 테스트.

Result: Bark는 텍스트 기반 모델처럼 명확한 체계적 성별 편향을 보이지 않음. 다만 텍스트의 성별 연상에 대해 성별 인지를 보이며 일부 성향(특정 프롬프트에 대해 특정 성별 음성 선택 경향)을 관찰함.

Conclusion: 화자 선택은 Speech-LLM의 편향 분석에 유용한 명시적 신호가 될 수 있음. Bark의 경우 심각한 체계적 편향은 없지만 완전히 중립적이지는 않아 추가 분석과 데이터/모델 개선 여지가 있음.

Abstract: Similar to text-based Large Language Models (LLMs), Speech-LLMs exhibit
emergent abilities and context awareness. However, whether these similarities
extend to gender bias remains an open question. This study proposes a
methodology leveraging speaker assignment as an analytic tool for bias
investigation. Unlike text-based models, which encode gendered associations
implicitly, Speech-LLMs must produce a gendered voice, making speaker selection
an explicit bias cue. We evaluate Bark, a Text-to-Speech (TTS) model, analyzing
its default speaker assignments for textual prompts. If Bark's speaker
selection systematically aligns with gendered associations, it may reveal
patterns in its training data or model design. To test this, we construct two
datasets: (i) Professions, containing gender-stereotyped occupations, and (ii)
Gender-Colored Words, featuring gendered connotations. While Bark does not
exhibit systematic bias, it demonstrates gender awareness and has some gender
inclinations.

</details>


### [121] [AdaDocVQA: Adaptive Framework for Long Document Visual Question Answering in Low-Resource Settings](https://arxiv.org/abs/2508.13606)
*Haoxuan Li,Wei Song,Aofan Liu,Peiwu Qin*

Main category: cs.CL

TL;DR: 논문은 장문 문서와 저자원 환경에서 Document VQA 문제를 해결하기 위해 AdaDocVQA라는 통합 적응형 프레임워크를 제안한다. 핵심은 하이브리드 텍스트 검색 기반 문서 분할, 자동 데이터 증강(다단계 검증을 포함한 질의응답 생성), 그리고 동적 구성 생성·얼리 스톱핑을 포함하는 적응형 앙상블 추론이다. 일본어 데이터셋에서 SOTA 성능을 달성했다.


<details>
  <summary>Details</summary>
Motivation: 긴 문서를 처리할 때 모델의 문맥 길이 제약과 학습 데이터 부족(저자원 언어)으로 Document VQA 성능이 크게 저하되는 문제를 해결하기 위함.

Method: 1) 하이브리드 텍스트 검색 아키텍처로 문서 분할을 효율화, 2) 자동 데이터 증강 파이프라인으로 고품질 추론형 QA를 생성하고 다중 수준 검증을 수행, 3) 동적 구성 생성과 얼리 스톱핑을 포함한 적응형 앙상블 추론을 도입하여 추론 효율성과 정확성 향상.

Result: 일본어 Document VQA 벤치마크에서 높은 성능을 기록: JDocQA에서 Yes/No 83.04%, 사실형 52.66%, 수치형 44.12%, LAVA에서 59% 정확도. 각 구성요소의 기여를 확인한 ablation 실험으로 성능 향상 근거 제시.

Conclusion: AdaDocVQA는 장문과 저자원 환경에 적합한 확장 가능한 프레임워크로 일본어 문서 VQA에서 SOTA를 달성했으며, 다른 저자원 언어와 특수 도메인으로의 확장이 유망하다. 코드 공개로 재현성과 활용성도 확보되었다.

Abstract: Document Visual Question Answering (Document VQA) faces significant
challenges when processing long documents in low-resource environments due to
context limitations and insufficient training data. This paper presents
AdaDocVQA, a unified adaptive framework addressing these challenges through
three core innovations: a hybrid text retrieval architecture for effective
document segmentation, an intelligent data augmentation pipeline that
automatically generates high-quality reasoning question-answer pairs with
multi-level verification, and adaptive ensemble inference with dynamic
configuration generation and early stopping mechanisms. Experiments on Japanese
document VQA benchmarks demonstrate substantial improvements with 83.04\%
accuracy on Yes/No questions, 52.66\% on factual questions, and 44.12\% on
numerical questions in JDocQA, and 59\% accuracy on LAVA dataset. Ablation
studies confirm meaningful contributions from each component, and our framework
establishes new state-of-the-art results for Japanese document VQA while
providing a scalable foundation for other low-resource languages and
specialized domains. Our code available at:
https://github.com/Haoxuanli-Thu/AdaDocVQA.

</details>


### [122] [CRISP: Persistent Concept Unlearning via Sparse Autoencoders](https://arxiv.org/abs/2508.13650)
*Tomer Ashuach,Dana Arad,Aaron Mueller,Martin Tutek,Yonatan Belinkov*

Main category: cs.CL

TL;DR: CRISP는 SAE(희소 오토인코더) 특징을 층별로 자동 식별해 해당 활성화를 억제함으로써 파라미터 수준에서 지속적으로 '개념 언러닝'을 수행하는 파라미터-효율적 기법이다. WMDP 안전성 벤치마크에서 유해 지식 제거 능력은 높이면서 일반·도메인 능력은 보존한다.


<details>
  <summary>Details</summary>
Motivation: LLM의 실제 배포가 늘면서 특정 유해하거나 원하지 않는 지식을 선택적으로 제거해야 할 필요가 커졌다. 기존 SAE 기반 방법들은 주로 추론 시점에서만 개입해 파라미터에 영구적 변화가 남지 않아, 파라미터 접근 권한이 있는 공격자에게 우회되거나 복구될 위험이 있다.

Method: CRISP는 SAE의 다층 특징들 가운데 대상 개념과 관련된 유의미한 특징들을 자동으로 식별하고, 해당 특징들의 활성화를 억제하는 방식으로 작동한다. 파라미터-효율적인 업데이트를 통해 변화가 모델에 지속적으로 남도록 설계되었다.

Result: 두 개의 LLM 실험에서 CRISP는 WMDP의 안전성 관련 언러닝 과제들에 대해 기존 방법들보다 우수한 성능을 보였고, 유해 지식을 성공적으로 제거하면서도 일반적·도메인 내 성능을 잘 보존했다.

Conclusion: 특징 수준 분석에서 CRISP는 대상 개념과 정상 개념 사이의 의미론적으로 일관된 분리를 달성해, 목표 특징만을 정밀하게 억제할 수 있음을 보여준다.

Abstract: As large language models (LLMs) are increasingly deployed in real-world
applications, the need to selectively remove unwanted knowledge while
preserving model utility has become paramount. Recent work has explored sparse
autoencoders (SAEs) to perform precise interventions on monosemantic features.
However, most SAE-based methods operate at inference time, which does not
create persistent changes in the model's parameters. Such interventions can be
bypassed or reversed by malicious actors with parameter access. We introduce
CRISP, a parameter-efficient method for persistent concept unlearning using
SAEs. CRISP automatically identifies salient SAE features across multiple
layers and suppresses their activations. We experiment with two LLMs and show
that our method outperforms prior approaches on safety-critical unlearning
tasks from the WMDP benchmark, successfully removing harmful knowledge while
preserving general and in-domain capabilities. Feature-level analysis reveals
that CRISP achieves semantically coherent separation between target and benign
concepts, allowing precise suppression of the target features.

</details>


### [123] [ViExam: Are Vision Language Models Better than Humans on Vietnamese Multimodal Exam Questions?](https://arxiv.org/abs/2508.13680)
*Vy Tuong Dang,An Vo,Quang Tau,Duc Dm,Daeyoung Kim*

Main category: cs.CL

TL;DR: ViExam이라는 2,548문항 규모의 베트남어 멀티모달 시험 벤치마크를 제안하고, 여러 VLM을 평가한 결과 SOTA 모델 평균 57.74%, 오픈소스 모델 평균 27.70%로 인간 평균(66.54%)에 미치지 못함을 보고함. 일부 모델(Thinking VLM o3)은 인간 평균을 넘지만 최고 인간 성과(99.60%)에는 크게 못미침. 영어 지침을 섞는 크로스링구얼 프롬프트는 성능 개선에 실패하며, 휴먼-인-더-루프로 약 5%p 개선 가능.


<details>
  <summary>Details</summary>
Motivation: 영어 중심으로 훈련된 VLM들이 실제로 저자원 언어(여기서는 베트남어)의 멀티모달 교육 평가를 잘 수행하는지 검증하고자 함. 교육용 문제는 그림·수식·표 등이 섞인 진정한 멀티모달 자료를 포함하므로 크로스링구얼 멀티모달 추론 능력의 한계 파악이 필요함.

Method: 베트남어 멀티모달 시험 데이터셋 ViExam(2,548문항, 수학·물리·화학·생물·지리·운전·IQ 등 7개 분야) 구성. SOTA 및 오픈소스 VLM들을 대상으로 벤치마크 평가를 수행하고, 영어 지침 교차프롬프트와 휴먼-인-더-루프 협업 시나리오를 추가 실험하여 성능 변화를 분석.

Result: SOTA VLM 평균 정확도 57.74%, 오픈소스 모델 평균 27.70%. 인간 평균 66.54%, 인간 최고 99.60%. Thinking VLM o3가 74.07%로 인간 평균을 넘었으나 최고 인간 성능과는 큰 격차. 영어 지침 사용 시 SOTA 성능이 약 1%p 감소. 인간-협업으로 약 5%p 성능 향상 관찰.

Conclusion: 영어 중심으로 훈련된 VLM들은 베트남어 멀티모달 교육 평가에서 제한적 성능을 보이며, 크로스링구얼 프롬프트는 도움이 되지 않음. 인간-인-루프가 일부 도움을 주지만 모델 개선 및 다국어 멀티모달 자료에 대한 추가 연구와 데이터/파인튜닝이 필요함.

Abstract: Vision language models (VLMs) demonstrate remarkable capabilities on English
multimodal tasks, but their performance on low-resource languages with
genuinely multimodal educational content remains largely unexplored. In this
work, we test how VLMs perform on Vietnamese educational assessments,
investigating whether VLMs trained predominantly on English data can handle
real-world cross-lingual multimodal reasoning. Our work presents the first
comprehensive evaluation of VLM capabilities on multimodal Vietnamese exams
through proposing ViExam, a benchmark containing 2,548 multimodal questions. We
find that state-of-the-art VLMs achieve only 57.74% while open-source models
achieve 27.70% mean accuracy across 7 academic domains, including Mathematics,
Physics, Chemistry, Biology, Geography, Driving Test, and IQ Test. Most VLMs
underperform average human test-takers (66.54%), with only the thinking VLM o3
(74.07%) exceeding human average performance, yet still falling substantially
short of human best performance (99.60%). Cross-lingual prompting with English
instructions while maintaining Vietnamese content fails to improve performance,
decreasing accuracy by 1 percentage point for SOTA VLMs. Human-in-the-loop
collaboration can partially improve VLM performance by 5 percentage points.
Code and data are available at: https://vi-exam.github.io.

</details>


### [124] [Generics and Default Reasoning in Large Language Models](https://arxiv.org/abs/2508.13718)
*James Ravi Kirkpatrick,Rachel Katharine Sterken*

Main category: cs.CL

TL;DR: 이 논문은 28개 대형 언어 모델(LLM)이 일반화 문장(generics)을 포함한 20가지 반(非)단조 논리 패턴에서의 결함 허용적 추론(defeasible reasoning) 능력을 평가한다. 성능은 모델과 프롬프트 방식에 따라 크게 달라지며, few-shot은 약간 개선하지만 chain-of-thought(CoT)는 종종 성능을 크게 저하시킨다. 많은 모델이 결함 허용 추론과 연역적 추론을 구분하지 못하거나 일반화를 보편적 진술로 오해한다는 점이 주요 결과다.


<details>
  <summary>Details</summary>
Motivation: 일반화(generics)는 예외를 허용하는 복잡한 특성 때문에 언어학·철학·논리학·인지과학에서 중요하며, 기본 추론(default reasoning), 개념 획득 등에서 핵심적이다. 현재 LLM들이 이러한 결함 허용적 추론을 얼마나 잘 수행하는지 평가할 필요가 있다.

Method: 28개 LLM을 대상으로 20가지 반단조 논리 패턴(예: 'Birds fly', 'Ravens are black' 등)을 포함한 시험지를 구성해 평가했다. 프롬프트 스타일(제로샷, 퓨샷, CoT)과 온도 변화를 조절해 성능 차이를 측정했다. 특히 제로샷에서 75% 이상 성능을 보인 모델(온도0)을 분석해 CoT 적용 시 성능 변화를 계산했다.

Result: 일부 최첨단 모델은 많은 기본 추론 문제를 잘 처리했지만, 모델과 프롬프트 방식에 따라 성능 편차가 컸다. Few-shot은 일부 모델에서 소폭 향상시키는 반면 CoT는 종종 성능을 크게 저하시켰다(제로샷 조건에서 75% 이상 모델들의 평균 정확도 감소 -11.14%, 표준편차 15.74%, 온도0). 대부분 모델은 결함 허용 추론과 연역적 추론을 구분하지 못하거나 일반화를 보편적 진술로 오해했다.

Conclusion: 현 LLM들은 기본(default) 추론에 대해 가능성을 보이나 한계도 명확하다. 향후 연구는 LLM의 예외 처리 및 일반화 해석 능력을 향상시키는 방법을 모색해야 한다.

Abstract: This paper evaluates the capabilities of 28 large language models (LLMs) to
reason with 20 defeasible reasoning patterns involving generic generalizations
(e.g., 'Birds fly', 'Ravens are black') central to non-monotonic logic.
Generics are of special interest to linguists, philosophers, logicians, and
cognitive scientists because of their complex exception-permitting behaviour
and their centrality to default reasoning, cognition, and concept acquisition.
We find that while several frontier models handle many default reasoning
problems well, performance varies widely across models and prompting styles.
Few-shot prompting modestly improves performance for some models, but
chain-of-thought (CoT) prompting often leads to serious performance degradation
(mean accuracy drop -11.14%, SD 15.74% in models performing above 75% accuracy
in zero-shot condition, temperature 0). Most models either struggle to
distinguish between defeasible and deductive inference or misinterpret generics
as universal statements. These findings underscore both the promise and limits
of current LLMs for default reasoning.

</details>


### [125] [Prediction is not Explanation: Revisiting the Explanatory Capacity of Mapping Embeddings](https://arxiv.org/abs/2508.13729)
*Hanna Herasimchyk,Alhassan Abdelhalim,Sören Laue,Michaela Regneri*

Main category: cs.CL

TL;DR: 이 논문은 단어 임베딩에서 인간 해석 가능한 특징(feature norms)을 예측하는 기존 방법들이 예측 정확도만으로 임베딩이 해당 지식을 담고 있다고 단정할 수 없음을 보인다. 예측 성능은 임베딩의 의미적 표현보다 알고리즘적 상한과 벡터 공간의 기하학적 유사성에 크게 의존한다는 결론을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 단어 임베딩이 어떤 지식을 내부에 암묵적으로 저장하고 있는지 이해하는 것은 AI 해석 가능성 향상에 중요하다. 기존 연구들은 임베딩을 사람 해석 가능한 의미적 특징(피처 노름)에 매핑해 그 지식 유무를 평가해왔으나, 예측 정확도가 곧 임베딩의 의미 지식 존재를 보장하는지 의문을 제기한다.

Method: 기존 피처 예측 방법을 분석하고, 무작위 정보(랜덤 레이블)를 사용한 실험을 포함해 예측 정확도가 실제 의미적 표현인지 판단하는 데 실패한다는 것을 입증한다. 알고리즘적 상한과 벡터 공간의 기하학적 유사성이 결과에 미치는 영향을 이론적·실험적으로 분석한다.

Result: 피처 노름 예측 방법은 랜덤 정보조차 성공적으로 예측할 수 있으며, 성능은 주로 알고리즘적 상한과 임베딩 벡터 간 기하학적 유사성(예: 코사인 유사도 등)에 의해 좌우된다. 따라서 데이터셋 간의 단순한 예측 성능 비교는 임베딩이 어떤 데이터셋을 더 잘 포착하는지를 신뢰성 있게 나타내지 못한다.

Conclusion: 단순한 피처 예측 성능은 임베딩의 진정한 의미적 지식의 존재를 증명하지 못한다. 이러한 매핑은 실제 의미 속성의 출현을 의미하기보다 벡터 공간의 기하학적 유사성을 반영한다. 따라서 임베딩 해석을 위해선 예측 정확도 외에 더 엄격한 검증 방법과 대안적 해석 기법이 필요하다.

Abstract: Understanding what knowledge is implicitly encoded in deep learning models is
essential for improving the interpretability of AI systems. This paper examines
common methods to explain the knowledge encoded in word embeddings, which are
core elements of large language models (LLMs). These methods typically involve
mapping embeddings onto collections of human-interpretable semantic features,
known as feature norms. Prior work assumes that accurately predicting these
semantic features from the word embeddings implies that the embeddings contain
the corresponding knowledge. We challenge this assumption by demonstrating that
prediction accuracy alone does not reliably indicate genuine feature-based
interpretability.
  We show that these methods can successfully predict even random information,
concluding that the results are predominantly determined by an algorithmic
upper bound rather than meaningful semantic representation in the word
embeddings. Consequently, comparisons between datasets based solely on
prediction performance do not reliably indicate which dataset is better
captured by the word embeddings. Our analysis illustrates that such mappings
primarily reflect geometric similarity within vector spaces rather than
indicating the genuine emergence of semantic properties.

</details>


### [126] [EEG-MedRAG: Enhancing EEG-based Clinical Decision-Making via Hierarchical Hypergraph Retrieval-Augmented Generation](https://arxiv.org/abs/2508.13735)
*Yi Wang,Haoran Luo,Lu Meng*

Main category: cs.CL

TL;DR: EEG-MedRAG is a three-layer hypergraph-based retrieval-augmented generation framework that integrates EEG domain knowledge, patient cases, and a large repository to enable semantic-temporal retrieval and causal-chain diagnostic generation, and it outperforms TimeRAG and HyperGraphRAG on a new cross-disease clinical QA benchmark.


<details>
  <summary>Details</summary>
Motivation: Large-scale, multi-source, heterogeneous EEG data are hard to retrieve and interpret semantically for clinical use; there is a need for unified representation and retrieval that supports diagnosis across diseases and roles.

Method: Constructs an n-ary relational hypergraph with three layers (domain knowledge, individual cases, large repository) to enable joint semantic-temporal retrieval and causal-chain generation; introduces EEG-MedRAG framework and a cross-disease, cross-role EEG clinical QA benchmark covering seven disorders and five clinical perspectives.

Result: EEG-MedRAG significantly outperforms TimeRAG and HyperGraphRAG in answer accuracy and retrieval; benchmark enables systematic evaluation of generalization and role-aware contextual understanding.

Conclusion: The hypergraph-based RAG approach effectively unifies heterogeneous EEG data for improved retrieval and diagnostic generation, showing strong potential for clinical decision support; code and data are publicly released.

Abstract: With the widespread application of electroencephalography (EEG) in
neuroscience and clinical practice, efficiently retrieving and semantically
interpreting large-scale, multi-source, heterogeneous EEG data has become a
pressing challenge. We propose EEG-MedRAG, a three-layer hypergraph-based
retrieval-augmented generation framework that unifies EEG domain knowledge,
individual patient cases, and a large-scale repository into a traversable n-ary
relational hypergraph, enabling joint semantic-temporal retrieval and
causal-chain diagnostic generation. Concurrently, we introduce the first
cross-disease, cross-role EEG clinical QA benchmark, spanning seven disorders
and five authentic clinical perspectives. This benchmark allows systematic
evaluation of disease-agnostic generalization and role-aware contextual
understanding. Experiments show that EEG-MedRAG significantly outperforms
TimeRAG and HyperGraphRAG in answer accuracy and retrieval, highlighting its
strong potential for real-world clinical decision support. Our data and code
are publicly available at https://github.com/yi9206413-boop/EEG-MedRAG.

</details>


### [127] [Sycophancy under Pressure: Evaluating and Mitigating Sycophantic Bias via Adversarial Dialogues in Scientific QA](https://arxiv.org/abs/2508.13743)
*Kaiwei Zhang,Qi Jia,Zijian Chen,Wei Sun,Xiangyang Zhu,Chunyi Li,Dandan Zhu,Guangtao Zhai*

Main category: cs.CL

TL;DR: LLM들이 사용자 신념에 무비판적으로 동조하는 ‘sycophancy’ 문제가 과학적 질의응답에서 심각하며, 저자들은 이를 측정하는 통합 평가틀과 공격적 프롬프트·특정 지표(예: misleading resistance, sycophancy resistance)를 제안하고, 합성 적대적 대화와 chain-of-thought 근거로 사후 미세조정하는 Pressure-Tune 기법으로 문제를 완화함.


<details>
  <summary>Details</summary>
Motivation: 사용자 만족도를 높이기 위한 선호 기반 정렬이 진실성(truthfulness)을 저해하고, 특히 과학 QA처럼 고위험·사실 기반 환경에서 모델의 잘못된 동조(sycophancy)가 의사결정과 지식 형성에 심각한 해를 끼칠 수 있어 이를 정량화하고 완화할 필요가 있음.

Method: (1) 과학적 QA 맥락에서 사용자 압력이 모델 출력을 어떻게 왜곡하는지 정량화하는 통합 평가 프레임워크 도입, (2) 적대적 프롬프트 설정과 misleading resistance·sycophancy resistance 같은 목표 지표 설계, (3) 공개·독점 모델들에 대한 체계적 평가, (4) Pressure-Tune: 합성 적대적 대화와 사용자 오도에 반박하는 chain-of-thought 근거를 이용한 경량 사후 미세조정.

Result: 공개·독점 모델 모두에서 광범위한 sycophantic 경향 관찰 — 모델 크기보다 정렬(alignment) 전략이 더 큰 영향 요인으로 나타남. Pressure-Tune은 sycophancy resistance를 현저히 향상시키면서 정확도와 적절한 피드백에 대한 응답성은 유지함.

Conclusion: 과학적 QA에서의 sycophancy는 중요한 위험 요소이며, Pressure-Tune 같은 경량 사후 미세조정이 현실적인 완화책을 제공한다. 더 넓은 평가와 정렬 전략 개선이 필요하다.

Abstract: Large language models (LLMs), while increasingly used in domains requiring
factual rigor, often display a troubling behavior: sycophancy, the tendency to
align with user beliefs regardless of correctness. This tendency is reinforced
by preference-based alignment techniques that optimize for user satisfaction
but can undermine truthfulness. While relatively benign in casual dialogue,
sycophancy poses serious risks in high-stakes settings such as scientific
question answering (QA), where model outputs may shape collaborative reasoning,
decision-making, and knowledge formation. Despite its importance, this
phenomenon remains underexamined in factual QA contexts. We address this gap by
introducing a unified evaluation framework to quantify the impact of
sycophantic context on model behavior in scientific QA, measuring how much
user-imposed social pressure distorts model outputs. The framework incorporates
adversarial prompting setups and targeted metrics, such as misleading
resistance and sycophancy resistance, that capture a model's ability to
maintain factual consistency under misleading cues. Systematic evaluations
across open-source and proprietary models reveal pervasive sycophantic
tendencies, driven more by alignment strategy than by model size. To mitigate
this issue, we propose Pressure-Tune, a lightweight post-training method that
fine-tunes models on synthetic adversarial dialogues paired with
chain-of-thought rationales. These rationales reject user misinformation while
reinforcing factual commitments. Experiments on challenging scientific QA
benchmarks show that Pressure-Tune significantly enhances sycophancy resistance
without compromising accuracy or responsiveness to valid feedback, offering a
practical pathway toward more truthful and principled model behavior.

</details>


### [128] [MGT-Prism: Enhancing Domain Generalization for Machine-Generated Text Detection via Spectral Alignment](https://arxiv.org/abs/2508.13768)
*Shengchao Liu,Xiaoming Liu,Chengzhengxu Li,Zhaohan Zhang,Guoxin Ma,Yu Lan,Shuai Xiao*

Main category: cs.CL

TL;DR: MGT-Prism은 텍스트 표현의 주파수 도메인 분석을 통해 도메인 간 일반화 성능을 개선하는 기계생성텍스트(MGT) 탐지 기법이다. 저주파 필터링과 동적 스펙트럼 정렬로 도메인 민감 특징을 제거하고 도메인 불변 특징을 추출해 기존 방법보다 약간 우수한 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 기존 MGT 탐지기는 동일 도메인에서 학습·평가할 때는 좋은 성능을 내지만, 다른 출처의 데이터(도메인)로 옮겨갈 때 성능이 크게 떨어진다. 도메인 간 분포 차이(domain shift)가 주된 원인이다.

Method: 텍스트 표현을 주파수 도메인에서 분석해 MGT와 인간 작성 텍스트(HWT) 간 스펙트럼의 크기 차이를 관찰했다. 이를 바탕으로 문서 수준의 도메인 민감 특징을 제거하는 저주파 도메인 필터링 모듈과, 과제 특이적이면서 도메인 불변적인 특징을 추출하는 동적 스펙트럼 정렬 전략을 설계했다.

Result: 11개 테스트 데이터셋, 3가지 도메인 일반화 시나리오에서 실험한 결과 MGT-Prism은 기존 최첨단(SoTA) 기법들보다 평균 정확도에서 0.90% 포인트, F1에서 0.92% 포인트 우수했다.

Conclusion: 주파수 도메인 관점의 특징 처리(저주파 필터링 + 스펙트럼 정렬)가 도메인 민감성을 줄이고 도메인 간 일반화를 개선함으로써 MGT 탐지의 실전 적용 가능성을 높였다.

Abstract: Large Language Models have shown growing ability to generate fluent and
coherent texts that are highly similar to the writing style of humans. Current
detectors for Machine-Generated Text (MGT) perform well when they are trained
and tested in the same domain but generalize poorly to unseen domains, due to
domain shift between data from different sources. In this work, we propose
MGT-Prism, an MGT detection method from the perspective of the frequency domain
for better domain generalization. Our key insight stems from analyzing text
representations in the frequency domain, where we observe consistent spectral
patterns across diverse domains, while significant discrepancies in magnitude
emerge between MGT and human-written texts (HWTs). The observation initiates
the design of a low frequency domain filtering module for filtering out the
document-level features that are sensitive to domain shift, and a dynamic
spectrum alignment strategy to extract the task-specific and domain-invariant
features for improving the detector's performance in domain generalization.
Extensive experiments demonstrate that MGT-Prism outperforms state-of-the-art
baselines by an average of 0.90% in accuracy and 0.92% in F1 score on 11 test
datasets across three domain-generalization scenarios.

</details>


### [129] [Can Large Language Models (LLMs) Describe Pictures Like Children? A Comparative Corpus Study](https://arxiv.org/abs/2508.13769)
*Hanna Woloszyn,Benjamin Gagl*

Main category: cs.CL

TL;DR: LLM이 생성한 텍스트는 독일어 아동의 그림 이야기 설명과 비교했을 때 더 길고 어휘적 다양성은 낮으며, 고빈도 단어에 의존하고 명사가 과소표집되는 등 아동 언어를 잘 재현하지 못했다. Few-shot 프롬프트는 유사성을 약간 높였지만 근본적 차이는 남아 있다.


<details>
  <summary>Details</summary>
Motivation: 교육 분야에서 LLM 활용이 증가하는 가운데, LLM이 생성한 텍스트가 아동 언어와 유사한지 여부는 중요하지만 충분히 연구되지 않았다. 아동 지향 교육 도구의 적합성 및 심리언어학적 연구 응용을 위해 비교 검증이 필요하다.

Method: 독일어 아동의 그림 이야기 설명 코퍼스를 기준으로 동일한 그림들에 대해 LLM으로 두 가지 프롬프트(제로샷, 연습 예시를 주는 few-shot)를 사용해 텍스트 코퍼스를 생성했다. 단어 빈도, 어휘적 풍부성, 문장·단어 길이, 품사 분포, 임베딩 기반 의미 유사도 등 심리언어학적 지표들을 비교 분석했다.

Result: LLM 텍스트는 문장이 더 길고 어휘 다양성은 낮으며 고빈도 단어를 더 많이 사용했다. 명사 비율이 낮게 나타났고 품사 분포 차이가 관찰되었다. 임베딩 기반 의미 공간에서도 유사도가 낮았고, few-shot은 유사성을 소폭 증가시켰지만 어휘적·의미적 패턴 차이는 여전했다.

Conclusion: 멀티모달 프롬프트(텍스트+이미지)를 사용하더라도 현행 LLM은 아동 언어를 충실히 모사하지 못한다. 이는 아동 대상 교육 도구에 LLM 텍스트를 바로 적용하는 것에 대한 주의와, 아동 언어 특성을 반영한 추가 연구·미세조정의 필요성을 시사한다.

Abstract: The role of large language models (LLMs) in education is increasing, yet
little attention has been paid to whether LLM-generated text resembles child
language. This study evaluates how LLMs replicate child-like language by
comparing LLM-generated texts to a collection of German children's descriptions
of picture stories. We generated two LLM-based corpora using the same picture
stories and two prompt types: zero-shot and few-shot prompts specifying a
general age from the children corpus. We conducted a comparative analysis
across psycholinguistic text properties, including word frequency, lexical
richness, sentence and word length, part-of-speech tags, and semantic
similarity with word embeddings. The results show that LLM-generated texts are
longer but less lexically rich, rely more on high-frequency words, and
under-represent nouns. Semantic vector space analysis revealed low similarity,
highlighting differences between the two corpora on the level of corpus
semantics. Few-shot prompt increased similarities between children and LLM text
to a minor extent, but still failed to replicate lexical and semantic patterns.
The findings contribute to our understanding of how LLMs approximate child
language through multimodal prompting (text + image) and give insights into
their use in psycholinguistic research and education while raising important
questions about the appropriateness of LLM-generated language in child-directed
educational tools.

</details>


### [130] [TracSum: A New Benchmark for Aspect-Based Summarization with Sentence-Level Traceability in Medical Domain](https://arxiv.org/abs/2508.13798)
*Bohao Chu,Meijie Li,Sameh Frihat,Chengyu Gu,Georg Lodde,Elisabeth Livingstone,Norbert Fuhr*

Main category: cs.CL

TL;DR: 의료 분야의 사실성 문제를 해결하기 위해 문장 수준의 근거(citation)를 쌍으로 갖는 추적 가능한 측면 기반 요약 벤치마크 TracSum을 제안하고, 500개 의학 초록을 7개 측면으로 주석화해 3.5K 요약-근거 쌍을 생성했으며, 완전성과 일관성을 평가하는 4개 지표를 포함한 평가 프레임워크와 Track-Then-Sum 파이프라인을 제시하고 LLM들과 비교·검증함.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 문서 요약의 사실성 문제, 특히 의료 분야에서의 위험을 완화하기 위해 요약이 어떤 원문 근거에서 파생되었는지 추적할 수 있는 메커니즘이 필요함.

Method: 500개 의료 초록을 7개 핵심 의료 측면으로 주석화(총 3.5K 요약-근거 페어)하고, 문장 수준 인용을 포함하는 추적 가능한 측면 기반 요약 태스크를 정의. 완전성·일관성 평가를 위한 4개 세부 지표를 제안하고, Track-Then-Sum(문장 단위 추적 후 요약) 파이프라인을 베이스라인으로 제시.

Result: 제안된 TracSum 벤치마크와 평가 프레임워크가 추적 가능한 측면 기반 요약을 효과적으로 평가함을 보였고, 문장 수준 추적을 선행하는 것이 생성 정확도를 향상시키며 전체 문맥을 포함하면 완전성이 더 좋아짐을 관찰함. 인간 평가를 통해 정량적 평가 결과를 검증함.

Conclusion: TracSum은 추적 가능한 측면 기반 요약 연구를 위한 실용적 벤치마크를 제공하며, 사전 문장 추적과 전체 문맥 활용이 요약의 정확성과 완전성을 개선한다는 점을 시사함.

Abstract: While document summarization with LLMs has enhanced access to textual
information, concerns about the factual accuracy of these summaries persist,
especially in the medical domain. Tracing evidence from which summaries are
derived enables users to assess their accuracy, thereby alleviating this
concern. In this paper, we introduce TracSum, a novel benchmark for traceable,
aspect-based summarization, in which generated summaries are paired with
sentence-level citations, enabling users to trace back to the original context.
First, we annotate 500 medical abstracts for seven key medical aspects,
yielding 3.5K summary-citation pairs. We then propose a fine-grained evaluation
framework for this new task, designed to assess the completeness and
consistency of generated content using four metrics. Finally, we introduce a
summarization pipeline, Track-Then-Sum, which serves as a baseline method for
comparison. In experiments, we evaluate both this baseline and a set of LLMs on
TracSum, and conduct a human evaluation to assess the evaluation results. The
findings demonstrate that TracSum can serve as an effective benchmark for
traceable, aspect-based summarization tasks. We also observe that explicitly
performing sentence-level tracking prior to summarization enhances generation
accuracy, while incorporating the full context further improves completeness.

</details>


### [131] [Beyond Human Judgment: A Bayesian Evaluation of LLMs' Moral Values Understanding](https://arxiv.org/abs/2508.13804)
*Maciej Skorski,Alina Landowska*

Main category: cs.CL

TL;DR: 대규모 베이지안 분석에서 주요 언어 모델들이 인간 annotator 상위 25% 수준의 도덕 판단 성능을 보이며 평균보다 높은 balanced accuracy와 인간보다 적은 false negative를 보였다.


<details>
  <summary>Details</summary>
Motivation: 기존 연구는 결정적 정답(다수결 등)에 의존해 인간의 이견을 무시해 왔으므로, 인간 간 불일치를 반영해 모델의 도덕적 이해도를 더 정확히 평가할 필요가 있다.

Method: 약 700명의 annotator가 만든 25만개 이상의 레이블을 포함한 10만개 이상의 텍스트(소셜미디어, 뉴스, 포럼)에서 annotator 불일치(aleatoric)와 모델의 도메인 민감도(epistemic)를 베이지안 프레임워크로 모델링. GPU 최적화로 100만건 이상의 모델 쿼리 수행. 평가 대상 모델: Claude Sonnet 4, DeepSeek-V3, Llama 4 Maverick 등.

Result: AI 모델은 일반적으로 인간 annotator 중 상위 25%에 들며 평균보다 우수한 balanced accuracy를 달성. 특히 인간보다 훨씬 적은 false negative를 기록해 도덕적 위반 탐지에서 더 민감한 경향을 보임.

Conclusion: 베이지안 기반으로 불확실성을 모델링하면 모델과 인간의 도덕 판단 차이를 더 정교하게 파악할 수 있으며, 실험 결과 상용 대형언어모델은 많은 상황에서 인간 평균을 상회하고 위반 탐지에서 특히 강점이 있다.

Abstract: How do large language models understand moral dimensions compared to humans?
  This first large-scale Bayesian evaluation of market-leading language models
provides the answer. In contrast to prior work using deterministic ground truth
(majority or inclusion rules), we model annotator disagreements to capture both
aleatoric uncertainty (inherent human disagreement) and epistemic uncertainty
(model domain sensitivity). We evaluate top language models (Claude Sonnet 4,
DeepSeek-V3, Llama 4 Maverick) across 250K+ annotations from ~700 annotators on
100K+ texts spanning social media, news, and forums.
  Our GPU-optimized Bayesian framework processed 1M+ model queries, revealing
that AI models typically rank among the top 25\% of human annotators, achieving
much better-than-average balanced accuracy. Importantly, we find that AI
produces far fewer false negatives than humans, highlighting their more
sensitive moral detection capabilities.

</details>


### [132] [Prompt-Based One-Shot Exact Length-Controlled Generation with LLMs](https://arxiv.org/abs/2508.13805)
*Juncheng Xie,Hung-yi Lee*

Main category: cs.CL

TL;DR: LLMs often fail to follow explicit length constraints. The paper introduces a one-shot prompt with countdown markers and counting rules that makes off-the-shelf LLMs output exactly the desired token count (words in English, characters in Chinese) without fine-tuning. Evaluated across four tasks, the prompt dramatically improves strict-length compliance (e.g., GPT-4.1 compliance rises from <30% to >95% on MT-Bench-LI) while preserving answer quality, outperforming draft-then-revise. This shows precise length control via prompt engineering is effective.


<details>
  <summary>Details</summary>
Motivation: LLMs can’t reliably maintain internal token counts, leading to overshooting or undershooting explicit length instructions. Existing solutions rely on fine-tuning or iterative decoding; the paper seeks a lightweight, prompt-based method to achieve exact length control without such overhead.

Method: A prompt-based, one-shot strategy that appends countdown markers and explicit counting rules, prompting the model to "write while counting." It instructs counting tokens (English words) or characters (Chinese) and includes a countdown mechanism to enforce exact output length, requiring no fine-tuning or iterative sampling.

Result: Across open-ended generation (1–1000 tokens), XSUM summarization, MT-Bench-LI instruction following, and LIFEBENCH equal-length track, the countdown prompt substantially increases strict length compliance. On MT-Bench-LI, GPT-4.1 compliance improves from below 30% to above 95%, surpassing draft-then-revise baselines, with no degradation in judged answer quality.

Conclusion: Precise length control of LLM outputs can be achieved through prompt engineering alone, offering a lightweight alternative to training- and decoding-based approaches.

Abstract: Controlling the length of text produced by large language models (LLMs)
remains challenging: models frequently overshoot or undershoot explicit length
instructions because they cannot reliably keep an internal token count. We
present a prompt-based, one-shot strategy that compels an off-the-shelf LLM to
generate exactly a desired number of tokens - words (English) or characters
(Chinese) - without any fine-tuning or iterative sampling. The prompt appends
countdown markers and explicit counting rules so that the model "writes while
counting." We evaluate on four settings: open-ended generation (1-1000 tokens),
XSUM summarization, MT-Bench-LI instruction following, and the LIFEBENCH
equal-length track. On MT-Bench-LI, strict length compliance with GPT-4.1 leaps
from below 30% under naive prompts to above 95% with our countdown prompt,
surpassing the popular draft-then-revise baseline, while judged answer quality
is preserved. These results show that precise length control can be achieved
through prompt engineering alone, offering a lightweight alternative to
training- or decoding-based methods.

</details>


### [133] [The illusion of a perfect metric: Why evaluating AI's words is harder than it looks](https://arxiv.org/abs/2508.13816)
*Maria Paz Oliva,Adriana Correia,Ivan Vankov,Viktor Botev*

Main category: cs.CL

TL;DR: 본 논문은 자동 평가 지표(AEM)의 현황과 한계를 분석하고, 다양한 지표가 특정 품질 측면만 포착하며 작업·데이터셋별 성능 차이와 검증 관행의 일관성 부족을 지적한다. 특히 최신 LLM 기반 평가자와 RAG 평가에서도 문제가 지속됨을 보여주며, '완벽한 지표' 추구를 비판하고 작업별 요구에 맞춘 지표 선택과 보완적 평가 및 향상된 검증 방법론을 권장한다.


<details>
  <summary>Details</summary>
Motivation: NLG의 실용적 채택을 위해 평가가 중요하지만, 인간 평가는 비용과 확장성 문제를 갖고 있어 자동 평가 지표가 필요하다. 그러나 다양한 AEM이 존재하고 한 지표로 정리되지 않아 평가 결과의 해석과 비교가 어렵다는 문제를 해결하려는 목적.

Method: 기존 메트릭들의 방법론을 면밀히 검토하고, 각 메트릭의 강점·제한점·검증 방법·인간 평가와의 상관관계를 분석. LLM-as-a-Judge 및 RAG 평가를 포함해 최신 지표들의 성능과 한계도 조사.

Result: 메트릭들이 텍스트 품질의 특정 측면만 포착하며, 작업·데이터셋에 따라 효과가 달라지고 검증 관행이 구조화되지 않았으며 인간 평가와의 상관성이 일관되지 않음을 발견. LLM 기반 평가자와 RAG 평가에서도 동일한 문제들이 존재함을 확인.

Conclusion: '완벽한 지표'를 기대하기보다, 작업별 요구에 맞는 지표 선택과 보완적 평가(복수 지표·휴먼 검증 등), 새로운 메트릭은 엄격하고 표준화된 검증 방식을 중심으로 개발되어야 한다.

Abstract: Evaluating Natural Language Generation (NLG) is crucial for the practical
adoption of AI, but has been a longstanding research challenge. While human
evaluation is considered the de-facto standard, it is expensive and lacks
scalability. Practical applications have driven the development of various
automatic evaluation metrics (AEM), designed to compare the model output with
human-written references, generating a score which approximates human judgment.
Over time, AEMs have evolved from simple lexical comparisons, to semantic
similarity models and, more recently, to LLM-based evaluators. However, it
seems that no single metric has emerged as a definitive solution, resulting in
studies using different ones without fully considering the implications. This
paper aims to show this by conducting a thorough examination of the
methodologies of existing metrics, their documented strengths and limitations,
validation methods, and correlations with human judgment. We identify several
key challenges: metrics often capture only specific aspects of text quality,
their effectiveness varies by task and dataset, validation practices remain
unstructured, and correlations with human judgment are inconsistent.
Importantly, we find that these challenges persist in the most recent type of
metric, LLM-as-a-Judge, as well as in the evaluation of Retrieval Augmented
Generation (RAG), an increasingly relevant task in academia and industry. Our
findings challenge the quest for the 'perfect metric'. We propose selecting
metrics based on task-specific needs and leveraging complementary evaluations
and advocate that new metrics should focus on enhanced validation
methodologies.

</details>


### [134] [Extracting Structured Requirements from Unstructured Building Technical Specifications for Building Information Modeling](https://arxiv.org/abs/2508.13833)
*Insaf Nahri,Romain Pinquié,Philippe Véron,Nicolas Bus,Mathieu Thorel*

Main category: cs.CL

TL;DR: 프랑스어 건설 기술 명세서(BTS) 문서에서 요구사항을 자동 추출하기 위해 BIM과 NLP를 통합한 연구. CamemBERT와 Fr_core_news_lg를 이용한 NER이 F1>90%를 달성했고, 관계추출(RE)에서는 Random Forest가 F1>80%로 가장 우수함.


<details>
  <summary>Details</summary>
Motivation: 건설 산업의 BTS 문서가 비정형 텍스트로 되어 있어 BIM에 요구사항을 수동으로 입력하는 데 시간과 비용이 많이 소요된다. 이를 자동화해 설계·검증 과정을 효율화하려는 목적.

Method: NER과 관계추출(RE)을 적용. NER에 트랜스포머 기반 CamemBERT와 프랑스어 사전학습 모델 Fr_core_news_lg(전이학습)을 사용하고, 규칙 기반부터 딥러닝 기반까지 여러 비교 기법을 개발. RE는 사용자 정의 특징 벡터로 Random Forest 등 감독학습 모델 4종을 구현. 비교를 위해 수작업 주석 데이터셋 사용.

Result: NER: CamemBERT와 Fr_core_news_lg가 우수하여 F1>90% 달성. RE: Random Forest가 가장 효과적이며 F1>80% 기록. 전체적으로 제안 기법들이 요구사항 추출에 높은 정확도를 보임.

Conclusion: 트랜스포머 기반 NER과 전통 머신러닝 기반 RE의 조합이 프랑스어 BTS에서 요구사항 자동 추출에 효과적임. 결과를 지식그래프로 표현해 자동 검증 시스템에 통합하는 후속 연구 계획이 제시됨.

Abstract: This study explores the integration of Building Information Modeling (BIM)
with Natural Language Processing (NLP) to automate the extraction of
requirements from unstructured French Building Technical Specification (BTS)
documents within the construction industry. Employing Named Entity Recognition
(NER) and Relation Extraction (RE) techniques, the study leverages the
transformer-based model CamemBERT and applies transfer learning with the French
language model Fr\_core\_news\_lg, both pre-trained on a large French corpus in
the general domain. To benchmark these models, additional approaches ranging
from rule-based to deep learning-based methods are developed. For RE, four
different supervised models, including Random Forest, are implemented using a
custom feature vector. A hand-crafted annotated dataset is used to compare the
effectiveness of NER approaches and RE models. Results indicate that CamemBERT
and Fr\_core\_news\_lg exhibited superior performance in NER, achieving
F1-scores over 90\%, while Random Forest proved most effective in RE, with an
F1 score above 80\%. The outcomes are intended to be represented as a knowledge
graph in future work to further enhance automatic verification systems.

</details>


### [135] [MME-SCI: A Comprehensive and Challenging Science Benchmark for Multimodal Large Language Models](https://arxiv.org/abs/2508.13938)
*Jiacheng Ruan,Dan Jiang,Xian Gao,Ting Liu,Yuzhuo Fu,Yangyang Kang*

Main category: cs.CL

TL;DR: MME-SCI는 수학·물리·화학·생물의 1,019개 고품질 QA와 3가지 평가 모드를 포함하고, 5개 언어를 지원하며 MLLM의 다국어·다중모달 추론과 세부 지식 약점을 평가하기 위해 고안된 어려운 벤치마크다.


<details>
  <summary>Details</summary>
Motivation: 기존 과학 도메인 벤치마크들이 다국어 평가 부족, 모달리티 커버리지 미흡, 과학 지식 포인트의 세부 주석 부재라는 한계를 보였기 때문에 이를 보완할 필요가 있다.

Method: 4개 과목(수학·물리·화학·생물)과 5개 언어(중·영·프·스·일)를 포함하는 1,019개 QA를 수집하고, 이미지 포함 여부 등 3가지 평가 모드로 테스트를 설계했다. 또한 16개 오픈소스·4개 클로즈드소스 모델에 대해 광범위한 실험을 수행하고, 다국어·세부 지식 속성에 따른 성능 분석을 진행했다.

Result: MME-SCI는 기존 모델에 대해 높은 난이도를 보였으며, 예컨대 Image-only 모드에서 o4-mini의 정확도는 수학 52.11%, 물리 24.73%, 화학 36.57%, 생물 29.80%로 낮게 나타났다. 전반적으로 대부분 모델이 특정 도메인과 언어·지식 항목에서 취약함을 보였다.

Conclusion: MME-SCI는 MLLM의 다국어·다중모달 과학 추론 능력을 더욱 정밀하게 평가할 수 있는 도구로, 모델의 약점을 파악하고 향후 개선 방향을 제시할 수 있다. 데이터·평가 코드는 공개되어 재현과 확장이 가능하다.

Abstract: Recently, multimodal large language models (MLLMs) have achieved significant
advancements across various domains, and corresponding evaluation benchmarks
have been continuously refined and improved. In this process, benchmarks in the
scientific domain have played an important role in assessing the reasoning
capabilities of MLLMs. However, existing benchmarks still face three key
challenges: 1) Insufficient evaluation of models' reasoning abilities in
multilingual scenarios; 2) Inadequate assessment of MLLMs' comprehensive
modality coverage; 3) Lack of fine-grained annotation of scientific knowledge
points. To address these gaps, we propose MME-SCI, a comprehensive and
challenging benchmark. We carefully collected 1,019 high-quality
question-answer pairs, which involve 3 distinct evaluation modes. These pairs
cover four subjects, namely mathematics, physics, chemistry, and biology, and
support five languages: Chinese, English, French, Spanish, and Japanese. We
conducted extensive experiments on 16 open-source models and 4 closed-source
models, and the results demonstrate that MME-SCI is widely challenging for
existing MLLMs. For instance, under the Image-only evaluation mode, o4-mini
achieved accuracy of only 52.11%, 24.73%, 36.57%, and 29.80% in mathematics,
physics, chemistry, and biology, respectively, indicating a significantly
higher difficulty level compared to existing benchmarks. More importantly,
using MME-SCI's multilingual and fine-grained knowledge attributes, we analyzed
existing models' performance in depth and identified their weaknesses in
specific domains. The Data and Evaluation Code are available at
https://github.com/JCruan519/MME-SCI.

</details>


### [136] [ReviewGraph: A Knowledge Graph Embedding Based Framework for Review Rating Prediction with Sentiment Features](https://arxiv.org/abs/2508.13953)
*A. J. W. de Vink,Natalia Amat-Lefort,Lifeng Han*

Main category: cs.CL

TL;DR: ReviewGraph은 고객 리뷰를 (주어, 술어, 목적어) 삼중항과 감정 점수로 변환해 지식 그래프로 구성하고, Node2Vec 그래프 임베딩과 감정 특징을 결합한 기계학습 분류기로 리뷰 평점(등급)을 예측하는 프레임워크다. HotelRec 데이터셋에서 전통적 NLP·LLM 기반 대안과 비교하여 유사한 예측 성능을 보이면서 계산 비용은 낮고 해석성·시각화·RAG 통합에 이점이 있다.


<details>
  <summary>Details</summary>
Motivation: 고객 리뷰로부터 평점에 영향을 주는 요인을 이해해 고객 만족·비즈니스 성과를 개선하려는 실무적 필요와, LLM 기반 접근의 높은 계산복잡도를 줄이면서 해석 가능한 대안을 제시하려는 연구적 동기.

Method: 리뷰 텍스트에서 (subject, predicate, object) 삼중항을 추출하고 각 삼중항에 감정 점수를 연계해 지식 그래프를 구성한다. Node2Vec로 노드 임베딩을 생성하고 감정 피처와 결합해 전통적 기계학습 분류기로 평점을 예측한다. 비교군으로 Bag-of-Words, TF-IDF, Word2Vec 등의 전통 기법과 LLM을 사용했으며 HotelRec 데이터셋에서 평가함.

Result: 제안한 모델은 문헌상의 최고 성능 모델과 유사한 예측 성능을 달성했으며, 앙상블 없이도 계산 비용이 낮다. Cohen's Kappa 같은 합의 기반 지표에서 기존 전통 기법들보다 우수했고, 해석 가능성과 시각화, RAG 통합 가능성이라는 추가 장점을 갖는다.

Conclusion: 그래프 기반 표현이 리뷰 분석을 향상시킬 잠재력이 있으며, 향후 고급 그래프 신경망과 LLM 기반 추출 기법을 통합하는 연구로 확장 가능하다. 코드를 오픈소스로 공개할 예정.

Abstract: In the hospitality industry, understanding the factors that drive customer
review ratings is critical for improving guest satisfaction and business
performance. This work proposes ReviewGraph for Review Rating Prediction (RRP),
a novel framework that transforms textual customer reviews into knowledge
graphs by extracting (subject, predicate, object) triples and associating
sentiment scores. Using graph embeddings (Node2Vec) and sentiment features, the
framework predicts review rating scores through machine learning classifiers.
We compare ReviewGraph performance with traditional NLP baselines (such as Bag
of Words, TF-IDF, and Word2Vec) and large language models (LLMs), evaluating
them in the HotelRec dataset. In comparison to the state of the art literature,
our proposed model performs similar to their best performing model but with
lower computational cost (without ensemble).
  While ReviewGraph achieves comparable predictive performance to LLMs and
outperforms baselines on agreement-based metrics such as Cohen's Kappa, it
offers additional advantages in interpretability, visual exploration, and
potential integration into Retrieval-Augmented Generation (RAG) systems. This
work highlights the potential of graph-based representations for enhancing
review analytics and lays the groundwork for future research integrating
advanced graph neural networks and fine-tuned LLM-based extraction methods. We
will share ReviewGraph output and platform open-sourced on our GitHub page
https://github.com/aaronlifenghan/ReviewGraph

</details>


### [137] [Chunks as Arms: Multi-Armed Bandit-Guided Sampling for Long-Context LLM Preference Optimization](https://arxiv.org/abs/2508.13993)
*Shaohua Duan,Xinze Li,Zhenghao Liu,Xiaoyuan Yi,Yukun Yan,Shuo Wang,Yu Gu,Ge Yu,Maosong Sun*

Main category: cs.CL

TL;DR: LongMab-PO는 긴 문맥을 여러 청크로 나누고 각 청크를 MAB(다중 무장 강도기) 팔로 취급해 보상을 바탕으로 유의미한 청크를 선택·롤아웃하여 LLM으로부터 다양하고 고품질의 응답을 생성한 뒤, 이를 DPO(직접 선호 최적화)로 학습시켜 장문 추론 성능을 크게 향상시키는 방법이다.


<details>
  <summary>Details</summary>
Motivation: 긴 문맥 QA·요약·추론 등에서 LLM의 장문 처리 능력이 중요하나, 합성 데이터로 파인튜닝할 때 생성 데이터의 다양성 부족과 사실적 불일치가 성능 향상을 제한함. 더 관련성 높고 다양한 응답을 효율적으로 수집할 방법이 필요함.

Method: 긴 문맥을 여러 청크로 분할하고 각 청크를 MAB의 팔로 간주. 기대 보상 점수에 따라 청크를 선택해 LLM에 입력하고 응답을 생성하며, 응답에 대한 보상 피드백으로 각 팔의 점수를 갱신하는 탐색·활용 루프를 수행. 롤아웃으로 수집한 다양한 고품질 응답을 쌍으로 만들어 DPO로 최종 학습함.

Result: 롤아웃 기반 샘플링이 선호 데이터 쌍의 다양성과 품질을 향상시켰고, 장문 추론 벤치마크에서 SOTA 수준의 성능을 달성했다고 보고. 코드·데이터 공개 예정.

Conclusion: MAB 기반 청크 선택과 DPO 결합은 장문 문맥에서 관련성 높은 고품질 합성 선호 데이터를 얻는 효과적 방법임. 다만 보상 설계와 계산 비용, 실제 문서 다양성에 대한 일반화 문제 등 한계가 있을 수 있으며 보상 신호 개선 및 스케일링 연구가 후속 과제다.

Abstract: Long-context modeling is critical for a wide range of real-world tasks,
including long-context question answering, summarization, and complex reasoning
tasks. Recent studies have explored fine-tuning Large Language Models (LLMs)
with synthetic data to enhance their long-context capabilities. However, the
effectiveness of such approaches is often limited by the low diversity and
factual inconsistencies in the generated data. To address these challenges, we
propose LongMab-PO, a novel framework that leverages a Multi-Armed Bandit (MAB)
rollout strategy to identify the most informative chunks from the given long
context for sampling high-quality and diverse responses and constructing
preference data pairs for Direct Preference Optimization (DPO) training.
Specifically, we treat context chunks as arms of MAB, select chunks based on
their expected reward scores to input into LLMs to generate responses, and
iteratively update these scores based on reward feedback. This exploration and
exploitation process enables the model to focus on the most relevant context
segments, thereby generating and collecting high-quality and diverse responses.
Finally, we collect these generated responses from the rollout process and
apply the DPO method to further optimize the LLM. Experimental results show
that LongMab-PO significantly improves the diversity and quality of preference
data pairs, achieving state-of-the-art performance on long-context reasoning
benchmarks. All code and data will be released on
https://github.com/NEUIR/LongMab-PO.

</details>


### [138] [Ask Good Questions for Large Language Models](https://arxiv.org/abs/2508.14025)
*Qi Wu,Zhongqi Lu*

Main category: cs.CL

TL;DR: AGQ(Ask-Good-Question) 프레임워크는 개선된 개념 강화 항목반응이론(CEIRT) 모델과 LLM을 결합해 사용자의 개념별 혼동을 판별하고, 영감을 주는 텍스트로부터 직접 안내 질문을 생성하여 질의응답 과정에서 정보 검색 효율을 크게 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 기존 대화 시스템은 연관 개념에 대한 사용자의 혼동을 정확히 구별하지 못해 주제 안내가 부정확하고 정보 탐색이 비효율적이라는 문제를 해결하려고 함.

Method: CEIRT 모델을 통해 사용자의 지식 수준(개념별 이해·혼동)을 더 정교하게 식별하고, 이 정보를 바탕으로 LLM과 결합해 ‘영감을 주는 텍스트’로부터 직접 안내 질문을 생성하는 AGQ 프레임워크를 제안함. 이를 통해 질의응답 중 사용자가 필요한 정보를 더 빠르게 찾도록 유도함.

Result: 제안 방법은 여러 baseline과 비교해 사용자의 정보 검색 경험을 유의미하게 개선했으며, 안내 질문 생성으로 검색 효율이 향상되었다고 보고함(정량적 수치 미공개).

Conclusion: CEIRT와 LLM의 결합을 통한 AGQ는 대화형 QA 시스템에서 사용자의 개념 혼동을 줄이고 주제 안내 및 정보 검색 효율을 높이는 실용적 접근법임.

Abstract: Recent advances in large language models (LLMs) have significantly improved
the performance of dialog systems, yet current approaches often fail to provide
accurate guidance of topic due to their inability to discern user confusion in
related concepts. To address this, we introduce the Ask-Good-Question (AGQ)
framework, which features an improved Concept-Enhanced Item Response Theory
(CEIRT) model to better identify users' knowledge levels. Our contributions
include applying the CEIRT model along with LLMs to directly generate guiding
questions based on the inspiring text, greatly improving information retrieval
efficiency during the question & answer process. Through comparisons with other
baseline methods, our approach outperforms by significantly enhencing the
users' information retrieval experiences.

</details>


### [139] [Beyond Pass@1: Self-Play with Variational Problem Synthesis Sustains RLVR](https://arxiv.org/abs/2508.14029)
*Xiao Liang,Zhongzhi Li,Yeyun Gong,Yelong Shen,Ying Nian Wu,Zhijiang Guo,Weizhu Chen*

Main category: cs.CL

TL;DR: SvS(online Self-play with Variational problem Synthesis)를 도입해 RLVR의 entropy collapse를 완화하고, 정책의 생성 다양성 및 Pass@k(특히 Pass@32)를 크게 개선한다. AIME24/25에서 큰 성능 향상과 12개 벤치마크·여러 모델 크기에서의 일반화 성능을 보고한다.


<details>
  <summary>Details</summary>
Motivation: 기존 RLVR는 Pass@1 성능을 올리지만 정책 엔트로피가 감소해 생성 다양성이 줄고 Pass@k(LLM의 상한선)를 제한한다. 엔트로피 붕괴 문제를 해결해 상위 k 성능을 회복할 필요가 있다.

Method: 정책의 정답(올바른 솔루션)을 이용해 참조 정답은 유지한 채 변이된 문제들을 합성하는 온라인 자기대결(self-play) 기반 변이적 문제 합성(SvS)을 제안한다. 학습 중 문제를 증강·갱신해 엔트로피 보존을 유도한다.

Result: SvS는 학습 중 정책 엔트로피를 유지하고 표준 RLVR 대비 Pass@k를 크게 향상시킨다. AIME24/AIME25에서 Pass@32가 절대 18.3% / 22.8% 향상했고, 3B~32B 모델 크기와 12개 추론 벤치마크에서 일관된 일반화·강건성을 보였다.

Conclusion: 문제 증강·갱신을 통한 Self-play 기반 변이 문제 합성은 RLVR의 엔트로피 붕괴를 완화하고 LLM의 상위 k 성능을 지속적으로 향상시킨다.

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has recently emerged as
a key paradigm for post-training Large Language Models (LLMs), particularly for
complex reasoning tasks. However, vanilla RLVR training has been shown to
improve Pass@1 performance at the expense of policy entropy, leading to reduced
generation diversity and limiting the Pass@k performance, which typically
represents the upper bound of LLM reasoning capability. In this paper, we
systematically analyze the policy's generation diversity from the perspective
of training problems and find that augmenting and updating training problems
helps mitigate entropy collapse during training. Based on these observations,
we propose an online Self-play with Variational problem Synthesis (SvS)
strategy for RLVR training, which uses the policy's correct solutions to
synthesize variational problems while ensuring their reference answers remain
identical to the originals. This self-improving strategy effectively maintains
policy entropy during training and substantially improves Pass@k compared with
standard RLVR, sustaining prolonged improvements and achieving absolute gains
of 18.3% and 22.8% in Pass@32 performance on the competition-level AIME24 and
AIME25 benchmarks. Experiments on 12 reasoning benchmarks across varying model
sizes from 3B to 32B consistently demonstrate the generalizability and
robustness of SvS.

</details>


### [140] [Unintended Misalignment from Agentic Fine-Tuning: Risks and Mitigation](https://arxiv.org/abs/2508.14031)
*Dongyoon Hahm,Taywon Min,Woogyeol Jin,Kimin Lee*

Main category: cs.CL

TL;DR: Fine-tuned LLM 에이전트가 에이전트 작업으로 미세조정될 때 의도치 않게 비동조화되어 유해한 요청을 더 잘 수행하고 거절을 덜 하게 되는 문제를 발견하고, 자동으로 생성한 자연어 접두사(prefix)를 응답 앞에 붙여 유해 요청을 거절하도록 유도하는 PING 기법을 제안한다. 성능 손실 없이 안전성 향상을 보이며 기존 프롬프트 기법들보다 우수하다.


<details>
  <summary>Details</summary>
Motivation: 에이전트 기능을 강화하기 위해 LLM을 에이전트 전용 작업으로 미세조정하면 안전성(유해 요청 거부)이 약화될 수 있다는 우려에서 출발. 미세조정 과정에서 발생하는 ‘비동조화(misalignment)’ 문제를 해결해 에이전트로서의 기능은 유지하면서도 유해행동을 줄이려 함.

Method: Prefix INjection Guard(PING): 자동으로 생성한 자연어 접두사들을 모델 응답 앞에 삽입해 유해 요청에 대해 거절하도록 유도. 반복적 접근법으로 (1) 후보 접두사 생성과 (2) 작업 성능과 거절 행동을 모두 최적화하는 접두사 선택을 교차적으로 수행.

Result: 웹 탐색 및 코드 생성 벤치마크에서 PING이 안전성을 크게 개선하면서 정상 작업 성능을 유지했고, 기존의 프롬프트 기반 방법들보다 일관되게 우수한 성능을 보임. 내부 히든 상태 분석(선형 프로브)을 통해 접두사 토큰이 행동 수정에 핵심적임을 확인.

Conclusion: 간단한 자연어 접두사 주입과 자동 선택 절차만으로 미세조정된 LLM 에이전트의 안전성을 실효성 있게 향상시킬 수 있으며, 접두사 토큰이 모델 행동을 조절하는 메커니즘을 뒷받침한다.

Abstract: Beyond simple text generation, Large Language Models (LLMs) have evolved into
agentic systems capable of planning and interacting with external tools to
solve complex tasks. This evolution involves fine-tuning LLMs on agent-specific
tasks to enhance their proficiency. However, safety concerns are frequently
overlooked during this fine-tuning process. In this work, we show that aligned
LLMs can become unintentionally misaligned, leading to a higher likelihood of
executing harmful tasks and a reduced tendency to refuse them when fine-tuned
to execute agentic tasks. To address these safety challenges, we propose Prefix
INjection Guard (PING), a simple yet effective method that prepends
automatically generated natural language prefixes to agent responses, guiding
them to refuse harmful requests while preserving performance on benign tasks.
Specifically, we introduce an iterative approach that alternates between (1)
generating candidate prefixes and (2) selecting those that optimize both task
performance and refusal behavior. Experimental results demonstrate that PING
significantly enhances the safety of fine-tuned LLM agents without sacrificing
their effectiveness. PING consistently outperforms existing prompting
approaches across diverse benchmarks in both web navigation and code generation
tasks. Our analysis of internal hidden states via linear probes reveals that
prefix tokens are crucial for behavior modification, explaining the performance
gains. WARNING: This paper contains contents that are unethical or offensive in
nature.

</details>


### [141] [The Promise of Large Language Models in Digital Health: Evidence from Sentiment Analysis in Online Health Communities](https://arxiv.org/abs/2508.14032)
*Xiancheng Li,Georgios D. Karampatakis,Helen E. Wood,Chris J. Griffiths,Borislava Mihaylova,Neil S. Coulson,Alessio Pasinato,Pietro Panzarasa,Marco Viviani,Anna De Simoni*

Main category: cs.CL

TL;DR: OHC(온라인 건강 커뮤니티) 게시물의 감정분석에서 전문지식 부족과 데이터·프라이버시 제약을 극복하기 위해, 전문가 해석 지침을 코드북으로 구조화하고 이를 in‑context prompting으로 LLM에 주입해 성능을 평가했다. 400개 전문가 주석 데이터에서 다양한 GPT 계열 LLM들은 BioBERT 등 전문 사전학습 모델과 사전 기반 방법들을 능가하며 전문가 수준의 합의도를 보였다.


<details>
  <summary>Details</summary>
Motivation: 환자 생성 건강 데이터는 복잡한 감정·임상 맥락과 암시적 감정 표현을 포함해 정확한 감정분석에 전문가 지식이 필요하지만, 의료 데이터의 부족과 프라이버시 제약으로 전통적 ML 학습이 어렵다. OHC는 혼재된 감정과 전문용어로 이 문제를 잘 드러낸다.

Method: 전문가 해석 지침을 체계화한 구조화된 코드북을 개발하고, 이를 LLM에 in‑context learning(지침 기반 프롬프트)으로 주입해 학습 대신 지식 통합을 유도했다. 6종의 GPT 모델(및 DeepSeek, LLaMA 3.1)을 BioBERT 변형 및 사전 정의된 어휘 기반 방법들과 비교 평가했다. 데이터는 두 개 OHC에서 전문가가 주석한 400개 게시물.

Result: LLM들이 우수한 성능을 보였고, 전문가 간 합의도와 통계적으로 유의미한 차이가 없을 정도의 전문가 수준 합의도를 달성했다. 다양한 LLM 모델에서 일관된 성능이 관찰되어 단순 패턴 인식 이상의 지식 통합이 이루어졌음을 시사한다.

Conclusion: in‑context learning을 통한 코드북 기반 지식 주입은 훈련 데이터가 제한된 의료 환경에서 실시간으로 전문가 수준의 감정분석을 가능하게 하며, 디지털 헬스 모니터링·중재 평가·근거 기반 전략 수립에 실용적 솔루션을 제공한다.

Abstract: Digital health analytics face critical challenges nowadays. The sophisticated
analysis of patient-generated health content, which contains complex emotional
and medical contexts, requires scarce domain expertise, while traditional ML
approaches are constrained by data shortage and privacy limitations in
healthcare settings. Online Health Communities (OHCs) exemplify these
challenges with mixed-sentiment posts, clinical terminology, and implicit
emotional expressions that demand specialised knowledge for accurate Sentiment
Analysis (SA). To address these challenges, this study explores how Large
Language Models (LLMs) can integrate expert knowledge through in-context
learning for SA, providing a scalable solution for sophisticated health data
analysis. Specifically, we develop a structured codebook that systematically
encodes expert interpretation guidelines, enabling LLMs to apply
domain-specific knowledge through targeted prompting rather than extensive
training. Six GPT models validated alongside DeepSeek and LLaMA 3.1 are
compared with pre-trained language models (BioBERT variants) and lexicon-based
methods, using 400 expert-annotated posts from two OHCs. LLMs achieve superior
performance while demonstrating expert-level agreement. This high agreement,
with no statistically significant difference from inter-expert agreement
levels, suggests knowledge integration beyond surface-level pattern
recognition. The consistent performance across diverse LLM models, supported by
in-context learning, offers a promising solution for digital health analytics.
This approach addresses the critical challenge of expert knowledge shortage in
digital health research, enabling real-time, expert-quality analysis for
patient monitoring, intervention assessment, and evidence-based health
strategies.

</details>


### [142] [Uncovering Emergent Physics Representations Learned In-Context by Large Language Models](https://arxiv.org/abs/2508.12448)
*Yeongwoo Song,Jaeyong Bae,Dong-Kyum Kim,Hawoong Jeong*

Main category: cs.CL

TL;DR: LLMs의 in-context learning(ICL)을 물리 기반 동역학 예측 과제로 조사함. 긴 입력 컨텍스트가 성능을 개선하며, 잔차 스트림(residual stream) 활성화를 희소 오토인코더(SAE)로 분석한 결과 SAE가 에너지 등 주요 물리량과 상관된 특징을 포착함을 보임. 이는 LLM이 문맥 내에서 의미 있는 물리 개념을 내부적으로 학습함을 시사함.


<details>
  <summary>Details</summary>
Motivation: ICL이 왜 다양한 과제에서 작동하는지, LLM 내부의 어떤 구조가 이를 가능케 하는지를 규명하고자 함. 합성적 산술/기호 문제 대신, 통제 가능한 실험적 데이터와 물리적 구조를 가진 실제적 시스템(물리 기반 과제)을 통해 모델의 추론 메커니즘을 탐구하려 함.

Method: 물리 시스템의 동역학 예측(dynamics forecasting) 과제를 프록시로 사용하여 LLM의 문맥 내 물리학 학습 능력을 평가. 입력 문맥 길이를 변화시키며 성능 변화를 관찰하고, 모델의 residual stream 활성화를 추출하여 희소 오토인코더(SAE)로 표현을 학습·분해. SAE로 얻은 특징과 실제 물리 변수(예: 에너지) 간의 상관관계를 분석.

Result: 문맥 길이가 길어질수록 동역학 예측 성능이 향상됨. SAE가 학습한 일부 특징이 에너지 같은 핵심 물리량과 높은 상관성을 보임. 즉, LLM 내부 표현에서 의미 있는 물리학적 개념이 추출 가능함을 확인.

Conclusion: LLM의 ICL에서 물리적 개념들이 내부 표현으로 형성될 수 있으며, residual stream과 SAE 분석을 통해 그 메커니즘을 부분적으로 설명할 수 있음. 이 사례 연구는 LLM의 문맥학습 이해를 확장함.

Abstract: Large language models (LLMs) exhibit impressive in-context learning (ICL)
abilities, enabling them to solve wide range of tasks via textual prompts
alone. As these capabilities advance, the range of applicable domains continues
to expand significantly. However, identifying the precise mechanisms or
internal structures within LLMs that allow successful ICL across diverse,
distinct classes of tasks remains elusive. Physics-based tasks offer a
promising testbed for probing this challenge. Unlike synthetic sequences such
as basic arithmetic or symbolic equations, physical systems provide
experimentally controllable, real-world data based on structured dynamics
grounded in fundamental principles. This makes them particularly suitable for
studying the emergent reasoning behaviors of LLMs in a realistic yet tractable
setting. Here, we mechanistically investigate the ICL ability of LLMs,
especially focusing on their ability to reason about physics. Using a dynamics
forecasting task in physical systems as a proxy, we evaluate whether LLMs can
learn physics in context. We first show that the performance of dynamics
forecasting in context improves with longer input contexts. To uncover how such
capability emerges in LLMs, we analyze the model's residual stream activations
using sparse autoencoders (SAEs). Our experiments reveal that the features
captured by SAEs correlate with key physical variables, such as energy. These
findings demonstrate that meaningful physical concepts are encoded within LLMs
during in-context learning. In sum, our work provides a novel case study that
broadens our understanding of how LLMs learn in context.

</details>


### [143] [MM-BrowseComp: A Comprehensive Benchmark for Multimodal Browsing Agents](https://arxiv.org/abs/2508.13186)
*Shilong Li,Xingyuan Bu,Wenjie Wang,Jiaheng Liu,Jun Dong,Haoyang He,Hao Lu,Haozhe Zhang,Chenchen Jing,Zhen Li,Chuanhao Li,Jiayi Tian,Chenchen Zhang,Tianhao Peng,Yancheng He,Jihao Gu,Yuanxing Zhang,Jian Yang,Ge Zhang,Wenhao Huang,Wangchunshu Zhou,Zhaoxiang Zhang,Ruizhe Ding,Shilei Wen*

Main category: cs.CL

TL;DR: Introduces MM-BrowseComp, a 224-question benchmark for multimodal web browsing; SOTA models perform poorly (OpenAI o3 with tools: 29.02% accuracy).


<details>
  <summary>Details</summary>
Motivation: Existing browsing benchmarks focus on text-only content and ignore images/videos on webpages that often contain crucial information; need to evaluate multimodal retrieval and reasoning.

Method: Construct 224 hand-crafted, challenging questions that include images in prompts and expect agents to retrieve and reason about multimodal content; provide verified checklist per question for fine-grained analysis of multimodal dependencies and reasoning paths; evaluate state-of-the-art models (e.g., OpenAI o3 with tools).

Result: State-of-the-art models show low performance on MM-BrowseComp; OpenAI o3 with tools achieves only 29.02% accuracy, demonstrating shortcomings in multimodal retrieval and native multimodal reasoning.

Conclusion: Current models lack robust native multimodal reasoning; MM-BrowseComp fills a gap by benchmarking multimodal web browsing and should drive development of better multimodal agents.

Abstract: AI agents with advanced reasoning and tool use capabilities have demonstrated
impressive performance in web browsing for deep search. While existing
benchmarks such as BrowseComp evaluate these browsing abilities, they primarily
focus on textual information, overlooking the prevalence of multimodal content.
To bridge this gap, we introduce MM-BrowseComp, a novel benchmark comprising
224 challenging, hand-crafted questions specifically designed to assess agents'
multimodal retrieval and reasoning capabilities. These questions often
incorporate images in prompts, and crucial information encountered during the
search and reasoning process may also be embedded within images or videos on
webpages. Consequently, methods relying solely on text prove insufficient for
our benchmark. Additionally, we provide a verified checklist for each question,
enabling fine-grained analysis of multimodal dependencies and reasoning paths.
Our comprehensive evaluation of state-of-the-art models on MM-BrowseComp
reveals that even top models like OpenAI o3 with tools achieve only 29.02\%
accuracy, highlighting the suboptimal multimodal capabilities and lack of
native multimodal reasoning in current models.

</details>


### [144] [Overcoming Latency Bottlenecks in On-Device Speech Translation: A Cascaded Approach with Alignment-Based Streaming MT](https://arxiv.org/abs/2508.13358)
*Zeeshan Ahmed,Frank Seide,Niko Moritz,Ju Lin,Ruiming Xie,Simone Merello,Zhe Liu,Christian Fuegen*

Main category: cs.CL

TL;DR: 본 논문은 온디바이스 실시간 스트리밍 음성 번역을 위해 ASR(RNN-T)과 MT를 효율적으로 통합하는 접근을 제시한다. 동시 번역 기법과 ASR의 언어적 신호를 활용한 컨텍스트 관리, 시간-아웃·강제 최종화 같은 빔 탐색 가지치기 기법을 도입하여 지연(latency)과 품질 사이의 균형을 맞춘다. 실험에서 지연과 번역 품질 면에서 기준선보다 우수하며 비스트리밍 시스템과의 품질 격차를 줄였다.


<details>
  <summary>Details</summary>
Motivation: 실시간(on-device) 스트리밍 음성 번역에서 RNN-T 기반 ASR은 실시간 전사에 강점을 보이나, 이를 번역으로 연결할 때 지연과 품질 문제로 실제 스트리밍 번역 구현이 어렵다. 따라서 낮은 지연과 높은 번역 품질을 동시에 만족시키는 통합 방법이 필요하다.

Method: 동시 번역(simultaneous translation) 프레임워크를 적용해 지연-품질 균형을 맞추고, ASR에서 생성되는 언어적 단서(예: 구문 경계, 단어 확신도 등)를 활용해 MT의 컨텍스트 관리에 도움을 준다. 또한 시간-아웃(time-out)과 강제 최종화(forced finalization) 같은 빔서치 가지치기 기법을 도입해 실시간 팩터(real-time factor)를 유지한다.

Result: 온디바이스 양방향 회화 음성 번역에 적용한 결과, 제안 기법이 기준선에 비해 지연과 품질 면에서 우수함을 보였다. 특히 비스트리밍(offline) 번역 시스템과의 품질 격차를 줄여, 실시간 정확도를 크게 향상시켰다.

Conclusion: ASR와 MT의 효율적 통합과 동시 번역 전략, 그리고 빔 탐색 최적화는 온디바이스 스트리밍 음성 번역에서 지연을 줄이면서 번역 품질을 유지·향상시킬 수 있다. 제안 기법은 실시간 음성 번역의 정확도와 효율성 향상에 기여한다.

Abstract: This paper tackles several challenges that arise when integrating Automatic
Speech Recognition (ASR) and Machine Translation (MT) for real-time, on-device
streaming speech translation. Although state-of-the-art ASR systems based on
Recurrent Neural Network Transducers (RNN-T) can perform real-time
transcription, achieving streaming translation in real-time remains a
significant challenge. To address this issue, we propose a simultaneous
translation approach that effectively balances translation quality and latency.
We also investigate efficient integration of ASR and MT, leveraging linguistic
cues generated by the ASR system to manage context and utilizing efficient
beam-search pruning techniques such as time-out and forced finalization to
maintain system's real-time factor. We apply our approach to an on-device
bilingual conversational speech translation and demonstrate that our techniques
outperform baselines in terms of latency and quality. Notably, our technique
narrows the quality gap with non-streaming translation systems, paving the way
for more accurate and efficient real-time speech translation.

</details>


### [145] [Whispering Context: Distilling Syntax and Semantics for Long Speech Transcripts](https://arxiv.org/abs/2508.13376)
*Duygu Altinok*

Main category: cs.CL

TL;DR: 우리는 길고 문맥이 풍부한 오디오 전사에서 문법적·의미적 정확성을 향상시키기 위해 LLaMA의 맥락 지식을 Whisper에 증류하는 방법을 제안한다. 토큰 수준의 최적 수송 정렬과 문장 임베딩 간 표현 손실 최소화를 사용해 통사·의미 정보를 결합하며, Spoken Wikipedia 데이터셋에서 WER, NER, 대소문자, 구두점 성능을 크게 개선한다.


<details>
  <summary>Details</summary>
Motivation: 긴 오디오 전사에서 ASR은 구두점, 대소문자, 개체 인식 등 문법적·의미적 정확성을 유지하기 어렵다. 문맥을 활용한 개선이 필요하다.

Method: 두 가지 전략을 사용한다: (1) 차원과 시퀀스 길이를 맞추기 위해 최적 수송을 이용한 토큰 수준 증류; (2) Whisper와 LLaMA의 문장 임베딩 간 표현 손실을 최소화하여 통사·의미를 혼합한다.

Result: Spoken Wikipedia 데이터셋에서 WER, NER, 대소문자, 구두점 성능이 유의미하게 향상되었다. 새로운 NER 평가 지표를 도입하고 의미 인지 ASR을 탐구함.

Conclusion: 언어학적 문맥을 전사 과정에 통합하면 장시간 음성 인식에서 더욱 견고하고 문맥 인지적인 ASR을 구축할 수 있음을 보여준다.

Abstract: ASR systems often struggle with maintaining syntactic and semantic accuracy
in long audio transcripts, impacting tasks like Named Entity Recognition (NER),
capitalization, and punctuation. We propose a novel approach that enhances ASR
by distilling contextual knowledge from LLaMA models into Whisper. Our method
uses two strategies: (1) token level distillation with optimal transport to
align dimensions and sequence lengths, and (2) representation loss minimization
between sentence embeddings of Whisper and LLaMA, blending syntax and
semantics. Evaluations on the Spoken Wikipedia dataset, a benchmark with long
audios and rich entities demonstrate significant improvements in Word Error
Rate (WER), NER, capitalization, and punctuation success. By introducing novel
NER metrics and exploring semantics aware ASR, our work highlights the value of
integrating linguistic context into transcription, setting a foundation for
robust, context-aware ASR in longform speech.

</details>


### [146] [Datarus-R1: An Adaptive Multi-Step Reasoning LLM for Automated Data Analysis](https://arxiv.org/abs/2508.13382)
*Ayoub Ben Chaliah,Hela Dellagi*

Main category: cs.CL

TL;DR: Datarus-R1-14B는 Qwen 2.5-14B-Instruct에서 파인튜닝된 14B 파라미터 오픈 모델로, ReAct 스타일 노트북 형식의 전체 분석 과정을 학습하여 데이터 분석가 및 대학원 수준 문제 해결사 역할을 수행한다. 트레이닝은 합성 데이터 생성기(144,000 에피소드), 태그 기반 구조 신호와 계층적 보상 모델을 결합한 이중 보상 프레임워크, KV-cache 재사용 등 메모리 최적화를 적용한 GRPO를 포함한다. 에이전트(코드 실행)와 리플렉션(CoT)이라는 이중 추론 인터페이스를 제공하며, AIME 및 LiveCodeBench에서 더 큰 모델과 견줄만한 성능과 토큰 절약을 보였다.


<details>
  <summary>Details</summary>
Motivation: 대학원 수준의 정량적 문제(금융, 의학, 수치해석 등)에 대한 완전한 분석 궤적(추론, 코드 실행, 오류 처리, 자기수정, 결론)을 모델이 학습하게 하여 실제 데이터 분석 작업과 고난도 문제 해결에서 신뢰할 수 있고 간결한 답변을 생성하도록 하는 것.

Method: (i) ReAct 스타일의 노트북 에피소드를 합성하는 트래젝토리 중심 데이터 생성기(144k 에피소드), (ii) 태그 기반 구조 신호와 단계별 타당성 및 종합적 일관성을 평가하는 계층적 보상모델(HRM)을 결합한 듀얼 보상 프레임워크, (iii) GRPO(그룹 상대적 정책 최적화)의 메모리 최적화 구현: KV-cache 재사용, 순차 생성, 레퍼런스 모델 샤딩. 코사인 커리큘럼으로 구조적 충실도에서 의미적 깊이로 초점 이동. 이중 추론 인터페이스(Agentic: ReAct+Python 실행, Reflection: <think>/<answer> CoT).

Result: AIME 2024/2025 및 LiveCodeBench에서 유사 규모 모델을 능가하고 QwQ-32B와 같은 더 큰 모델 수준에 도달, 정확도 최대 30% 향상, 솔루션 당 토큰 18-49% 절감. 모델은 'AHA-moment' 패턴(가설 제시-수정-수렴)을 보이며 과도한 반복·토큰 팽창을 피함.

Conclusion: 트래젝토리 중심 학습, 이중 보상 설계, GRPO 기반 최적화 및 이중 추론 인터페이스의 결합이 대학원 수준의 정량적 문제 해결에서 효율적이고 정확한 오픈 소스 대안을 제공함.

Abstract: We present Datarus-R1-14B, a 14 B-parameter open-weights language model
fine-tuned from Qwen 2.5-14B-Instruct to act as a virtual data analyst and
graduate-level problem solver. Datarus is trained not on isolated
question-answer pairs but on full analytical trajectories including reasoning
steps, code execution, error traces, self-corrections, and final conclusions,
all captured in a ReAct-style notebook format spanning finance, medicine,
numerical analysis, and other quantitative domains. Our training pipeline
combines (i) a trajectory-centric synthetic data generator that yielded 144 000
tagged notebook episodes, (ii) a dual-reward framework blending a lightweight
tag-based structural signal with a Hierarchical Reward Model (HRM) that scores
both single-step soundness and end-to-end coherence, and (iii) a
memory-optimized implementation of Group Relative Policy Optimization (GRPO)
featuring KV-cache reuse, sequential generation, and reference-model sharding.
A cosine curriculum smoothly shifts emphasis from structural fidelity to
semantic depth, reducing the format collapse and verbosity that often plague
RL-aligned LLMs. A central design choice in Datarus is it dual reasoning
interface. In agentic mode the model produces ReAct-tagged steps that invoke
Python tools to execute real code; in reflection mode it outputs compact
Chain-of-Thought (CoT) traces delimited by <think> and <answer> tags. On
demanding postgraduate-level problems, Datarus exhibits an "AHA-moment"
pattern: it sketches hypotheses, revises them once or twice, and converges
avoiding the circular, token-inflating loops common to contemporary systems.
Across standard public benchmarks Datarus surpasses similar size models and
even reaches the level of larger reasoning models such as QwQ-32B achieving up
to 30% higher accuracy on AIME 2024/2025 and LiveCodeBench while emitting
18-49% fewer tokens per solution.

</details>


### [147] [ALIGN: Word Association Learning for Cross-Cultural Generalization in Large Language Models](https://arxiv.org/abs/2508.13426)
*Chunhua Liu,Kabir Manandhar Shrestha,Sukai Huang*

Main category: cs.CL

TL;DR: LLM을 영어(미국)과 중국어(중국어권) 단어 연상 규범으로 파라미터-효율적 미세조정하여 문화 정렬을 시도했다. 소수의 연상 데이터로 7–8B 모델이 70B 기본 모델을 능가하거나 동급의 성능을 보이며, 연상 정밀도·구체성·감정성 지표와 가치응답 분포가 목표 문화 방향으로 유의미하게 이동했다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어모델은 학습 코퍼스의 언어·관점 편향을 반영해 교차문화 의사소통에서 부적절하거나 비대표적인 출력을 할 수 있다. 그러나 문화 모델링·정렬은 문화 지식의 한계와 효과적 학습 방법론의 부재 때문에 어려움이 크다.

Method: 인간의 인지적 연상 규범(Free word-association norms)을 이용한 파라미터-효율적 미세조정. Small-World-of-Words의 영어(미국)·중국어 연상 데이터를 활용해 Llama-3.1-8B와 Qwen-2.5-7B를 SFT(감독 학습)와 PPO 기반 선호 최적화로 적응시켰다.

Result: SFT로 보류된 연상 Precision@5가 영어에서 +16–20%, 중국어에서 +43–165% 개선되고, 중앙 구체성(median concreteness) +0.20 상승, 인간 수준의 감성(valence)·각성(arousal) 달성. 전이성: World Values Survey 문항에서 응답 분포가 목표 문화로 이동하고, 긴장도 높은 50개 항목에서는 Qwen의 중국 정렬 응답이 2배로, Llama의 미국 편향은 1/3 감소. 7–8B 모델이 몇백만 건의 연상 데이터만으로 70B 기본 모델에 필적하거나 능가.

Conclusion: 인지 기반의 소수 데이터로 파라미터-효율적 미세조정만으로 문화적 가치 정렬이 가능하다는 것을 보이며, 비용 효율적인 대안으로 유망하다. 다만 더 넓은 문화 적용, 데이터·윤리적 한계, 세부적 평가가 필요한 후속 연구가 요구된다.

Abstract: As large language models (LLMs) increasingly mediate cross-cultural
communication, their behavior still reflects the distributional bias of the
languages and viewpoints that are over-represented in their pre-training
corpora. Yet, it remains a challenge to model and align culture due to limited
cultural knowledge and a lack of exploration into effective learning
approaches. We introduce a cost-efficient, cognitively grounded remedy:
parameter-efficient fine-tuning on native speakers' free word-association
norms, which encode implicit cultural schemas. Leveraging English-US and
Mandarin associations from the Small-World-of-Words project, we adapt
Llama-3.1-8B and Qwen-2.5-7B via supervised fine-tuning (SFT) and PPO-based
preference optimization. SFT boosts held-out association Precision at 5 by
16-20% in English and 43-165% in Mandarin, lifts median concreteness by +0.20,
and attains human-level valence and arousal. These lexical gains transfer: on
World-Values-Survey questions, fine-tuned models shift answer distributions
toward the target culture, and on a 50-item high-tension subset, Qwen's
Chinese-aligned responses double while Llama's US bias drops by one-third. Our
7-8B models rival or beat vanilla 70B baselines, showing that a few million
culture-grounded associations can instill value alignment without costly
retraining. Our work highlights both the promise and the need for future
research grounded in human cognition in improving cultural alignment in AI
models.

</details>


### [148] [ProMed: Shapley Information Gain Guided Reinforcement Learning for Proactive Medical LLMs](https://arxiv.org/abs/2508.13514)
*Hongxin Ding,Baixiang Huang,Yue Fang,Weibin Liao,Xinke Jiang,Zheng Li,Junfeng Zhao,Yasha Wang*

Main category: cs.CL

TL;DR: ProMed는 의료 LLM을 ‘반응형’에서 ‘능동적 질문’ 패러다임으로 전환하는 강화학습 프레임워크다. 핵심은 Shapley Information Gain(SIG) 보상으로, 질문이 새로 제공하는 정보량과 그 정보의 문맥적 중요도를 결합해 임상적 가치를 정량화한다. SIG를 이용한 MCTS 기반 초기화와 SIG 보강 정책 최적화를 통해 모델이 임상적으로 유용한 질문을 우선 학습하도록 한다. 실험에서 기존 기법 대비 평균 6.29% 향상, 반응형 대비 54.45% 개선을 보였고, 도메인 밖 사례에서도 강건한 일반화를 보였다.


<details>
  <summary>Details</summary>
Motivation: 실제 임상 상담에서는 의사가 환자에게 능동적으로 질문을 던져 추가 정보를 수집해야 정확한 진단과 의사결정을 내릴 수 있다. 기존 의료 LLM들은 주로 정적 질문응답(reactive) 방식으로, 추가 정보를 묻지 않고 바로 답변을 생성해 잘못된 진단 위험이 크다. 이를 보완해 모델이 임상적으로 가치 있는 질문을 스스로 제시하도록 학습시키는 것이 필요하다.

Method: 1) Shapley Information Gain(SIG) 보상 설계: 각 질문의 임상적 유용성을 ‘새로 얻은 정보량’과 그 정보의 문맥적 중요도(Shapley 값)를 결합해 정량화. 2) 두 단계 학습 파이프라인: (a) SIG-Guided Model Initialization: MCTS를 사용해 SIG 보상이 높은 상호작용 궤적을 구성하고 이를 감독 신호로 초기화; (b) SIG-Augmented Policy Optimization: SIG를 보상에 통합해 정책 최적화 수행, 특히 SIG-guided Reward Distribution Mechanism으로 정보가 많은 질문에 더 높은 보상을 할당해 목표지향적 최적화 유도.

Result: 두 개의 새로 구성한 부분정보 의료 벤치마크에서 ProMed는 최신 기법 대비 평균 6.29% 향상, 기존의 반응형 패러다임 대비 54.45%의 큰 성능 향상을 기록. 또한 도메인 외 사례에서 강한 일반화 성능을 보였음.

Conclusion: SIG 기반 보상과 이를 이용한 MCTS 초기화+보상 분배를 결합한 ProMed는 의료 LLM을 능동적 질문자(proactive)로 전환시켜 임상적 의사결정 성능을 크게 향상시킨다. 이 접근은 인터랙티브 의료 상담에서 안전하고 정확한 진단을 지원하는 방향으로 유용하게 쓰일 수 있다.

Abstract: Interactive medical questioning is essential in real-world clinical
consultations, where physicians must actively gather information from patients.
While medical Large Language Models (LLMs) have shown impressive capabilities
in static medical question answering, they predominantly operate under a
reactive paradigm: generating answers directly without seeking additional
information, which risks incorrect diagnoses in such interactive settings. To
address this limitation, we propose ProMed, a reinforcement learning (RL)
framework that transitions medical LLMs toward a proactive paradigm, equipping
them with the ability to ask clinically valuable questions before
decision-making. At the core of ProMed is the Shapley Information Gain (SIG)
reward, which quantifies the clinical utility of each question by combining the
amount of newly acquired information with its contextual importance, estimated
via Shapley values. We integrate SIG into a two-stage training pipeline: (1)
SIG-Guided Model Initialization uses Monte Carlo Tree Search (MCTS) to
construct high-reward interaction trajectories to supervise the model, and (2)
SIG-Augmented Policy Optimization, which integrates SIG and enhances RL with a
novel SIG-guided Reward Distribution Mechanism that assigns higher rewards to
informative questions for targeted optimization. Extensive experiments on two
newly curated partial-information medical benchmarks demonstrate that ProMed
significantly outperforms state-of-the-art methods by an average of 6.29% and
delivers a 54.45% gain over the reactive paradigm, while also generalizing
robustly to out-of-domain cases.

</details>


### [149] [A Comparative Study of Decoding Strategies in Medical Text Generation](https://arxiv.org/abs/2508.13580)
*Oriana Presacan,Alireza Nik,Vajira Thambawita,Bogdan Ionescu,Michael Riegler*

Main category: cs.CL

TL;DR: Deterministic decoding methods (especially beam search) generally produce higher-quality outputs than stochastic sampling in medical LLM tasks; decoding choice can affect performance more than model choice, and metric correlations vary by task.


<details>
  <summary>Details</summary>
Motivation: Decoding strategy affects LLM output quality, and in high-stakes domains like healthcare accuracy is critical, yet the impact of decoding choices on medical tasks is underexplored.

Method: Evaluate 11 decoding strategies across five open-ended medical tasks (translation, summarization, question answering, dialogue, image captioning) using medically-specialized and general-purpose LLMs of varying sizes; measure output quality with multiple automatic metrics and perform statistical analyses on performance and robustness to decoding choice.

Result: Deterministic strategies outperform stochastic ones; beam search yields highest scores while η and top-k sampling perform worst. Slower decoding tends to produce better quality. Larger models score higher but have longer inference and are not more robust to decoding choice. Medical LLMs outperform general LLMs in 2 of 5 tasks but show no overall advantage and are more sensitive to decoding. Metric correlations vary by task; MAUVE shows weak agreement with BERTScore and ROUGE and greater sensitivity to decoding.

Conclusion: Decoding method selection is crucial for medical LLM applications—its influence can exceed model choice—and evaluation metric selection also affects perceived performance; practitioners should carefully choose decoding strategies and metrics.

Abstract: Large Language Models (LLMs) rely on various decoding strategies to generate
text, and these choices can significantly affect output quality. In healthcare,
where accuracy is critical, the impact of decoding strategies remains
underexplored. We investigate this effect in five open-ended medical tasks,
including translation, summarization, question answering, dialogue, and image
captioning, evaluating 11 decoding strategies with medically specialized and
general-purpose LLMs of different sizes. Our results show that deterministic
strategies generally outperform stochastic ones: beam search achieves the
highest scores, while {\eta} and top-k sampling perform worst. Slower decoding
methods tend to yield better quality. Larger models achieve higher scores
overall but have longer inference times and are no more robust to decoding.
Surprisingly, while medical LLMs outperform general ones in two of the five
tasks, statistical analysis shows no overall performance advantage and reveals
greater sensitivity to decoding choice. We further compare multiple evaluation
metrics and find that correlations vary by task, with MAUVE showing weak
agreement with BERTScore and ROUGE, as well as greater sensitivity to the
decoding strategy. These results highlight the need for careful selection of
decoding methods in medical applications, as their influence can sometimes
exceed that of model choice.

</details>


### [150] [Who Gets the Mic? Investigating Gender Bias in the Speaker Assignment of a Speech-LLM](https://arxiv.org/abs/2508.13603)
*Dariia Puhach,Amir H. Payberah,Éva Székely*

Main category: cs.CL

TL;DR: Speech-LLM의 화자 선택을 이용해 성별 편향을 분석하는 연구. Bark(TTS)를 대상으로 직업 및 성별 연상 단어 데이터셋으로 실험한 결과, Bark는 체계적 편향은 보이지 않지만 성별 인지와 일부 성향은 나타남.


<details>
  <summary>Details</summary>
Motivation: 텍스트 기반 LLM에서 관찰된 성별 편향이 음성 기반 모델(특히 Speech-LLM 및 TTS)에 동일하게 존재하는지 확인하고, 음성 생성 과정에서의 화자 선택을 편향 분석의 명시적 신호로 활용하고자 함.

Method: 화자 할당(speaker assignment)을 분석 도구로 사용. Bark의 기본 화자 선택을 텍스트 프롬프트에 대해 관찰하고, 성별화된 연상과 화자 성별 간의 체계적 정렬 여부를 평가. 두 개의 데이터셋(Professions, Gender-Colored Words)을 구성해 테스트.

Result: Bark는 텍스트 기반 모델처럼 명확한 체계적 성별 편향을 보이지 않음. 다만 텍스트의 성별 연상에 대해 성별 인지를 보이며 일부 성향(특정 프롬프트에 대해 특정 성별 음성 선택 경향)을 관찰함.

Conclusion: 화자 선택은 Speech-LLM의 편향 분석에 유용한 명시적 신호가 될 수 있음. Bark의 경우 심각한 체계적 편향은 없지만 완전히 중립적이지는 않아 추가 분석과 데이터/모델 개선 여지가 있음.

Abstract: Similar to text-based Large Language Models (LLMs), Speech-LLMs exhibit
emergent abilities and context awareness. However, whether these similarities
extend to gender bias remains an open question. This study proposes a
methodology leveraging speaker assignment as an analytic tool for bias
investigation. Unlike text-based models, which encode gendered associations
implicitly, Speech-LLMs must produce a gendered voice, making speaker selection
an explicit bias cue. We evaluate Bark, a Text-to-Speech (TTS) model, analyzing
its default speaker assignments for textual prompts. If Bark's speaker
selection systematically aligns with gendered associations, it may reveal
patterns in its training data or model design. To test this, we construct two
datasets: (i) Professions, containing gender-stereotyped occupations, and (ii)
Gender-Colored Words, featuring gendered connotations. While Bark does not
exhibit systematic bias, it demonstrates gender awareness and has some gender
inclinations.

</details>


### [151] [Generics and Default Reasoning in Large Language Models](https://arxiv.org/abs/2508.13718)
*James Ravi Kirkpatrick,Rachel Katharine Sterken*

Main category: cs.CL

TL;DR: 이 논문은 28개 대형 언어 모델(LLM)이 일반화 문장(generics)을 포함한 20가지 반(非)단조 논리 패턴에서의 결함 허용적 추론(defeasible reasoning) 능력을 평가한다. 성능은 모델과 프롬프트 방식에 따라 크게 달라지며, few-shot은 약간 개선하지만 chain-of-thought(CoT)는 종종 성능을 크게 저하시킨다. 많은 모델이 결함 허용 추론과 연역적 추론을 구분하지 못하거나 일반화를 보편적 진술로 오해한다는 점이 주요 결과다.


<details>
  <summary>Details</summary>
Motivation: 일반화(generics)는 예외를 허용하는 복잡한 특성 때문에 언어학·철학·논리학·인지과학에서 중요하며, 기본 추론(default reasoning), 개념 획득 등에서 핵심적이다. 현재 LLM들이 이러한 결함 허용적 추론을 얼마나 잘 수행하는지 평가할 필요가 있다.

Method: 28개 LLM을 대상으로 20가지 반단조 논리 패턴(예: 'Birds fly', 'Ravens are black' 등)을 포함한 시험지를 구성해 평가했다. 프롬프트 스타일(제로샷, 퓨샷, CoT)과 온도 변화를 조절해 성능 차이를 측정했다. 특히 제로샷에서 75% 이상 성능을 보인 모델(온도0)을 분석해 CoT 적용 시 성능 변화를 계산했다.

Result: 일부 최첨단 모델은 많은 기본 추론 문제를 잘 처리했지만, 모델과 프롬프트 방식에 따라 성능 편차가 컸다. Few-shot은 일부 모델에서 소폭 향상시키는 반면 CoT는 종종 성능을 크게 저하시켰다(제로샷 조건에서 75% 이상 모델들의 평균 정확도 감소 -11.14%, 표준편차 15.74%, 온도0). 대부분 모델은 결함 허용 추론과 연역적 추론을 구분하지 못하거나 일반화를 보편적 진술로 오해했다.

Conclusion: 현 LLM들은 기본(default) 추론에 대해 가능성을 보이나 한계도 명확하다. 향후 연구는 LLM의 예외 처리 및 일반화 해석 능력을 향상시키는 방법을 모색해야 한다.

Abstract: This paper evaluates the capabilities of 28 large language models (LLMs) to
reason with 20 defeasible reasoning patterns involving generic generalizations
(e.g., 'Birds fly', 'Ravens are black') central to non-monotonic logic.
Generics are of special interest to linguists, philosophers, logicians, and
cognitive scientists because of their complex exception-permitting behaviour
and their centrality to default reasoning, cognition, and concept acquisition.
We find that while several frontier models handle many default reasoning
problems well, performance varies widely across models and prompting styles.
Few-shot prompting modestly improves performance for some models, but
chain-of-thought (CoT) prompting often leads to serious performance degradation
(mean accuracy drop -11.14%, SD 15.74% in models performing above 75% accuracy
in zero-shot condition, temperature 0). Most models either struggle to
distinguish between defeasible and deductive inference or misinterpret generics
as universal statements. These findings underscore both the promise and limits
of current LLMs for default reasoning.

</details>


### [152] [Prediction is not Explanation: Revisiting the Explanatory Capacity of Mapping Embeddings](https://arxiv.org/abs/2508.13729)
*Hanna Herasimchyk,Alhassan Abdelhalim,Sören Laue,Michaela Regneri*

Main category: cs.CL

TL;DR: 이 논문은 단어 임베딩에서 인간 해석 가능한 특징(feature norms)을 예측하는 기존 방법들이 예측 정확도만으로 임베딩이 해당 지식을 담고 있다고 단정할 수 없음을 보인다. 예측 성능은 임베딩의 의미적 표현보다 알고리즘적 상한과 벡터 공간의 기하학적 유사성에 크게 의존한다는 결론을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 단어 임베딩이 어떤 지식을 내부에 암묵적으로 저장하고 있는지 이해하는 것은 AI 해석 가능성 향상에 중요하다. 기존 연구들은 임베딩을 사람 해석 가능한 의미적 특징(피처 노름)에 매핑해 그 지식 유무를 평가해왔으나, 예측 정확도가 곧 임베딩의 의미 지식 존재를 보장하는지 의문을 제기한다.

Method: 기존 피처 예측 방법을 분석하고, 무작위 정보(랜덤 레이블)를 사용한 실험을 포함해 예측 정확도가 실제 의미적 표현인지 판단하는 데 실패한다는 것을 입증한다. 알고리즘적 상한과 벡터 공간의 기하학적 유사성이 결과에 미치는 영향을 이론적·실험적으로 분석한다.

Result: 피처 노름 예측 방법은 랜덤 정보조차 성공적으로 예측할 수 있으며, 성능은 주로 알고리즘적 상한과 임베딩 벡터 간 기하학적 유사성(예: 코사인 유사도 등)에 의해 좌우된다. 따라서 데이터셋 간의 단순한 예측 성능 비교는 임베딩이 어떤 데이터셋을 더 잘 포착하는지를 신뢰성 있게 나타내지 못한다.

Conclusion: 단순한 피처 예측 성능은 임베딩의 진정한 의미적 지식의 존재를 증명하지 못한다. 이러한 매핑은 실제 의미 속성의 출현을 의미하기보다 벡터 공간의 기하학적 유사성을 반영한다. 따라서 임베딩 해석을 위해선 예측 정확도 외에 더 엄격한 검증 방법과 대안적 해석 기법이 필요하다.

Abstract: Understanding what knowledge is implicitly encoded in deep learning models is
essential for improving the interpretability of AI systems. This paper examines
common methods to explain the knowledge encoded in word embeddings, which are
core elements of large language models (LLMs). These methods typically involve
mapping embeddings onto collections of human-interpretable semantic features,
known as feature norms. Prior work assumes that accurately predicting these
semantic features from the word embeddings implies that the embeddings contain
the corresponding knowledge. We challenge this assumption by demonstrating that
prediction accuracy alone does not reliably indicate genuine feature-based
interpretability.
  We show that these methods can successfully predict even random information,
concluding that the results are predominantly determined by an algorithmic
upper bound rather than meaningful semantic representation in the word
embeddings. Consequently, comparisons between datasets based solely on
prediction performance do not reliably indicate which dataset is better
captured by the word embeddings. Our analysis illustrates that such mappings
primarily reflect geometric similarity within vector spaces rather than
indicating the genuine emergence of semantic properties.

</details>


### [153] [MM-BrowseComp: A Comprehensive Benchmark for Multimodal Browsing Agents](https://arxiv.org/abs/2508.13186)
*Shilong Li,Xingyuan Bu,Wenjie Wang,Jiaheng Liu,Jun Dong,Haoyang He,Hao Lu,Haozhe Zhang,Chenchen Jing,Zhen Li,Chuanhao Li,Jiayi Tian,Chenchen Zhang,Tianhao Peng,Yancheng He,Jihao Gu,Yuanxing Zhang,Jian Yang,Ge Zhang,Wenhao Huang,Wangchunshu Zhou,Zhaoxiang Zhang,Ruizhe Ding,Shilei Wen*

Main category: cs.CL

TL;DR: Introduces MM-BrowseComp, a 224-question benchmark for multimodal web browsing; SOTA models perform poorly (OpenAI o3 with tools: 29.02% accuracy).


<details>
  <summary>Details</summary>
Motivation: Existing browsing benchmarks focus on text-only content and ignore images/videos on webpages that often contain crucial information; need to evaluate multimodal retrieval and reasoning.

Method: Construct 224 hand-crafted, challenging questions that include images in prompts and expect agents to retrieve and reason about multimodal content; provide verified checklist per question for fine-grained analysis of multimodal dependencies and reasoning paths; evaluate state-of-the-art models (e.g., OpenAI o3 with tools).

Result: State-of-the-art models show low performance on MM-BrowseComp; OpenAI o3 with tools achieves only 29.02% accuracy, demonstrating shortcomings in multimodal retrieval and native multimodal reasoning.

Conclusion: Current models lack robust native multimodal reasoning; MM-BrowseComp fills a gap by benchmarking multimodal web browsing and should drive development of better multimodal agents.

Abstract: AI agents with advanced reasoning and tool use capabilities have demonstrated
impressive performance in web browsing for deep search. While existing
benchmarks such as BrowseComp evaluate these browsing abilities, they primarily
focus on textual information, overlooking the prevalence of multimodal content.
To bridge this gap, we introduce MM-BrowseComp, a novel benchmark comprising
224 challenging, hand-crafted questions specifically designed to assess agents'
multimodal retrieval and reasoning capabilities. These questions often
incorporate images in prompts, and crucial information encountered during the
search and reasoning process may also be embedded within images or videos on
webpages. Consequently, methods relying solely on text prove insufficient for
our benchmark. Additionally, we provide a verified checklist for each question,
enabling fine-grained analysis of multimodal dependencies and reasoning paths.
Our comprehensive evaluation of state-of-the-art models on MM-BrowseComp
reveals that even top models like OpenAI o3 with tools achieve only 29.02\%
accuracy, highlighting the suboptimal multimodal capabilities and lack of
native multimodal reasoning in current models.

</details>


### [154] [Saudi-Dialect-ALLaM: LoRA Fine-Tuning for Dialectal Arabic Generation](https://arxiv.org/abs/2508.13525)
*Hassan Barmandah*

Main category: cs.CL

TL;DR: LoRA-tuned ALLaM-7B-Instruct-preview on a private Saudi dialect instruction dataset (5,466 pairs) improves Saudi dialect generation, with a Dialect-Token variant boosting detected Saudi dialect rate from 47.97% to 84.21% and reducing MSA leakage; fidelity metrics (chrF++, BERTScore) also improve. Code and datasheet released, but not dataset/models.


<details>
  <summary>Details</summary>
Motivation: Large Arabic LLMs focus on Modern Standard Arabic (MSA), underrepresenting Saudi dialects (Najdi, Hijazi), which limits models' ability to generate authentic dialectal language.

Method: Curated a private Saudi Dialect Instruction dataset (Hijazi & Najdi; 5,466 synthetic instruction-response pairs, 50/50 split). LoRA-tuned ALLaM-7B-Instruct-preview with two variants: (i) Dialect-Token training (explicit dialect tag prepended), (ii) No-Token training (no tag). Evaluated using an external dialect classifier, chrF++, BERTScore, and diversity metrics; compared against several strong instruction-tuned baselines.

Result: Dialect-Token model achieved best dialect control: Saudi detection rate increased from 47.97% to 84.21%, MSA leakage reduced from 32.63% to 6.21%. Fidelity improved (chrF++ +3.53, BERTScore +0.059). Both LoRA variants outperformed baseline instruction models in dialect control and fidelity and avoided metadata-tag echoing. Dataset and weights not released; training/eval/inference code and datasheet released.

Conclusion: Lightweight LoRA tuning on a modest synthetic Saudi dialect dataset substantially improves dialect-specific generation and control, especially when using explicit dialect tokens; authors provide reproducibility materials (code, datasheet) while withholding raw data and weights.

Abstract: Large language models (LLMs) for Arabic are still dominated by Modern
Standard Arabic (MSA), with limited support for Saudi dialects such as Najdi
and Hijazi. This underrepresentation hinders their ability to capture authentic
dialectal variation. Using a privately curated Saudi Dialect Instruction
dataset (Hijazi and Najdi; 5,466 synthetic instruction-response pairs; 50/50
split), we LoRA-tune ALLaM-7B-Instruct-preview, the first foundation model
developed in Saudi Arabia, for Saudi dialect generation. We investigate two
variants: (i) Dialect-Token training, which prepends an explicit dialect tag to
the instruction, and (ii) No-Token training, which omits the tag at formatting
time. Evaluation on a held-out test set combines an external dialect classifier
with text fidelity metrics (chrF++ and BERTScore) and diversity measures. The
Dialect-Token model achieves the best control, raising the Saudi rate from
47.97% to 84.21% and reducing MSA leakage from 32.63% to 6.21%; fidelity also
improves (chrF++ +3.53, BERTScore +0.059). Both LoRA variants outperform strong
generic instruction models (Falcon-7B-Instruct, Llama-3.1-8B-Instruct,
Qwen-2.5-7B-Instruct, AceGPT-v2-8B-Chat, JAIS-13B-Chat) in dialect control and
fidelity, while avoiding metadata-tag echoing that these baselines frequently
exhibit. We do not release the dataset or any model weights/adapters; instead,
we release training/evaluation/inference code and a detailed datasheet (schema
and aggregate statistics) to support independent verification.

</details>


### [155] [Compressed Models are NOT Trust-equivalent to Their Large Counterparts](https://arxiv.org/abs/2508.13533)
*Rohit Raj Rai,Chirag Kothari,Siddhesh Shelke,Amit Awekar*

Main category: cs.CL

TL;DR: 압축된 대형 딥러닝 모델은 정확도가 비슷해도 원본 모델과 '신뢰 동등성(trust-equivalence)'을 보장하지 못한다. 해석가능성 정렬(LIME, SHAP)과 캘리브레이션 유사도(ECE, MCE, Brier, 신뢰도 다이어그램)를 통해 평가했을 때 BERT-base와 그 압축 변형들 사이에 낮은 정렬성과 뚜렷한 캘리브레이션 불일치가 관찰되었다.


<details>
  <summary>Details</summary>
Motivation: 압축 모델이 자원 제약 환경에 배포되지만, 단순한 성능(정확도) 평등만으로 원본 모델과 동일하게 신뢰할 수 있는지(같은 근거로 예측하고, 동등한 확률적 신뢰도를 갖는지)를 평가할 필요가 있다.

Method: 신뢰 동등성 평가를 위한 2차원 프레임워크 제안: (1) 해석가능성 정렬(interpretability alignment) — LIME와 SHAP를 사용해 모델들이 동일한 입력 특징에 근거해 예측하는지 측정; (2) 캘리브레이션 유사성 — ECE, MCE, Brier Score, 신뢰도 다이어그램으로 예측 확률의 신뢰도 비교. 실험은 BERT-base와 여러 압축 변형을 대상으로 자연어 추론(NLI)과 패러프레이즈 식별 과제에서 수행.

Result: 정확도가 거의 동일한 경우에도 해석가능성 정렬이 낮았고, 캘리브레이션에서도 유의미한 불일치가 발생함. 따라서 압축 모델은 원본과 신뢰 동등하지 않음.

Conclusion: 압축 모델을 원본 모델의 대체품으로 무비판적으로 배포하면 안 되며, 성능 평행성 외에 해석가능성 및 확률적 신뢰도 관점에서 추가 평가가 필요하다.

Abstract: Large Deep Learning models are often compressed before being deployed in a
resource-constrained environment. Can we trust the prediction of compressed
models just as we trust the prediction of the original large model? Existing
work has keenly studied the effect of compression on accuracy and related
performance measures. However, performance parity does not guarantee
trust-equivalence. We propose a two-dimensional framework for trust-equivalence
evaluation. First, interpretability alignment measures whether the models base
their predictions on the same input features. We use LIME and SHAP tests to
measure the interpretability alignment. Second, calibration similarity measures
whether the models exhibit comparable reliability in their predicted
probabilities. It is assessed via ECE, MCE, Brier Score, and reliability
diagrams. We conducted experiments using BERT-base as the large model and its
multiple compressed variants. We focused on two text classification tasks:
natural language inference and paraphrase identification. Our results reveal
low interpretability alignment and significant mismatch in calibration
similarity. It happens even when the accuracies are nearly identical between
models. These findings show that compressed models are not trust-equivalent to
their large counterparts. Deploying compressed models as a drop-in replacement
for large models requires careful assessment, going beyond performance parity.

</details>


### [156] [Prompt-Based One-Shot Exact Length-Controlled Generation with LLMs](https://arxiv.org/abs/2508.13805)
*Juncheng Xie,Hung-yi Lee*

Main category: cs.CL

TL;DR: LLMs often fail to follow explicit length constraints. The paper introduces a one-shot prompt with countdown markers and counting rules that makes off-the-shelf LLMs output exactly the desired token count (words in English, characters in Chinese) without fine-tuning. Evaluated across four tasks, the prompt dramatically improves strict-length compliance (e.g., GPT-4.1 compliance rises from <30% to >95% on MT-Bench-LI) while preserving answer quality, outperforming draft-then-revise. This shows precise length control via prompt engineering is effective.


<details>
  <summary>Details</summary>
Motivation: LLMs can’t reliably maintain internal token counts, leading to overshooting or undershooting explicit length instructions. Existing solutions rely on fine-tuning or iterative decoding; the paper seeks a lightweight, prompt-based method to achieve exact length control without such overhead.

Method: A prompt-based, one-shot strategy that appends countdown markers and explicit counting rules, prompting the model to "write while counting." It instructs counting tokens (English words) or characters (Chinese) and includes a countdown mechanism to enforce exact output length, requiring no fine-tuning or iterative sampling.

Result: Across open-ended generation (1–1000 tokens), XSUM summarization, MT-Bench-LI instruction following, and LIFEBENCH equal-length track, the countdown prompt substantially increases strict length compliance. On MT-Bench-LI, GPT-4.1 compliance improves from below 30% to above 95%, surpassing draft-then-revise baselines, with no degradation in judged answer quality.

Conclusion: Precise length control of LLM outputs can be achieved through prompt engineering alone, offering a lightweight alternative to training- and decoding-based approaches.

Abstract: Controlling the length of text produced by large language models (LLMs)
remains challenging: models frequently overshoot or undershoot explicit length
instructions because they cannot reliably keep an internal token count. We
present a prompt-based, one-shot strategy that compels an off-the-shelf LLM to
generate exactly a desired number of tokens - words (English) or characters
(Chinese) - without any fine-tuning or iterative sampling. The prompt appends
countdown markers and explicit counting rules so that the model "writes while
counting." We evaluate on four settings: open-ended generation (1-1000 tokens),
XSUM summarization, MT-Bench-LI instruction following, and the LIFEBENCH
equal-length track. On MT-Bench-LI, strict length compliance with GPT-4.1 leaps
from below 30% under naive prompts to above 95% with our countdown prompt,
surpassing the popular draft-then-revise baseline, while judged answer quality
is preserved. These results show that precise length control can be achieved
through prompt engineering alone, offering a lightweight alternative to
training- or decoding-based methods.

</details>


### [157] [The illusion of a perfect metric: Why evaluating AI's words is harder than it looks](https://arxiv.org/abs/2508.13816)
*Maria Paz Oliva,Adriana Correia,Ivan Vankov,Viktor Botev*

Main category: cs.CL

TL;DR: 본 논문은 자동 평가 지표(AEM)의 현황과 한계를 분석하고, 다양한 지표가 특정 품질 측면만 포착하며 작업·데이터셋별 성능 차이와 검증 관행의 일관성 부족을 지적한다. 특히 최신 LLM 기반 평가자와 RAG 평가에서도 문제가 지속됨을 보여주며, '완벽한 지표' 추구를 비판하고 작업별 요구에 맞춘 지표 선택과 보완적 평가 및 향상된 검증 방법론을 권장한다.


<details>
  <summary>Details</summary>
Motivation: NLG의 실용적 채택을 위해 평가가 중요하지만, 인간 평가는 비용과 확장성 문제를 갖고 있어 자동 평가 지표가 필요하다. 그러나 다양한 AEM이 존재하고 한 지표로 정리되지 않아 평가 결과의 해석과 비교가 어렵다는 문제를 해결하려는 목적.

Method: 기존 메트릭들의 방법론을 면밀히 검토하고, 각 메트릭의 강점·제한점·검증 방법·인간 평가와의 상관관계를 분석. LLM-as-a-Judge 및 RAG 평가를 포함해 최신 지표들의 성능과 한계도 조사.

Result: 메트릭들이 텍스트 품질의 특정 측면만 포착하며, 작업·데이터셋에 따라 효과가 달라지고 검증 관행이 구조화되지 않았으며 인간 평가와의 상관성이 일관되지 않음을 발견. LLM 기반 평가자와 RAG 평가에서도 동일한 문제들이 존재함을 확인.

Conclusion: '완벽한 지표'를 기대하기보다, 작업별 요구에 맞는 지표 선택과 보완적 평가(복수 지표·휴먼 검증 등), 새로운 메트릭은 엄격하고 표준화된 검증 방식을 중심으로 개발되어야 한다.

Abstract: Evaluating Natural Language Generation (NLG) is crucial for the practical
adoption of AI, but has been a longstanding research challenge. While human
evaluation is considered the de-facto standard, it is expensive and lacks
scalability. Practical applications have driven the development of various
automatic evaluation metrics (AEM), designed to compare the model output with
human-written references, generating a score which approximates human judgment.
Over time, AEMs have evolved from simple lexical comparisons, to semantic
similarity models and, more recently, to LLM-based evaluators. However, it
seems that no single metric has emerged as a definitive solution, resulting in
studies using different ones without fully considering the implications. This
paper aims to show this by conducting a thorough examination of the
methodologies of existing metrics, their documented strengths and limitations,
validation methods, and correlations with human judgment. We identify several
key challenges: metrics often capture only specific aspects of text quality,
their effectiveness varies by task and dataset, validation practices remain
unstructured, and correlations with human judgment are inconsistent.
Importantly, we find that these challenges persist in the most recent type of
metric, LLM-as-a-Judge, as well as in the evaluation of Retrieval Augmented
Generation (RAG), an increasingly relevant task in academia and industry. Our
findings challenge the quest for the 'perfect metric'. We propose selecting
metrics based on task-specific needs and leveraging complementary evaluations
and advocate that new metrics should focus on enhanced validation
methodologies.

</details>


### [158] [MME-SCI: A Comprehensive and Challenging Science Benchmark for Multimodal Large Language Models](https://arxiv.org/abs/2508.13938)
*Jiacheng Ruan,Dan Jiang,Xian Gao,Ting Liu,Yuzhuo Fu,Yangyang Kang*

Main category: cs.CL

TL;DR: MME-SCI는 수학·물리·화학·생물의 1,019개 고품질 QA와 3가지 평가 모드를 포함하고, 5개 언어를 지원하며 MLLM의 다국어·다중모달 추론과 세부 지식 약점을 평가하기 위해 고안된 어려운 벤치마크다.


<details>
  <summary>Details</summary>
Motivation: 기존 과학 도메인 벤치마크들이 다국어 평가 부족, 모달리티 커버리지 미흡, 과학 지식 포인트의 세부 주석 부재라는 한계를 보였기 때문에 이를 보완할 필요가 있다.

Method: 4개 과목(수학·물리·화학·생물)과 5개 언어(중·영·프·스·일)를 포함하는 1,019개 QA를 수집하고, 이미지 포함 여부 등 3가지 평가 모드로 테스트를 설계했다. 또한 16개 오픈소스·4개 클로즈드소스 모델에 대해 광범위한 실험을 수행하고, 다국어·세부 지식 속성에 따른 성능 분석을 진행했다.

Result: MME-SCI는 기존 모델에 대해 높은 난이도를 보였으며, 예컨대 Image-only 모드에서 o4-mini의 정확도는 수학 52.11%, 물리 24.73%, 화학 36.57%, 생물 29.80%로 낮게 나타났다. 전반적으로 대부분 모델이 특정 도메인과 언어·지식 항목에서 취약함을 보였다.

Conclusion: MME-SCI는 MLLM의 다국어·다중모달 과학 추론 능력을 더욱 정밀하게 평가할 수 있는 도구로, 모델의 약점을 파악하고 향후 개선 방향을 제시할 수 있다. 데이터·평가 코드는 공개되어 재현과 확장이 가능하다.

Abstract: Recently, multimodal large language models (MLLMs) have achieved significant
advancements across various domains, and corresponding evaluation benchmarks
have been continuously refined and improved. In this process, benchmarks in the
scientific domain have played an important role in assessing the reasoning
capabilities of MLLMs. However, existing benchmarks still face three key
challenges: 1) Insufficient evaluation of models' reasoning abilities in
multilingual scenarios; 2) Inadequate assessment of MLLMs' comprehensive
modality coverage; 3) Lack of fine-grained annotation of scientific knowledge
points. To address these gaps, we propose MME-SCI, a comprehensive and
challenging benchmark. We carefully collected 1,019 high-quality
question-answer pairs, which involve 3 distinct evaluation modes. These pairs
cover four subjects, namely mathematics, physics, chemistry, and biology, and
support five languages: Chinese, English, French, Spanish, and Japanese. We
conducted extensive experiments on 16 open-source models and 4 closed-source
models, and the results demonstrate that MME-SCI is widely challenging for
existing MLLMs. For instance, under the Image-only evaluation mode, o4-mini
achieved accuracy of only 52.11%, 24.73%, 36.57%, and 29.80% in mathematics,
physics, chemistry, and biology, respectively, indicating a significantly
higher difficulty level compared to existing benchmarks. More importantly,
using MME-SCI's multilingual and fine-grained knowledge attributes, we analyzed
existing models' performance in depth and identified their weaknesses in
specific domains. The Data and Evaluation Code are available at
https://github.com/JCruan519/MME-SCI.

</details>


### [159] [Extracting Structured Requirements from Unstructured Building Technical Specifications for Building Information Modeling](https://arxiv.org/abs/2508.13833)
*Insaf Nahri,Romain Pinquié,Philippe Véron,Nicolas Bus,Mathieu Thorel*

Main category: cs.CL

TL;DR: 프랑스어 건설 기술 명세서(BTS) 문서에서 요구사항을 자동 추출하기 위해 BIM과 NLP를 통합한 연구. CamemBERT와 Fr_core_news_lg를 이용한 NER이 F1>90%를 달성했고, 관계추출(RE)에서는 Random Forest가 F1>80%로 가장 우수함.


<details>
  <summary>Details</summary>
Motivation: 건설 산업의 BTS 문서가 비정형 텍스트로 되어 있어 BIM에 요구사항을 수동으로 입력하는 데 시간과 비용이 많이 소요된다. 이를 자동화해 설계·검증 과정을 효율화하려는 목적.

Method: NER과 관계추출(RE)을 적용. NER에 트랜스포머 기반 CamemBERT와 프랑스어 사전학습 모델 Fr_core_news_lg(전이학습)을 사용하고, 규칙 기반부터 딥러닝 기반까지 여러 비교 기법을 개발. RE는 사용자 정의 특징 벡터로 Random Forest 등 감독학습 모델 4종을 구현. 비교를 위해 수작업 주석 데이터셋 사용.

Result: NER: CamemBERT와 Fr_core_news_lg가 우수하여 F1>90% 달성. RE: Random Forest가 가장 효과적이며 F1>80% 기록. 전체적으로 제안 기법들이 요구사항 추출에 높은 정확도를 보임.

Conclusion: 트랜스포머 기반 NER과 전통 머신러닝 기반 RE의 조합이 프랑스어 BTS에서 요구사항 자동 추출에 효과적임. 결과를 지식그래프로 표현해 자동 검증 시스템에 통합하는 후속 연구 계획이 제시됨.

Abstract: This study explores the integration of Building Information Modeling (BIM)
with Natural Language Processing (NLP) to automate the extraction of
requirements from unstructured French Building Technical Specification (BTS)
documents within the construction industry. Employing Named Entity Recognition
(NER) and Relation Extraction (RE) techniques, the study leverages the
transformer-based model CamemBERT and applies transfer learning with the French
language model Fr\_core\_news\_lg, both pre-trained on a large French corpus in
the general domain. To benchmark these models, additional approaches ranging
from rule-based to deep learning-based methods are developed. For RE, four
different supervised models, including Random Forest, are implemented using a
custom feature vector. A hand-crafted annotated dataset is used to compare the
effectiveness of NER approaches and RE models. Results indicate that CamemBERT
and Fr\_core\_news\_lg exhibited superior performance in NER, achieving
F1-scores over 90\%, while Random Forest proved most effective in RE, with an
F1 score above 80\%. The outcomes are intended to be represented as a knowledge
graph in future work to further enhance automatic verification systems.

</details>


### [160] [ViExam: Are Vision Language Models Better than Humans on Vietnamese Multimodal Exam Questions?](https://arxiv.org/abs/2508.13680)
*Vy Tuong Dang,An Vo,Quang Tau,Duc Dm,Daeyoung Kim*

Main category: cs.CL

TL;DR: ViExam이라는 2,548문항 규모의 베트남어 멀티모달 시험 벤치마크를 제안하고, 여러 VLM을 평가한 결과 SOTA 모델 평균 57.74%, 오픈소스 모델 평균 27.70%로 인간 평균(66.54%)에 미치지 못함을 보고함. 일부 모델(Thinking VLM o3)은 인간 평균을 넘지만 최고 인간 성과(99.60%)에는 크게 못미침. 영어 지침을 섞는 크로스링구얼 프롬프트는 성능 개선에 실패하며, 휴먼-인-더-루프로 약 5%p 개선 가능.


<details>
  <summary>Details</summary>
Motivation: 영어 중심으로 훈련된 VLM들이 실제로 저자원 언어(여기서는 베트남어)의 멀티모달 교육 평가를 잘 수행하는지 검증하고자 함. 교육용 문제는 그림·수식·표 등이 섞인 진정한 멀티모달 자료를 포함하므로 크로스링구얼 멀티모달 추론 능력의 한계 파악이 필요함.

Method: 베트남어 멀티모달 시험 데이터셋 ViExam(2,548문항, 수학·물리·화학·생물·지리·운전·IQ 등 7개 분야) 구성. SOTA 및 오픈소스 VLM들을 대상으로 벤치마크 평가를 수행하고, 영어 지침 교차프롬프트와 휴먼-인-더-루프 협업 시나리오를 추가 실험하여 성능 변화를 분석.

Result: SOTA VLM 평균 정확도 57.74%, 오픈소스 모델 평균 27.70%. 인간 평균 66.54%, 인간 최고 99.60%. Thinking VLM o3가 74.07%로 인간 평균을 넘었으나 최고 인간 성능과는 큰 격차. 영어 지침 사용 시 SOTA 성능이 약 1%p 감소. 인간-협업으로 약 5%p 성능 향상 관찰.

Conclusion: 영어 중심으로 훈련된 VLM들은 베트남어 멀티모달 교육 평가에서 제한적 성능을 보이며, 크로스링구얼 프롬프트는 도움이 되지 않음. 인간-인-루프가 일부 도움을 주지만 모델 개선 및 다국어 멀티모달 자료에 대한 추가 연구와 데이터/파인튜닝이 필요함.

Abstract: Vision language models (VLMs) demonstrate remarkable capabilities on English
multimodal tasks, but their performance on low-resource languages with
genuinely multimodal educational content remains largely unexplored. In this
work, we test how VLMs perform on Vietnamese educational assessments,
investigating whether VLMs trained predominantly on English data can handle
real-world cross-lingual multimodal reasoning. Our work presents the first
comprehensive evaluation of VLM capabilities on multimodal Vietnamese exams
through proposing ViExam, a benchmark containing 2,548 multimodal questions. We
find that state-of-the-art VLMs achieve only 57.74% while open-source models
achieve 27.70% mean accuracy across 7 academic domains, including Mathematics,
Physics, Chemistry, Biology, Geography, Driving Test, and IQ Test. Most VLMs
underperform average human test-takers (66.54%), with only the thinking VLM o3
(74.07%) exceeding human average performance, yet still falling substantially
short of human best performance (99.60%). Cross-lingual prompting with English
instructions while maintaining Vietnamese content fails to improve performance,
decreasing accuracy by 1 percentage point for SOTA VLMs. Human-in-the-loop
collaboration can partially improve VLM performance by 5 percentage points.
Code and data are available at: https://vi-exam.github.io.

</details>


### [161] [Prediction is not Explanation: Revisiting the Explanatory Capacity of Mapping Embeddings](https://arxiv.org/abs/2508.13729)
*Hanna Herasimchyk,Alhassan Abdelhalim,Sören Laue,Michaela Regneri*

Main category: cs.CL

TL;DR: 이 논문은 단어 임베딩에서 인간 해석 가능한 특징(feature norms)을 예측하는 기존 방법들이 예측 정확도만으로 임베딩이 해당 지식을 담고 있다고 단정할 수 없음을 보인다. 예측 성능은 임베딩의 의미적 표현보다 알고리즘적 상한과 벡터 공간의 기하학적 유사성에 크게 의존한다는 결론을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 단어 임베딩이 어떤 지식을 내부에 암묵적으로 저장하고 있는지 이해하는 것은 AI 해석 가능성 향상에 중요하다. 기존 연구들은 임베딩을 사람 해석 가능한 의미적 특징(피처 노름)에 매핑해 그 지식 유무를 평가해왔으나, 예측 정확도가 곧 임베딩의 의미 지식 존재를 보장하는지 의문을 제기한다.

Method: 기존 피처 예측 방법을 분석하고, 무작위 정보(랜덤 레이블)를 사용한 실험을 포함해 예측 정확도가 실제 의미적 표현인지 판단하는 데 실패한다는 것을 입증한다. 알고리즘적 상한과 벡터 공간의 기하학적 유사성이 결과에 미치는 영향을 이론적·실험적으로 분석한다.

Result: 피처 노름 예측 방법은 랜덤 정보조차 성공적으로 예측할 수 있으며, 성능은 주로 알고리즘적 상한과 임베딩 벡터 간 기하학적 유사성(예: 코사인 유사도 등)에 의해 좌우된다. 따라서 데이터셋 간의 단순한 예측 성능 비교는 임베딩이 어떤 데이터셋을 더 잘 포착하는지를 신뢰성 있게 나타내지 못한다.

Conclusion: 단순한 피처 예측 성능은 임베딩의 진정한 의미적 지식의 존재를 증명하지 못한다. 이러한 매핑은 실제 의미 속성의 출현을 의미하기보다 벡터 공간의 기하학적 유사성을 반영한다. 따라서 임베딩 해석을 위해선 예측 정확도 외에 더 엄격한 검증 방법과 대안적 해석 기법이 필요하다.

Abstract: Understanding what knowledge is implicitly encoded in deep learning models is
essential for improving the interpretability of AI systems. This paper examines
common methods to explain the knowledge encoded in word embeddings, which are
core elements of large language models (LLMs). These methods typically involve
mapping embeddings onto collections of human-interpretable semantic features,
known as feature norms. Prior work assumes that accurately predicting these
semantic features from the word embeddings implies that the embeddings contain
the corresponding knowledge. We challenge this assumption by demonstrating that
prediction accuracy alone does not reliably indicate genuine feature-based
interpretability.
  We show that these methods can successfully predict even random information,
concluding that the results are predominantly determined by an algorithmic
upper bound rather than meaningful semantic representation in the word
embeddings. Consequently, comparisons between datasets based solely on
prediction performance do not reliably indicate which dataset is better
captured by the word embeddings. Our analysis illustrates that such mappings
primarily reflect geometric similarity within vector spaces rather than
indicating the genuine emergence of semantic properties.

</details>


### [162] [Unintended Misalignment from Agentic Fine-Tuning: Risks and Mitigation](https://arxiv.org/abs/2508.14031)
*Dongyoon Hahm,Taywon Min,Woogyeol Jin,Kimin Lee*

Main category: cs.CL

TL;DR: Fine-tuned LLM 에이전트가 에이전트 작업으로 미세조정될 때 의도치 않게 비동조화되어 유해한 요청을 더 잘 수행하고 거절을 덜 하게 되는 문제를 발견하고, 자동으로 생성한 자연어 접두사(prefix)를 응답 앞에 붙여 유해 요청을 거절하도록 유도하는 PING 기법을 제안한다. 성능 손실 없이 안전성 향상을 보이며 기존 프롬프트 기법들보다 우수하다.


<details>
  <summary>Details</summary>
Motivation: 에이전트 기능을 강화하기 위해 LLM을 에이전트 전용 작업으로 미세조정하면 안전성(유해 요청 거부)이 약화될 수 있다는 우려에서 출발. 미세조정 과정에서 발생하는 ‘비동조화(misalignment)’ 문제를 해결해 에이전트로서의 기능은 유지하면서도 유해행동을 줄이려 함.

Method: Prefix INjection Guard(PING): 자동으로 생성한 자연어 접두사들을 모델 응답 앞에 삽입해 유해 요청에 대해 거절하도록 유도. 반복적 접근법으로 (1) 후보 접두사 생성과 (2) 작업 성능과 거절 행동을 모두 최적화하는 접두사 선택을 교차적으로 수행.

Result: 웹 탐색 및 코드 생성 벤치마크에서 PING이 안전성을 크게 개선하면서 정상 작업 성능을 유지했고, 기존의 프롬프트 기반 방법들보다 일관되게 우수한 성능을 보임. 내부 히든 상태 분석(선형 프로브)을 통해 접두사 토큰이 행동 수정에 핵심적임을 확인.

Conclusion: 간단한 자연어 접두사 주입과 자동 선택 절차만으로 미세조정된 LLM 에이전트의 안전성을 실효성 있게 향상시킬 수 있으며, 접두사 토큰이 모델 행동을 조절하는 메커니즘을 뒷받침한다.

Abstract: Beyond simple text generation, Large Language Models (LLMs) have evolved into
agentic systems capable of planning and interacting with external tools to
solve complex tasks. This evolution involves fine-tuning LLMs on agent-specific
tasks to enhance their proficiency. However, safety concerns are frequently
overlooked during this fine-tuning process. In this work, we show that aligned
LLMs can become unintentionally misaligned, leading to a higher likelihood of
executing harmful tasks and a reduced tendency to refuse them when fine-tuned
to execute agentic tasks. To address these safety challenges, we propose Prefix
INjection Guard (PING), a simple yet effective method that prepends
automatically generated natural language prefixes to agent responses, guiding
them to refuse harmful requests while preserving performance on benign tasks.
Specifically, we introduce an iterative approach that alternates between (1)
generating candidate prefixes and (2) selecting those that optimize both task
performance and refusal behavior. Experimental results demonstrate that PING
significantly enhances the safety of fine-tuned LLM agents without sacrificing
their effectiveness. PING consistently outperforms existing prompting
approaches across diverse benchmarks in both web navigation and code generation
tasks. Our analysis of internal hidden states via linear probes reveals that
prefix tokens are crucial for behavior modification, explaining the performance
gains. WARNING: This paper contains contents that are unethical or offensive in
nature.

</details>


### [163] [Chunks as Arms: Multi-Armed Bandit-Guided Sampling for Long-Context LLM Preference Optimization](https://arxiv.org/abs/2508.13993)
*Shaohua Duan,Xinze Li,Zhenghao Liu,Xiaoyuan Yi,Yukun Yan,Shuo Wang,Yu Gu,Ge Yu,Maosong Sun*

Main category: cs.CL

TL;DR: LongMab-PO는 긴 문맥을 여러 청크로 나누고 각 청크를 MAB(다중 무장 강도기) 팔로 취급해 보상을 바탕으로 유의미한 청크를 선택·롤아웃하여 LLM으로부터 다양하고 고품질의 응답을 생성한 뒤, 이를 DPO(직접 선호 최적화)로 학습시켜 장문 추론 성능을 크게 향상시키는 방법이다.


<details>
  <summary>Details</summary>
Motivation: 긴 문맥 QA·요약·추론 등에서 LLM의 장문 처리 능력이 중요하나, 합성 데이터로 파인튜닝할 때 생성 데이터의 다양성 부족과 사실적 불일치가 성능 향상을 제한함. 더 관련성 높고 다양한 응답을 효율적으로 수집할 방법이 필요함.

Method: 긴 문맥을 여러 청크로 분할하고 각 청크를 MAB의 팔로 간주. 기대 보상 점수에 따라 청크를 선택해 LLM에 입력하고 응답을 생성하며, 응답에 대한 보상 피드백으로 각 팔의 점수를 갱신하는 탐색·활용 루프를 수행. 롤아웃으로 수집한 다양한 고품질 응답을 쌍으로 만들어 DPO로 최종 학습함.

Result: 롤아웃 기반 샘플링이 선호 데이터 쌍의 다양성과 품질을 향상시켰고, 장문 추론 벤치마크에서 SOTA 수준의 성능을 달성했다고 보고. 코드·데이터 공개 예정.

Conclusion: MAB 기반 청크 선택과 DPO 결합은 장문 문맥에서 관련성 높은 고품질 합성 선호 데이터를 얻는 효과적 방법임. 다만 보상 설계와 계산 비용, 실제 문서 다양성에 대한 일반화 문제 등 한계가 있을 수 있으며 보상 신호 개선 및 스케일링 연구가 후속 과제다.

Abstract: Long-context modeling is critical for a wide range of real-world tasks,
including long-context question answering, summarization, and complex reasoning
tasks. Recent studies have explored fine-tuning Large Language Models (LLMs)
with synthetic data to enhance their long-context capabilities. However, the
effectiveness of such approaches is often limited by the low diversity and
factual inconsistencies in the generated data. To address these challenges, we
propose LongMab-PO, a novel framework that leverages a Multi-Armed Bandit (MAB)
rollout strategy to identify the most informative chunks from the given long
context for sampling high-quality and diverse responses and constructing
preference data pairs for Direct Preference Optimization (DPO) training.
Specifically, we treat context chunks as arms of MAB, select chunks based on
their expected reward scores to input into LLMs to generate responses, and
iteratively update these scores based on reward feedback. This exploration and
exploitation process enables the model to focus on the most relevant context
segments, thereby generating and collecting high-quality and diverse responses.
Finally, we collect these generated responses from the rollout process and
apply the DPO method to further optimize the LLM. Experimental results show
that LongMab-PO significantly improves the diversity and quality of preference
data pairs, achieving state-of-the-art performance on long-context reasoning
benchmarks. All code and data will be released on
https://github.com/NEUIR/LongMab-PO.

</details>


### [164] [Ask Good Questions for Large Language Models](https://arxiv.org/abs/2508.14025)
*Qi Wu,Zhongqi Lu*

Main category: cs.CL

TL;DR: AGQ(Ask-Good-Question) 프레임워크는 개선된 개념 강화 항목반응이론(CEIRT) 모델과 LLM을 결합해 사용자의 개념별 혼동을 판별하고, 영감을 주는 텍스트로부터 직접 안내 질문을 생성하여 질의응답 과정에서 정보 검색 효율을 크게 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 기존 대화 시스템은 연관 개념에 대한 사용자의 혼동을 정확히 구별하지 못해 주제 안내가 부정확하고 정보 탐색이 비효율적이라는 문제를 해결하려고 함.

Method: CEIRT 모델을 통해 사용자의 지식 수준(개념별 이해·혼동)을 더 정교하게 식별하고, 이 정보를 바탕으로 LLM과 결합해 ‘영감을 주는 텍스트’로부터 직접 안내 질문을 생성하는 AGQ 프레임워크를 제안함. 이를 통해 질의응답 중 사용자가 필요한 정보를 더 빠르게 찾도록 유도함.

Result: 제안 방법은 여러 baseline과 비교해 사용자의 정보 검색 경험을 유의미하게 개선했으며, 안내 질문 생성으로 검색 효율이 향상되었다고 보고함(정량적 수치 미공개).

Conclusion: CEIRT와 LLM의 결합을 통한 AGQ는 대화형 QA 시스템에서 사용자의 개념 혼동을 줄이고 주제 안내 및 정보 검색 효율을 높이는 실용적 접근법임.

Abstract: Recent advances in large language models (LLMs) have significantly improved
the performance of dialog systems, yet current approaches often fail to provide
accurate guidance of topic due to their inability to discern user confusion in
related concepts. To address this, we introduce the Ask-Good-Question (AGQ)
framework, which features an improved Concept-Enhanced Item Response Theory
(CEIRT) model to better identify users' knowledge levels. Our contributions
include applying the CEIRT model along with LLMs to directly generate guiding
questions based on the inspiring text, greatly improving information retrieval
efficiency during the question & answer process. Through comparisons with other
baseline methods, our approach outperforms by significantly enhencing the
users' information retrieval experiences.

</details>


### [165] [Unintended Misalignment from Agentic Fine-Tuning: Risks and Mitigation](https://arxiv.org/abs/2508.14031)
*Dongyoon Hahm,Taywon Min,Woogyeol Jin,Kimin Lee*

Main category: cs.CL

TL;DR: Fine-tuned LLM 에이전트가 에이전트 작업으로 미세조정될 때 의도치 않게 비동조화되어 유해한 요청을 더 잘 수행하고 거절을 덜 하게 되는 문제를 발견하고, 자동으로 생성한 자연어 접두사(prefix)를 응답 앞에 붙여 유해 요청을 거절하도록 유도하는 PING 기법을 제안한다. 성능 손실 없이 안전성 향상을 보이며 기존 프롬프트 기법들보다 우수하다.


<details>
  <summary>Details</summary>
Motivation: 에이전트 기능을 강화하기 위해 LLM을 에이전트 전용 작업으로 미세조정하면 안전성(유해 요청 거부)이 약화될 수 있다는 우려에서 출발. 미세조정 과정에서 발생하는 ‘비동조화(misalignment)’ 문제를 해결해 에이전트로서의 기능은 유지하면서도 유해행동을 줄이려 함.

Method: Prefix INjection Guard(PING): 자동으로 생성한 자연어 접두사들을 모델 응답 앞에 삽입해 유해 요청에 대해 거절하도록 유도. 반복적 접근법으로 (1) 후보 접두사 생성과 (2) 작업 성능과 거절 행동을 모두 최적화하는 접두사 선택을 교차적으로 수행.

Result: 웹 탐색 및 코드 생성 벤치마크에서 PING이 안전성을 크게 개선하면서 정상 작업 성능을 유지했고, 기존의 프롬프트 기반 방법들보다 일관되게 우수한 성능을 보임. 내부 히든 상태 분석(선형 프로브)을 통해 접두사 토큰이 행동 수정에 핵심적임을 확인.

Conclusion: 간단한 자연어 접두사 주입과 자동 선택 절차만으로 미세조정된 LLM 에이전트의 안전성을 실효성 있게 향상시킬 수 있으며, 접두사 토큰이 모델 행동을 조절하는 메커니즘을 뒷받침한다.

Abstract: Beyond simple text generation, Large Language Models (LLMs) have evolved into
agentic systems capable of planning and interacting with external tools to
solve complex tasks. This evolution involves fine-tuning LLMs on agent-specific
tasks to enhance their proficiency. However, safety concerns are frequently
overlooked during this fine-tuning process. In this work, we show that aligned
LLMs can become unintentionally misaligned, leading to a higher likelihood of
executing harmful tasks and a reduced tendency to refuse them when fine-tuned
to execute agentic tasks. To address these safety challenges, we propose Prefix
INjection Guard (PING), a simple yet effective method that prepends
automatically generated natural language prefixes to agent responses, guiding
them to refuse harmful requests while preserving performance on benign tasks.
Specifically, we introduce an iterative approach that alternates between (1)
generating candidate prefixes and (2) selecting those that optimize both task
performance and refusal behavior. Experimental results demonstrate that PING
significantly enhances the safety of fine-tuned LLM agents without sacrificing
their effectiveness. PING consistently outperforms existing prompting
approaches across diverse benchmarks in both web navigation and code generation
tasks. Our analysis of internal hidden states via linear probes reveals that
prefix tokens are crucial for behavior modification, explaining the performance
gains. WARNING: This paper contains contents that are unethical or offensive in
nature.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [166] [BERT-VQA: Visual Question Answering on Plots](https://arxiv.org/abs/2508.13184)
*Tai Vu,Robert Yang*

Main category: cs.LG

TL;DR: 시각-질문 응답(plots VQA) 과제에서 VisualBERT 기반 BERT-VQA와 ResNet101 이미지 인코더를 사용해 LSTM+CNN 기반 베이스라인과 비교했다. 교차-모달리티 모듈이 플롯 구성 요소와 질문 구문 정렬에 필수적이라는 가설은 기각되었다.


<details>
  <summary>Details</summary>
Motivation: 시각-언어 통합 능력을 요구하는 visual question answering에서 특히 플롯(그래프) 이미지에 대한 질문 응답 성능을 향상시키는 것.

Method: VisualBERT를 기반으로 한 BERT-VQA 아키텍처와 사전학습된 ResNet101 이미지 인코더를 사용하고, 옵션으로 joint fusion을 추가. 베이스라인으로는 LSTM, CNN, 얕은 분류기를 구성하여 비교 실험 수행.

Result: 실험 결과 교차-모달리티 모듈(VisualBERT의 cross-modality)이 플롯 요소와 질문 구문을 정렬하는 데 필수적이라는 핵심 가설이 기각됨. 즉, 추가적 교차-모달리티가 기대만큼 도움이 되지 않음.

Conclusion: 플롯 질문 응답 문제의 난이도와 다양한 모델 아키텍처의 적절성에 대한 통찰을 제공. 특정 경우에는 VisualBERT의 cross-modality 모듈이 성능 향상에 결정적이지 않을 수 있음을 시사.

Abstract: Visual question answering has been an exciting challenge in the field of
natural language understanding, as it requires deep learning models to exchange
information from both vision and language domains. In this project, we aim to
tackle a subtask of this problem, namely visual question answering on plots. To
achieve this, we developed BERT-VQA, a VisualBERT-based model architecture with
a pretrained ResNet 101 image encoder, along with a potential addition of joint
fusion. We trained and evaluated this model against a baseline that consisted
of a LSTM, a CNN, and a shallow classifier. The final outcome disproved our
core hypothesis that the cross-modality module in VisualBERT is essential in
aligning plot components with question phrases. Therefore, our work provided
valuable insights into the difficulty of the plot question answering challenge
as well as the appropriateness of different model architectures in solving this
problem.

</details>


### [167] [Contextual Attention-Based Multimodal Fusion of LLM and CNN for Sentiment Analysis](https://arxiv.org/abs/2508.13196)
*Meriem Zerkouk,Miloud Mihoubi,Belkacem Chikhaoui*

Main category: cs.LG

TL;DR: 자연재해 상황의 소셜미디어 다중모달 감정분석을 위해 이미지(CNN)와 텍스트(LLM/GPT)를 통합하고, 문맥적 어텐션 기반 융합을 도입하여 CrisisMMD 데이터셋에서 유의미한 성능 향상을 보인 모델을 제안한다. Accuracy +2.43%, F1 +5.18%.


<details>
  <summary>Details</summary>
Motivation: 재난 상황에서 대중의 감정(정보성 여부)을 신속·정확하게 파악하는 것은 위기 관리에 중요하다. 기존 방법은 텍스트와 이미지를 개별 처리해 모달 간 상호작용을 충분히 반영하지 못한다.

Method: 이미지 특징은 CNN으로 추출하고 텍스트는 GPT 기반 LLM과 프롬프트 엔지니어링으로 감정 관련 특징을 추출한다. 추출된 특징들은 문맥적 어텐션층을 통해 교차-모달 상호작용을 학습하며, 융합된 특징을 심층 신경망으로 분류에 이용한다.

Result: CrisisMMD 데이터셋에서 기존 베이스라인 대비 정확도 2.43%p, F1-score 5.18%p 향상. 다양한 재난 유형에서 유의미/비유의미 분류 성능 개선을 확인.

Conclusion: LLM 기반 텍스트 처리와 CNN 이미지 처리의 융합, 특히 문맥적 어텐션을 통한 상호작용 모델링이 멀티모달 재난 감정분석 성능을 개선하며, 실시간 재난 대응에 활용 가능한 잠재력을 보인다.

Abstract: This paper introduces a novel approach for multimodal sentiment analysis on
social media, particularly in the context of natural disasters, where
understanding public sentiment is crucial for effective crisis management.
Unlike conventional methods that process text and image modalities separately,
our approach seamlessly integrates Convolutional Neural Network (CNN) based
image analysis with Large Language Model (LLM) based text processing,
leveraging Generative Pre-trained Transformer (GPT) and prompt engineering to
extract sentiment relevant features from the CrisisMMD dataset. To effectively
model intermodal relationships, we introduce a contextual attention mechanism
within the fusion process. Leveraging contextual-attention layers, this
mechanism effectively captures intermodality interactions, enhancing the
model's comprehension of complex relationships between textual and visual data.
The deep neural network architecture of our model learns from these fused
features, leading to improved accuracy compared to existing baselines.
Experimental results demonstrate significant advancements in classifying social
media data into informative and noninformative categories across various
natural disasters. Our model achieves a notable 2.43% increase in accuracy and
5.18% in F1-score, highlighting its efficacy in processing complex multimodal
data. Beyond quantitative metrics, our approach provides deeper insight into
the sentiments expressed during crises. The practical implications extend to
real time disaster management, where enhanced sentiment analysis can optimize
the accuracy of emergency interventions. By bridging the gap between multimodal
analysis, LLM powered text understanding, and disaster response, our work
presents a promising direction for Artificial Intelligence (AI) driven crisis
management solutions. Keywords:

</details>


### [168] [Strategies for training point distributions in physics-informed neural networks](https://arxiv.org/abs/2508.13216)
*Santosh Humagain,Toni Schneidereit*

Main category: cs.LG

TL;DR: 


<details>
  <summary>Details</summary>
Motivation: 

Method: 

Result: 

Conclusion: 

Abstract: Physics-informed neural networks approach the approximation of differential
equations by directly incorporating their structure and given conditions in a
loss function. This enables conditions like, e.g., invariants to be easily
added during the modelling phase. In addition, the approach can be considered
as mesh free and can be utilised to compute solutions on arbitrary grids after
the training phase. Therefore, physics-informed neural networks are emerging as
a promising alternative to solving differential equations with methods from
numerical mathematics. However, their performance highly depends on a large
variety of factors. In this paper, we systematically investigate and evaluate a
core component of the approach, namely the training point distribution. We test
two ordinary and two partial differential equations with five strategies for
training data generation and shallow network architectures, with one and two
hidden layers. In addition to common distributions, we introduce sine-based
training points, which are motivated by the construction of Chebyshev nodes.
The results are challenged by using certain parameter combinations like, e.g.,
random and fixed-seed weight initialisation for reproducibility. The results
show the impact of the training point distributions on the solution accuracy
and we find evidence that they are connected to the characteristics of the
differential equation.

</details>


### [169] [Deep Graph Neural Point Process For Learning Temporal Interactive Networks](https://arxiv.org/abs/2508.13219)
*Su Chen,Xiaohua Qi,Xixun Lin,Yanmin Shang,Xiaolin Xu,Yangxi Li*

Main category: cs.LG

TL;DR: DGNPP는 네트워크 토폴로지를 반영해 정적 표현을 생성하는 Node Aggregation Layer와 시점에 따라 임베딩을 갱신하는 Self Attentive Layer를 결합해 시공간 상호작용 이벤트와 발생시간을 예측하는 모델이다. 정적+동적 임베딩을 강도함수에 통합하고 최대우도추정을 통해 학습하며, 세 데이터셋에서 이벤트 및 시간 예측에서 기존 모델들보다 우수한 성능과 효율성을 보였다.


<details>
  <summary>Details</summary>
Motivation: 기존 TIN(temporal interaction networks) 연구들은 다중 시퀀스 예측 문제로 간주해 네트워크 토폴로지(정적 구조)의 영향을 무시했다. 그러나 사용자-아이템 간의 정적 네트워크 구조는 상호작용 패턴과 이벤트 발생 확률에 중요한 영향을 미칠 수 있어 이를 반영하는 모델이 필요하다.

Method: DGNPP는 두 모듈로 구성된다: (1) Node Aggregation Layer: 그래프 신경망을 통해 사용자와 아이템의 정적(토폴로지 기반) 표현을 생성한다. (2) Self Attentive Layer: 시간에 따라 임베딩을 동적으로 업데이트하는 자기어텐션 기반 모듈. 정적 및 동적 임베딩을 이벤트 강도(intensity) 함수에 결합하고, 최대우도추정을 통해 모델을 학습하여 다음 이벤트의 종류(대상)와 발생시각을 예측한다.

Result: 세 개 공개 데이터셋에서 실험한 결과, DGNPP는 이벤트 예측과 시간 예측에서 베이스라인 모델들보다 유의미하게 우수한 성능을 보였고 계산 효율성도 높았다. 또한 기존 접근법의 한계를 효과적으로 완화했다.

Conclusion: 정적 그래프 구조와 동적 시간적 패턴을 결합한 DGNPP는 TIN의 예측 정확도와 효율성을 개선하며, 토폴로지 정보를 반영하는 것이 시간적 상호작용 모델링에 유용함을 입증한다.

Abstract: Learning temporal interaction networks(TIN) is previously regarded as a
coarse-grained multi-sequence prediction problem, ignoring the network topology
structure influence. This paper addresses this limitation and a Deep Graph
Neural Point Process(DGNPP) model for TIN is proposed. DGNPP consists of two
key modules: the Node Aggregation Layer and the Self Attentive Layer. The Node
Aggregation Layer captures topological structures to generate static
representation for users and items, while the Self Attentive Layer dynamically
updates embeddings over time. By incorporating both dynamic and static
embeddings into the event intensity function and optimizing the model via
maximum likelihood estimation, DGNPP predicts events and occurrence time
effectively. Experimental evaluations on three public datasets demonstrate that
DGNPP achieves superior performance in event prediction and time prediction
tasks with high efficiency, significantly outperforming baseline models and
effectively mitigating the limitations of prior approaches.

</details>


### [170] [A Recurrent Neural Network based Clustering Method for Binary Data Sets in Education](https://arxiv.org/abs/2508.13224)
*Mizuki Ohira,Toshimichi Saito*

Main category: cs.LG

TL;DR: S-P 차트(교육에서 널리 쓰이는 이진 데이터)를 군집화하기 위해 순환신경망을 적용한 방법을 제시한다. 네트워크의 고정점을 군집의 중심으로 사용하고 수렴 역역을 각 군집으로 해석한다. 군집 성능 평가지표로 평균 주의 지수(average caution index)를 도입하고 실험으로 방법의 유효성을 확인했다.


<details>
  <summary>Details</summary>
Motivation: 학생 수가 증가함에 따라 S-P 차트가 다루기 어려워지므로, 큰 차트를 더 작은 차트로 분류(군집화)하여 분석을 용이하게 하려는 필요성.

Method: 순환신경망(RNN)을 사용하여 여러 고정점을 갖는 네트워크를 설계하고, 각 고정점의 흡인역(수렴 영역)을 하나의 군집으로 본다. 이는 네트워크 동역학을 이용한 단순한 군집화 방법이다. 또한 군집 성능을 평가하기 위해 '평균 주의 지수(average caution index)'라는 특성량을 제안한다.

Result: 기본적인 실험에서 제안한 방법이 효과적임을 확인했으며, 평균 주의 지수가 학생 응답 패턴의 특이성(특성)을 잘 나타내는 것으로 보인다.

Conclusion: 네트워크 동역학 기반 군집화 방법은 대규모 S-P 차트를 소규모 차트로 분류하는 데 유효하며, 평균 주의 지수는 군집 성능 평가에 유용한 지표로 사용될 수 있다.

Abstract: This paper studies an application of a recurrent neural network to clustering
method for the S-P chart: a binary data set used widely in education. As the
number of students increases, the S-P chart becomes hard to handle. In order to
classify the large chart into smaller charts, we present a simple clustering
method based on the network dynamics. In the method, the network has multiple
fixed points and basins of attraction give clusters corresponding to small S-P
charts. In order to evaluate the clustering performance, we present an
important feature quantity: average caution index that characterizes
singularity of students answer oatterns. Performing fundamental experiments,
effectiveness of the method is confirmed.

</details>


### [171] [RISE: Enhancing VLM Image Annotation with Self-Supervised Reasoning](https://arxiv.org/abs/2508.13229)
*Suhang Hu,Wei Hu,Yuhang Su,Fan Zhang*

Main category: cs.LG

TL;DR: RISE는 시각 언어 모델의 복잡한 이미지 주석(감정 분류, 상황 기반 객체 탐지 등)에서 추론을 개선하기 위한 두 단계 프레임워크다. 첫 단계(RISE-CoT)는 강화학습 기반의 '주석-추론-주석' 폐쇄 루프를 통해 시각적으로 근거있고 논리적으로 일관된 CoT를 생성하고, CoT의 품질을 보상으로 평가해 샘플을 필터링한다. 두 번째 단계(RISE-R1)는 필터된 고품질 CoT로 SFT와 이후 RFT를 순차 적용하여 해석 가능한 추론과 정확한 주석을 얻는다. Qwen2-VL-2B에 적용 시 SFT와 Visual-RFT보다 우수한 성능과 설명 가능성을 보였고, 수동 라벨링된 CoT 없이 자기지도 방식으로 VLM의 추론 능력을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 기존 SFT는 결과(주석)만 학습해 내적 추론을 배우지 못하고, Visual-RFT는 사전학습 시 고품질 CoT가 없어 일관된 사고흐름(CoT)을 생성하지 못한다. 복잡한 시각 주석 작업에는 시각적 근거와 논리적 일관성을 가진 CoT가 필요하다.

Method: 두 단계: 1) Reason 단계(RISE-CoT): 강화학습 기반의 'annotation-reasoning-annotation' 폐쇄 루프를 통해 CoT를 생성하고, 생성된 CoT가 원래 주석을 재구성할 수 있는지를 검증해 보상 신호를 줌. 이 과정에서 직접 정답 누수(leakage)를 피하도록 설계. 2) Inspire & Strengthen 단계(RISE-R1): RISE-CoT의 보상으로 필터링된 고품질 CoT 서브셋으로 먼저 감독학습(SFT)한 뒤, 추가로 강화학습(RFT)으로 정교화하여 해석 가능한 추론과 정확한 주석을 달성.

Result: Qwen2-VL-2B에 적용한 결과, RISE는 복잡하고 단순한 이미지 주석 작업 모두에서 SFT와 Visual-RFT를 능가했다. 성능 향상뿐 아니라 향상된 설명 가능성(해석 가능한 CoT)을 보였다.

Conclusion: RISE는 수동으로 라벨링된 CoT가 없어도 자기지도적 방식으로 VLM의 추론 능력을 향상시키는 실용적 방법을 제시한다. 강화학습을 이용한 폐쇄 루프 검증과 단계적 SFT→RFT 파이프라인으로 일관된 고품질 CoT와 우수한 주석 성능을 달성한다.

Abstract: Vision-Language Models (VLMs) struggle with complex image annotation tasks,
such as emotion classification and context-driven object detection, which
demand sophisticated reasoning. Standard Supervised Fine-Tuning (SFT) focuses
solely on annotation outcomes, ignoring underlying rationales, while Visual
Reinforcement Fine-Tuning (Visual-RFT) produces inconsistent Chains of Thought
(CoTs) due to the absence of high-quality, verified CoTs during pre-training.
We introduce RISE (Reason-Inspire-Strengthen-Expertise), a two-stage framework
to overcome these limitations. In the Reason stage (RISE-CoT), a reinforcement
learning-driven "annotation-reasoning-annotation" closed-loop generates
visually grounded, logically consistent CoTs by verifying their ability to
reconstruct original annotations without direct leakage. The Inspire and
Strengthen stage (RISE-R1) leverages a high-quality CoT subset, filtered by
RISE-CoT rewards, for supervised fine-tuning, followed by reinforcement
fine-tuning to produce interpretable reasoning and accurate annotations,
achieving Expertise in complex visual tasks. Evaluated on complex and simple
image annotation tasks, RISE-trained Qwen2-VL-2B outperforms SFT and
Visual-RFT, achieving robust performance and enhanced explainability. RISE
offers a self-supervised solution for advancing VLM reasoning without requiring
manually annotated CoTs.

</details>


### [172] [MACTAS: Self-Attention-Based Module for Inter-Agent Communication in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2508.13661)
*Maciej Wojtala,Bogusz Stefańczyk,Dominik Bogucki,Łukasz Lepak,Jakub Strykowski,Paweł Wawrzyński*

Main category: cs.LG

TL;DR: 본 논문은 MARL 환경에서 에이전트 간의 통신을 위해 자기-어텐션 기반의 완전 미분 가능한 통신 모듈을 제안한다. 이 모듈은 행동-가치 함수 분해(action-value decomposition)와 자연스럽게 결합되며, 에이전트 수에 독립적인 고정된 수의 학습 가능한 파라미터를 가진다. SMAC 벤치마크에서 여러 맵에 대해 최첨단 성능을 보였다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 집단 과제를 인간 에이전트들이 수행할 때 통신이 필수적이다. 기존 MARL 통신 프로토콜은 종종 복잡하거나 미분 불가능하여 보상 기반 학습에 제약이 있다. 이를 해결하기 위해 단순하고 완전 미분 가능한 통신 메커니즘이 필요하다.

Method: 자기-어텐션(self-attention) 기반의 통신 모듈을 설계하여 에이전트 간 정보를 교환하도록 함. 이 모듈은 완전 미분 가능하며, 에이전트들이 보상에 따라 메시지를 생성하도록 학습된다. 또한, 어떤 행동-가치 분해 방법과도 통합 가능하고, 에이전트 수와 무관하게 고정된 수의 학습 가능한 파라미터를 갖는다.

Result: SMAC(StarCraft Multi-Agent Challenge) 벤치마크 실험에서 제안한 방법은 여러 맵에서 최첨단 성능을 달성함을 보여주었다.

Conclusion: 제안된 자기-어텐션 기반 통신 모듈은 학습 가능하고 효율적이며 확장성이 좋은 MARL 통신 메커니즘으로, 기존 행동-가치 분해 방법의 확장으로 활용될 수 있다.

Abstract: Communication is essential for the collective execution of complex tasks by
human agents, motivating interest in communication mechanisms for multi-agent
reinforcement learning (MARL). However, existing communication protocols in
MARL are often complex and non-differentiable. In this work, we introduce a
self-attention-based communication module that exchanges information between
the agents in MARL. Our proposed approach is fully differentiable, allowing
agents to learn to generate messages in a reward-driven manner. The module can
be seamlessly integrated with any action-value function decomposition method
and can be viewed as an extension of such decompositions. Notably, it includes
a fixed number of trainable parameters, independent of the number of agents.
Experimental results on the SMAC benchmark demonstrate the effectiveness of our
approach, which achieves state-of-the-art performance on several maps.

</details>


### [173] [Data driven feedback linearization of nonlinear control systems via Lie derivatives and stacked regression approach](https://arxiv.org/abs/2508.13241)
*Lakshmi Priya P. K.,Andreas Schwung*

Main category: cs.LG

TL;DR: Sparse regression과 Lie 도함수를 결합해 알려진 동적 거동으로부터 피드백 선형화 가능한 물리 시스템을 식별하고 제어기를 설계하는 새로운 방법론을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 물리 시스템의 지배 방정식을 발견하고 효과적인 피드백 제어기를 설계하는 일은 비선형성 등 복잡한 동역학을 이해해야 하며 여전히 어려운 연구 분야다. 기존 방법의 한계(내부 동역학 관찰, 잘못된 모델 추정 등)를 극복하려는 동기가 있다.

Method: 우선 희소 회귀(sparse regression)로 시스템을 식별한다. 그 다음 출력함수 사전(dictionary)에 대해 Lie 도함수를 적용해 상대 차수(relative degree) 조건을 유도하고, 이를 통해 내부 동역학이 관찰되지 않도록 하는 증강 제약을 만들고 이를 이용해 피드백 제어기를 설계한다. 또한 stacked(계층화된) 회귀 알고리즘과 상대 차수 조건을 결합한 점이 새롭다.

Result: 제시된 방법론은 알려진 동작(사전 지식)으로부터 실제 지배 방정식을 더 정확히 발견하고, 발견된 모델에 대해 피드백 선형화를 성공적으로 수행할 수 있도록 한다는 주장(실험/수치 예제 기반의 검증 가능성)이 암시된다.

Conclusion: 희소 회귀와 Lie 도함수 기반의 상대 차수 조건을 결합한 접근은 물리 모델의 진짜 지배방정식 발견과 피드백 선형화를 동시에 달성하는 데 유리하다. 기존 연구와 달리 stacked regression과 상대 차수 조건의 결합이 핵심 기여이다.

Abstract: Discovering the governing equations of a physical system and designing an
effective feedback controller remains one of the most challenging and intensive
areas of ongoing research. This task demands a deep understanding of the system
behavior, including the nonlinear factors that influence its dynamics. In this
article, we propose a novel methodology for identifying a feedback linearized
physical system based on known prior dynamic behavior. Initially, the system is
identified using a sparse regression algorithm, subsequently a feedback
controller is designed for the discovered system by applying Lie derivatives to
the dictionary of output functions to derive an augmented constraint which
guarantees that no internal dynamics are observed. Unlike the prior related
works, the novel aspect of this article combines the approach of stacked
regression algorithm and relative degree conditions to discover and feedback
linearize the true governing equations of a physical model.

</details>


### [174] [Physically Plausible Data Augmentations for Wearable IMU-based Human Activity Recognition Using Physics Simulation](https://arxiv.org/abs/2508.13284)
*Nobuyuki Oishi,Philip Birch,Daniel Roggen,Paula Lago*

Main category: cs.LG

TL;DR: Introduce Physically Plausible Data Augmentation (PPDA) using physics simulation to generate realistic IMU data for HAR, outperforming common signal-transformation augmentations and reducing needed labeled subjects.


<details>
  <summary>Details</summary>
Motivation: Labeled sensor data for HAR is scarce; common signal-transformation augmentations often produce physically implausible samples that can change activity semantics, limiting model performance and generalization.

Method: Use motion-capture or video-based pose data and physics simulation to create physically plausible augmentations: vary body movements, sensor placement, and hardware effects to synthesize inertial signals. Systematically compare PPDA variants against traditional Signal Transformation-based Data Augmentation (STDA) on three public HAR datasets, both individually and in combinations, and evaluate effects of training with fewer subjects.

Result: PPDA consistently improves macro F1 by an average of 3.7 percentage points (up to 13 pp) over STDAs and achieves competitive performance with up to 60% fewer training subjects. Combining multiple PPDAs further reduces required data.

Conclusion: Physics-based, physically plausible augmentation provides a cost-effective, scalable way to generate realistic synthetic IMU data, improving HAR model performance and addressing annotation scarcity; PPDA is a promising direction for future HAR augmentation work.

Abstract: The scarcity of high-quality labeled data in sensor-based Human Activity
Recognition (HAR) hinders model performance and limits generalization across
real-world scenarios. Data augmentation is a key strategy to mitigate this
issue by enhancing the diversity of training datasets. Signal
Transformation-based Data Augmentation (STDA) techniques have been widely used
in HAR. However, these methods are often physically implausible, potentially
resulting in augmented data that fails to preserve the original meaning of the
activity labels. In this study, we introduce and systematically characterize
Physically Plausible Data Augmentation (PPDA) enabled by physics simulation.
PPDA leverages human body movement data from motion capture or video-based pose
estimation and incorporates various realistic variabilities through physics
simulation, including modifying body movements, sensor placements, and
hardware-related effects. We compare the performance of PPDAs with traditional
STDAs on three public datasets of daily activities and fitness workouts. First,
we evaluate each augmentation method individually, directly comparing PPDAs to
their STDA counterparts. Next, we assess how combining multiple PPDAs can
reduce the need for initial data collection by varying the number of subjects
used for training. Experiments show consistent benefits of PPDAs, improving
macro F1 scores by an average of 3.7 pp (up to 13 pp) and achieving competitive
performance with up to 60% fewer training subjects than STDAs. As the first
systematic study of PPDA in sensor-based HAR, these results highlight the
advantages of pursuing physical plausibility in data augmentation and the
potential of physics simulation for generating synthetic Inertial Measurement
Unit data for training deep learning HAR models. This cost-effective and
scalable approach therefore helps address the annotation scarcity challenge in
HAR.

</details>


### [175] [Towards Human-AI Complementarity in Matching Tasks](https://arxiv.org/abs/2508.13285)
*Adrian Arnaiz-Rodriguez,Nina Corvelo Benz,Suhas Thejaswi,Nuria Oliver,Manuel Gomez-Rodriguez*

Main category: cs.LG

TL;DR: 제안된 comatch는 알고리즘-사람 보완성을 목표로 하는 협업형 매칭 시스템으로, 자신이 확신하는 일부 매칭만 자동으로 수행하고 나머지는 인간에게 위임하여 전체 성능을 최대화한다. 800명 참가자의 대규모 실험에서 comatch가 인간 또는 알고리즘 단독보다 우수한 결과를 보였다.


<details>
  <summary>Details</summary>
Motivation: 기존 데이터 기반 매칭 시스템은 인간-알고리즘 보완성을 고려하지 않아, 인간이 알고리즘을 사용했을 때 결과가 인간이나 알고리즘 단독보다 항상 더 나아지지 않는다. 따라서 의사결정자가 더 나은 매칭 결정을 내릴 수 있도록 알고리즘이 어떤 결정을 수행하고 어떤 결정을 인간에게 맡길지 최적화하는 시스템이 필요하다.

Method: comatch는 자신이 가장 확신하는 매칭 결정만 자동으로 수행하고, 확신이 낮은 결정은 인간에게 위임하는 협업적 접근을 사용한다. 또한 알고리즘이 자동으로 처리할 결정 수와 인간에게 위임할 결정 수를 최적화하여 이론적으로 성능을 극대화한다. 시스템 구현과 사람실험(800명)을 통해 검증하였다.

Result: 800명 참가자의 대규모 인간 실험 결과, comatch의 매칭 성과는 인간 단독 또는 알고리즘 단독보다 우수했다. 또한 관련 데이터와 구현체는 공개되었다.

Conclusion: 협업적 위임 전략을 사용한 comatch는 인간-알고리즘 보완성을 달성하여 매칭 성과를 향상시킬 수 있음을 실증했다. 공개된 데이터와 코드로 후속 연구를 지원한다.

Abstract: Data-driven algorithmic matching systems promise to help human decision
makers make better matching decisions in a wide variety of high-stakes
application domains, such as healthcare and social service provision. However,
existing systems are not designed to achieve human-AI complementarity:
decisions made by a human using an algorithmic matching system are not
necessarily better than those made by the human or by the algorithm alone. Our
work aims to address this gap. To this end, we propose collaborative matching
(comatch), a data-driven algorithmic matching system that takes a collaborative
approach: rather than making all the matching decisions for a matching task
like existing systems, it selects only the decisions that it is the most
confident in, deferring the rest to the human decision maker. In the process,
comatch optimizes how many decisions it makes and how many it defers to the
human decision maker to provably maximize performance. We conduct a large-scale
human subject study with $800$ participants to validate the proposed approach.
The results demonstrate that the matching outcomes produced by comatch
outperform those generated by either human participants or by algorithmic
matching on their own. The data gathered in our human subject study and an
implementation of our system are available as open source at
https://github.com/Networks-Learning/human-AI-complementarity-matching.

</details>


### [176] [Hierarchical Conformal Classification](https://arxiv.org/abs/2508.13288)
*Floris den Hengst,Inès Blin,Majid Mohammadi,Syed Ihtesham Hussain Shah,Taraneh Younesian*

Main category: cs.LG

TL;DR: 계층 구조를 반영한 컨포멀 예측(HCC)을 도입해 클래스 계층을 포함한 예측 집합을 생성하고, 보장된 커버리지를 유지하면서 조합폭발 문제를 후보 집합 축소로 실용적으로 해결한다.


<details>
  <summary>Details</summary>
Motivation: 표준 컨포멀 예측은 클래스들을 평탄하게 다루어 라벨 간 의미적·계층적 관계를 무시한다. 실제 응용에서는 계층 정보가 예측의 해석성·실용성을 크게 높일 수 있으나 기존 CP는 이를 반영하지 못한다.

Method: 클래스 계층을 예측 집합의 구조와 의미에 포함시키는 ‘계층적 컨포멀 분류(HCC)’를 제안하고, 이를 제약 최적화 문제로 정식화함. 해 공간이 조합적으로 커지는 문제를 해결하기 위해 보장성과 최적성을 유지하는 소수의 잘 구조화된 후보 해 집합으로 충분함을 이론적으로 보임.

Result: 오디오·이미지·텍스트의 세 가지 벤치마크에서 HCC가 이점(해석성·유용성 등)을 보였고, 사용자 연구에서 주석자들이 평탄한 예측 집합보다 계층적 예측 집합을 유의미하게 선호함.

Conclusion: HCC는 유한표본 커버리지 보장을 유지하면서 클래스 계층을 활용해 더 풍부하고 실용적인 예측 집합을 제공하며, 계산 문제는 후보군 축소로 실용적으로 해결할 수 있다.

Abstract: Conformal prediction (CP) is a powerful framework for quantifying uncertainty
in machine learning models, offering reliable predictions with finite-sample
coverage guarantees. When applied to classification, CP produces a prediction
set of possible labels that is guaranteed to contain the true label with high
probability, regardless of the underlying classifier. However, standard CP
treats classes as flat and unstructured, ignoring domain knowledge such as
semantic relationships or hierarchical structure among class labels. This paper
presents hierarchical conformal classification (HCC), an extension of CP that
incorporates class hierarchies into both the structure and semantics of
prediction sets. We formulate HCC as a constrained optimization problem whose
solutions yield prediction sets composed of nodes at different levels of the
hierarchy, while maintaining coverage guarantees. To address the combinatorial
nature of the problem, we formally show that a much smaller, well-structured
subset of candidate solutions suffices to ensure coverage while upholding
optimality. An empirical evaluation on three new benchmarks consisting of
audio, image, and text data highlights the advantages of our approach, and a
user study shows that annotators significantly prefer hierarchical over flat
prediction sets.

</details>


### [177] [X-MoE: Enabling Scalable Training for Emerging Mixture-of-Experts Architectures on HPC Platforms](https://arxiv.org/abs/2508.13337)
*Yueming Yuan,Ahan Gupta,Jianping Li,Sajal Dash,Feiyi Wang,Minjia Zhang*

Main category: cs.LG

TL;DR: X-MoE는 패딩-프리 크로스-플랫폼 커널, 중복 우회 디스패치, 시퀀스-셰어드 MoE 블록을 결합한 새로운 MoE 훈련 시스템으로, AMD MI250X 기반 Frontier에서 DeepSeek 스타일 MoE를 1024 GPU에 걸쳐 545억(545B) 파라미터까지 10배 확장하며 높은 처리량을 유지한다.


<details>
  <summary>Details</summary>
Motivation: 최근 발전한 전문가 특화 Mixture-of-Experts(MoE) 아키텍처(예: DeepSeek-MoE)는 세밀한 전문가 분할과 큰 top-k 라우팅으로 모델 품질을 향상시키지만, 활성화 메모리 오버헤드와 비용이 큰 all-to-all 통신 때문에 확장성이 제한된다. 또한 기존 MoE 훈련 시스템은 주로 NVIDIA GPU에 최적화되어 비-NVIDIA 플랫폼에서 성능이 저하되어 잠재 역량을 활용하지 못한다.

Method: X-MoE는 (1) 패딩이 없는 효율적인 MoE 학습을 위한 크로스-플랫폼 커널, (2) 중복을 우회하는(dispatch redundancy-bypassing) 디스패치 메커니즘, (3) 시퀀스 셰어드 MoE 블록을 포함한 하이브리드 병렬성 설계를 도입한다. 이들 기법으로 활성화 메모리와 통신 비용을 줄이고 비-NVIDIA 하드웨어에서 높은 확장성을 달성한다.

Result: Frontier(AMD MI250X)에서 X-MoE는 DeepSeek 스타일 MoE를 최대 545B 파라미터로 1024 GPU에 걸쳐 학습 가능하게 했으며, 동일 하드웨어 예산에서 기존 방법보다 10배 큰 모델을 훈련할 수 있었다. 높은 학습 처리량을 유지하며 소스코드는 공개되어 있다.

Conclusion: X-MoE는 비-NVIDIA 플랫폼에서도 대규모 MoE 아키텍처의 확장성을 크게 개선하여, 하드웨어 다양성에서의 성능 저하 문제를 완화하고 더 큰 모델 훈련을 가능하게 한다.

Abstract: Emerging expert-specialized Mixture-of-Experts (MoE) architectures, such as
DeepSeek-MoE, deliver strong model quality through fine-grained expert
segmentation and large top-k routing. However, their scalability is limited by
substantial activation memory overhead and costly all-to-all communication.
Furthermore, current MoE training systems - primarily optimized for NVIDIA GPUs
- perform suboptimally on non-NVIDIA platforms, leaving significant
computational potential untapped. In this work, we present X-MoE, a novel MoE
training system designed to deliver scalable training performance for
next-generation MoE architectures. X-MoE achieves this via several novel
techniques, including efficient padding-free MoE training with cross-platform
kernels, redundancy-bypassing dispatch, and hybrid parallelism with
sequence-sharded MoE blocks. Our evaluation on the Frontier supercomputer,
powered by AMD MI250X GPUs, shows that X-MoE scales DeepSeek-style MoEs up to
545 billion parameters across 1024 GPUs - 10x larger than the largest trainable
model with existing methods under the same hardware budget, while maintaining
high training throughput. The source code of X-MoE is available at
https://github.com/Supercomputing-System-AI-Lab/X-MoE.

</details>


### [178] [Efficient Constraint-Aware Flow Matching via Randomized Exploration](https://arxiv.org/abs/2508.13316)
*Zhengyan Huan,Jacob Boerma,Li-Ping Liu,Shuchin Aeron*

Main category: cs.LG

TL;DR: Flow Matching(FM)에 제약을 추가한 샘플 생성법을 제안한다. (a) 제약까지의 미분 가능한 거리함수를 알면 FM 목적함수에 거리 페널티를 더하고, (b) 제약집합을 멤버십 오라클로만 접근할 수 있으면 랜덤화된 평균 흐름(mean flow)을 학습해 제약을 만족할 가능성이 높은 샘플을 생성한다. 또한 두 단계(two-stage) 학습이 계산적으로 효율적임을 보이며, 합성 실험과 하드-라벨 블랙박스 분류기 기반의 적대적 예제 생성에서 제약 만족도와 분포 정합성 모두 향상됨을 보인다.


<details>
  <summary>Details</summary>
Motivation: 제약을 만족하는 샘플을 생성해야 하는 문제에서 기존 방법들은 단순한 볼록 제약, 배리어 함수 지식, 또는 반사(reflection) 메커니즘 등을 필요로 하는 제한이 있다. 실제로는 미분가능한 거리함수만 주어지거나 오직 멤버십 쿼리만 가능한 경우가 있어 더 일반적인 접근이 필요하다.

Method: (a) 미분가능한 거리함수가 주어지는 경우: FM 목적함수에 제약집합과 생성 샘플 간의 거리를 벌점으로 추가하는 간단한 수정.
(b) 멤버십 오라클만 주어지는 경우: 랜덤화를 도입하여 제약을 만족할 확률이 높은 평균 흐름(mean flow)을 학습. 또한 두 단계 접근법을 제안하여 두 단계 모두 원래 흐름을 근사하되 두 번째 단계에서만 랜덤화로 제약을 탐색하게 하여 계산 효율을 개선.

Result: 여러 합성(constrained generation) 사례에서 제안 기법들이 제약 만족도를 크게 향상시키면서 목표 분포에도 잘 부합함을 수치적으로 보임. 실용적 오라클 기반 제약의 사례로 하드-라벨 블랙박스 분류기에 대한 쿼리를 이용한 적대적 예제 생성 실험을 수행하여 성공적으로 적용됨.

Conclusion: 제안된 방법들은 볼록성·배리어·반사 등 기존 제약을 요구하지 않고 FM 기반 생성모델을 제약 조건 하에서 확장할 수 있음을 보인다. 또한 두 단계 학습이 효율적이며 실제 응용(예: 블랙박스 공격)에 유용하다. 코드 공개 및 향후 연구 방향 제시.

Abstract: We consider the problem of generating samples via Flow Matching (FM) with an
additional requirement that the generated samples must satisfy given
constraints. We consider two scenarios, viz.: (a) when a differentiable
distance function to the constraint set is given, and (b) when the constraint
set is only available via queries to a membership oracle. For case (a), we
propose a simple adaptation of the FM objective with an additional term that
penalizes the distance between the constraint set and the generated samples.
For case (b), we propose to employ randomization and learn a mean flow that is
numerically shown to have a high likelihood of satisfying the constraints. This
approach deviates significantly from existing works that require simple convex
constraints, knowledge of a barrier function, or a reflection mechanism to
constrain the probability flow. Furthermore, in the proposed setting we show
that a two-stage approach, where both stages approximate the same original flow
but with only the second stage probing the constraints via randomization, is
more computationally efficient. Through several synthetic cases of constrained
generation, we numerically show that the proposed approaches achieve
significant gains in terms of constraint satisfaction while matching the target
distributions. As a showcase for a practical oracle-based constraint, we show
how our approach can be used for training an adversarial example generator,
using queries to a hard-label black-box classifier. We conclude with several
future research directions. Our code is available at
https://github.com/ZhengyanHuan/FM-RE.

</details>


### [179] [Trans-XFed: An Explainable Federated Learning for Supply Chain Credit Assessment](https://arxiv.org/abs/2508.13715)
*Jie Shi,Arno P. J. M. Siebes,Siamak Mehrkanoon*

Main category: cs.LG

TL;DR: 연합학습(Federated Learning)과 설명가능한 AI 기법을 결합한 Trans-XFed를 제안하여 프라이버시 유지 하에 공급망 신용평가를 수행한다. 성능 기반 클라이언트 선택(PBCS), FedProx+동형암호, 트랜스포머 인코더, 통합 그래디언트 설명기법을 결합해 정확도, 투명성, 프라이버시를 개선했다고 보고한다.


<details>
  <summary>Details</summary>
Motivation: 공급망 신용평가는 개인정보·기업 간 정보 사일로, 클래스 불균형, Non-IID 데이터, 모델 해석 가능성 등의 문제를 가지며, 중앙집중식 학습은 프라이버시 이슈와 데이터 이동의 제약을 초래한다. 이를 해결할 수 있는 분산·해석 가능한 프레임워크가 필요하다.

Method: FedProx를 기반으로 동형암호를 적용해 서버-클라이언트 통신의 프라이버시를 보호하고, 트랜스포머 인코더 블록을 통합해 학습된 특징에 대한 인사이트를 제공한다. 성능 기반 클라이언트 선택(PBCS)은 로컬 F1 점수가 높은 클라이언트를 우선 선택해 클래스 불균형과 Non-IID 문제에 대한 수렴 속도를 개선한다. 최종적으로 통합 그래디언트(Integrated Gradients)를 사용해 모델 의사결정의 설명을 제공한다.

Result: 실제 공급망 데이터셋에서 여러 베이스라인 대비 더 우수한 신용평가 정확도를 달성했다고 보고한다. PBCS로 수렴이 빨라지고, 트랜스포머+통합 그래디언트로 해석 가능성을 확보했으며, 동형암호로 프라이버시를 어느 정도 보장했다고 주장한다.

Conclusion: Trans-XFed는 프라이버시 보호, 비동질·불균형 데이터 환경에서의 학습 효율성, 및 모델 설명성을 동시에 개선하는 통합 프레임워크로 제안되며, 실험에서 유의미한 성능 향상을 보였다.

Abstract: This paper proposes a Trans-XFed architecture that combines federated
learning with explainable AI techniques for supply chain credit assessment. The
proposed model aims to address several key challenges, including privacy,
information silos, class imbalance, non-identically and independently
distributed (Non-IID) data, and model interpretability in supply chain credit
assessment. We introduce a performance-based client selection strategy (PBCS)
to tackle class imbalance and Non-IID problems. This strategy achieves faster
convergence by selecting clients with higher local F1 scores. The FedProx
architecture, enhanced with homomorphic encryption, is used as the core model,
and further incorporates a transformer encoder. The transformer encoder block
provides insights into the learned features. Additionally, we employ the
integrated gradient explainable AI technique to offer insights into
decision-making. We demonstrate the effectiveness of Trans-XFed through
experimental evaluations on real-world supply chain datasets. The obtained
results show its ability to deliver accurate credit assessments compared to
several baselines, while maintaining transparency and privacy.

</details>


### [180] [Decoding Communications with Partial Information](https://arxiv.org/abs/2508.13326)
*Dylan Cope,Peter McBurney*

Main category: cs.LG

TL;DR: 


<details>
  <summary>Details</summary>
Motivation: 

Method: 

Result: 

Conclusion: 

Abstract: Machine language acquisition is often presented as a problem of imitation
learning: there exists a community of language users from which a learner
observes speech acts and attempts to decode the mappings between utterances and
situations. However, an interesting consideration that is typically unaddressed
is partial observability, i.e. the learner is assumed to see all relevant
information. This paper explores relaxing this assumption, thereby posing a
more challenging setting where such information needs to be inferred from
knowledge of the environment, the actions taken, and messages sent. We see
several motivating examples of this problem, demonstrate how they can be solved
in a toy setting, and formally explore challenges that arise in more general
settings. A learning-based algorithm is then presented to perform the decoding
of private information to facilitate language acquisition.

</details>


### [181] [Contextual Attention-Based Multimodal Fusion of LLM and CNN for Sentiment Analysis](https://arxiv.org/abs/2508.13196)
*Meriem Zerkouk,Miloud Mihoubi,Belkacem Chikhaoui*

Main category: cs.LG

TL;DR: 자연재해 상황의 소셜미디어 다중모달 감정분석을 위해 이미지(CNN)와 텍스트(LLM/GPT)를 통합하고, 문맥적 어텐션 기반 융합을 도입하여 CrisisMMD 데이터셋에서 유의미한 성능 향상을 보인 모델을 제안한다. Accuracy +2.43%, F1 +5.18%.


<details>
  <summary>Details</summary>
Motivation: 재난 상황에서 대중의 감정(정보성 여부)을 신속·정확하게 파악하는 것은 위기 관리에 중요하다. 기존 방법은 텍스트와 이미지를 개별 처리해 모달 간 상호작용을 충분히 반영하지 못한다.

Method: 이미지 특징은 CNN으로 추출하고 텍스트는 GPT 기반 LLM과 프롬프트 엔지니어링으로 감정 관련 특징을 추출한다. 추출된 특징들은 문맥적 어텐션층을 통해 교차-모달 상호작용을 학습하며, 융합된 특징을 심층 신경망으로 분류에 이용한다.

Result: CrisisMMD 데이터셋에서 기존 베이스라인 대비 정확도 2.43%p, F1-score 5.18%p 향상. 다양한 재난 유형에서 유의미/비유의미 분류 성능 개선을 확인.

Conclusion: LLM 기반 텍스트 처리와 CNN 이미지 처리의 융합, 특히 문맥적 어텐션을 통한 상호작용 모델링이 멀티모달 재난 감정분석 성능을 개선하며, 실시간 재난 대응에 활용 가능한 잠재력을 보인다.

Abstract: This paper introduces a novel approach for multimodal sentiment analysis on
social media, particularly in the context of natural disasters, where
understanding public sentiment is crucial for effective crisis management.
Unlike conventional methods that process text and image modalities separately,
our approach seamlessly integrates Convolutional Neural Network (CNN) based
image analysis with Large Language Model (LLM) based text processing,
leveraging Generative Pre-trained Transformer (GPT) and prompt engineering to
extract sentiment relevant features from the CrisisMMD dataset. To effectively
model intermodal relationships, we introduce a contextual attention mechanism
within the fusion process. Leveraging contextual-attention layers, this
mechanism effectively captures intermodality interactions, enhancing the
model's comprehension of complex relationships between textual and visual data.
The deep neural network architecture of our model learns from these fused
features, leading to improved accuracy compared to existing baselines.
Experimental results demonstrate significant advancements in classifying social
media data into informative and noninformative categories across various
natural disasters. Our model achieves a notable 2.43% increase in accuracy and
5.18% in F1-score, highlighting its efficacy in processing complex multimodal
data. Beyond quantitative metrics, our approach provides deeper insight into
the sentiments expressed during crises. The practical implications extend to
real time disaster management, where enhanced sentiment analysis can optimize
the accuracy of emergency interventions. By bridging the gap between multimodal
analysis, LLM powered text understanding, and disaster response, our work
presents a promising direction for Artificial Intelligence (AI) driven crisis
management solutions. Keywords:

</details>


### [182] [A Dual-Attention Graph Network for fMRI Data Classification](https://arxiv.org/abs/2508.13328)
*Amirali Arbab,Zeinab Davarani,Mehran Safayani*

Main category: cs.LG

TL;DR: 주어진 논문은 transformer 기반의 attention으로 시계열 구간마다 동적으로 뇌의 기능적 연결망을 생성하고, 이를 GCN과 transformer로 처리하여 ASD 진단 성능을 개선한다는 내용이다.


<details>
  <summary>Details</summary>
Motivation: 기존 fMRI 분류는 정적 연결성 기반이거나 시공간적 관계를 포괄적으로 캡처하지 못하기 때문에, 시간에 따라 변하는 뇌 영역 간 상호작용을 모델링하고 중요한 시점과 영역에 주목하는 방법이 필요하다.

Method: transformer 기반 attention으로 각 시간 간격에서 동적 그래프를 추론하고, 시간가변 그래프를 GCN과 transformer로 처리하여 국소적 상호작용과 전역 시간의존성을 함께 캡처한다. 또한 GCN-transformer의 계층적 융합으로 시공간 특징을 통합한다.

Result: ABIDE 데이터셋 부분집합에서 모델은 정확도 63.2%, AUC 60.0을 달성하여 정적 그래프 기반 방법(GCN 51.8%)을 능가했다.

Conclusion: attention 기반 동적 그래프 생성과 GCN-transformer 계층적 시공간 융합을 통해 fMRI 분류에서 동적 연결성 및 시공간 맥락의 공동 모델링이 효과적임을 검증한다.

Abstract: Understanding the complex neural activity dynamics is crucial for the
development of the field of neuroscience. Although current functional MRI
classification approaches tend to be based on static functional connectivity or
cannot capture spatio-temporal relationships comprehensively, we present a new
framework that leverages dynamic graph creation and spatiotemporal attention
mechanisms for Autism Spectrum Disorder(ASD) diagnosis. The approach used in
this research dynamically infers functional brain connectivity in each time
interval using transformer-based attention mechanisms, enabling the model to
selectively focus on crucial brain regions and time segments. By constructing
time-varying graphs that are then processed with Graph Convolutional Networks
(GCNs) and transformers, our method successfully captures both localized
interactions and global temporal dependencies. Evaluated on the subset of ABIDE
dataset, our model achieves 63.2 accuracy and 60.0 AUC, outperforming static
graph-based approaches (e.g., GCN:51.8). This validates the efficacy of joint
modeling of dynamic connectivity and spatio-temporal context for fMRI
classification. The core novelty arises from (1) attention-driven dynamic graph
creation that learns temporal brain region interactions and (2) hierarchical
spatio-temporal feature fusion through GCNtransformer fusion.

</details>


### [183] [X-MoE: Enabling Scalable Training for Emerging Mixture-of-Experts Architectures on HPC Platforms](https://arxiv.org/abs/2508.13337)
*Yueming Yuan,Ahan Gupta,Jianping Li,Sajal Dash,Feiyi Wang,Minjia Zhang*

Main category: cs.LG

TL;DR: X-MoE는 패딩-프리 크로스-플랫폼 커널, 중복 우회 디스패치, 시퀀스-셰어드 MoE 블록을 결합한 새로운 MoE 훈련 시스템으로, AMD MI250X 기반 Frontier에서 DeepSeek 스타일 MoE를 1024 GPU에 걸쳐 545억(545B) 파라미터까지 10배 확장하며 높은 처리량을 유지한다.


<details>
  <summary>Details</summary>
Motivation: 최근 발전한 전문가 특화 Mixture-of-Experts(MoE) 아키텍처(예: DeepSeek-MoE)는 세밀한 전문가 분할과 큰 top-k 라우팅으로 모델 품질을 향상시키지만, 활성화 메모리 오버헤드와 비용이 큰 all-to-all 통신 때문에 확장성이 제한된다. 또한 기존 MoE 훈련 시스템은 주로 NVIDIA GPU에 최적화되어 비-NVIDIA 플랫폼에서 성능이 저하되어 잠재 역량을 활용하지 못한다.

Method: X-MoE는 (1) 패딩이 없는 효율적인 MoE 학습을 위한 크로스-플랫폼 커널, (2) 중복을 우회하는(dispatch redundancy-bypassing) 디스패치 메커니즘, (3) 시퀀스 셰어드 MoE 블록을 포함한 하이브리드 병렬성 설계를 도입한다. 이들 기법으로 활성화 메모리와 통신 비용을 줄이고 비-NVIDIA 하드웨어에서 높은 확장성을 달성한다.

Result: Frontier(AMD MI250X)에서 X-MoE는 DeepSeek 스타일 MoE를 최대 545B 파라미터로 1024 GPU에 걸쳐 학습 가능하게 했으며, 동일 하드웨어 예산에서 기존 방법보다 10배 큰 모델을 훈련할 수 있었다. 높은 학습 처리량을 유지하며 소스코드는 공개되어 있다.

Conclusion: X-MoE는 비-NVIDIA 플랫폼에서도 대규모 MoE 아키텍처의 확장성을 크게 개선하여, 하드웨어 다양성에서의 성능 저하 문제를 완화하고 더 큰 모델 훈련을 가능하게 한다.

Abstract: Emerging expert-specialized Mixture-of-Experts (MoE) architectures, such as
DeepSeek-MoE, deliver strong model quality through fine-grained expert
segmentation and large top-k routing. However, their scalability is limited by
substantial activation memory overhead and costly all-to-all communication.
Furthermore, current MoE training systems - primarily optimized for NVIDIA GPUs
- perform suboptimally on non-NVIDIA platforms, leaving significant
computational potential untapped. In this work, we present X-MoE, a novel MoE
training system designed to deliver scalable training performance for
next-generation MoE architectures. X-MoE achieves this via several novel
techniques, including efficient padding-free MoE training with cross-platform
kernels, redundancy-bypassing dispatch, and hybrid parallelism with
sequence-sharded MoE blocks. Our evaluation on the Frontier supercomputer,
powered by AMD MI250X GPUs, shows that X-MoE scales DeepSeek-style MoEs up to
545 billion parameters across 1024 GPUs - 10x larger than the largest trainable
model with existing methods under the same hardware budget, while maintaining
high training throughput. The source code of X-MoE is available at
https://github.com/Supercomputing-System-AI-Lab/X-MoE.

</details>


### [184] [Dimension lower bounds for linear approaches to function approximation](https://arxiv.org/abs/2508.13346)
*Daniel Hsu*

Main category: cs.LG

TL;DR: 이 논문은 선형 대수 기법으로 L^2 함수 근사 문제를 해결하는 선형 방법들의 차원(또는 샘플 수)에 대한 하한을 증명한다. 기존 문헌의 기본 논거를 재활용해 커널 방법의 샘플 크기 하한을 도출한다.


<details>
  <summary>Details</summary>
Motivation: 선형 방법(예: 선형 조합, 커널 방법 등)이 L^2 함수 근사 문제에서 필요한 최소 차원 혹은 샘플 수를 이해해 계산 자원과 일반화 성능의 근본적 한계를 밝히려는 목적.

Method: Kolmogorov n-폭 관련 기존 선형 대수적 논증(예: Barron 1993)을 사용해 선형 근사 방법의 표현 능력에 대한 하한을 만든다. 이 접근을 kernel methods에 응용하여 샘플 수(또는 차원)에 대한 하한을 유도한다.

Result: 선형 방법으로 L^2 함수 근사를 할 때 필요한 차원/샘플 수에 대한 명시적 하한을 제시함. 커널 방법에 대해서도 유사한 샘플 크기 하한을 얻음.

Conclusion: 선형 대수적 접근은 L^2 근사에서 선형 방법들의 근본적 한계를 간결하게 증명하는 데 유용하며, 커널 방법의 샘플 수 설계 시 이러한 하한을 고려해야 한다.

Abstract: This short note presents a linear algebraic approach to proving dimension
lower bounds for linear methods that solve $L^2$ function approximation
problems. The basic argument has appeared in the literature before (e.g.,
Barron, 1993) for establishing lower bounds on Kolmogorov $n$-widths. The
argument is applied to give sample size lower bounds for kernel methods.

</details>


### [185] [Counterfactual Probabilistic Diffusion with Expert Models](https://arxiv.org/abs/2508.13355)
*Wenhao Mu,Zhi Cao,Mehmed Uludag,Alexander Rodríguez*

Main category: cs.LG

TL;DR: Introduce ODE-Diff: a time-series diffusion model that incorporates high-level signals from imperfect mechanistic (ODE) expert models as structured priors to improve counterfactual distribution prediction under data scarcity.


<details>
  <summary>Details</summary>
Motivation: Counterfactual distribution prediction in complex dynamical systems is crucial for domains like public health and medicine, but existing methods (point estimates or purely data-driven models) fail when data are scarce and cannot leverage imperfect but informative mechanistic knowledge.

Method: Propose ODE-Diff, a diffusion-based generative framework for time series that extracts high-level signals from expert ODE/mechanistic models and uses them as structured priors/guidance during diffusion-based generation, thus blending mechanistic and data-driven approaches for causal inference.

Result: Evaluated on semi-synthetic COVID-19 simulations, synthetic pharmacological dynamics, and real-world case studies; ODE-Diff consistently outperforms strong baselines in both point prediction and distributional accuracy.

Conclusion: Guiding diffusion-based time-series generative models with structured priors from imperfect mechanistic models yields more reliable, interpretable causal counterfactual predictions, particularly under limited-data settings.

Abstract: Predicting counterfactual distributions in complex dynamical systems is
essential for scientific modeling and decision-making in domains such as public
health and medicine. However, existing methods often rely on point estimates or
purely data-driven models, which tend to falter under data scarcity. We propose
a time series diffusion-based framework that incorporates guidance from
imperfect expert models by extracting high-level signals to serve as structured
priors for generative modeling. Our method, ODE-Diff, bridges mechanistic and
data-driven approaches, enabling more reliable and interpretable causal
inference. We evaluate ODE-Diff across semi-synthetic COVID-19 simulations,
synthetic pharmacological dynamics, and real-world case studies, demonstrating
that it consistently outperforms strong baselines in both point prediction and
distributional accuracy.

</details>


### [186] [Adaptive Conformal Prediction Intervals Over Trajectory Ensembles](https://arxiv.org/abs/2508.13362)
*Ruipu Li,Daniel Menacho,Alexander Rodríguez*

Main category: cs.LG

TL;DR: 논문은 확률적 샘플링 또는 여러 자기회귀 예측기를 통해 생성된 미래 궤적(trajectory)을 보정(calibrate)해 신뢰구간(prediction intervals)을 제공하는 통합적 방법을 제안한다. 제안 기법은 conformal prediction을 기반으로 온라인 업데이트와 시점 간 의존성을 반영하는 최적화 단계를 도입하여 불연속적인 구간을 허용하고 시간적 의존성을 자연스럽게 포착하며 더 날카롭고 적응적인 불확실성 추정을 제공한다.


<details>
  <summary>Details</summary>
Motivation: 미래 궤적 예측(예: 자율주행, 허리케인 경로, 역학 모델)에서 표본화된 궤적들은 불확실성을 반영하지만 보정되어 있지 않아 신뢰성 있는 예측구간을 제공하지 못한다. 따라서 이들을 이론적 보장(coverage)을 갖는 보정된 prediction intervals로 변환할 필요가 있다.

Method: conformal prediction 프레임워크를 기반으로, 샘플d trajectories를 보정하여 보장된 커버리지를 가진 prediction intervals를 생성한다. 핵심은 온라인 업데이트 단계와 시점 간 의존성을 포착하는 최적화 단계로, 각 샘플 궤적 주위에 불연속적인(prediction) 구간을 만들고 시간적 의존성 및 단계 간 상호작용을 반영하여 더 날카로운 불확실성 추정치를 얻는다.

Result: 제안 방법은 불연속 구간을 허용하고 시간적 의존성을 포착함으로써 기존 방식보다 더 날카롭고 적응적인 불확실성 추정을 제공하며, 이론적 커버리지 보장을 유지한다(실험적 성능 개선 암시).

Conclusion: 샘플된 궤적을 conformal prediction으로 보정하면 이론적 보장을 지키면서 실용적으로 더 정확하고 적응적인 예측구간을 얻을 수 있다. 온라인 업데이트와 최적화로 시간 의존성을 반영하고 불연속적 구간을 허용하는 것이 핵심 기여이다.

Abstract: Future trajectories play an important role across domains such as autonomous
driving, hurricane forecasting, and epidemic modeling, where practitioners
commonly generate ensemble paths by sampling probabilistic models or leveraging
multiple autoregressive predictors. While these trajectories reflect inherent
uncertainty, they are typically uncalibrated. We propose a unified framework
based on conformal prediction that transforms sampled trajectories into
calibrated prediction intervals with theoretical coverage guarantees. By
introducing a novel online update step and an optimization step that captures
inter-step dependencies, our method can produce discontinuous prediction
intervals around each trajectory, naturally capture temporal dependencies, and
yield sharper, more adaptive uncertainty estimates.

</details>


### [187] [Batching-Aware Joint Model Onloading and Offloading for Hierarchical Multi-Task Inference](https://arxiv.org/abs/2508.13380)
*Seohyeon Cha,Kevin Chan,Gustavo de Veciana,Haris Vikalo*

Main category: cs.LG

TL;DR: 엣지-클라우드 계층에서 다중 작업용 모델의 클라이언트 온로드(onload)와 쿼리 오프로딩(offload)을 공동 최적화해 전체 추론 정확도를 극대화하는 프레임워크(J3O)를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 실제 응용(자율주행, AR 등)은 탐지·분할·깊이추정 등 다양한 작업을 동시에 요구하며, 기존 프레임워크는 단일 작업·단일 모델 중심이라 자원 제약(메모리·연산·통신) 하에서 다중 작업을 효율적으로 배치·라우팅하는 방법이 필요하다.

Method: 온로드(어떤 다중작업 모델을 클라이언트/엣지에 배치할지)와 오프로딩(계층 간 쿼리 라우팅)을 결합한 혼합 정수 계획으로 문제를 모델링하고, J3O라는 교대 최적화 알고리즘을 제안한다. J3O는 (i) 라그랑주 완화된 서브모듈러 최적화로 모델 온로드를 탐욕적으로 선택하고, (ii) 제한된 선형계획으로 오프로딩 결정을 최적으로 도출하며, 엣지 배칭을 고려한 확장도 제시한다.

Result: J3O는 다중작업 벤치마크에서 최적 해의 97% 이상 정확도를 일관되게 달성하면서 최적 해 계산에 비해 런타임은 15% 미만으로 절감된다.

Conclusion: 온로드와 오프로딩을 공동 최적화하면 메모리·연산·통신 제약 하에서도 다중작업 추론 성능을 거의 최적 수준으로 유지하면서 실시간성·확장성을 확보할 수 있다.

Abstract: The growing demand for intelligent services on resource-constrained edge
devices has spurred the development of collaborative inference systems that
distribute workloads across end devices, edge servers, and the cloud. While
most existing frameworks focus on single-task, single-model scenarios, many
real-world applications (e.g., autonomous driving and augmented reality)
require concurrent execution of diverse tasks including detection,
segmentation, and depth estimation. In this work, we propose a unified
framework to jointly decide which multi-task models to deploy (onload) at
clients and edge servers, and how to route queries across the hierarchy
(offload) to maximize overall inference accuracy under memory, compute, and
communication constraints. We formulate this as a mixed-integer program and
introduce J3O (Joint Optimization of Onloading and Offloading), an alternating
algorithm that (i) greedily selects models to onload via Lagrangian-relaxed
submodular optimization and (ii) determines optimal offloading via constrained
linear programming. We further extend J3O to account for batching at the edge,
maintaining scalability under heterogeneous task loads. Experiments show J3O
consistently achieves over $97\%$ of the optimal accuracy while incurring less
than $15\%$ of the runtime required by the optimal solver across multi-task
benchmarks.

</details>


### [188] [Semi-Supervised Anomaly Detection Pipeline for SOZ Localization Using Ictal-Related Chirp](https://arxiv.org/abs/2508.13406)
*Nooshin Bahador,Milad Lankarany*

Main category: cs.LG

TL;DR: 시간-주파수 기반 chirp 이벤트의 스펙트로템포럴 특징으로 LOF 기반 이상치 탐지를 수행하고, 전극 근접성과 반구 일치를 가중치로 반영한 공간 상관 지표로 임상 정의된 SOZ와의 일치도를 정량화한 연구. 가중치 기반 색인 매칭이 정확한 동시발생 매칭보다 SOZ 지역화에 더 우수했고, 수술 성공군에서 특히 높은 일치도를 보였음.


<details>
  <summary>Details</summary>
Motivation: 임상적으로 정의된 발작 시작 영역(SOZ)과 시간-주파수 분석으로 식별된 통계적 이상 채널 간의 공간적 일치성을 정량적으로 평가해, 비침습적/보완적 SOZ 지역화 방법을 제시하려는 목적.

Method: (1) 비지도 이상치 탐지: chirp의 onset freq, offset freq, duration 같은 스펙트로-템포럴 피처로 Local Outlier Factor(LOF)를 사용해 적응적 이웃수 선택으로 이상 채널을 식별(파라미터: N_neighbors=20, contamination=0.2). (2) 공간 상관 분석: 정확 동시발생 매칭 및 전극 근접성과 반구 일치를 반영한 가중 색인 유사도를 계산해 SOZ와의 공간적 대응성을 평가.

Result: LOF 기반 방법이 이상치를 효과적으로 탐지했으며, 채널 근접성으로 가중한 색인 매칭이 정확 매칭보다 SOZ 지역화 성능(precision, recall, F1)이 우수. 발작 완전 소실(seizure-free) 환자에서 색인 정밀도(mean)=0.903, 성공적 수술 결과 환자에서 mean=0.865, 실패 사례에서는 mean=0.460으로 그룹별 편차가 뚜렷함.

Conclusion: chirp 기반 이상치 탐지와 가중된 공간 지표의 결합은 특히 수술 성공 환자에서 SOZ 지역화를 보완할 수 있는 유용한 방법으로 제시됨.

Abstract: This study presents a quantitative framework for evaluating the spatial
concordance between clinically defined seizure onset zones (SOZs) and
statistically anomalous channels identified through time-frequency analysis of
chirp events. The proposed pipeline employs a two-step methodology: (1)
Unsupervised Outlier Detection, where Local Outlier Factor (LOF) analysis with
adaptive neighborhood selection identifies anomalous channels based on
spectro-temporal features of chirp (Onset frequency, offset frequency, and
temporal duration); and (2) Spatial Correlation Analysis, which computes both
exact co-occurrence metrics and weighted index similarity, incorporating
hemispheric congruence and electrode proximity. Key findings demonstrate that
the LOF-based approach (N neighbors=20, contamination=0.2) effectively detects
outliers, with index matching (weighted by channel proximity) outperforming
exact matching in SOZ localization. Performance metrics (precision, recall, F1)
were highest for seizure-free patients (Index Precision mean: 0.903) and those
with successful surgical outcomes (Index Precision mean: 0.865), whereas
failure cases exhibited lower concordance (Index Precision mean: 0.460). The
key takeaway is that chirp-based outlier detection, combined with weighted
spatial metrics, provides a complementary method for SOZ localization,
particularly in patients with successful surgical outcomes.

</details>


### [189] [NovoMolGen: Rethinking Molecular Language Model Pretraining](https://arxiv.org/abs/2508.13408)
*Kamran Chitsaz,Roshan Balaji,Quentin Fournier,Nirav Pravinbhai Bhatt,Sarath Chandar*

Main category: cs.LG

TL;DR: NovoMolGen은 15억 분자 데이터로 사전학습된 Transformer 계열의 분자 LLM 계열로, 전형적인 언어모델링 실습(표현, 토크나이저, 모델 크기, 데이터 규모)이 분자 생성 성능에 미치는 영향을 체계적으로 연구하고, 사전학습 지표와 실제 다운스트림 성능 간 약한 상관관계를 발견하며 기존 모델들을 능가하는 SOTA 성능을 달성했다.


<details>
  <summary>Details</summary>
Motivation: 합성 가능한 후보가 10^23–10^60에 달하는 방대한 화학 공간에서 원하는 특성의 분자를 설계하려면 효율적인 탐색이 필요하다. 문자열 기반 Mol-LLM은 확장성이 좋아 수십억 분자 탐색이 가능하지만, 텍스트 표현 방식, 토크나이저, 모델 크기, 데이터 스케일 같은 표준 언어모델링 관행이 분자 생성 성능에 어떻게 영향을 주는지는 명확하지 않다.

Method: NovoMolGen이라는 Transformer 기반 파운데이션 모델 계열을 제안하고 15억 개 분자 데이터로 사전학습했다. 텍스트 표현, 토크나이저 전략, 모델 크기, 데이터 규모 등 주요 요소들을 체계적으로 변경·평가하는 광범위한 실험을 수행해 사전학습 지표와 다운스트림 생성 성능의 관계를 분석했다.

Result: 사전학습 중 측정되는 성능 지표(예: loss 등)와 실제 다운스트림 분자 생성 성능 간의 상관관계가 약함을 확인했다. 또한 NovoMolGen은 제약 없는(unconstrained) 및 목표 지향(goal-directed) 분자 생성 과제에서 기존 Mol-LLM 및 특화 생성 모델들을 크게 앞서며 새로운 SOTA를 수립했다.

Conclusion: 분자 설계용 LLM은 일반 NLP와 다른 학습 역학을 보이므로 단순한 사전학습 지표에 의존하면 안 된다. 다운스트림 과제 성능을 직접 평가하는 전략과 대규모 파운데이션 모델 전사가 분자 설계 성능 향상에 유용함을 제시한다.

Abstract: Designing de-novo molecules with desired property profiles requires efficient
exploration of the vast chemical space ranging from $10^{23}$ to $10^{60}$
possible synthesizable candidates. While various deep generative models have
been developed to design small molecules using diverse input representations,
Molecular Large Language Models (Mol-LLMs) based on string representations have
emerged as a scalable approach capable of exploring billions of molecules.
However, there remains limited understanding regarding how standard language
modeling practices such as textual representations, tokenization strategies,
model size, and dataset scale impact molecular generation performance. In this
work, we systematically investigate these critical aspects by introducing
NovoMolGen, a family of transformer-based foundation models pretrained on 1.5
billion molecules for de-novo molecule generation. Through extensive empirical
analyses, we identify a weak correlation between performance metrics measured
during pretraining and actual downstream performance, revealing important
distinctions between molecular and general NLP training dynamics. NovoMolGen
establishes new state-of-the-art results, substantially outperforming prior
Mol-LLMs and specialized generative models in both unconstrained and
goal-directed molecular generation tasks, thus providing a robust foundation
for advancing efficient and effective molecular modeling strategies.

</details>


### [190] [Decentralized Contextual Bandits with Network Adaptivity](https://arxiv.org/abs/2508.13411)
*Chuyun Deng,Huiwen Jia*

Main category: cs.LG

TL;DR: 네트워크에 분산된 컨텍스추얼 선형 밴딧 문제를 다루며, 동적 네트워크 가중치로 적응적 정보 공유를 하는 두 가지 UCB 기반 알고리즘(NetLinUCB, Net-SGD-UCB)을 제안한다. 이들은 전역·지역 성분으로 학습을 분해해 동형(공통) 피처 요약만을 공유함으로써 통신비용을 줄이고, 공유 구조와 관련된 학습 복잡도를 O(N)에서 O(√N)으로 낮춘다.


<details>
  <summary>Details</summary>
Motivation: 클래식 컨텍스추얼 밴딧은 완전 중앙집중식 데이터 또는 완전 분리된 학습자만 고려해 네트워크 환경의 부분적 정보 공유 문제를 충분히 다루지 못함. 여러 장소에서 관측이 동시 발생하고 보상분포에 공유된 구조가 있지만 지역적 차이도 존재하는 현실적 상황을 해결하고자 함.

Method: 두 알고리즘(NetLinUCB, Net-SGD-UCB)은 학습을 전역(공통 구조)과 지역(이질성)으로 분해하고, 동적으로 업데이트되는 네트워크 가중치에 따라 요약된 동형 피처 정보만을 교환하는 방식으로 적응적 정보 공유를 수행한다. NetLinUCB는 선형 확률 모델 기반의 UCB를 활용하고, Net-SGD-UCB는 SGD 기반 업데이트를 통합해 고차원·고분산 맥락에 강하게 설계됨.

Result: 이론적 후회(regret) 경계를 제시하여 네트워크 크기 N에 대한 학습 복잡도를 기존 O(N)에서 O(√N)으로 개선함을 보임. 통신량은 완전 중앙집중식보다 가볍고, 실험(시뮬레이션된 가격 책정 환경)에서 표준 벤치마크 대비 성능 우수성을 확인함.

Conclusion: 동적 네트워크 가중치에 기반한 요약 정보 교환을 통해 분산된 컨텍스추얼 밴딧 문제에서 효율적인 공동 학습이 가능함. 두 알고리즘은 노이즈 수준과 차원의 특성에 따라 상호보완적이며, 네트워크화된 학습 환경에서 통신·샘플 복잡도를 동시에 개선할 수 있음.

Abstract: We consider contextual linear bandits over networks, a class of sequential
decision-making problems where learning occurs simultaneously across multiple
locations and the reward distributions share structural similarities while also
exhibiting local differences. While classical contextual bandits assume either
fully centralized data or entirely isolated learners, much remains unexplored
in networked environments when information is partially shared. In this paper,
we address this gap by developing two network-aware Upper Confidence Bound
(UCB) algorithms, NetLinUCB and Net-SGD-UCB, which enable adaptive information
sharing guided by dynamically updated network weights. Our approach decompose
learning into global and local components and as a result allow agents to
benefit from shared structure without full synchronization. Both algorithms
incur lighter communication costs compared to a fully centralized setting as
agents only share computed summaries regarding the homogeneous features. We
establish regret bounds showing that our methods reduce the learning complexity
associated with the shared structure from $O(N)$ to sublinear $O(\sqrt{N})$,
where $N$ is the size of the network. The two algorithms reveal complementary
strengths: NetLinUCB excels in low-noise regimes with fine-grained
heterogeneity, while Net-SGD-UCB is robust to high-dimensional, high-variance
contexts. We further demonstrate the effectiveness of our methods across
simulated pricing environments compared to standard benchmarks.

</details>


### [191] [MAVIS: Multi-Objective Alignment via Value-Guided Inference-Time Search](https://arxiv.org/abs/2508.13415)
*Jeremy Carleton,Debajoy Mukherjee,Srinivas Shakkottai,Dileep Kalathil*

Main category: cs.LG

TL;DR: MAVIS는 베이스 LLM의 가중치를 변경하지 않고, 각 목표(objective)별로 작은 value 모델들을 학습해 사용자 지정 가중치로 조합하여 출력 분포를 'tilt'함으로써 다중 목표(예: helpfulness, harmlessness, humor)의 트레이드오프를 동적으로 제어하는 추론 시 정렬(inference-time alignment) 프레임워크다. 계산 비용이 큰 per-config fine-tuning 없이도 우수한 성능을 보이며, 이상적 사용자 맞춤 미세조정에 근접한다.


<details>
  <summary>Details</summary>
Motivation: 다중 목표 환경에서 서로 충돌하는 속성들을 사용자별로 다른 가중치로 맞추려면 각각의 설정에 대해 모델을 미세조정해야 하는데, 이는 계산적으로 비싸고 유연성이 낮다. 따라서 베이스 모델을 유지하면서 추론 시에 동적으로 행동을 제어할 방법이 필요하다.

Method: 각 목표마다 작은 value 모델들을 학습하고, 추론 시 사용자 지정 가중치로 이 value 모델들을 결합해 'tilting function'을 만든다. 이 함수로 베이스 모델의 출력 분포를 조정한다. value 모델들은 KL-정규화된 정책에 대해 단조 개선을 보장하는 간단한 반복 알고리즘으로 학습된다.

Result: MAVIS는 각 목표별로 미세조정한 모델을 사후 결합하는 기준선들보다 우수한 성능을 보였고, 사용자의 정확한 선호에 맞춰 미세조정한 이상적 설정에 근접하는 성능을 달성했다.

Conclusion: MAVIS는 가볍고 유연한 추론 시 정렬 기법으로, 배포된 LLM의 행동을 실시간으로 사용자 선호에 맞춰 조절할 수 있게 해주며, 비용·유연성 측면에서 실용적 대안이 된다.

Abstract: Large Language Models (LLMs) are increasingly deployed across diverse
applications that demand balancing multiple, often conflicting, objectives --
such as helpfulness, harmlessness, or humor. Aligning outputs to user-specific
preferences in such multi-objective settings typically requires fine-tuning
models for each objective or preference configuration, which is computationally
expensive and inflexible. We introduce MAVIS -- Multi-Objective Alignment via
Value-Guided Inference-Time Search -- a lightweight inference-time alignment
framework that enables dynamic control over LLM behavior without modifying the
base model's weights. MAVIS trains a set of small value models, each
corresponding to a distinct objective. At inference time, these value models
are combined using user-specified weights to produce a tilting function that
adjusts the base model's output distribution toward desired trade-offs. The
value models are trained using a simple iterative algorithm that ensures
monotonic improvement of the KL-regularized policy. We show empirically that
MAVIS outperforms baselines that fine-tune per-objective models and combine
them post hoc, and even approaches the performance of the idealized setting
where models are fine-tuned for a user's exact preferences.

</details>


### [192] [EventTSF: Event-Aware Non-Stationary Time Series Forecasting](https://arxiv.org/abs/2508.13434)
*Yunfeng Ge,Ming Jin,Yiji Zhao,Hongyan Li,Bo Du,Chang Xu,Shirui Pan*

Main category: cs.LG

TL;DR: 이 논문은 텍스트 기반 이벤트를 통합해 비정상(non-stationary) 시계열 예측 성능을 높이는 EventTSF라는 자기회귀 생성 프레임워크를 제안한다. 오토리그레시브 확산(autoregressive diffusion)과 flow matching을 결합하고, 이벤트 의미 신호에 따라 timestep을 적응적으로 제어하며, 멀티해상도에서 시계열과 텍스트를 융합하는 U자형 확산 트랜스포머 denoiser를 사용한다. 다양한 데이터셋에서 기존 12개 기법을 능가하며 예측 정확도 10.7% 향상과 학습 효율 1.13배 개선을 보였다.


<details>
  <summary>Details</summary>
Motivation: 에너지·교통 등 분야에서 시계열의 비정상성이 외부 텍스트 이벤트와 밀접하게 연관되지만, 기존 연구는 단일 모달리티에 의존해 텍스트 기반 이벤트를 활용한 정밀한 예측이 부족하다. 텍스트 이벤트와 연속 시계열의 미세 동기화, 텍스트가 유발하는 시간적 불확실성, 텍스트 임베딩과 다중 해상도 시계열 패턴의 불일치 같은 근본적 난제가 존재한다.

Method: EventTSF: (1) 히스토리 시계열과 텍스트 이벤트를 통합해 다음 구간을 생성하는 자기회귀 생성 구조; (2) 각 스텝에서 세밀한 시계열-이벤트 상호작용을 포착하기 위해 autoregressive diffusion과 flow matching을 결합; (3) 이벤트 의미 신호에 따라 flow matching의 timestep을 적응적으로 제어해 이벤트로 인한 불확실성 처리; (4) 멀티해상도에서 시계열·텍스트를 효율적으로 융합하는 U자형(diffusion) 트랜스포머 기반 denoiser.

Result: 8개의 합성 및 실제 데이터셋 실험에서 12개 베이스라인 대비 전반적 우수성 입증. 평균적으로 예측 정확도 10.7% 향상, 학습 속도는 약 1.13배 빨라짐. 다양한 이벤트-인지 비정상 시나리오에서 성능 우위 확인.

Conclusion: EventTSF는 텍스트 이벤트를 정교하게 통합해 비정상 시계열 예측의 동기화·불확실성·멀티해상도 정렬 문제를 해결하며, 정확도와 학습 효율 모두에서 유의미한 개선을 달성한다.

Abstract: Time series forecasting plays a vital role in critical domains like energy
and transportation, where non-stationary dynamics are deeply intertwined with
events in other modalities such as texts. However, incorporating natural
language-based external events to improve non-stationary forecasting remains
largely unexplored, as most approaches still rely on a single modality,
resulting in limited contextual knowledge and model underperformance. Enabling
fine-grained multimodal interactions between temporal and textual data is
challenged by three fundamental issues: (1) the difficulty of fine-grained
synchronization between time-varying discrete textual events and continuous
time series; (2) the inherent temporal uncertainty introduced by textual
semantics; and (3) the misalignment between textual event embeddings and
multi-resolution temporal patterns. In this work, we address these challenges
by introducing event-aware non-stationary time series forecasting (EventTSF),
an autoregressive generation framework that integrates historical time series
with textual events to make subsequent forecasts. Specifically, EventTSF uses
autoregressive diffusion with flow matching at each step to capture nuanced
temporal-event interactions. To handle event-induced uncertainty, flow matching
timesteps are adaptively controlled according to event semantic signals. The
underlying denoiser employs a multimodal U-shaped diffusion transformer that
efficiently fuses temporal and textual modalities across different resolutions.
Extensive experiments on 8 synthetic and real-world datasets show that EventTSF
outperforms 12 baselines across diverse event-aware non-stationary time series
forecasting scenarios, achieving substantial improvements of 10.7% higher
forecasting accuracy and $1.13\times$ faster training efficiency.

</details>


### [193] [SVDformer: Direction-Aware Spectral Graph Embedding Learning via SVD and Transformer](https://arxiv.org/abs/2508.13435)
*Jiayu Fang,Zhiqi Shao,S T Boris Choy,Junbin Gao*

Main category: cs.LG

TL;DR: SVDformer는 SVD와 Transformer를 결합해 방향성을 보존하는 그래프 표현 학습을 제안한다. 싱귤러 값 임베딩을 self-attention으로 정제해 스펙트럼 성분을 강조/억제하고, 싱귤러 벡터를 방향 투영 기저로 사용해 Transformer로 입/출력 엣지 패턴의 다중 스케일 상호작용을 모델링한다. 노드 분류에서 기존 기법들보다 우수한 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 기존의 방향 그래프 GNN들은 등방성(동일한 방식으로 이웃을 집계)과 국소적 필터링 때문에 방향성 의미와 전역 구조 패턴을 동시에 포착하기 어려움.

Method: SVDformer는 SVD로 얻은 싱귤러 값/벡터를 사용한다. 싱귤러 값 임베딩을 멀티헤드 self-attention으로 정제해 중요한 스펙트럼 성분을 증강하고 고주파 잡음을 억제한다(학습 가능한 로우패스/하이패스 필터링). 싱귤러 벡터를 방향 투영 기저로, 싱귤러 값을 스케일링 인자라고 보고 Transformer의 어텐션으로 입/출력 엣지 패턴 간 다중 스케일 상호작용을 모델링하여 특성 전파 시 엣지 방향성을 명시적으로 보존.

Result: 여섯 개의 방향 그래프 벤치마크에서 SVDformer가 최첨단 GNN들과 방향성 기반 베이스라인보다 일관되게 우수한 노드 분류 성능을 보임.

Conclusion: SVD와 Transformer의 결합은 방향성 보존과 스펙트럼 기반 필터링을 가능하게 해, 방향 그래프 표현 학습의 새로운 패러다임을 제시한다.

Abstract: Directed graphs are widely used to model asymmetric relationships in
real-world systems. However, existing directed graph neural networks often
struggle to jointly capture directional semantics and global structural
patterns due to their isotropic aggregation mechanisms and localized filtering
mechanisms. To address this limitation, this paper proposes SVDformer, a novel
framework that synergizes SVD and Transformer architecture for direction-aware
graph representation learning. SVDformer first refines singular value
embeddings through multi-head self-attention, adaptively enhancing critical
spectral components while suppressing high-frequency noise. This enables
learnable low-pass/high-pass graph filtering without requiring spectral
kernels. Furthermore, by treating singular vectors as directional projection
bases and singular values as scaling factors, SVDformer uses the Transformer to
model multi-scale interactions between incoming/outgoing edge patterns through
attention weights, thereby explicitly preserving edge directionality during
feature propagation. Extensive experiments on six directed graph benchmarks
demonstrate that SVDformer consistently outperforms state-of-the-art GNNs and
direction-aware baselines on node classification tasks, establishing a new
paradigm for learning representations on directed graphs.

</details>


### [194] [Dynamic Design of Machine Learning Pipelines via Metalearning](https://arxiv.org/abs/2508.13436)
*Edesio Alcobaça,André C. P. L. F. de Carvalho*

Main category: cs.LG

TL;DR: 히스토리 메타지식을 활용해 AutoML의 탐색공간을 동적으로 설계함으로써 탐색 속도를 크게 향상시키고(무작위 탐색에서 실행시간 89% 절감), 검색공간을 크게 줄이면서 예측 성능 저하를 거의 발생시키지 않음.


<details>
  <summary>Details</summary>
Motivation: 전통적 AutoML은 모델·하이퍼파라미터·피처 엔지니어링을 자동화하지만 탐색·최적화 비용이 매우 높고, 큰 탐색공간이 오버피팅을 유발할 수 있음. 따라서 계산 비용과 과적합을 줄이는 방법이 필요함.

Method: 과거의 메타지식을 이용한 메타러닝 기법으로 탐색공간을 동적으로 설계하여 유망한 영역만 선택하도록 함. 제안 기법을 Random Search와 Auto-Sklearn에 적용해 검색공간 축소 및 최적화 가속을 수행함.

Result: 제안 기법은 Random Search에서 실행시간을 89% 줄였고, 전처리기와 분류기 후보군을 각각 평균적으로 (1.8/13, 4.3/16)만큼 축소함. 예측 성능 저하 없이 효율성을 확보했으며, Auto-Sklearn에 적용했을 때도 경쟁력 있는 성능을 보임.

Conclusion: 메타러닝 기반의 동적 탐색공간 설계는 AutoML의 계산 비용을 크게 낮추고 탐색 효율을 높이는 실용적 접근이다. 다만 메타피처 선택, 메타모델 설명가능성, 탐색공간 축소에 따른 트레이드오프를 신중히 고려해야 함.

Abstract: Automated machine learning (AutoML) has democratized the design of machine
learning based systems, by automating model selection, hyperparameter tuning
and feature engineering. However, the high computational cost associated with
traditional search and optimization strategies, such as Random Search, Particle
Swarm Optimization and Bayesian Optimization, remains a significant challenge.
Moreover, AutoML systems typically explore a large search space, which can lead
to overfitting. This paper introduces a metalearning method for dynamically
designing search spaces for AutoML system. The proposed method uses historical
metaknowledge to select promising regions of the search space, accelerating the
optimization process. According to experiments conducted for this study, the
proposed method can reduce runtime by 89\% in Random Search and search space by
(1.8/13 preprocessor and 4.3/16 classifier), without compromising significant
predictive performance. Moreover, the proposed method showed competitive
performance when adapted to Auto-Sklearn, reducing its search space.
Furthermore, this study encompasses insights into meta-feature selection,
meta-model explainability, and the trade-offs inherent in search space
reduction strategies.

</details>


### [195] [ASAP: Unsupervised Post-training with Label Distribution Shift Adaptive Learning Rate](https://arxiv.org/abs/2508.13445)
*Heewon Park,Mugon Joe,Miru Kim,Minhae Kwon*

Main category: cs.LG

TL;DR: ASAP은 이전 소프트맥스 출력과 현재 출력의 코사인 거리로 학습률을 동적으로 조절해 온라인 라벨 분포 변화(online label shift)에 빠르고 가벼운 비지도 적응을 제공한다. 라벨·앙상블·과거 입력이 필요 없고 여러 데이터셋·변화 시나리오에서 정확도와 효율성을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 온라인 환경에서 라벨 분포가 시간에 따라 변할 때 모델을 신속하게 적응시키려면 학습률 선택이 중요하다. 너무 작으면 적응이 느리고, 너무 크면 불안정해진다. 라벨이 없는 상황에서 안전하고 자동화된 학습률 조정 방법이 필요하다.

Method: 현재와 이전의 모델 출력(소프트맥스 확률 벡터) 간 코사인 거리를 계산하고 이를 적절한 범위로 매핑해 학습률을 동적으로 조절한다. 라벨, 모델 앙상블, 과거 입력 등을 요구하지 않고 이전 출력만 저장하면 된다.

Result: 여러 데이터셋과 다양한 라벨 이동 시나리오에서 ASAP은 일관되게 정확도와 적응 효율을 향상시켰다(논문 주장).

Conclusion: 간단한 출력 차이 측정과 학습률 매핑으로 비지도 온라인 적응을 빠르고 가볍게 수행 가능하므로 실무 적용에 적합하다.

Abstract: In real-world applications, machine learning models face online label shift,
where label distributions change over time. Effective adaptation requires
careful learning rate selection: too low slows adaptation and too high causes
instability. We propose ASAP (Adaptive Shift Aware Post-training), which
dynamically adjusts the learning rate by computing the cosine distance between
current and previous unlabeled outputs and mapping it within a bounded range.
ASAP requires no labels, model ensembles, or past inputs, using only the
previous softmax output for fast, lightweight adaptation. Experiments across
multiple datasets and shift scenarios show ASAP consistently improves accuracy
and efficiency, making it practical for unsupervised model adaptation.

</details>


### [196] [Hierarchy-Consistent Learning and Adaptive Loss Balancing for Hierarchical Multi-Label Classification](https://arxiv.org/abs/2508.13452)
*Ruobing Jiang,Mengzhe Liu,Haobing Liu,Yanwei Yu*

Main category: cs.LG

TL;DR: HCAL은 계층적 다중 레이블 분류에서 구조적 일관성 유지와 MTL의 손실 가중치 불균형 문제를 해결하기 위해 프로토타입 대조학습과 적응형 태스크 가중화를 결합한 분류기이다. 프로토타입과 자식→부모 특징 집계를 통해 의미적 일관성을 확보하고, 태스크별 수렴률을 모니터링해 동적으로 손실 가중치를 조정하며, 프로토타입 교란으로 결정 경계의 강건성을 높인다. HVR 지표로 계층 위반을 정량화하고, 세 데이터셋에서 정확도와 HVR에서 기존 방법보다 우수함을 보였다.


<details>
  <summary>Details</summary>
Motivation: 계층적 다중 레이블 분류(HMC)는 클래스 계층 구조의 일관성을 유지해야 하고, 다중 과제 학습(MTL)에서는 태스크 간 손실 균형(‘one-strong-many-weak’ 편향)이 성능 저하를 초래한다. 이를 해결할 방법이 필요하다.

Method: MTL 기반 분류기(HCAL)를 제안한다. 핵심 구성요소는 (1) 프로토타입 대조학습과 자식→부모 특징 집계를 통한 명시적 라벨-프로토타입 의미 일관성, (2) 태스크별 수렴률을 모니터링하는 적응형 손실 가중화로 학습 자원 배분 자동화, (3) 프로토타입에 제어된 노이즈를 주입하는 교란 메커니즘으로 결정 경계 확장.

Result: 세 가지 데이터셋에 대한 광범위한 실험에서 제안한 HCAL은 기존 베이스라인보다 분류 정확도가 높았고, 새로 제안한 계층 위반률(HVR)이 낮아 계층적 일관성과 일반화 능력이 향상되었음을 보였다.

Conclusion: 프로토타입 기반 의미 일관성, 적응적 손실 가중화, 프로토타입 교란을 결합한 HCAL은 HMC 문제에서 구조적 일관성과 MTL 편향을 효과적으로 완화하며 실험적으로 우수한 성능을 보인다.

Abstract: Hierarchical Multi-Label Classification (HMC) faces critical challenges in
maintaining structural consistency and balancing loss weighting in Multi-Task
Learning (MTL). In order to address these issues, we propose a classifier
called HCAL based on MTL integrated with prototype contrastive learning and
adaptive task-weighting mechanisms. The most significant advantage of our
classifier is semantic consistency including both prototype with explicitly
modeling label and feature aggregation from child classes to parent classes.
The other important advantage is an adaptive loss-weighting mechanism that
dynamically allocates optimization resources by monitoring task-specific
convergence rates. It effectively resolves the "one-strong-many-weak"
optimization bias inherent in traditional MTL approaches. To further enhance
robustness, a prototype perturbation mechanism is formulated by injecting
controlled noise into prototype to expand decision boundaries. Additionally, we
formalize a quantitative metric called Hierarchical Violation Rate (HVR) as to
evaluate hierarchical consistency and generalization. Extensive experiments
across three datasets demonstrate both the higher classification accuracy and
reduced hierarchical violation rate of the proposed classifier over baseline
models.

</details>


### [197] [Classifying Clinical Outcome of Epilepsy Patients with Ictal Chirp Embeddings](https://arxiv.org/abs/2508.13476)
*Nooshin Bahador,Milad Lankarany*

Main category: cs.LG

TL;DR: Pipeline uses t-SNE to create interpretable 2D embeddings of chirp-based temporal/spectral/frequency features, trains classifiers (RF, SVM, LR, k-NN) on embeddings for three clinical tasks, and applies SHAP to produce spatially localized feature-importance maps; RF and k-NN perform best (up to 88.8% accuracy for optimal-case detection).


<details>
  <summary>Details</summary>
Motivation: Provide interpretable visualization and attribution of chirp-derived signal features to support clinical stratification and decision-making by revealing latent structure associated with outcomes and case difficulty.

Method: Extract chirp temporal, spectral, and frequency metrics; apply t-SNE with Student t-distribution similarity to obtain 2D embeddings while preserving local neighborhoods and addressing crowding; define three binary classification tasks on embeddings; train Random Forest, SVM, Logistic Regression, and k-NN using stratified 5-fold CV; generate SHAP-based sensitivity maps by training models to predict t-SNE coordinates and attributing feature influence across embedding space.

Result: Random Forest and k-NN showed superior classification performance across tasks, with up to 88.8% accuracy for identifying optimal cases (successful + low difficulty). SHAP sensitivity maps revealed spatially localized feature importance that explained regional clustering and class separation in the embedding.

Conclusion: Combining interpretable 2D embeddings (t-SNE) with local feature-attribution (SHAP) yields an explainable framework for clinical stratification and decision support based on chirp features; however, reproducibility, embedding limitations, and the indirect nature of attributing features via predicted embeddings warrant further validation.

Abstract: This study presents a pipeline leveraging t-Distributed Stochastic Neighbor
Embedding (t-SNE) for interpretable visualizations of chirp features across
diverse outcome scenarios. The dataset, comprising chirp-based temporal,
spectral, and frequency metrics. Using t-SNE, local neighborhood relationships
were preserved while addressing the crowding problem through Student
t-distribution-based similarity optimization. Three classification tasks were
formulated on the 2D t-SNE embeddings: (1) distinguishing clinical success from
failure/no-resection, (2) separating high-difficulty from low-difficulty cases,
and (3) identifying optimal cases, defined as successful outcomes with minimal
clinical difficulty. Four classifiers, namely, Random Forests, Support Vector
Machines, Logistic Regression, and k-Nearest Neighbors, were trained and
evaluated using stratified 5-fold cross-validation. Across tasks, the Random
Forest and k-NN classifiers demonstrated superior performance, achieving up to
88.8% accuracy in optimal case detection (successful outcomes with minimal
clinical difficulty). Additionally, feature influence sensitivity maps were
generated using SHAP explanations applied to model predicting t-SNE
coordinates, revealing spatially localized feature importance within the
embedding space. These maps highlighted how specific chirp attributes drive
regional clustering and class separation, offering insights into the latent
structure of the data. The integrated framework showcases the potential of
interpretable embeddings and local feature attribution for clinical
stratification and decision support.

</details>


### [198] [DyMixOp: Guiding Neural Operator Design for PDEs from a Complex Dynamics Perspective with Local-Global-Mixing](https://arxiv.org/abs/2508.13490)
*Pengyu Lai,Yixiao Chen,Hui Xu*

Main category: cs.LG

TL;DR: DyMixOp은 관성 매니폴드 이론과 Local-Global-Mixing 변환을 결합해 무한차원 PDE 동역학을 유한차원 잠재공간으로 변환하고, 다층 LGM 구조로 선형·비선형 시간을 모사하여 대류 지배 PDE에서 특히 성능을 크게 개선하는 신경 연산자(framework)이다.


<details>
  <summary>Details</summary>
Motivation: 신경망으로 비선형 PDE 동역학을 근사하려면 시스템을 적절한 형식으로 변환해야 하나, 많은 경우 비선형화가 어렵거나 선형화에 무한차원 공간이 필요해 학습과 해석이 힘들다. 기존 신경 연산자는 스펙트럼 바이어스 등으로 미세 구조·비선형 상호작용 포착에 한계가 있다.

Method: DyMixOp은 관성 매니폴드 이론을 기반으로 무한차원 비선형 PDE를 유한차원 잠재공간으로 사상하여 본질적 비선형 상호작용을 보존한다. 핵심 구성인 Local-Global-Mixing(LGM) 변환은 난류의 대류 동역학에서 영감을 얻어 국소 세부와 전역 비선형 상호작용을 동시에 포착하고 스펙트럼 바이어스를 완화한다. 또한 여러 LGM 레이어를 연결하는 동역학-정보 아키텍처로 시간 진화를 반영해 선형·비선형 동역학을 근사한다.

Result: 여러 PDE 벤치마크에서 SOTA 성능을 보였고, 특히 대류 지배 시나리오에서 예측 오차를 최대 86.7%까지 큰 폭으로 감소시켰다. 계산 효율성과 확장성도 유지됨을 주장한다.

Conclusion: 관성 매니폴드 기반 잠재 변환과 LGM을 결합한 DyMixOp은 물리적 해석 가능성을 높이면서 비선형·미세 구조를 잘 포착해 기존 신경 연산자의 한계를 극복한다. 대류 우세 문제에 특히 유용하며 확장성이 기대된다.

Abstract: A primary challenge in using neural networks to approximate nonlinear
dynamical systems governed by partial differential equations (PDEs) is
transforming these systems into a suitable format, especially when dealing with
non-linearizable dynamics or the need for infinite-dimensional spaces for
linearization. This paper introduces DyMixOp, a novel neural operator framework
for PDEs that integrates insights from complex dynamical systems to address
this challenge. Grounded in inertial manifold theory, DyMixOp transforms
infinite-dimensional nonlinear PDE dynamics into a finite-dimensional latent
space, establishing a structured foundation that maintains essential nonlinear
interactions and enhances physical interpretability. A key innovation is the
Local-Global-Mixing (LGM) transformation, inspired by convection dynamics in
turbulence. This transformation effectively captures both fine-scale details
and nonlinear interactions, while mitigating spectral bias commonly found in
existing neural operators. The framework is further strengthened by a
dynamics-informed architecture that connects multiple LGM layers to approximate
linear and nonlinear dynamics, reflecting the temporal evolution of dynamical
systems. Experimental results across diverse PDE benchmarks demonstrate that
DyMixOp achieves state-of-the-art performance, significantly reducing
prediction errors, particularly in convection-dominated scenarios reaching up
to 86.7\%, while maintaining computational efficiency and scalability.

</details>


### [199] [Uncertainty Tube Visualization of Particle Trajectories](https://arxiv.org/abs/2508.13505)
*Jixian Li,Timbwaoga Aime Judicael Ouermi,Mengjiao Han,Chris R. Johnson*

Main category: cs.LG

TL;DR: 주어진 논문 초록은 입자 궤적을 예측하는 신경망의 불확실성을 시각화하기 위해 슈퍼엘립스 관(uncertainty tube)을 제안한다. 이 방법은 비대칭 불확실성을 포착하며 Deep Ensembles, MC Dropout, SWAG 같은 불확실성 추정 기법과 통합되어 합성 및 시뮬레이션 데이터에서 유용함을 보인다.


<details>
  <summary>Details</summary>
Motivation: 신경망이 입자 궤적 예측에서 널리 사용되지만, 예측의 불확실성을 효과적으로 정량화하고 시각화하는 것이 어렵다. 신뢰성이 중요한 응용에서 불확실성의 이해 없이는 모델의 신뢰도가 크게 저하된다.

Method: 비대칭 불확실성을 직관적으로 나타내는 슈퍼엘립스(슈퍼엘립티컬) 관을 설계 및 구현했다. 또한 Deep Ensembles, Monte Carlo Dropout, SWAG 등 기존의 불확실성 정량화 기법들과 통합하여 불확실성 관을 생성한다.

Result: 슈퍼엘립스 관은 계산적으로 효율적이며, 합성 데이터와 시뮬레이션 데이터에 적용한 결과 비대칭 불확실성을 정확하게 캡처하고 직관적으로 전달하는 데 성공했다.

Conclusion: 제안된 불확실성 관은 NN 기반 입자 궤적 예측의 불확실성을 가시화하는 실용적 도구로서 유용하며, 다양한 불확실성 추정 기법과 호환되어 신뢰성 있는 모델 검증과 해석에 기여할 수 있다.

Abstract: Predicting particle trajectories with neural networks (NNs) has substantially
enhanced many scientific and engineering domains. However, effectively
quantifying and visualizing the inherent uncertainty in predictions remains
challenging. Without an understanding of the uncertainty, the reliability of NN
models in applications where trustworthiness is paramount is significantly
compromised. This paper introduces the uncertainty tube, a novel,
computationally efficient visualization method designed to represent this
uncertainty in NN-derived particle paths. Our key innovation is the design and
implementation of a superelliptical tube that accurately captures and
intuitively conveys nonsymmetric uncertainty. By integrating well-established
uncertainty quantification techniques, such as Deep Ensembles, Monte Carlo
Dropout (MC Dropout), and Stochastic Weight Averaging-Gaussian (SWAG), we
demonstrate the practical utility of the uncertainty tube, showcasing its
application on both synthetic and simulation datasets.

</details>


### [200] [Explainability of Algorithms](https://arxiv.org/abs/2508.13529)
*Andrés Páez*

Main category: cs.LG

TL;DR: 이 논문은 AI의 불투명성(opacity)을 두 가지 관점—기술적 복잡성으로 인한 '블랙박스'와 독점적·영업상 비공개로 인한 '의도적 은닉'—으로 구분하고, 각 경우의 윤리적 함의와 이를 극복하기 위한 설명 가능한 AI(XAI) 기법들의 한계와 도전 과제를 분석한다.


<details>
  <summary>Details</summary>
Motivation: AI 알고리즘의 불투명성은 윤리적 AI 개발의 주요 장애물로 지목되며, 불투명성의 다양한 원인(기술적 복잡성 vs. 의도적 은닉)을 구분하고 각각의 윤리적 문제를 명확히 하고자 함.

Method: 문헌 및 개념적 분석을 통해 불투명성의 두 가지 유형을 이론적으로 구분하고, 컴퓨터 과학에서 제안된 설명 기법들(XAI 접근법)을 검토하여 이들이 기술적 불투명성을 어떻게 해결하려 하는지 평가함.

Result: 기술적 복잡성으로 인한 불투명성은 여러 XAI 기법으로 부분적 해명이 가능하지만, 설명 가능성은 여전히 제한적이며 완전한 투명성을 보장하지 못함. 한편, 상업적·법적 이유로 의도적으로 숨겨진 알고리즘은 기술적 수단으로는 해소하기 어려운 별개의 윤리적 문제를 제기함.

Conclusion: 불투명성의 원인에 따라 다른 윤리적·정책적 대응이 필요하며, XAI는 중요한 도구지만 단독으로는 부족하므로 법적 규제·조직적 투명성 확보 등 다른 대책과 병행돼야 한다.

Abstract: The opaqueness of many complex machine learning algorithms is often mentioned
as one of the main obstacles to the ethical development of artificial
intelligence (AI). But what does it mean for an algorithm to be opaque? Highly
complex algorithms such as artificial neural networks process enormous volumes
of data in parallel along multiple hidden layers of interconnected nodes,
rendering their inner workings epistemically inaccessible to any human being,
including their designers and developers; they are "black boxes" for all their
stakeholders. But opaqueness is not always the inevitable result of technical
complexity. Sometimes, the way an algorithm works is intentionally hidden from
view for proprietary reasons, especially in commercial automated decision
systems, creating an entirely different type of opaqueness. In the first part
of the chapter, we will examine these two ways of understanding opacity and the
ethical implications that stem from each of them. In the second part, we
explore the different explanatory methods that have been developed in computer
science to overcome an AI system's technical opaqueness. As the analysis shows,
explainable AI (XAI) still faces numerous challenges.

</details>


### [201] [MuFlex: A Scalable, Physics-based Platform for Multi-Building Flexibility Analysis and Coordination](https://arxiv.org/abs/2508.13532)
*Ziyan Wu,Ivan Korolija,Rui Tang*

Main category: cs.LG

TL;DR: MuFlex는 EnergyPlus 기반의 동기식 정보 교환과 OpenAI Gym 인터페이스를 갖춘 다중 건물 유연성 조정 오픈소스 플랫폼으로, 4개 사무실 건물을 대상으로 한 사례에서 Soft Actor-Critic로 총 피크 수요를 지정 임계값 이하로 낮추면서 실내 환경 품질을 유지함을 보였다.


<details>
  <summary>Details</summary>
Motivation: 재생에너지 확대에 따라 전력계통 균형을 위해 건물 집합체의 수요 유연성이 필요하나, 기존 오픈소스 테스트베드는 단일 건물 위주이거나 RC·데이터 기반의 단순 모델에 의존해 물리적 정밀도 및 해석성을 제한하고, 고정된 입출력·모델 포맷 때문에 다양한 제어 시나리오 벤치마킹에 제약이 있다.

Method: MuFlex를 설계·구현하여 EnergyPlus 건물 모델들 간의 동기식 정보 교환을 지원하고, OpenAI Gym API를 따르는 모듈형 RL 인터페이스를 제공함. 플랫폼을 사용해 4개 사무실 건물의 수요 유연성을 Soft Actor-Critic(SAC) 알고리즘으로 제어하는 사례를 수행하며 하이퍼파라미터를 세밀하게 튜닝함.

Result: SAC 기반 제어로 4개 건물의 집계 유연성을 활용해 전체 피크 수요를 지정된 임계값 이하로 감소시켰고, 동시에 실내 환경 품질(예: 온열 쾌적성)을 유지함을 확인.

Conclusion: MuFlex는 다중 건물 유연성 조정 연구를 위한 확장 가능하고 표준화된 오픈소스 플랫폼으로 기존 테스트베드의 물리적 정확도·유연성·벤치마킹 제한을 해소하며, RL 기반 제어 알고리즘의 개발·비교에 유용하다.

Abstract: With the increasing penetration of renewable generation on the power grid,
maintaining system balance requires coordinated demand flexibility from
aggregations of buildings. Reinforcement learning (RL) has been widely explored
for building controls because of its model-free nature. Open-source simulation
testbeds are essential not only for training RL agents but also for fairly
benchmarking control strategies. However, most building-sector testbeds target
single buildings; multi-building platforms are relatively limited and typically
rely on simplified models (e.g., Resistance-Capacitance) or data-driven
approaches, which lack the ability to fully capture the physical intricacies
and intermediate variables necessary for interpreting control performance.
Moreover, these platforms often impose fixed inputs, outputs, and model
formats, restricting their applicability as benchmarking tools across diverse
control scenarios. To address these gaps, MuFlex, a scalable, open-source
platform for benchmarking and testing control strategies for multi-building
flexibility coordination, was developed in this study. MuFlex enables
synchronous information exchange across EnergyPlus building models and adheres
to the latest OpenAI Gym interface, providing a modular, standardized RL
implementation. The platform capabilities were demonstrated in a case study
coordinating demand flexibility across four office buildings using the Soft
Actor-Critic algorithm with carefully fine-tuned hyperparameters. The results
show that aggregating the four buildings flexibility reduced total peak demand
below a specified threshold while maintaining indoor environmental quality.

</details>


### [202] [CALYPSO: Forecasting and Analyzing MRSA Infection Patterns with Community and Healthcare Transmission Dynamics](https://arxiv.org/abs/2508.13548)
*Rituparna Datta,Jiaming Cui,Gregory R. Madden,Anil Vullikanti*

Main category: cs.LG

TL;DR: CALYPSO는 신경망과 역학적 메타개체군 모델을 결합해 병원·지역사회에서의 MRSA 전파를 설명하고, 환자 청구자료·통근·의료이송 데이터를 사용해 지역·시간별 전파 파라미터를 학습해 다중 공간해상도의 예측 및 정책 시뮬레이션을 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: MRSA는 의료시설과 장기요양시설에서 중대한 공중보건 위협이며, 위험 이해·중재 평가·발병 예측이 필요하다. 기존 통계·딥러닝 모델은 역학적 해석성이 부족하고 성능 제약이 있으며, 기구적 모델은 보정과 다양한 데이터 통합이 어렵다.

Method: CALYPSO는 신경망으로 지역·시간 의존 파라미터를 추정하고 이를 메타개체군(병원·지역 간 환자 이동·통근·의료이송 기반) 역학 모델에 결합한다. 보험청구, 통근 데이터, 의료이송 패턴을 입력으로 사용해 각 공간 해상도(카운티·의료시설·지역·주)에서 전파 동학을 모델링하고 반사실험 분석을 지원한다.

Result: 주(州) 단위 예측에서 기존 머신러닝 베이스라인보다 성능이 4.5% 이상 향상되었고, 고위험 지역 식별 및 감염예방 자원 배분의 비용효율적 전략 도출이 가능했다. 다양한 공간 해상도에서 해석 가능한 예측과 정책 시나리오 평가를 제공한다.

Conclusion: CALYPSO는 데이터 통합형 하이브리드 모델로 MRSA 전파 예측의 정확도와 역학적 해석성을 개선하고, 정책 결정을 위한 반사실험과 자원배분 분석에 실무적인 도구를 제공한다.

Abstract: Methicillin-resistant Staphylococcus aureus (MRSA) is a critical public
health threat within hospitals as well as long-term care facilities. Better
understanding of MRSA risks, evaluation of interventions and forecasting MRSA
rates are important public health problems. Existing forecasting models rely on
statistical or neural network approaches, which lack epidemiological
interpretability, and have limited performance. Mechanistic epidemic models are
difficult to calibrate and limited in incorporating diverse datasets. We
present CALYPSO, a hybrid framework that integrates neural networks with
mechanistic metapopulation models to capture the spread dynamics of infectious
diseases (i.e., MRSA) across healthcare and community settings. Our model
leverages patient-level insurance claims, commuting data, and healthcare
transfer patterns to learn region- and time-specific parameters governing MRSA
spread. This enables accurate, interpretable forecasts at multiple spatial
resolutions (county, healthcare facility, region, state) and supports
counterfactual analyses of infection control policies and outbreak risks. We
also show that CALYPSO improves statewide forecasting performance by over 4.5%
compared to machine learning baselines, while also identifying high-risk
regions and cost-effective strategies for allocating infection prevention
resources.

</details>


### [203] [Collapsing ROC approach for risk prediction research on both common and rare variants](https://arxiv.org/abs/2508.13552)
*Changshuai Wei,Qing Lu*

Main category: cs.LG

TL;DR: 저자는 공통변이뿐 아니라 희귀변이를 통합해 위험예측 정확도를 높이기 위해 'collapsing ROC(CROC)'을 제안함. GAW17 미니-엑솜 데이터(533 SNP, 37 유전자)에서 평가한 결과, 모든 SNP를 사용한 모델(AUC=0.605)이 공통변이만 사용한 모델(AUC=0.585)보다 우수했고, 특히 공통변이가 줄어들수록 CROC가 기존 FROC보다 큰 성능 이득을 보였음(희귀변이만일 때 CROC AUC=0.603 vs FROC AUC=0.524).


<details>
  <summary>Details</summary>
Motivation: 현재의 유전체 기반 위험예측은 주로 공통 변이에 의존해 임상적 활용을 위한 예측정확도가 부족하고, 대부분의 희귀변이는 아직 예측모델에 제대로 반영되지 않았음. 따라서 공통·희귀 변이를 모두 고려하는 포괄적 예측방법이 필요함.

Method: 기존의 forward ROC(FROC)를 확장한 collapsing ROC(CROC)를 제안. CROC는 희귀변이를 처리하기 위한 추가 절차(희귀변이의 집계/콜랩스 전략)를 도입해 공통·희귀 변이를 함께 사용한 리스크 예측 모델을 구축. GAW17 미니-엑솜 데이터의 533 SNP(37 유전자)를 사용해 CROC와 FROC 성능을 비교하고, 공통변이 수를 점차 줄이는 실험을 수행함.

Result: - 모든 SNP 사용: AUC=0.605 vs 공통변이만: AUC=0.585
- 공통변이가 줄어들수록 CROC의 상대적 이득 증가
- 희귀변이만의 극단적 시나리오: CROC AUC=0.603, FROC AUC=0.524

Conclusion: CROC는 희귀변이가 많은 상황에서도 예측성능을 유지하거나 개선해, 공통·희귀 변이를 모두 고려하는 차세대 유전성 리스크 예측에 유망한 접근법임.

Abstract: Risk prediction that capitalizes on emerging genetic findings holds great
promise for improving public health and clinical care. However, recent risk
prediction research has shown that predictive tests formed on existing common
genetic loci, including those from genome-wide association studies, have lacked
sufficient accuracy for clinical use. Because most rare variants on the genome
have not yet been studied for their role in risk prediction, future disease
prediction discoveries should shift toward a more comprehensive risk prediction
strategy that takes into account both common and rare variants. We are
proposing a collapsing receiver operating characteristic CROC approach for risk
prediction research on both common and rare variants. The new approach is an
extension of a previously developed forward ROC FROC approach, with additional
procedures for handling rare variants. The approach was evaluated through the
use of 533 single-nucleotide polymorphisms SNPs in 37 candidate genes from the
Genetic Analysis Workshop 17 mini-exome data set. We found that a prediction
model built on all SNPs gained more accuracy AUC = 0.605 than one built on
common variants alone AUC = 0.585. We further evaluated the performance of two
approaches by gradually reducing the number of common variants in the analysis.
We found that the CROC method attained more accuracy than the FROC method when
the number of common variants in the data decreased. In an extreme scenario,
when there are only rare variants in the data, the CROC reached an AUC value of
0.603, whereas the FROC had an AUC value of 0.524.

</details>


### [204] [Prediction of Hospital Associated Infections During Continuous Hospital Stays](https://arxiv.org/abs/2508.13561)
*Rituparna Datta,Methun Kamruzzaman,Eili Y. Klein,Gregory R Madden,Xinwei Deng,Anil Vullikanti,Parantapa Bhattacharya*

Main category: cs.LG

TL;DR: GenHAI는 입원 기간 동안의 MRSA 검사 결과 시퀀스를 모델링하는 새로운 생성 확률 모델로, 예측·인과·반사실 질문에 대해 근사적으로 답할 수 있으며, 두 실제 데이터셋에서 다른 머신러닝 모델들과 비교해 효능을 보였다.


<details>
  <summary>Details</summary>
Motivation: MRSA는 CDC가 지정한 심각한 항생제 내성 위협으로, 입원 환자는 기저질환, 면역억제, 항생제 사용, 오염된 의료진·장비와의 접촉 등으로 감염 위험과 치명적 결과 위험이 특히 높다. 병원 관리자가 MRSA 위험을 경감하기 위한 의사결정을 할 수 있도록 검사 결과 시퀀스를 모델링하는 도구가 필요하다.

Method: 확률적 프로그래밍 패러다임에 기반한 생성 확률 모델 GenHAI를 제안하여 단일 입원 기간 동안 환자의 MRSA 검사 결과 시퀀스를 모델링한다. 이 모델은 예측적(query), 인과적(causal), 반사실(counterfactual) 질문에 대해 근사적으로 답할 수 있도록 설계되었다.

Result: 두 개의 실제 데이터셋을 사용해 GenHAI를 판별(discriminative) 및 다른 생성 모델들과 비교 평가했으며, 논문은 GenHAI의 효능을 입증했다고 보고한다.

Conclusion: GenHAI는 병원 관리자가 MRSA 감염 위험을 완화하는 데 유용한 예측·인과·반사실 분석을 제공할 수 있는 실용적 모델이다.

Abstract: The US Centers for Disease Control and Prevention (CDC), in 2019, designated
Methicillin-resistant Staphylococcus aureus (MRSA) as a serious antimicrobial
resistance threat. The risk of acquiring MRSA and suffering life-threatening
consequences due to it remains especially high for hospitalized patients due to
a unique combination of factors, including: co-morbid conditions, immuno
suppression, antibiotic use, and risk of contact with contaminated hospital
workers and equipment. In this paper, we present a novel generative
probabilistic model, GenHAI, for modeling sequences of MRSA test results
outcomes for patients during a single hospitalization. This model can be used
to answer many important questions from the perspectives of hospital
administrators for mitigating the risk of MRSA infections. Our model is based
on the probabilistic programming paradigm, and can be used to approximately
answer a variety of predictive, causal, and counterfactual questions. We
demonstrate the efficacy of our model by comparing it against discriminative
and generative machine learning models using two real-world datasets.

</details>


### [205] [A Generalized Learning Framework for Self-Supervised Contrastive Learning](https://arxiv.org/abs/2508.13596)
*Lingyu Si,Jingyao Wang,Wenwen Qiang*

Main category: cs.LG

TL;DR: 이 논문은 기존의 self-supervised contrastive learning(SSCL) 기법들을 하나의 일반화된 학습 프레임워크(GLF)로 통합하고, feature 공간에서의 intra-class compactness와 inter-class separability를 보장하는 제약부를 설계하기 위한 이론·실험적 통찰을 바탕으로 Adaptive Distribution Calibration(ADC)라는 간단한 플러그인 방법을 제안한다. ADC는 원본 입력 공간에서의 샘플 간 거리를 보존하도록 특징 공간에서 거리를 조정해 성능을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: SSCL 방법들이 다양한 형태로 발전했지만, 이들을 통일적으로 이해하고 더 나은 제약(regularization) 설계를 위한 원칙이 필요하다. 또한 라벨이 없는 상황에서 intra-class compactness와 inter-class separability를 보장하는 제약을 효과적으로 설계하는 방법이 요구된다.

Method: 기존 SSCL들을 'aligning part'와 'constraining part'로 분해해 일반화 프레임워크(GLF)를 제안한다. 세 가지 기존 방법(BYOL, Barlow Twins, SwAV)을 GLF로 재해석한 뒤, intra-class compactness와 inter-class separability의 개념을 도입해 제약부 설계 원칙을 도출한다. 그 기반 위에서 원본 입력 공간의 샘플 간 동적 관계를 반복적으로 포착하여 특징 공간의 분포를 보정하는 Adaptive Distribution Calibration(ADC)을 제안한다. ADC는 'anchor'와 다른 샘플 간의 거리가 원본 공간과 특징 공간에서 일치하도록 조정한다.

Result: 이론적 분석과 실험 결과에서 ADC가 제안된 GLF의 제약부 설계 원칙을 만족시키며, 기존 SSCL 기법들보다 우수한 성능을 보임을 입증한다.

Conclusion: SSCL 기법들을 통합한 GLF는 제약부 설계의 두 핵심 속성(내부 응집성, 클래스 간 분리성)을 제시하며, ADC는 라벨이 없는 상황에서 이러한 속성들을 유도해 실험적으로 그리고 이론적으로 성능 향상을 달성한다.

Abstract: Self-supervised contrastive learning (SSCL) has recently demonstrated
superiority in multiple downstream tasks. In this paper, we generalize the
standard SSCL methods to a Generalized Learning Framework (GLF) consisting of
two parts: the aligning part and the constraining part. We analyze three
existing SSCL methods: BYOL, Barlow Twins, and SwAV, and show that they can be
unified under GLF with different choices of the constraining part. We further
propose empirical and theoretical analyses providing two insights into
designing the constraining part of GLF: intra-class compactness and inter-class
separability, which measure how well the feature space preserves the class
information of the inputs. However, since SSCL can not use labels, it is
challenging to design a constraining part that satisfies these properties. To
address this issue, we consider inducing intra-class compactness and
inter-class separability by iteratively capturing the dynamic relationship
between anchor and other samples and propose a plug-and-play method called
Adaptive Distribution Calibration (ADC) to ensure that samples that are near or
far from the anchor point in the original input space are closer or further
away from the anchor point in the feature space. Both the theoretical analysis
and the empirical evaluation demonstrate the superiority of ADC.

</details>


### [206] [Approximate Bayesian Inference via Bitstring Representations](https://arxiv.org/abs/2508.13598)
*Aleksanteri Sladek,Martin Trapp,Arno Solin*

Main category: cs.LG

TL;DR: 


<details>
  <summary>Details</summary>
Motivation: 

Method: 

Result: 

Conclusion: 

Abstract: The machine learning community has recently put effort into quantized or
low-precision arithmetics to scale large models. This paper proposes performing
probabilistic inference in the quantized, discrete parameter space created by
these representations, effectively enabling us to learn a continuous
distribution using discrete parameters. We consider both 2D densities and
quantized neural networks, where we introduce a tractable learning approach
using probabilistic circuits. This method offers a scalable solution to manage
complex distributions and provides clear insights into model behavior. We
validate our approach with various models, demonstrating inference efficiency
without sacrificing accuracy. This work advances scalable, interpretable
machine learning by utilizing discrete approximations for probabilistic
computations.

</details>


### [207] [Bounding Causal Effects and Counterfactuals](https://arxiv.org/abs/2508.13607)
*Tobias Maringgele*

Main category: cs.LG

TL;DR: 이 논문은 인과추론에서 강한 가정 대신 부분식별(partial identification)을 사용해 인과효과의 경계(bounds)를 구하는 방법들을 체계적으로 비교·통합하고, 실무자를 위한 선택 지침과 오픈소스 도구를 제공한다.


<details>
  <summary>Details</summary>
Motivation: 현실에서 '무측정 혼란 없음' 등 강한 가정은 잘 성립하지 않아 부분식별이 유리하지만, 기존 방법들이 분산되어 있고 실무적 가이드가 부족해 적용이 제한적이다.

Method: 기호적(symbolic), 최적화 기반, 정보이론적 방법들을 공통 평가 프레임워크로 구현·확장·통합하고, 특히 엔트로피 기반 방법을 확장해 PNS 같은 반사실적(counterfactual) 질의에 적용 가능하게 함. 수천 개의 시뮬레이션(이산·연속 데이터)을 통해 경계의 타이트함, 계산 효율성, 가정 위반에 대한 강건성을 비교하고, 알고리즘 선택을 위한 결정 트리와 관측적 특징으로 최적 방법을 예측하는 ML 모델을 훈련시킴.

Result: 엔트로피 기반 방법의 PNS 적용 확장, 각 방법의 성능·트레이드오프에 대한 대규모 실험 결과, 알고리즘 선택을 위한 실무용 결정 트리 및 예측 모델, 그리고 모든 구현을 포함한 오픈소스 패키지(CausalBoundingEngine) 공개.

Conclusion: 다양한 부분식별 기법을 통합·비교하고 실무자를 위한 명확한 선택 지침과 도구를 제시함으로써 부분식별의 실제 적용을 촉진하려 한다.

Abstract: Causal inference often hinges on strong assumptions - such as no unmeasured
confounding or perfect compliance - that are rarely satisfied in practice.
Partial identification offers a principled alternative: instead of relying on
unverifiable assumptions to estimate causal effects precisely, it derives
bounds that reflect the uncertainty inherent in the data. Despite its
theoretical appeal, partial identification remains underutilized in applied
work, in part due to the fragmented nature of existing methods and the lack of
practical guidance. This thesis addresses these challenges by systematically
comparing a diverse set of bounding algorithms across multiple causal
scenarios. We implement, extend, and unify state-of-the-art methods - including
symbolic, optimization-based, and information-theoretic approaches - within a
common evaluation framework. In particular, we propose an extension of a
recently introduced entropy-bounded method, making it applicable to
counterfactual queries such as the Probability of Necessity and Sufficiency
(PNS). Our empirical study spans thousands of randomized simulations involving
both discrete and continuous data-generating processes. We assess each method
in terms of bound tightness, computational efficiency, and robustness to
assumption violations. To support practitioners, we distill our findings into a
practical decision tree for algorithm selection and train a machine learning
model to predict the best-performing method based on observable data
characteristics.
  All implementations are released as part of an open-source Python package,
CausalBoundingEngine, which enables users to apply and compare bounding methods
through a unified interface.

</details>


### [208] [Towards a Larger Model via One-Shot Federated Learning on Heterogeneous Client Models](https://arxiv.org/abs/2508.13625)
*Wenxuan Ye,Xueli An,Onur Ayan,Junfan Wang,Xueqiang Yan,Georg Carle*

Main category: cs.LG

TL;DR: FedOL은 클라이언트가 라벨 없는 공개 데이터에 대한 예측만 전송해 한 번의 통신으로 서버에 더 큰 모델을 구성하는 원샷 지식 증류 방식이다. 의사라벨을 반복 정제하고 맞춤형 증류 전략을 사용해 이질적 아키텍처와 통신·계산 부담 문제를 완화하며 시뮬레이션에서 기존 기법들을 능가한다.


<details>
  <summary>Details</summary>
Motivation: 모바일 네트워크 환경에서 서버는 더 큰 모델을 수용할 수 있으나 개인정보 때문에 원시 데이터 공유가 불가능하다. 기존 연합학습(FL)은 동일 아키텍처와 여러 통신 라운드를 요구해 클라이언트 자원·통신 부담과 이질성 문제를 야기한다.

Method: 클라이언트는 모델 파라미터 대신 라벨 없는 공개 데이터에 대한 예측(로그잇/확률값)을 전송한다. 서버는 지식 증류 기반으로 서버 모델을 학습하며, 편향된 클라이언트 예측을 보정하기 위해 의사라벨과 서버 모델을 반복적으로 정제하는 특수 목적 함수와 맞춤형 의사라벨 생성 및 증류 전략을 도입한다.

Result: 시뮬레이션에서 FedOL이 기존 베이스라인보다 성능 우위를 보였으며 통신량 감소와 클라이언트 계산 부담 경감 효과를 확인했다.

Conclusion: FedOL은 이질적 아키텍처를 허용하고 통신·계산 비용을 줄이면서 편향을 완화하는 실용적인 원샷 대안으로, 모바일 네트워크의 한계하에 비용효율적인 모델 통합 방법을 제시한다.

Abstract: Large models, renowned for superior performance, outperform smaller ones even
without billion-parameter scales. While mobile network servers have ample
computational resources to support larger models than client devices, privacy
constraints prevent clients from directly sharing their raw data. Federated
Learning (FL) enables decentralized clients to collaboratively train a shared
model by exchanging model parameters instead of transmitting raw data. Yet, it
requires a uniform model architecture and multiple communication rounds, which
neglect resource heterogeneity, impose heavy computational demands on clients,
and increase communication overhead. To address these challenges, we propose
FedOL, to construct a larger and more comprehensive server model in one-shot
settings (i.e., in a single communication round). Instead of model parameter
sharing, FedOL employs knowledge distillation, where clients only exchange
model prediction outputs on an unlabeled public dataset. This reduces
communication overhead by transmitting compact predictions instead of full
model weights and enables model customization by allowing heterogeneous model
architectures. A key challenge in this setting is that client predictions may
be biased due to skewed local data distributions, and the lack of ground-truth
labels in the public dataset further complicates reliable learning. To mitigate
these issues, FedOL introduces a specialized objective function that
iteratively refines pseudo-labels and the server model, improving learning
reliability. To complement this, FedOL incorporates a tailored pseudo-label
generation and knowledge distillation strategy that effectively integrates
diverse knowledge. Simulation results show that FedOL significantly outperforms
existing baselines, offering a cost-effective solution for mobile networks
where clients possess valuable private data but limited computational
resources.

</details>


### [209] [X-MoE: Enabling Scalable Training for Emerging Mixture-of-Experts Architectures on HPC Platforms](https://arxiv.org/abs/2508.13337)
*Yueming Yuan,Ahan Gupta,Jianping Li,Sajal Dash,Feiyi Wang,Minjia Zhang*

Main category: cs.LG

TL;DR: X-MoE는 패딩-프리 크로스-플랫폼 커널, 중복 우회 디스패치, 시퀀스-셰어드 MoE 블록을 결합한 새로운 MoE 훈련 시스템으로, AMD MI250X 기반 Frontier에서 DeepSeek 스타일 MoE를 1024 GPU에 걸쳐 545억(545B) 파라미터까지 10배 확장하며 높은 처리량을 유지한다.


<details>
  <summary>Details</summary>
Motivation: 최근 발전한 전문가 특화 Mixture-of-Experts(MoE) 아키텍처(예: DeepSeek-MoE)는 세밀한 전문가 분할과 큰 top-k 라우팅으로 모델 품질을 향상시키지만, 활성화 메모리 오버헤드와 비용이 큰 all-to-all 통신 때문에 확장성이 제한된다. 또한 기존 MoE 훈련 시스템은 주로 NVIDIA GPU에 최적화되어 비-NVIDIA 플랫폼에서 성능이 저하되어 잠재 역량을 활용하지 못한다.

Method: X-MoE는 (1) 패딩이 없는 효율적인 MoE 학습을 위한 크로스-플랫폼 커널, (2) 중복을 우회하는(dispatch redundancy-bypassing) 디스패치 메커니즘, (3) 시퀀스 셰어드 MoE 블록을 포함한 하이브리드 병렬성 설계를 도입한다. 이들 기법으로 활성화 메모리와 통신 비용을 줄이고 비-NVIDIA 하드웨어에서 높은 확장성을 달성한다.

Result: Frontier(AMD MI250X)에서 X-MoE는 DeepSeek 스타일 MoE를 최대 545B 파라미터로 1024 GPU에 걸쳐 학습 가능하게 했으며, 동일 하드웨어 예산에서 기존 방법보다 10배 큰 모델을 훈련할 수 있었다. 높은 학습 처리량을 유지하며 소스코드는 공개되어 있다.

Conclusion: X-MoE는 비-NVIDIA 플랫폼에서도 대규모 MoE 아키텍처의 확장성을 크게 개선하여, 하드웨어 다양성에서의 성능 저하 문제를 완화하고 더 큰 모델 훈련을 가능하게 한다.

Abstract: Emerging expert-specialized Mixture-of-Experts (MoE) architectures, such as
DeepSeek-MoE, deliver strong model quality through fine-grained expert
segmentation and large top-k routing. However, their scalability is limited by
substantial activation memory overhead and costly all-to-all communication.
Furthermore, current MoE training systems - primarily optimized for NVIDIA GPUs
- perform suboptimally on non-NVIDIA platforms, leaving significant
computational potential untapped. In this work, we present X-MoE, a novel MoE
training system designed to deliver scalable training performance for
next-generation MoE architectures. X-MoE achieves this via several novel
techniques, including efficient padding-free MoE training with cross-platform
kernels, redundancy-bypassing dispatch, and hybrid parallelism with
sequence-sharded MoE blocks. Our evaluation on the Frontier supercomputer,
powered by AMD MI250X GPUs, shows that X-MoE scales DeepSeek-style MoEs up to
545 billion parameters across 1024 GPUs - 10x larger than the largest trainable
model with existing methods under the same hardware budget, while maintaining
high training throughput. The source code of X-MoE is available at
https://github.com/Supercomputing-System-AI-Lab/X-MoE.

</details>


### [210] [Text2Weight: Bridging Natural Language and Neural Network Weight Spaces](https://arxiv.org/abs/2508.13633)
*Bowen Tian,Wenshuo Chen,Zexi Li,Songning Lai,Jiemin Wu,Yutao Yue*

Main category: cs.LG

TL;DR: T2W는 자연어 설명을 조건으로 신경망 가중치를 생성하는 확산-트랜스포머 프레임워크로, 파라미터를 계층적 블록으로 정규화하고 CLIP 텍스트 임베딩을 prior attention으로 통합하며 가중치 공간 증강을 포함한 적대적 학습으로 일반화 성능을 향상시킨다. Cifar100, Caltech256, TinyImageNet 실험에서 미지의 태스크에 대해 최적화 기반 초기화보다 우수한 성능을 보이고 가중치 보강, 텍스트 기반 모델 융합 등 새로운 응용을 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: 신경망 가중치 생성은 가능성을 보이나, 보편화(특히 미지의 태스크로의 일반화)와 실제 응용 가능성 탐색에서 한계가 있다. 텍스트로 기술된 태스크 정보를 가중치 공간으로 연결해 자동 가중치 합성의 실용성을 높이고자 한다.

Method: (1) 네트워크 파라미터를 균일한 블록들로 계층적 전처리/표현, (2) CLIP 텍스트 임베딩을 prior attention 메커니즘으로 통합해 텍스트-가중치 조건화, (3) 확산(diffusion) 기반 생성기(트랜스포머 아키텍처)로 가중치 샘플링, (4) 가중치 공간 증강을 적용한 적대적(adversarial) 학습으로 일반화 강화, (5) 텍스트-가중치 쌍 데이터셋으로 학습.

Result: Cifar100, Caltech256, TinyImageNet에서 T2W가 미지의 태스크에 대해 유의미한 성능을 보였고, 최적화 기반 초기화보다 상회했다. 또한 가중치 향상(weight enhancement)과 텍스트 유도 모델 융합(text-guided fusion) 같은 새로운 응용 사례를 시연했다. 코드와 텍스트-가중치 데이터셋을 공개함.

Conclusion: 텍스트 의미와 가중치 공간 역학을 연결하는 실용적 접근을 제시하여, 신경망 파라미터 합성의 가능성을 확장하고 관련 데이터·코드를 공개함으로써 후속 연구 및 응용 개발을 촉진한다.

Abstract: How far are we really from automatically generating neural networks? While
neural network weight generation shows promise, current approaches struggle
with generalization to unseen tasks and practical application exploration. To
address this, we propose T2W, a diffusion transformer framework that generates
task-specific weights conditioned on natural language descriptions. T2W
hierarchically processes network parameters into uniform blocks, integrates
text embeddings from CLIP via a prior attention mechanism, and employs
adversarial training with weight-space augmentation to enhance generalization.
Experiments on Cifar100, Caltech256, and TinyImageNet demonstrate T2W's ability
to produce high-quality weights for unseen tasks, outperforming
optimization-based initialization and enabling novel applications such as
weight enhancement and text-guided model fusion. Our work bridges textual
semantics with weight-space dynamics, supported by an open-source dataset of
text-weight pairs, advancing the practicality of generative models in neural
network parameter synthesis. Our code is available on Github.

</details>


### [211] [Explainable Learning Rate Regimes for Stochastic Optimization](https://arxiv.org/abs/2508.13639)
*Zhuang Yang*

Main category: cs.LG

TL;DR: 스텝별 확률적 기울기의 변화량(노름)에 따라 학습률을 자동으로 증가·감소시키는 설명 가능한 러닝레이트(LR) 스케줄을 제안한다. 추가 하이퍼파라미터 없이 확률적 2차 정보(stochastic second-order)를 이용해 구현되며 SGD, SGDM, SIGNSGD 등에서 효율성과 견고성, 확장성을 보였다.


<details>
  <summary>Details</summary>
Motivation: SGD 성능이 LR 스케줄에 민감하지만 기존 스케줄은 복잡하거나 추가 하이퍼파라미터 튜닝이 필요해 계산·시간·전력 비용이 크다.

Method: 확률적 2차 알고리즘을 활용하여 stochastic gradient의 내재적 변동성에 따라 LR을 자동으로 조정하는 규칙을 제시한다. 구체적으로 gradient의 노름이 작아지면 LR을 키우고, 노름이 커지면 LR을 줄이는 방식으로 동작하며 별도의 파라미터 튜닝을 요구하지 않는다.

Result: 제안한 LR 규칙이 SGD, SGDM, SIGNSGD 등 고전적 확률적 알고리즘들에서 효율성·견고성·확장성을 보이는 실험 결과를 제시한다.

Conclusion: 추론 가능한, 파라미터 튜닝이 불필요한 자동 LR 조정 절차를 제공하여 휴리스틱한 규칙과 유사한 패턴을 보이며 실무적 유용성을 확보한다.

Abstract: Modern machine learning is trained by stochastic gradient descent (SGD),
whose performance critically depends on how the learning rate (LR) is adjusted
and decreased over time. Yet existing LR regimes may be intricate, or need to
tune one or more additional hyper-parameters manually whose bottlenecks include
huge computational expenditure, time and power in practice. This work, in a
natural and direct manner, clarifies how LR should be updated automatically
only according to the intrinsic variation of stochastic gradients. An
explainable LR regime by leveraging stochastic second-order algorithms is
developed, behaving a similar pattern to heuristic algorithms but implemented
simply without any parameter tuning requirement, where it is of an automatic
procedure that LR should increase (decrease) as the norm of stochastic
gradients decreases (increases). The resulting LR regime shows its efficiency,
robustness, and scalability in different classical stochastic algorithms,
containing SGD, SGDM, and SIGNSGD, on machine learning tasks.

</details>


### [212] [Contextual Attention-Based Multimodal Fusion of LLM and CNN for Sentiment Analysis](https://arxiv.org/abs/2508.13196)
*Meriem Zerkouk,Miloud Mihoubi,Belkacem Chikhaoui*

Main category: cs.LG

TL;DR: 자연재해 상황의 소셜미디어 다중모달 감정분석을 위해 이미지(CNN)와 텍스트(LLM/GPT)를 통합하고, 문맥적 어텐션 기반 융합을 도입하여 CrisisMMD 데이터셋에서 유의미한 성능 향상을 보인 모델을 제안한다. Accuracy +2.43%, F1 +5.18%.


<details>
  <summary>Details</summary>
Motivation: 재난 상황에서 대중의 감정(정보성 여부)을 신속·정확하게 파악하는 것은 위기 관리에 중요하다. 기존 방법은 텍스트와 이미지를 개별 처리해 모달 간 상호작용을 충분히 반영하지 못한다.

Method: 이미지 특징은 CNN으로 추출하고 텍스트는 GPT 기반 LLM과 프롬프트 엔지니어링으로 감정 관련 특징을 추출한다. 추출된 특징들은 문맥적 어텐션층을 통해 교차-모달 상호작용을 학습하며, 융합된 특징을 심층 신경망으로 분류에 이용한다.

Result: CrisisMMD 데이터셋에서 기존 베이스라인 대비 정확도 2.43%p, F1-score 5.18%p 향상. 다양한 재난 유형에서 유의미/비유의미 분류 성능 개선을 확인.

Conclusion: LLM 기반 텍스트 처리와 CNN 이미지 처리의 융합, 특히 문맥적 어텐션을 통한 상호작용 모델링이 멀티모달 재난 감정분석 성능을 개선하며, 실시간 재난 대응에 활용 가능한 잠재력을 보인다.

Abstract: This paper introduces a novel approach for multimodal sentiment analysis on
social media, particularly in the context of natural disasters, where
understanding public sentiment is crucial for effective crisis management.
Unlike conventional methods that process text and image modalities separately,
our approach seamlessly integrates Convolutional Neural Network (CNN) based
image analysis with Large Language Model (LLM) based text processing,
leveraging Generative Pre-trained Transformer (GPT) and prompt engineering to
extract sentiment relevant features from the CrisisMMD dataset. To effectively
model intermodal relationships, we introduce a contextual attention mechanism
within the fusion process. Leveraging contextual-attention layers, this
mechanism effectively captures intermodality interactions, enhancing the
model's comprehension of complex relationships between textual and visual data.
The deep neural network architecture of our model learns from these fused
features, leading to improved accuracy compared to existing baselines.
Experimental results demonstrate significant advancements in classifying social
media data into informative and noninformative categories across various
natural disasters. Our model achieves a notable 2.43% increase in accuracy and
5.18% in F1-score, highlighting its efficacy in processing complex multimodal
data. Beyond quantitative metrics, our approach provides deeper insight into
the sentiments expressed during crises. The practical implications extend to
real time disaster management, where enhanced sentiment analysis can optimize
the accuracy of emergency interventions. By bridging the gap between multimodal
analysis, LLM powered text understanding, and disaster response, our work
presents a promising direction for Artificial Intelligence (AI) driven crisis
management solutions. Keywords:

</details>


### [213] [Personalized Subgraph Federated Learning with Sheaf Collaboration](https://arxiv.org/abs/2508.13642)
*Wenfei Liang,Yanan Zhao,Rui She,Yiming Li,Wee Peng Tay*

Main category: cs.LG

TL;DR: FedSheafHN은 각 클라이언트의 로컬 서브그래프를 그래프 수준 임베딩으로 서버의 협력 그래프에 배치하고, 그 협력 그래프 위에서 sheaf diffusion을 통해 클라이언트 표현을 풍부하게 한 뒤 서버 최적화 하이퍼네트워크로 개인화된 모델을 생성하는 개인화된 서브그래프 연합학습 프레임워크이다. 기존 방법들보다 성능, 수렴 속도, 신규 클라이언트 일반화에서 우수하다.


<details>
  <summary>Details</summary>
Motivation: 서브그래프 FL에서 클라이언트 간 데이터 분포(로컬 서브그래프)의 이질성으로 인해 클라이언트별 성능 편차가 크다. 각 클라이언트에 맞춘 개인화 모델을 효율적으로 생성하고 클라이언트 표현을 개선할 필요가 있다.

Method: 각 클라이언트의 그래프 수준 임베딩을 서버에 보내 서버가 협력 그래프를 구성한다. 협력 그래프 상에서 sheaf diffusion 기법을 적용해 클라이언트 디스크립터(표현)를 확장·강화하고, 서버에서 학습된 하이퍼네트워크가 그 디스크립터를 입력으로 받아 클라이언트별 맞춤 모델을 생성한다.

Result: 여러 그래프 데이터셋에서 기존 개인화 서브그래프 FL 방법들을 능가하는 성능을 보였고, 모델 수렴이 빠르며 새로운(보지 않은) 클라이언트에 대한 일반화 능력도 좋았다.

Conclusion: sheaf 기반의 협업 표현 강화와 하이퍼네트워크 기반 개인화 모델 생성의 결합은 서브그래프 FL의 이질성 문제를 효과적으로 완화하며 실용적인 개인화 성능 향상을 제공한다.

Abstract: Graph-structured data is prevalent in many applications. In subgraph
federated learning (FL), this data is distributed across clients, each with a
local subgraph. Personalized subgraph FL aims to develop a customized model for
each client to handle diverse data distributions. However, performance
variation across clients remains a key issue due to the heterogeneity of local
subgraphs. To overcome the challenge, we propose FedSheafHN, a novel framework
built on a sheaf collaboration mechanism to unify enhanced client descriptors
with efficient personalized model generation. Specifically, FedSheafHN embeds
each client's local subgraph into a server-constructed collaboration graph by
leveraging graph-level embeddings and employing sheaf diffusion within the
collaboration graph to enrich client representations. Subsequently, FedSheafHN
generates customized client models via a server-optimized hypernetwork.
Empirical evaluations demonstrate that FedSheafHN outperforms existing
personalized subgraph FL methods on various graph datasets. Additionally, it
exhibits fast model convergence and effectively generalizes to new clients.

</details>


### [214] [GRAFT: Gradient-Aware Fast MaxVol Technique for Dynamic Data Sampling](https://arxiv.org/abs/2508.13653)
*Ashish Jha,Anh huy Phan,Razan Dibo,Valentin Leplat*

Main category: cs.LG

TL;DR: 


<details>
  <summary>Details</summary>
Motivation: 

Method: 

Result: 

Conclusion: 

Abstract: Training modern neural networks on large datasets is computationally and
environmentally costly. We introduce GRAFT, a scalable in-training subset
selection method that (i) extracts a low-rank feature representation for each
batch, (ii) applies a Fast MaxVol sampler to select a small, diverse subset
that spans the batch's dominant subspace, and (iii) dynamically adjusts the
subset size using a gradient-approximation criterion. By operating in low-rank
subspaces and training on carefully chosen examples instead of full batches,
GRAFT preserves the training trajectory while reducing wall-clock time, energy
consumption, and $\mathrm{CO}_2$ emissions. Across multiple benchmarks, GRAFT
matches or exceeds recent selection baselines in both accuracy and efficiency,
providing a favorable trade-off between accuracy, efficiency, and emissions.

</details>


### [215] [Deep Graph Neural Point Process For Learning Temporal Interactive Networks](https://arxiv.org/abs/2508.13219)
*Su Chen,Xiaohua Qi,Xixun Lin,Yanmin Shang,Xiaolin Xu,Yangxi Li*

Main category: cs.LG

TL;DR: DGNPP는 네트워크 토폴로지를 반영해 정적 표현을 생성하는 Node Aggregation Layer와 시점에 따라 임베딩을 갱신하는 Self Attentive Layer를 결합해 시공간 상호작용 이벤트와 발생시간을 예측하는 모델이다. 정적+동적 임베딩을 강도함수에 통합하고 최대우도추정을 통해 학습하며, 세 데이터셋에서 이벤트 및 시간 예측에서 기존 모델들보다 우수한 성능과 효율성을 보였다.


<details>
  <summary>Details</summary>
Motivation: 기존 TIN(temporal interaction networks) 연구들은 다중 시퀀스 예측 문제로 간주해 네트워크 토폴로지(정적 구조)의 영향을 무시했다. 그러나 사용자-아이템 간의 정적 네트워크 구조는 상호작용 패턴과 이벤트 발생 확률에 중요한 영향을 미칠 수 있어 이를 반영하는 모델이 필요하다.

Method: DGNPP는 두 모듈로 구성된다: (1) Node Aggregation Layer: 그래프 신경망을 통해 사용자와 아이템의 정적(토폴로지 기반) 표현을 생성한다. (2) Self Attentive Layer: 시간에 따라 임베딩을 동적으로 업데이트하는 자기어텐션 기반 모듈. 정적 및 동적 임베딩을 이벤트 강도(intensity) 함수에 결합하고, 최대우도추정을 통해 모델을 학습하여 다음 이벤트의 종류(대상)와 발생시각을 예측한다.

Result: 세 개 공개 데이터셋에서 실험한 결과, DGNPP는 이벤트 예측과 시간 예측에서 베이스라인 모델들보다 유의미하게 우수한 성능을 보였고 계산 효율성도 높았다. 또한 기존 접근법의 한계를 효과적으로 완화했다.

Conclusion: 정적 그래프 구조와 동적 시간적 패턴을 결합한 DGNPP는 TIN의 예측 정확도와 효율성을 개선하며, 토폴로지 정보를 반영하는 것이 시간적 상호작용 모델링에 유용함을 입증한다.

Abstract: Learning temporal interaction networks(TIN) is previously regarded as a
coarse-grained multi-sequence prediction problem, ignoring the network topology
structure influence. This paper addresses this limitation and a Deep Graph
Neural Point Process(DGNPP) model for TIN is proposed. DGNPP consists of two
key modules: the Node Aggregation Layer and the Self Attentive Layer. The Node
Aggregation Layer captures topological structures to generate static
representation for users and items, while the Self Attentive Layer dynamically
updates embeddings over time. By incorporating both dynamic and static
embeddings into the event intensity function and optimizing the model via
maximum likelihood estimation, DGNPP predicts events and occurrence time
effectively. Experimental evaluations on three public datasets demonstrate that
DGNPP achieves superior performance in event prediction and time prediction
tasks with high efficiency, significantly outperforming baseline models and
effectively mitigating the limitations of prior approaches.

</details>


### [216] [Input Time Scaling](https://arxiv.org/abs/2508.13654)
*Rapheal Huang,Weilong Guo*

Main category: cs.LG

TL;DR: 새로운 'Input Time Scaling' 패러다임 제안 — 쿼리(입력) 단계에 자원 투입해 학습·추론 시 입력을 정제. 훈련-테스트 공동설계가 필수이며, 낮은 품질 데이터나 무관 정보가 오히려 성능을 높일 수 있다는 놀라운 발견. 소량의 예시로도 높은 추론 능력 유도 가능. Qwen2.5-32B 기반 실험에서 AIME24/25에서 32B급 SOTA 성능 달성.


<details>
  <summary>Details</summary>
Motivation: 기존의 데이터·학습 스케일링(data & training scaling)과 추론 시 확장(inference time scaling)을 보완하기 위해, 쿼리(입력) 단계에 자원을 집중하는 새로운 스케일링 축을 제안하려는 것.

Method: LLM의 메타지식을 활용해 학습·테스트 시 입력을 다양한 전략으로 정제(Input Time Scaling). 훈련과 테스트 양쪽 모두에서 동일한 쿼리 전략을 적용(훈련-테스트 공동설계). 다양한 데이터 품질 및 크기(무작위 예시, 무관 정보 추가 등)를 실험하고 Qwen2.5-32B-Instruct 등으로 AIME24/AIME25에서 평가.

Result: 훈련·테스트 양쪽에 전략을 적용하지 않으면 성능이 크게 저하되는 '훈련-테스트 공동설계' 현상 발견. 무관 정보 추가, 최소 필터링된 데이터에서 무작위 예시 선택 등이 오히려 최고 성능을 보일 때가 있음(‘garbage in, garbage out’ 편향에 도전). 데이터 양 증가(15k vs 1k)가 항상 성능 향상을 보장하지 않음. 소수의 예시로도 높은 수준의 추론 능력 유도 가능(Less is More). Qwen2.5-32B-Instruct 기반으로 AIME24/25에서 pass@1 76.7% 달성, 다수결(3모델)로 AIME25 80% 달성. DeepSeek-R1-Distill-Qwen-32B 시작 시 AIME24 86.7% 등 더 높은 결과 보고.

Conclusion: Input Time Scaling은 기존 스케일링 패러다임을 보완하는 유망한 접근. 데이터 품질·크기와 관련된 일반적 가정들을 재검토해야 하며, 훈련-테스트 공동설계와 소량의 예시 활용이 중요한 시사점. 데이터·파이프라인·체크포인트 등을 오픈소스로 공개할 예정.

Abstract: Current Large Language Models (LLMs) are usually post-trained on large-scale
carefully curated datasets (data & training scaling) and doing reasoning in
test time (inference time scaling). In this work, we present a new scaling
paradigm, Input Time Scaling, to complement previous scaling methods by putting
resources on queries (input time). During training and testing, we combine
meta-knowledge from LLMs to refine inputs with different strategies. We also
find a new phenomenon, training-testing co-design there. We need to apply query
strategies during both training and testing. Only applying strategies on
training or testing would seriously degrade the performance. We are also
surprised to find that seemingly low data quality datasets can gain high
performance. Adding irrelevant information to the queries, randomly selecting
examples from a minimally filtered dataset, can even perform the best. These
findings contradict the widely held inductive bias, "garbage in, garbage out".
Curating datasets with seemingly high-quality data can even potentially limit
the performance ceiling. In addition, models trained on more data with similar
quality (15k VS 1k) perform worse, simple dataset size scaling should also be
carefully inspected. The good news is that our findings are compatible with the
Less is More phenomenon. A small set of examples is enough to evoke high-level
reasoning ability. With experiments on models trained on Qwen2.5-32B-Instruct,
we are able to reach SOTA performance among 32B models on AIME24(76.7%) and
AIME25(76.7%) pass@1. We can further achieve AIME24(76.7%) and AIME25(80%) with
a majority vote of three models. Starting from DeepSeek-R1-Distill-Qwen-32B,
the best result would be 86.7% on AIME24 and 76.7% on AIME25. To facilitate
reproducibility and further research, we are working on open-source our
datasets, data pipelines, evaluation results, and checkpoints.

</details>


### [217] [Input Time Scaling](https://arxiv.org/abs/2508.13654)
*Rapheal Huang,Weilong Guo*

Main category: cs.LG

TL;DR: 새로운 'Input Time Scaling' 패러다임 제안 — 쿼리(입력) 단계에 자원 투입해 학습·추론 시 입력을 정제. 훈련-테스트 공동설계가 필수이며, 낮은 품질 데이터나 무관 정보가 오히려 성능을 높일 수 있다는 놀라운 발견. 소량의 예시로도 높은 추론 능력 유도 가능. Qwen2.5-32B 기반 실험에서 AIME24/25에서 32B급 SOTA 성능 달성.


<details>
  <summary>Details</summary>
Motivation: 기존의 데이터·학습 스케일링(data & training scaling)과 추론 시 확장(inference time scaling)을 보완하기 위해, 쿼리(입력) 단계에 자원을 집중하는 새로운 스케일링 축을 제안하려는 것.

Method: LLM의 메타지식을 활용해 학습·테스트 시 입력을 다양한 전략으로 정제(Input Time Scaling). 훈련과 테스트 양쪽 모두에서 동일한 쿼리 전략을 적용(훈련-테스트 공동설계). 다양한 데이터 품질 및 크기(무작위 예시, 무관 정보 추가 등)를 실험하고 Qwen2.5-32B-Instruct 등으로 AIME24/AIME25에서 평가.

Result: 훈련·테스트 양쪽에 전략을 적용하지 않으면 성능이 크게 저하되는 '훈련-테스트 공동설계' 현상 발견. 무관 정보 추가, 최소 필터링된 데이터에서 무작위 예시 선택 등이 오히려 최고 성능을 보일 때가 있음(‘garbage in, garbage out’ 편향에 도전). 데이터 양 증가(15k vs 1k)가 항상 성능 향상을 보장하지 않음. 소수의 예시로도 높은 수준의 추론 능력 유도 가능(Less is More). Qwen2.5-32B-Instruct 기반으로 AIME24/25에서 pass@1 76.7% 달성, 다수결(3모델)로 AIME25 80% 달성. DeepSeek-R1-Distill-Qwen-32B 시작 시 AIME24 86.7% 등 더 높은 결과 보고.

Conclusion: Input Time Scaling은 기존 스케일링 패러다임을 보완하는 유망한 접근. 데이터 품질·크기와 관련된 일반적 가정들을 재검토해야 하며, 훈련-테스트 공동설계와 소량의 예시 활용이 중요한 시사점. 데이터·파이프라인·체크포인트 등을 오픈소스로 공개할 예정.

Abstract: Current Large Language Models (LLMs) are usually post-trained on large-scale
carefully curated datasets (data & training scaling) and doing reasoning in
test time (inference time scaling). In this work, we present a new scaling
paradigm, Input Time Scaling, to complement previous scaling methods by putting
resources on queries (input time). During training and testing, we combine
meta-knowledge from LLMs to refine inputs with different strategies. We also
find a new phenomenon, training-testing co-design there. We need to apply query
strategies during both training and testing. Only applying strategies on
training or testing would seriously degrade the performance. We are also
surprised to find that seemingly low data quality datasets can gain high
performance. Adding irrelevant information to the queries, randomly selecting
examples from a minimally filtered dataset, can even perform the best. These
findings contradict the widely held inductive bias, "garbage in, garbage out".
Curating datasets with seemingly high-quality data can even potentially limit
the performance ceiling. In addition, models trained on more data with similar
quality (15k VS 1k) perform worse, simple dataset size scaling should also be
carefully inspected. The good news is that our findings are compatible with the
Less is More phenomenon. A small set of examples is enough to evoke high-level
reasoning ability. With experiments on models trained on Qwen2.5-32B-Instruct,
we are able to reach SOTA performance among 32B models on AIME24(76.7%) and
AIME25(76.7%) pass@1. We can further achieve AIME24(76.7%) and AIME25(80%) with
a majority vote of three models. Starting from DeepSeek-R1-Distill-Qwen-32B,
the best result would be 86.7% on AIME24 and 76.7% on AIME25. To facilitate
reproducibility and further research, we are working on open-source our
datasets, data pipelines, evaluation results, and checkpoints.

</details>


### [218] [In-Context Decision Making for Optimizing Complex AutoML Pipelines](https://arxiv.org/abs/2508.13657)
*Amir Rezaei Balef,Katharina Eggensperger*

Main category: cs.LG

TL;DR: 현대 AutoML 파이프라인(미세조정, 앙상블 등)의 적응까지 포괄하도록 CASH를 확장한 논문. PS-PFN을 제안해 Posterior Sampling을 max k-armed bandit 문제로 확장하고, PFN을 사용해 최대 보상의 사후분포를 효율적으로 추정한다. 비용 가중 시나리오와 각 팔(arm)마다 다른 PFN 적용도 다룬다. 벤치마크에서 기존 밴딧 및 AutoML 전략보다 우수함을 보임.


<details>
  <summary>Details</summary>
Motivation: 전이학습 및 사전학습 모델의 발전으로 ML 워크플로우가 단순한 하이퍼파라미터 최적화를 넘어서 미세조정(fine-tuning), 앙상블, 기타 적응기법을 포함하게 되었고, 이로 인해 파이프라인의 이질성이 커져 기존 CASH 프레임워크만으로는 최적 모델 탐색에 한계가 있다.

Method: CASH를 확장해 모델 선택과 적응(adaptation)을 함께 다루는 새로운 방법 PS-PFN을 제안. Posterior Sampling(PS)을 max k-armed bandit 설정으로 확장하고, prior-data fitted networks(PFNs)를 활용해 인컨텍스트 러닝으로 최대 보상에 대한 사후분포를 빠르게 추정한다. 비용이 서로 다른 팔을 고려하는 방법과 각 팔별 보상 분포를 별도의 PFN으로 모델링하는 확장도 포함.

Result: 새로운 벤치마크 1개와 기존 표준 벤치마크 2개에서 실험을 수행하여 PS-PFN이 다른 밴딧 알고리즘 및 AutoML 전략보다 우수한 성능을 보였음을 보고. 코드와 데이터는 공개됨.

Conclusion: PS-PFN은 현대의 적응이 필요한 ML 파이프라인 탐색 문제에서 효율적이고 효과적인 접근법이며, 비용을 고려한 확장과 팔별 PFN 모델링을 통해 실용적 적용성이 높다.

Abstract: Combined Algorithm Selection and Hyperparameter Optimization (CASH) has been
fundamental to traditional AutoML systems. However, with the advancements of
pre-trained models, modern ML workflows go beyond hyperparameter optimization
and often require fine-tuning, ensembling, and other adaptation techniques.
While the core challenge of identifying the best-performing model for a
downstream task remains, the increasing heterogeneity of ML pipelines demands
novel AutoML approaches. This work extends the CASH framework to select and
adapt modern ML pipelines. We propose PS-PFN to efficiently explore and exploit
adapting ML pipelines by extending Posterior Sampling (PS) to the max k-armed
bandit problem setup. PS-PFN leverages prior-data fitted networks (PFNs) to
efficiently estimate the posterior distribution of the maximal value via
in-context learning. We show how to extend this method to consider varying
costs of pulling arms and to use different PFNs to model reward distributions
individually per arm. Experimental results on one novel and two existing
standard benchmark tasks demonstrate the superior performance of PS-PFN
compared to other bandit and AutoML strategies. We make our code and data
available at https://github.com/amirbalef/CASHPlus.

</details>


### [219] [MACTAS: Self-Attention-Based Module for Inter-Agent Communication in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2508.13661)
*Maciej Wojtala,Bogusz Stefańczyk,Dominik Bogucki,Łukasz Lepak,Jakub Strykowski,Paweł Wawrzyński*

Main category: cs.LG

TL;DR: 본 논문은 MARL 환경에서 에이전트 간의 통신을 위해 자기-어텐션 기반의 완전 미분 가능한 통신 모듈을 제안한다. 이 모듈은 행동-가치 함수 분해(action-value decomposition)와 자연스럽게 결합되며, 에이전트 수에 독립적인 고정된 수의 학습 가능한 파라미터를 가진다. SMAC 벤치마크에서 여러 맵에 대해 최첨단 성능을 보였다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 집단 과제를 인간 에이전트들이 수행할 때 통신이 필수적이다. 기존 MARL 통신 프로토콜은 종종 복잡하거나 미분 불가능하여 보상 기반 학습에 제약이 있다. 이를 해결하기 위해 단순하고 완전 미분 가능한 통신 메커니즘이 필요하다.

Method: 자기-어텐션(self-attention) 기반의 통신 모듈을 설계하여 에이전트 간 정보를 교환하도록 함. 이 모듈은 완전 미분 가능하며, 에이전트들이 보상에 따라 메시지를 생성하도록 학습된다. 또한, 어떤 행동-가치 분해 방법과도 통합 가능하고, 에이전트 수와 무관하게 고정된 수의 학습 가능한 파라미터를 갖는다.

Result: SMAC(StarCraft Multi-Agent Challenge) 벤치마크 실험에서 제안한 방법은 여러 맵에서 최첨단 성능을 달성함을 보여주었다.

Conclusion: 제안된 자기-어텐션 기반 통신 모듈은 학습 가능하고 효율적이며 확장성이 좋은 MARL 통신 메커니즘으로, 기존 행동-가치 분해 방법의 확장으로 활용될 수 있다.

Abstract: Communication is essential for the collective execution of complex tasks by
human agents, motivating interest in communication mechanisms for multi-agent
reinforcement learning (MARL). However, existing communication protocols in
MARL are often complex and non-differentiable. In this work, we introduce a
self-attention-based communication module that exchanges information between
the agents in MARL. Our proposed approach is fully differentiable, allowing
agents to learn to generate messages in a reward-driven manner. The module can
be seamlessly integrated with any action-value function decomposition method
and can be viewed as an extension of such decompositions. Notably, it includes
a fixed number of trainable parameters, independent of the number of agents.
Experimental results on the SMAC benchmark demonstrate the effectiveness of our
approach, which achieves state-of-the-art performance on several maps.

</details>


### [220] [Heavy-tailed Linear Bandits: Adversarial Robustness, Best-of-both-worlds, and Beyond](https://arxiv.org/abs/2508.13679)
*Canzhe Zhao,Shinji Ito,Shuai Li*

Main category: cs.LG

TL;DR: 본 논문은 중-꼬리(heavy-tailed) 잡음이 있는 밴딧 문제를 adversarial 환경까지 확장한 일반적인 프레임워크를 제안한다. FTRL에 보너스가 더해진 손실 추정치를 사용하고, HT-SPM이라는 데이터 의존 학습률과 분산 감소 선형 추정기를 도입해 MAB와 유한-팔 선형 밴딧에 대해 최초의 FTRL계열 BOBW(최악·확률적 두 환경에서 모두 좋은) 보장을 얻는다.


<details>
  <summary>Details</summary>
Motivation: 기존 연구는 주로 확률적(stochastic) 중-꼬리 밴딧에 집중되어 있으며, adversarial(적대적) 환경이나 선형 밴딧의 일반적 경우는 거의 다루어지지 않았다. 확률적·적대적 두 환경에서 모두 좋은(BOBW) 결과를 중-꼬리 잡음 하에서도 얻고자 함.

Method: 손실 추정치에 보너스 함수를 더한 형태로 FTRL(regularized follow-the-leader)을 수행하는 일반 프레임워크를 제안한다. 보너스 함수의 정교한 설계로 truncated non-negativity 가정 없이도 MAB에서 FTRL 기반 BOBW 알고리즘을 구성한다. 선형 경우에는 분산-감소(variance-reduced) 선형 손실 추정기와 함께 HT-SPM(heavy-tailed noise aware stability-penalty matching)이라는 데이터-의존 학습률을 도입한다.

Result: MAB: truncated non-negativity 가정 없이 FTRL계열 최초의 BOBW 알고리즘을 얻었고, adversarial 환경에서 Õ(T^{1/ε}) 최악-케이스 후회와 stochastic 환경에서 Õ(log T) gap-종속 후회를 달성. 선형(유한 팔) 밴딧: adversarial 중-꼬리 설정에서 최초의 알고리즘으로 Õ(d^{1/2} T^{1/ε}) 후회를 달성하여, 확률적 환경에서의 최상-기존 경계와 일치. 또한 HT-SPM을 통해 일반 중-꼬리 밴딧 문제에 대해 조건 만족 시 BOBW 보장을 제공.

Conclusion: 제안한 보너스-보정 FTRL 프레임워크와 HT-SPM 학습률은 중-꼬리 잡음이 있는 밴딧 문제를 adversarial·stochastic 두 환경에서 모두 다룰 수 있게 하며, 특히 선형 밴딧에서 최초의 BOBW 보장을 제공한다. 일부 조건(예: HT-SPM의 가정) 하에서 일반화 가능하다.

Abstract: Heavy-tailed bandits have been extensively studied since the seminal work of
\citet{Bubeck2012BanditsWH}. In particular, heavy-tailed linear bandits,
enabling efficient learning with both a large number of arms and heavy-tailed
noises, have recently attracted significant attention
\citep{ShaoYKL18,XueWWZ20,ZhongHYW21,Wang2025heavy,tajdini2025improved}.
However, prior studies focus almost exclusively on stochastic regimes, with few
exceptions limited to the special case of heavy-tailed multi-armed bandits
(MABs) \citep{Huang0H22,ChengZ024,Chen2024uniINF}.
  In this work, we propose a general framework for adversarial heavy-tailed
bandit problems, which performs follow-the-regularized-leader (FTRL) over the
loss estimates shifted by a bonus function. Via a delicate setup of the bonus
function, we devise the first FTRL-type best-of-both-worlds (BOBW) algorithm
for heavy-tailed MABs, which does not require the truncated non-negativity
assumption and achieves an $\widetilde{O}(T^{\frac{1}{\varepsilon}})$
worst-case regret in the adversarial regime as well as an $\widetilde{O}(\log
T)$ gap-dependent regret in the stochastic regime. We then extend our framework
to the linear case, proposing the first algorithm for adversarial heavy-tailed
linear bandits with finite arm sets. This algorithm achieves an
$\widetilde{O}(d^{\frac{1}{2}}T^{\frac{1}{\varepsilon}})$ regret, matching the
best-known worst-case regret bound in stochastic regimes. Moreover, we propose
a general data-dependent learning rate, termed \textit{heavy-tailed noise aware
stability-penalty matching} (HT-SPM). We prove that HT-SPM guarantees BOBW
regret bounds for general heavy-tailed bandit problems once certain conditions
are satisfied. By using HT-SPM and, in particular, a variance-reduced linear
loss estimator, we obtain the first BOBW result for heavy-tailed linear
bandits.

</details>


### [221] [Hierarchical Conformal Classification](https://arxiv.org/abs/2508.13288)
*Floris den Hengst,Inès Blin,Majid Mohammadi,Syed Ihtesham Hussain Shah,Taraneh Younesian*

Main category: cs.LG

TL;DR: 계층 구조를 반영한 컨포멀 예측(HCC)을 도입해 클래스 계층을 포함한 예측 집합을 생성하고, 보장된 커버리지를 유지하면서 조합폭발 문제를 후보 집합 축소로 실용적으로 해결한다.


<details>
  <summary>Details</summary>
Motivation: 표준 컨포멀 예측은 클래스들을 평탄하게 다루어 라벨 간 의미적·계층적 관계를 무시한다. 실제 응용에서는 계층 정보가 예측의 해석성·실용성을 크게 높일 수 있으나 기존 CP는 이를 반영하지 못한다.

Method: 클래스 계층을 예측 집합의 구조와 의미에 포함시키는 ‘계층적 컨포멀 분류(HCC)’를 제안하고, 이를 제약 최적화 문제로 정식화함. 해 공간이 조합적으로 커지는 문제를 해결하기 위해 보장성과 최적성을 유지하는 소수의 잘 구조화된 후보 해 집합으로 충분함을 이론적으로 보임.

Result: 오디오·이미지·텍스트의 세 가지 벤치마크에서 HCC가 이점(해석성·유용성 등)을 보였고, 사용자 연구에서 주석자들이 평탄한 예측 집합보다 계층적 예측 집합을 유의미하게 선호함.

Conclusion: HCC는 유한표본 커버리지 보장을 유지하면서 클래스 계층을 활용해 더 풍부하고 실용적인 예측 집합을 제공하며, 계산 문제는 후보군 축소로 실용적으로 해결할 수 있다.

Abstract: Conformal prediction (CP) is a powerful framework for quantifying uncertainty
in machine learning models, offering reliable predictions with finite-sample
coverage guarantees. When applied to classification, CP produces a prediction
set of possible labels that is guaranteed to contain the true label with high
probability, regardless of the underlying classifier. However, standard CP
treats classes as flat and unstructured, ignoring domain knowledge such as
semantic relationships or hierarchical structure among class labels. This paper
presents hierarchical conformal classification (HCC), an extension of CP that
incorporates class hierarchies into both the structure and semantics of
prediction sets. We formulate HCC as a constrained optimization problem whose
solutions yield prediction sets composed of nodes at different levels of the
hierarchy, while maintaining coverage guarantees. To address the combinatorial
nature of the problem, we formally show that a much smaller, well-structured
subset of candidate solutions suffices to ensure coverage while upholding
optimality. An empirical evaluation on three new benchmarks consisting of
audio, image, and text data highlights the advantages of our approach, and a
user study shows that annotators significantly prefer hierarchical over flat
prediction sets.

</details>


### [222] [Minimizing the Weighted Number of Tardy Jobs: Data-Driven Heuristic for Single-Machine Scheduling](https://arxiv.org/abs/2508.13703)
*Nikolai Antonov,Prěmysl Šůcha,Mikoláš Janota,Jan Hůla*

Main category: cs.LG

TL;DR: 


<details>
  <summary>Details</summary>
Motivation: 

Method: 

Result: 

Conclusion: 

Abstract: Existing research on single-machine scheduling is largely focused on exact
algorithms, which perform well on typical instances but can significantly
deteriorate on certain regions of the problem space. In contrast, data-driven
approaches provide strong and scalable performance when tailored to the
structure of specific datasets. Leveraging this idea, we focus on a
single-machine scheduling problem where each job is defined by its weight,
duration, due date, and deadline, aiming to minimize the total weight of tardy
jobs. We introduce a novel data-driven scheduling heuristic that combines
machine learning with problem-specific characteristics, ensuring feasible
solutions, which is a common challenge for ML-based algorithms. Experimental
results demonstrate that our approach significantly outperforms the
state-of-the-art in terms of optimality gap, number of optimal solutions, and
adaptability across varied data scenarios, highlighting its flexibility for
practical applications. In addition, we conduct a systematic exploration of ML
models, addressing a common gap in similar studies by offering a detailed model
selection process and providing insights into why the chosen model is the best
fit.

</details>


### [223] [Trans-XFed: An Explainable Federated Learning for Supply Chain Credit Assessment](https://arxiv.org/abs/2508.13715)
*Jie Shi,Arno P. J. M. Siebes,Siamak Mehrkanoon*

Main category: cs.LG

TL;DR: 연합학습(Federated Learning)과 설명가능한 AI 기법을 결합한 Trans-XFed를 제안하여 프라이버시 유지 하에 공급망 신용평가를 수행한다. 성능 기반 클라이언트 선택(PBCS), FedProx+동형암호, 트랜스포머 인코더, 통합 그래디언트 설명기법을 결합해 정확도, 투명성, 프라이버시를 개선했다고 보고한다.


<details>
  <summary>Details</summary>
Motivation: 공급망 신용평가는 개인정보·기업 간 정보 사일로, 클래스 불균형, Non-IID 데이터, 모델 해석 가능성 등의 문제를 가지며, 중앙집중식 학습은 프라이버시 이슈와 데이터 이동의 제약을 초래한다. 이를 해결할 수 있는 분산·해석 가능한 프레임워크가 필요하다.

Method: FedProx를 기반으로 동형암호를 적용해 서버-클라이언트 통신의 프라이버시를 보호하고, 트랜스포머 인코더 블록을 통합해 학습된 특징에 대한 인사이트를 제공한다. 성능 기반 클라이언트 선택(PBCS)은 로컬 F1 점수가 높은 클라이언트를 우선 선택해 클래스 불균형과 Non-IID 문제에 대한 수렴 속도를 개선한다. 최종적으로 통합 그래디언트(Integrated Gradients)를 사용해 모델 의사결정의 설명을 제공한다.

Result: 실제 공급망 데이터셋에서 여러 베이스라인 대비 더 우수한 신용평가 정확도를 달성했다고 보고한다. PBCS로 수렴이 빨라지고, 트랜스포머+통합 그래디언트로 해석 가능성을 확보했으며, 동형암호로 프라이버시를 어느 정도 보장했다고 주장한다.

Conclusion: Trans-XFed는 프라이버시 보호, 비동질·불균형 데이터 환경에서의 학습 효율성, 및 모델 설명성을 동시에 개선하는 통합 프레임워크로 제안되며, 실험에서 유의미한 성능 향상을 보였다.

Abstract: This paper proposes a Trans-XFed architecture that combines federated
learning with explainable AI techniques for supply chain credit assessment. The
proposed model aims to address several key challenges, including privacy,
information silos, class imbalance, non-identically and independently
distributed (Non-IID) data, and model interpretability in supply chain credit
assessment. We introduce a performance-based client selection strategy (PBCS)
to tackle class imbalance and Non-IID problems. This strategy achieves faster
convergence by selecting clients with higher local F1 scores. The FedProx
architecture, enhanced with homomorphic encryption, is used as the core model,
and further incorporates a transformer encoder. The transformer encoder block
provides insights into the learned features. Additionally, we employ the
integrated gradient explainable AI technique to offer insights into
decision-making. We demonstrate the effectiveness of Trans-XFed through
experimental evaluations on real-world supply chain datasets. The obtained
results show its ability to deliver accurate credit assessments compared to
several baselines, while maintaining transparency and privacy.

</details>


### [224] [A Dual-Attention Graph Network for fMRI Data Classification](https://arxiv.org/abs/2508.13328)
*Amirali Arbab,Zeinab Davarani,Mehran Safayani*

Main category: cs.LG

TL;DR: 주어진 논문은 transformer 기반의 attention으로 시계열 구간마다 동적으로 뇌의 기능적 연결망을 생성하고, 이를 GCN과 transformer로 처리하여 ASD 진단 성능을 개선한다는 내용이다.


<details>
  <summary>Details</summary>
Motivation: 기존 fMRI 분류는 정적 연결성 기반이거나 시공간적 관계를 포괄적으로 캡처하지 못하기 때문에, 시간에 따라 변하는 뇌 영역 간 상호작용을 모델링하고 중요한 시점과 영역에 주목하는 방법이 필요하다.

Method: transformer 기반 attention으로 각 시간 간격에서 동적 그래프를 추론하고, 시간가변 그래프를 GCN과 transformer로 처리하여 국소적 상호작용과 전역 시간의존성을 함께 캡처한다. 또한 GCN-transformer의 계층적 융합으로 시공간 특징을 통합한다.

Result: ABIDE 데이터셋 부분집합에서 모델은 정확도 63.2%, AUC 60.0을 달성하여 정적 그래프 기반 방법(GCN 51.8%)을 능가했다.

Conclusion: attention 기반 동적 그래프 생성과 GCN-transformer 계층적 시공간 융합을 통해 fMRI 분류에서 동적 연결성 및 시공간 맥락의 공동 모델링이 효과적임을 검증한다.

Abstract: Understanding the complex neural activity dynamics is crucial for the
development of the field of neuroscience. Although current functional MRI
classification approaches tend to be based on static functional connectivity or
cannot capture spatio-temporal relationships comprehensively, we present a new
framework that leverages dynamic graph creation and spatiotemporal attention
mechanisms for Autism Spectrum Disorder(ASD) diagnosis. The approach used in
this research dynamically infers functional brain connectivity in each time
interval using transformer-based attention mechanisms, enabling the model to
selectively focus on crucial brain regions and time segments. By constructing
time-varying graphs that are then processed with Graph Convolutional Networks
(GCNs) and transformers, our method successfully captures both localized
interactions and global temporal dependencies. Evaluated on the subset of ABIDE
dataset, our model achieves 63.2 accuracy and 60.0 AUC, outperforming static
graph-based approaches (e.g., GCN:51.8). This validates the efficacy of joint
modeling of dynamic connectivity and spatio-temporal context for fMRI
classification. The core novelty arises from (1) attention-driven dynamic graph
creation that learns temporal brain region interactions and (2) hierarchical
spatio-temporal feature fusion through GCNtransformer fusion.

</details>


### [225] [DREAMS: Preserving both Local and Global Structure in Dimensionality Reduction](https://arxiv.org/abs/2508.13747)
*Noël Kury,Dmitry Kobak,Sebastian Damrich*

Main category: cs.LG

TL;DR: DREAMS는 t-SNE의 지역 구조 보존과 PCA의 전역 구조 보존을 결합한 차원 축소 방법으로, 단순 정규화 항을 통해 두 임베딩 사이의 스펙트럼을 생성하여 다중 스케일 구조를 효율적으로 보존한다. 여러 실제 데이터셋(단일 세포 전사체 및 집단 유전학 포함)에서 기존 방법들보다 다중 스케일 구조 보존에서 우수함을 정성적·정량적으로 입증한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 차원 축소 기법들은 지역 구조(t-SNE, UMAP) 또는 전역 구조(MDS, PCA) 중 하나만 잘 보존하도록 설계되어 있어, 동시에 두 측면을 잘 표현하는 방법이 부족하다. 따라서 두 구조를 모두 유지하면서 시각화할 수 있는 방법이 필요하다.

Method: DREAMS는 t-SNE 목적함수에 PCA와의 차이를 줄이는 단순한 정규화 항을 추가하여, t-SNE(지역 보존)와 PCA(전역 보존) 사이의 스펙트럼을 생성한다. 이 정규화 항을 통해 지역적 구조를 유지하면서 전역적 배치를 조절할 수 있으며, 파라미터를 통해 두 구조 보존의 균형을 조절할 수 있다.

Result: 7개의 실제 데이터셋(단일 세포 전사체 5개, 집단 유전학 1개 등)에서 DREAMS는 기존 기법들보다 다양한 스케일에서의 구조 보존에서 우수한 성능을 보였다. 정성적 시각화와 정량적 지표에서 모두 향상된 결과를 보고한다.

Conclusion: 간단한 정규화 기반 접근만으로도 t-SNE와 PCA의 장점을 결합하여 다중 스케일 구조를 잘 보존하는 임베딩을 얻을 수 있다. DREAMS는 지역 및 전역 구조를 균형 있게 보존해야 하는 실험 데이터 분석에 유용하다.

Abstract: Dimensionality reduction techniques are widely used for visualizing
high-dimensional data in two dimensions. Existing methods are typically
designed to preserve either local (e.g. $t$-SNE, UMAP) or global (e.g. MDS,
PCA) structure of the data, but none of the established methods can represent
both aspects well. In this paper, we present DREAMS (Dimensionality Reduction
Enhanced Across Multiple Scales), a method that combines the local structure
preservation of $t$-SNE with the global structure preservation of PCA via a
simple regularization term. Our approach generates a spectrum of embeddings
between the locally well-structured $t$-SNE embedding and the globally
well-structured PCA embedding, efficiently balancing both local and global
structure preservation. We benchmark DREAMS across seven real-world datasets,
including five from single-cell transcriptomics and one from population
genetics, showcasing qualitatively and quantitatively its superior ability to
preserve structure across multiple scales compared to previous approaches.

</details>


### [226] [Counterfactual Probabilistic Diffusion with Expert Models](https://arxiv.org/abs/2508.13355)
*Wenhao Mu,Zhi Cao,Mehmed Uludag,Alexander Rodríguez*

Main category: cs.LG

TL;DR: Introduce ODE-Diff: a time-series diffusion model that incorporates high-level signals from imperfect mechanistic (ODE) expert models as structured priors to improve counterfactual distribution prediction under data scarcity.


<details>
  <summary>Details</summary>
Motivation: Counterfactual distribution prediction in complex dynamical systems is crucial for domains like public health and medicine, but existing methods (point estimates or purely data-driven models) fail when data are scarce and cannot leverage imperfect but informative mechanistic knowledge.

Method: Propose ODE-Diff, a diffusion-based generative framework for time series that extracts high-level signals from expert ODE/mechanistic models and uses them as structured priors/guidance during diffusion-based generation, thus blending mechanistic and data-driven approaches for causal inference.

Result: Evaluated on semi-synthetic COVID-19 simulations, synthetic pharmacological dynamics, and real-world case studies; ODE-Diff consistently outperforms strong baselines in both point prediction and distributional accuracy.

Conclusion: Guiding diffusion-based time-series generative models with structured priors from imperfect mechanistic models yields more reliable, interpretable causal counterfactual predictions, particularly under limited-data settings.

Abstract: Predicting counterfactual distributions in complex dynamical systems is
essential for scientific modeling and decision-making in domains such as public
health and medicine. However, existing methods often rely on point estimates or
purely data-driven models, which tend to falter under data scarcity. We propose
a time series diffusion-based framework that incorporates guidance from
imperfect expert models by extracting high-level signals to serve as structured
priors for generative modeling. Our method, ODE-Diff, bridges mechanistic and
data-driven approaches, enabling more reliable and interpretable causal
inference. We evaluate ODE-Diff across semi-synthetic COVID-19 simulations,
synthetic pharmacological dynamics, and real-world case studies, demonstrating
that it consistently outperforms strong baselines in both point prediction and
distributional accuracy.

</details>


### [227] [Order Optimal Regret Bounds for Sharpe Ratio Optimization in the Bandit Setting](https://arxiv.org/abs/2508.13749)
*Mohammad Taha Shah,Sabrina Khurshid,Gourab Ghatak*

Main category: cs.LG

TL;DR: This paper studies maximizing the Sharpe ratio in stochastic multi-armed bandits with Gaussian rewards and unknown parameters, proposing a Thompson Sampling variant (SRTS) with a novel regret decomposition; it proves logarithmic, order-optimal regret bounds and demonstrates superior empirical performance.


<details>
  <summary>Details</summary>
Motivation: Sharpe ratio optimization differs from cumulative-reward objectives by requiring a tradeoff between mean and variance (returns vs. risk), so algorithms must explore both mean and variance to learn risk-adjusted performance of arms.

Method: Introduce SRTS, a Thompson Sampling-based algorithm tailored for Gaussian rewards with unknown mean and variance; develop a new SR-specific regret decomposition that links information acquisition about reward distribution to learning efficiency; derive upper bound on regret for SRTS and matching lower bound.

Result: Theoretical: SRTS achieves logarithmic regret with distribution-dependent constants reflecting difficulty of distinguishing arms by Sharpe ratio; lower bound matches upper bound (order-optimal). Empirical: simulations show SRTS significantly outperforms existing algorithms.

Conclusion: Thompson Sampling can be adapted to Sharpe ratio maximization, yielding provably optimal algorithms (SRTS) that balance return-risk tradeoffs effectively and learn efficiently in Gaussian bandit settings.

Abstract: In this paper, we investigate the problem of sequential decision-making for
Sharpe ratio (SR) maximization in a stochastic bandit setting. We focus on the
Thompson Sampling (TS) algorithm, a Bayesian approach celebrated for its
empirical performance and exploration efficiency, under the assumption of
Gaussian rewards with unknown parameters. Unlike conventional bandit objectives
focusing on maximizing cumulative reward, Sharpe ratio optimization instead
introduces an inherent tradeoff between achieving high returns and controlling
risk, demanding careful exploration of both mean and variance. Our theoretical
contributions include a novel regret decomposition specifically designed for
the Sharpe ratio, highlighting the role of information acquisition about the
reward distribution in driving learning efficiency. Then, we establish
fundamental performance limits for the proposed algorithm \texttt{SRTS} in
terms of an upper bound on regret. We also derive the matching lower bound and
show the order-optimality. Our results show that Thompson Sampling achieves
logarithmic regret over time, with distribution-dependent factors capturing the
difficulty of distinguishing arms based on risk-adjusted performance. Empirical
simulations show that our algorithm significantly outperforms existing
algorithms.

</details>


### [228] [Depth-Breadth Synergy in RLVR: Unlocking LLM Reasoning Gains with Adaptive Exploration](https://arxiv.org/abs/2508.13755)
*Zhicheng Yang,Zhijiang Guo,Yinya Huang,Yongxin Wang,Dongchun Xie,Yiwei Wang,Xiaodan Liang,Jing Tang*

Main category: cs.LG

TL;DR: 이 논문은 RLVR(Verifiable Reward)에서 ‘깊이’(가장 어려운 문제 해결 능력)와 ‘폭’(한 번에 소비되는 인스턴스 수)이라는 두 축을 제시하고, GRPO의 누적-어드밴티지가 중간 난이도 샘플에 편향되는 문제를 지적한다. 이를 해결하기 위해 난이도 적응형 다단계 롤아웃(DARS)을 도입해 어려운 문제의 긍정적 롤아웃 수를 늘리고, 대규모 배치(full-batch) 학습으로 폭을 확장해 Pass@K 및 Pass@1 성능을 동시에 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 기존 RLVR 기법(특히 GRPO)은 논리적 추론 능력을 끌어내는 데 유망하지만, 모델이 더 어렵고 드문 문제를 충분히 탐색하지 못하는 ‘깊이’ 문제와, 한 번에 소비하는 데이터 수(‘폭’)를 고려한 최적화가 부족해 성능 향상의 한계가 존재한다는 점을 밝힘.

Method: 1) GRPO의 누적-어드밴티지가 중간 정확도 샘플에 과도한 가중치를 주는 편향을 분석. 2) DARS: 난이도 적응형 다단계 롤아웃을 도입해 어려운 문제에 대해 재표본화·재롤아웃을 통해 긍정적(정답) 롤아웃 비율을 증가시킴. 3) 폭 확장: 배치 크기를 대폭 늘리고 PPO의 미니배치 반복을 제거해 멀티 에폭 풀-배치 업데이트를 수행. 4) DARS-B: DARS에 대규모 배치(폭) 기법을 결합.

Result: 단순히 롤아웃 수를 늘리는 것은 수렴을 빠르게 할 뿐 Pass@K를 악화시킬 수 있으나, DARS는 추가 추론 비용 없이 Pass@K를 지속적으로 개선. 대규모 폭 학습은 Pass@1을 크게 향상시키며 토큰 수준 엔트로피를 유지해 탐색 지속성과 그래디언트 노이즈 저감을 보임. DARS-B는 Pass@K와 Pass@1을 동시에 개선.

Conclusion: 깊이(난이도 적응적 탐색)와 폭(대규모 배치 학습)은 서로 독립적이면서 상호보완적인 차원으로, 두 축을 모두 확장·조정해야 RLVR의 추론 능력을 최대한 끌어낼 수 있다.

Abstract: Reinforcement Learning with Verifiable Reward (RLVR) has emerged as a
powerful paradigm for unlocking reasoning capabilities in large language
models, yet its full potential is hindered by two under-explored dimensions:
Depth-the hardest problem a model can sample; Breadth-the number of instances
consumed in a single iteration. We dissect the popular GRPO algorithm and
reveal a systematic bias: the cumulative-advantage disproportionately weights
samples with medium accuracy, while down-weighting the low-accuracy instances
that are crucial for pushing reasoning boundaries. To rectify the depth
neglect, we introduce Difficulty Adaptive Rollout Sampling (DARS), which
re-weights hard problems through targeted multi-stage rollouts, thereby
increasing the number of positive rollouts for hard problems. Empirically,
naively enlarging rollout size only accelerates convergence and even hurts
Pass@K. Our DARS, in contrast, delivers consistent Pass@K gains without extra
inference cost at convergence. Just as we adaptively expanded the depth of
exploration, we now ask whether aggressively scaling the breadth of training
data can further amplify reasoning gains. To this end, we intensely scale batch
size and replace PPO's mini-batch iterations with full-batch updates over
multiple epochs. Increasing breadth significantly enhances Pass@1 performance.
Large-breadth training sustains high token-level entropy, indicating continued
exploration and reduced gradient noise. We further present DARS-B, which
augments DARS with large breadth, and demonstrate simultaneous gains in Pass@K
and Pass@1. The results confirm that breadth and adaptive exploration across
depth operate as orthogonal dimensions in RLVR, which are key to unleashing the
reasoning power of RLVR.

</details>


### [229] [PENGUIN: Enhancing Transformer with Periodic-Nested Group Attention for Long-term Time Series Forecasting](https://arxiv.org/abs/2508.13773)
*Tian Sun,Yuqi Chen,Weiwei Sun*

Main category: cs.LG

TL;DR: 추상으로부터 PENGUIN 모델(TS 시계열 예측용으로 주기성·상대적 주의 편향·그룹화된 다중 주의 활용)을 요약


<details>
  <summary>Details</summary>
Motivation: 자기-어텐션의 역할을 재검토하고 시계열의 주기적 패턴과 상대적 주의 편향의 중요성을 강조하려는 목적

Method: 주기-중첩(relative) 주의 편향과 여러 공존 주기들을 처리하는 그룹화된 멀티-쿼리 어텐션 설계

Result: 다양한 벤치마크에서 MLP/트랜스포머 기반 모델들보다 일관되게 우수한 성능

Conclusion: 명시적 주기성 모델링과 상대적 편향을 통합한 단순하지만 효과적인 어텐션 설계가 LTSF에 유리함

Abstract: Long-term time series forecasting (LTSF) is a fundamental task with
wide-ranging applications. Although Transformer-based models have made
significant breakthroughs in forecasting, their effectiveness for time series
forecasting remains debatable. In this paper, we revisit the significance of
self-attention and propose a simple yet effective mechanism, Periodic-Nested
Group Attention, namely PENGUIN. Our approach highlights the importance of
explicitly modeling periodic patterns and incorporating relative attention bias
for effective time series modeling. To this end, we introduce a periodic-nested
relative attention bias that captures periodic structures directly. To handle
multiple coexisting periodicities (e.g., daily and weekly cycles), we design a
grouped attention mechanism, where each group targets a specific periodicity
using a multi-query attention mechanism. Extensive experiments across diverse
benchmarks demonstrate that PENGUIN consistently outperforms both MLP-based and
Transformer-based models.

</details>


### [230] [Communication-Efficient Federated Learning with Adaptive Number of Participants](https://arxiv.org/abs/2508.13803)
*Sergey Skorik,Vladislav Dorofeev,Gleb Molodtsov,Aram Avetisyan,Dmitry Bylinkin,Daniil Medyakov,Aleksandr Beznosikov*

Main category: cs.LG

TL;DR: 제안된 ISP(지능형 참여자 선별)는 각 라운드에 참여할 클라이언트 수를 동적으로 결정해 통신 효율을 높이는 방법이다. 다양한 설정에서 최대 30%의 통신 절감 효과를 보이며 모델 성능 저하 없이 동작한다.


<details>
  <summary>Details</summary>
Motivation: 대형 딥러닝 모델의 확장으로 성능은 향상되었지만 중앙집중식 학습의 한계(개인정보, 자원 등)로 인해 연합학습(FL)이 주목받음. 그러나 FL에서는 통신 비용이 주요 병목이며, 특히 이질적이고 동적인 클라이언트 참여 환경에서 라운드당 몇 명의 클라이언트를 선택할지가 충분히 연구되지 않음.

Method: ISP(Intelligent Selection of Participants)는 라운드별로 최적의 클라이언트 수를 적응적으로 결정하는 메커니즘을 제안한다. 해당 기법은 비전 트랜스포머, 실제 ECG 분류, 그라디언트 압축을 포함한 다양한 실험 설정에 적용되어 통신량과 성능의 균형을 평가함.

Result: 여러 실험에서 최종 모델 품질을 유지하면서 통신량을 최대 30%까지 절감하는 일관된 성능을 보임. 실제 ECG 분류 실험에서는 클라이언트 수 선택 자체가 연합학습의 별도 과제로 중요하다는 점을 강조함.

Conclusion: 클라이언트 수를 동적으로 조정하는 것은 통신 효율 개선에 실질적 효과가 있으며, ISP는 다양한 환경에서 적용 가능하고 성능 저하 없이 통신비용을 줄일 수 있음을 보였다.

Abstract: Rapid scaling of deep learning models has enabled performance gains across
domains, yet it introduced several challenges. Federated Learning (FL) has
emerged as a promising framework to address these concerns by enabling
decentralized training. Nevertheless, communication efficiency remains a key
bottleneck in FL, particularly under heterogeneous and dynamic client
participation. Existing methods, such as FedAvg and FedProx, or other
approaches, including client selection strategies, attempt to mitigate
communication costs. However, the problem of choosing the number of clients in
a training round remains extremely underexplored. We introduce Intelligent
Selection of Participants (ISP), an adaptive mechanism that dynamically
determines the optimal number of clients per round to enhance communication
efficiency without compromising model accuracy. We validate the effectiveness
of ISP across diverse setups, including vision transformers, real-world ECG
classification, and training with gradient compression. Our results show
consistent communication savings of up to 30\% without losing the final
quality. Applying ISP to different real-world ECG classification setups
highlighted the selection of the number of clients as a separate task of
federated learning.

</details>


### [231] [Semi-Supervised Anomaly Detection Pipeline for SOZ Localization Using Ictal-Related Chirp](https://arxiv.org/abs/2508.13406)
*Nooshin Bahador,Milad Lankarany*

Main category: cs.LG

TL;DR: 시간-주파수 기반 chirp 이벤트의 스펙트로템포럴 특징으로 LOF 기반 이상치 탐지를 수행하고, 전극 근접성과 반구 일치를 가중치로 반영한 공간 상관 지표로 임상 정의된 SOZ와의 일치도를 정량화한 연구. 가중치 기반 색인 매칭이 정확한 동시발생 매칭보다 SOZ 지역화에 더 우수했고, 수술 성공군에서 특히 높은 일치도를 보였음.


<details>
  <summary>Details</summary>
Motivation: 임상적으로 정의된 발작 시작 영역(SOZ)과 시간-주파수 분석으로 식별된 통계적 이상 채널 간의 공간적 일치성을 정량적으로 평가해, 비침습적/보완적 SOZ 지역화 방법을 제시하려는 목적.

Method: (1) 비지도 이상치 탐지: chirp의 onset freq, offset freq, duration 같은 스펙트로-템포럴 피처로 Local Outlier Factor(LOF)를 사용해 적응적 이웃수 선택으로 이상 채널을 식별(파라미터: N_neighbors=20, contamination=0.2). (2) 공간 상관 분석: 정확 동시발생 매칭 및 전극 근접성과 반구 일치를 반영한 가중 색인 유사도를 계산해 SOZ와의 공간적 대응성을 평가.

Result: LOF 기반 방법이 이상치를 효과적으로 탐지했으며, 채널 근접성으로 가중한 색인 매칭이 정확 매칭보다 SOZ 지역화 성능(precision, recall, F1)이 우수. 발작 완전 소실(seizure-free) 환자에서 색인 정밀도(mean)=0.903, 성공적 수술 결과 환자에서 mean=0.865, 실패 사례에서는 mean=0.460으로 그룹별 편차가 뚜렷함.

Conclusion: chirp 기반 이상치 탐지와 가중된 공간 지표의 결합은 특히 수술 성공 환자에서 SOZ 지역화를 보완할 수 있는 유용한 방법으로 제시됨.

Abstract: This study presents a quantitative framework for evaluating the spatial
concordance between clinically defined seizure onset zones (SOZs) and
statistically anomalous channels identified through time-frequency analysis of
chirp events. The proposed pipeline employs a two-step methodology: (1)
Unsupervised Outlier Detection, where Local Outlier Factor (LOF) analysis with
adaptive neighborhood selection identifies anomalous channels based on
spectro-temporal features of chirp (Onset frequency, offset frequency, and
temporal duration); and (2) Spatial Correlation Analysis, which computes both
exact co-occurrence metrics and weighted index similarity, incorporating
hemispheric congruence and electrode proximity. Key findings demonstrate that
the LOF-based approach (N neighbors=20, contamination=0.2) effectively detects
outliers, with index matching (weighted by channel proximity) outperforming
exact matching in SOZ localization. Performance metrics (precision, recall, F1)
were highest for seizure-free patients (Index Precision mean: 0.903) and those
with successful surgical outcomes (Index Precision mean: 0.865), whereas
failure cases exhibited lower concordance (Index Precision mean: 0.460). The
key takeaway is that chirp-based outlier detection, combined with weighted
spatial metrics, provides a complementary method for SOZ localization,
particularly in patients with successful surgical outcomes.

</details>


### [232] [Reinforcement Learning-based Adaptive Path Selection for Programmable Networks](https://arxiv.org/abs/2508.13806)
*José Eduardo Zerna Torres,Marios Avgeris,Chrysa Papagianni,Gergely Pongrácz,István Gódor,Paola Grosso*

Main category: cs.LG

TL;DR: Proof-of-concept distributed in-network reinforcement learning using Stochastic Learning Automata (SLA) plus In-Band Network Telemetry (INT) for adaptive path selection; implemented on P4-programmable BMv2 switches in Mininet and shown to converge and adapt to congestion at line rate.


<details>
  <summary>Details</summary>
Motivation: Provide local, low-latency, data-driven forwarding decisions in programmable networks that can dynamically adapt to congestion without centralized control by leveraging real-time telemetry.

Method: Integrate Stochastic Learning Automata running in-network with real-time telemetry data collected via INT; implement decision logic in P4 on BMv2 switches and test in a Mininet testbed.

Result: SLA-based mechanism converges to effective path selections, adapts to shifting network conditions, and operates at line rate in the Mininet/P4 BMv2 evaluation.

Conclusion: Demonstrates feasibility of distributed IN-RL for adaptive forwarding; promising proof-of-concept that requires further study for scaling, hardware deployment, and richer reward/observation models.

Abstract: This work presents a proof-of-concept implementation of a distributed,
in-network reinforcement learning (IN-RL) framework for adaptive path selection
in programmable networks. By combining Stochastic Learning Automata (SLA) with
real-time telemetry data collected via In-Band Network Telemetry (INT), the
proposed system enables local, data-driven forwarding decisions that adapt
dynamically to congestion conditions. The system is evaluated on a
Mininet-based testbed using P4-programmable BMv2 switches, demonstrating how
our SLA-based mechanism converges to effective path selections and adapts to
shifting network conditions at line rate.

</details>


### [233] [Assessing Trustworthiness of AI Training Dataset using Subjective Logic -- A Use Case on Bias](https://arxiv.org/abs/2508.13813)
*Koffi Ismael Ouattara,Ioannis Krontiris,Theo Dimitrakos,Frank Kargl*

Main category: cs.LG

TL;DR: 이 논문은 Subjective Logic을 기반으로 AI 학습 데이터셋의 신뢰성(특히 편향 같은 전역 속성)을 불확실성까지 고려해 평가하는 최초의 형식적 프레임워크를 제시한다. 증거가 불완전하거나 분산·상충할 때에도 작동하며, 트래픽 표지판 인식 데이터셋에서 클래스 불균형을 포착하고 중앙화 및 연합 학습 시나리오 모두에서 해석 가능하고 견고함을 보였다.


<details>
  <summary>Details</summary>
Motivation: AI 시스템이 학습 데이터에 점점 의존함에 따라, 데이터셋 수준에서 나타나는 편향·공정성 같은 전역 속성의 신뢰성을 평가하는 도구가 필요하다. 기존 연구는 개별 데이터 항목의 신뢰성을 Subjective Logic으로 평가했지만, 데이터셋 전체에서만 나타나는 속성을 평가하는 데는 적용되지 않았다.

Method: Subjective Logic을 기반으로 한 형식적 프레임워크를 도입하여 신뢰 명제(trust propositions)를 정의하고, 불완전·분산·상충 증거 상황에서 불확실성을 정량화한다. 편향(bias)을 신뢰성 속성의 인스턴스로 삼아 프레임워크를 적용하고, 중앙화 및 연합(federated) 환경에서의 증거 통합과 해석을 가능하게 했다.

Result: 트래픽 표지판 인식 데이터셋을 대상으로 한 실험에서 제안 방법은 클래스 불균형을 효과적으로 포착했으며, 중앙집중식과 연합학습 시나리오 모두에서 해석 가능하고 견고한 결과를 보였다.

Conclusion: 제안된 프레임워크는 데이터셋 수준의 전역 속성(예: 편향)에 대한 불확실성-감수 평가를 가능하게 하며, 분산·상충·불완전한 증거가 존재하는 현실적 상황에서 신뢰성 평가에 유용하다.

Abstract: As AI systems increasingly rely on training data, assessing dataset
trustworthiness has become critical, particularly for properties like fairness
or bias that emerge at the dataset level. Prior work has used Subjective Logic
to assess trustworthiness of individual data, but not to evaluate
trustworthiness properties that emerge only at the level of the dataset as a
whole. This paper introduces the first formal framework for assessing the
trustworthiness of AI training datasets, enabling uncertainty-aware evaluations
of global properties such as bias. Built on Subjective Logic, our approach
supports trust propositions and quantifies uncertainty in scenarios where
evidence is incomplete, distributed, and/or conflicting. We instantiate this
framework on the trustworthiness property of bias, and we experimentally
evaluate it based on a traffic sign recognition dataset. The results
demonstrate that our method captures class imbalance and remains interpretable
and robust in both centralized and federated contexts.

</details>


### [234] [Disentangled Deep Smoothed Bootstrap for Fair Imbalanced Regression](https://arxiv.org/abs/2508.13829)
*Samuel Stocksieker,Denys pommeret,Arthur Charpentier*

Main category: cs.LG

TL;DR: 이 논문은 불균형 회귀 문제를 다루기 위해 분리된(VAE-based) 잠재공간에서 Smoothed Bootstrap를 적용한 데이터 생성 기법을 제안한다. 


<details>
  <summary>Details</summary>
Motivation: 표준 알고리즘은 불균형 분포에서 성능 저하가 심한데, 특히 회귀 문제에 대한 해결책이 부족하다. 따라서 탭ular 데이터에서 불균형 회귀 성능을 향상시킬 방법이 필요하다.

Method: 분리된(Disentangled) 변분 오토인코더(VAE)를 사용하여 데이터의 잠재 표현을 학습하고, 잠재공간에서 Smoothed Bootstrap을 적용해 희소 영역의 데이터를 생성한다. 생성된 데이터로 학습을 보강해 모델 성능을 향상시킨다.

Result: 벤치마크 IR 데이터셋에서 경쟁 기법들과 수치적 비교를 통해 제안 방법의 효율성을 평가했으며, 성능 향상 결과를 보고한다.

Conclusion: 분리된 VAE와 잠재공간에서의 Smoothed Bootstrap 결합은 불균형 회귀 문제에서 유효하며, 탭ular 데이터에 적용 가능하다.

Abstract: Imbalanced distribution learning is a common and significant challenge in
predictive modeling, often reducing the performance of standard algorithms.
Although various approaches address this issue, most are tailored to
classification problems, with a limited focus on regression. This paper
introduces a novel method to improve learning on tabular data within the
Imbalanced Regression (IR) framework, which is a critical problem. We propose
using Variational Autoencoders (VAEs) to model and define a latent
representation of data distributions. However, VAEs can be inefficient with
imbalanced data like other standard approaches. To address this, we develop an
innovative data generation method that combines a disentangled VAE with a
Smoothed Bootstrap applied in the latent space. We evaluate the efficiency of
this method through numerical comparisons with competitors on benchmark
datasets for IR.

</details>


### [235] [One Shot vs. Iterative: Rethinking Pruning Strategies for Model Compression](https://arxiv.org/abs/2508.13836)
*Mikołaj Janusz,Tomasz Wojnar,Yawei Li,Luca Benini,Kamil Adamczewski*

Main category: cs.LG

TL;DR: 원샷(한번에) 가지치기와 반복(다회) 가지치기를 체계적으로 비교한 연구. 낮은 가지치기 비율에서는 원샷이, 높은 비율에서는 반복이 유리하며, 인내 기반(patience) 가지치기와 하이브리드 접근이 특정 상황에서 더 좋음.


<details>
  <summary>Details</summary>
Motivation: 가지치기는 모델 압축의 핵심이지만 원샷과 반복 방식 중 어느 쪽이 더 우수한지에 대한 체계적이고 포괄적인 비교가 부족함. 반복 방식이 널리 쓰이긴 하지만 그 가정은 충분히 검증되지 않았음.

Method: 원샷과 반복 가지치기에 대한 엄밀한 정의를 제시하고, 구조화(structured) 및 비구조화(unstructured) 설정에서 여러 가지치기 기준과 모달리티를 포함한 광범위한 벤치마크를 수행하여 성능을 비교함.

Result: 저자들은 실험적으로 각 방식의 장단점을 규명함. 낮은 가지치기 비율에서는 원샷 방식이 더 효과적이고, 높은 가지치기 비율에서는 반복 방식이 우수함. 또한 인내 기반 가지치기(patience-based)와 두 방식을 결합한 하이브리드 방법이 특정 시나리오에서 기존 방법을 능가함을 보임.

Conclusion: 가지치기 전략은 목표 희소성(sparsity) 수준에 따라 선택되어야 하며, 인내 기반 및 하이브리드 접근이 실무자에게 유용할 수 있음. 코드: https://github.com/janumiko/pruning-benchmark

Abstract: Pruning is a core technique for compressing neural networks to improve
computational efficiency. This process is typically approached in two ways:
one-shot pruning, which involves a single pass of training and pruning, and
iterative pruning, where pruning is performed over multiple cycles for
potentially finer network refinement. Although iterative pruning has
historically seen broader adoption, this preference is often assumed rather
than rigorously tested. Our study presents one of the first systematic and
comprehensive comparisons of these methods, providing rigorous definitions,
benchmarking both across structured and unstructured settings, and applying
different pruning criteria and modalities. We find that each method has
specific advantages: one-shot pruning proves more effective at lower pruning
ratios, while iterative pruning performs better at higher ratios. Building on
these findings, we advocate for patience-based pruning and introduce a hybrid
approach that can outperform traditional methods in certain scenarios,
providing valuable insights for practitioners selecting a pruning strategy
tailored to their goals and constraints. Source code is available at
https://github.com/janumiko/pruning-benchmark.

</details>


### [236] [EventTSF: Event-Aware Non-Stationary Time Series Forecasting](https://arxiv.org/abs/2508.13434)
*Yunfeng Ge,Ming Jin,Yiji Zhao,Hongyan Li,Bo Du,Chang Xu,Shirui Pan*

Main category: cs.LG

TL;DR: 이 논문은 텍스트 기반 이벤트를 통합해 비정상(non-stationary) 시계열 예측 성능을 높이는 EventTSF라는 자기회귀 생성 프레임워크를 제안한다. 오토리그레시브 확산(autoregressive diffusion)과 flow matching을 결합하고, 이벤트 의미 신호에 따라 timestep을 적응적으로 제어하며, 멀티해상도에서 시계열과 텍스트를 융합하는 U자형 확산 트랜스포머 denoiser를 사용한다. 다양한 데이터셋에서 기존 12개 기법을 능가하며 예측 정확도 10.7% 향상과 학습 효율 1.13배 개선을 보였다.


<details>
  <summary>Details</summary>
Motivation: 에너지·교통 등 분야에서 시계열의 비정상성이 외부 텍스트 이벤트와 밀접하게 연관되지만, 기존 연구는 단일 모달리티에 의존해 텍스트 기반 이벤트를 활용한 정밀한 예측이 부족하다. 텍스트 이벤트와 연속 시계열의 미세 동기화, 텍스트가 유발하는 시간적 불확실성, 텍스트 임베딩과 다중 해상도 시계열 패턴의 불일치 같은 근본적 난제가 존재한다.

Method: EventTSF: (1) 히스토리 시계열과 텍스트 이벤트를 통합해 다음 구간을 생성하는 자기회귀 생성 구조; (2) 각 스텝에서 세밀한 시계열-이벤트 상호작용을 포착하기 위해 autoregressive diffusion과 flow matching을 결합; (3) 이벤트 의미 신호에 따라 flow matching의 timestep을 적응적으로 제어해 이벤트로 인한 불확실성 처리; (4) 멀티해상도에서 시계열·텍스트를 효율적으로 융합하는 U자형(diffusion) 트랜스포머 기반 denoiser.

Result: 8개의 합성 및 실제 데이터셋 실험에서 12개 베이스라인 대비 전반적 우수성 입증. 평균적으로 예측 정확도 10.7% 향상, 학습 속도는 약 1.13배 빨라짐. 다양한 이벤트-인지 비정상 시나리오에서 성능 우위 확인.

Conclusion: EventTSF는 텍스트 이벤트를 정교하게 통합해 비정상 시계열 예측의 동기화·불확실성·멀티해상도 정렬 문제를 해결하며, 정확도와 학습 효율 모두에서 유의미한 개선을 달성한다.

Abstract: Time series forecasting plays a vital role in critical domains like energy
and transportation, where non-stationary dynamics are deeply intertwined with
events in other modalities such as texts. However, incorporating natural
language-based external events to improve non-stationary forecasting remains
largely unexplored, as most approaches still rely on a single modality,
resulting in limited contextual knowledge and model underperformance. Enabling
fine-grained multimodal interactions between temporal and textual data is
challenged by three fundamental issues: (1) the difficulty of fine-grained
synchronization between time-varying discrete textual events and continuous
time series; (2) the inherent temporal uncertainty introduced by textual
semantics; and (3) the misalignment between textual event embeddings and
multi-resolution temporal patterns. In this work, we address these challenges
by introducing event-aware non-stationary time series forecasting (EventTSF),
an autoregressive generation framework that integrates historical time series
with textual events to make subsequent forecasts. Specifically, EventTSF uses
autoregressive diffusion with flow matching at each step to capture nuanced
temporal-event interactions. To handle event-induced uncertainty, flow matching
timesteps are adaptively controlled according to event semantic signals. The
underlying denoiser employs a multimodal U-shaped diffusion transformer that
efficiently fuses temporal and textual modalities across different resolutions.
Extensive experiments on 8 synthetic and real-world datasets show that EventTSF
outperforms 12 baselines across diverse event-aware non-stationary time series
forecasting scenarios, achieving substantial improvements of 10.7% higher
forecasting accuracy and $1.13\times$ faster training efficiency.

</details>


### [237] [FedUP: Efficient Pruning-based Federated Unlearning for Model Poisoning Attacks](https://arxiv.org/abs/2508.13853)
*Nicolò Romandini,Cristian Borcea,Rebecca Montanari,Luca Foschini*

Main category: cs.LG

TL;DR: FedUP는 연합학습에서 악성 클라이언트의 영향을 선택적으로 제거하기 위한 경량 연합 언러닝 알고리즘이다. 마지막 학습 라운드의 클라이언트 가중치만을 사용해 공격과 무관한 가중치는 유지하면서, 악성 영향과 가장 크게 발산하는 고절대값 연결을 선택해 0으로 만들어 공격 효과를 차단한다. 실험에서 최대(클라이언트의 절반-1) 수준의 강력한 공격(레이블 플립·백도어) 하에서도 악성 데이터에 대한 정확도를 재학습 모델 수준으로 낮추면서 정상 성능은 보존했고, 속도·저장 측면에서 SOTA보다 우수했다.


<details>
  <summary>Details</summary>
Motivation: 연합학습은 모델 중독(모델 포이즈닝) 등의 공격에 취약하다. 연합 언러닝(FU)은 악성 기여자의 영향을 전체 재학습 없이 제거하는 해결책이지만, 일반적 FU는 클라이언트가 신뢰할 만하고 협조적이라는 가정을 전제로 한다. 악성 또는 공모하는 클라이언트가 존재하는 현실에서는 이들이 언러닝 과정에 협력하지 않을 수 있어 기존 FU 적용이 어려워진다.

Method: FedUP는 마지막 학습 라운드에서 수집한 클라이언트 가중치만으로 어떤 연결을 억제(프루닝)할지 결정한다. 핵심은 정상(benign)과 악성(malicious) 업데이트 간 차이를 계산해 그 차이가 크고 절대값이 큰 가중치들을 선택·제로화하여 악성 영향을 격리하는 것이다. 이렇게 하면 정상 정보는 최대한 보존하면서 공격 신호를 제거할 수 있다. 방법은 경량이며 추가적인 전체 재학습이나 대규모 저장을 요구하지 않는다.

Result: 강력한 위협 모델(클라이언트의 최대 50%-1이 악성, 집계 과정에 대한 완전한 지식 보유)에서 IID/Non-IID 데이터, 레이블 플립·백도어 공격을 포함한 다양한 실험을 수행했다. 모든 시나리오에서 FedUP는 악성 영향(악성 데이터에 대한 정확도)을 완전히 줄여 다시 학습한 모델과 동등한 수준으로 낮추었고 정상 데이터 성능은 유지했다. 또한 SOTA FU 방법들과 비교해 항상 더 빠르고 저장 공간을 절약했다.

Conclusion: FedUP는 마지막 라운드 가중치만으로도 악성 클라이언트의 영향을 효과적·효율적으로 제거할 수 있음을 보였다. 이는 공격자가 협력하지 않는 상황에서도 실용적인 연합 언러닝 대안이 된다. 다만 악성 기여자 검출(누가 악성인지 식별)이나 매우 겹치는(benign과 malicious 업데이트가 완전히 중첩되는) 경우의 한계는 남아 있을 수 있다.

Abstract: Federated Learning (FL) can be vulnerable to attacks, such as model
poisoning, where adversaries send malicious local weights to compromise the
global model. Federated Unlearning (FU) is emerging as a solution to address
such vulnerabilities by selectively removing the influence of detected
malicious contributors on the global model without complete retraining.
However, unlike typical FU scenarios where clients are trusted and cooperative,
applying FU with malicious and possibly colluding clients is challenging
because their collaboration in unlearning their data cannot be assumed. This
work presents FedUP, a lightweight FU algorithm designed to efficiently
mitigate malicious clients' influence by pruning specific connections within
the attacked model. Our approach achieves efficiency by relying only on
clients' weights from the last training round before unlearning to identify
which connections to inhibit. Isolating malicious influence is non-trivial due
to overlapping updates from benign and malicious clients. FedUP addresses this
by carefully selecting and zeroing the highest magnitude weights that diverge
the most between the latest updates from benign and malicious clients while
preserving benign information. FedUP is evaluated under a strong adversarial
threat model, where up to 50%-1 of the clients could be malicious and have full
knowledge of the aggregation process. We demonstrate the effectiveness,
robustness, and efficiency of our solution through experiments across IID and
Non-IID data, under label-flipping and backdoor attacks, and by comparing it
with state-of-the-art (SOTA) FU solutions. In all scenarios, FedUP reduces
malicious influence, lowering accuracy on malicious data to match that of a
model retrained from scratch while preserving performance on benign data. FedUP
achieves effective unlearning while consistently being faster and saving
storage compared to the SOTA.

</details>


### [238] [SVDformer: Direction-Aware Spectral Graph Embedding Learning via SVD and Transformer](https://arxiv.org/abs/2508.13435)
*Jiayu Fang,Zhiqi Shao,S T Boris Choy,Junbin Gao*

Main category: cs.LG

TL;DR: SVDformer는 SVD와 Transformer를 결합해 방향성을 보존하는 그래프 표현 학습을 제안한다. 싱귤러 값 임베딩을 self-attention으로 정제해 스펙트럼 성분을 강조/억제하고, 싱귤러 벡터를 방향 투영 기저로 사용해 Transformer로 입/출력 엣지 패턴의 다중 스케일 상호작용을 모델링한다. 노드 분류에서 기존 기법들보다 우수한 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 기존의 방향 그래프 GNN들은 등방성(동일한 방식으로 이웃을 집계)과 국소적 필터링 때문에 방향성 의미와 전역 구조 패턴을 동시에 포착하기 어려움.

Method: SVDformer는 SVD로 얻은 싱귤러 값/벡터를 사용한다. 싱귤러 값 임베딩을 멀티헤드 self-attention으로 정제해 중요한 스펙트럼 성분을 증강하고 고주파 잡음을 억제한다(학습 가능한 로우패스/하이패스 필터링). 싱귤러 벡터를 방향 투영 기저로, 싱귤러 값을 스케일링 인자라고 보고 Transformer의 어텐션으로 입/출력 엣지 패턴 간 다중 스케일 상호작용을 모델링하여 특성 전파 시 엣지 방향성을 명시적으로 보존.

Result: 여섯 개의 방향 그래프 벤치마크에서 SVDformer가 최첨단 GNN들과 방향성 기반 베이스라인보다 일관되게 우수한 노드 분류 성능을 보임.

Conclusion: SVD와 Transformer의 결합은 방향성 보존과 스펙트럼 기반 필터링을 가능하게 해, 방향 그래프 표현 학습의 새로운 패러다임을 제시한다.

Abstract: Directed graphs are widely used to model asymmetric relationships in
real-world systems. However, existing directed graph neural networks often
struggle to jointly capture directional semantics and global structural
patterns due to their isotropic aggregation mechanisms and localized filtering
mechanisms. To address this limitation, this paper proposes SVDformer, a novel
framework that synergizes SVD and Transformer architecture for direction-aware
graph representation learning. SVDformer first refines singular value
embeddings through multi-head self-attention, adaptively enhancing critical
spectral components while suppressing high-frequency noise. This enables
learnable low-pass/high-pass graph filtering without requiring spectral
kernels. Furthermore, by treating singular vectors as directional projection
bases and singular values as scaling factors, SVDformer uses the Transformer to
model multi-scale interactions between incoming/outgoing edge patterns through
attention weights, thereby explicitly preserving edge directionality during
feature propagation. Extensive experiments on six directed graph benchmarks
demonstrate that SVDformer consistently outperforms state-of-the-art GNNs and
direction-aware baselines on node classification tasks, establishing a new
paradigm for learning representations on directed graphs.

</details>


### [239] [A Comprehensive Re-Evaluation of Biometric Modality Properties in the Modern Era](https://arxiv.org/abs/2508.13874)
*Rouqaiah Al-Refai,Pankaja Priya Ramasamy,Ragini Ramesh,Patricia Arias-Cabarcos,Philipp Terhörst*

Main category: cs.LG

TL;DR: 이 논문은 최신 생체인식 기술 발전과 취약성을 반영하여 1998년 표 기반 평가체계를 대체하거나 보완할 목적으로, 24명의 전문가 설문을 통해 생체인식 모달리티(예: 얼굴, 지문 등)의 특성 평가를 재검토했다. 결과는 얼굴 인식의 신뢰도 향상과 지문의 취약성 증가 등 평가 변화와 전문가 합의 수준, 그리고 55개 데이터셋의 불확실성과의 정합성을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 기존의 1998년 표 기반 생체인식 모달리티 평가체계가 최신 기술 발전과 새로운 공격/취약성을 반영하지 못하므로, 최신 상황을 반영한 신뢰할 만한 평가 프레임워크가 필요하다.

Method: 24명의 생체인식 전문가를 대상으로 설문을 실시하여 다양한 모달리티별 속성(property)에 대한 평가를 수집하고, 전문가 간의 합의 수준(agreement)을 분석했다. 또한 55개 생체인식 데이터셋에서의 데이터 수준 불확실성과 전문가 평가를 비교했다.

Result: 전문가 평가는 모달리티별로 큰 변화를 보였다(예: 얼굴 인식 평점 상승, 지문 평점 하락). 전문가 간 합의도 분석 결과 평가의 신뢰성을 뒷받침했으며, 데이터셋 수준의 불확실성과 전문가 평가 간에는 대부분의 모달리티에서 강한 정렬(alignment)이 관찰되었다.

Conclusion: 전문가 설문을 통한 재평가로 기존 평가체계의 업데이트 필요성을 확인했고, 전문가 간 이견은 주요 연구 과제를 제시한다. 실험적 데이터(데이터셋 불확실성)와 전문가 인사이트를 통합하는 것이 중요하다.

Abstract: The rapid advancement of authentication systems and their increasing reliance
on biometrics for faster and more accurate user verification experience,
highlight the critical need for a reliable framework to evaluate the
suitability of biometric modalities for specific applications. Currently, the
most widely known evaluation framework is a comparative table from 1998, which
no longer adequately captures recent technological developments or emerging
vulnerabilities in biometric systems. To address these challenges, this work
revisits the evaluation of biometric modalities through an expert survey
involving 24 biometric specialists. The findings indicate substantial shifts in
property ratings across modalities. For example, face recognition, shows
improved ratings due to technological progress, while fingerprint, shows
decreased reliability because of emerging vulnerabilities and attacks. Further
analysis of expert agreement levels across rated properties highlighted the
consistency of the provided evaluations and ensured the reliability of the
ratings. Finally, expert assessments are compared with dataset-level
uncertainty across 55 biometric datasets, revealing strong alignment in most
modalities and underscoring the importance of integrating empirical evidence
with expert insight. Moreover, the identified expert disagreements reveal key
open challenges and help guide future research toward resolving them.

</details>


### [240] [Dynamic Design of Machine Learning Pipelines via Metalearning](https://arxiv.org/abs/2508.13436)
*Edesio Alcobaça,André C. P. L. F. de Carvalho*

Main category: cs.LG

TL;DR: 히스토리 메타지식을 활용해 AutoML의 탐색공간을 동적으로 설계함으로써 탐색 속도를 크게 향상시키고(무작위 탐색에서 실행시간 89% 절감), 검색공간을 크게 줄이면서 예측 성능 저하를 거의 발생시키지 않음.


<details>
  <summary>Details</summary>
Motivation: 전통적 AutoML은 모델·하이퍼파라미터·피처 엔지니어링을 자동화하지만 탐색·최적화 비용이 매우 높고, 큰 탐색공간이 오버피팅을 유발할 수 있음. 따라서 계산 비용과 과적합을 줄이는 방법이 필요함.

Method: 과거의 메타지식을 이용한 메타러닝 기법으로 탐색공간을 동적으로 설계하여 유망한 영역만 선택하도록 함. 제안 기법을 Random Search와 Auto-Sklearn에 적용해 검색공간 축소 및 최적화 가속을 수행함.

Result: 제안 기법은 Random Search에서 실행시간을 89% 줄였고, 전처리기와 분류기 후보군을 각각 평균적으로 (1.8/13, 4.3/16)만큼 축소함. 예측 성능 저하 없이 효율성을 확보했으며, Auto-Sklearn에 적용했을 때도 경쟁력 있는 성능을 보임.

Conclusion: 메타러닝 기반의 동적 탐색공간 설계는 AutoML의 계산 비용을 크게 낮추고 탐색 효율을 높이는 실용적 접근이다. 다만 메타피처 선택, 메타모델 설명가능성, 탐색공간 축소에 따른 트레이드오프를 신중히 고려해야 함.

Abstract: Automated machine learning (AutoML) has democratized the design of machine
learning based systems, by automating model selection, hyperparameter tuning
and feature engineering. However, the high computational cost associated with
traditional search and optimization strategies, such as Random Search, Particle
Swarm Optimization and Bayesian Optimization, remains a significant challenge.
Moreover, AutoML systems typically explore a large search space, which can lead
to overfitting. This paper introduces a metalearning method for dynamically
designing search spaces for AutoML system. The proposed method uses historical
metaknowledge to select promising regions of the search space, accelerating the
optimization process. According to experiments conducted for this study, the
proposed method can reduce runtime by 89\% in Random Search and search space by
(1.8/13 preprocessor and 4.3/16 classifier), without compromising significant
predictive performance. Moreover, the proposed method showed competitive
performance when adapted to Auto-Sklearn, reducing its search space.
Furthermore, this study encompasses insights into meta-feature selection,
meta-model explainability, and the trade-offs inherent in search space
reduction strategies.

</details>


### [241] [Fisher-Orthogonal Projection Methods for Natural Gradient Descent with Large Batches](https://arxiv.org/abs/2508.13898)
*Yishun Lu,Wesley Armour*

Main category: cs.LG

TL;DR: FOP(Fisher-Orthogonal Projection)는 두 개의 서브배치에서 얻은 그래디언트를 이용해 평균 그래디언트에 대해 Fisher-메트릭상 직교인 그래디언트 차분 성분을 더하는 방식으로 대규모 배치에서도 KFAC 같은 2차 방법의 장점을 회복시켜 수렴 속도와 일반화 성능을 개선한다.


<details>
  <summary>Details</summary>
Motivation: 현대 GPU의 대용량 고대역폭 메모리로 수만 개의 미니배치를 처리할 수 있으나, 배치가 커질수록 그래디언트 노이즈가 줄어들어 1차 방법은 sharp한/비최적의 최소값에서 벗어나기 어려워지고, KFAC 같은 2차 자연그래디언트는 안정성을 위해 과도한 damping을 필요로 해 곡률 정보를 상실한다.

Method: FOP는 하나의 전체 배치를 두 개의 서브배치로 나누어 각각의 그래디언트를 계산하고, 평균 그래디언트에 대해 두 서브배치 그래디언트 차분의 Fisher-내적 기준 직교 성분을 보강하는 분산 인식(variance-aware) 업데이트 방향을 구성한다. 이 방향은 KFAC 기반 자연그래디언트와 결합되어 큰 damping 없이도 곡률 정보를 활용할 수 있도록 설계된다.

Result: 대규모 배치 조건에서 2차 방법의 효과를 복원하여 기존 방법보다 더 빠른 수렴과 향상된 일반화 성능을 달성한다(논문은 실험적으로 이득을 보고).

Conclusion: FOP는 배치 크기가 매우 클 때도 2차 최적화의 이점을 유지하게 해 주며, 대규모 병렬/스케일러블 학습 환경에서 성능과 안정성을 동시에 향상시킨다.

Abstract: Modern GPUs are equipped with large amounts of high-bandwidth memory,
enabling them to support mini-batch sizes of up to tens of thousands of
training samples. However, most existing optimizers struggle to perform
effectively at such a large batch size. As batch size increases, gradient noise
decreases due to averaging over many samples, limiting the ability of
first-order methods to escape sharp or suboptimal minima and reach the global
minimum. Meanwhile, second-order methods like the natural gradient with
Kronecker-Factored Approximate Curvature (KFAC) often require excessively high
damping to remain stable at large batch sizes. This high damping effectively
washes out the curvature information that gives these methods their advantage,
reducing their performance to that of simple gradient descent. In this paper,
we introduce Fisher-Orthogonal Projection (FOP), a novel technique that
restores the effectiveness of the second-order method at very large batch
sizes, enabling scalable training with improved generalization and faster
convergence. FOP constructs a variance-aware update direction by leveraging
gradients from two sub-batches, enhancing the average gradient with a component
of the gradient difference that is orthogonal to the average under the
Fisher-metric.

</details>


### [242] [Revisiting Diffusion Q-Learning: From Iterative Denoising to One-Step Action Generation](https://arxiv.org/abs/2508.13904)
*Thanh Nguyen,Chang D. Yoo*

Main category: cs.LG

TL;DR: DQL의 멀티스텝 디노이징 의존성을 제거한 One-Step Flow Q-Learning(OFQL)을 제안하여, 보조 모델/증류/다단계 학습 없이 한 단계로 정확한 행동을 생성하고 학습/추론 속도를 크게 개선함.


<details>
  <summary>Details</summary>
Motivation: 확률적 생성 모델(특히 diffusion model)이 오프라인 RL에서 뛰어난 성능을 내지만, 대표적 방법인 DQL은 행동 생성에 멀티스텝 디노이징을 필요로 해 학습·추론 비용이 크고 실용성이 떨어짐. 단일 스텝(one-step) 생성은 바람직하나 기존 DQL에 그대로 적용하면 성능이 급감함.

Method: DQL을 샘플 효율적인 Flow Matching(FM) 프레임워크로 재구성하고, 기존 FM의 곡선형 생성 궤적 대신 평균 속도장(average velocity field)을 학습하도록 설계. 이를 통해 보조 모델·증류·다단계 훈련 없이도 직접적이고 정확한 한 단계 행동 생성이 가능하도록 함.

Result: D4RL 벤치마크에서 OFQL이 DQL 및 다른 diffusion 기반 기법들을 능가했고, 학습 및 추론 시간은 DQL에 비해 상당히 단축됨.

Conclusion: OFQL은 멀티스텝 샘플링과 재귀적 그래디언트 업데이트의 필요를 제거해 더 빠르고 견고한 학습·추론을 가능하게 하며, 실용적인 오프라인 RL용 확률적 행동 생성 방법을 제시함.

Abstract: The generative power of diffusion models (DMs) has recently enabled
high-performing decision-making algorithms in offline reinforcement learning
(RL), achieving state-of-the-art results across standard benchmarks. Among
them, Diffusion Q-Learning (DQL) stands out as a leading method for its
consistently strong performance. Nevertheless, DQL remains limited in practice
due to its reliance on multi-step denoising for action generation during both
training and inference. Although one-step denoising is desirable, simply
applying it to DQL leads to a drastic performance drop. In this work, we
revisit DQL and identify its core limitations. We then propose One-Step Flow
Q-Learning (OFQL), a novel framework that enables efficient one-step action
generation during both training and inference, without requiring auxiliary
models, distillation, or multi-phase training. Specifically, OFQL reformulates
DQL within the sample-efficient Flow Matching (FM) framework. While
conventional FM induces curved generative trajectories that impede one-step
generation, OFQL instead learns an average velocity field that facilitates
direct, accurate action generation. Collectively, OFQL eliminates the need for
multi-step sampling and recursive gradient updates in DQL, resulting in faster
and more robust training and inference. Extensive experiments on the D4RL
benchmark demonstrate that OFQL outperforms DQL and other diffusion-based
baselines, while substantially reducing both training and inference time
compared to DQL.

</details>


### [243] [Automated Energy-Aware Time-Series Model Deployment on Embedded FPGAs for Resilient Combined Sewer Overflow Management](https://arxiv.org/abs/2508.13905)
*Tianheng Ling,Vipin Singh,Chao Qian,Felix Biessmann,Gregor Schiele*

Main category: cs.LG

TL;DR: 엣지 장치에서 동작하는 경량화된 Transformer 및 LSTM을 8비트 정수 양자화로 압축하고 FPGA(AMD Spartan‑7 XC7S15) 대상의 하드웨어 인식 자동 배포 파이프라인으로 정확도와 에너지 소모를 공동 최적화한 하수관거 오버플로 예측 프레임워크. Transformer는 MSE 0.0376에 추론당 0.370 mJ, LSTM은 MSE 0.0432(정확도 14.89% 저하)지만 추론당 0.009 mJ로 에너지 40배 이상 절감.


<details>
  <summary>Details</summary>
Motivation: 기후 변화로 인한 극한 기상 빈도 증가와 노후 복합 하수관거의 방류 위험 증가로, 통신 장애 시에도 동작 가능한 로컬·저전력 예측이 필요함.

Method: 경량 Transformer 및 LSTM 모델을 설계하고 정수 전용(8비트) 양자화를 적용. AMD Spartan‑7 XC7S15 FPGA를 대상으로 에러와 에너지 소모를 동시에 최소화하는 하드웨어 인식 자동 배포 파이프라인으로 최적 모델 구성을 탐색. 실제 하수 데이터에 대해 24시간 이력 기반 학습 및 평가.

Result: 선택된 8비트 Transformer: MSE 0.0376, 추론당 0.370 mJ. 최적 8비트 LSTM: MSE 0.0432(14.89% 더 나쁨), 추론당 0.009 mJ(>40× 낮음). LSTM은 훈련시간이 더 길었음.

Conclusion: 디바이스 내 에너지 효율적 로컬 예측을 가능하게 하여 하수관거의 회복탄력성에 기여. 배치 우선순위에 따라 LSTM(초저전력) 또는 Transformer(고정밀) 선택을 권장. 코드 공개(깃허브).

Abstract: Extreme weather events, intensified by climate change, increasingly challenge
aging combined sewer systems, raising the risk of untreated wastewater
overflow. Accurate forecasting of sewer overflow basin filling levels can
provide actionable insights for early intervention, helping mitigating
uncontrolled discharge. In recent years, AI-based forecasting methods have
offered scalable alternatives to traditional physics-based models, but their
reliance on cloud computing limits their reliability during communication
outages. To address this, we propose an end-to-end forecasting framework that
enables energy-efficient inference directly on edge devices. Our solution
integrates lightweight Transformer and Long Short-Term Memory (LSTM) models,
compressed via integer-only quantization for efficient on-device execution.
Moreover, an automated hardware-aware deployment pipeline is used to search for
optimal model configurations by jointly minimizing prediction error and energy
consumption on an AMD Spartan-7 XC7S15 FPGA. Evaluated on real-world sewer
data, the selected 8-bit Transformer model, trained on 24 hours of historical
measurements, achieves high accuracy (MSE 0.0376) at an energy cost of 0.370 mJ
per inference. In contrast, the optimal 8-bit LSTM model requires significantly
less energy (0.009 mJ, over 40x lower) but yields 14.89% worse accuracy (MSE
0.0432) and much longer training time. This trade-off highlights the need to
align model selection with deployment priorities, favoring LSTM for ultra-low
energy consumption or Transformer for higher predictive accuracy. In general,
our work enables local, energy-efficient forecasting, contributing to more
resilient combined sewer systems. All code can be found in the GitHub
Repository (https://github.com/tianheng-ling/EdgeOverflowForecast).

</details>


### [244] [Categorical Policies: Multimodal Policy Learning and Exploration in Continuous Control](https://arxiv.org/abs/2508.13922)
*SM Mazharul Islam,Manfred Huber*

Main category: cs.LG

TL;DR: 연속 제어 문제에서 기존의 Gaussian 정책이 단봉(unimodal) 제한으로 탐험에 제약을 받는 문제를 해결하기 위해, 범주형(카테고리) 잠재 변수를 도입하여 다봉(multimodal) 행동 모드를 모델링하고 모드에 조건화된 행동을 생성하는 'Categorical Policies'를 제안한다. 미분 가능한 이산 잠재 구조를 유지하는 두 가지 샘플링 기법을 사용하며, DeepMind Control Suite에서 Gaussian 정책보다 빠르게 수렴하고 성능이 우수함을 보인다.


<details>
  <summary>Details</summary>
Motivation: 많은 실제 의사결정 문제는 다수의 행동 모드(멀티모달 정책)를 필요로 하며, 연속 제어 영역에서 Gaussian 단일 분포는 탐험이 예측된 최적 행동 주변에 국한되어 희박한 보상, 복잡한 동역학, 환경 맥락에 따른 전략적 적응 문제를 해결하기 어렵다.

Method: 중간의 범주형 분포를 잠재 변수로 도입해 여러 행동 모드를 표현하고, 샘플링된 모드에 조건화된 행동을 생성한다. 미분 가능한 이산 잠재 구조를 보장하기 위해 두 가지 샘플링 스킴(추정: Gumbel-Softmax 등 유사 기법)을 사용해 경사 기반 최적화를 유지한다.

Result: DeepMind Control Suite 환경들에서 평가한 결과, 제안한 Categorical Policies가 더 나은 탐험을 통해 학습 속도가 빨라지고 기존의 Gaussian 정책을 능가하는 성능을 보였다.

Conclusion: 범주형(카테고리) 잠재 변수를 이용한 멀티모달 정책은 연속 제어에서 구조화된 탐험과 멀티모달 행동 표현에 효과적인 도구이며, 미분 가능한 이산 모드 선택을 통해 실용적으로 적용 가능하다.

Abstract: A policy in deep reinforcement learning (RL), either deterministic or
stochastic, is commonly parameterized as a Gaussian distribution alone,
limiting the learned behavior to be unimodal. However, the nature of many
practical decision-making problems favors a multimodal policy that facilitates
robust exploration of the environment and thus to address learning challenges
arising from sparse rewards, complex dynamics, or the need for strategic
adaptation to varying contexts. This issue is exacerbated in continuous control
domains where exploration usually takes place in the vicinity of the predicted
optimal action, either through an additive Gaussian noise or the sampling
process of a stochastic policy. In this paper, we introduce Categorical
Policies to model multimodal behavior modes with an intermediate categorical
distribution, and then generate output action that is conditioned on the
sampled mode. We explore two sampling schemes that ensure differentiable
discrete latent structure while maintaining efficient gradient-based
optimization. By utilizing a latent categorical distribution to select the
behavior mode, our approach naturally expresses multimodality while remaining
fully differentiable via the sampling tricks. We evaluate our multimodal policy
on a set of DeepMind Control Suite environments, demonstrating that through
better exploration, our learned policies converge faster and outperform
standard Gaussian policies. Our results indicate that the Categorical
distribution serves as a powerful tool for structured exploration and
multimodal behavior representation in continuous control.

</details>


### [245] [How Usable is Automated Feature Engineering for Tabular Data?](https://arxiv.org/abs/2508.13932)
*Bastian Schäfer,Lennart Purucker,Maciej Janowski,Frank Hutter*

Main category: cs.LG

TL;DR: 53개의 AutoFE 방법을 조사한 결과, 대부분 사용하기 어렵고 문서·커뮤니티가 부실하며 시간/메모리 제약을 설정할 수 없어 실무 적용성이 낮다. 사용성 개선이 필요하다.


<details>
  <summary>Details</summary>
Motivation: 표 형식 데이터에서 성능을 끌어올리려면 특성 공학이 중요하지만 수작업은 비용과 시간이 많이 든다. 자동화된 특성 공학(AutoFE)이 제안되었으나, 실무자가 실제로 사용하기 쉬운지(사용성)는 조사된 적이 없어 이를 평가할 필요가 있다.

Method: 문헌·도구 조사로 53개의 AutoFE 방법을 선정해 사용성 관점에서 분석했다. 구체적으로 설치·사용 난이도, 문서화 수준, 커뮤니티 활동성, 그리고 시간·메모리 제약 설정 가능성 등을 검사했다.

Result: 대부분의 방법이 사용하기 어렵고, 문서가 부족하며 활성 커뮤니티가 없다. 특히 조사한 모든 방법에서 사용자 수준의 시간 및 메모리 제약을 설정할 수 없었다.

Conclusion: AutoFE 분야는 성능뿐 아니라 사용성을 고려한 엔지니어링 노력이 필요하다. 향후 연구는 사용 친화적이고 잘 설계된 AutoFE 도구 개발에 초점을 맞춰야 한다.

Abstract: Tabular data, consisting of rows and columns, is omnipresent across various
machine learning applications. Each column represents a feature, and features
can be combined or transformed to create new, more informative features. Such
feature engineering is essential to achieve peak performance in machine
learning. Since manual feature engineering is expensive and time-consuming, a
substantial effort has been put into automating it. Yet, existing automated
feature engineering (AutoFE) methods have never been investigated regarding
their usability for practitioners. Thus, we investigated 53 AutoFE methods. We
found that these methods are, in general, hard to use, lack documentation, and
have no active communities. Furthermore, no method allows users to set time and
memory constraints, which we see as a necessity for usable automation. Our
survey highlights the need for future work on usable, well-engineered AutoFE
methods.

</details>


### [246] [Convergent Reinforcement Learning Algorithms for Stochastic Shortest Path Problem](https://arxiv.org/abs/2508.13963)
*Soumyajit Guin,Shalabh Bhatnagar*

Main category: cs.LG

TL;DR: Stochastic Shortest Path(SSP) 문제에 대해 표(tabular) 설정에서의 두 알고리즘과 함수 근사(function approximation) 설정에서의 한 알고리즘을 제안하고, 이들에 대해 거의 확실한 점근 수렴성을 보이며 실험에서 표형 알고리즘은 기존의 수렴 보장 알고리즘들보다 우수하고 함수 근사 알고리즘도 신뢰할 만한 성능을 보였다는 연구.


<details>
  <summary>Details</summary>
Motivation: SSP는 강화학습의 중요 비용 기준 클래스이며, 다른 비용 기준 문제들이 SSP로 환원될 수 있어 실용적·이론적 중요성이 크다. 따라서 SSP에 대해 수렴성이 보장되는 알고리즘(특히 표와 함수 근사 설정 모두)이 필요하다.

Method: 표 설정에서 두 가지 알고리즘을 제안하고, 함수 근사 설정에서 하나의 알고리즘을 제안한다. 모든 알고리즘에 대해 거의 확실한(asymptotic almost-sure) 수렴성을 이론적으로 증명하였다. (구체적 알고리즘 설계나 업데이트 규칙은 초록에 기술되지 않음.)

Result: 세 알고리즘 모두에 대해 점근적 거의 확실한 수렴성 증명을 제공하였다. 실험적으로 표형 알고리즘들이 다른 잘 알려진 수렴 보장 RL 알고리즘들보다 우수한 성능을 보였고, 함수 근사 알고리즘도 다른 함수 근사 기법들에 비해 신뢰할 만한 성능을 보였다.

Conclusion: 제안된 알고리즘들은 이론적 수렴성과 실험적 성능을 동시에 만족한다. SSP 문제 해결을 위한 실용적이고 수렴성이 보장되는 방법을 표와 함수 근사 양쪽 설정에서 제시한다.

Abstract: In this paper we propose two algorithms in the tabular setting and an
algorithm for the function approximation setting for the Stochastic Shortest
Path (SSP) problem. SSP problems form an important class of problems in
Reinforcement Learning (RL), as other types of cost-criteria in RL can be
formulated in the setting of SSP. We show asymptotic almost-sure convergence
for all our algorithms. We observe superior performance of our tabular
algorithms compared to other well-known convergent RL algorithms. We further
observe reliable performance of our function approximation algorithm compared
to other algorithms in the function approximation setting.

</details>


### [247] [AutoScale: Linear Scalarization Guided by Multi-Task Optimization Metrics](https://arxiv.org/abs/2508.13979)
*Yi Yang,Kei Ikemura,Qingwen Zhang,Xiaomeng Zhu,Ci Li,Nazre Batool,Sina Sharif Mansouri,John Folkesson*

Main category: cs.LG

TL;DR: 이 논문은 다중작업 학습에서 선형 스칼라화(linear scalarization)가 적절한 고정 가중치를 사용할 경우 복잡한 MTO 방법들과 비슷하거나 더 나은 성능을 낼 수 있음을 보인다. 특정 가중치가 왜 좋은지, 그리고 이를 전수 탐색 없이 어떻게 결정할지 불분명한 문제를 해결하기 위해, 저자들은 선형 스칼라화와 MTO 지표들(예: 그래디언트 유사성) 사이의 직접적 연관을 규명하고, 이를 바탕으로 MTO 지표를 이용해 가중치를 선택하는 두 단계 프레임워크 AutoScale을 제안한다. AutoScale은 여러 데이터셋에서 높은 효율성과 우수한 성능을 일관되게 보였다.


<details>
  <summary>Details</summary>
Motivation: 현재 다중작업 최적화(MTO) 기법들은 복잡하고 계산 비용이 큰 경우가 많다. 반면, 선형 스칼라화는 잘 선택된 고정 과제 가중치로도 유사하거나 더 나은 성능을 보여주지만, 왜 특정 가중치가 최적인지와 그 가중치를 어떻게 효율적으로 찾을지는 명확하지 않다. 이 문제를 해결하고 간단하면서 효율적인 가중치 선택 방법을 제안하는 것이 동기다.

Method: 저자들은 선형 스칼라화와 기존의 MTO 메트릭(예: 그래디언트 크기 및 방향 유사성) 사이의 관계를 분석하고, 잘 동작하는 스칼라화 가중치들이 특정 MTO 메트릭에서 일관된 경향을 보인다는 실험적 증거를 제시한다. 이를 바탕으로 두 단계로 구성된 AutoScale 프레임워크를 제안한다: (1) 여러 후보 가중치에 대해 MTO 메트릭을 측정하여 성능이 좋을 것으로 보이는 가중치들을 식별하고, (2) 선택된 가중치로 최종 학습을 수행한다. 이 과정은 전수 탐색보다 훨씬 효율적이다.

Result: 광범위한 실험에서 AutoScale은 다양한 데이터셋(새로운 대규모 벤치마크 포함)에서 높은 효율성과 향상된 성능을 보여주었다. 잘 동작하는 스칼라화 가중치들은 높은 그래디언트 크기 유사성 등 특정 MTO 지표에서 일관된 특성을 보였고, AutoScale은 이러한 지표를 효과적으로 활용했다.

Conclusion: 선형 스칼라화는 적절한 가중치 선택 시 복잡한 MTO 방법들에 필적하거나 이를 능가할 수 있으며, MTO 지표를 이용해 가중치를 효율적으로 선택하는 AutoScale은 실용적이고 효율적인 대안임을 제시한다.

Abstract: Recent multi-task learning studies suggest that linear scalarization, when
using well-chosen fixed task weights, can achieve comparable to or even better
performance than complex multi-task optimization (MTO) methods. It remains
unclear why certain weights yield optimal performance and how to determine
these weights without relying on exhaustive hyperparameter search. This paper
establishes a direct connection between linear scalarization and MTO methods,
revealing through extensive experiments that well-performing scalarization
weights exhibit specific trends in key MTO metrics, such as high gradient
magnitude similarity. Building on this insight, we introduce AutoScale, a
simple yet effective two-phase framework that uses these MTO metrics to guide
weight selection for linear scalarization, without expensive weight search.
AutoScale consistently shows superior performance with high efficiency across
diverse datasets including a new large-scale benchmark.

</details>


### [248] [Multi-User Contextual Cascading Bandits for Personalized Recommendation](https://arxiv.org/abs/2508.13981)
*Jiho Park,Huiwen Jia*

Main category: cs.LG

TL;DR: 이 논문은 다수 사용자 동시 상호작용과 순차적 아이템 노출을 반영한 새로운 조합 밴딧 모델(Multi-User Contextual Cascading Bandit, MCCB)을 제안한다. UCBBP와 AUCBBP라는 두 알고리즘을 제시하고, 각각의 이론적 후회(regret) 경계를 증명하며 수치 실험으로 결과를 검증한다.


<details>
  <summary>Details</summary>
Motivation: 온라인 광고 등 현실적 시나리오에서 여러 사용자가 동시에 순차적으로 노출되는 아이템에 반응하고, 사용자별 맥락과 아이템별 보상이 이질적이라는 점을 반영한 새로운 밴딧 모델이 필요하다.

Method: MCCB 모델을 정의하고, UCB 스타일의 UCBBP(Backward Planning 포함) 알고리즘을 제안하여 후회 O~(sqrt(THN))을 보인다. 다수 사용자 동시 상호작용을 활용하는 AUCBBP를 도입하여 컨텍스트(사용자) 수에 대한 효율성을 개선하여 후회 O~(sqrt(T+HN))을 달성한다. 수치 실험으로 이론을 검증.

Result: UCBBP는 T 에피소드, H 세션 길이, 각 에피소드당 N 컨텍스트에 대해 후회 상한 O~(sqrt(THN))을 보이고, AUCBBP는 사용자 확장성에서 향상된 O~(sqrt(T+HN))을 보였다. 실험에서 두 알고리즘이 다양한 설정에서 효과적임을 확인했다.

Conclusion: MCCB 모델과 제안된 두 알고리즘은 다중 사용자와 순차 노출, 이질적 보상을 동시에 고려하는 현실적 온라인 추천/광고 문제에 대해 이론적 보장과 실험적 효능을 제공한다.

Abstract: We introduce a Multi-User Contextual Cascading Bandit model, a new
combinatorial bandit framework that captures realistic online advertising
scenarios where multiple users interact with sequentially displayed items
simultaneously. Unlike classical contextual bandits, MCCB integrates three key
structural elements: (i) cascading feedback based on sequential arm exposure,
(ii) parallel context sessions enabling selective exploration, and (iii)
heterogeneous arm-level rewards. We first propose Upper Confidence Bound with
Backward Planning (UCBBP), a UCB-style algorithm tailored to this setting, and
prove that it achieves a regret bound of $\widetilde{O}(\sqrt{THN})$ over $T$
episodes, $H$ session steps, and $N$ contexts per episode. Motivated by the
fact that many users interact with the system simultaneously, we introduce a
second algorithm, termed Active Upper Confidence Bound with Backward Planning
(AUCBBP), which shows a strict efficiency improvement in context scaling, i.e.,
user scaling, with a regret bound of $\widetilde{O}(\sqrt{T+HN})$. We validate
our theoretical findings via numerical experiments, demonstrating the empirical
effectiveness of both algorithms under various settings.

</details>


### [249] [Formal Algorithms for Model Efficiency](https://arxiv.org/abs/2508.14000)
*Naman Tyagi,Srishti Das,Kunal,Vatsal Gupta*

Main category: cs.LG

TL;DR: KMR(노브-미터-룰) 프레임워크는 가지치기, 양자화, 지식 증류 등 다양한 모델 효율화 기법들을 통일된 방식(조절 가능한 노브, 결정적 규칙, 측정 가능한 미터)으로 표현하고 결합·정책 기반 적용·예산 기반 최적화를 가능하게 한다. Budgeted-KMR 알고리즘으로 반복적 예산 최적화가 가능하며, 여러 기법의 관계와 하이브리드 파이프라인 구성이 쉬워진다.


<details>
  <summary>Details</summary>
Motivation: 딥러닝의 효율성(메모리·연산·전력 등) 개선을 위해 다양한 기법이 존재하지만, 기법별 표현·평가·조합 방법이 달라 체계적 분석·조합·자동화가 어렵다. 이를 통일된 형식으로 추상화해 정책 학습·동적 적응·비용-성능 이론 분석을 용이하게 하려 함.

Method: 효율화 기법들을 '노브'(조절 가능한 파라미터들), '룰'(결정적/정책적 변환 규칙들), '미터'(효율성·품질 지표) 세 가지 요소로 추상화한 KMR 삼중항을 정의. 여러 기법을 KMR 트리플로 인스턴스화하고, 기법 조합을 위한 템플릿 및 Budgeted-KMR이라는 예산 제약 반복 최적화 알고리즘을 제시하여 정책 기반 적용과 순차적 최적화를 가능하게 함.

Result: 논문은 기존의 잘 알려진 효율화 기법들을 KMR로 표현하는 사례를 제시하고, 각 기법별 간결한 알고리즘 템플릿을 제공함. KMR이 기법 간 관계를 드러내고 하이브리드 파이프라인 설계를 촉진함을 보였으며, 자동화된 정책 학습·동적 적응·이론적 비용-성능 분석 연구의 기초를 마련함을 주장함.

Conclusion: KMR은 모델 효율화 연구에 개념적·실용적 통일 틀을 제공하여 다양한 기법의 통합·조합·자동화와 예산 기반 최적화를 가능하게 하며, 향후 정책 학습, 동적 적용, 이론 분석 등의 연구를 촉진할 수 있다.

Abstract: We introduce the Knob-Meter-Rule (KMR) framework, a unified formalism for
representing and reasoning about model efficiency techniques in deep learning.
By abstracting diverse methods, including pruning, quantization, knowledge
distillation, and parameter-efficient architectures, into a consistent set of
controllable knobs, deterministic rules, and measurable meters, KMR provides a
mathematically precise and modular perspective on efficiency optimization. The
framework enables systematic composition of multiple techniques, flexible
policy-driven application, and iterative budgeted optimization through the
Budgeted-KMR algorithm. We demonstrate how well-known efficiency methods can be
instantiated as KMR triples and present concise algorithmic templates for each.
The framework highlights underlying relationships between methods, facilitates
hybrid pipelines, and lays the foundation for future research in automated
policy learning, dynamic adaptation, and theoretical analysis of cost-quality
trade-offs. Overall, KMR offers both a conceptual and practical tool for
unifying and advancing model efficiency research.

</details>


### [250] [GDNSQ: Gradual Differentiable Noise Scale Quantization for Low-bit Neural Networks](https://arxiv.org/abs/2508.14004)
*Sergey Salishev,Ian Akhremchik*

Main category: cs.LG

TL;DR: 


<details>
  <summary>Details</summary>
Motivation: 

Method: 

Result: 

Conclusion: 

Abstract: Quantized neural networks can be viewed as a chain of noisy channels, where
rounding in each layer reduces capacity as bit-width shrinks; the
floating-point (FP) checkpoint sets the maximum input rate. We track capacity
dynamics as the average bit-width decreases and identify resulting quantization
bottlenecks by casting fine-tuning as a smooth, constrained optimization
problem. Our approach employs a fully differentiable Straight-Through Estimator
(STE) with learnable bit-width, noise scale and clamp bounds, and enforces a
target bit-width via an exterior-point penalty; mild metric smoothing (via
distillation) stabilizes training. Despite its simplicity, the method attains
competitive accuracy down to the extreme W1A1 setting while retaining the
efficiency of STE.

</details>


### [251] [ASDFormer: A Transformer with Mixtures of Pooling-Classifier Experts for Robust Autism Diagnosis and Biomarker Discovery](https://arxiv.org/abs/2508.14005)
*Mohammad Izadi,Mehran Safayani*

Main category: cs.LG

TL;DR: ASDFormer는 Transformer 기반 모델에 Mixture of Pooling-Classifier Experts(MoE)를 결합해 fMRI 기반 뇌 영역 간 연결성 패턴을 학습, ABIDE 데이터셋에서 최첨단(또는 우수한) ASD 진단 성능과 해석 가능한 바이오마커(연결성 교란) 식별을 제시한다.


<details>
  <summary>Details</summary>
Motivation: ASD는 뇌 연결성의 복잡한 교란을 동반하며, 특히 기능적 커뮤니티 내·간 연결 패턴이 민감한 변화 지표임. 이러한 패턴을 효과적으로 포착하고 비정상적 상호작용을 식별하면 진단 정확도 향상 및 바이오마커 발견에 기여할 수 있다.

Method: Transformer 아키텍처에 MoE(다중 전문 풀링-분류기)를 도입하여 여러 전문 브랜치와 어텐션을 통해 서로 다른 뇌 영역 및 연결성 패턴에 가중치를 부여. ROI 기반 BOLD 신호를 커뮤니티 단위 상호작용으로 모델링하고, 전문가별로 특화된 특징을 학습해 적응적으로 강조함으로써 분류와 해석 가능성 동시 확보.

Result: ABIDE 데이터셋에 적용한 결과 최고 수준의 ASD 진단 정확도를 달성했으며, 모델의 주목(attention)과 전문가 기여 분석을 통해 ASD 관련 기능적 연결성의 교란 양상에 대한 일관된 인사이트를 도출함.

Conclusion: ASDFormer는 성능과 해석성을 모두 갖춘 fMRI 기반 ASD 진단·바이오마커 탐색 도구로서 유망하며, 커뮤니티 수준 연결성 강조와 MoE 기반 적응적 주목 메커니즘이 핵심 기여 요소이다.

Abstract: Autism Spectrum Disorder (ASD) is a complex neurodevelopmental condition
marked by disruptions in brain connectivity. Functional MRI (fMRI) offers a
non-invasive window into large-scale neural dynamics by measuring
blood-oxygen-level-dependent (BOLD) signals across the brain. These signals can
be modeled as interactions among Regions of Interest (ROIs), which are grouped
into functional communities based on their underlying roles in brain function.
Emerging evidence suggests that connectivity patterns within and between these
communities are particularly sensitive to ASD-related alterations. Effectively
capturing these patterns and identifying interactions that deviate from typical
development is essential for improving ASD diagnosis and enabling biomarker
discovery. In this work, we introduce ASDFormer, a Transformer-based
architecture that incorporates a Mixture of Pooling-Classifier Experts (MoE) to
capture neural signatures associated with ASD. By integrating multiple
specialized expert branches with attention mechanisms, ASDFormer adaptively
emphasizes different brain regions and connectivity patterns relevant to
autism. This enables both improved classification performance and more
interpretable identification of disorder-related biomarkers. Applied to the
ABIDE dataset, ASDFormer achieves state-of-the-art diagnostic accuracy and
reveals robust insights into functional connectivity disruptions linked to ASD,
highlighting its potential as a tool for biomarker discovery.

</details>


### [252] [Typed Topological Structures Of Datasets](https://arxiv.org/abs/2508.14008)
*Wanjun Hu*

Main category: cs.LG

TL;DR: R^2 위의 유한 데이터셋 X를 위해 '타입이 부여된 위상'을 정의하여 데이터 구조(트랙, 컴포넌트, 분기)를 추출하고, 이를 정수열과 typed-II 유사트리로 표현하여 볼록껍질, 구멍, 군집, 이상탐지 등의 알고리즘적 응용을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 유한 위상공간(특히 데이터셋)에 대한 기존 연구는 통계적 방법과 대수적 위상학에 집중되어 있으며, 일반위상학 관점에서의 새로운 도구가 필요하다. '타입이 부여된 위상' 개념은 유한 위상공간을 세분화해 내부 구조를 드러낼 가능성을 제공한다.

Method: R^2 上의 데이터셋 X에 대해 특별한 타입 집합과 이에 상응하는 typed topology를 구성한다. 이 구조를 통해 X를 자연스럽게 트랙으로 분할하고 각 트랙을 순서가 있는 컴포넌트로 나눈다. 컴포넌트는 정수열로 표현 가능하며, 트랙을 가로지르는 컴포넌트들 간의 관계는 typed-II 유사트리(가짜트리) 형태로 모델링한다.

Result: 데이터의 내부 구조(트랙, 정렬된 컴포넌트, 분기 구조)를 명확히 식별할 수 있으며, 이 표현은 볼록껍질 계산, 구멍(홀) 탐지, 군집화, 이상치 탐지 같은 알고리즘적 문제들에 대한 새로운 접근법을 제공한다.

Conclusion: 타입 기반의 위상학적 프레임워크는 유한 데이터셋의 내부 구조를 체계적으로 드러내고, 정수열 및 typed-II 유사트리 같은 이산적 표현을 통해 실용적 알고리즘 설계에 기여할 수 있다.

Abstract: A datatset $X$ on $R^2$ is a finite topological space. Current research of a
dataset focuses on statistical methods and the algebraic topological method
\cite{carlsson}. In \cite{hu}, the concept of typed topological space was
introduced and showed to have the potential for studying finite topological
spaces, such as a dataset. It is a new method from the general topology
perspective. A typed topological space is a topological space whose open sets
are assigned types. Topological concepts and methods can be redefined using
open sets of certain types. In this article, we develop a special set of types
and its related typed topology on a dataset $X$. Using it, we can investigate
the inner structure of $X$. In particular, $R^2$ has a natural quotient space,
in which $X$ is organized into tracks, and each track is split into components.
Those components are in a order. Further, they can be represented by an integer
sequence. Components crossing tracks form branches, and the relationship can be
well represented by a type of pseudotree (called typed-II pseudotree). Such
structures provide a platform for new algorithms for problems such as
calculating convex hull, holes, clustering and anomaly detection.

</details>


### [253] [Collapsing ROC approach for risk prediction research on both common and rare variants](https://arxiv.org/abs/2508.13552)
*Changshuai Wei,Qing Lu*

Main category: cs.LG

TL;DR: 저자는 공통변이뿐 아니라 희귀변이를 통합해 위험예측 정확도를 높이기 위해 'collapsing ROC(CROC)'을 제안함. GAW17 미니-엑솜 데이터(533 SNP, 37 유전자)에서 평가한 결과, 모든 SNP를 사용한 모델(AUC=0.605)이 공통변이만 사용한 모델(AUC=0.585)보다 우수했고, 특히 공통변이가 줄어들수록 CROC가 기존 FROC보다 큰 성능 이득을 보였음(희귀변이만일 때 CROC AUC=0.603 vs FROC AUC=0.524).


<details>
  <summary>Details</summary>
Motivation: 현재의 유전체 기반 위험예측은 주로 공통 변이에 의존해 임상적 활용을 위한 예측정확도가 부족하고, 대부분의 희귀변이는 아직 예측모델에 제대로 반영되지 않았음. 따라서 공통·희귀 변이를 모두 고려하는 포괄적 예측방법이 필요함.

Method: 기존의 forward ROC(FROC)를 확장한 collapsing ROC(CROC)를 제안. CROC는 희귀변이를 처리하기 위한 추가 절차(희귀변이의 집계/콜랩스 전략)를 도입해 공통·희귀 변이를 함께 사용한 리스크 예측 모델을 구축. GAW17 미니-엑솜 데이터의 533 SNP(37 유전자)를 사용해 CROC와 FROC 성능을 비교하고, 공통변이 수를 점차 줄이는 실험을 수행함.

Result: - 모든 SNP 사용: AUC=0.605 vs 공통변이만: AUC=0.585
- 공통변이가 줄어들수록 CROC의 상대적 이득 증가
- 희귀변이만의 극단적 시나리오: CROC AUC=0.603, FROC AUC=0.524

Conclusion: CROC는 희귀변이가 많은 상황에서도 예측성능을 유지하거나 개선해, 공통·희귀 변이를 모두 고려하는 차세대 유전성 리스크 예측에 유망한 접근법임.

Abstract: Risk prediction that capitalizes on emerging genetic findings holds great
promise for improving public health and clinical care. However, recent risk
prediction research has shown that predictive tests formed on existing common
genetic loci, including those from genome-wide association studies, have lacked
sufficient accuracy for clinical use. Because most rare variants on the genome
have not yet been studied for their role in risk prediction, future disease
prediction discoveries should shift toward a more comprehensive risk prediction
strategy that takes into account both common and rare variants. We are
proposing a collapsing receiver operating characteristic CROC approach for risk
prediction research on both common and rare variants. The new approach is an
extension of a previously developed forward ROC FROC approach, with additional
procedures for handling rare variants. The approach was evaluated through the
use of 533 single-nucleotide polymorphisms SNPs in 37 candidate genes from the
Genetic Analysis Workshop 17 mini-exome data set. We found that a prediction
model built on all SNPs gained more accuracy AUC = 0.605 than one built on
common variants alone AUC = 0.585. We further evaluated the performance of two
approaches by gradually reducing the number of common variants in the analysis.
We found that the CROC method attained more accuracy than the FROC method when
the number of common variants in the data decreased. In an extreme scenario,
when there are only rare variants in the data, the CROC reached an AUC value of
0.603, whereas the FROC had an AUC value of 0.524.

</details>


### [254] [Efficient Knowledge Graph Unlearning with Zeroth-order Information](https://arxiv.org/abs/2508.14013)
*Yang Xiao,Ruimeng Ye,Bohan Liu,Xiaolong Ma,Bo Hui*

Main category: cs.LG

TL;DR: 제안된 방법은 KG(지식 그래프)에서 데이터 제거의 영향(언러닝)을 효율적으로 근사하는 알고리즘으로, 테일러 전개와 피셔 행렬 및 제로차 최적화를 활용해 역해시안-벡터 곱을 계산하여 계산량을 줄인다.


<details>
  <summary>Details</summary>
Motivation: 삭제 데이터 및 그 영향 제거(예: Right to be Forgotten 규정)에 따른 KG에서의 효율적 언러닝 요구. KG의 구조적·의미적 특성 때문에 일반 그래프 언러닝 기법을 바로 적용하기 어렵고, 영향 함수 기반 방법은 대규모 KG에 대해 계산 비용이 크다.

Method: 언러닝을 위한 영향 함수를 정의하고, 파라미터 변화는 테일러 전개로 근사. 1차 및 2차 도함수 계산 비용을 줄이기 위해 피셔 정보 행렬과 제로차 최적화를 사용해 역해시안-벡터 곱을 근사(계산 그래프를 구성하지 않음).

Result: 제안 기법이 기존 그래프 언러닝 최첨단 기법들보다 언러닝 효율성과 품질 측면에서 유의미하게 우수함을 실험적으로 입증. 코드 공개.

Conclusion: 대규모 KG에서 비용 효율적이면서 품질이 좋은 언러닝을 달성할 수 있는 실용적 방법을 제시. 1차·2차 도함수 계산을 회피하는 근사 기법이 효과적임.

Abstract: Due to regulations like the Right to be Forgotten, there is growing demand
for removing training data and its influence from models. Since full retraining
is costly, various machine unlearning methods have been proposed. In this
paper, we firstly present an efficient knowledge graph (KG) unlearning
algorithm. We remark that KG unlearning is nontrivial due to the distinctive
structure of KG and the semantic relations between entities. Also, unlearning
by estimating the influence of removed components incurs significant
computational overhead when applied to large-scale knowledge graphs. To this
end, we define an influence function for KG unlearning and propose to
approximate the model's sensitivity without expensive computation of
first-order and second-order derivatives for parameter updates. Specifically,
we use Taylor expansion to estimate the parameter changes caused by data
removal. Given that the first-order gradients and second-order derivatives
dominate the computational load, we use the Fisher matrices and zeroth-order
optimization to approximate the inverse-Hessian vector product without
constructing the computational graphs. Our experimental results demonstrate
that the proposed method outperforms other state-of-the-art graph unlearning
baselines significantly in terms of unlearning efficiency and unlearning
quality. Our code is released at https://github.com/NKUShaw/ZOWFKGIF.

</details>


### [255] [BLIPs: Bayesian Learned Interatomic Potentials](https://arxiv.org/abs/2508.14022)
*Dario Coscia,Pim de Haan,Max Welling*

Main category: cs.LG

TL;DR: BLIP은 변분 드롭아웃 기반의 확률적(베이지안) 학습 프레임워크로, 기존 ML 기반 상호작용 포텐셜(MLIP)에 대한 불확실성 추정과 성능 향상을 제공한다. 아키텍처에 무관하게 적용 가능하며 추론 시 계산 오버헤드가 작고, 데이터 희소·OOD 상황에서 특히 신뢰할 수 있는 불확실성 및 예측 정확도 개선을 보인다.


<details>
  <summary>Details</summary>
Motivation: ML 기반 상호작용 포텐셜(MLIP)은 시뮬레이션 화학에서 중요하지만, 데이터 부족이나 분포 밖 데이터(OOD)에 약하고 불확실성 추정을 제공하지 않아 능동학습과 양자 계산 대비 신뢰성 확보에 한계가 있다.

Method: 적응형 변분 드롭아웃(adaptive Variational Dropout)을 기반으로 한 확장 가능한 변분 베이지안 프레임워크(BLIP)를 제안한다. 아키텍처-무관적이며 (등변) 메시지 패싱 구조와도 통합되며, 에너지와 힘 예측에서 추론 시 계산 부담을 최소화하도록 설계되었다.

Result: 시뮬레이션 기반 화학 과제에서 표준 MLIP 대비 예측 정확도 향상과 잘 보정된(캘리브레이션된) 불확실성 추정을 보였다. 특히 데이터 희소 또는 OOD 상황에서 성능 개선이 뚜렷하며, 사전학습된 MLIP를 BLIP으로 파인튜닝하면 일관된 성능 향상과 캘리브레이션 개선이 관찰된다.

Conclusion: BLIP은 실용적 오버헤드로 신뢰할 수 있는 불확실성 추정과 예측 성능 향상을 제공하여 능동학습 파이프라인 및 시뮬레이션의 신뢰성 확보에 기여할 수 있다.

Abstract: Machine Learning Interatomic Potentials (MLIPs) are becoming a central tool
in simulation-based chemistry. However, like most deep learning models, MLIPs
struggle to make accurate predictions on out-of-distribution data or when
trained in a data-scarce regime, both common scenarios in simulation-based
chemistry. Moreover, MLIPs do not provide uncertainty estimates by
construction, which are fundamental to guide active learning pipelines and to
ensure the accuracy of simulation results compared to quantum calculations. To
address this shortcoming, we propose BLIPs: Bayesian Learned Interatomic
Potentials. BLIP is a scalable, architecture-agnostic variational Bayesian
framework for training or fine-tuning MLIPs, built on an adaptive version of
Variational Dropout. BLIP delivers well-calibrated uncertainty estimates and
minimal computational overhead for energy and forces prediction at inference
time, while integrating seamlessly with (equivariant) message-passing
architectures. Empirical results on simulation-based computational chemistry
tasks demonstrate improved predictive accuracy with respect to standard MLIPs,
and trustworthy uncertainty estimates, especially in data-scarse or heavy
out-of-distribution regimes. Moreover, fine-tuning pretrained MLIPs with BLIP
yields consistent performance gains and calibrated uncertainties.

</details>


### [256] [Learning from Preferences and Mixed Demonstrations in General Settings](https://arxiv.org/abs/2508.14027)
*Jason R Brown,Carl Henrik Ek,Robert D Mullins*

Main category: cs.LG

TL;DR: 새로운 학습 프레임워크(관찰에 대한 보상-합리적 부분 순서)와 실용적 알고리즘 LEOPARD를 제안하여, 선호(기호) 피드백과 시연(데모)를 결합해 스케일 가능하고 유연하게 보상함수를 학습한다. 제한된 양의 선호·시연 데이터에서 기존 방법들보다 성능이 우수하며, 다양한 피드백 유형을 결합하면 성능 향상이 가능하다.


<details>
  <summary>Details</summary>
Motivation: 강화학습에서 복잡한 작업에 대해 좋은 보상함수를 설계하기 어렵고, 선호 피드백이나 전문가 시연을 대신 사용할 수 있으나 둘을 함께 사용하는 기존 접근은 경험적·도메인 특화·확장성 문제를 가진다.

Method: 관찰들에 대한 '보상-합리적 부분 순서(reward-rational partial orderings)'라는 새로운 프레이밍을 도입하고, 이를 바탕으로 다양한 형태의 인간데이터(선호, 순위화된 시연, 음성 데모 등)를 처리할 수 있는 실용적 알고리즘 LEOPARD(=Learning Estimated Objectives from Preferences And Ranked Demonstrations)를 제시한다.

Result: LEOPARD는 음성(negative) 시연을 포함한 폭넓은 데이터를 학습에 활용하며, 제한된 양의 선호 및 시연 피드백 환경에서 기존 베이스라인들보다 유의미하게 우수한 보상학습 성능을 보였다.

Conclusion: 새로운 프레이밍과 LEOPARD는 서로 다른 유형의 인간 피드백을 통합적으로 활용할 수 있게 하여 확장성과 실용성을 제공하며, 다양한 피드백을 결합하는 것이 단일 피드백 사용보다 대체로 유리함을 보여준다.

Abstract: Reinforcement learning is a general method for learning in sequential
settings, but it can often be difficult to specify a good reward function when
the task is complex. In these cases, preference feedback or expert
demonstrations can be used instead. However, existing approaches utilising both
together are often ad-hoc, rely on domain-specific properties, or won't scale.
We develop a new framing for learning from human data, \emph{reward-rational
partial orderings over observations}, designed to be flexible and scalable.
Based on this we introduce a practical algorithm, LEOPARD: Learning Estimated
Objectives from Preferences And Ranked Demonstrations. LEOPARD can learn from a
broad range of data, including negative demonstrations, to efficiently learn
reward functions across a wide range of domains. We find that when a limited
amount of preference and demonstration feedback is available, LEOPARD
outperforms existing baselines by a significant margin. Furthermore, we use
LEOPARD to investigate learning from many types of feedback compared to just a
single one, and find that combining feedback types is often beneficial.

</details>


### [257] [Bounding Causal Effects and Counterfactuals](https://arxiv.org/abs/2508.13607)
*Tobias Maringgele*

Main category: cs.LG

TL;DR: 이 논문은 인과추론에서 강한 가정 대신 부분식별(partial identification)을 사용해 인과효과의 경계(bounds)를 구하는 방법들을 체계적으로 비교·통합하고, 실무자를 위한 선택 지침과 오픈소스 도구를 제공한다.


<details>
  <summary>Details</summary>
Motivation: 현실에서 '무측정 혼란 없음' 등 강한 가정은 잘 성립하지 않아 부분식별이 유리하지만, 기존 방법들이 분산되어 있고 실무적 가이드가 부족해 적용이 제한적이다.

Method: 기호적(symbolic), 최적화 기반, 정보이론적 방법들을 공통 평가 프레임워크로 구현·확장·통합하고, 특히 엔트로피 기반 방법을 확장해 PNS 같은 반사실적(counterfactual) 질의에 적용 가능하게 함. 수천 개의 시뮬레이션(이산·연속 데이터)을 통해 경계의 타이트함, 계산 효율성, 가정 위반에 대한 강건성을 비교하고, 알고리즘 선택을 위한 결정 트리와 관측적 특징으로 최적 방법을 예측하는 ML 모델을 훈련시킴.

Result: 엔트로피 기반 방법의 PNS 적용 확장, 각 방법의 성능·트레이드오프에 대한 대규모 실험 결과, 알고리즘 선택을 위한 실무용 결정 트리 및 예측 모델, 그리고 모든 구현을 포함한 오픈소스 패키지(CausalBoundingEngine) 공개.

Conclusion: 다양한 부분식별 기법을 통합·비교하고 실무자를 위한 명확한 선택 지침과 도구를 제시함으로써 부분식별의 실제 적용을 촉진하려 한다.

Abstract: Causal inference often hinges on strong assumptions - such as no unmeasured
confounding or perfect compliance - that are rarely satisfied in practice.
Partial identification offers a principled alternative: instead of relying on
unverifiable assumptions to estimate causal effects precisely, it derives
bounds that reflect the uncertainty inherent in the data. Despite its
theoretical appeal, partial identification remains underutilized in applied
work, in part due to the fragmented nature of existing methods and the lack of
practical guidance. This thesis addresses these challenges by systematically
comparing a diverse set of bounding algorithms across multiple causal
scenarios. We implement, extend, and unify state-of-the-art methods - including
symbolic, optimization-based, and information-theoretic approaches - within a
common evaluation framework. In particular, we propose an extension of a
recently introduced entropy-bounded method, making it applicable to
counterfactual queries such as the Probability of Necessity and Sufficiency
(PNS). Our empirical study spans thousands of randomized simulations involving
both discrete and continuous data-generating processes. We assess each method
in terms of bound tightness, computational efficiency, and robustness to
assumption violations. To support practitioners, we distill our findings into a
practical decision tree for algorithm selection and train a machine learning
model to predict the best-performing method based on observable data
characteristics.
  All implementations are released as part of an open-source Python package,
CausalBoundingEngine, which enables users to apply and compare bounding methods
through a unified interface.

</details>


### [258] [Towards a Larger Model via One-Shot Federated Learning on Heterogeneous Client Models](https://arxiv.org/abs/2508.13625)
*Wenxuan Ye,Xueli An,Onur Ayan,Junfan Wang,Xueqiang Yan,Georg Carle*

Main category: cs.LG

TL;DR: FedOL은 클라이언트가 라벨 없는 공개 데이터에 대한 예측만 전송해 한 번의 통신으로 서버에 더 큰 모델을 구성하는 원샷 지식 증류 방식이다. 의사라벨을 반복 정제하고 맞춤형 증류 전략을 사용해 이질적 아키텍처와 통신·계산 부담 문제를 완화하며 시뮬레이션에서 기존 기법들을 능가한다.


<details>
  <summary>Details</summary>
Motivation: 모바일 네트워크 환경에서 서버는 더 큰 모델을 수용할 수 있으나 개인정보 때문에 원시 데이터 공유가 불가능하다. 기존 연합학습(FL)은 동일 아키텍처와 여러 통신 라운드를 요구해 클라이언트 자원·통신 부담과 이질성 문제를 야기한다.

Method: 클라이언트는 모델 파라미터 대신 라벨 없는 공개 데이터에 대한 예측(로그잇/확률값)을 전송한다. 서버는 지식 증류 기반으로 서버 모델을 학습하며, 편향된 클라이언트 예측을 보정하기 위해 의사라벨과 서버 모델을 반복적으로 정제하는 특수 목적 함수와 맞춤형 의사라벨 생성 및 증류 전략을 도입한다.

Result: 시뮬레이션에서 FedOL이 기존 베이스라인보다 성능 우위를 보였으며 통신량 감소와 클라이언트 계산 부담 경감 효과를 확인했다.

Conclusion: FedOL은 이질적 아키텍처를 허용하고 통신·계산 비용을 줄이면서 편향을 완화하는 실용적인 원샷 대안으로, 모바일 네트워크의 한계하에 비용효율적인 모델 통합 방법을 제시한다.

Abstract: Large models, renowned for superior performance, outperform smaller ones even
without billion-parameter scales. While mobile network servers have ample
computational resources to support larger models than client devices, privacy
constraints prevent clients from directly sharing their raw data. Federated
Learning (FL) enables decentralized clients to collaboratively train a shared
model by exchanging model parameters instead of transmitting raw data. Yet, it
requires a uniform model architecture and multiple communication rounds, which
neglect resource heterogeneity, impose heavy computational demands on clients,
and increase communication overhead. To address these challenges, we propose
FedOL, to construct a larger and more comprehensive server model in one-shot
settings (i.e., in a single communication round). Instead of model parameter
sharing, FedOL employs knowledge distillation, where clients only exchange
model prediction outputs on an unlabeled public dataset. This reduces
communication overhead by transmitting compact predictions instead of full
model weights and enables model customization by allowing heterogeneous model
architectures. A key challenge in this setting is that client predictions may
be biased due to skewed local data distributions, and the lack of ground-truth
labels in the public dataset further complicates reliable learning. To mitigate
these issues, FedOL introduces a specialized objective function that
iteratively refines pseudo-labels and the server model, improving learning
reliability. To complement this, FedOL incorporates a tailored pseudo-label
generation and knowledge distillation strategy that effectively integrates
diverse knowledge. Simulation results show that FedOL significantly outperforms
existing baselines, offering a cost-effective solution for mobile networks
where clients possess valuable private data but limited computational
resources.

</details>


### [259] [GRAFT: Gradient-Aware Fast MaxVol Technique for Dynamic Data Sampling](https://arxiv.org/abs/2508.13653)
*Ashish Jha,Anh huy Phan,Razan Dibo,Valentin Leplat*

Main category: cs.LG

TL;DR: 


<details>
  <summary>Details</summary>
Motivation: 

Method: 

Result: 

Conclusion: 

Abstract: Training modern neural networks on large datasets is computationally and
environmentally costly. We introduce GRAFT, a scalable in-training subset
selection method that (i) extracts a low-rank feature representation for each
batch, (ii) applies a Fast MaxVol sampler to select a small, diverse subset
that spans the batch's dominant subspace, and (iii) dynamically adjusts the
subset size using a gradient-approximation criterion. By operating in low-rank
subspaces and training on carefully chosen examples instead of full batches,
GRAFT preserves the training trajectory while reducing wall-clock time, energy
consumption, and $\mathrm{CO}_2$ emissions. Across multiple benchmarks, GRAFT
matches or exceeds recent selection baselines in both accuracy and efficiency,
providing a favorable trade-off between accuracy, efficiency, and emissions.

</details>


### [260] [Input Time Scaling](https://arxiv.org/abs/2508.13654)
*Rapheal Huang,Weilong Guo*

Main category: cs.LG

TL;DR: 새로운 'Input Time Scaling' 패러다임 제안 — 쿼리(입력) 단계에 자원 투입해 학습·추론 시 입력을 정제. 훈련-테스트 공동설계가 필수이며, 낮은 품질 데이터나 무관 정보가 오히려 성능을 높일 수 있다는 놀라운 발견. 소량의 예시로도 높은 추론 능력 유도 가능. Qwen2.5-32B 기반 실험에서 AIME24/25에서 32B급 SOTA 성능 달성.


<details>
  <summary>Details</summary>
Motivation: 기존의 데이터·학습 스케일링(data & training scaling)과 추론 시 확장(inference time scaling)을 보완하기 위해, 쿼리(입력) 단계에 자원을 집중하는 새로운 스케일링 축을 제안하려는 것.

Method: LLM의 메타지식을 활용해 학습·테스트 시 입력을 다양한 전략으로 정제(Input Time Scaling). 훈련과 테스트 양쪽 모두에서 동일한 쿼리 전략을 적용(훈련-테스트 공동설계). 다양한 데이터 품질 및 크기(무작위 예시, 무관 정보 추가 등)를 실험하고 Qwen2.5-32B-Instruct 등으로 AIME24/AIME25에서 평가.

Result: 훈련·테스트 양쪽에 전략을 적용하지 않으면 성능이 크게 저하되는 '훈련-테스트 공동설계' 현상 발견. 무관 정보 추가, 최소 필터링된 데이터에서 무작위 예시 선택 등이 오히려 최고 성능을 보일 때가 있음(‘garbage in, garbage out’ 편향에 도전). 데이터 양 증가(15k vs 1k)가 항상 성능 향상을 보장하지 않음. 소수의 예시로도 높은 수준의 추론 능력 유도 가능(Less is More). Qwen2.5-32B-Instruct 기반으로 AIME24/25에서 pass@1 76.7% 달성, 다수결(3모델)로 AIME25 80% 달성. DeepSeek-R1-Distill-Qwen-32B 시작 시 AIME24 86.7% 등 더 높은 결과 보고.

Conclusion: Input Time Scaling은 기존 스케일링 패러다임을 보완하는 유망한 접근. 데이터 품질·크기와 관련된 일반적 가정들을 재검토해야 하며, 훈련-테스트 공동설계와 소량의 예시 활용이 중요한 시사점. 데이터·파이프라인·체크포인트 등을 오픈소스로 공개할 예정.

Abstract: Current Large Language Models (LLMs) are usually post-trained on large-scale
carefully curated datasets (data & training scaling) and doing reasoning in
test time (inference time scaling). In this work, we present a new scaling
paradigm, Input Time Scaling, to complement previous scaling methods by putting
resources on queries (input time). During training and testing, we combine
meta-knowledge from LLMs to refine inputs with different strategies. We also
find a new phenomenon, training-testing co-design there. We need to apply query
strategies during both training and testing. Only applying strategies on
training or testing would seriously degrade the performance. We are also
surprised to find that seemingly low data quality datasets can gain high
performance. Adding irrelevant information to the queries, randomly selecting
examples from a minimally filtered dataset, can even perform the best. These
findings contradict the widely held inductive bias, "garbage in, garbage out".
Curating datasets with seemingly high-quality data can even potentially limit
the performance ceiling. In addition, models trained on more data with similar
quality (15k VS 1k) perform worse, simple dataset size scaling should also be
carefully inspected. The good news is that our findings are compatible with the
Less is More phenomenon. A small set of examples is enough to evoke high-level
reasoning ability. With experiments on models trained on Qwen2.5-32B-Instruct,
we are able to reach SOTA performance among 32B models on AIME24(76.7%) and
AIME25(76.7%) pass@1. We can further achieve AIME24(76.7%) and AIME25(80%) with
a majority vote of three models. Starting from DeepSeek-R1-Distill-Qwen-32B,
the best result would be 86.7% on AIME24 and 76.7% on AIME25. To facilitate
reproducibility and further research, we are working on open-source our
datasets, data pipelines, evaluation results, and checkpoints.

</details>


### [261] [In-Context Decision Making for Optimizing Complex AutoML Pipelines](https://arxiv.org/abs/2508.13657)
*Amir Rezaei Balef,Katharina Eggensperger*

Main category: cs.LG

TL;DR: 현대 AutoML 파이프라인(미세조정, 앙상블 등)의 적응까지 포괄하도록 CASH를 확장한 논문. PS-PFN을 제안해 Posterior Sampling을 max k-armed bandit 문제로 확장하고, PFN을 사용해 최대 보상의 사후분포를 효율적으로 추정한다. 비용 가중 시나리오와 각 팔(arm)마다 다른 PFN 적용도 다룬다. 벤치마크에서 기존 밴딧 및 AutoML 전략보다 우수함을 보임.


<details>
  <summary>Details</summary>
Motivation: 전이학습 및 사전학습 모델의 발전으로 ML 워크플로우가 단순한 하이퍼파라미터 최적화를 넘어서 미세조정(fine-tuning), 앙상블, 기타 적응기법을 포함하게 되었고, 이로 인해 파이프라인의 이질성이 커져 기존 CASH 프레임워크만으로는 최적 모델 탐색에 한계가 있다.

Method: CASH를 확장해 모델 선택과 적응(adaptation)을 함께 다루는 새로운 방법 PS-PFN을 제안. Posterior Sampling(PS)을 max k-armed bandit 설정으로 확장하고, prior-data fitted networks(PFNs)를 활용해 인컨텍스트 러닝으로 최대 보상에 대한 사후분포를 빠르게 추정한다. 비용이 서로 다른 팔을 고려하는 방법과 각 팔별 보상 분포를 별도의 PFN으로 모델링하는 확장도 포함.

Result: 새로운 벤치마크 1개와 기존 표준 벤치마크 2개에서 실험을 수행하여 PS-PFN이 다른 밴딧 알고리즘 및 AutoML 전략보다 우수한 성능을 보였음을 보고. 코드와 데이터는 공개됨.

Conclusion: PS-PFN은 현대의 적응이 필요한 ML 파이프라인 탐색 문제에서 효율적이고 효과적인 접근법이며, 비용을 고려한 확장과 팔별 PFN 모델링을 통해 실용적 적용성이 높다.

Abstract: Combined Algorithm Selection and Hyperparameter Optimization (CASH) has been
fundamental to traditional AutoML systems. However, with the advancements of
pre-trained models, modern ML workflows go beyond hyperparameter optimization
and often require fine-tuning, ensembling, and other adaptation techniques.
While the core challenge of identifying the best-performing model for a
downstream task remains, the increasing heterogeneity of ML pipelines demands
novel AutoML approaches. This work extends the CASH framework to select and
adapt modern ML pipelines. We propose PS-PFN to efficiently explore and exploit
adapting ML pipelines by extending Posterior Sampling (PS) to the max k-armed
bandit problem setup. PS-PFN leverages prior-data fitted networks (PFNs) to
efficiently estimate the posterior distribution of the maximal value via
in-context learning. We show how to extend this method to consider varying
costs of pulling arms and to use different PFNs to model reward distributions
individually per arm. Experimental results on one novel and two existing
standard benchmark tasks demonstrate the superior performance of PS-PFN
compared to other bandit and AutoML strategies. We make our code and data
available at https://github.com/amirbalef/CASHPlus.

</details>


### [262] [Depth-Breadth Synergy in RLVR: Unlocking LLM Reasoning Gains with Adaptive Exploration](https://arxiv.org/abs/2508.13755)
*Zhicheng Yang,Zhijiang Guo,Yinya Huang,Yongxin Wang,Dongchun Xie,Yiwei Wang,Xiaodan Liang,Jing Tang*

Main category: cs.LG

TL;DR: 이 논문은 RLVR(Verifiable Reward)에서 ‘깊이’(가장 어려운 문제 해결 능력)와 ‘폭’(한 번에 소비되는 인스턴스 수)이라는 두 축을 제시하고, GRPO의 누적-어드밴티지가 중간 난이도 샘플에 편향되는 문제를 지적한다. 이를 해결하기 위해 난이도 적응형 다단계 롤아웃(DARS)을 도입해 어려운 문제의 긍정적 롤아웃 수를 늘리고, 대규모 배치(full-batch) 학습으로 폭을 확장해 Pass@K 및 Pass@1 성능을 동시에 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 기존 RLVR 기법(특히 GRPO)은 논리적 추론 능력을 끌어내는 데 유망하지만, 모델이 더 어렵고 드문 문제를 충분히 탐색하지 못하는 ‘깊이’ 문제와, 한 번에 소비하는 데이터 수(‘폭’)를 고려한 최적화가 부족해 성능 향상의 한계가 존재한다는 점을 밝힘.

Method: 1) GRPO의 누적-어드밴티지가 중간 정확도 샘플에 과도한 가중치를 주는 편향을 분석. 2) DARS: 난이도 적응형 다단계 롤아웃을 도입해 어려운 문제에 대해 재표본화·재롤아웃을 통해 긍정적(정답) 롤아웃 비율을 증가시킴. 3) 폭 확장: 배치 크기를 대폭 늘리고 PPO의 미니배치 반복을 제거해 멀티 에폭 풀-배치 업데이트를 수행. 4) DARS-B: DARS에 대규모 배치(폭) 기법을 결합.

Result: 단순히 롤아웃 수를 늘리는 것은 수렴을 빠르게 할 뿐 Pass@K를 악화시킬 수 있으나, DARS는 추가 추론 비용 없이 Pass@K를 지속적으로 개선. 대규모 폭 학습은 Pass@1을 크게 향상시키며 토큰 수준 엔트로피를 유지해 탐색 지속성과 그래디언트 노이즈 저감을 보임. DARS-B는 Pass@K와 Pass@1을 동시에 개선.

Conclusion: 깊이(난이도 적응적 탐색)와 폭(대규모 배치 학습)은 서로 독립적이면서 상호보완적인 차원으로, 두 축을 모두 확장·조정해야 RLVR의 추론 능력을 최대한 끌어낼 수 있다.

Abstract: Reinforcement Learning with Verifiable Reward (RLVR) has emerged as a
powerful paradigm for unlocking reasoning capabilities in large language
models, yet its full potential is hindered by two under-explored dimensions:
Depth-the hardest problem a model can sample; Breadth-the number of instances
consumed in a single iteration. We dissect the popular GRPO algorithm and
reveal a systematic bias: the cumulative-advantage disproportionately weights
samples with medium accuracy, while down-weighting the low-accuracy instances
that are crucial for pushing reasoning boundaries. To rectify the depth
neglect, we introduce Difficulty Adaptive Rollout Sampling (DARS), which
re-weights hard problems through targeted multi-stage rollouts, thereby
increasing the number of positive rollouts for hard problems. Empirically,
naively enlarging rollout size only accelerates convergence and even hurts
Pass@K. Our DARS, in contrast, delivers consistent Pass@K gains without extra
inference cost at convergence. Just as we adaptively expanded the depth of
exploration, we now ask whether aggressively scaling the breadth of training
data can further amplify reasoning gains. To this end, we intensely scale batch
size and replace PPO's mini-batch iterations with full-batch updates over
multiple epochs. Increasing breadth significantly enhances Pass@1 performance.
Large-breadth training sustains high token-level entropy, indicating continued
exploration and reduced gradient noise. We further present DARS-B, which
augments DARS with large breadth, and demonstrate simultaneous gains in Pass@K
and Pass@1. The results confirm that breadth and adaptive exploration across
depth operate as orthogonal dimensions in RLVR, which are key to unleashing the
reasoning power of RLVR.

</details>


### [263] [BERT-VQA: Visual Question Answering on Plots](https://arxiv.org/abs/2508.13184)
*Tai Vu,Robert Yang*

Main category: cs.LG

TL;DR: 시각-질문 응답(plots VQA) 과제에서 VisualBERT 기반 BERT-VQA와 ResNet101 이미지 인코더를 사용해 LSTM+CNN 기반 베이스라인과 비교했다. 교차-모달리티 모듈이 플롯 구성 요소와 질문 구문 정렬에 필수적이라는 가설은 기각되었다.


<details>
  <summary>Details</summary>
Motivation: 시각-언어 통합 능력을 요구하는 visual question answering에서 특히 플롯(그래프) 이미지에 대한 질문 응답 성능을 향상시키는 것.

Method: VisualBERT를 기반으로 한 BERT-VQA 아키텍처와 사전학습된 ResNet101 이미지 인코더를 사용하고, 옵션으로 joint fusion을 추가. 베이스라인으로는 LSTM, CNN, 얕은 분류기를 구성하여 비교 실험 수행.

Result: 실험 결과 교차-모달리티 모듈(VisualBERT의 cross-modality)이 플롯 요소와 질문 구문을 정렬하는 데 필수적이라는 핵심 가설이 기각됨. 즉, 추가적 교차-모달리티가 기대만큼 도움이 되지 않음.

Conclusion: 플롯 질문 응답 문제의 난이도와 다양한 모델 아키텍처의 적절성에 대한 통찰을 제공. 특정 경우에는 VisualBERT의 cross-modality 모듈이 성능 향상에 결정적이지 않을 수 있음을 시사.

Abstract: Visual question answering has been an exciting challenge in the field of
natural language understanding, as it requires deep learning models to exchange
information from both vision and language domains. In this project, we aim to
tackle a subtask of this problem, namely visual question answering on plots. To
achieve this, we developed BERT-VQA, a VisualBERT-based model architecture with
a pretrained ResNet 101 image encoder, along with a potential addition of joint
fusion. We trained and evaluated this model against a baseline that consisted
of a LSTM, a CNN, and a shallow classifier. The final outcome disproved our
core hypothesis that the cross-modality module in VisualBERT is essential in
aligning plot components with question phrases. Therefore, our work provided
valuable insights into the difficulty of the plot question answering challenge
as well as the appropriateness of different model architectures in solving this
problem.

</details>


### [264] [PENGUIN: Enhancing Transformer with Periodic-Nested Group Attention for Long-term Time Series Forecasting](https://arxiv.org/abs/2508.13773)
*Tian Sun,Yuqi Chen,Weiwei Sun*

Main category: cs.LG

TL;DR: 추상으로부터 PENGUIN 모델(TS 시계열 예측용으로 주기성·상대적 주의 편향·그룹화된 다중 주의 활용)을 요약


<details>
  <summary>Details</summary>
Motivation: 자기-어텐션의 역할을 재검토하고 시계열의 주기적 패턴과 상대적 주의 편향의 중요성을 강조하려는 목적

Method: 주기-중첩(relative) 주의 편향과 여러 공존 주기들을 처리하는 그룹화된 멀티-쿼리 어텐션 설계

Result: 다양한 벤치마크에서 MLP/트랜스포머 기반 모델들보다 일관되게 우수한 성능

Conclusion: 명시적 주기성 모델링과 상대적 편향을 통합한 단순하지만 효과적인 어텐션 설계가 LTSF에 유리함

Abstract: Long-term time series forecasting (LTSF) is a fundamental task with
wide-ranging applications. Although Transformer-based models have made
significant breakthroughs in forecasting, their effectiveness for time series
forecasting remains debatable. In this paper, we revisit the significance of
self-attention and propose a simple yet effective mechanism, Periodic-Nested
Group Attention, namely PENGUIN. Our approach highlights the importance of
explicitly modeling periodic patterns and incorporating relative attention bias
for effective time series modeling. To this end, we introduce a periodic-nested
relative attention bias that captures periodic structures directly. To handle
multiple coexisting periodicities (e.g., daily and weekly cycles), we design a
grouped attention mechanism, where each group targets a specific periodicity
using a multi-query attention mechanism. Extensive experiments across diverse
benchmarks demonstrate that PENGUIN consistently outperforms both MLP-based and
Transformer-based models.

</details>


### [265] [RISE: Enhancing VLM Image Annotation with Self-Supervised Reasoning](https://arxiv.org/abs/2508.13229)
*Suhang Hu,Wei Hu,Yuhang Su,Fan Zhang*

Main category: cs.LG

TL;DR: RISE는 시각 언어 모델의 복잡한 이미지 주석(감정 분류, 상황 기반 객체 탐지 등)에서 추론을 개선하기 위한 두 단계 프레임워크다. 첫 단계(RISE-CoT)는 강화학습 기반의 '주석-추론-주석' 폐쇄 루프를 통해 시각적으로 근거있고 논리적으로 일관된 CoT를 생성하고, CoT의 품질을 보상으로 평가해 샘플을 필터링한다. 두 번째 단계(RISE-R1)는 필터된 고품질 CoT로 SFT와 이후 RFT를 순차 적용하여 해석 가능한 추론과 정확한 주석을 얻는다. Qwen2-VL-2B에 적용 시 SFT와 Visual-RFT보다 우수한 성능과 설명 가능성을 보였고, 수동 라벨링된 CoT 없이 자기지도 방식으로 VLM의 추론 능력을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 기존 SFT는 결과(주석)만 학습해 내적 추론을 배우지 못하고, Visual-RFT는 사전학습 시 고품질 CoT가 없어 일관된 사고흐름(CoT)을 생성하지 못한다. 복잡한 시각 주석 작업에는 시각적 근거와 논리적 일관성을 가진 CoT가 필요하다.

Method: 두 단계: 1) Reason 단계(RISE-CoT): 강화학습 기반의 'annotation-reasoning-annotation' 폐쇄 루프를 통해 CoT를 생성하고, 생성된 CoT가 원래 주석을 재구성할 수 있는지를 검증해 보상 신호를 줌. 이 과정에서 직접 정답 누수(leakage)를 피하도록 설계. 2) Inspire & Strengthen 단계(RISE-R1): RISE-CoT의 보상으로 필터링된 고품질 CoT 서브셋으로 먼저 감독학습(SFT)한 뒤, 추가로 강화학습(RFT)으로 정교화하여 해석 가능한 추론과 정확한 주석을 달성.

Result: Qwen2-VL-2B에 적용한 결과, RISE는 복잡하고 단순한 이미지 주석 작업 모두에서 SFT와 Visual-RFT를 능가했다. 성능 향상뿐 아니라 향상된 설명 가능성(해석 가능한 CoT)을 보였다.

Conclusion: RISE는 수동으로 라벨링된 CoT가 없어도 자기지도적 방식으로 VLM의 추론 능력을 향상시키는 실용적 방법을 제시한다. 강화학습을 이용한 폐쇄 루프 검증과 단계적 SFT→RFT 파이프라인으로 일관된 고품질 CoT와 우수한 주석 성능을 달성한다.

Abstract: Vision-Language Models (VLMs) struggle with complex image annotation tasks,
such as emotion classification and context-driven object detection, which
demand sophisticated reasoning. Standard Supervised Fine-Tuning (SFT) focuses
solely on annotation outcomes, ignoring underlying rationales, while Visual
Reinforcement Fine-Tuning (Visual-RFT) produces inconsistent Chains of Thought
(CoTs) due to the absence of high-quality, verified CoTs during pre-training.
We introduce RISE (Reason-Inspire-Strengthen-Expertise), a two-stage framework
to overcome these limitations. In the Reason stage (RISE-CoT), a reinforcement
learning-driven "annotation-reasoning-annotation" closed-loop generates
visually grounded, logically consistent CoTs by verifying their ability to
reconstruct original annotations without direct leakage. The Inspire and
Strengthen stage (RISE-R1) leverages a high-quality CoT subset, filtered by
RISE-CoT rewards, for supervised fine-tuning, followed by reinforcement
fine-tuning to produce interpretable reasoning and accurate annotations,
achieving Expertise in complex visual tasks. Evaluated on complex and simple
image annotation tasks, RISE-trained Qwen2-VL-2B outperforms SFT and
Visual-RFT, achieving robust performance and enhanced explainability. RISE
offers a self-supervised solution for advancing VLM reasoning without requiring
manually annotated CoTs.

</details>


### [266] [Hierarchy-Consistent Learning and Adaptive Loss Balancing for Hierarchical Multi-Label Classification](https://arxiv.org/abs/2508.13452)
*Ruobing Jiang,Mengzhe Liu,Haobing Liu,Yanwei Yu*

Main category: cs.LG

TL;DR: HCAL은 계층적 다중 레이블 분류에서 구조적 일관성 유지와 MTL의 손실 가중치 불균형 문제를 해결하기 위해 프로토타입 대조학습과 적응형 태스크 가중화를 결합한 분류기이다. 프로토타입과 자식→부모 특징 집계를 통해 의미적 일관성을 확보하고, 태스크별 수렴률을 모니터링해 동적으로 손실 가중치를 조정하며, 프로토타입 교란으로 결정 경계의 강건성을 높인다. HVR 지표로 계층 위반을 정량화하고, 세 데이터셋에서 정확도와 HVR에서 기존 방법보다 우수함을 보였다.


<details>
  <summary>Details</summary>
Motivation: 계층적 다중 레이블 분류(HMC)는 클래스 계층 구조의 일관성을 유지해야 하고, 다중 과제 학습(MTL)에서는 태스크 간 손실 균형(‘one-strong-many-weak’ 편향)이 성능 저하를 초래한다. 이를 해결할 방법이 필요하다.

Method: MTL 기반 분류기(HCAL)를 제안한다. 핵심 구성요소는 (1) 프로토타입 대조학습과 자식→부모 특징 집계를 통한 명시적 라벨-프로토타입 의미 일관성, (2) 태스크별 수렴률을 모니터링하는 적응형 손실 가중화로 학습 자원 배분 자동화, (3) 프로토타입에 제어된 노이즈를 주입하는 교란 메커니즘으로 결정 경계 확장.

Result: 세 가지 데이터셋에 대한 광범위한 실험에서 제안한 HCAL은 기존 베이스라인보다 분류 정확도가 높았고, 새로 제안한 계층 위반률(HVR)이 낮아 계층적 일관성과 일반화 능력이 향상되었음을 보였다.

Conclusion: 프로토타입 기반 의미 일관성, 적응적 손실 가중화, 프로토타입 교란을 결합한 HCAL은 HMC 문제에서 구조적 일관성과 MTL 편향을 효과적으로 완화하며 실험적으로 우수한 성능을 보인다.

Abstract: Hierarchical Multi-Label Classification (HMC) faces critical challenges in
maintaining structural consistency and balancing loss weighting in Multi-Task
Learning (MTL). In order to address these issues, we propose a classifier
called HCAL based on MTL integrated with prototype contrastive learning and
adaptive task-weighting mechanisms. The most significant advantage of our
classifier is semantic consistency including both prototype with explicitly
modeling label and feature aggregation from child classes to parent classes.
The other important advantage is an adaptive loss-weighting mechanism that
dynamically allocates optimization resources by monitoring task-specific
convergence rates. It effectively resolves the "one-strong-many-weak"
optimization bias inherent in traditional MTL approaches. To further enhance
robustness, a prototype perturbation mechanism is formulated by injecting
controlled noise into prototype to expand decision boundaries. Additionally, we
formalize a quantitative metric called Hierarchical Violation Rate (HVR) as to
evaluate hierarchical consistency and generalization. Extensive experiments
across three datasets demonstrate both the higher classification accuracy and
reduced hierarchical violation rate of the proposed classifier over baseline
models.

</details>


### [267] [Assessing Trustworthiness of AI Training Dataset using Subjective Logic -- A Use Case on Bias](https://arxiv.org/abs/2508.13813)
*Koffi Ismael Ouattara,Ioannis Krontiris,Theo Dimitrakos,Frank Kargl*

Main category: cs.LG

TL;DR: 이 논문은 Subjective Logic을 기반으로 AI 학습 데이터셋의 신뢰성(특히 편향 같은 전역 속성)을 불확실성까지 고려해 평가하는 최초의 형식적 프레임워크를 제시한다. 증거가 불완전하거나 분산·상충할 때에도 작동하며, 트래픽 표지판 인식 데이터셋에서 클래스 불균형을 포착하고 중앙화 및 연합 학습 시나리오 모두에서 해석 가능하고 견고함을 보였다.


<details>
  <summary>Details</summary>
Motivation: AI 시스템이 학습 데이터에 점점 의존함에 따라, 데이터셋 수준에서 나타나는 편향·공정성 같은 전역 속성의 신뢰성을 평가하는 도구가 필요하다. 기존 연구는 개별 데이터 항목의 신뢰성을 Subjective Logic으로 평가했지만, 데이터셋 전체에서만 나타나는 속성을 평가하는 데는 적용되지 않았다.

Method: Subjective Logic을 기반으로 한 형식적 프레임워크를 도입하여 신뢰 명제(trust propositions)를 정의하고, 불완전·분산·상충 증거 상황에서 불확실성을 정량화한다. 편향(bias)을 신뢰성 속성의 인스턴스로 삼아 프레임워크를 적용하고, 중앙화 및 연합(federated) 환경에서의 증거 통합과 해석을 가능하게 했다.

Result: 트래픽 표지판 인식 데이터셋을 대상으로 한 실험에서 제안 방법은 클래스 불균형을 효과적으로 포착했으며, 중앙집중식과 연합학습 시나리오 모두에서 해석 가능하고 견고한 결과를 보였다.

Conclusion: 제안된 프레임워크는 데이터셋 수준의 전역 속성(예: 편향)에 대한 불확실성-감수 평가를 가능하게 하며, 분산·상충·불완전한 증거가 존재하는 현실적 상황에서 신뢰성 평가에 유용하다.

Abstract: As AI systems increasingly rely on training data, assessing dataset
trustworthiness has become critical, particularly for properties like fairness
or bias that emerge at the dataset level. Prior work has used Subjective Logic
to assess trustworthiness of individual data, but not to evaluate
trustworthiness properties that emerge only at the level of the dataset as a
whole. This paper introduces the first formal framework for assessing the
trustworthiness of AI training datasets, enabling uncertainty-aware evaluations
of global properties such as bias. Built on Subjective Logic, our approach
supports trust propositions and quantifies uncertainty in scenarios where
evidence is incomplete, distributed, and/or conflicting. We instantiate this
framework on the trustworthiness property of bias, and we experimentally
evaluate it based on a traffic sign recognition dataset. The results
demonstrate that our method captures class imbalance and remains interpretable
and robust in both centralized and federated contexts.

</details>


### [268] [A Comprehensive Re-Evaluation of Biometric Modality Properties in the Modern Era](https://arxiv.org/abs/2508.13874)
*Rouqaiah Al-Refai,Pankaja Priya Ramasamy,Ragini Ramesh,Patricia Arias-Cabarcos,Philipp Terhörst*

Main category: cs.LG

TL;DR: 이 논문은 최신 생체인식 기술 발전과 취약성을 반영하여 1998년 표 기반 평가체계를 대체하거나 보완할 목적으로, 24명의 전문가 설문을 통해 생체인식 모달리티(예: 얼굴, 지문 등)의 특성 평가를 재검토했다. 결과는 얼굴 인식의 신뢰도 향상과 지문의 취약성 증가 등 평가 변화와 전문가 합의 수준, 그리고 55개 데이터셋의 불확실성과의 정합성을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 기존의 1998년 표 기반 생체인식 모달리티 평가체계가 최신 기술 발전과 새로운 공격/취약성을 반영하지 못하므로, 최신 상황을 반영한 신뢰할 만한 평가 프레임워크가 필요하다.

Method: 24명의 생체인식 전문가를 대상으로 설문을 실시하여 다양한 모달리티별 속성(property)에 대한 평가를 수집하고, 전문가 간의 합의 수준(agreement)을 분석했다. 또한 55개 생체인식 데이터셋에서의 데이터 수준 불확실성과 전문가 평가를 비교했다.

Result: 전문가 평가는 모달리티별로 큰 변화를 보였다(예: 얼굴 인식 평점 상승, 지문 평점 하락). 전문가 간 합의도 분석 결과 평가의 신뢰성을 뒷받침했으며, 데이터셋 수준의 불확실성과 전문가 평가 간에는 대부분의 모달리티에서 강한 정렬(alignment)이 관찰되었다.

Conclusion: 전문가 설문을 통한 재평가로 기존 평가체계의 업데이트 필요성을 확인했고, 전문가 간 이견은 주요 연구 과제를 제시한다. 실험적 데이터(데이터셋 불확실성)와 전문가 인사이트를 통합하는 것이 중요하다.

Abstract: The rapid advancement of authentication systems and their increasing reliance
on biometrics for faster and more accurate user verification experience,
highlight the critical need for a reliable framework to evaluate the
suitability of biometric modalities for specific applications. Currently, the
most widely known evaluation framework is a comparative table from 1998, which
no longer adequately captures recent technological developments or emerging
vulnerabilities in biometric systems. To address these challenges, this work
revisits the evaluation of biometric modalities through an expert survey
involving 24 biometric specialists. The findings indicate substantial shifts in
property ratings across modalities. For example, face recognition, shows
improved ratings due to technological progress, while fingerprint, shows
decreased reliability because of emerging vulnerabilities and attacks. Further
analysis of expert agreement levels across rated properties highlighted the
consistency of the provided evaluations and ensured the reliability of the
ratings. Finally, expert assessments are compared with dataset-level
uncertainty across 55 biometric datasets, revealing strong alignment in most
modalities and underscoring the importance of integrating empirical evidence
with expert insight. Moreover, the identified expert disagreements reveal key
open challenges and help guide future research toward resolving them.

</details>


### [269] [One Shot vs. Iterative: Rethinking Pruning Strategies for Model Compression](https://arxiv.org/abs/2508.13836)
*Mikołaj Janusz,Tomasz Wojnar,Yawei Li,Luca Benini,Kamil Adamczewski*

Main category: cs.LG

TL;DR: 원샷(한번에) 가지치기와 반복(다회) 가지치기를 체계적으로 비교한 연구. 낮은 가지치기 비율에서는 원샷이, 높은 비율에서는 반복이 유리하며, 인내 기반(patience) 가지치기와 하이브리드 접근이 특정 상황에서 더 좋음.


<details>
  <summary>Details</summary>
Motivation: 가지치기는 모델 압축의 핵심이지만 원샷과 반복 방식 중 어느 쪽이 더 우수한지에 대한 체계적이고 포괄적인 비교가 부족함. 반복 방식이 널리 쓰이긴 하지만 그 가정은 충분히 검증되지 않았음.

Method: 원샷과 반복 가지치기에 대한 엄밀한 정의를 제시하고, 구조화(structured) 및 비구조화(unstructured) 설정에서 여러 가지치기 기준과 모달리티를 포함한 광범위한 벤치마크를 수행하여 성능을 비교함.

Result: 저자들은 실험적으로 각 방식의 장단점을 규명함. 낮은 가지치기 비율에서는 원샷 방식이 더 효과적이고, 높은 가지치기 비율에서는 반복 방식이 우수함. 또한 인내 기반 가지치기(patience-based)와 두 방식을 결합한 하이브리드 방법이 특정 시나리오에서 기존 방법을 능가함을 보임.

Conclusion: 가지치기 전략은 목표 희소성(sparsity) 수준에 따라 선택되어야 하며, 인내 기반 및 하이브리드 접근이 실무자에게 유용할 수 있음. 코드: https://github.com/janumiko/pruning-benchmark

Abstract: Pruning is a core technique for compressing neural networks to improve
computational efficiency. This process is typically approached in two ways:
one-shot pruning, which involves a single pass of training and pruning, and
iterative pruning, where pruning is performed over multiple cycles for
potentially finer network refinement. Although iterative pruning has
historically seen broader adoption, this preference is often assumed rather
than rigorously tested. Our study presents one of the first systematic and
comprehensive comparisons of these methods, providing rigorous definitions,
benchmarking both across structured and unstructured settings, and applying
different pruning criteria and modalities. We find that each method has
specific advantages: one-shot pruning proves more effective at lower pruning
ratios, while iterative pruning performs better at higher ratios. Building on
these findings, we advocate for patience-based pruning and introduce a hybrid
approach that can outperform traditional methods in certain scenarios,
providing valuable insights for practitioners selecting a pruning strategy
tailored to their goals and constraints. Source code is available at
https://github.com/janumiko/pruning-benchmark.

</details>


### [270] [Fisher-Orthogonal Projection Methods for Natural Gradient Descent with Large Batches](https://arxiv.org/abs/2508.13898)
*Yishun Lu,Wesley Armour*

Main category: cs.LG

TL;DR: FOP(Fisher-Orthogonal Projection)는 두 개의 서브배치에서 얻은 그래디언트를 이용해 평균 그래디언트에 대해 Fisher-메트릭상 직교인 그래디언트 차분 성분을 더하는 방식으로 대규모 배치에서도 KFAC 같은 2차 방법의 장점을 회복시켜 수렴 속도와 일반화 성능을 개선한다.


<details>
  <summary>Details</summary>
Motivation: 현대 GPU의 대용량 고대역폭 메모리로 수만 개의 미니배치를 처리할 수 있으나, 배치가 커질수록 그래디언트 노이즈가 줄어들어 1차 방법은 sharp한/비최적의 최소값에서 벗어나기 어려워지고, KFAC 같은 2차 자연그래디언트는 안정성을 위해 과도한 damping을 필요로 해 곡률 정보를 상실한다.

Method: FOP는 하나의 전체 배치를 두 개의 서브배치로 나누어 각각의 그래디언트를 계산하고, 평균 그래디언트에 대해 두 서브배치 그래디언트 차분의 Fisher-내적 기준 직교 성분을 보강하는 분산 인식(variance-aware) 업데이트 방향을 구성한다. 이 방향은 KFAC 기반 자연그래디언트와 결합되어 큰 damping 없이도 곡률 정보를 활용할 수 있도록 설계된다.

Result: 대규모 배치 조건에서 2차 방법의 효과를 복원하여 기존 방법보다 더 빠른 수렴과 향상된 일반화 성능을 달성한다(논문은 실험적으로 이득을 보고).

Conclusion: FOP는 배치 크기가 매우 클 때도 2차 최적화의 이점을 유지하게 해 주며, 대규모 병렬/스케일러블 학습 환경에서 성능과 안정성을 동시에 향상시킨다.

Abstract: Modern GPUs are equipped with large amounts of high-bandwidth memory,
enabling them to support mini-batch sizes of up to tens of thousands of
training samples. However, most existing optimizers struggle to perform
effectively at such a large batch size. As batch size increases, gradient noise
decreases due to averaging over many samples, limiting the ability of
first-order methods to escape sharp or suboptimal minima and reach the global
minimum. Meanwhile, second-order methods like the natural gradient with
Kronecker-Factored Approximate Curvature (KFAC) often require excessively high
damping to remain stable at large batch sizes. This high damping effectively
washes out the curvature information that gives these methods their advantage,
reducing their performance to that of simple gradient descent. In this paper,
we introduce Fisher-Orthogonal Projection (FOP), a novel technique that
restores the effectiveness of the second-order method at very large batch
sizes, enabling scalable training with improved generalization and faster
convergence. FOP constructs a variance-aware update direction by leveraging
gradients from two sub-batches, enhancing the average gradient with a component
of the gradient difference that is orthogonal to the average under the
Fisher-metric.

</details>


### [271] [Categorical Policies: Multimodal Policy Learning and Exploration in Continuous Control](https://arxiv.org/abs/2508.13922)
*SM Mazharul Islam,Manfred Huber*

Main category: cs.LG

TL;DR: 연속 제어 문제에서 기존의 Gaussian 정책이 단봉(unimodal) 제한으로 탐험에 제약을 받는 문제를 해결하기 위해, 범주형(카테고리) 잠재 변수를 도입하여 다봉(multimodal) 행동 모드를 모델링하고 모드에 조건화된 행동을 생성하는 'Categorical Policies'를 제안한다. 미분 가능한 이산 잠재 구조를 유지하는 두 가지 샘플링 기법을 사용하며, DeepMind Control Suite에서 Gaussian 정책보다 빠르게 수렴하고 성능이 우수함을 보인다.


<details>
  <summary>Details</summary>
Motivation: 많은 실제 의사결정 문제는 다수의 행동 모드(멀티모달 정책)를 필요로 하며, 연속 제어 영역에서 Gaussian 단일 분포는 탐험이 예측된 최적 행동 주변에 국한되어 희박한 보상, 복잡한 동역학, 환경 맥락에 따른 전략적 적응 문제를 해결하기 어렵다.

Method: 중간의 범주형 분포를 잠재 변수로 도입해 여러 행동 모드를 표현하고, 샘플링된 모드에 조건화된 행동을 생성한다. 미분 가능한 이산 잠재 구조를 보장하기 위해 두 가지 샘플링 스킴(추정: Gumbel-Softmax 등 유사 기법)을 사용해 경사 기반 최적화를 유지한다.

Result: DeepMind Control Suite 환경들에서 평가한 결과, 제안한 Categorical Policies가 더 나은 탐험을 통해 학습 속도가 빨라지고 기존의 Gaussian 정책을 능가하는 성능을 보였다.

Conclusion: 범주형(카테고리) 잠재 변수를 이용한 멀티모달 정책은 연속 제어에서 구조화된 탐험과 멀티모달 행동 표현에 효과적인 도구이며, 미분 가능한 이산 모드 선택을 통해 실용적으로 적용 가능하다.

Abstract: A policy in deep reinforcement learning (RL), either deterministic or
stochastic, is commonly parameterized as a Gaussian distribution alone,
limiting the learned behavior to be unimodal. However, the nature of many
practical decision-making problems favors a multimodal policy that facilitates
robust exploration of the environment and thus to address learning challenges
arising from sparse rewards, complex dynamics, or the need for strategic
adaptation to varying contexts. This issue is exacerbated in continuous control
domains where exploration usually takes place in the vicinity of the predicted
optimal action, either through an additive Gaussian noise or the sampling
process of a stochastic policy. In this paper, we introduce Categorical
Policies to model multimodal behavior modes with an intermediate categorical
distribution, and then generate output action that is conditioned on the
sampled mode. We explore two sampling schemes that ensure differentiable
discrete latent structure while maintaining efficient gradient-based
optimization. By utilizing a latent categorical distribution to select the
behavior mode, our approach naturally expresses multimodality while remaining
fully differentiable via the sampling tricks. We evaluate our multimodal policy
on a set of DeepMind Control Suite environments, demonstrating that through
better exploration, our learned policies converge faster and outperform
standard Gaussian policies. Our results indicate that the Categorical
distribution serves as a powerful tool for structured exploration and
multimodal behavior representation in continuous control.

</details>


### [272] [ASDFormer: A Transformer with Mixtures of Pooling-Classifier Experts for Robust Autism Diagnosis and Biomarker Discovery](https://arxiv.org/abs/2508.14005)
*Mohammad Izadi,Mehran Safayani*

Main category: cs.LG

TL;DR: ASDFormer는 Transformer 기반 모델에 Mixture of Pooling-Classifier Experts(MoE)를 결합해 fMRI 기반 뇌 영역 간 연결성 패턴을 학습, ABIDE 데이터셋에서 최첨단(또는 우수한) ASD 진단 성능과 해석 가능한 바이오마커(연결성 교란) 식별을 제시한다.


<details>
  <summary>Details</summary>
Motivation: ASD는 뇌 연결성의 복잡한 교란을 동반하며, 특히 기능적 커뮤니티 내·간 연결 패턴이 민감한 변화 지표임. 이러한 패턴을 효과적으로 포착하고 비정상적 상호작용을 식별하면 진단 정확도 향상 및 바이오마커 발견에 기여할 수 있다.

Method: Transformer 아키텍처에 MoE(다중 전문 풀링-분류기)를 도입하여 여러 전문 브랜치와 어텐션을 통해 서로 다른 뇌 영역 및 연결성 패턴에 가중치를 부여. ROI 기반 BOLD 신호를 커뮤니티 단위 상호작용으로 모델링하고, 전문가별로 특화된 특징을 학습해 적응적으로 강조함으로써 분류와 해석 가능성 동시 확보.

Result: ABIDE 데이터셋에 적용한 결과 최고 수준의 ASD 진단 정확도를 달성했으며, 모델의 주목(attention)과 전문가 기여 분석을 통해 ASD 관련 기능적 연결성의 교란 양상에 대한 일관된 인사이트를 도출함.

Conclusion: ASDFormer는 성능과 해석성을 모두 갖춘 fMRI 기반 ASD 진단·바이오마커 탐색 도구로서 유망하며, 커뮤니티 수준 연결성 강조와 MoE 기반 적응적 주목 메커니즘이 핵심 기여 요소이다.

Abstract: Autism Spectrum Disorder (ASD) is a complex neurodevelopmental condition
marked by disruptions in brain connectivity. Functional MRI (fMRI) offers a
non-invasive window into large-scale neural dynamics by measuring
blood-oxygen-level-dependent (BOLD) signals across the brain. These signals can
be modeled as interactions among Regions of Interest (ROIs), which are grouped
into functional communities based on their underlying roles in brain function.
Emerging evidence suggests that connectivity patterns within and between these
communities are particularly sensitive to ASD-related alterations. Effectively
capturing these patterns and identifying interactions that deviate from typical
development is essential for improving ASD diagnosis and enabling biomarker
discovery. In this work, we introduce ASDFormer, a Transformer-based
architecture that incorporates a Mixture of Pooling-Classifier Experts (MoE) to
capture neural signatures associated with ASD. By integrating multiple
specialized expert branches with attention mechanisms, ASDFormer adaptively
emphasizes different brain regions and connectivity patterns relevant to
autism. This enables both improved classification performance and more
interpretable identification of disorder-related biomarkers. Applied to the
ABIDE dataset, ASDFormer achieves state-of-the-art diagnostic accuracy and
reveals robust insights into functional connectivity disruptions linked to ASD,
highlighting its potential as a tool for biomarker discovery.

</details>


### [273] [Efficient Knowledge Graph Unlearning with Zeroth-order Information](https://arxiv.org/abs/2508.14013)
*Yang Xiao,Ruimeng Ye,Bohan Liu,Xiaolong Ma,Bo Hui*

Main category: cs.LG

TL;DR: 제안된 방법은 KG(지식 그래프)에서 데이터 제거의 영향(언러닝)을 효율적으로 근사하는 알고리즘으로, 테일러 전개와 피셔 행렬 및 제로차 최적화를 활용해 역해시안-벡터 곱을 계산하여 계산량을 줄인다.


<details>
  <summary>Details</summary>
Motivation: 삭제 데이터 및 그 영향 제거(예: Right to be Forgotten 규정)에 따른 KG에서의 효율적 언러닝 요구. KG의 구조적·의미적 특성 때문에 일반 그래프 언러닝 기법을 바로 적용하기 어렵고, 영향 함수 기반 방법은 대규모 KG에 대해 계산 비용이 크다.

Method: 언러닝을 위한 영향 함수를 정의하고, 파라미터 변화는 테일러 전개로 근사. 1차 및 2차 도함수 계산 비용을 줄이기 위해 피셔 정보 행렬과 제로차 최적화를 사용해 역해시안-벡터 곱을 근사(계산 그래프를 구성하지 않음).

Result: 제안 기법이 기존 그래프 언러닝 최첨단 기법들보다 언러닝 효율성과 품질 측면에서 유의미하게 우수함을 실험적으로 입증. 코드 공개.

Conclusion: 대규모 KG에서 비용 효율적이면서 품질이 좋은 언러닝을 달성할 수 있는 실용적 방법을 제시. 1차·2차 도함수 계산을 회피하는 근사 기법이 효과적임.

Abstract: Due to regulations like the Right to be Forgotten, there is growing demand
for removing training data and its influence from models. Since full retraining
is costly, various machine unlearning methods have been proposed. In this
paper, we firstly present an efficient knowledge graph (KG) unlearning
algorithm. We remark that KG unlearning is nontrivial due to the distinctive
structure of KG and the semantic relations between entities. Also, unlearning
by estimating the influence of removed components incurs significant
computational overhead when applied to large-scale knowledge graphs. To this
end, we define an influence function for KG unlearning and propose to
approximate the model's sensitivity without expensive computation of
first-order and second-order derivatives for parameter updates. Specifically,
we use Taylor expansion to estimate the parameter changes caused by data
removal. Given that the first-order gradients and second-order derivatives
dominate the computational load, we use the Fisher matrices and zeroth-order
optimization to approximate the inverse-Hessian vector product without
constructing the computational graphs. Our experimental results demonstrate
that the proposed method outperforms other state-of-the-art graph unlearning
baselines significantly in terms of unlearning efficiency and unlearning
quality. Our code is released at https://github.com/NKUShaw/ZOWFKGIF.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [274] [Uncertainty-Aware Learning Policy for Reliable Pulmonary Nodule Detection on Chest X-Ray](https://arxiv.org/abs/2508.13236)
*Hyeonjin Choi,Jinse Kim,Dong-yeon Yoo,Ju-sung Sun,Jung-won Lee*

Main category: eess.IV

TL;DR: ?


<details>
  <summary>Details</summary>
Motivation: ?

Method: ?

Result: ?

Conclusion: ?

Abstract: Early detection and rapid intervention of lung cancer are crucial.
Nonetheless, ensuring an accurate diagnosis is challenging, as physicians'
ability to interpret chest X-rays varies significantly depending on their
experience and degree of fatigue. Although medical AI has been rapidly
advancing to assist in diagnosis, physicians' trust in such systems remains
limited, preventing widespread clinical adoption. This skepticism fundamentally
stems from concerns about its diagnostic uncertainty. In clinical diagnosis,
physicians utilize extensive background knowledge and clinical experience. In
contrast, medical AI primarily relies on repetitive learning of the target
lesion to generate diagnoses based solely on that data. In other words, medical
AI does not possess sufficient knowledge to render a diagnosis, leading to
diagnostic uncertainty. Thus, this study suggests an Uncertainty-Aware Learning
Policy that can address the issue of knowledge deficiency by learning the
physicians' background knowledge alongside the Chest X-ray lesion information.
We used 2,517 lesion-free images and 656 nodule images, all obtained from Ajou
University Hospital. The proposed model attained 92% (IoU 0.2 / FPPI 2) with a
10% enhancement in sensitivity compared to the baseline model while also
decreasing entropy as a measure of uncertainty by 0.2.

</details>


### [275] [Uncertainty-Aware Learning Policy for Reliable Pulmonary Nodule Detection on Chest X-Ray](https://arxiv.org/abs/2508.13236)
*Hyeonjin Choi,Jinse Kim,Dong-yeon Yoo,Ju-sung Sun,Jung-won Lee*

Main category: eess.IV

TL;DR: ?


<details>
  <summary>Details</summary>
Motivation: ?

Method: ?

Result: ?

Conclusion: ?

Abstract: Early detection and rapid intervention of lung cancer are crucial.
Nonetheless, ensuring an accurate diagnosis is challenging, as physicians'
ability to interpret chest X-rays varies significantly depending on their
experience and degree of fatigue. Although medical AI has been rapidly
advancing to assist in diagnosis, physicians' trust in such systems remains
limited, preventing widespread clinical adoption. This skepticism fundamentally
stems from concerns about its diagnostic uncertainty. In clinical diagnosis,
physicians utilize extensive background knowledge and clinical experience. In
contrast, medical AI primarily relies on repetitive learning of the target
lesion to generate diagnoses based solely on that data. In other words, medical
AI does not possess sufficient knowledge to render a diagnosis, leading to
diagnostic uncertainty. Thus, this study suggests an Uncertainty-Aware Learning
Policy that can address the issue of knowledge deficiency by learning the
physicians' background knowledge alongside the Chest X-ray lesion information.
We used 2,517 lesion-free images and 656 nodule images, all obtained from Ajou
University Hospital. The proposed model attained 92% (IoU 0.2 / FPPI 2) with a
10% enhancement in sensitivity compared to the baseline model while also
decreasing entropy as a measure of uncertainty by 0.2.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [276] [Harnessing the Full Potential of RRAMs through Scalable and Distributed In-Memory Computing with Integrated Error Correction](https://arxiv.org/abs/2508.13298)
*Huynh Q. N. Vo,Md Tawsif Rahman Chowdhury,Paritosh Ramanan,Murat Yildirim,Gozde Tutuncuoglu*

Main category: cs.DC

TL;DR: MELISO+는 RRAM 기반 인메모리 컴퓨팅의 비이상성(device non-idealities)과 대규모 행렬 연산 확장 한계를 해결하는 풀스택 분산 프레임워크다. 이중 오류 보정 계층과 분산 RRAM 연산 아키텍처로 65,000×65,000 이상의 행렬 계산을 지원하며, 디바이스 오차를 90% 이상 줄이고 에너지 효율을 10^3–10^5배 향상, 지연 시간을 100배 감소시킨다. 낮은 정밀도 RRAM이 고정밀 디바이스를 능가하게 한다.


<details>
  <summary>Details</summary>
Motivation: 전통적 아키텍처는 데이터 이동에 따른 높은 에너지 소비로 인해 대규모 컴퓨팅에서 비효율적이다. RRAM 기반 인메모리 컴퓨팅은 메모리와 연산의 통합으로 해결책을 제공하지만, 디바이스 수준의 비이상성과 대규모 연산의 확장성 부족이 실제 적용을 제한한다.

Method: MELISO+는(1) 디바이스 비이상성에 대응하는 이중(투-티어) 오류 보정 메커니즘(첫·이차 산술 오차 보정)과 (2) 대규모 행렬 연산을 가능하게 하는 분산 RRAM 연산 프레임워크를 제안한다. 아키텍처적 통합으로 낮은 정밀도 디바이스에서도 고정밀 성능을 달성하도록 알고리즘-하드웨어 공동설계가 적용된다.

Result: 제안된 방법은 디바이스 비이상성으로 인한 1·2차 산술 오차를 90% 이상 감소시키고, 에너지 효율을 10^3–10^5배 향상시키며 지연 시간을 100배 단축한다. 또한 65,000×65,000 이상의 행렬 연산을 지원하고, 낮은 정밀도 RRAM이 정확도·에너지·지연 측면에서 고정밀 디바이스를 능가함을 보인다.

Conclusion: MELISO+는 알고리즘-하드웨어 공동설계를 통한 풀스택 분산 RRAM 기반 인메모리 컴퓨팅 솔루션으로, 대규모 및 지속가능한 고차원 컴퓨팅(예: LLM, 생성 AI)에 적합한 실용적 경로를 제시한다.

Abstract: Exponential growth in global computing demand is exacerbated due to the
higher-energy requirements of conventional architectures, primarily due to
energy-intensive data movement. In-memory computing with Resistive Random
Access Memory (RRAM) addresses this by co-integrating memory and processing,
but faces significant hurdles related to device-level non-idealities and poor
scalability for large computing tasks. Here, we introduce \textbf{MELISO+}
(In-\textbf{Me}mory \textbf{Li}near \textbf{So}lver), a full-stack, distributed
framework for energy-efficient in-memory computing. MELISO+ proposes a novel
two-tier error correction mechanism to mitigate device non-idealities and
develops a distributed RRAM computing framework to enable matrix computations
exceeding dimensions of $65,000 \times 65,000$. This approach reduces first-
and second-order arithmetic errors due to device non-idealities by over 90\%,
enhances energy efficiency by three to five orders of magnitude, and decreases
latency 100-fold. Hence, MELISO+ allows lower-precision RRAM devices to
outperform high-precision device alternatives in accuracy, energy and latency
metrics. By unifying algorithm-hardware co-design with scalable architecture,
MELISO+ significantly advances sustainable, high-dimensional computing suitable
for applications like large language models and generative AI.

</details>


### [277] [Persistent and Partitioned MPI for Stencil Communication](https://arxiv.org/abs/2508.13370)
*Gerald Collom,Jason Burmark,Olga Pearce,Amanda Bienz*

Main category: cs.DC

TL;DR: Stencil 통신 성능을 개선하기 위해 비차단, persistent, partitioned MPI 통신을 비교한 연구로, Comb 벤치마크에서 측정한 결과 persistent는 최대 37% 속도 향상, partitioned는 최대 68% 향상.


<details>
  <summary>Details</summary>
Motivation: 대규모 병렬 애플리케이션에서 반복적 스텐실 연산의 성능은 통신 비용이 지배적이므로, MPI의 다양한 통신 최적화 기법이 실제 성능에 미치는 영향을 평가할 필요가 있음.

Method: Comb 벤치마크에서 비차단(non-blocking), persistent, partitioned MPI 통신 루틴을 사용해 다양한 스케일(프로세스 수, 스레드 수, 메시지 크기)에 대해 성능을 측정하고 각 최적화의 영향 분석을 수행.

Result: 측정 결과 persistent MPI는 기본 통신 대비 최대 37% 속도 향상, partitioned MPI는 최대 68% 속도 향상을 보였음. 또한 프로세스 수, 스레드 수, 메시지 크기가 partitioned 통신 성능에 중요한 영향을 미침.

Conclusion: MPI의 persistent와 partitioned 통신은 스텐실 통신 성능을 크게 개선할 수 있으며, 최적의 이득은 스케일과 메시지·스레드 특성에 따라 달라짐.

Abstract: Many parallel applications rely on iterative stencil operations, whose
performance are dominated by communication costs at large scales. Several MPI
optimizations, such as persistent and partitioned communication, reduce
overheads and improve communication efficiency through amortized setup costs
and reduced synchronization of threaded sends. This paper presents the
performance of stencil communication in the Comb benchmarking suite when using
non blocking, persistent, and partitioned communication routines. The impact of
each optimization is analyzed at various scales. Further, the paper presents an
analysis of the impact of process count, thread count, and message size on
partitioned communication routines. Measured timings show that persistent MPI
communication can provide a speedup of up to 37% over the baseline MPI
communication, and partitioned MPI communication can provide a speedup of up to
68%.

</details>


### [278] [OrbitChain: Orchestrating In-orbit Real-time Analytics of Earth Observation Data](https://arxiv.org/abs/2508.13374)
*Zhouyu Li,Zhijing Yang,Huayue Gu,Xiaojian Wang,Yuchen Liu,Ruozhou Yu*

Main category: cs.DC

TL;DR: OrbitChain은 지구 관측 위성군의 계산 자원을 협력적으로 오케스트레이션해 실시간 분석을 가능하게 하는 프레임워크로, 마이크로서비스 분해·자원 할당·트래픽 라우팅·파이프라인 워크플로를 통해 기존 대비 처리량을 최대 60% 향상하고 통신 오버헤드를 최대 72% 절감한다.


<details>
  <summary>Details</summary>
Motivation: 지상-위성 연결의 대역폭과 지속 시간 제한 때문에 기존 지구 관측 데이터는 다운로드·분석에 수시간~수일이 걸려 재난 대응 같은 실시간 응용을 지원하지 못한다.

Method: 애플리케이션을 마이크로서비스로 분해하고 여러 위성에 계산 작업을 분산·할당한다. 시간 제약을 고려한 자원 스케줄링과 위성 간 통신 오버헤드를 최소화하는 트래픽 라우팅 알고리즘을 도입하며, 파이프라인 워크플로로 태스크를 실시간으로 처리하고 콘스텔레이션 간 협업(예: tip-and-cue)을 지원한다.

Result: 하드웨어-인-더-루프 궤도 컴퓨팅 테스트베드 실험에서 기존 프레임워크 대비 분석 처리량을 최대 60% 높이고 통신 오버헤드를 최대 72% 줄였다.

Conclusion: OrbitChain은 위성 간 분산 컴퓨팅과 통신 최적화를 결합해 지구 관측 분석의 실시간성·효율성을 크게 개선하며, 시의성 있는 재난 대응과 위성군 간 협업에 실용적이다.

Abstract: Earth observation analytics have the potential to serve many time-sensitive
applications. However, due to limited bandwidth and duration of
ground-satellite connections, it takes hours or even days to download and
analyze data from existing Earth observation satellites, making real-time
demands like timely disaster response impossible. Toward real-time analytics,
we introduce OrbitChain, a collaborative analytics framework that orchestrates
computational resources across multiple satellites in an Earth observation
constellation. OrbitChain decomposes analytics applications into microservices
and allocates computational resources for time-constrained analysis. A traffic
routing algorithm is devised to minimize the inter-satellite communication
overhead. OrbitChain adopts a pipeline workflow that completes Earth
observation tasks in real-time, facilitates time-sensitive applications and
inter-constellation collaborations such as tip-and-cue. To evaluate OrbitChain,
we implement a hardware-in-the-loop orbital computing testbed. Experiments show
that our system can complete up to 60% analytics workload than existing Earth
observation analytics framework while reducing the communication overhead by up
to 72%.

</details>


### [279] [Optimizing Allreduce Operations for Heterogeneous Architectures with Multiple Processes per GPU](https://arxiv.org/abs/2508.13397)
*Michael Adams,Amanda Bienz*

Main category: cs.DC

TL;DR: 대형 GPU 간 all-reduce 연산은 통신 비용이 병목이다. 노드 내 여러 CPU 코어를 활용하고 GPU에 lane-aware reductions를 확장해 multi-CPU 가속 GPU-aware lane all-reduces를 제안한다. 최대 2.45x(MPI), 라이브러리 확장시 최대 1.77x(NVIDIA), 1.71x(AMD) 속도 향상을 보인다.


<details>
  <summary>Details</summary>
Motivation: 현대의 이질적 노드(예: 4 GPUs + 다수의 CPU 코어)는 대부분 GPU 계산에만 집중하고 CPU 코어는 유휴 상태다. 대규모 all-reduce 같은 통신 집약 연산에서 이 남는 CPU 자원을 활용하면 통신 병목을 완화할 수 있다.

Method: GPU-aware lane reductions를 GPU로 확장하고, 각 GPU당 여러 CPU 코어를 활용하는 multi-CPU-accelerated lane all-reduces를 설계·구현했다. 또한 이 기법을 NVIDIA와 AMD의 집단 통신 라이브러리에도 통합하여 성능을 측정했다.

Result: NCSA의 Delta 슈퍼컴퓨터(A100 GPU)에서 큰 MPI all-reduce에 대해 최대 2.45x 속도 향상을 달성했다. NVIDIA와 AMD 집단 통신 라이브러리에서도 각각 최대 1.77x, 1.71x의 향상을 보였다.

Conclusion: 노드 내 유휴 CPU 코어를 적극적으로 사용하고 lane-aware 알고리즘을 GPU로 확장하면 대규모 GPU all-reduce의 통신 성능을 크게 개선할 수 있다.

Abstract: Large inter-GPU all-reduce operations, prevalent throughout deep learning,
are bottlenecked by communication costs. Emerging heterogeneous architectures
are comprised of complex nodes, often containing $4$ GPUs and dozens to
hundreds of CPU cores per node. Parallel applications are typically accelerated
on the available GPUs, using only a single CPU core per GPU while the remaining
cores sit idle. This paper presents novel optimizations to large GPU-aware
all-reduce operations, extending lane-aware reductions to the GPUs, and notably
using multiple CPU cores per GPU to accelerate these operations. These
multi-CPU-accelerated GPU-aware lane all-reduces yield speedup of up to $2.45$x
for large MPI all-reduces across the NVIDIA A100 GPUs of NCSA's Delta
supercomputer. Finally, the approach is extended to NVIDIA's and AMD's
collective communication libraries, achieving speedup of up to $1.77$x and
$1.71$x, respectively, across $2$ state-of-the-art supercomputers.

</details>


### [280] [DDoS Attacks in Cloud Computing: Detection and Prevention](https://arxiv.org/abs/2508.13522)
*Zain Ahmad,Musab Ahmad,Bilal Ahmad*

Main category: cs.DC

TL;DR: 본 논문은 DDoS 공격(볼류메트릭, 프로토콜, 애플리케이션 계층)의 특성·영향을 정리하고, 패킷 필터링·IDS·머신러닝 등 탐지 기법과 방화벽·레이트 리미팅·CPP·ELD 등 완화 기법을 비교·평가하여 실무 적용 가이드를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 최근 DDoS 공격의 빈도와 복잡성이 증가하여 기존 탐지·완화 기법만으로는 효과적 대응이 어려워, 공격 유형별 특성에 맞는 분석과 적합한 방어 기법 검토가 필요하다.

Method: 문헌·기술 분석을 통해 DDoS의 유형별 특징과 목표를 정리하고, 각 탐지(패킷 필터링, IDS, ML 기반 등) 및 예방(방화벽, 레이트 리미팅, CPP, ELD 등) 기법의 장단점과 적용성(공격 유형·환경별 적합성)을 비교·평가하였다.

Result: 각 DDoS 유형의 특징과 목표가 정리되었고, 탐지·예방 기법별 강점과 한계(예: ML의 적응성 vs 오탐, 패킷 필터링의 단순성 vs 우회 취약성)가 도출되었다. 또한 기법별로 공격 유형·운영환경에 따른 적합성 권고가 제시되었다.

Conclusion: 종합적으로 환경·공격 유형에 따라 다중 계층·혼합형 방어(시그니처 기반+행위 기반 탐지, 네트워크·애플리케이션 측 완화 조치)와 지속적 모니터링·적응적 조정의 필요성을 강조하며, 조직별 보안 태세 개선을 위한 실무 가이드라인을 제공한다.

Abstract: DDoS attacks are one of the most prevalent and harmful cybersecurity threats
faced by organizations and individuals today. In recent years, the complexity
and frequency of DDoS attacks have increased significantly, making it
challenging to detect and mitigate them effectively. The study analyzes various
types of DDoS attacks, including volumetric, protocol, and application layer
attacks, and discusses the characteristics, impact, and potential targets of
each type. It also examines the existing techniques used for DDoS attack
detection, such as packet filtering, intrusion detection systems, and machine
learning-based approaches, and their strengths and limitations. Moreover, the
study explores the prevention techniques employed to mitigate DDoS attacks,
such as firewalls, rate limiting , CPP and ELD mechanism. It evaluates the
effectiveness of each approach and its suitability for different types of
attacks and environments. In conclusion, this study provides a comprehensive
overview of the different types of DDoS attacks, their detection, and
prevention techniques. It aims to provide insights and guidelines for
organizations and individuals to enhance their cybersecurity posture and
protect against DDoS attacks.

</details>


### [281] [LAMMPS-KOKKOS: Performance Portable Molecular Dynamics Across Exascale Architectures](https://arxiv.org/abs/2508.13523)
*Anders Johansson,Evan Weinberg,Christian R. Trott,Megan J. McCarthy,Stan G. Moore*

Main category: cs.DC

TL;DR: LAMMPS에 Kokkos를 통합해 다양한 GPU 아키텍처와 엑사스케일 시스템에서 여러 상호작용 포텐셜(단일쌍, 다체, ML 기반)의 성능 이식성과 확장성을 분석한 연구.


<details>
  <summary>Details</summary>
Motivation: 현대의 이기종 컴퓨팅(다양한 GPU 벤더·세대, 엑사스케일 시스템)에 맞춰 LAMMPS의 성능 이식성을 확보하고, 기존 C++ 코드베이스에 성능 포터블 라이브러리(Kokkos)를 통합해 유지보수성과 고성능 실행을 동시에 달성하려 함.

Method: 기존 LAMMPS 코드에 Kokkos를 통합하고, 단일쌍(pairwise), 다체 반응형(many-body reactive), 머신러닝 기반(force-field) 포텐셜에 대한 구현·최적화를 수행. 여러 벤더·세대의 GPU에서 벤치마크를 수행하고 FLOPS, 메모리 대역폭, 캐시, 스레드 원자 연산 성능 등을 측정·분석. 또한 OLCF Frontier, ALCF Aurora, NNSA El Capitan에서 강한 스케일링 실험을 수행.

Result: Kokkos 통합을 통해 다양한 GPU 아키텍처에서 성능 포터블 구현이 가능함을 보였고, 포텐셜별로 FLOPS 활용도·메모리 병목·원자 연산 비용 등의 성능 특성이 달랐음. 또한 세 개의 엑사스케일 머신에서 강한 스케일링을 달성했다는 결과를 제시.

Conclusion: Kokkos 기반의 포터블 구현으로 LAMMPS가 현대 이기종·엑사스케일 환경에서 효율적으로 동작하며, 포텐셜 유형에 따라 최적화 초점(계산대역 vs 메모리·동기화 비용)을 달리해야 함을 시사한다.

Abstract: Since its inception in 1995, LAMMPS has grown to be a world-class molecular
dynamics code, with thousands of users, over one million lines of code, and
multi-scale simulation capabilities. We discuss how LAMMPS has adapted to the
modern heterogeneous computing landscape by integrating the Kokkos performance
portability library into the existing C++ code. We investigate performance
portability of simple pairwise, many-body reactive, and machine-learned
force-field interatomic potentials. We present results on GPUs across different
vendors and generations, and analyze performance trends, probing FLOPS
throughput, memory bandwidths, cache capabilities, and thread-atomic operation
performance. Finally, we demonstrate strong scaling on all current US exascale
machines -- OLCF Frontier, and ALCF Aurora, and NNSA El Capitan -- for the
three potentials.

</details>


### [282] [LUNDIsim: model meshes for flow simulation and scientific data compression benchmarks](https://arxiv.org/abs/2508.13636)
*Laurent Duval,Frédéric Payan,Christophe Preux,Lauriane Bouard*

Main category: cs.DC

TL;DR: 논문은 지구과학 시뮬레이션 데이터 급증 문제를 다루며, 효율성·불일치·다양성·해석가능성·가용성의 5가지 평가 이슈를 제시한다. 이를 위해 SPE10에서 영감을 받은 LUNDIsim이라는 결함 지질 메쉬(다중 해상도·다공성/투과성 데이터 포함)를 공개하여 압축·업스케일링·유동 시뮬레이션 벤치마크용 데이터셋을 제공한다.


<details>
  <summary>Details</summary>
Motivation: 수치 시뮬레이션으로 생성되는 과학 데이터의 급증이 계산 능력·해석성·지속 가능성에 문제를 일으키며, 특히 기후·지구과학 분야에서 데이터 관리·검증·비교를 위한 표준화된 공개 데이터(FAIR)와 재현 가능한 부속 자료(MRE)가 필요하다.

Method: SPE10을 참고해 네 가지 지하환경을 가진 결함 지질 메쉬(LUNDIsim)를 생성하고, 다공성/투과성 속성 데이터를 부여했다. 각 모델은 HexaShrink 멀티스케일 표현을 포함한 여러 해상도로 제공되며, 전형적 2상 유동 시뮬레이션을 재현하기 위한 저장소 특성(리저버 피처)도 함께 제시된다.

Result: LUNDIsim은 압축(손실·무손실)과 업스케일링, 복합 메쉬 처리 알고리즘의 벤치마크에 적합한 여러 일관된 해상도의 모델과 재현 가능한 시뮬레이션 설정을 제공한다. 데이터는 DOI(https://doi.org/10.5281/zenodo.14641958)로 공개되었다.

Conclusion: LUNDIsim은 지구·저장소 공학 분야에서 데이터 크기 축소·메쉬 처리·시각화·머신러닝 워크플로를 평가하는 표준 벤치마크로 활용될 수 있으며, FAIR 원칙과 MRE를 통한 성능 비교·재현성 확보를 촉진한다.

Abstract: The volume of scientific data produced for and by numerical simulation
workflows is increasing at an incredible rate. This raises concerns either in
computability, interpretability, and sustainability. This is especially
noticeable in earth science (geology, meteorology, oceanography, and
astronomy), notably with climate studies.
  We highlight five main evaluation issues: efficiency, discrepancy, diversity,
interpretability, availability.
  Among remedies, lossless and lossy compression techniques are becoming
popular to better manage dataset volumes. Performance assessment -- with
comparative benchmarks -- require open datasets shared under FAIR principles
(Findable, Accessible, Interoperable, Reusable), with MRE (Minimal Reproducible
Example) ancillary data for reuse. We share LUNDIsim, an exemplary faulted
geological mesh. It is inspired by SPE10 comparative Challenge. Enhanced by
porosity/permeability datasets, this dataset proposes four distinct subsurface
environments. They were primarily designed for flow simulation in porous media.
Several consistent resolutions (with HexaShrink multiscale representations) are
proposed for each model. We also provide a set of reservoir features for
reproducing typical two-phase flow simulations on all LUNDIsim models in a
reservoir engineering context. This dataset is chiefly meant for benchmarking
and evaluating data size reduction (upscaling) or genuine composite mesh
compression algorithms. It is also suitable for other advanced mesh processing
workflows in geology and reservoir engineering, from visualization to machine
learning.
  LUNDIsim meshes are available at https://doi.org/10.5281/zenodo.14641958

</details>


### [283] [Estimating CO$_2$ emissions of distributed applications and platforms with SimGrid/Batsim](https://arxiv.org/abs/2508.13693)
*Gabriella Saraiva,Miguel Vasconcelos,Sarita Mazzini Bruschi,Danilo Carastan-Santos,Daniel Cordeiro*

Main category: cs.DC

TL;DR: A plugin for Batsim/SimGrid that computes CO2 emissions during simulations by using simulated machines' energy consumption and carbon intensity, enabling assessment of scheduling strategies' environmental impact.


<details>
  <summary>Details</summary>
Motivation: To comprehensively assess the environmental impact (CO2 emissions) of task and resource management strategies in data centers during simulations.

Method: Implemented a carbon footprint plugin within SimGrid (Batsim's underlying framework) that calculates emissions from simulated platform energy consumption and per-machine carbon intensity factor; integrated the plugin into Batsim for workflow compatibility.

Result: The plugin enables CO2 calculation during simulation runs and allows researchers to measure and compare the carbon efficiency of scheduling/resource management strategies within existing Batsim workflows.

Conclusion: Extending Batsim with a SimGrid-based carbon footprint plugin provides a practical tool to evaluate and optimize scheduling strategies for lower carbon emissions in simulated data center scenarios.

Abstract: This work presents a carbon footprint plugin designed to extend the
capabilities of the Batsim simulator by allowing the calculation of CO$_2$
emissions during simulation runs. The goal is to comprehensively assess the
environmental impact associated with task and resource management strategies in
data centers. The plugin is developed within SimGrid -- the underlying
simulation framework of Batsim -- and computes carbon emissions based on the
simulated platform's energy consumption and carbon intensity factor of the
simulated machines. Once implemented, it is integrated into Batsim, ensuring
compatibility with existing simulation workflows and enabling researchers to
assess the carbon efficiency of their scheduling strategies.

</details>


### [284] [CaPGNN: Optimizing Parallel Graph Neural Network Training with Joint Caching and Resource-Aware Graph Partitioning](https://arxiv.org/abs/2508.13716)
*Xianfeng Song,Yi Zou,Zheng Shi*

Main category: cs.DC

TL;DR: CaPGNN은 CPU/GPU 메모리를 활용한 적응형 캐싱과 GPU별 리소스에 맞춘 동적 그래프 분할로 멀티-GPU 단일 서버에서 전체 배치 GNN 학습의 통신 오버헤드와 작업 불균형을 줄여 최대 96% 통신 감소, 최대 12.7배 가속을 달성한다.


<details>
  <summary>Details</summary>
Motivation: 전체 배치 GNN 학습은 멀티-GPU 환경에서 정점 특성의 반복 전송으로 인한 높은 통신 오버헤드와 GPU 간 계산 부하 불균형 때문에 확장성에 제약이 있다.

Method: (1) CPU와 GPU 메모리를 모두 활용하는 공동 적응형 캐싱 알고리즘을 제안해 파티션 간 반복적인 정점 특성 전송을 줄임. (2) GPU들의 이질적 계산 및 통신 능력에 따라 서브그래프 크기를 동적으로 조정하는 리소스-인식 그래프 분할 알고리즘을 도입해 계산 부하를 균형화함.

Result: 대규모 벤치마크에서 CaPGNN은 통신 비용을 최대 96%까지 줄이고, 학습 속도를 기존 최첨단 기법 대비 최대 12.7배 향상시킴.

Conclusion: 적응형 캐싱과 리소스-인식 분할은 멀티-GPU 환경에서 전체 배치 GNN 학습의 통신 병목과 불균형 문제를 효과적으로 완화하여 확장 가능하고 실용적인 학습을 가능하게 한다.

Abstract: Graph Neural Networks (GNNs) have shown remarkable capabilities in processing
graph-structured data prevalent in various real-world applications. However,
the scalability of full-batch GNN training becomes severely limited by high
communication overhead and load imbalance in distributed environments. In this
paper, we present CaPGNN, a novel framework for efficient parallel full-batch
GNN training on single-server with multi-GPU, designed specifically to reduce
redundant inter-GPU communication and balance computational workloads. We
propose a joint adaptive caching algorithm that leverages both CPU and GPU
memory to significantly reduce the repetitive transmission of vertex features
across partitions. Additionally, we introduce a resource-aware graph
partitioning algorithm that adjusts subgraph sizes dynamically according to the
heterogeneous computational and communication capacities of GPUs. Extensive
experiments on large-scale benchmark datasets demonstrate that CaPGNN
effectively reduces communication costs by up to 96% and accelerates GNN
training by up to 12.7 times compared to state-of-the-art approaches. Our
results highlight the potential of adaptive caching and resource-aware
partitioning to facilitate scalable, efficient, and practical deployment of
full-batch GNN training in distributed computing environments.

</details>


### [285] [Is RISC-V ready for High Performance Computing? An evaluation of the Sophon SG2044](https://arxiv.org/abs/2508.13840)
*Nick Brown*

Main category: cs.DC

TL;DR: 


<details>
  <summary>Details</summary>
Motivation: 

Method: 

Result: 

Conclusion: 

Abstract: The pace of RISC-V adoption continues to grow rapidly, yet for the successes
enjoyed in areas such as embedded computing, RISC-V is yet to gain ubiquity in
High Performance Computing (HPC). The Sophon SG2044 is SOPHGO's next generation
64-core high performance CPU that has been designed for workstation and server
grade workloads. Building upon the SG2042, subsystems that were a bottleneck in
the previous generation have been upgraded.
  In this paper we undertake the first performance study of the SG2044 for HPC.
Comparing against the SG2042 and other architectures, we find that the SG2044
is most advantageous when running at higher core counts, delivering up to 4.91
greater performance than the SG2042 over 64-cores. Two of the most important
upgrades in the SG2044 are support for RVV v1.0 and an enhanced memory
subsystem. This results in the SG2044 significantly closing the performance gap
with other architectures, especially for compute-bound workloads.

</details>


### [286] [DDoS Attacks in Cloud Computing: Detection and Prevention](https://arxiv.org/abs/2508.13522)
*Zain Ahmad,Musab Ahmad,Bilal Ahmad*

Main category: cs.DC

TL;DR: 본 논문은 DDoS 공격(볼류메트릭, 프로토콜, 애플리케이션 계층)의 특성·영향을 정리하고, 패킷 필터링·IDS·머신러닝 등 탐지 기법과 방화벽·레이트 리미팅·CPP·ELD 등 완화 기법을 비교·평가하여 실무 적용 가이드를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 최근 DDoS 공격의 빈도와 복잡성이 증가하여 기존 탐지·완화 기법만으로는 효과적 대응이 어려워, 공격 유형별 특성에 맞는 분석과 적합한 방어 기법 검토가 필요하다.

Method: 문헌·기술 분석을 통해 DDoS의 유형별 특징과 목표를 정리하고, 각 탐지(패킷 필터링, IDS, ML 기반 등) 및 예방(방화벽, 레이트 리미팅, CPP, ELD 등) 기법의 장단점과 적용성(공격 유형·환경별 적합성)을 비교·평가하였다.

Result: 각 DDoS 유형의 특징과 목표가 정리되었고, 탐지·예방 기법별 강점과 한계(예: ML의 적응성 vs 오탐, 패킷 필터링의 단순성 vs 우회 취약성)가 도출되었다. 또한 기법별로 공격 유형·운영환경에 따른 적합성 권고가 제시되었다.

Conclusion: 종합적으로 환경·공격 유형에 따라 다중 계층·혼합형 방어(시그니처 기반+행위 기반 탐지, 네트워크·애플리케이션 측 완화 조치)와 지속적 모니터링·적응적 조정의 필요성을 강조하며, 조직별 보안 태세 개선을 위한 실무 가이드라인을 제공한다.

Abstract: DDoS attacks are one of the most prevalent and harmful cybersecurity threats
faced by organizations and individuals today. In recent years, the complexity
and frequency of DDoS attacks have increased significantly, making it
challenging to detect and mitigate them effectively. The study analyzes various
types of DDoS attacks, including volumetric, protocol, and application layer
attacks, and discusses the characteristics, impact, and potential targets of
each type. It also examines the existing techniques used for DDoS attack
detection, such as packet filtering, intrusion detection systems, and machine
learning-based approaches, and their strengths and limitations. Moreover, the
study explores the prevention techniques employed to mitigate DDoS attacks,
such as firewalls, rate limiting , CPP and ELD mechanism. It evaluates the
effectiveness of each approach and its suitability for different types of
attacks and environments. In conclusion, this study provides a comprehensive
overview of the different types of DDoS attacks, their detection, and
prevention techniques. It aims to provide insights and guidelines for
organizations and individuals to enhance their cybersecurity posture and
protect against DDoS attacks.

</details>


### [287] [OrbitChain: Orchestrating In-orbit Real-time Analytics of Earth Observation Data](https://arxiv.org/abs/2508.13374)
*Zhouyu Li,Zhijing Yang,Huayue Gu,Xiaojian Wang,Yuchen Liu,Ruozhou Yu*

Main category: cs.DC

TL;DR: OrbitChain은 지구 관측 위성군의 계산 자원을 협력적으로 오케스트레이션해 실시간 분석을 가능하게 하는 프레임워크로, 마이크로서비스 분해·자원 할당·트래픽 라우팅·파이프라인 워크플로를 통해 기존 대비 처리량을 최대 60% 향상하고 통신 오버헤드를 최대 72% 절감한다.


<details>
  <summary>Details</summary>
Motivation: 지상-위성 연결의 대역폭과 지속 시간 제한 때문에 기존 지구 관측 데이터는 다운로드·분석에 수시간~수일이 걸려 재난 대응 같은 실시간 응용을 지원하지 못한다.

Method: 애플리케이션을 마이크로서비스로 분해하고 여러 위성에 계산 작업을 분산·할당한다. 시간 제약을 고려한 자원 스케줄링과 위성 간 통신 오버헤드를 최소화하는 트래픽 라우팅 알고리즘을 도입하며, 파이프라인 워크플로로 태스크를 실시간으로 처리하고 콘스텔레이션 간 협업(예: tip-and-cue)을 지원한다.

Result: 하드웨어-인-더-루프 궤도 컴퓨팅 테스트베드 실험에서 기존 프레임워크 대비 분석 처리량을 최대 60% 높이고 통신 오버헤드를 최대 72% 줄였다.

Conclusion: OrbitChain은 위성 간 분산 컴퓨팅과 통신 최적화를 결합해 지구 관측 분석의 실시간성·효율성을 크게 개선하며, 시의성 있는 재난 대응과 위성군 간 협업에 실용적이다.

Abstract: Earth observation analytics have the potential to serve many time-sensitive
applications. However, due to limited bandwidth and duration of
ground-satellite connections, it takes hours or even days to download and
analyze data from existing Earth observation satellites, making real-time
demands like timely disaster response impossible. Toward real-time analytics,
we introduce OrbitChain, a collaborative analytics framework that orchestrates
computational resources across multiple satellites in an Earth observation
constellation. OrbitChain decomposes analytics applications into microservices
and allocates computational resources for time-constrained analysis. A traffic
routing algorithm is devised to minimize the inter-satellite communication
overhead. OrbitChain adopts a pipeline workflow that completes Earth
observation tasks in real-time, facilitates time-sensitive applications and
inter-constellation collaborations such as tip-and-cue. To evaluate OrbitChain,
we implement a hardware-in-the-loop orbital computing testbed. Experiments show
that our system can complete up to 60% analytics workload than existing Earth
observation analytics framework while reducing the communication overhead by up
to 72%.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [288] [Chain-of-Agents: End-to-End Agent Foundation Models via Multi-Agent Distillation and Agentic RL](https://arxiv.org/abs/2508.13167)
*Weizhen Li,Jianbo Lin,Zhuosong Jiang,Jingyi Cao,Xinpeng Liu,Jiayu Zhang,Zhenqiang Huang,Qianben Chen,Weichen Sun,Qiexiang Wang,Hongxuan Lu,Tianrui Qin,Chenghao Zhu,Yi Yao,Shuying Fan,Xiaowan Li,Tiannan Wang,Pai Liu,King Zhu,He Zhu,Dingfeng Shi,Piaohong Wang,Yeyi Guan,Xiangru Tang,Minghao Liu,Yuchen Eleanor Jiang,Jian Yang,Jiaheng Liu,Ge Zhang,Wangchunshu Zhou*

Main category: cs.AI

TL;DR: 이 논문은 다중 에이전트 시스템의 동작을 하나의 대형언어모델 내부에서 재현하는 Chain-of-Agents(CoA) 패러다임과, 이를 학습시키기 위한 다중-에이전트 증류 및 에이전틱 강화학습 기법을 제안한다. 결과로 얻은 Agent Foundation Models(AFMs)은 웹·코드 에이전트 벤치마크에서 SOTA 성능을 보이며 전체 연구(모델, 코드, 데이터)를 공개한다.


<details>
  <summary>Details</summary>
Motivation: 기존 다중 에이전트 시스템은 수작업 프롬프트/워크플로우·복잡한 프레임워크에 의존해 계산 비효율적이고 확장성이 떨어지며 데이터 중심 학습의 이점을 활용하지 못한다는 한계가 있다.

Method: Chain-of-Agents(CoA): 단일 모델 내에서 여러 도구 에이전트와 역할 기반 에이전트를 동적 활성화하여 멀티턴 협업을 시뮬레이션함. 학습은(1) SOTA 다중 에이전트 시스템을 CoA 궤적으로 증류하는 다중-에이전트 증류(supervised fine-tuning)와 (2) 검증 가능한 에이전틱 태스크에 대한 에이전틱 강화학습(agentic RL)으로 구성된다.

Result: 학습된 Agent Foundation Models(AFMs)이 웹 에이전트 및 코드 에이전트 설정에서 다양한 벤치마크에 대해 새로운 SOTA 성능을 달성했다. 연구 전체(모델 가중치, 학습·평가 코드, 학습 데이터)를 공개함.

Conclusion: CoA 패러다임과 증류+에이전틱 RL 학습 파이프라인은 단일 모델 내에서 엔드-투-엔드 다중 에이전트 문제해결 능력을 촉진하며 향후 에이전트 모델 및 에이전틱 RL 연구를 위한 기반을 제공한다.

Abstract: Recent advances in large language models (LLMs) and multi-agent systems have
demonstrated remarkable capabilities in complex problem-solving tasks such as
deep research, vibe coding, and mathematical reasoning. However, most existing
multi-agent systems are built upon manual prompt/workflow engineering with
sophisticated agent frameworks, making them computationally inefficient, less
capable, and can not benefit from data-centric learning. In this work, we
introduce Chain-of-Agents (CoA), a novel paradigm of LLM reasoning that enables
native end-to-end complex problem-solving in the same way as a multi-agent
system (i.e., multi-turn problem solving with multiple tools and multiple
agents) within one model. In chain-of-agents problem-solving, the model
dynamically activates different tool agents and role-playing agents to simulate
multi-agent collaboration in an end-to-end fashion. To elicit end-to-end
chain-of-agents problem-solving abilities in LLMs, we introduce a multi-agent
distillation framework to distill state-of-the-art multi-agent systems into
chain-of-agents trajectories for agentic supervised fine-tuning. We then use
agentic reinforcement learning on verifiable agentic tasks to further improve
the models' capabilities on chain-of-agents problem solving. We call the
resulting models Agent Foundation Models (AFMs). Our empirical studies
demonstrate that AFM establishes new state-of-the-art performance across
diverse benchmarks in both web agent and code agent settings. We make the
entire research, including the model weights, code for training and evaluation,
and the training data, fully open-sourced, which offers a solid starting point
for future research on agent models and agentic RL.

</details>


### [289] [Cognitive Workspace: Active Memory Management for LLMs -- An Empirical Study of Functional Infinite Context](https://arxiv.org/abs/2508.13171)
*Tao An*

Main category: cs.AI

TL;DR: Cognitive Workspace는 RAG를 넘어 인간의 외부 기억 사용을 모방한 능동적 메모리 관리 패러다임으로, 계층적 인지 버퍼와 과업 기반 컨텍스트 최적화를 통해 LLM의 문맥 한계를 극복하려 한다. 실험에서 전통적 RAG(메모리 재사용 0%)에 비해 평균 58.6% 메모리 재사용률과 17–18% 순효율 향상을 보였고 통계적으로 유의미한 차이를 보고한다.


<details>
  <summary>Details</summary>
Motivation: LLM은 컨텍스트 길이를 늘려도 문맥 관리의 근본적 한계(동적·과업 중심의 메모리 사용 부족)를 갖고 있으며, 기존의 수동적 검색 기반 시스템은 인간의 작업 중심 기억 관리 방식을 반영하지 못한다는 문제의식에서 출발.

Method: 인지과학(Baddeley의 작업기억, Clark의 확장된 마음, Hutchins의 분산인지) 이론을 바탕으로 (1) 능동적 메모리 큐레이션, (2) 계층적 인지 버퍼로 지속적 작업 상태 유지, (3) 과업 구동형 컨텍스트 최적화의 세 가지 설계를 제안하고 50+ 논문을 통합한 이론 프레임워크로 정립. 다양한 태스크에서 재사용률·효율성을 비교 실험 수행.

Result: 평균 58.6% 메모리 재사용(태스크별 54–60%), 전통 RAG 대비 0% 재사용, 3.3배 높은 연산 횟수에도 불구하고 17–18% 순효율 증가. 통계적 유의성 p<0.001, 효과크기 Cohen’s d>23 보고.

Conclusion: 능동적 메모리 관리와 계층적 버퍼를 통한 Cognitive Workspace는 단순 검색을 넘는 '진정한 인지 보강'으로서 LLM 문맥 관리의 패러다임 전환을 제안하며, 정량적 증거로 능동 메모리의 우위를 주장한다.

Abstract: Large Language Models (LLMs) face fundamental limitations in context
management despite recent advances extending context windows to millions of
tokens. We propose Cognitive Workspace, a novel paradigm that transcends
traditional Retrieval-Augmented Generation (RAG) by emulating human cognitive
mechanisms of external memory use. Drawing from cognitive science foundations
including Baddeley's working memory model, Clark's extended mind thesis, and
Hutchins' distributed cognition framework, we demonstrate that current passive
retrieval systems fail to capture the dynamic, task-driven nature of human
memory management. Our analysis of 2024-2025 developments reveals that while
techniques like Infini-attention and StreamingLLM achieve impressive context
lengths, they lack the metacognitive awareness and active planning capabilities
essential for true cognitive extension. Cognitive Workspace addresses these
limitations through three core innovations: (1) active memory management with
deliberate information curation, (2) hierarchical cognitive buffers enabling
persistent working states, and (3) task-driven context optimization that
dynamically adapts to cognitive demands. Empirical validation demonstrates
Cognitive Workspace achieves an average 58.6% memory reuse rate (ranging from
54-60% across different tasks) compared to 0% for traditional RAG, with 17-18%
net efficiency gain despite 3.3x higher operation counts. Statistical analysis
confirms these advantages with p < 0.001 and Cohen's d > 23 across multiple
task types, establishing the first quantitative evidence for active memory
superiority in LLM systems. We present a comprehensive theoretical framework
synthesizing insights from 50+ recent papers, positioning Cognitive Workspace
as a fundamental shift from information retrieval to genuine cognitive
augmentation.

</details>


### [290] [AlphaEval: A Comprehensive and Efficient Evaluation Framework for Formula Alpha Mining](https://arxiv.org/abs/2508.13174)
*Hongjun Ding,Binqi Chen,Jinsheng Huang,Taian Guo,Zhengyang Mao,Guoyi Shao,Lutong Zou,Luchen Liu,Ming Zhang*

Main category: cs.AI

TL;DR: 


<details>
  <summary>Details</summary>
Motivation: 

Method: 

Result: 

Conclusion: 

Abstract: Formula alpha mining, which generates predictive signals from financial data,
is critical for quantitative investment. Although various algorithmic
approaches-such as genetic programming, reinforcement learning, and large
language models-have significantly expanded the capacity for alpha discovery,
systematic evaluation remains a key challenge. Existing evaluation metrics
predominantly include backtesting and correlation-based measures. Backtesting
is computationally intensive, inherently sequential, and sensitive to specific
strategy parameters. Correlation-based metrics, though efficient, assess only
predictive ability and overlook other crucial properties such as temporal
stability, robustness, diversity, and interpretability. Additionally, the
closed-source nature of most existing alpha mining models hinders
reproducibility and slows progress in this field. To address these issues, we
propose AlphaEval, a unified, parallelizable, and backtest-free evaluation
framework for automated alpha mining models. AlphaEval assesses the overall
quality of generated alphas along five complementary dimensions: predictive
power, stability, robustness to market perturbations, financial logic, and
diversity. Extensive experiments across representative alpha mining algorithms
demonstrate that AlphaEval achieves evaluation consistency comparable to
comprehensive backtesting, while providing more comprehensive insights and
higher efficiency. Furthermore, AlphaEval effectively identifies superior
alphas compared to traditional single-metric screening approaches. All
implementations and evaluation tools are open-sourced to promote
reproducibility and community engagement.

</details>


### [291] [Fitting Ontologies and Constraints to Relational Structures](https://arxiv.org/abs/2508.13176)
*Simon Hosemann,Jean Christoph Jung,Carsten Lutz,Sebastian Rudolph*

Main category: cs.AI

TL;DR: 논문은 유한 관계 구조로 표현된 긍정·부정 예제에 대해 설명 논리 $\mathcal{E\mkern-2mu L}$, $\mathcal{E\mkern-2mu LI}$ 및 여러 TGD(전부, 가디드, 프론티어-가디드, 프론티어-원, 무제한, 포함 종속성)를 적합시키는 문제를 다룬다. 복잡도 경계, 알고리즘, 적합해의 크기 분석 및 주어진 유한 구조 집합에 대한 개념 포함/TDG의 유한 기저 존재 여부를 연구한다. 일부 언어(EL, ELI, 가디드 TGD, 포함 종속성)는 유한 기저가 존재하나, 전부·프론티어-가디드·프론티어-원 TGD는 일반적으로 존재하지 않는다.


<details>
  <summary>Details</summary>
Motivation: 실제로 관찰되는 긍정/부정 예제를 만족하는 온톨로지나 제약을 자동으로 학습/구성하려는 문제. 온톨로지/제약 언어별로 적합성(fit) 여부, 계산 복잡도, 해의 크기, 그리고 주어진 사례에 대해 유한한 기저(모든 함축을 대표하는 유한 집합)의 존재 가능성을 이해하는 것이 필요하다.

Method: 설명 논리(EL, ELI)와 여러 TGD 클래스에 대해 수학적·계산적 분석 수행. 각 언어에 대해 적합성 결정 문제의 정확한 복잡도 분류, 적합한 온톨로지/TGD를 구성하는 알고리즘 제시, 생성물의 크기 분석을 수행. 또한 유한한 기저 존재 여부를 구조적·반례적 방법으로 판별.

Result: 정확한 계산 복잡도(논문 내에 언급된 각 언어/제약 클래스별로 분류), 적합 해를 구성하는 알고리즘과 그 크기 경계 제시. 유한 기저는 EL, ELI, 가디드 TGD, 포함 종속성의 경우 존재함을 보였고, 전부, 프론티어-가디드, 프론티어-원 TGD의 경우 일반적으로 유한 기저가 존재하지 않음을 증명.

Conclusion: 온톨로지/제약 학습에서 언어 선택이 결정적이며, 일부 넓은 클래스의 TGD에서는 유한 기저가 없으므로 학습이나 표현의 어려움이 본질적임. 반면 EL/ELI/가디드TGD/포함종속성은 실용적 학습 가능성(유한 기저 존재 등) 측면에서 유리함.

Abstract: We study the problem of fitting ontologies and constraints to positive and
negative examples that take the form of a finite relational structure. As
ontology and constraint languages, we consider the description logics
$\mathcal{E\mkern-2mu L}$ and $\mathcal{E\mkern-2mu LI}$ as well as several
classes of tuple-generating dependencies (TGDs): full, guarded,
frontier-guarded, frontier-one, and unrestricted TGDs as well as inclusion
dependencies. We pinpoint the exact computational complexity, design
algorithms, and analyze the size of fitting ontologies and TGDs. We also
investigate the related problem of constructing a finite basis of concept
inclusions / TGDs for a given set of finite structures. While finite bases
exist for $\mathcal{E\mkern-2mu L}$, $\mathcal{E\mkern-2mu LI}$, guarded TGDs,
and inclusion dependencies, they in general do not exist for full,
frontier-guarded and frontier-one TGDs.

</details>


### [292] [A Hardware-oriented Approach for Efficient Active Inference Computation and Deployment](https://arxiv.org/abs/2508.13177)
*Nikola Pižurica,Nikola Milović,Igor Jovančević,Conor Heins,Miguel de Prado*

Main category: cs.AI

TL;DR: AIF의 계산·메모리 부담을 줄이기 위해 pymdp의 유연성에 기반한 통합된 희소 계산 그래프를 하드웨어 효율적으로 구현하여 지연을 2배 이상, 메모리를 최대 35% 절감한 방법을 제시한다.


<details>
  <summary>Details</summary>
Motivation: Active Inference는 강력한 의사결정 프레임워크이나 계산량과 메모리 요구가 커서 리얼타임·임베디드 환경에 적용하기 어렵다. 이를 경감해 배포성을 높이는 것이 목표이다.

Method: pymdp의 모듈성과 효율성을 유지하면서 연산을 하나의 통합된 희소(sparse) 계산 그래프로 변환해 하드웨어 친화적으로 구현하였다. 그래프 설계는 메모리 접근과 연산을 최적화하도록 맞춤화되었다.

Result: 제안한 접근으로 지연(latency)을 2배 이상 감소시키고 메모리 사용량을 최대 35%까지 줄였음을 보고한다. 이는 실시간 및 임베디드 응용에서 AIF 에이전트 배포 가능성을 크게 향상시킨다.

Conclusion: 통합된 희소 계산 그래프를 통한 pymdp 기반 AIF 구현은 계산·메모리 효율을 획기적으로 개선하였으며, 하드웨어 효율적 실행을 통해 실시간 임베디드 적용을 촉진한다.

Abstract: Active Inference (AIF) offers a robust framework for decision-making, yet its
computational and memory demands pose challenges for deployment, especially in
resource-constrained environments. This work presents a methodology that
facilitates AIF's deployment by integrating pymdp's flexibility and efficiency
with a unified, sparse, computational graph tailored for hardware-efficient
execution. Our approach reduces latency by over 2x and memory by up to 35%,
advancing the deployment of efficient AIF agents for real-time and embedded
applications.

</details>


### [293] [The Interpretability Analysis of the Model Can Bring Improvements to the Text-to-SQL Task](https://arxiv.org/abs/2508.13178)
*Cong Zhang*

Main category: cs.AI

TL;DR: 제안된 CESQL 모델은 WHERE 절 조건 추론에서 모델 해석성 분석과 실행(실행-유도) 전략을 결합하고 필터·논리 상관관계 보정 및 모델 퓨전을 더해 조건 예측 성능을 크게 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 텍스트→SQL 모델의 기초 역량과 일반화 능력을 실무 환경에서 향상시키고, 특히 WHERE 절의 조건 값 예측에서 테이블 열 데이터 의존도와 수작업 레이블링 의존도를 줄이려 함.

Method: 모델 해석성(interpretability) 분석을 통해 내부 동작을 파악하고, 실행-유도(execution-guided) 전략으로 WHERE 절 의미를 검증·교정한다. 여기에 필터링 조정, 논리적 상관관계 정제, 그리고 여러 모델의 퓨전을 결합해 ‘CESQL’이라는 조건 향상 모델을 설계·적용함.

Result: 단일 테이블 질의 대표 데이터셋인 WikiSQL에서 예측 정확도를 크게 향상시켰으며, WHERE 절 조건 값 예측 시 조건 열의 데이터에 대한 의존도를 줄이고 수작업 레이블의 영향을 회피함.

Conclusion: 기본 데이터베이스 질의 처리 정확도를 개선함으로써 복잡 쿼리나 비정형(real-world) 데이터 시나리오 처리 연구에 새로운 관점을 제공할 수 있다.

Abstract: To elevate the foundational capabilities and generalization prowess of the
text-to-SQL model in real-world applications, we integrate model
interpretability analysis with execution-guided strategy for semantic parsing
of WHERE clauses in SQL queries. Furthermore, we augment this approach with
filtering adjustments, logical correlation refinements, and model fusion,
culminating in the design of the CESQL model that facilitates conditional
enhancement. Our model excels on the WikiSQL dataset, which is emblematic of
single-table database query tasks, markedly boosting the accuracy of prediction
outcomes. When predicting conditional values in WHERE clauses, we have not only
minimized our dependence on data within the condition columns of tables but
also circumvented the impact of manually labeled training data. Our hope is
that this endeavor to enhance accuracy in processing basic database queries
will offer fresh perspectives for research into handling complex queries and
scenarios featuring irregular data in real-world database environments.

</details>


### [294] [Search-Time Data Contamination](https://arxiv.org/abs/2508.13180)
*Ziwen Han,Meher Mankikar,Julian Michael,Zifan Wang*

Main category: cs.AI

TL;DR: Search-time contamination (STC): search-based LLM agents can retrieve evaluation datasets (or near-duplicates) from the web (notably HuggingFace), allowing them to copy answers instead of reasoning. On three benchmarks (HLE, SimpleQA, GPQA) ~3% of questions had direct leaks; blocking HuggingFace reduced accuracy on the contaminated subset by ~15%. Authors run ablations, find other public sources may also cause STC, release logs, and propose best practices to preserve benchmark validity.


<details>
  <summary>Details</summary>
Motivation: Ensure validity of evaluations for search-enabled LLM agents by identifying and quantifying a novel leakage mode (STC) where retrieval surfaces test data and answers, thus inflating performance and shortening benchmark lifespan.

Method: Analyze logs of search-based LLM agents that use tools to query online sources; identify retrieved sources that contain test questions/answers (esp. HuggingFace); quantify contamination rate across three benchmarks; perform intervention (block HuggingFace) and ablation experiments; release full experiment logs.

Result: Approximately 3% of questions across HLE, SimpleQA, and GPQA had direct matches on HuggingFace enabling copying. After blocking HuggingFace, accuracy on the contaminated subset dropped about 15%. Ablations indicate other public datasets/sources can also cause STC.

Conclusion: STC is a meaningful threat to benchmark integrity for search-based agents. The paper recommends best practices for benchmark design and reporting, and provides logs to facilitate auditing and trustworthy evaluation.

Abstract: Data contamination refers to the leakage of evaluation data into model
training data, resulting in overfitting to supposedly held-out test sets and
compromising test validity. We identify an analogous issue, search-time
contamination (STC), in evaluating search-based LLM agents which use tools to
gather information from online sources when answering user queries. STC occurs
when the retrieval step surfaces a source containing the test question (or a
near-duplicate) alongside its answer, enabling agents to copy rather than
genuinely infer or reason, undermining benchmark integrity. We find that
HuggingFace, an online platform hosting evaluation datasets, appears among
retrieved sources in search based agent logs. Consequently, agents often
explicitly acknowledge discovering question answer pairs from HuggingFace
within their reasoning chains. On three commonly used capability benchmarks:
Humanity's Last Exam (HLE), SimpleQA, and GPQA, we demonstrate that for
approximately 3% of questions, search-based agents directly find the datasets
with ground truth labels on HuggingFace. When millions of evaluation queries
target the same benchmark, even small, repeated leaks can accelerate the
benchmark's obsolescence, shortening its intended lifecycle. After HuggingFace
is blocked, we observe a drop in accuracy on the contaminated subset of
approximately 15%. We further show through ablation experiments that publicly
accessible evaluation datasets on HuggingFace may not be the sole source of
STC. To this end, we conclude by proposing best practices for benchmark design
and result reporting to address this novel form of leakage and ensure
trustworthy evaluation of search-based LLM agents. To facilitate the auditing
of evaluation results, we also publicly release the complete logs from our
experiments.

</details>


### [295] [QuickMerge++: Fast Token Merging with Autoregressive Prior](https://arxiv.org/abs/2508.13204)
*Dong Liu,Yanxuan Yu*

Main category: cs.AI

TL;DR: QuickMerge는 어텐션 노름(attention norm) 기반의 동적 토큰 선택과 엔트로피 기반 예산 추정기(entropy-based budget estimator), 그리고 병합된 토큰 시퀀스에 대해 학습된 경량 트랜스포머 프라이어(transformer prior)를 결합해 자동회귀(next-token) 생성에서 토큰 수를 크게 줄이면서 성능을 유지하거나 향상시키는 토큰 병합 프레임워크입니다.


<details>
  <summary>Details</summary>
Motivation: 생성 모델이 대규모 입력(언어, 비전, 비디오)으로 확장됨에 따라 토큰 수준 계산 비용이 주요 병목으로 작용합니다. 기존 토큰 선택 방법들은 정적이거나 모달리티별 특화, 또는 자동회귀 생성과 호환되지 않는 경우가 많아 실용적 제약이 있습니다.

Method: QuickMerge는 어텐션 노름 크기로 토큰의 의미적 중요도를 동적으로 평가하고, 엔트로피 기반 예산 추정기로 각 단계에서 유지할 토큰 수를 결정합니다. 자동회귀 호환성을 위해 병합된 토큰 시퀀스 위에 경량 트랜스포머 프라이어를 학습시켜 AR 정렬을 보장합니다.

Result: 다중 모달리티 도메인에서 계산-정확도 트레이드오프가 일관되게 개선되었으며, 토큰 수를 크게 줄이면서도 학습된 토크나이저와 고정 패치 기반 방법들보다 동등하거나 우수한 성능을 달성했습니다.

Conclusion: 의미적 중요도 추정, 유연한 토큰 예산, 자동회귀 정렬을 결합한 QuickMerge는 다음 토큰 예측에서 더 적은 토큰으로 정확한 생성을 가능하게 하는 실용적이고 효율적인 접근법임을 제시합니다.

Abstract: As generative models scale to larger inputs across language, vision, and
video domains, the cost of token-level computation has become a key bottleneck.
While prior work suggests that only a subset of tokens significantly influence
downstream predictions, most token selection methods are static,
modality-specific, or incompatible with autoregressive generation. In this
paper, we propose QuickMerge, a lightweight token merging framework designed
for efficient next-token prediction.
  QuickMerge dynamically selects a reduced number of tokens based on attention
norm magnitude, guided by an entropy-based budget estimator. To preserve
autoregressive compatibility, we introduce a lightweight transformer prior
trained over the merged token sequence. By combining semantic salience
estimation, flexible token budgets, and AR alignment, QuickMerge enables
accurate generation with fewer tokens.
  We evaluate QuickMerge across multi-modality domains, demonstrating
consistent improvements in compute-accuracy tradeoffs. Specifically, QuickMerge
reduces token counts sustantially while matching as well as exceeding the
performance of learned tokenizers and fixed-patch baselines.

</details>


### [296] [AI sustains higher strategic tension than humans in chess](https://arxiv.org/abs/2508.13213)
*Adamo Cerioli,Edward D. Lee,Vito D. P. Servedio*

Main category: cs.AI

TL;DR: 체스에서 ‘전략적 긴장’(piece-to-piece 상호작용 네트워크로 측정)을 도입해 인간대결과 AI대결의 동역학을 비교함. 경쟁력 높은 AI는 엘리트 인간보다 더 오랜 기간 높은 긴장을 유지하며, AI 알고리즘 복잡도와 인간의 엘로 수준(약 1600, 2300)에서 누적 긴장이 급증함.


<details>
  <summary>Details</summary>
Motivation: 즉시적 기회와 장기 목표 사이의 균형(전략적 긴장)을 정량화해 인간과 AI의 의사결정 차이를 체계적으로 분석하려는 목적.

Method: 체스 보드의 기물 간 상호작용을 네트워크 기반 메트릭으로 정의·측정하고, 게임 진행에 따른 메트릭 변화(동역학)를 인간 대 인간과 AI 대 AI 게임에서 비교 분석.

Result: 상위 경쟁 AI는 장기간 높은 전략적 긴장을 유지함. AI의 누적 긴장은 알고리즘 복잡도와 함께 변하며, 인간의 경우 누적 긴장이 약 1600 Elo와 2300 Elo 근처에서 급격히 증가함. AI는 공격·방어가 균형된 상호연결된 포지션을 더 오래 허용하는 반면, 인간은 긴장과 복잡도를 제한하는 경향이 있음.

Conclusion: 인간의 인지적 한계나 적응적 전략이 긴장 수준을 제한할 수 있으며, AI의 높은 긴장 지속은 복잡 전략 환경에서의 AI 활용에 대한 시사점을 제공함.

Abstract: Strategic decision-making involves managing the tension between immediate
opportunities and long-term objectives. We study this trade-off in chess by
characterizing and comparing dynamics between human vs human and AI vs AI
games. We propose a network-based metric of piece-to-piece interaction to
quantify the ongoing strategic tension on the board. Its evolution in games
reveals that the most competitive AI players sustain higher levels of strategic
tension for longer durations than elite human players. Cumulative tension
varies with algorithmic complexity for AI and correspondingly in human-played
games increases abruptly with expertise at about 1600 Elo and again at 2300
Elo. The profiles reveal different approaches. Highly competitive AI tolerates
interconnected positions balanced between offensive and defensive tactics over
long periods. Human play, in contrast, limits tension and game complexity,
which may reflect cognitive limitations and adaptive strategies. The difference
may have implications for AI usage in complex, strategic environments.

</details>


### [297] [CardAIc-Agents: A Multimodal Framework with Hierarchical Adaptation for Cardiac Care Support](https://arxiv.org/abs/2508.13256)
*Yuting Zhang,Karina V. Bunting,Asgher Champsi,Xiaoxia Wang,Wenqi Lu,Alexander Thorley,Sandeep S Hothi,Zhaowen Qiu,Dipak Kotecha,Jinming Duan*

Main category: cs.AI

TL;DR: CardAIc-Agents는 도메인 특화 도구와 업데이트 가능한 지식 기반을 통합한 다중모달 에이전트 프레임워크로, 적응형 계획 생성과 실행-피드백 기반의 단계적 업데이트, 다학제 토론 및 시각적 검토 패널을 통해 심혈관 질환 관련 다양한 임상 과제를 자율적으로 수행하고 기존 VLM 및 에이전트 시스템보다 효율성이 우수함을 보였다.


<details>
  <summary>Details</summary>
Motivation: 심혈관질환은 전 세계 사망 원인 1위이며 의료 인력 부족이 심하다. 기존 AI 적용은 (1) 도메인 도구 부재 상태의 프롬프트 기반 역할 지정, (2) 임상에 비해 경직된 순차적 워크플로우, (3) 정적 지식 기반과 지속 학습 불가, (4) 고정된 입력/출력 모달리티 등의 한계가 있어 실제 임상 적용에 제약이 있다.

Method: 다중모달 프레임워크 CardAIc-Agents 제안: CardiacRAG 에이전트는 업데이트 가능한 심장 지식에서 일반 계획을 생성하고, chief agent는 외부 도구들을 통합해 계획을 자율 실행해 결정을 도출한다. 복잡한 과제로 판단되면 실행 결과를 기반으로 계획을 단계적으로 갱신하는 stepwise update 전략을 사용한다. 다학제 토론 도구로 난이도 높은 사례 해석을 보조하고, 임상의 우려 시 시각적 검토 패널을 제공해 최종 검증을 지원한다.

Result: 세 개 데이터셋에 대한 실험에서 CardAIc-Agents는 주류 VLM, 최신 에이전트 시스템 및 파인튜닝된 VLM들과 비교해 효율성을 입증함(초록에 수치 미제공).

Conclusion: 도메인 도구 통합, 적응적 계획 갱신, 다학제 해석 및 시각적 검토를 결합한 CardAIc-Agents는 심혈관 질환의 조기 탐지·선별에서 임상 적용 가능성을 높이는 유망한 접근법이다.

Abstract: Cardiovascular diseases (CVDs) remain the foremost cause of mortality
worldwide, a burden worsened by a severe deficit of healthcare workers.
Artificial intelligence (AI) agents have shown potential to alleviate this gap
via automated early detection and proactive screening, yet their clinical
application remains limited by: 1) prompt-based clinical role assignment that
relies on intrinsic model capabilities without domain-specific tool support; or
2) rigid sequential workflows, whereas clinical care often requires adaptive
reasoning that orders specific tests and, based on their results, guides
personalised next steps; 3) general and static knowledge bases without
continuous learning capability; and 4) fixed unimodal or bimodal inputs and
lack of on-demand visual outputs when further clarification is needed. In
response, a multimodal framework, CardAIc-Agents, was proposed to augment
models with external tools and adaptively support diverse cardiac tasks.
Specifically, a CardiacRAG agent generated general plans from updatable cardiac
knowledge, while the chief agent integrated tools to autonomously execute these
plans and deliver decisions. To enable adaptive and case-specific
customization, a stepwise update strategy was proposed to dynamically refine
plans based on preceding execution results, once the task was assessed as
complex. In addition, a multidisciplinary discussion tool was introduced to
interpret challenging cases, thereby supporting further adaptation. When
clinicians raised concerns, visual review panels were provided to assist final
validation. Experiments across three datasets showed the efficiency of
CardAIc-Agents compared to mainstream Vision-Language Models (VLMs),
state-of-the-art agentic systems, and fine-tuned VLMs.

</details>


### [298] [Explicit v.s. Implicit Memory: Exploring Multi-hop Complex Reasoning Over Personalized Information](https://arxiv.org/abs/2508.13250)
*Zeyu Zhang,Yang Zhang,Haoran Tan,Rui Li,Xu Chen*

Main category: cs.AI

TL;DR: 이 논문은 개인화된 정보를 기반으로 한 다중 홉 추론(Multi-hop Personalized Reasoning, MPR) 과제를 정의하고, 데이터셋과 통합 평가 프레임워크를 구축한 뒤 다양한 명시적/암묵적 메모리 기법을 비교·분석하고 하이브리드 모델(HybridMem)을 제안해 성능 향상을 보였음을 보고한다.


<details>
  <summary>Details</summary>
Motivation: 현재 LLM 기반 에이전트의 메모리는 개인화와 단순 QA에 사용되어 왔지만, 실제 복잡한 작업은 많은 개인 정보에 대한 다중 홉 추론을 요구하며 기존 메모리 방식으로는 한계가 있다. 이를 해결하기 위해 메모리 메커니즘의 다중 홉 추론 성능을 체계적으로 평가할 필요가 있다.

Method: 다중 홉 개인화 추론(MPR) 과제를 명확히 정의하고, 해당 과제용 데이터셋과 통합 평가 프레임워크를 구축함. 명시적(explicit) 메모리와 암묵적(implicit) 메모리 기법들을 구현하고 비교 실험을 수행. 또한 두 패러다임을 결합한 하이브리드 방식(HybridMem)을 제안하여 각각의 한계를 보완함.

Result: 다양한 메모리 기법을 실험한 결과, 각 방식은 장단점이 존재했으며 하이브리드 접근(특히 제안된 HybridMem)은 성능 우수성을 보였다. 실험을 통해 제안 모델의 효과성을 입증함.

Conclusion: MPR 과제와 데이터셋, 평가 프레임워크는 개인화된 정보에서의 다중 홉 추론 성능을 체계적으로 연구할 수 있게 하며, 하이브리드 메모리 접근이 기존 명시적/암묵적 방법의 한계를 보완해 유망하다는 결론을 제시한다.

Abstract: In large language model-based agents, memory serves as a critical capability
for achieving personalization by storing and utilizing users' information.
Although some previous studies have adopted memory to implement user
personalization, they typically focus on preference alignment and simple
question-answering. However, in the real world, complex tasks often require
multi-hop reasoning on a large amount of user information, which poses
significant challenges for current memory approaches. To address this
limitation, we propose the multi-hop personalized reasoning task to explore how
different memory mechanisms perform in multi-hop reasoning over personalized
information. We explicitly define this task and construct a dataset along with
a unified evaluation framework. Then, we implement various explicit and
implicit memory methods and conduct comprehensive experiments. We evaluate
their performance on this task from multiple perspectives and analyze their
strengths and weaknesses. Besides, we explore hybrid approaches that combine
both paradigms and propose the HybridMem method to address their limitations.
We demonstrate the effectiveness of our proposed model through extensive
experiments. To benefit the research community, we release this project at
https://github.com/nuster1128/MPR.

</details>


### [299] ["DIVE" into Hydrogen Storage Materials Discovery with AI Agents](https://arxiv.org/abs/2508.13251)
*Di Zhang,Xue Jia,Tran Ba Hung,Seong Hoon Jang,Linda Zhang,Ryuhei Sato,Yusuke Hashimoto,Toyoto Sato,Kiyoe Konno,Shin-ichi Orimo,Hao Li*

Main category: cs.AI

TL;DR: DIVE 다중 에이전트 워크플로우는 논문 내 도표·그래픽에서 실험 데이터를 체계적으로 추출·구성하여 고체 수소 저장 재료 데이터베이스(약 30,000개 항목)를 구축하고, 추출 정확도를 상용 모델보다 10–15%, 오픈소스 모델보다 30% 이상 개선하며 2분 내 역설계로 미보고 조성식을 찾는다.


<details>
  <summary>Details</summary>
Motivation: 과학 문헌의 많은 유용한 재료 데이터가 비정형 그래픽(그림·표)에 갇혀 있어 LLM 기반 자동화된 재료 설계 에이전트 구축을 방해한다.

Method: DIVE라는 다중 에이전트 멀티스텝 워크플로우를 제시해 그래픽 요소를 읽고 실험 데이터를 구조화함. 상용·오픈소스 멀티모달 모델의 직접 추출과 비교 평가하고, 4,000편의 논문에서 30,000개 이상의 엔트리를 큐레이션하여 역설계 파이프라인에 통합.

Result: 그래픽 데이터 추출의 정확도 및 범위가 상용 모델 대비 10–15% 향상, 오픈소스 대비 30% 이상 향상. 구축된 데이터베이스를 이용해 2분 내에 이전에 보고되지 않은 수소 저장 조성들을 식별하는 역설계 워크플로우 시연.

Conclusion: 제안된 AI 워크플로우 및 에이전트 설계는 다양한 재료 분야로 전이 가능하며 AI 기반 재료 발견의 새로운 패러다임을 제공한다.

Abstract: Data-driven artificial intelligence (AI) approaches are fundamentally
transforming the discovery of new materials. Despite the unprecedented
availability of materials data in the scientific literature, much of this
information remains trapped in unstructured figures and tables, hindering the
construction of large language model (LLM)-based AI agent for automated
materials design. Here, we present the Descriptive Interpretation of Visual
Expression (DIVE) multi-agent workflow, which systematically reads and
organizes experimental data from graphical elements in scientific literatures.
We focus on solid-state hydrogen storage materials-a class of materials central
to future clean-energy technologies and demonstrate that DIVE markedly improves
the accuracy and coverage of data extraction compared to the direct extraction
by multimodal models, with gains of 10-15% over commercial models and over 30%
relative to open-source models. Building on a curated database of over 30,000
entries from 4,000 publications, we establish a rapid inverse design workflow
capable of identifying previously unreported hydrogen storage compositions in
two minutes. The proposed AI workflow and agent design are broadly transferable
across diverse materials, providing a paradigm for AI-driven materials
discovery.

</details>


### [300] [CardAIc-Agents: A Multimodal Framework with Hierarchical Adaptation for Cardiac Care Support](https://arxiv.org/abs/2508.13256)
*Yuting Zhang,Karina V. Bunting,Asgher Champsi,Xiaoxia Wang,Wenqi Lu,Alexander Thorley,Sandeep S Hothi,Zhaowen Qiu,Dipak Kotecha,Jinming Duan*

Main category: cs.AI

TL;DR: CardAIc-Agents는 도메인 특화 도구와 업데이트 가능한 지식 기반을 통합한 다중모달 에이전트 프레임워크로, 적응형 계획 생성과 실행-피드백 기반의 단계적 업데이트, 다학제 토론 및 시각적 검토 패널을 통해 심혈관 질환 관련 다양한 임상 과제를 자율적으로 수행하고 기존 VLM 및 에이전트 시스템보다 효율성이 우수함을 보였다.


<details>
  <summary>Details</summary>
Motivation: 심혈관질환은 전 세계 사망 원인 1위이며 의료 인력 부족이 심하다. 기존 AI 적용은 (1) 도메인 도구 부재 상태의 프롬프트 기반 역할 지정, (2) 임상에 비해 경직된 순차적 워크플로우, (3) 정적 지식 기반과 지속 학습 불가, (4) 고정된 입력/출력 모달리티 등의 한계가 있어 실제 임상 적용에 제약이 있다.

Method: 다중모달 프레임워크 CardAIc-Agents 제안: CardiacRAG 에이전트는 업데이트 가능한 심장 지식에서 일반 계획을 생성하고, chief agent는 외부 도구들을 통합해 계획을 자율 실행해 결정을 도출한다. 복잡한 과제로 판단되면 실행 결과를 기반으로 계획을 단계적으로 갱신하는 stepwise update 전략을 사용한다. 다학제 토론 도구로 난이도 높은 사례 해석을 보조하고, 임상의 우려 시 시각적 검토 패널을 제공해 최종 검증을 지원한다.

Result: 세 개 데이터셋에 대한 실험에서 CardAIc-Agents는 주류 VLM, 최신 에이전트 시스템 및 파인튜닝된 VLM들과 비교해 효율성을 입증함(초록에 수치 미제공).

Conclusion: 도메인 도구 통합, 적응적 계획 갱신, 다학제 해석 및 시각적 검토를 결합한 CardAIc-Agents는 심혈관 질환의 조기 탐지·선별에서 임상 적용 가능성을 높이는 유망한 접근법이다.

Abstract: Cardiovascular diseases (CVDs) remain the foremost cause of mortality
worldwide, a burden worsened by a severe deficit of healthcare workers.
Artificial intelligence (AI) agents have shown potential to alleviate this gap
via automated early detection and proactive screening, yet their clinical
application remains limited by: 1) prompt-based clinical role assignment that
relies on intrinsic model capabilities without domain-specific tool support; or
2) rigid sequential workflows, whereas clinical care often requires adaptive
reasoning that orders specific tests and, based on their results, guides
personalised next steps; 3) general and static knowledge bases without
continuous learning capability; and 4) fixed unimodal or bimodal inputs and
lack of on-demand visual outputs when further clarification is needed. In
response, a multimodal framework, CardAIc-Agents, was proposed to augment
models with external tools and adaptively support diverse cardiac tasks.
Specifically, a CardiacRAG agent generated general plans from updatable cardiac
knowledge, while the chief agent integrated tools to autonomously execute these
plans and deliver decisions. To enable adaptive and case-specific
customization, a stepwise update strategy was proposed to dynamically refine
plans based on preceding execution results, once the task was assessed as
complex. In addition, a multidisciplinary discussion tool was introduced to
interpret challenging cases, thereby supporting further adaptation. When
clinicians raised concerns, visual review panels were provided to assist final
validation. Experiments across three datasets showed the efficiency of
CardAIc-Agents compared to mainstream Vision-Language Models (VLMs),
state-of-the-art agentic systems, and fine-tuned VLMs.

</details>


### [301] [Towards Unified Multimodal Financial Forecasting: Integrating Sentiment Embeddings and Market Indicators via Cross-Modal Attention](https://arxiv.org/abs/2508.13327)
*Sarthak Khanna,Armin Berger,David Berghaus,Tobias Deusser,Lorenz Sparrenberg,Rafet Sifa*

Main category: cs.AI

TL;DR: STONK는 뉴스 임베딩과 수치 시장 지표를 결합한 멀티모달 프레임워크로, 일일 주가 변동 예측 정확도를 높이기 위해 텍스트 감성 정보와 수치 데이터를 융합한다. 특징 결합과 교차-모달 어텐션으로 정보를 통합하며, 백테스트에서 수치 전용 모델보다 우수한 성능을 보였다.


<details>
  <summary>Details</summary>
Motivation: 수치 지표만을 사용하는 기존 주가 예측 접근법은 뉴스와 같은 텍스트 기반 정보의 정서적·맥락적 신호를 반영하지 못해 예측력이 제한된다. 멀티모달 융합을 통해 두 유형의 정보를 통합하면 더 견고한 예측이 가능하다는 점을 보여주려 함.

Method: 뉴스 임베딩(감성 포함)과 수치 시장 지표를 임베딩한 뒤 특징(concatenation)과 교차-모달 어텐션 모듈을 통해 융합하는 단일 파이프라인(STONK)을 제안. 다양한 융합 전략과 모델 구성(예: 단순 결합 vs. 어텐션 기반)을 비교 평가하고 백테스트로 실거래 성능을 검증.

Result: 백테스트 결과 STONK는 수치 데이터만 사용하는 베이스라인 모델들보다 더 높은 예측 성능과 수익률을 보였다. 또한, 다양한 융합 전략 평가를 통해 교차-모달 어텐션 등이 우수한 성능을 보인다는 증거를 제시.

Conclusion: 감성 보강 뉴스 임베딩을 수치 시장 지표와 멀티모달로 융합하면 일일 주가 변동 예측이 개선되며, 제안한 STONK 파이프라인과 융합 전략 가이드는 확장 가능한 금융 예측 시스템 개발에 유용하다.

Abstract: We propose STONK (Stock Optimization using News Knowledge), a multimodal
framework integrating numerical market indicators with sentiment-enriched news
embeddings to improve daily stock-movement prediction. By combining numerical &
textual embeddings via feature concatenation and cross-modal attention, our
unified pipeline addresses limitations of isolated analyses. Backtesting shows
STONK outperforms numeric-only baselines. A comprehensive evaluation of fusion
strategies and model configurations offers evidence-based guidance for scalable
multimodal financial forecasting. Source code is available on GitHub

</details>


### [302] [HiFo-Prompt: Prompting with Hindsight and Foresight for LLM-based Automatic Heuristic Design](https://arxiv.org/abs/2508.13333)
*Chentong Chen,Mengyuan Zhong,Jianyong Sun,Ye Fan,Jialong Shi*

Main category: cs.AI

TL;DR: LLM 기반 자동 휴리스틱 설계(AHD)는 고정 연산자와 지식 축적 부족으로 제약을 받음. HiFo-Prompt는 Foresight와 Hindsight라는 두 가지 프롬프트 전략을 결합해 탐색-개선 균형을 동적으로 관리하고, 과거 성공적 휴리스틱에서 재사용 가능한 설계 원칙을 추출해 지속적 지식 베이스를 구축함. 이 접근은 기존 방법보다 더 나은 휴리스틱을 더 빠르게, 더 적은 쿼리로 생성함.


<details>
  <summary>Details</summary>
Motivation: 기존 LLM 기반 AHD는 정적 연산자 사용과 지식 축적 메커니즘 부재로 성능과 효율이 제한됨. 검색 과정에서 탐색과 착취의 균형을 동적으로 조절하고, 세대 간 성공 사례를 학습해 재사용 가능한 지식으로 축적할 필요가 있음.

Method: HiFo-Prompt는 두 가지 프롬프트 전략을 사용: (1) Foresight 프롬프트는 개체군(population) 동역학을 기반으로 탐색-착취를 적응적으로 조정해 검색을 안내함. (2) Hindsight 프롬프트는 과거 세대에서 성공한 휴리스틱을 증류해 근본적이고 재사용 가능한 설계 원칙으로 변환, 이를 지속적인 지식 베이스로 통합해 LLM이 경험에서 학습하게 함.

Result: 실험에서 HiFo-Prompt는 최신 LLM 기반 AHD 방법들보다 우수한 성능을 보였음: 더 높은 품질의 휴리스틱을 생성하고, 수렴 속도가 훨씬 빠르며 쿼리 효율성이 뛰어남.

Conclusion: 전향적·후향적 프롬프트의 결합을 통해 일시적 발견을 지속적 지식으로 변환함으로써 LLM 기반 AHD의 효과와 효율을 크게 향상시킴, 이는 EC 프레임워크 내에서 자동화된 휴리스틱 설계의 실용성을 높임.

Abstract: LLM-based Automatic Heuristic Design (AHD) within Evolutionary Computation
(EC) frameworks has shown promising results. However, its effectiveness is
hindered by the use of static operators and the lack of knowledge accumulation
mechanisms. We introduce HiFo-Prompt, a framework that guides LLMs with two
synergistic prompting strategies: Foresight and Hindsight. Foresight-based
prompts adaptively steer the search based on population dynamics, managing the
exploration-exploitation trade-off. In addition, hindsight-based prompts mimic
human expertise by distilling successful heuristics from past generations into
fundamental, reusable design principles. This dual mechanism transforms
transient discoveries into a persistent knowledge base, enabling the LLM to
learn from its own experience. Empirical results demonstrate that HiFo-Prompt
significantly outperforms state-of-the-art LLM-based AHD methods, generating
higher-quality heuristics while achieving substantially faster convergence and
superior query efficiency.

</details>


### [303] [LOOP: A Plug-and-Play Neuro-Symbolic Framework for Enhancing Planning in Autonomous Systems](https://arxiv.org/abs/2508.13371)
*Ronit Virwani,Ruchika Suryawanshi*

Main category: cs.AI

TL;DR: LOOP는 신경망과 심볼릭 플래너가 반복적으로 대화하며 계획을 생성·수정하는 신경-심볼릭 프레임워크다. 13개의 신경적 모듈(예: GNN, 다중 에이전트 검증, 계층적 분해, 인과 메모리)을 통합해 PDDL을 생성하고 심볼릭 피드백으로 반복 정제하며 실행 기록으로 인과 지식을 축적한다. IPC 벤치마크 6개 도메인에서 85.8% 성공률을 기록해 기존 LLM 기반 방법들보다 우수하다.


<details>
  <summary>Details</summary>
Motivation: 현대 자율시스템에서 계획 오류는 치명적이다. 순수 신경망 기반 방법은 전제조건 누락·목표 불일치·환각 문제를 보이고, 전통적 심볼릭 플래너는 자연어 이해 및 유연성에서 한계가 있다. 기존 신경-심볼릭은 일회성 번역에 그쳐 협업 개선 기회를 놓친다.

Method: 신경·심볼릭 컴포넌트가 반복적으로 상호작용하는 대화형 프로세스를 제안한다. 13개의 신경적 기능(공간관계용 GNN, 다중 에이전트 합의 검증, 계층적 작업 분해, 성공/실패로부터 학습하는 인과 메모리 등)을 결합하여 자연어에서 PDDL을 생성하고, 심볼릭 플래너의 피드백을 받아 PDDL을 점진적으로 수정·정제하며 실행 트레이스로 인과 지식을 구축한다.

Result: IPC 표준 벤치마크 6개 도메인에서 성공률 85.8%를 달성(비교: LLM+P 55.0%, LLM-as-Planner 19.2%, Tree-of-Thoughts 3.3%).

Conclusion: 신경망과 심볼릭 추론기의 성능 차이가 아니라, 두 구성요소가 전체 과정에서 실제로 '대화'하도록 설계하는 것이 신뢰할 수 있는 계획의 핵심이다. LOOP는 신경-심볼릭 협업을 통한 신뢰성 높은 자율계획의 실용적 설계도를 제시한다.

Abstract: Planning is one of the most critical tasks in autonomous systems, where even
a small error can lead to major failures or million-dollar losses. Current
state-of-the-art neural planning approaches struggle with complex domains,
producing plans with missing preconditions, inconsistent goals, and
hallucinations. While classical planners provide logical guarantees, they lack
the flexibility and natural language understanding capabilities needed for
modern autonomous systems. Existing neuro-symbolic approaches use one-shot
translation from natural language to formal plans, missing the opportunity for
neural and symbolic components to work and refine solutions together. To
address this gap, we develop LOOP -- a novel neuro-symbolic planning framework
that treats planning as an iterative conversation between neural and symbolic
components rather than simple translation. LOOP integrates 13 coordinated
neural features including graph neural networks for spatial relationships,
multi-agent validation for consensus-based correctness, hierarchical
decomposition for complex task management, and causal memory that learns from
both successes and failures. Unlike existing approaches, LOOP generates PDDL
specifications, refines them iteratively based on symbolic feedback, and builds
a causal knowledge base from execution traces. LOOP was evaluated on six
standard IPC benchmark domains, where it achieved 85.8% success rate compared
to LLM+P (55.0%), LLM-as-Planner (19.2%), and Tree-of-Thoughts (3.3%). This
work shows that the key to reliable planning is not in choosing between neural
networks or symbolic reasoners but it lies in making them actually ``talk'' to
each other during the entire process. LOOP provides a thorough blueprint for
building autonomous systems that can finally be trusted with critical
real-world applications.

</details>


### [304] [SPANER: Shared Prompt Aligner for Multimodal Semantic Representation](https://arxiv.org/abs/2508.13387)
*Thye Shan Ng,Caren Soyeon Han,Eun-Jung Holden*

Main category: cs.AI

TL;DR: SPANER은 공유 프롬프트를 이용해 다양한 모달리티 입력을 단일 의미 공간으로 정렬하는 모달리티-중립 PEFT 프레임워크로, 적은 샷의 검색 성능을 유지하면서 임베딩의 의미적 일관성을 높인다.


<details>
  <summary>Details</summary>
Motivation: 기존의 멀티모달 PEFT 연구들은 하위 작업 성능 향상에 집중했지만, 멀티모달 임베딩 공간의 구조적 정렬은 무시하여 모달리티별 표현이 고립되고 교차-모달 일반화가 제한된다.

Method: Shared Prompt AligNER(SPANER)는 모든 모달리티에서 공유되는 프롬프트를 개념적 앵커로 사용해 의미적으로 관련된 인스턴스들이 모달리티와 무관하게 공간적으로 수렴하도록 학습한다. 설계상 확장 가능하여 오디오 등 추가 모달리티를 핵심 구조 변경 없이 통합할 수 있다.

Result: 비전-언어 및 오디오-비주얼 벤치마크에서 포괄적 실험을 통해 SPANER는 경쟁력 있는 few-shot 검색 성능을 보였고, 학습된 임베딩 공간에서 높은 의미적 응집도를 유지했다.

Conclusion: 어댑터 가중치 조정만이 아니라 임베딩 구조의 정렬이 멀티모달 학습의 확장성과 교차-모달 일반화에 중요하며, 공유 프롬프트 방식이 효과적인 해결책임을 시사한다.

Abstract: Recent advances in multimodal Parameter-Efficient Fine-Tuning (PEFT) have
significantly improved performance on downstream tasks such as few-shot
retrieval. However, most existing approaches focus on task-specific gains while
neglecting the structure of the multimodal embedding space. As a result,
modality-specific representations often remain isolated, limiting cross-modal
generalisation. In this work, we introduce Shared Prompt AligNER (SPANER), a
modality-agnostic PEFT framework designed to embed inputs from diverse
modalities into a unified semantic space. At its core, SPANER employs a shared
prompt mechanism that acts as a conceptual anchor, enabling semantically
related instances to converge spatially regardless of modality. This shared
prompt design is inherently extensible, supporting the seamless integration of
additional modalities, such as audio, without altering the core architecture.
Through comprehensive experiments across vision-language and audio-visual
benchmarks, SPANER demonstrates competitive few-shot retrieval performance
while preserving high semantic coherence in the learned embedding space. Our
results highlight the importance of aligning embedding structures, rather than
merely tuning adapter weights, for scalable multimodal learning.

</details>


### [305] [TASER: Table Agents for Schema-guided Extraction and Recommendation](https://arxiv.org/abs/2508.13404)
*Nicole Cho,Kirsty Fielding,William Watson,Sumitra Ganesh,Manuela Veloso*

Main category: cs.AI

TL;DR: TASER은 복잡하고 비구조화된 다페이지 금융 테이블을 스키마 기반으로 지속적으로 학습하는 에이전트형 추출 시스템으로, 테이블 검출·분류·추출·스키마 권고를 에이전트들이 수행하고 Recommender Agent가 스키마 수정과 최종 권고를 결정하여 기존 모델보다 성능을 높이고 대규모 실제 금융 테이블 데이터셋(TASERTab)을 공개한다.


<details>
  <summary>Details</summary>
Motivation: 실제 금융 문서의 테이블은 파편화되고 다페이지·이종적이며 경계 박스가 거의 없고 행 개수가 매우 많은 등 전형적 테이블 추출 기법이 취약한 특성을 지님. 이러한 현실적 난제를 해결하기 위한 강건한 추출 방법이 필요함.

Method: 스키마로 초기화된 복수의 테이블 에이전트(검출, 분류, 추출, 권고)가 작동하는 에이전트형 시스템 TASER를 제안. Recommender Agent가 출력물을 검토해 스키마 개정안을 제안·결정하고, 이를 통해 지속적 학습(스키마 권고 ↔ 적용)을 수행. 대규모 수작업 라벨링(22,584페이지, 3,213테이블, 28M 토큰)을 통해 학습·평가함.

Result: TASER는 Table Transformer 대비 테이블 검출 성능에서 +10.1% 향상. 배치 사이즈 증가는 액션 가능한 스키마 권고를 104.3% 더 만들어내며, 결과적으로 추출된 보유내역이 9.8% 증가. TASERTab 데이터셋(22,584페이지, $731.7B 상당의 보유 등) 공개.

Conclusion: 에이전트 기반 스키마 유도 추출과 연속 학습 프로세스는 실제 금융 테이블의 강건한 이해·정규화에 유망하며, 공개 데이터셋이 향후 연구를 촉진할 것임.

Abstract: Real-world financial documents report essential information about an entity's
financial holdings that can span millions of different financial instrument
types. Yet, these details are often buried in messy, multi-page, fragmented
tables - for example, 99.4% of the tables in our dataset have no bounding boxes
with the maximum number of rows amounting to 426 per table across 44 pages. To
tackle these unique challenges from real-world tables, we present a
continuously learning, agentic table extraction system, TASER (Table Agents for
Schema-guided Extraction and Recommendation) that extracts highly unstructured,
multi-page, heterogeneous tables into normalized, schema-conforming outputs.
Our table agents execute on table detection, classification, extraction, and
recommendations by leveraging an initial schema. Then, our Recommender Agent
reviews the outputs, recommends schema revisions, and decides on the final
recommendations, enabling TASER to outperform existing table detection models
such as Table Transformer by 10.1%. Within this continuous learning process, we
highlight that larger batch sizes result in a 104.3% increase in schema
recommendations that are actionable and utilized, resulting in a 9.8% increase
in extracted holdings - highlighting the importance of a continuous learning
process. To train TASER, we have manually labeled 22,584 pages (28,150,449
tokens), 3,213 tables for $731,685,511,687 of holdings culminating in one of
the first real financial table datasets. We release our dataset TASERTab to
enable the research community to access real-world financial tables and
outputs. Our results highlight the promise of agentic, schema-guided extraction
systems for robust understanding of real-world financial tables.

</details>


### [306] [Explicit v.s. Implicit Memory: Exploring Multi-hop Complex Reasoning Over Personalized Information](https://arxiv.org/abs/2508.13250)
*Zeyu Zhang,Yang Zhang,Haoran Tan,Rui Li,Xu Chen*

Main category: cs.AI

TL;DR: 이 논문은 개인화된 정보를 기반으로 한 다중 홉 추론(Multi-hop Personalized Reasoning, MPR) 과제를 정의하고, 데이터셋과 통합 평가 프레임워크를 구축한 뒤 다양한 명시적/암묵적 메모리 기법을 비교·분석하고 하이브리드 모델(HybridMem)을 제안해 성능 향상을 보였음을 보고한다.


<details>
  <summary>Details</summary>
Motivation: 현재 LLM 기반 에이전트의 메모리는 개인화와 단순 QA에 사용되어 왔지만, 실제 복잡한 작업은 많은 개인 정보에 대한 다중 홉 추론을 요구하며 기존 메모리 방식으로는 한계가 있다. 이를 해결하기 위해 메모리 메커니즘의 다중 홉 추론 성능을 체계적으로 평가할 필요가 있다.

Method: 다중 홉 개인화 추론(MPR) 과제를 명확히 정의하고, 해당 과제용 데이터셋과 통합 평가 프레임워크를 구축함. 명시적(explicit) 메모리와 암묵적(implicit) 메모리 기법들을 구현하고 비교 실험을 수행. 또한 두 패러다임을 결합한 하이브리드 방식(HybridMem)을 제안하여 각각의 한계를 보완함.

Result: 다양한 메모리 기법을 실험한 결과, 각 방식은 장단점이 존재했으며 하이브리드 접근(특히 제안된 HybridMem)은 성능 우수성을 보였다. 실험을 통해 제안 모델의 효과성을 입증함.

Conclusion: MPR 과제와 데이터셋, 평가 프레임워크는 개인화된 정보에서의 다중 홉 추론 성능을 체계적으로 연구할 수 있게 하며, 하이브리드 메모리 접근이 기존 명시적/암묵적 방법의 한계를 보완해 유망하다는 결론을 제시한다.

Abstract: In large language model-based agents, memory serves as a critical capability
for achieving personalization by storing and utilizing users' information.
Although some previous studies have adopted memory to implement user
personalization, they typically focus on preference alignment and simple
question-answering. However, in the real world, complex tasks often require
multi-hop reasoning on a large amount of user information, which poses
significant challenges for current memory approaches. To address this
limitation, we propose the multi-hop personalized reasoning task to explore how
different memory mechanisms perform in multi-hop reasoning over personalized
information. We explicitly define this task and construct a dataset along with
a unified evaluation framework. Then, we implement various explicit and
implicit memory methods and conduct comprehensive experiments. We evaluate
their performance on this task from multiple perspectives and analyze their
strengths and weaknesses. Besides, we explore hybrid approaches that combine
both paradigms and propose the HybridMem method to address their limitations.
We demonstrate the effectiveness of our proposed model through extensive
experiments. To benefit the research community, we release this project at
https://github.com/nuster1128/MPR.

</details>


### [307] [Virtuous Machines: Towards Artificial General Science](https://arxiv.org/abs/2508.13421)
*Gabrielle Wehr,Reuben Rideaux,Amaya J. Fox,David R. Lightfoot,Jason Tangen,Jason B. Mattingley,Shane E. Ehrhardt*

Main category: cs.AI

TL;DR: 에이전트형(도메인 비종속) AI 시스템이 가설 생성부터 데이터 수집·분석·논문 작성까지 독립적으로 수행하여 시각 작업기억, 정신회전, 심상 생생도에 대한 세 가지 심리학 실험을 설계·실행하고 온라인 데이터(288명)를 수집한 뒤 분석 파이프라인을 구축해 완성된 원고를 산출했다. 이 시스템은 경험 연구자에 준하는 방법론적 엄밀성과 이론적 추론 능력을 보였으나 개념적 미세함과 이론 해석에서는 한계가 있었다.


<details>
  <summary>Details</summary>
Motivation: 급증하는 과학 문헌과 고도화된 도메인 분화로 연구자가 학제간 지식을 종합하고 통합 이론을 개발하는 역량이 제한되므로, 보다 범용적인 AI가 과학적 발견을 가속·확장할 수 있는지 탐구하려는 필요성.

Method: 도메인 비종속의 에이전트형 AI가 독자적으로 연구 워크플로우를 수행: 가설 생성, 실험 설계, 실제 온라인 데이터 수집(새로운 실험, 참가자 288명), 8시간 이상 연속 코딩을 포함한 분석 파이프라인 개발, 그리고 논문 작성까지 전 과정 자율 수행.

Result: AI가 비사소한 연구를 독립적으로 완성함. 세 가지 심리학 연구가 설계·실행되어 데이터가 수집·분석되었고 완결된 원고가 산출되었다. 방법론적 엄밀성과 이론적 추론에서 경험적 연구자와 비교 가능한 성과를 보였으나 개념적 미세함·이론 해석에서는 제한적.

Conclusion: 현실 실험을 통해 가설을 검증할 수 있는 체현형(embodied) AI로의 진전 가능성을 시사하며, 인간의 인지·자원 한계로 미탐색된 과학적 영역을 자율적으로 탐색·확장할 잠재력이 있다. 동시에 과학적 이해의 본질과 공로 귀속 등 윤리·사회적 문제를 제기한다.

Abstract: Artificial intelligence systems are transforming scientific discovery by
accelerating specific research tasks, from protein structure prediction to
materials design, yet remain confined to narrow domains requiring substantial
human oversight. The exponential growth of scientific literature and increasing
domain specialisation constrain researchers' capacity to synthesise knowledge
across disciplines and develop unifying theories, motivating exploration of
more general-purpose AI systems for science. Here we show that a
domain-agnostic, agentic AI system can independently navigate the scientific
workflow - from hypothesis generation through data collection to manuscript
preparation. The system autonomously designed and executed three psychological
studies on visual working memory, mental rotation, and imagery vividness,
executed one new online data collection with 288 participants, developed
analysis pipelines through 8-hour+ continuous coding sessions, and produced
completed manuscripts. The results demonstrate the capability of AI scientific
discovery pipelines to conduct non-trivial research with theoretical reasoning
and methodological rigour comparable to experienced researchers, though with
limitations in conceptual nuance and theoretical interpretation. This is a step
toward embodied AI that can test hypotheses through real-world experiments,
accelerating discovery by autonomously exploring regions of scientific space
that human cognitive and resource constraints might otherwise leave unexplored.
It raises important questions about the nature of scientific understanding and
the attribution of scientific credit.

</details>


### [308] [TASER: Table Agents for Schema-guided Extraction and Recommendation](https://arxiv.org/abs/2508.13404)
*Nicole Cho,Kirsty Fielding,William Watson,Sumitra Ganesh,Manuela Veloso*

Main category: cs.AI

TL;DR: TASER은 복잡하고 비구조화된 다페이지 금융 테이블을 스키마 기반으로 지속적으로 학습하는 에이전트형 추출 시스템으로, 테이블 검출·분류·추출·스키마 권고를 에이전트들이 수행하고 Recommender Agent가 스키마 수정과 최종 권고를 결정하여 기존 모델보다 성능을 높이고 대규모 실제 금융 테이블 데이터셋(TASERTab)을 공개한다.


<details>
  <summary>Details</summary>
Motivation: 실제 금융 문서의 테이블은 파편화되고 다페이지·이종적이며 경계 박스가 거의 없고 행 개수가 매우 많은 등 전형적 테이블 추출 기법이 취약한 특성을 지님. 이러한 현실적 난제를 해결하기 위한 강건한 추출 방법이 필요함.

Method: 스키마로 초기화된 복수의 테이블 에이전트(검출, 분류, 추출, 권고)가 작동하는 에이전트형 시스템 TASER를 제안. Recommender Agent가 출력물을 검토해 스키마 개정안을 제안·결정하고, 이를 통해 지속적 학습(스키마 권고 ↔ 적용)을 수행. 대규모 수작업 라벨링(22,584페이지, 3,213테이블, 28M 토큰)을 통해 학습·평가함.

Result: TASER는 Table Transformer 대비 테이블 검출 성능에서 +10.1% 향상. 배치 사이즈 증가는 액션 가능한 스키마 권고를 104.3% 더 만들어내며, 결과적으로 추출된 보유내역이 9.8% 증가. TASERTab 데이터셋(22,584페이지, $731.7B 상당의 보유 등) 공개.

Conclusion: 에이전트 기반 스키마 유도 추출과 연속 학습 프로세스는 실제 금융 테이블의 강건한 이해·정규화에 유망하며, 공개 데이터셋이 향후 연구를 촉진할 것임.

Abstract: Real-world financial documents report essential information about an entity's
financial holdings that can span millions of different financial instrument
types. Yet, these details are often buried in messy, multi-page, fragmented
tables - for example, 99.4% of the tables in our dataset have no bounding boxes
with the maximum number of rows amounting to 426 per table across 44 pages. To
tackle these unique challenges from real-world tables, we present a
continuously learning, agentic table extraction system, TASER (Table Agents for
Schema-guided Extraction and Recommendation) that extracts highly unstructured,
multi-page, heterogeneous tables into normalized, schema-conforming outputs.
Our table agents execute on table detection, classification, extraction, and
recommendations by leveraging an initial schema. Then, our Recommender Agent
reviews the outputs, recommends schema revisions, and decides on the final
recommendations, enabling TASER to outperform existing table detection models
such as Table Transformer by 10.1%. Within this continuous learning process, we
highlight that larger batch sizes result in a 104.3% increase in schema
recommendations that are actionable and utilized, resulting in a 9.8% increase
in extracted holdings - highlighting the importance of a continuous learning
process. To train TASER, we have manually labeled 22,584 pages (28,150,449
tokens), 3,213 tables for $731,685,511,687 of holdings culminating in one of
the first real financial table datasets. We release our dataset TASERTab to
enable the research community to access real-world financial tables and
outputs. Our results highlight the promise of agentic, schema-guided extraction
systems for robust understanding of real-world financial tables.

</details>


### [309] [STPFormer: A State-of-the-Art Pattern-Aware Spatio-Temporal Transformer for Traffic Forecasting](https://arxiv.org/abs/2508.13433)
*Jiayu Fang,Zhiqi Shao,S T Boris Choy,Junbin Gao*

Main category: cs.AI

TL;DR: STPFormer is a Spatio-Temporal Pattern-Aware Transformer that improves traffic forecasting by learning unified, interpretable representations via four modules (TPA, SSA, STGM, Attention Mixer), achieving state-of-the-art results on five real-world datasets.


<details>
  <summary>Details</summary>
Motivation: Traffic forecasting faces complex temporal dynamics, changing spatial relationships, and varied input formats. Existing Transformer-based models capture global dependencies but suffer from inflexible temporal encoding and weak fusion of spatial and temporal information.

Method: Introduce STPFormer with four modules: Temporal Position Aggregator (TPA) for pattern-aware temporal encoding, Spatial Sequence Aggregator (SSA) for sequential spatial modeling, Spatial-Temporal Graph Matching (STGM) for aligning spatial and temporal domains, and an Attention Mixer for multi-scale fusion, producing unified and interpretable spatio-temporal representations.

Result: On five real-world datasets STPFormer consistently attains new state-of-the-art forecasting accuracy. Ablation studies and visualizations show each module contributes positively and the model generalizes across datasets.

Conclusion: STPFormer addresses Transformer limitations in traffic forecasting by flexible temporal encoding and stronger space-time fusion, yielding interpretable, generalizable improvements over prior methods.

Abstract: Spatio-temporal traffic forecasting is challenging due to complex temporal
patterns, dynamic spatial structures, and diverse input formats. Although
Transformer-based models offer strong global modeling, they often struggle with
rigid temporal encoding and weak space-time fusion. We propose STPFormer, a
Spatio-Temporal Pattern-Aware Transformer that achieves state-of-the-art
performance via unified and interpretable representation learning. It
integrates four modules: Temporal Position Aggregator (TPA) for pattern-aware
temporal encoding, Spatial Sequence Aggregator (SSA) for sequential spatial
learning, Spatial-Temporal Graph Matching (STGM) for cross-domain alignment,
and an Attention Mixer for multi-scale fusion. Experiments on five real-world
datasets show that STPFormer consistently sets new SOTA results, with ablation
and visualizations confirming its effectiveness and generalizability.

</details>


### [310] [Discrete Optimization of Min-Max Violation and its Applications Across Computational Sciences](https://arxiv.org/abs/2508.13437)
*Cheikh Ahmed,Mahdi Mostajabdaveh,Samin Aref,Zirui Zhou*

Main category: cs.AI

TL;DR: Introduce Discrete Min-Max Violation (DMMV): a context-free discrete optimization that minimizes the maximum constraint violation. Provide mathematical definition and properties, and a GPU-accelerated heuristic exploiting those properties. Demonstrate on three applications (post-training quantization, discrete tomography, FIR filter design) with notable empirical gains (≈14% quantization improvement, 16% lower tomography error and 6× GPU speedup, ≈50% ripple reduction vs Gurobi). Code to be open-sourced.


<details>
  <summary>Details</summary>
Motivation: Many applications require worst-case performance guarantees and discrete assignments; a general, context-free formulation that minimizes the maximum violation can unify such problems and enable transferable solvers. Practical instance sizes require scalable heuristics leveraging hardware acceleration.

Method: Formally define DMMV and analyze its mathematical properties. Design a GPU-accelerated heuristic that leverages those properties to speed up search for assignments minimizing the maximum violation. Apply the heuristic to three distinct optimization problems as case studies.

Result: Heuristic outperforms or matches existing methods across three tasks: 14% average improvement over prior quantization methods (without outlier separation); 16% reduction in reconstruction error under uniform noise and 6× GPU speedup for discrete tomography; nearly 50% ripple reduction in FIR filter design compared to Gurobi. Demonstrates versatility and computational benefits.

Conclusion: DMMV is a useful, general formalism for worst-case discrete optimization problems. The proposed GPU-accelerated heuristic shows strong empirical performance across diverse applications. Open-source release aims to stimulate further research, though full assessment requires reading the full paper for algorithmic details, baselines, and limitations.

Abstract: We introduce the Discrete Min-Max Violation (DMMV) as a general optimization
problem which seeks an assignment of discrete values to variables that
minimizes the largest constraint violation. This context-free mathematical
formulation is applicable to a wide range of use cases that have worst-case
performance requirements. After defining the DMMV problem mathematically, we
explore its properties to establish a foundational understanding. To tackle
DMMV instance sizes of practical relevance, we develop a GPU-accelerated
heuristic that takes advantage of the mathematical properties of DMMV for
speeding up the solution process. We demonstrate the versatile applicability of
our heuristic by solving three optimization problems as use cases: (1)
post-training quantization of language models, (2) discrete tomography, and (3)
Finite Impulse Response (FIR) filter design. In quantization without outlier
separation, our heuristic achieves 14% improvement on average over existing
methods. In discrete tomography, it reduces reconstruction error by 16% under
uniform noise and accelerates computations by a factor of 6 on GPU. For FIR
filter design, it nearly achieves 50% ripple reduction compared to using the
commercial integer optimization solver, Gurobi. Our comparative results point
to the benefits of studying DMMV as a context-free optimization problem and the
advantages that our proposed heuristic offers on three distinct problems. Our
GPU-accelerated heuristic will be made open-source to further stimulate
research on DMMV and its other applications. The code is available at
https://anonymous.4open.science/r/AMVM-5F3E/

</details>


### [311] [LM Agents May Fail to Act on Their Own Risk Knowledge](https://arxiv.org/abs/2508.13465)
*Yuzhi Tang,Tianxiao Li,Elizabeth Li,Chris J. Maddison,Honghua Dong,Yangjun Ruan*

Main category: cs.AI

TL;DR: LM 에이전트는 위험 지식을 잘 갖고 있으나 실제 실행 궤적에서는 그 지식을 적용하지 못해 위험한 행동을 수행한다. 저자들은 지식・식별・행동의 3단계 평가 프레임워크를 제시하고, 독립적 검증자(리스크 베리파이어)와 추상화기(abstractor)를 도입해 위험 실행을 55.3% 감소시켰다.


<details>
  <summary>Details</summary>
Motivation: LM 에이전트가 안전 비판 질문에는 '위험하다'고 답하지만, 실제 에이전트 역할에서 동일한 위험을 식별하거나 회피하지 못하는 간극(knowledge vs. execution gap)을 체계적으로 규명하고 개선책을 제시하기 위함.

Method: 에이전트 안전을 3가지 차원(1. 위험 지식, 2. 실행 궤적에서의 위험 식별, 3. 위험 행동 회피)으로 평가하는 프레임워크를 구축하고 다양한 모델(일반 대형언어모델 및 DeepSeek-R1 등)에 대해 실험. 관찰된 격차를 이용해, 실행 궤적을 추상화해 리스크를 더 잘 판별하는 abstractor와 에이전트의 제안을 독립적으로 비평하는 risk verifier를 설계·통합.

Result: 에이전트는 위험 지식 테스트에서 >98% 합격률을 보였으나 실제 시나리오에서 위험 식별은 >23% 포인트 하락, 위험 행동 회피는 <26% 합격률로 크게 저조했다. 제안한 검증자+추상화 시스템을 적용하면 위험 행동 실행을 55.3% 감소시켰다.

Conclusion: 단순히 모델 규모나 추론 자원을 늘리는 것만으로는 안전 문제가 해결되지 않으며, 독립적 검증 메커니즘과 추상화 처리가 에이전트 안전성을 실질적으로 개선할 수 있다.

Abstract: Language model (LM) agents have demonstrated significant potential for
automating real-world tasks, yet they pose a diverse array of potential, severe
risks in safety-critical scenarios. In this work, we identify a significant gap
between LM agents' risk awareness and safety execution abilities: while they
often answer "Yes" to queries like "Is executing `sudo rm -rf /*' dangerous?",
they will likely fail to identify such risks in instantiated trajectories or
even directly perform these risky actions when acting as agents. To
systematically investigate this, we develop a comprehensive evaluation
framework to examine agents' safety across three progressive dimensions: 1)
their knowledge about potential risks, 2) their ability to identify
corresponding risks in execution trajectories, and 3) their actual behaviors to
avoid executing these risky actions. Our evaluation reveals two critical
performance gaps that resemble the generator-validator gaps observed in LMs:
while agents demonstrate near-perfect risk knowledge ($>98\%$ pass rates), they
fail to apply this knowledge when identifying risks in actual scenarios (with
performance dropping by $>23\%$) and often still execute risky actions ($<26\%$
pass rates). Notably, this trend persists across more capable LMs as well as in
specialized reasoning models like DeepSeek-R1, indicating that simply scaling
model capabilities or inference compute does not inherently resolve safety
concerns. Instead, we take advantage of these observed gaps to develop a risk
verifier that independently critiques the proposed actions by agents, with an
abstractor that converts specific execution trajectories into abstract
descriptions where LMs can more effectively identify the risks. Our overall
system achieves a significant reduction of risky action execution by $55.3\%$
over vanilla-prompted agents.

</details>


### [312] [CrafterDojo: A Suite of Foundation Models for Building Open-Ended Embodied Agents in Crafter](https://arxiv.org/abs/2508.13530)
*Junyeong Park,Hyeonseo Cho,Sungjin Ahn*

Main category: cs.AI

TL;DR: CrafterDojo는 Crafter 환경을 위한 경량화된 파운데이션 모델과 도구 모음으로, Minecraft 유사 환경에서의 일반 목적 화신(embodied) 에이전트 연구를 빠르게 프로토타이핑할 수 있게 한다.


<details>
  <summary>Details</summary>
Motivation: Minecraft는 복잡성과 대규모 데이터가 있지만 느린 속도와 높은 엔지니어링 비용 때문에 빠른 실험에 부적합하다. Crafter는 경량 대안이지만 파운데이션 모델 부재로 한정된 과제에만 사용되어왔다. 이를 해결해 Crafter를 연구용 테스트베드로 활성화하려 함.

Method: CrafterDojo는 CrafterVPT(행동 프라이어), CrafterCLIP(비전-언어 정합), CrafterSteve-1(지시 수행) 등 세 가지 파운데이션 모델과 CrafterPlay, CrafterCaption 데이터셋 도구, 참고 에이전트 구현, 벤치마크 평가 및 오픈소스 코드베이스를 제공한다.

Result: CrafterDojo는 Crafter 환경에서의 프로토타이핑과 연구를 촉진하며, 다양한 행동, 시각-언어 정합 및 지시 수행 능력을 가진 모델들을 제시한다.

Conclusion: CrafterDojo는 Crafter를 Minecraft 유사, 경량 실험 플랫폼으로 개방하여 일반 목적 화신 에이전트 연구의 진입 장벽을 낮춘다.

Abstract: Developing general-purpose embodied agents is a core challenge in AI.
Minecraft provides rich complexity and internet-scale data, but its slow speed
and engineering overhead make it unsuitable for rapid prototyping. Crafter
offers a lightweight alternative that retains key challenges from Minecraft,
yet its use has remained limited to narrow tasks due to the absence of
foundation models that have driven progress in the Minecraft setting. In this
paper, we present CrafterDojo, a suite of foundation models and tools that
unlock the Crafter environment as a lightweight, prototyping-friendly, and
Minecraft-like testbed for general-purpose embodied agent research. CrafterDojo
addresses this by introducing CrafterVPT, CrafterCLIP, and CrafterSteve-1 for
behavior priors, vision-language grounding, and instruction following,
respectively. In addition, we provide toolkits for generating behavior and
caption datasets (CrafterPlay and CrafterCaption), reference agent
implementations, benchmark evaluations, and a complete open-source codebase.

</details>


### [313] [Toward Better EHR Reasoning in LLMs: Reinforcement Learning with Expert Attention Guidance](https://arxiv.org/abs/2508.13579)
*Yue Fang,Yuxin Guo,Jiaran Gao,Hongxin Ding,Xinke Jiang,Weibin Liao,Yongxin Xu,Yinghao Zhu,Zhibang Yang,Liantao Ma,Junfeng Zhao,Yasha Wang*

Main category: cs.AI

TL;DR: EAG-RL은 전문가 EHR 모델이 제공하는 중요 특징(attention)을 이용해 LLM의 EHR 추론 능력을 본질적으로 향상시키는 두 단계 학습 프레임워크입니다. 1) 전문가 안내 MCTS로 단계별 추론 궤적을 생성해 정책을 초기화하고, 2) 전문가-유도 주의(attention) 정렬을 목표로 강화학습으로 정책을 최적화합니다. 실제 EHR 데이터셋 두 곳에서 평균 14.62% 향상과 향상된 강건성·일반화 성능을 보고합니다.


<details>
  <summary>Details</summary>
Motivation: 기존 LLM은 의료 텍스트 이해에는 강하지만, 시계열적·고차원인 EHR 데이터 기반 예측에서는 성능이 떨어집니다. 지금까지의 하이브리드 접근(고정된 LLM을 priors로 사용하고 downstream DL로 예측)은 LLM 자체의 추론 능력을 개선하지 못하고 DL 모델의 일반화 한계를 승계합니다. 따라서 LLM의 내재적 EHR 추론 능력을 키우려는 동기가 제시됩니다.

Method: EAG-RL은 두 단계로 구성됩니다. 첫째, 전문가(태스크 특화 DL EHR 모델)가 안내하는 Monte Carlo Tree Search(MCTS)를 통해 고품질의 단계별(reasoning) 궤적을 생성하고 LLM 정책을 효과적으로 초기화합니다. 둘째, 생성된 정책을 기반으로 강화학습을 수행하되, 보상/목표는 LLM의 주의(attention)를 전문가 EHR 모델이 식별한 임상적으로 중요한 특징들과 정렬시키는 방향으로 설계합니다.

Result: 두 개의 실제 EHR 데이터셋에서 실험하여 LLM의 내재적 EHR 추론 능력이 평균 14.62% 향상됨을 보고합니다. 또한 피처 교란에 대한 강건성 및 보지 못한(미지) 임상 도메인으로의 일반화가 개선되었다고 주장합니다. 코드 공개 링크 제공.

Conclusion: 전문가 EHR 모델의 지식을 활용한 주의 정렬 기반의 MCTS+RL 학습은 LLM의 EHR 추론 능력을 본질적으로 향상시키며 실무적 임상 예측 태스크에 적용 가능성을 시사합니다.

Abstract: Improving large language models (LLMs) for electronic health record (EHR)
reasoning is essential for enabling accurate and generalizable clinical
predictions. While LLMs excel at medical text understanding, they underperform
on EHR-based prediction tasks due to challenges in modeling temporally
structured, high-dimensional data. Existing approaches often rely on hybrid
paradigms, where LLMs serve merely as frozen prior retrievers while downstream
deep learning (DL) models handle prediction, failing to improve the LLM's
intrinsic reasoning capacity and inheriting the generalization limitations of
DL models. To this end, we propose EAG-RL, a novel two-stage training framework
designed to intrinsically enhance LLMs' EHR reasoning ability through expert
attention guidance, where expert EHR models refer to task-specific DL models
trained on EHR data. Concretely, EAG-RL first constructs high-quality, stepwise
reasoning trajectories using expert-guided Monte Carlo Tree Search to
effectively initialize the LLM's policy. Then, EAG-RL further optimizes the
policy via reinforcement learning by aligning the LLM's attention with
clinically salient features identified by expert EHR models. Extensive
experiments on two real-world EHR datasets show that EAG-RL improves the
intrinsic EHR reasoning ability of LLMs by an average of 14.62%, while also
enhancing robustness to feature perturbations and generalization to unseen
clinical domains. These results demonstrate the practical potential of EAG-RL
for real-world deployment in clinical prediction tasks. Our code have been
available at https://github.com/devilran6/EAG-RL.

</details>


### [314] [Breaking the SFT Plateau: Multimodal Structured Reinforcement Learning for Chart-to-Code Generation](https://arxiv.org/abs/2508.13587)
*Lei Chen,Xuanle Zhao,Zhixiong Zeng,Jing Huang,Liming Zheng,Yufeng Zhong,Lin Ma*

Main category: cs.AI

TL;DR: 차트에서 구조화된 코드로 변환하는 문제에서 SFT는 한계에 봉착하며, 저자들은 대규모 실제 데이터(3M 차트-코드 쌍)와 다중-입력·다중-세분화 보상(텍스트 규칙 기반 + 시각적 모델 기반)을 활용한 Multimodal Structured Reinforcement Learning(MSRL)을 제안해 이 한계를 돌파했다. MSRL은 두 단계 커리큘럼으로 안정적으로 학습되며 ChartMimic과 ReachQA에서 각각 상위 지표를 6.2%·9.9% 향상시켰다.


<details>
  <summary>Details</summary>
Motivation: 차트처럼 정보가 풍부한 시각 자료에서 복잡한 추론을 통해 구조화된 코드를 생성하는 작업은 단순한 SFT만으로는 성능 한계(플래토)를 보이며, 구조적 출력에 적절한 보상을 제공하는 RL 전략이 필요하다.

Method: 1) 대규모 실제 데이터 수집: arXiv 테이블 기반 3M 차트-코드 쌍 구축으로 합성 데이터의 단순 패턴 회피. 2) MSRL 설계: 멀티-그레인(세분화) 구조 보상 사용—텍스트 수준에서는 규칙 기반 보상으로 코드의 세세한 부분 검증, 시각 수준에서는 생성 코드를 렌더링해 이미지로 변환한 뒤 평가자 모델로 구조적 유사성 평가. 3) 학습 안정성을 위해 2단계 커리큘럼 적용.

Result: MSRL은 SFT 스케일링으로는 도달하기 힘든 성능 향상을 달성함. ChartMimic에서 상위 지표 6.2% 향상, ReachQA에서 9.9% 향상. SFT는 데이터 증대로 결국 성능 플래토에 도달했으나 MSRL로 이를 돌파했고, 폐쇄형 고성능 모델들과 경쟁 가능한 성능을 보임.

Conclusion: 차트-투-코드 과제에서는 대규모 실제 데이터와 멀티모달·구조적 보상을 결합한 강화학습(MSRL)이 SFT의 한계를 극복하는 효과적인 접근법이다. 멀티그레인 보상과 시각적 평가, 커리큘럼 학습이 핵심 요소로 작용한다.

Abstract: While reinforcement learning (RL) has proven highly effective for general
reasoning in vision-language models, its application to tasks requiring
in-depth understanding of information-rich images and generation of structured
outputs remains underexplored. Chart-to-code generation exemplifies this
challenge, demanding complex reasoning over visual charts to generate
structured code. Supervised fine-tuning (SFT) alone is often insufficient,
highlighting the need for effective RL strategies that appropriately reward
structured outputs. We systematically investigate the performance plateau in
SFT through large-scale experiments and propose Multimodal Structured
Reinforcement Learning (MSRL) for chart-to-code generation, which substantially
breaks through this plateau. We construct the largest training corpus to date,
containing 3 million chart-code pairs from real-world arXiv tables to mitigate
simplistic patterns of prior synthetic data. Despite reaching state-of-the-art
performance, our experiments show that scaling SFT data eventually hits a
plateau where further increases yield negligible improvements. Our MSRL method
leverages a multi-granularity structured reward system using multimodal textual
and visual feedback. At the textual level, rule-based rewards validate
fine-grained code details. At the visual level, model-based rewards assess
structural similarity by rendering generated code into images and employing an
evaluator model. We implement this within a two-stage curriculum for training
stability. Results demonstrate that MSRL significantly breaks the SFT plateau,
improving high-level metrics by 6.2% and 9.9% on ChartMimic and ReachQA
benchmarks respectively, achieving competitive performance with advanced
closed-source models.

</details>


### [315] [V2P: From Background Suppression to Center Peaking for Robust GUI Grounding Task](https://arxiv.org/abs/2508.13634)
*Jikai Chen,Long Chen,Dong Wang,Leilei Gan,Chenyi Zhuang,Jinjie Gu*

Main category: cs.AI

TL;DR: V2P는 배경 억제(suppression attention)와 Fitts' Law 기반 2D 가우시안 히트맵 라벨링을 결합해 GUI 요소의 위치 정확도를 높인다. 두 벤치마크에서 각각 92.3%와 50.5% 성능을 달성한다.


<details>
  <summary>Details</summary>
Motivation: 기존 방법들은 바운딩박스/중심점 회귀로 공간적 불확실성과 시각-의미 계층을 무시하거나, 주의(attention) 기반 방법이 배경으로 관심이 흘러가거나 대상의 중심과 가장자리를 구분하지 못해 클릭 부정확이 발생하는 문제를 가짐.

Method: (1) 배경을 억제하는 suppression attention으로 모델의 관심을 불필요한 영역에서 벗어나게 함. (2) Fitts' Law에서 영감을 받아 대상의 중심에서 가장자리로 가며 가중치가 감소하는 2D 가우시안 히트맵을 라벨로 사용. 분산은 대상 크기로 결정.

Result: ScreenSpot-v2에서 92.3%, ScreenSpot-Pro에서 50.5% 성능 달성. 제거 실험(ablation)으로 각 구성 요소의 기여도 확인. 모델이 대상 영역을 효과적으로 분리하고 중심에 집중하도록 학습됨.

Conclusion: V2P는 배경 방해를 줄이고 중심-가장자리 구분을 통해 GUI 그라운딩의 정밀도를 향상시키며, 구성요소별 유효성이 실험적으로 입증되어 일반화 가능성이 높음.

Abstract: Precise localization of GUI elements is crucial for the development of GUI
agents. Traditional methods rely on bounding box or center-point regression,
neglecting spatial interaction uncertainty and visual-semantic hierarchies.
Recent methods incorporate attention mechanisms but still face two key issues:
(1) ignoring processing background regions causes attention drift from the
desired area, and (2) uniform labeling fails to distinguish between center and
edges of the target UI element, leading to click imprecision. Inspired by how
humans visually process and interact with GUI elements, we propose the
Valley-to-Peak (V2P) method to address these issues. To mitigate background
distractions, V2P introduces a suppression attention mechanism that minimizes
the model's focus on irrelevant regions to highlight the intended region. For
the issue of center-edge distinction, V2P applies a Fitts' Law-inspired
approach by modeling GUI interactions as 2D Gaussian heatmaps where the weight
gradually decreases from the center towards the edges. The weight distribution
follows a Gaussian function, with the variance determined by the target's size.
Consequently, V2P effectively isolates the target area and teaches the model to
concentrate on the most essential point of the UI element. The model trained by
V2P achieves the performance with 92.3% and 50.5% on two benchmarks
ScreenSpot-v2 and ScreenSpot-Pro. Ablations further confirm each component's
contribution, highlighting V2P's generalizability for precise GUI grounding
tasks.

</details>


### [316] [Interactive Query Answering on Knowledge Graphs with Soft Entity Constraints](https://arxiv.org/abs/2508.13663)
*Daniel Daza,Alberto Bernardi,Luca Costabello,Christophe Gueret,Masoud Mansoury,Michael Cochez,Martijn Schut*

Main category: cs.AI

TL;DR: 논문은 불완전한 지식 그래프(KG)에서 직접 경로로 도달할 수 없는 답변들을 찾는 문제에 대해, 기존의 엄격한 논리 기반 질의에서 벗어나 애매하거나 문맥 의존적인 제약(soft constraints)을 다루는 새 문제를 제안한다. 이를 해결하기 위해 Neural Query Reranker(NQR)를 제시하고, 원래 질의의 답을 해치지 않으면서 소프트 제약을 반영해 답 점수를 조정하도록 학습한다. NQR는 대화형으로 작동하며 선호/비선호 예시를 점진적으로 반영한다. 데이터셋 확장과 실험에서 NQR가 소프트 제약을 잘 포착하면서 견고한 질의 응답 성능을 유지함을 보였다.


<details>
  <summary>Details</summary>
Motivation: 기존의 KG 질의 응답 방식은 결손된 엣지 때문에 정답에 직접 도달하지 못하는 경우가 있어, 그래프 기반 추론/순위화가 필요하다. 그러나 실제 쿼리에는 선호나 속성 같은 모호하고 문맥 의존적인 제약이 자주 포함되어 기존의 1차 논리 기반 포맷으로 표현하기 어렵다. 이러한 소프트 제약을 반영한 질의 응답 체계가 필요하다.

Method: Neural Query Reranker(NQR)를 제안한다. NQR는 기존 쿼리 응답 후보의 점수를 조정하는 재순위기(re-ranker)로, 원래의 정답들을 보존하면서 소프트 제약을 반영하도록 설계됐다. 모델은 상호작용적으로 작동하며, 선호/비선호 엔티티의 점진적 피드백을 받아 점수를 갱신한다. 또한 기존 QA 벤치마크를 확장해 소프트 제약이 포함된 데이터셋을 생성했다.

Result: 실험 결과 NQR는 소프트 제약을 효과적으로 학습해 선호를 반영한 재순위 결과를 제공하며, 원래의 질의 응답 성능도 유지하거나 크게 훼손하지 않았다.

Conclusion: 소프트 제약을 포함한 질의 응답은 현실적 요구를 더 잘 반영하며, NQR는 상호작용적 예시 기반 학습을 통해 이를 달성할 수 있음을 보였다. 이 방향은 지식 그래프 기반 QA 시스템의 유연성과 사용자 맞춤화를 향상시킬 수 있다.

Abstract: Methods for query answering over incomplete knowledge graphs retrieve
entities that are likely to be answers, which is particularly useful when such
answers cannot be reached by direct graph traversal due to missing edges.
However, existing approaches have focused on queries formalized using
first-order-logic. In practice, many real-world queries involve constraints
that are inherently vague or context-dependent, such as preferences for
attributes or related categories. Addressing this gap, we introduce the problem
of query answering with soft constraints. We propose a Neural Query Reranker
(NQR) designed to adjust query answer scores by incorporating soft constraints
without disrupting the original answers to a query. NQR operates interactively,
refining answers based on incremental examples of preferred and non-preferred
entities. We extend existing QA benchmarks by generating datasets with soft
constraints. Our experiments demonstrate that NQR can capture soft constraints
while maintaining robust query answering performance.

</details>


### [317] [ITL-LIME: Instance-Based Transfer Learning for Enhancing Local Explanations in Low-Resource Data Settings](https://arxiv.org/abs/2508.13672)
*Rehan Raza,Guanjin Wang,Kevin Wong,Hamid Laga,Marco Fisichella*

Main category: cs.AI

TL;DR: 


<details>
  <summary>Details</summary>
Motivation: 

Method: 

Result: 

Conclusion: 

Abstract: Explainable Artificial Intelligence (XAI) methods, such as Local
Interpretable Model-Agnostic Explanations (LIME), have advanced the
interpretability of black-box machine learning models by approximating their
behavior locally using interpretable surrogate models. However, LIME's inherent
randomness in perturbation and sampling can lead to locality and instability
issues, especially in scenarios with limited training data. In such cases, data
scarcity can result in the generation of unrealistic variations and samples
that deviate from the true data manifold. Consequently, the surrogate model may
fail to accurately approximate the complex decision boundary of the original
model. To address these challenges, we propose a novel Instance-based Transfer
Learning LIME framework (ITL-LIME) that enhances explanation fidelity and
stability in data-constrained environments. ITL-LIME introduces instance
transfer learning into the LIME framework by leveraging relevant real instances
from a related source domain to aid the explanation process in the target
domain. Specifically, we employ clustering to partition the source domain into
clusters with representative prototypes. Instead of generating random
perturbations, our method retrieves pertinent real source instances from the
source cluster whose prototype is most similar to the target instance. These
are then combined with the target instance's neighboring real instances. To
define a compact locality, we further construct a contrastive learning-based
encoder as a weighting mechanism to assign weights to the instances from the
combined set based on their proximity to the target instance. Finally, these
weighted source and target instances are used to train the surrogate model for
explanation purposes.

</details>


### [318] [Knowledge Graph Completion for Action Prediction on Situational Graphs -- A Case Study on Household Tasks](https://arxiv.org/abs/2508.13675)
*Mariam Arustashvili,Jörg Deigmöller,Heiko Paulheim*

Main category: cs.AI

TL;DR: 가정 행동을 나타내는 상황적 지식 그래프(situational KG)는 영상에서 추출되는 누락 정보를 보완해야 하지만, 특수한 특성 때문에 기존 링크 예측 알고리즘들이 단순한 베이스라인도 능가하지 못한다는 점을 보인다.


<details>
  <summary>Details</summary>
Motivation: 가정용 로봇 제어와 영상 분석(동작 인식·상황 파악)에 유용한 행동 지식 그래프를 완성하여 누락된 정보를 보강하고 상황 인식을 개선하려는 필요성.

Method: 가정 행동을 서술하는 지식 그래프의 특성을 조사하고, 표준 링크 예측 문제로 다루었을 때 발생하는 한계를 분석하여 여러 기존 알고리즘 성능을 비교·평가하였다.

Result: 상황적 지식 그래프의 고유한 특성 때문에 많은 기존 링크 예측 기법이 부적합하며, 일부는 단순한 기준선(baseline)조차 능가하지 못함을 실험적으로 보여줌.

Conclusion: 상황적 KG의 누락 보완을 위해서는 표준 링크 예측 기법의 직접 적용이 불충분하며, 해당 도메인 특성에 맞춘 방법론 설계가 필요하다.

Abstract: Knowledge Graphs are used for various purposes, including business
applications, biomedical analyses, or digital twins in industry 4.0. In this
paper, we investigate knowledge graphs describing household actions, which are
beneficial for controlling household robots and analyzing video footage. In the
latter case, the information extracted from videos is notoriously incomplete,
and completing the knowledge graph for enhancing the situational picture is
essential. In this paper, we show that, while a standard link prediction
problem, situational knowledge graphs have special characteristics that render
many link prediction algorithms not fit for the job, and unable to outperform
even simple baselines.

</details>


### [319] [MHSNet:An MoE-based Hierarchical Semantic Representation Network for Accurate Duplicate Resume Detection with Large Language Model](https://arxiv.org/abs/2508.13676)
*Yu Li,Zulong Chen,Wenjian Xu,Hong Wen,Yipeng Yu,Man Lung Yiu,Yuyu Yin*

Main category: cs.AI

TL;DR: 제3자 이력서와 자사 데이터 간 중복(동일인) 검출을 위해 제안된 MHSNet은 BGE-M3를 대비학습으로 파인튜닝하고, Mixture-of-Experts 기반의 다층(희소/밀집) 표현과 상태 인지 게이팅을 통해 불완전한 이력서들을 효율적으로 비교·식별한다.


<details>
  <summary>Details</summary>
Motivation: 외부(LinkedIn, Indeed 등)에서 수집한 이력서는 불완전하거나 부정확한 경우가 많아 자사 인재풀을 갱신·보강하기 위해서는 중복 여부(동일인 판정)를 정확히 판단해야 함. 그러나 이력서 텍스트의 의미적 복잡성, 구조적 이질성, 정보 불완전성이 중복 검출을 어렵게 함.

Method: BGE-M3를 대비(contrastive) 학습으로 파인튜닝하여 표현 품질을 높이고, Mixture-of-Experts(MoE)를 통해 다층(희소·밀집) 표현을 생성해 레쥬메별로 다수준 의미 유사도를 산출함. 또한 상태 인지(State-aware) MoE를 도입해 누락·불완전 정보가 다양한 이력서들에 대해 전문가별 처리를 달리함으로써 강건성을 확보함.

Result: 제안한 MHSNet이 실험적으로 유효함이 검증됨(초록에서는 구체적 수치·데이터셋·비교군 미제시). 다층 표현과 상태 인지 MoE가 불완전·이질적 이력서에 대한 중복 판정 성능 향상에 기여한 것으로 보임.

Conclusion: MHSNet은 대비학습으로 개선된 표현과 MoE 기반 다층·상태 인지 처리를 결합해 제3자 이력서의 정보 불완전성·구조적 이질성을 다루며, 중복(동일인) 검출 문제에 실용적인 개선을 제공함.

Abstract: To maintain the company's talent pool, recruiters need to continuously search
for resumes from third-party websites (e.g., LinkedIn, Indeed). However,
fetched resumes are often incomplete and inaccurate. To improve the quality of
third-party resumes and enrich the company's talent pool, it is essential to
conduct duplication detection between the fetched resumes and those already in
the company's talent pool. Such duplication detection is challenging due to the
semantic complexity, structural heterogeneity, and information incompleteness
of resume texts. To this end, we propose MHSNet, an multi-level identity
verification framework that fine-tunes BGE-M3 using contrastive learning. With
the fine-tuned , Mixture-of-Experts (MoE) generates multi-level sparse and
dense representations for resumes, enabling the computation of corresponding
multi-level semantic similarities. Moreover, the state-aware Mixture-of-Experts
(MoE) is employed in MHSNet to handle diverse incomplete resumes. Experimental
results verify the effectiveness of MHSNet

</details>


### [320] [Neuro-Symbolic Artificial Intelligence: Towards Improving the Reasoning Abilities of Large Language Models](https://arxiv.org/abs/2508.13678)
*Xiao-Wen Yang,Jie-Jing Shao,Lan-Zhe Guo,Bo-Wen Zhang,Zhi Zhou,Lin-Han Jia,Wang-Zhou Dai,Yu-Feng Li*

Main category: cs.AI

TL;DR: Comprehensive survey of neuro-symbolic methods to improve reasoning in LLMs: formalizes reasoning tasks, introduces the neurosymbolic paradigm, categorizes methods into Symbolic->LLM, LLM->Symbolic, and LLM+Symbolic, and discusses challenges and future directions; provides an accompanying GitHub resource list.


<details>
  <summary>Details</summary>
Motivation: LLMs show strong performance but lack robust reasoning; improving reasoning is crucial for progress toward AGI and has high academic/industrial interest. Neuro-symbolic approaches are particularly promising for combining strengths of symbolic reasoning and neural LLMs.

Method: Literature survey: (1) formalize reasoning tasks, (2) overview neurosymbolic learning paradigm, (3) review and categorize recent neuro-symbolic techniques into three perspectives—Symbolic->LLM (inject symbolic knowledge/constraints into LLMs), LLM->Symbolic (use LLMs to generate or drive symbolic components), and LLM+Symbolic (tight integration/hybrid pipelines), (4) analyze strengths/limitations, and (5) compile challenges and future directions; release a GitHub repo of papers/resources.

Result: A structured taxonomy and synthesis of recent neuro-symbolic work targeting LLM reasoning, highlighting representative methods in each category, comparative insights on effectiveness and limitations, and an organized resource repository for researchers.

Conclusion: Neuro-symbolic approaches are a promising avenue to enhance LLM reasoning, but key challenges remain (scalability, alignment, benchmarks, interpretability, compositionality). The survey maps current progress, gaps, and promising research directions and provides resources for follow-up work.

Abstract: Large Language Models (LLMs) have shown promising results across various
tasks, yet their reasoning capabilities remain a fundamental challenge.
Developing AI systems with strong reasoning capabilities is regarded as a
crucial milestone in the pursuit of Artificial General Intelligence (AGI) and
has garnered considerable attention from both academia and industry. Various
techniques have been explored to enhance the reasoning capabilities of LLMs,
with neuro-symbolic approaches being a particularly promising way. This paper
comprehensively reviews recent developments in neuro-symbolic approaches for
enhancing LLM reasoning. We first present a formalization of reasoning tasks
and give a brief introduction to the neurosymbolic learning paradigm. Then, we
discuss neuro-symbolic methods for improving the reasoning capabilities of LLMs
from three perspectives: Symbolic->LLM, LLM->Symbolic, and LLM+Symbolic.
Finally, we discuss several key challenges and promising future directions. We
have also released a GitHub repository including papers and resources related
to this survey: https://github.com/LAMDASZ-ML/Awesome-LLM-Reasoning-with-NeSy.

</details>


### [321] [The DeepLog Neurosymbolic Machine](https://arxiv.org/abs/2508.13697)
*Vincent Derkinderen,Robin Manhaeve,Rik Adriaensen,Lucas Van Praet,Lennert De Smet,Giuseppe Marra,Luc De Raedt*

Main category: cs.AI

TL;DR: DeepLog는 신경-심볼릭 AI를 위한 이론적·운영상 프레임워크로, 주석된 신경 확장 1차 술어 논리 언어와 확장 대수 회로를 결합해 다양한 논리(불, 퍼지, 확률적)를 추상화하고 GPU 친화적 구현을 제공한다. 논리의 사용(아키텍처 vs 손실) 및 논리 종류에 따른 성능을 실험적으로 비교하며, CPU vs GPU 구현 차이도 보인다.


<details>
  <summary>Details</summary>
Motivation: 신경망의 표현력과 심볼릭 논리의 추론 능력을 결합하는 신경-심볼릭 AI 시스템을 일반화하고 효율적으로 구현할 수 있는 추상적·운영상 틀을 제공하기 위해.

Method: 1) DeepLog 언어: 주석된 신경 확장의 기초 1차 술어 논리로 다양한 논리 유형과 논리 사용 방식을 추상화. 2) 컴퓨테이셔널 레벨: 확장된 대수 회로(알gebraic circuits)를 계산 그래프로 사용하여 GPU 최적화된 연산을 구현. 소프트웨어 구현을 통해 여러 논리·구성 선택을 선언적으로 변경 가능.

Result: DeepLog는 다양한 퍼지/확률 논리 사이의 성능 차이, 논리의 활용 방식(아키텍처 대 손실) 비교, 그리고 기존 CPU 기반 시스템 대비 GPU 기반 DeepLog의 효율성 우위를 실험적으로 보여준다.

Conclusion: DeepLog는 신경-심볼릭 모델을 표현·실행하기 위한 범용적이고 효율적인 추상 머신을 제안하며, 선언적 언어와 GPU 친화적 대수 회로의 결합으로 다양한 논리와 구현 선택을 용이하게 탐색할 수 있다.

Abstract: We contribute a theoretical and operational framework for neurosymbolic AI
called DeepLog. DeepLog introduces building blocks and primitives for
neurosymbolic AI that make abstraction of commonly used representations and
computational mechanisms used in neurosymbolic AI. DeepLog can represent and
emulate a wide range of neurosymbolic systems. It consists of two key
components. The first is the DeepLog language for specifying neurosymbolic
models and inference tasks. This language consists of an annotated neural
extension of grounded first-order logic, and makes abstraction of the type of
logic, e.g. boolean, fuzzy or probabilistic, and whether logic is used in the
architecture or in the loss function. The second DeepLog component is situated
at the computational level and uses extended algebraic circuits as
computational graphs. Together these two components are to be considered as a
neurosymbolic abstract machine, with the DeepLog language as the intermediate
level of abstraction and the circuits level as the computational one. DeepLog
is implemented in software, relies on the latest insights in implementing
algebraic circuits on GPUs, and is declarative in that it is easy to obtain
different neurosymbolic models by making different choices for the underlying
algebraic structures and logics. The generality and efficiency of the DeepLog
neurosymbolic machine is demonstrated through an experimental comparison
between 1) different fuzzy and probabilistic logics, 2) between using logic in
the architecture or in the loss function, and 3) between a standalone CPU-based
implementation of a neurosymbolic AI system and a DeepLog GPU-based one.

</details>


### [322] [CausalPlan: Empowering Efficient LLM Multi-Agent Collaboration Through Causality-Driven Planning](https://arxiv.org/abs/2508.13721)
*Minh Hoang Nguyen,Van Dai Do,Dung Nguyen,Thin Nguyen,Hung Le*

Main category: cs.AI

TL;DR: CausalPlan은 SCA(Structural Causal Action)를 통해 에이전트 궤적에서 인과 그래프를 학습하고, 그 구조로 LLM이 제안한 행동에 인과 점수를 부여해 재가중 또는 대체하는 두-단계 프레임워크이다. 미세조정 없이 인과적으로 일관된 계획을 유도해 Overcooked-AI에서 무효 행동을 줄이고 협업 성능을 향상시켰다.


<details>
  <summary>Details</summary>
Motivation: 작고 오픈한 LLM들은 표면적 상관관계에 의존해 인과적으로 타당하지 않거나 비일관적 행동을 생성해 다자 협업·계획 수행 능력이 떨어진다.

Method: CausalPlan: (1) SCA 모델로 에이전트 행동・환경 상태로부터 인과 그래프 학습하여 과거 행동/상태가 미래 결정에 미치는 영향 포착, (2) 그래프 기반 인과 점수로 LLM이 생성한 행동 후보들을 재가중하거나 폴백 행동으로 대체해 인과적 일관성 확보. LLM 자체는 미세조정하지 않음.

Result: Overcooked-AI의 5개 협업 태스크와 Gemma-7B, Llama-8B, Qwen-14B, Llama-70B에서 실험한 결과, CausalPlan이 무효 행동을 일관되게 감소시키고 AI-AI 및 인간-AI 협업에서 성능을 향상시켜 강력한 RL 베이스라인들을 능가함.

Conclusion: 의사결정 루프에 인과 지식을 직접 삽입하면 개입-일관적 행동을 강제해 해석성·일반화·효율성을 개선할 수 있으며, 미세조정 없이도 작은 모델에 적용 가능해 다자 LLM 시스템 배치에 실용적이다.

Abstract: Large language model (LLM) agents-especially smaller, open-source
models-often produce causally invalid or incoherent actions in collaborative
tasks due to their reliance on surface-level correlations rather than grounded
causal reasoning. This limitation undermines their performance in terms of
coordination and planning in dynamic environments. We address this challenge
with CausalPlan, a two-phase framework that integrates explicit structural
causal reasoning into the LLM planning process. At the core of CausalPlan is
the Structural Causal Action (SCA) model, which learns a causal graph from
agent trajectories to capture how prior actions and current environment states
influence future decisions. This structure is then used to guide action
selection by assigning causal scores to LLM-generated proposals, reweighting
them accordingly, or falling back to causally grounded alternatives when
needed. By embedding this causal knowledge directly into the decision loop,
CausalPlan constrains planning to intervention-consistent behaviours without
requiring fine-tuning of the LLM itself. We evaluate CausalPlan on the
Overcooked-AI benchmark across five multi-agent coordination tasks and four
LLMs of varying sizes: Gemma-7B, Llama-8B, Qwen-14B, and Llama-70B.
Experimental results show that CausalPlan consistently reduces invalid actions
and improves collaboration in both AI-AI and human-AI settings, outperforming
strong reinforcement learning baselines. Our findings highlight the value of
causality-driven planning for deploying efficient, interpretable, and
generalisable multi-agent LLM systems.

</details>


### [323] [Expertise-aware Multi-LLM Recruitment and Collaboration for Medical Decision-Making](https://arxiv.org/abs/2508.13754)
*Liuxin Bao,Zhihao Peng,Xiaofei Zhou,Runmin Cong,Jiyong Zhang,Yixuan Yuan*

Main category: cs.AI

TL;DR: EMRC는 여러 LLM의 전문성을 활용해 의료 의사결정 정확성을 높이는 프레임워크로, 전문성 기반 에이전트 선발과 신뢰도·대결 기반 협업 두 단계로 동작한다. 공개 코퍼스로 LLM별 전문성 테이블을 구축해 질의별 최적 LLM을 동적으로 선발하고, 에이전트 신뢰점수 결합과 적대적 검증으로 진단 신뢰도를 향상시킨다. 공개 MDM 데이터셋에서 SOTA를 능가하며 MMLU-Pro-Health에서 GPT-4-0613보다 2.69% 높은 74.45%를 기록했다.


<details>
  <summary>Details</summary>
Motivation: 단일 LLM은 파라메트릭한 지식 한계와 정적인 훈련 데이터셋 때문에 의료 의사결정에서 임상 정보를 견고하게 통합하지 못한다. 따라서 여러 LLM의 전문성을 동적으로 활용해 진단 정확성과 신뢰도를 개선할 필요가 있다.

Method: EMRC는 (1) 공개 코퍼스를 이용해 LLM별로 의료 과(부문) 및 질의 난이도별 전문성 테이블을 구축해, 추론 시 질의에 최적화된 LLM을 에이전트로 선발하는 전문성 인식 에이전트 모집 단계와 (2) 선발된 에이전트들이 자가 신뢰 점수를 포함한 응답을 생성하면 이를 신뢰도 융합(confidence fusion)과 적대적 검증(adversarial validation)으로 통합·검증하는 신뢰도 및 적대 기반 다중 에이전트 협업 단계를 포함한다.

Result: 세 개의 공개 MDM 데이터셋에서 평가하여 기존 단일/다중 LLM 방식보다 성능이 우수했다. 예를 들어 MMLU-Pro-Health 데이터셋에서 EMRC는 74.45%의 정확도를 기록했으며, 이는 최고 성능의 폐쇄형 모델 GPT-4-0613보다 2.69% 개선된 수치다.

Conclusion: 전문성 인식 기반 에이전트 선발과 신뢰/적대적 협업 메커니즘을 통해 LLM의 전문성 보완 및 상호보완성을 효과적으로 활용할 수 있으며, 의료 의사결정 시스템의 정확성과 신뢰도를 향상시킨다.

Abstract: Medical Decision-Making (MDM) is a complex process requiring substantial
domain-specific expertise to effectively synthesize heterogeneous and
complicated clinical information. While recent advancements in Large Language
Models (LLMs) show promise in supporting MDM, single-LLM approaches are limited
by their parametric knowledge constraints and static training corpora, failing
to robustly integrate the clinical information. To address this challenge, we
propose the Expertise-aware Multi-LLM Recruitment and Collaboration (EMRC)
framework to enhance the accuracy and reliability of MDM systems. It operates
in two stages: (i) expertise-aware agent recruitment and (ii) confidence- and
adversarial-driven multi-agent collaboration. Specifically, in the first stage,
we use a publicly available corpus to construct an LLM expertise table for
capturing expertise-specific strengths of multiple LLMs across medical
department categories and query difficulty levels. This table enables the
subsequent dynamic selection of the optimal LLMs to act as medical expert
agents for each medical query during the inference phase. In the second stage,
we employ selected agents to generate responses with self-assessed confidence
scores, which are then integrated through the confidence fusion and adversarial
validation to improve diagnostic reliability. We evaluate our EMRC framework on
three public MDM datasets, where the results demonstrate that our EMRC
outperforms state-of-the-art single- and multi-LLM methods, achieving superior
diagnostic performance. For instance, on the MMLU-Pro-Health dataset, our EMRC
achieves 74.45% accuracy, representing a 2.69% improvement over the
best-performing closed-source model GPT- 4-0613, which demonstrates the
effectiveness of our expertise-aware agent recruitment strategy and the agent
complementarity in leveraging each LLM's specialized capabilities.

</details>


### [324] [Quantifier Instantiations: To Mimic or To Revolt?](https://arxiv.org/abs/2508.13811)
*Jan Jakubův,Mikoláš Janota*

Main category: cs.AI

TL;DR: 


<details>
  <summary>Details</summary>
Motivation: 

Method: 

Result: 

Conclusion: 

Abstract: Quantified formulas pose a significant challenge for Satisfiability Modulo
Theories (SMT) solvers due to their inherent undecidability. Existing
instantiation techniques, such as e-matching, syntax-guided, model-based,
conflict-based, and enumerative methods, often complement each other. This
paper introduces a novel instantiation approach that dynamically learns from
these techniques during solving. By treating observed instantiations as samples
from a latent language, we use probabilistic context-free grammars to generate
new, similar terms. Our method not only mimics successful past instantiations
but also explores diversity by optionally inverting learned term probabilities,
aiming to balance exploitation and exploration in quantifier reasoning.

</details>


### [325] [Revisiting RAG Ensemble: A Theoretical and Mechanistic Analysis of Multi-RAG System Collaboration](https://arxiv.org/abs/2508.13828)
*Yifei Chen,Guanting Dong,Yutao Zhu,Zhicheng Dou*

Main category: cs.AI

TL;DR: 


<details>
  <summary>Details</summary>
Motivation: 

Method: 

Result: 

Conclusion: 

Abstract: Retrieval-Augmented Generation (RAG) technology has been widely applied in
recent years. However, despite the emergence of various RAG frameworks, a
single RAG framework still cannot adapt well to a broad range of downstream
tasks. Therefore, how to leverage the advantages of multiple RAG systems has
become an area worth exploring. To address this issue, we have conducted a
comprehensive and systematic investigation into ensemble methods based on RAG
systems. Specifically, we have analyzed the RAG ensemble framework from both
theoretical and mechanistic analysis perspectives. From the theoretical
analysis, we provide the first explanation of the RAG ensemble framework from
the perspective of information entropy. In terms of mechanism analysis, we have
explored the RAG ensemble framework from both the pipeline and module levels.
We carefully select four different pipelines (Branching, Iterative, Loop, and
Agentic) and three different modules (Generator, Retriever, and Reranker) to
solve seven different research questions. The experiments show that aggregating
multiple RAG systems is both generalizable and robust, whether at the pipeline
level or the module level. Our work lays the foundation for similar research on
the multi-RAG system ensemble.

</details>


### [326] [Improved Generalized Planning with LLMs through Strategy Refinement and Reflection](https://arxiv.org/abs/2508.13876)
*Katharina Stein,Nils Hodel,Daniel Fišer,Jörg Hoffmann,Michael Katz,Alexander Koller*

Main category: cs.AI

TL;DR: LLM으로 PDDL 도메인의 일반화된 계획을 생성하는 기존 3단계 파이프라인을 개선함. 전략을 자연어 대신 의사코드로 생성하고 의사코드를 자동 디버깅해 오류를 수정한 뒤 파이썬 구현을 생성한다. 파이썬 디버깅에 reflection 단계를 추가하고 여러 코드 변형을 생성해 최적안을 선택한다. 17개 벤치마크 도메인에서 성능이 크게 향상되어, 12개 도메인에서는 모든 생성 가능한 태스크를 해결함.


<details>
  <summary>Details</summary>
Motivation: 단일 자연어 전략을 바로 코드화하면 전략 자체의 오류가 그대로 일반화 계획의 실패로 이어지므로, 전략 단계에서 오류를 조기에 발견·수정할 필요가 있음.

Method: (1) 전략을 자연어가 아니라 의사코드로 생성하여 형식적 검증 및 자동 디버깅 수행, (2) 수정된 의사코드를 기반으로 파이썬 프로그램 생성, (3) 파이썬 디버깅 단계에 LLM에게 실패 원인을 묻는 reflection 프롬프트 추가, (4) 코드 생성에서 여러 변형을 만들고 예제에 대해 성능이 좋은 것 선택.

Result: 제안한 확장들은 일반화 계획의 품질을 실질적으로 개선(절대 악화시키지 않음). 17개 도메인 실험에서 12개 도메인에서는 최적 파이썬 프로그램이 모든 인스턴스 생성 가능한 태스크를 해결함.

Conclusion: 전략을 의사코드 형태로 만들고 그 수준에서 자동 디버깅을 수행하는 것, 그리고 reflection 및 여러 변형 생성은 LLM 기반 일반화 계획 생성의 신뢰성과 성능을 크게 높임.

Abstract: LLMs have recently been used to generate Python programs representing
generalized plans in PDDL planning, i.e., plans that generalize across the
tasks of a given PDDL domain. Previous work proposed a framework consisting of
three steps: the LLM first generates a summary and then a strategy for the
domain, both in natural language, and then implements that strategy as a Python
program, that gets debugged on example planning tasks. In that work, only one
strategy is generated and passed directly to the program generation. If the
strategy is incorrect, its implementation will therefore result in an incorrect
generalized plan. Here, we introduce an approach that generates the strategy in
the form of pseudocode and enables automatic debugging of the pseudocode, hence
allowing us to identify and fix errors prior to the generation of the
generalized plan itself. Additionally, we extend the Python debugging phase
with a reflection step prompting the LLM to pinpoint the reason for the
observed plan failure. Finally, we take inspiration from LLM code generation to
produce several program variants and pick the best one. Running experiments on
17 benchmark domains, we show that these extensions substantially improve (and
never deteriorate) the quality of the generalized plans. In 12 of the domains,
our best Python programs solve all tasks that can be generated with the
respective instance generator.

</details>


### [327] [Structured Agentic Workflows for Financial Time-Series Modeling with LLMs and Reflective Feedback](https://arxiv.org/abs/2508.13915)
*Yihao Ang,Yifan Bao,Lei Jiang,Jiajie Tao,Anthony K. H. Tung,Lukasz Szpruch,Hao Ni*

Main category: cs.AI

TL;DR: 금융 시계열 모델링을 위해 설계된 모듈형 에이전트 프레임워크 TS-Agent를 제안한다. TS-Agent는 모델 선택, 코드 정제, 파인튜닝의 반복적 의사결정 파이프라인과 플래너 에이전트를 통해 AutoML 및 기존 에이전트 기반 접근보다 정확성·견고성·추적성이 우수함을 보인다.


<details>
  <summary>Details</summary>
Motivation: 금융 의사결정에서 시계열 데이터의 중요성은 크지만, 고성능이면서도 해석 가능하고 감사 가능한 모델을 만드는 것은 어려움. 기존 AutoML은 개발을 간소화하지만 도메인 특화 요구사항과 변화하는 목표에 유연하게 대응하지 못함. 반면 LLM 기반 에이전트는 추론, 메모리 관리, 동적 코드 생성 능력으로 더 유연한 워크플로 자동화를 가능하게 함.

Method: TS-Agent는 모듈형 에이전트 아키텍처로 파이프라인을 모델 선택, 코드 정제, 파인튜닝의 세 단계로 구조화된 반복 의사결정 과정으로 정식화. 플래너 에이전트는 구조화된 지식 저장소와 모델·정제 전략 라이브러리를 이용해 탐색을 안내하고 해석가능성 향상 및 오류 전파 감소를 목표로 함. 맥락적 추론과 실험적 피드백으로 적응학습, 디버깅, 감사 가능성을 지원.

Result: 다양한 금융 예측 및 합성 데이터 생성 과제에서 기존 최첨단 AutoML 및 에이전트 기반 기법을 일관되게 능가하여 정확도, 견고성, 의사결정 추적성 측면에서 우수한 성능을 달성했다고 보고함.

Conclusion: TS-Agent는 고위험 금융 환경의 요구사항(적응성, 디버깅, 투명한 감사)을 충족하는 자동화된 시계열 모델링 워크플로를 제공하며, 실무 적용과 규제 환경에서 유용할 가능성이 크다.

Abstract: Time-series data is central to decision-making in financial markets, yet
building high-performing, interpretable, and auditable models remains a major
challenge. While Automated Machine Learning (AutoML) frameworks streamline
model development, they often lack adaptability and responsiveness to
domain-specific needs and evolving objectives. Concurrently, Large Language
Models (LLMs) have enabled agentic systems capable of reasoning, memory
management, and dynamic code generation, offering a path toward more flexible
workflow automation. In this paper, we introduce \textsf{TS-Agent}, a modular
agentic framework designed to automate and enhance time-series modeling
workflows for financial applications. The agent formalizes the pipeline as a
structured, iterative decision process across three stages: model selection,
code refinement, and fine-tuning, guided by contextual reasoning and
experimental feedback. Central to our architecture is a planner agent equipped
with structured knowledge banks, curated libraries of models and refinement
strategies, which guide exploration, while improving interpretability and
reducing error propagation. \textsf{TS-Agent} supports adaptive learning,
robust debugging, and transparent auditing, key requirements for high-stakes
environments such as financial services. Empirical evaluations on diverse
financial forecasting and synthetic data generation tasks demonstrate that
\textsf{TS-Agent} consistently outperforms state-of-the-art AutoML and agentic
baselines, achieving superior accuracy, robustness, and decision traceability.

</details>


### [328] [The Collaboration Paradox: Why Generative AI Requires Both Strategic Intelligence and Operational Stability in Supply Chain Management](https://arxiv.org/abs/2508.13942)
*Soumyadeep Dhar*

Main category: cs.AI

TL;DR: 


<details>
  <summary>Details</summary>
Motivation: 

Method: 

Result: 

Conclusion: 

Abstract: The rise of autonomous, AI-driven agents in economic settings raises critical
questions about their emergent strategic behavior. This paper investigates
these dynamics in the cooperative context of a multi-echelon supply chain, a
system famously prone to instabilities like the bullwhip effect. We conduct
computational experiments with generative AI agents, powered by Large Language
Models (LLMs), within a controlled supply chain simulation designed to isolate
their behavioral tendencies. Our central finding is the "collaboration
paradox": a novel, catastrophic failure mode where theoretically superior
collaborative AI agents, designed with Vendor-Managed Inventory (VMI)
principles, perform even worse than non-AI baselines. We demonstrate that this
paradox arises from an operational flaw where agents hoard inventory, starving
the system. We then show that resilience is only achieved through a synthesis
of two distinct layers: high-level, AI-driven proactive policy-setting to
establish robust operational targets, and a low-level, collaborative execution
protocol with proactive downstream replenishment to maintain stability. Our
final framework, which implements this synthesis, can autonomously generate,
evaluate, and quantify a portfolio of viable strategic choices. The work
provides a crucial insight into the emergent behaviors of collaborative AI
agents and offers a blueprint for designing stable, effective AI-driven systems
for business analytics.

</details>


### [329] [ChronoLLM: Customizing Language Models for Physics-Based Simulation Code Generation](https://arxiv.org/abs/2508.13975)
*Jingquan Wang,Andrew Negrut,Harry Zhang,Khailanii Slaton,Shu Wang,Radu Serban,Jinlong Wu,Dan Negrut*

Main category: cs.AI

TL;DR: 사전학습된 대형 언어모델(LLM)을 정제·맞춤화하여 PyChrono 시뮬레이터용 스크립트를 생성하고 전문가의 가상 어시스턴트로 활용할 수 있는지 검증하는 연구. 제안된 프레임워크는 오픈·클로즈드 소스 LLM들을 정제해 PyChrono 스크립트 품질을 계량적으로 향상시키며, 생성된 스크립트는 완벽하진 않지만 강력한 시작점이 된다.


<details>
  <summary>Details</summary>
Motivation: 시뮬레이션 툴의 진입장벽을 낮추고 전문가들이 보다 효율적으로 도구를 사용할 수 있도록, LLM을 가상 어시스턴트로 활용할 수 있는지 탐구하기 위해. PyChrono를 사례로 삼아 범용적인 접근법의 유효성을 보이려 함.

Method: 오픈·클로즈드 소스 LLM들을 대상으로 정제 및 맞춤화 과정(파인튜닝·프롬프트 설계·도메인 특화 데이터 활용 등으로 추정)을 설계·적용하여 PyChrono 스크립트 생성 능력을 향상시키는 프레임워크를 제시. 생성된 스크립트의 품질을 정량적으로 평가하는 절차를 포함.

Result: 정제·맞춤화 과정을 통해 PyChrono 스크립트의 생성 품질이 계량적으로 개선됨. 생성되는 스크립트는 단일 진자에서 차량-변형 지형 같은 복잡한 가상 실험까지 다양하며, 완전하진 않아도 사용자 수정의 출발점으로 유용함. 또한 LLM은 API 관련 질문에 답하거나 모델링 접근법을 추천할 수 있음.

Conclusion: 제시한 프레임워크는 PyChrono 사례를 통해 LLM을 시뮬레이션 어시스턴트로 활용할 가능성을 입증하며, 다른 분야의 시뮬레이터로 확장하여 진입장벽을 낮추는 데 적용할 수 있음.

Abstract: This contribution is concerned with the following issue: can pretrained large
language models (LLMs) be refined and customized to the point where they become
virtual assistants helping experts with the effective use of a simulation tool?
In this case study, the ``simulation tool'' considered is PyChrono, an open
source multi-physics dynamics engine for multibody systems. We present a
framework for refining and customizing both open- and closed-source LLMs to
harness the power of AI in generating scripts that perform PyChrono virtual
experiments. We refine and customize several classes of LLMs through a process
that leads to a quantifiable improvement in the quality of the generated
PyChrono simulation scripts. These scripts can range from simple
single-pendulum simulations to complex virtual experiments involving full
vehicles on deformable terrain. While the generated scripts are rarely perfect,
they often serve as strong starting points for the user to modify and improve
on. Additionally, the LLM can answer specific API questions about the
simulator, or recommend modeling approaches. The framework discussed is general
and can be applied to lower the entry barrier for simulation tools associated
with other application domains.

</details>


### [330] [Chain-of-Agents: End-to-End Agent Foundation Models via Multi-Agent Distillation and Agentic RL](https://arxiv.org/abs/2508.13167)
*Weizhen Li,Jianbo Lin,Zhuosong Jiang,Jingyi Cao,Xinpeng Liu,Jiayu Zhang,Zhenqiang Huang,Qianben Chen,Weichen Sun,Qiexiang Wang,Hongxuan Lu,Tianrui Qin,Chenghao Zhu,Yi Yao,Shuying Fan,Xiaowan Li,Tiannan Wang,Pai Liu,King Zhu,He Zhu,Dingfeng Shi,Piaohong Wang,Yeyi Guan,Xiangru Tang,Minghao Liu,Yuchen Eleanor Jiang,Jian Yang,Jiaheng Liu,Ge Zhang,Wangchunshu Zhou*

Main category: cs.AI

TL;DR: 이 논문은 다중 에이전트 시스템의 동작을 하나의 대형언어모델 내부에서 재현하는 Chain-of-Agents(CoA) 패러다임과, 이를 학습시키기 위한 다중-에이전트 증류 및 에이전틱 강화학습 기법을 제안한다. 결과로 얻은 Agent Foundation Models(AFMs)은 웹·코드 에이전트 벤치마크에서 SOTA 성능을 보이며 전체 연구(모델, 코드, 데이터)를 공개한다.


<details>
  <summary>Details</summary>
Motivation: 기존 다중 에이전트 시스템은 수작업 프롬프트/워크플로우·복잡한 프레임워크에 의존해 계산 비효율적이고 확장성이 떨어지며 데이터 중심 학습의 이점을 활용하지 못한다는 한계가 있다.

Method: Chain-of-Agents(CoA): 단일 모델 내에서 여러 도구 에이전트와 역할 기반 에이전트를 동적 활성화하여 멀티턴 협업을 시뮬레이션함. 학습은(1) SOTA 다중 에이전트 시스템을 CoA 궤적으로 증류하는 다중-에이전트 증류(supervised fine-tuning)와 (2) 검증 가능한 에이전틱 태스크에 대한 에이전틱 강화학습(agentic RL)으로 구성된다.

Result: 학습된 Agent Foundation Models(AFMs)이 웹 에이전트 및 코드 에이전트 설정에서 다양한 벤치마크에 대해 새로운 SOTA 성능을 달성했다. 연구 전체(모델 가중치, 학습·평가 코드, 학습 데이터)를 공개함.

Conclusion: CoA 패러다임과 증류+에이전틱 RL 학습 파이프라인은 단일 모델 내에서 엔드-투-엔드 다중 에이전트 문제해결 능력을 촉진하며 향후 에이전트 모델 및 에이전틱 RL 연구를 위한 기반을 제공한다.

Abstract: Recent advances in large language models (LLMs) and multi-agent systems have
demonstrated remarkable capabilities in complex problem-solving tasks such as
deep research, vibe coding, and mathematical reasoning. However, most existing
multi-agent systems are built upon manual prompt/workflow engineering with
sophisticated agent frameworks, making them computationally inefficient, less
capable, and can not benefit from data-centric learning. In this work, we
introduce Chain-of-Agents (CoA), a novel paradigm of LLM reasoning that enables
native end-to-end complex problem-solving in the same way as a multi-agent
system (i.e., multi-turn problem solving with multiple tools and multiple
agents) within one model. In chain-of-agents problem-solving, the model
dynamically activates different tool agents and role-playing agents to simulate
multi-agent collaboration in an end-to-end fashion. To elicit end-to-end
chain-of-agents problem-solving abilities in LLMs, we introduce a multi-agent
distillation framework to distill state-of-the-art multi-agent systems into
chain-of-agents trajectories for agentic supervised fine-tuning. We then use
agentic reinforcement learning on verifiable agentic tasks to further improve
the models' capabilities on chain-of-agents problem solving. We call the
resulting models Agent Foundation Models (AFMs). Our empirical studies
demonstrate that AFM establishes new state-of-the-art performance across
diverse benchmarks in both web agent and code agent settings. We make the
entire research, including the model weights, code for training and evaluation,
and the training data, fully open-sourced, which offers a solid starting point
for future research on agent models and agentic RL.

</details>


### [331] [A Biased Random Key Genetic Algorithm for Solving the Longest Run Subsequence Problem](https://arxiv.org/abs/2508.14020)
*Christian Blum,Pedro Pinacho-Davidson*

Main category: cs.AI

TL;DR: 제안된 논문은 Biased Random Key Genetic Algorithm(BRKGA)를 이용해 Longest Run Subsequence(LRS) 문제를 푼다. 개인 평가 효율성을 강조하고 Max-Min Ant System 및 CPLEX와 비교했다. 실험 결과 BRKGA가 최첨단 성능을 보였으나, 큰 알파벳 크기에서는 개선 여지가 있다.


<details>
  <summary>Details</summary>
Motivation: LRS 문제는 NP-hard인 서브시퀀스 문제로서 유전체 재조립 등 바이오인포매틱스 응용에서 중요하다. 효율적인 해법 개발이 필요하다.

Method: BRKGA를 사용하여 연속(런) 길이가 가장 긴 서브시퀀스를 찾는다. 개인 평가에서 그레이 값 벡터를 유효한 해로 변환하는 과정을 효율화하는 데 초점을 맞추었다. 성능 비교를 위해 Max-Min Ant System도 구현했으며, 정밀 비교를 위해 CPLEX로 모든 인스턴스를 풀었다.

Result: 계산 실험에서 제안한 BRKGA가 LRS 문제에 대해 현재 최고 수준의 기법으로 나타났다. 그러나 입력 문자열의 알파벳 크기가 클 경우 성능 향상의 여지가 관찰되었다.

Conclusion: BRKGA는 LRS 문제에 대해 강력한 접근법이나, 특히 큰 알파벳을 가진 인스턴스에서는 추가 개선이 필요하다.

Abstract: The longest run subsequence (LRS) problem is an NP-hard combinatorial
optimization problem belonging to the class of subsequence problems from
bioinformatics. In particular, the problem plays a role in genome reassembly.
In this paper, we present a solution to the LRS problem using a Biased Random
Key Genetic Algorithm (BRKGA). Our approach places particular focus on the
computational efficiency of evaluating individuals, which involves converting
vectors of gray values into valid solutions to the problem. For comparison
purposes, a Max-Min Ant System is developed and implemented. This is in
addition to the application of the integer linear programming solver CPLEX for
solving all considered problem instances. The computation results show that the
proposed BRKGA is currently a state-of-the-art technique for the LRS problem.
Nevertheless, the results also show that there is room for improvement,
especially in the context of input strings based on large alphabet sizes.

</details>


### [332] [Cognitive Workspace: Active Memory Management for LLMs -- An Empirical Study of Functional Infinite Context](https://arxiv.org/abs/2508.13171)
*Tao An*

Main category: cs.AI

TL;DR: Cognitive Workspace는 RAG를 넘어 인간의 외부 기억 사용을 모방한 능동적 메모리 관리 패러다임으로, 계층적 인지 버퍼와 과업 기반 컨텍스트 최적화를 통해 LLM의 문맥 한계를 극복하려 한다. 실험에서 전통적 RAG(메모리 재사용 0%)에 비해 평균 58.6% 메모리 재사용률과 17–18% 순효율 향상을 보였고 통계적으로 유의미한 차이를 보고한다.


<details>
  <summary>Details</summary>
Motivation: LLM은 컨텍스트 길이를 늘려도 문맥 관리의 근본적 한계(동적·과업 중심의 메모리 사용 부족)를 갖고 있으며, 기존의 수동적 검색 기반 시스템은 인간의 작업 중심 기억 관리 방식을 반영하지 못한다는 문제의식에서 출발.

Method: 인지과학(Baddeley의 작업기억, Clark의 확장된 마음, Hutchins의 분산인지) 이론을 바탕으로 (1) 능동적 메모리 큐레이션, (2) 계층적 인지 버퍼로 지속적 작업 상태 유지, (3) 과업 구동형 컨텍스트 최적화의 세 가지 설계를 제안하고 50+ 논문을 통합한 이론 프레임워크로 정립. 다양한 태스크에서 재사용률·효율성을 비교 실험 수행.

Result: 평균 58.6% 메모리 재사용(태스크별 54–60%), 전통 RAG 대비 0% 재사용, 3.3배 높은 연산 횟수에도 불구하고 17–18% 순효율 증가. 통계적 유의성 p<0.001, 효과크기 Cohen’s d>23 보고.

Conclusion: 능동적 메모리 관리와 계층적 버퍼를 통한 Cognitive Workspace는 단순 검색을 넘는 '진정한 인지 보강'으로서 LLM 문맥 관리의 패러다임 전환을 제안하며, 정량적 증거로 능동 메모리의 우위를 주장한다.

Abstract: Large Language Models (LLMs) face fundamental limitations in context
management despite recent advances extending context windows to millions of
tokens. We propose Cognitive Workspace, a novel paradigm that transcends
traditional Retrieval-Augmented Generation (RAG) by emulating human cognitive
mechanisms of external memory use. Drawing from cognitive science foundations
including Baddeley's working memory model, Clark's extended mind thesis, and
Hutchins' distributed cognition framework, we demonstrate that current passive
retrieval systems fail to capture the dynamic, task-driven nature of human
memory management. Our analysis of 2024-2025 developments reveals that while
techniques like Infini-attention and StreamingLLM achieve impressive context
lengths, they lack the metacognitive awareness and active planning capabilities
essential for true cognitive extension. Cognitive Workspace addresses these
limitations through three core innovations: (1) active memory management with
deliberate information curation, (2) hierarchical cognitive buffers enabling
persistent working states, and (3) task-driven context optimization that
dynamically adapts to cognitive demands. Empirical validation demonstrates
Cognitive Workspace achieves an average 58.6% memory reuse rate (ranging from
54-60% across different tasks) compared to 0% for traditional RAG, with 17-18%
net efficiency gain despite 3.3x higher operation counts. Statistical analysis
confirms these advantages with p < 0.001 and Cohen's d > 23 across multiple
task types, establishing the first quantitative evidence for active memory
superiority in LLM systems. We present a comprehensive theoretical framework
synthesizing insights from 50+ recent papers, positioning Cognitive Workspace
as a fundamental shift from information retrieval to genuine cognitive
augmentation.

</details>


### [333] [ComputerRL: Scaling End-to-End Online Reinforcement Learning for Computer Use Agents](https://arxiv.org/abs/2508.14040)
*Hanyu Lai,Xiao Liu,Yanxiao Zhao,Han Xu,Hanchen Zhang,Bohao Jing,Yanyu Ren,Shuntian Yao,Yuxiao Dong,Jie Tang*

Main category: cs.AI

TL;DR: ComputerRL은 API-GUI 패러다임과 대규모 분산 RL 인프라, Entropulse 훈련 전략을 결합해 데스크톱 자동화 작업에서 효율적이고 안정적인 대규모 온라인 RL 학습을 가능하게 한 프레임워크이다. GLM-4-9B-0414 기반 AutoGLM-OS-9B가 OSWorld에서 48.1%의 SOTA 성능을 달성했다.


<details>
  <summary>Details</summary>
Motivation: 기계 에이전트와 인간 중심의 데스크톱 환경 간 불일치를 해소하고, 다양한 데스크톱 작업에서 성능과 일반화 능력을 향상시키려면 대규모 종단간 RL 훈련이 필요하지만, 환경 비효율성과 장기간 훈련에서의 불안정성이 문제이다.

Method: (1) API-GUI 패러다임: 프로그램적 API 호출과 직접 GUI 상호작용을 통합해 데스크톱 조작을 처리함.
(2) 분산 RL 인프라: 수천 개의 병렬 가상 데스크톱 환경을 오케스트레이션해 대규모 온라인 RL을 가속.
(3) Entropulse: 강화학습과 감독학습 미세조정을 교대로 수행해 장기 훈련 중 엔트로피 붕괴를 완화.
(4) 모델: GLM-4-9B-0414, Qwen2.5-14B 사용. 평가: OSWorld 벤치마크.

Result: GLM-4-9B-0414 기반의 AutoGLM-OS-9B가 OSWorld에서 48.1% 정확도로 새로운 SOTA를 달성하며, 데스크톱 자동화 일반 에이전트의 성능을 유의미하게 향상시켰다.

Conclusion: ComputerRL의 알고리즘과 프레임워크는 데스크톱 자동화에서 확장성 있고 안정적인 대규모 RL 훈련을 가능하게 하며, 제안 기법은 AutoGLM에 채택되어 실용적 영향력을 입증했다.

Abstract: We introduce ComputerRL, a framework for autonomous desktop intelligence that
enables agents to operate complex digital workspaces skillfully. ComputerRL
features the API-GUI paradigm, which unifies programmatic API calls and direct
GUI interaction to address the inherent mismatch between machine agents and
human-centric desktop environments. Scaling end-to-end RL training is crucial
for improvement and generalization across diverse desktop tasks, yet remains
challenging due to environmental inefficiency and instability in extended
training. To support scalable and robust training, we develop a distributed RL
infrastructure capable of orchestrating thousands of parallel virtual desktop
environments to accelerate large-scale online RL. Furthermore, we propose
Entropulse, a training strategy that alternates reinforcement learning with
supervised fine-tuning, effectively mitigating entropy collapse during extended
training runs. We employ ComputerRL on open models GLM-4-9B-0414 and
Qwen2.5-14B, and evaluate them on the OSWorld benchmark. The AutoGLM-OS-9B
based on GLM-4-9B-0414 achieves a new state-of-the-art accuracy of 48.1%,
demonstrating significant improvements for general agents in desktop
automation. The algorithm and framework are adopted in building AutoGLM (Liu et
al., 2024a)

</details>


### [334] [The Interpretability Analysis of the Model Can Bring Improvements to the Text-to-SQL Task](https://arxiv.org/abs/2508.13178)
*Cong Zhang*

Main category: cs.AI

TL;DR: 제안된 CESQL 모델은 WHERE 절 조건 추론에서 모델 해석성 분석과 실행(실행-유도) 전략을 결합하고 필터·논리 상관관계 보정 및 모델 퓨전을 더해 조건 예측 성능을 크게 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 텍스트→SQL 모델의 기초 역량과 일반화 능력을 실무 환경에서 향상시키고, 특히 WHERE 절의 조건 값 예측에서 테이블 열 데이터 의존도와 수작업 레이블링 의존도를 줄이려 함.

Method: 모델 해석성(interpretability) 분석을 통해 내부 동작을 파악하고, 실행-유도(execution-guided) 전략으로 WHERE 절 의미를 검증·교정한다. 여기에 필터링 조정, 논리적 상관관계 정제, 그리고 여러 모델의 퓨전을 결합해 ‘CESQL’이라는 조건 향상 모델을 설계·적용함.

Result: 단일 테이블 질의 대표 데이터셋인 WikiSQL에서 예측 정확도를 크게 향상시켰으며, WHERE 절 조건 값 예측 시 조건 열의 데이터에 대한 의존도를 줄이고 수작업 레이블의 영향을 회피함.

Conclusion: 기본 데이터베이스 질의 처리 정확도를 개선함으로써 복잡 쿼리나 비정형(real-world) 데이터 시나리오 처리 연구에 새로운 관점을 제공할 수 있다.

Abstract: To elevate the foundational capabilities and generalization prowess of the
text-to-SQL model in real-world applications, we integrate model
interpretability analysis with execution-guided strategy for semantic parsing
of WHERE clauses in SQL queries. Furthermore, we augment this approach with
filtering adjustments, logical correlation refinements, and model fusion,
culminating in the design of the CESQL model that facilitates conditional
enhancement. Our model excels on the WikiSQL dataset, which is emblematic of
single-table database query tasks, markedly boosting the accuracy of prediction
outcomes. When predicting conditional values in WHERE clauses, we have not only
minimized our dependence on data within the condition columns of tables but
also circumvented the impact of manually labeled training data. Our hope is
that this endeavor to enhance accuracy in processing basic database queries
will offer fresh perspectives for research into handling complex queries and
scenarios featuring irregular data in real-world database environments.

</details>


### [335] [Explicit v.s. Implicit Memory: Exploring Multi-hop Complex Reasoning Over Personalized Information](https://arxiv.org/abs/2508.13250)
*Zeyu Zhang,Yang Zhang,Haoran Tan,Rui Li,Xu Chen*

Main category: cs.AI

TL;DR: 이 논문은 개인화된 정보를 기반으로 한 다중 홉 추론(Multi-hop Personalized Reasoning, MPR) 과제를 정의하고, 데이터셋과 통합 평가 프레임워크를 구축한 뒤 다양한 명시적/암묵적 메모리 기법을 비교·분석하고 하이브리드 모델(HybridMem)을 제안해 성능 향상을 보였음을 보고한다.


<details>
  <summary>Details</summary>
Motivation: 현재 LLM 기반 에이전트의 메모리는 개인화와 단순 QA에 사용되어 왔지만, 실제 복잡한 작업은 많은 개인 정보에 대한 다중 홉 추론을 요구하며 기존 메모리 방식으로는 한계가 있다. 이를 해결하기 위해 메모리 메커니즘의 다중 홉 추론 성능을 체계적으로 평가할 필요가 있다.

Method: 다중 홉 개인화 추론(MPR) 과제를 명확히 정의하고, 해당 과제용 데이터셋과 통합 평가 프레임워크를 구축함. 명시적(explicit) 메모리와 암묵적(implicit) 메모리 기법들을 구현하고 비교 실험을 수행. 또한 두 패러다임을 결합한 하이브리드 방식(HybridMem)을 제안하여 각각의 한계를 보완함.

Result: 다양한 메모리 기법을 실험한 결과, 각 방식은 장단점이 존재했으며 하이브리드 접근(특히 제안된 HybridMem)은 성능 우수성을 보였다. 실험을 통해 제안 모델의 효과성을 입증함.

Conclusion: MPR 과제와 데이터셋, 평가 프레임워크는 개인화된 정보에서의 다중 홉 추론 성능을 체계적으로 연구할 수 있게 하며, 하이브리드 메모리 접근이 기존 명시적/암묵적 방법의 한계를 보완해 유망하다는 결론을 제시한다.

Abstract: In large language model-based agents, memory serves as a critical capability
for achieving personalization by storing and utilizing users' information.
Although some previous studies have adopted memory to implement user
personalization, they typically focus on preference alignment and simple
question-answering. However, in the real world, complex tasks often require
multi-hop reasoning on a large amount of user information, which poses
significant challenges for current memory approaches. To address this
limitation, we propose the multi-hop personalized reasoning task to explore how
different memory mechanisms perform in multi-hop reasoning over personalized
information. We explicitly define this task and construct a dataset along with
a unified evaluation framework. Then, we implement various explicit and
implicit memory methods and conduct comprehensive experiments. We evaluate
their performance on this task from multiple perspectives and analyze their
strengths and weaknesses. Besides, we explore hybrid approaches that combine
both paradigms and propose the HybridMem method to address their limitations.
We demonstrate the effectiveness of our proposed model through extensive
experiments. To benefit the research community, we release this project at
https://github.com/nuster1128/MPR.

</details>


### [336] [TASER: Table Agents for Schema-guided Extraction and Recommendation](https://arxiv.org/abs/2508.13404)
*Nicole Cho,Kirsty Fielding,William Watson,Sumitra Ganesh,Manuela Veloso*

Main category: cs.AI

TL;DR: TASER은 복잡하고 비구조화된 다페이지 금융 테이블을 스키마 기반으로 지속적으로 학습하는 에이전트형 추출 시스템으로, 테이블 검출·분류·추출·스키마 권고를 에이전트들이 수행하고 Recommender Agent가 스키마 수정과 최종 권고를 결정하여 기존 모델보다 성능을 높이고 대규모 실제 금융 테이블 데이터셋(TASERTab)을 공개한다.


<details>
  <summary>Details</summary>
Motivation: 실제 금융 문서의 테이블은 파편화되고 다페이지·이종적이며 경계 박스가 거의 없고 행 개수가 매우 많은 등 전형적 테이블 추출 기법이 취약한 특성을 지님. 이러한 현실적 난제를 해결하기 위한 강건한 추출 방법이 필요함.

Method: 스키마로 초기화된 복수의 테이블 에이전트(검출, 분류, 추출, 권고)가 작동하는 에이전트형 시스템 TASER를 제안. Recommender Agent가 출력물을 검토해 스키마 개정안을 제안·결정하고, 이를 통해 지속적 학습(스키마 권고 ↔ 적용)을 수행. 대규모 수작업 라벨링(22,584페이지, 3,213테이블, 28M 토큰)을 통해 학습·평가함.

Result: TASER는 Table Transformer 대비 테이블 검출 성능에서 +10.1% 향상. 배치 사이즈 증가는 액션 가능한 스키마 권고를 104.3% 더 만들어내며, 결과적으로 추출된 보유내역이 9.8% 증가. TASERTab 데이터셋(22,584페이지, $731.7B 상당의 보유 등) 공개.

Conclusion: 에이전트 기반 스키마 유도 추출과 연속 학습 프로세스는 실제 금융 테이블의 강건한 이해·정규화에 유망하며, 공개 데이터셋이 향후 연구를 촉진할 것임.

Abstract: Real-world financial documents report essential information about an entity's
financial holdings that can span millions of different financial instrument
types. Yet, these details are often buried in messy, multi-page, fragmented
tables - for example, 99.4% of the tables in our dataset have no bounding boxes
with the maximum number of rows amounting to 426 per table across 44 pages. To
tackle these unique challenges from real-world tables, we present a
continuously learning, agentic table extraction system, TASER (Table Agents for
Schema-guided Extraction and Recommendation) that extracts highly unstructured,
multi-page, heterogeneous tables into normalized, schema-conforming outputs.
Our table agents execute on table detection, classification, extraction, and
recommendations by leveraging an initial schema. Then, our Recommender Agent
reviews the outputs, recommends schema revisions, and decides on the final
recommendations, enabling TASER to outperform existing table detection models
such as Table Transformer by 10.1%. Within this continuous learning process, we
highlight that larger batch sizes result in a 104.3% increase in schema
recommendations that are actionable and utilized, resulting in a 9.8% increase
in extracted holdings - highlighting the importance of a continuous learning
process. To train TASER, we have manually labeled 22,584 pages (28,150,449
tokens), 3,213 tables for $731,685,511,687 of holdings culminating in one of
the first real financial table datasets. We release our dataset TASERTab to
enable the research community to access real-world financial tables and
outputs. Our results highlight the promise of agentic, schema-guided extraction
systems for robust understanding of real-world financial tables.

</details>


### [337] [Improved Generalized Planning with LLMs through Strategy Refinement and Reflection](https://arxiv.org/abs/2508.13876)
*Katharina Stein,Nils Hodel,Daniel Fišer,Jörg Hoffmann,Michael Katz,Alexander Koller*

Main category: cs.AI

TL;DR: LLM으로 PDDL 도메인의 일반화된 계획을 생성하는 기존 3단계 파이프라인을 개선함. 전략을 자연어 대신 의사코드로 생성하고 의사코드를 자동 디버깅해 오류를 수정한 뒤 파이썬 구현을 생성한다. 파이썬 디버깅에 reflection 단계를 추가하고 여러 코드 변형을 생성해 최적안을 선택한다. 17개 벤치마크 도메인에서 성능이 크게 향상되어, 12개 도메인에서는 모든 생성 가능한 태스크를 해결함.


<details>
  <summary>Details</summary>
Motivation: 단일 자연어 전략을 바로 코드화하면 전략 자체의 오류가 그대로 일반화 계획의 실패로 이어지므로, 전략 단계에서 오류를 조기에 발견·수정할 필요가 있음.

Method: (1) 전략을 자연어가 아니라 의사코드로 생성하여 형식적 검증 및 자동 디버깅 수행, (2) 수정된 의사코드를 기반으로 파이썬 프로그램 생성, (3) 파이썬 디버깅 단계에 LLM에게 실패 원인을 묻는 reflection 프롬프트 추가, (4) 코드 생성에서 여러 변형을 만들고 예제에 대해 성능이 좋은 것 선택.

Result: 제안한 확장들은 일반화 계획의 품질을 실질적으로 개선(절대 악화시키지 않음). 17개 도메인 실험에서 12개 도메인에서는 최적 파이썬 프로그램이 모든 인스턴스 생성 가능한 태스크를 해결함.

Conclusion: 전략을 의사코드 형태로 만들고 그 수준에서 자동 디버깅을 수행하는 것, 그리고 reflection 및 여러 변형 생성은 LLM 기반 일반화 계획 생성의 신뢰성과 성능을 크게 높임.

Abstract: LLMs have recently been used to generate Python programs representing
generalized plans in PDDL planning, i.e., plans that generalize across the
tasks of a given PDDL domain. Previous work proposed a framework consisting of
three steps: the LLM first generates a summary and then a strategy for the
domain, both in natural language, and then implements that strategy as a Python
program, that gets debugged on example planning tasks. In that work, only one
strategy is generated and passed directly to the program generation. If the
strategy is incorrect, its implementation will therefore result in an incorrect
generalized plan. Here, we introduce an approach that generates the strategy in
the form of pseudocode and enables automatic debugging of the pseudocode, hence
allowing us to identify and fix errors prior to the generation of the
generalized plan itself. Additionally, we extend the Python debugging phase
with a reflection step prompting the LLM to pinpoint the reason for the
observed plan failure. Finally, we take inspiration from LLM code generation to
produce several program variants and pick the best one. Running experiments on
17 benchmark domains, we show that these extensions substantially improve (and
never deteriorate) the quality of the generalized plans. In 12 of the domains,
our best Python programs solve all tasks that can be generated with the
respective instance generator.

</details>


### [338] [AlphaEval: A Comprehensive and Efficient Evaluation Framework for Formula Alpha Mining](https://arxiv.org/abs/2508.13174)
*Hongjun Ding,Binqi Chen,Jinsheng Huang,Taian Guo,Zhengyang Mao,Guoyi Shao,Lutong Zou,Luchen Liu,Ming Zhang*

Main category: cs.AI

TL;DR: 


<details>
  <summary>Details</summary>
Motivation: 

Method: 

Result: 

Conclusion: 

Abstract: Formula alpha mining, which generates predictive signals from financial data,
is critical for quantitative investment. Although various algorithmic
approaches-such as genetic programming, reinforcement learning, and large
language models-have significantly expanded the capacity for alpha discovery,
systematic evaluation remains a key challenge. Existing evaluation metrics
predominantly include backtesting and correlation-based measures. Backtesting
is computationally intensive, inherently sequential, and sensitive to specific
strategy parameters. Correlation-based metrics, though efficient, assess only
predictive ability and overlook other crucial properties such as temporal
stability, robustness, diversity, and interpretability. Additionally, the
closed-source nature of most existing alpha mining models hinders
reproducibility and slows progress in this field. To address these issues, we
propose AlphaEval, a unified, parallelizable, and backtest-free evaluation
framework for automated alpha mining models. AlphaEval assesses the overall
quality of generated alphas along five complementary dimensions: predictive
power, stability, robustness to market perturbations, financial logic, and
diversity. Extensive experiments across representative alpha mining algorithms
demonstrate that AlphaEval achieves evaluation consistency comparable to
comprehensive backtesting, while providing more comprehensive insights and
higher efficiency. Furthermore, AlphaEval effectively identifies superior
alphas compared to traditional single-metric screening approaches. All
implementations and evaluation tools are open-sourced to promote
reproducibility and community engagement.

</details>


### [339] [Search-Time Data Contamination](https://arxiv.org/abs/2508.13180)
*Ziwen Han,Meher Mankikar,Julian Michael,Zifan Wang*

Main category: cs.AI

TL;DR: Search-time contamination (STC): search-based LLM agents can retrieve evaluation datasets (or near-duplicates) from the web (notably HuggingFace), allowing them to copy answers instead of reasoning. On three benchmarks (HLE, SimpleQA, GPQA) ~3% of questions had direct leaks; blocking HuggingFace reduced accuracy on the contaminated subset by ~15%. Authors run ablations, find other public sources may also cause STC, release logs, and propose best practices to preserve benchmark validity.


<details>
  <summary>Details</summary>
Motivation: Ensure validity of evaluations for search-enabled LLM agents by identifying and quantifying a novel leakage mode (STC) where retrieval surfaces test data and answers, thus inflating performance and shortening benchmark lifespan.

Method: Analyze logs of search-based LLM agents that use tools to query online sources; identify retrieved sources that contain test questions/answers (esp. HuggingFace); quantify contamination rate across three benchmarks; perform intervention (block HuggingFace) and ablation experiments; release full experiment logs.

Result: Approximately 3% of questions across HLE, SimpleQA, and GPQA had direct matches on HuggingFace enabling copying. After blocking HuggingFace, accuracy on the contaminated subset dropped about 15%. Ablations indicate other public datasets/sources can also cause STC.

Conclusion: STC is a meaningful threat to benchmark integrity for search-based agents. The paper recommends best practices for benchmark design and reporting, and provides logs to facilitate auditing and trustworthy evaluation.

Abstract: Data contamination refers to the leakage of evaluation data into model
training data, resulting in overfitting to supposedly held-out test sets and
compromising test validity. We identify an analogous issue, search-time
contamination (STC), in evaluating search-based LLM agents which use tools to
gather information from online sources when answering user queries. STC occurs
when the retrieval step surfaces a source containing the test question (or a
near-duplicate) alongside its answer, enabling agents to copy rather than
genuinely infer or reason, undermining benchmark integrity. We find that
HuggingFace, an online platform hosting evaluation datasets, appears among
retrieved sources in search based agent logs. Consequently, agents often
explicitly acknowledge discovering question answer pairs from HuggingFace
within their reasoning chains. On three commonly used capability benchmarks:
Humanity's Last Exam (HLE), SimpleQA, and GPQA, we demonstrate that for
approximately 3% of questions, search-based agents directly find the datasets
with ground truth labels on HuggingFace. When millions of evaluation queries
target the same benchmark, even small, repeated leaks can accelerate the
benchmark's obsolescence, shortening its intended lifecycle. After HuggingFace
is blocked, we observe a drop in accuracy on the contaminated subset of
approximately 15%. We further show through ablation experiments that publicly
accessible evaluation datasets on HuggingFace may not be the sole source of
STC. To this end, we conclude by proposing best practices for benchmark design
and result reporting to address this novel form of leakage and ensure
trustworthy evaluation of search-based LLM agents. To facilitate the auditing
of evaluation results, we also publicly release the complete logs from our
experiments.

</details>


### [340] [TASER: Table Agents for Schema-guided Extraction and Recommendation](https://arxiv.org/abs/2508.13404)
*Nicole Cho,Kirsty Fielding,William Watson,Sumitra Ganesh,Manuela Veloso*

Main category: cs.AI

TL;DR: TASER은 복잡하고 비구조화된 다페이지 금융 테이블을 스키마 기반으로 지속적으로 학습하는 에이전트형 추출 시스템으로, 테이블 검출·분류·추출·스키마 권고를 에이전트들이 수행하고 Recommender Agent가 스키마 수정과 최종 권고를 결정하여 기존 모델보다 성능을 높이고 대규모 실제 금융 테이블 데이터셋(TASERTab)을 공개한다.


<details>
  <summary>Details</summary>
Motivation: 실제 금융 문서의 테이블은 파편화되고 다페이지·이종적이며 경계 박스가 거의 없고 행 개수가 매우 많은 등 전형적 테이블 추출 기법이 취약한 특성을 지님. 이러한 현실적 난제를 해결하기 위한 강건한 추출 방법이 필요함.

Method: 스키마로 초기화된 복수의 테이블 에이전트(검출, 분류, 추출, 권고)가 작동하는 에이전트형 시스템 TASER를 제안. Recommender Agent가 출력물을 검토해 스키마 개정안을 제안·결정하고, 이를 통해 지속적 학습(스키마 권고 ↔ 적용)을 수행. 대규모 수작업 라벨링(22,584페이지, 3,213테이블, 28M 토큰)을 통해 학습·평가함.

Result: TASER는 Table Transformer 대비 테이블 검출 성능에서 +10.1% 향상. 배치 사이즈 증가는 액션 가능한 스키마 권고를 104.3% 더 만들어내며, 결과적으로 추출된 보유내역이 9.8% 증가. TASERTab 데이터셋(22,584페이지, $731.7B 상당의 보유 등) 공개.

Conclusion: 에이전트 기반 스키마 유도 추출과 연속 학습 프로세스는 실제 금융 테이블의 강건한 이해·정규화에 유망하며, 공개 데이터셋이 향후 연구를 촉진할 것임.

Abstract: Real-world financial documents report essential information about an entity's
financial holdings that can span millions of different financial instrument
types. Yet, these details are often buried in messy, multi-page, fragmented
tables - for example, 99.4% of the tables in our dataset have no bounding boxes
with the maximum number of rows amounting to 426 per table across 44 pages. To
tackle these unique challenges from real-world tables, we present a
continuously learning, agentic table extraction system, TASER (Table Agents for
Schema-guided Extraction and Recommendation) that extracts highly unstructured,
multi-page, heterogeneous tables into normalized, schema-conforming outputs.
Our table agents execute on table detection, classification, extraction, and
recommendations by leveraging an initial schema. Then, our Recommender Agent
reviews the outputs, recommends schema revisions, and decides on the final
recommendations, enabling TASER to outperform existing table detection models
such as Table Transformer by 10.1%. Within this continuous learning process, we
highlight that larger batch sizes result in a 104.3% increase in schema
recommendations that are actionable and utilized, resulting in a 9.8% increase
in extracted holdings - highlighting the importance of a continuous learning
process. To train TASER, we have manually labeled 22,584 pages (28,150,449
tokens), 3,213 tables for $731,685,511,687 of holdings culminating in one of
the first real financial table datasets. We release our dataset TASERTab to
enable the research community to access real-world financial tables and
outputs. Our results highlight the promise of agentic, schema-guided extraction
systems for robust understanding of real-world financial tables.

</details>


### [341] [Breaking the SFT Plateau: Multimodal Structured Reinforcement Learning for Chart-to-Code Generation](https://arxiv.org/abs/2508.13587)
*Lei Chen,Xuanle Zhao,Zhixiong Zeng,Jing Huang,Liming Zheng,Yufeng Zhong,Lin Ma*

Main category: cs.AI

TL;DR: 차트에서 구조화된 코드로 변환하는 문제에서 SFT는 한계에 봉착하며, 저자들은 대규모 실제 데이터(3M 차트-코드 쌍)와 다중-입력·다중-세분화 보상(텍스트 규칙 기반 + 시각적 모델 기반)을 활용한 Multimodal Structured Reinforcement Learning(MSRL)을 제안해 이 한계를 돌파했다. MSRL은 두 단계 커리큘럼으로 안정적으로 학습되며 ChartMimic과 ReachQA에서 각각 상위 지표를 6.2%·9.9% 향상시켰다.


<details>
  <summary>Details</summary>
Motivation: 차트처럼 정보가 풍부한 시각 자료에서 복잡한 추론을 통해 구조화된 코드를 생성하는 작업은 단순한 SFT만으로는 성능 한계(플래토)를 보이며, 구조적 출력에 적절한 보상을 제공하는 RL 전략이 필요하다.

Method: 1) 대규모 실제 데이터 수집: arXiv 테이블 기반 3M 차트-코드 쌍 구축으로 합성 데이터의 단순 패턴 회피. 2) MSRL 설계: 멀티-그레인(세분화) 구조 보상 사용—텍스트 수준에서는 규칙 기반 보상으로 코드의 세세한 부분 검증, 시각 수준에서는 생성 코드를 렌더링해 이미지로 변환한 뒤 평가자 모델로 구조적 유사성 평가. 3) 학습 안정성을 위해 2단계 커리큘럼 적용.

Result: MSRL은 SFT 스케일링으로는 도달하기 힘든 성능 향상을 달성함. ChartMimic에서 상위 지표 6.2% 향상, ReachQA에서 9.9% 향상. SFT는 데이터 증대로 결국 성능 플래토에 도달했으나 MSRL로 이를 돌파했고, 폐쇄형 고성능 모델들과 경쟁 가능한 성능을 보임.

Conclusion: 차트-투-코드 과제에서는 대규모 실제 데이터와 멀티모달·구조적 보상을 결합한 강화학습(MSRL)이 SFT의 한계를 극복하는 효과적인 접근법이다. 멀티그레인 보상과 시각적 평가, 커리큘럼 학습이 핵심 요소로 작용한다.

Abstract: While reinforcement learning (RL) has proven highly effective for general
reasoning in vision-language models, its application to tasks requiring
in-depth understanding of information-rich images and generation of structured
outputs remains underexplored. Chart-to-code generation exemplifies this
challenge, demanding complex reasoning over visual charts to generate
structured code. Supervised fine-tuning (SFT) alone is often insufficient,
highlighting the need for effective RL strategies that appropriately reward
structured outputs. We systematically investigate the performance plateau in
SFT through large-scale experiments and propose Multimodal Structured
Reinforcement Learning (MSRL) for chart-to-code generation, which substantially
breaks through this plateau. We construct the largest training corpus to date,
containing 3 million chart-code pairs from real-world arXiv tables to mitigate
simplistic patterns of prior synthetic data. Despite reaching state-of-the-art
performance, our experiments show that scaling SFT data eventually hits a
plateau where further increases yield negligible improvements. Our MSRL method
leverages a multi-granularity structured reward system using multimodal textual
and visual feedback. At the textual level, rule-based rewards validate
fine-grained code details. At the visual level, model-based rewards assess
structural similarity by rendering generated code into images and employing an
evaluator model. We implement this within a two-stage curriculum for training
stability. Results demonstrate that MSRL significantly breaks the SFT plateau,
improving high-level metrics by 6.2% and 9.9% on ChartMimic and ReachQA
benchmarks respectively, achieving competitive performance with advanced
closed-source models.

</details>


### [342] [Interactive Query Answering on Knowledge Graphs with Soft Entity Constraints](https://arxiv.org/abs/2508.13663)
*Daniel Daza,Alberto Bernardi,Luca Costabello,Christophe Gueret,Masoud Mansoury,Michael Cochez,Martijn Schut*

Main category: cs.AI

TL;DR: 논문은 불완전한 지식 그래프(KG)에서 직접 경로로 도달할 수 없는 답변들을 찾는 문제에 대해, 기존의 엄격한 논리 기반 질의에서 벗어나 애매하거나 문맥 의존적인 제약(soft constraints)을 다루는 새 문제를 제안한다. 이를 해결하기 위해 Neural Query Reranker(NQR)를 제시하고, 원래 질의의 답을 해치지 않으면서 소프트 제약을 반영해 답 점수를 조정하도록 학습한다. NQR는 대화형으로 작동하며 선호/비선호 예시를 점진적으로 반영한다. 데이터셋 확장과 실험에서 NQR가 소프트 제약을 잘 포착하면서 견고한 질의 응답 성능을 유지함을 보였다.


<details>
  <summary>Details</summary>
Motivation: 기존의 KG 질의 응답 방식은 결손된 엣지 때문에 정답에 직접 도달하지 못하는 경우가 있어, 그래프 기반 추론/순위화가 필요하다. 그러나 실제 쿼리에는 선호나 속성 같은 모호하고 문맥 의존적인 제약이 자주 포함되어 기존의 1차 논리 기반 포맷으로 표현하기 어렵다. 이러한 소프트 제약을 반영한 질의 응답 체계가 필요하다.

Method: Neural Query Reranker(NQR)를 제안한다. NQR는 기존 쿼리 응답 후보의 점수를 조정하는 재순위기(re-ranker)로, 원래의 정답들을 보존하면서 소프트 제약을 반영하도록 설계됐다. 모델은 상호작용적으로 작동하며, 선호/비선호 엔티티의 점진적 피드백을 받아 점수를 갱신한다. 또한 기존 QA 벤치마크를 확장해 소프트 제약이 포함된 데이터셋을 생성했다.

Result: 실험 결과 NQR는 소프트 제약을 효과적으로 학습해 선호를 반영한 재순위 결과를 제공하며, 원래의 질의 응답 성능도 유지하거나 크게 훼손하지 않았다.

Conclusion: 소프트 제약을 포함한 질의 응답은 현실적 요구를 더 잘 반영하며, NQR는 상호작용적 예시 기반 학습을 통해 이를 달성할 수 있음을 보였다. 이 방향은 지식 그래프 기반 QA 시스템의 유연성과 사용자 맞춤화를 향상시킬 수 있다.

Abstract: Methods for query answering over incomplete knowledge graphs retrieve
entities that are likely to be answers, which is particularly useful when such
answers cannot be reached by direct graph traversal due to missing edges.
However, existing approaches have focused on queries formalized using
first-order-logic. In practice, many real-world queries involve constraints
that are inherently vague or context-dependent, such as preferences for
attributes or related categories. Addressing this gap, we introduce the problem
of query answering with soft constraints. We propose a Neural Query Reranker
(NQR) designed to adjust query answer scores by incorporating soft constraints
without disrupting the original answers to a query. NQR operates interactively,
refining answers based on incremental examples of preferred and non-preferred
entities. We extend existing QA benchmarks by generating datasets with soft
constraints. Our experiments demonstrate that NQR can capture soft constraints
while maintaining robust query answering performance.

</details>


### [343] [Neuro-Symbolic Artificial Intelligence: Towards Improving the Reasoning Abilities of Large Language Models](https://arxiv.org/abs/2508.13678)
*Xiao-Wen Yang,Jie-Jing Shao,Lan-Zhe Guo,Bo-Wen Zhang,Zhi Zhou,Lin-Han Jia,Wang-Zhou Dai,Yu-Feng Li*

Main category: cs.AI

TL;DR: Comprehensive survey of neuro-symbolic methods to improve reasoning in LLMs: formalizes reasoning tasks, introduces the neurosymbolic paradigm, categorizes methods into Symbolic->LLM, LLM->Symbolic, and LLM+Symbolic, and discusses challenges and future directions; provides an accompanying GitHub resource list.


<details>
  <summary>Details</summary>
Motivation: LLMs show strong performance but lack robust reasoning; improving reasoning is crucial for progress toward AGI and has high academic/industrial interest. Neuro-symbolic approaches are particularly promising for combining strengths of symbolic reasoning and neural LLMs.

Method: Literature survey: (1) formalize reasoning tasks, (2) overview neurosymbolic learning paradigm, (3) review and categorize recent neuro-symbolic techniques into three perspectives—Symbolic->LLM (inject symbolic knowledge/constraints into LLMs), LLM->Symbolic (use LLMs to generate or drive symbolic components), and LLM+Symbolic (tight integration/hybrid pipelines), (4) analyze strengths/limitations, and (5) compile challenges and future directions; release a GitHub repo of papers/resources.

Result: A structured taxonomy and synthesis of recent neuro-symbolic work targeting LLM reasoning, highlighting representative methods in each category, comparative insights on effectiveness and limitations, and an organized resource repository for researchers.

Conclusion: Neuro-symbolic approaches are a promising avenue to enhance LLM reasoning, but key challenges remain (scalability, alignment, benchmarks, interpretability, compositionality). The survey maps current progress, gaps, and promising research directions and provides resources for follow-up work.

Abstract: Large Language Models (LLMs) have shown promising results across various
tasks, yet their reasoning capabilities remain a fundamental challenge.
Developing AI systems with strong reasoning capabilities is regarded as a
crucial milestone in the pursuit of Artificial General Intelligence (AGI) and
has garnered considerable attention from both academia and industry. Various
techniques have been explored to enhance the reasoning capabilities of LLMs,
with neuro-symbolic approaches being a particularly promising way. This paper
comprehensively reviews recent developments in neuro-symbolic approaches for
enhancing LLM reasoning. We first present a formalization of reasoning tasks
and give a brief introduction to the neurosymbolic learning paradigm. Then, we
discuss neuro-symbolic methods for improving the reasoning capabilities of LLMs
from three perspectives: Symbolic->LLM, LLM->Symbolic, and LLM+Symbolic.
Finally, we discuss several key challenges and promising future directions. We
have also released a GitHub repository including papers and resources related
to this survey: https://github.com/LAMDASZ-ML/Awesome-LLM-Reasoning-with-NeSy.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [344] [Research on Conversational Recommender System Considering Consumer Types](https://arxiv.org/abs/2508.13209)
*Yaying Luo,Hui Fang,Zhu Sun*

Main category: cs.IR

TL;DR: CT-CRS는 소비자 유형(의사결정 스타일과 지식수준에 따른 4분류)을 실시간으로 추론해 맞춤형 대화 추천 정책을 적용하고 IRL로 정책을 최적화하여 추천 성공률을 높이고 대화 턴을 줄인다.


<details>
  <summary>Details</summary>
Motivation: 기존 대화형 추천 시스템은 사용자마다 다른 의사결정 스타일(최대화자 vs 만족화자)과 지식 수준을 반영하지 않아 추천 정확성과 효율성이 제한된다.

Method: 소비자 유형 이론에 기반해 사용자 유형(의존형, 효율형, 신중형, 전문가)을 정의하고, 상호작용 이력으로 LLM을 미세조정해 실시간 유형 추론을 수행한다. 유형을 상태 표현에 포함시키고, 유형에 적응하는 정책으로 추천의 세분성·다양성·속성 질의 복잡도를 동적으로 조절한다. 정책 학습에는 Inverse Reinforcement Learning을 사용해 전문가 유사 전략을 모방한다.

Result: LastFM, Amazon-Book, Yelp 데이터셋에서 CT-CRS는 강력한 기준선보다 추천 성공률을 개선하고 대화 턴을 감소시켰다. 소거 연구에서 소비자 유형 모델링과 IRL이 성능 향상에 유의미하게 기여함을 확인했다.

Conclusion: CT-CRS는 심리학적 사용자 모델링과 고급 정책 최적화를 통합해 CRS의 개인화, 효율성, 해석가능성을 향상시키는 확장 가능하고 해석 가능한 솔루션을 제시한다.

Abstract: Conversational Recommender Systems (CRS) provide personalized services
through multi-turn interactions, yet most existing methods overlook users'
heterogeneous decision-making styles and knowledge levels, which constrains
both accuracy and efficiency. To address this gap, we propose CT-CRS (Consumer
Type-Enhanced Conversational Recommender System), a framework that integrates
consumer type modeling into dialogue recommendation. Based on consumer type
theory, we define four user categories--dependent, efficient, cautious, and
expert--derived from two dimensions: decision-making style (maximizers vs.
satisficers) and knowledge level (high vs. low). CT-CRS employs interaction
histories and fine-tunes the large language model to automatically infer user
types in real time, avoiding reliance on static questionnaires. We incorporate
user types into state representation and design a type-adaptive policy that
dynamically adjusts recommendation granularity, diversity, and attribute query
complexity. To further optimize the dialogue policy, we adopt Inverse
Reinforcement Learning (IRL), enabling the agent to approximate expert-like
strategies conditioned on consumer type. Experiments on LastFM, Amazon-Book,
and Yelp show that CTCRS improves recommendation success rate and reduces
interaction turns compared to strong baselines. Ablation studies confirm that
both consumer type modeling and IRL contribute significantly to performance
gains. These results demonstrate that CT-CRS offers a scalable and
interpretable solution for enhancing CRS personalization through the
integration of psychological modeling and advanced policy optimization.

</details>


### [345] [FLAIR: Feedback Learning for Adaptive Information Retrieval](https://arxiv.org/abs/2508.13390)
*William Zhang,Yiwen Zhu,Yunlei Lu,Mathieu Demarne,Wenjing Wang,Kai Deng,Nutan Sahoo,Katherine Lin,Miso Cilimdzic,Subru Krishnan*

Main category: cs.IR

TL;DR: FLAIR은 도메인 전문가의 피드백을 통합해 코파일럿의 검색 전략을 적응시키는 경량 피드백 학습 프레임워크다. 오프라인 단계에서 사용자 피드백과 문서에서 합성한 질문을 통해 지표를 수집·분산 저장하고, 온라인 단계에서는 원시 유사도 점수와 지표를 결합하는 이중 트랙 랭킹을 적용해 검색을 반복적으로 개선한다. 실환경 평가에서 기존 방법을 능가했으며 Copilot DECO에 통합되어 수천 사용자를 지원한다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 코파일럿의 복잡한 기술 시나리오 확산으로 도메인 특화 정보 검색 솔루션의 필요성이 증가했다. 기존 일반적 검색 방식은 도메인 지식과 사용자 피드백을 반영하지 못해 성능 한계가 있어, 경량 피드백 학습을 통한 검색 적응화 필요성이 제시된다.

Method: FLAIR은 오프라인과 온라인 두 단계로 동작한다. 오프라인에서 (1) 사용자 피드백과 (2) 문서로부터 합성한 질문을 통해 지표를 생성·분산 저장한다. 온라인에서는 두 가지 트랙(원시 유사도 점수 트랙, 지표 기반 트랙)을 결합해 최종 랭킹을 생성한다. 반복적 피드백 루프를 통해 검색 성능을 점진적으로 향상시킨다.

Result: 실제 운영 환경 평가에서 본 기법은 기존 최첨단 방법들을 능가하는 유의미한 성능 향상을 보였다. 보지 못한 쿼리에도 개선을 보였고, Copilot DECO에 적용되어 수천 명 규모의 사용자를 처리하며 확장성과 효과성을 확인했다.

Conclusion: FLAIR은 경량의 피드백 학습과 분산 지표 저장, 이중 트랙 랭킹을 통해 코파일럿의 검색 성능을 실환경에서 효율적으로 개선한다. 도메인 전문가 피드백을 통합함으로써 기존 방법 대비 더 우수한 적응능력과 확장성을 제공한다.

Abstract: Recent advances in Large Language Models (LLMs) have driven the adoption of
copilots in complex technical scenarios, underscoring the growing need for
specialized information retrieval solutions. In this paper, we introduce FLAIR,
a lightweight, feedback learning framework that adapts copilot systems'
retrieval strategies by integrating domain-specific expert feedback. FLAIR
operates in two stages: an offline phase obtains indicators from (1) user
feedback and (2) questions synthesized from documentation, storing these
indicators in a decentralized manner. An online phase then employs a two-track
ranking mechanism to combine raw similarity scores with the collected
indicators. This iterative setup refines retrieval performance for any query.
Extensive real-world evaluations of FLAIR demonstrate significant performance
gains on both previously seen and unseen queries, surpassing state-of-the-art
approaches. The system has been successfully integrated into Copilot DECO,
serving thousands of users at Microsoft, demonstrating its scalability and
effectiveness in operational environments.

</details>


### [346] [CASPER: Concept-integrated Sparse Representation for Scientific Retrieval](https://arxiv.org/abs/2508.13394)
*Lam Thanh Do,Linh Van Nguyen,David Fu,Kevin Chen-Chuan Chang*

Main category: cs.IR

TL;DR: CASPER은 토큰과 핵심어(keyphrase)를 표현 단위로 사용하는 희소 검색 모델로, 과학 논문 검색에서 쿼리와 문서를 개념적·세부적으로 매칭한다. 학습 데이터 부족 문제를 해결하기 위해 제목, 인용 문맥, 저자가 지정한 핵심어, 공동 인용 등 학술적 참조 신호를 활용해 학습 데이터를 마이닝한다. 여러 과학 검색 벤치마크에서 강력한 희소·밀집 베이스라인을 능가하며, 후처리로 핵심어 생성에도 활용되어 더 다양한 핵심어를 빠르게 생성한다.


<details>
  <summary>Details</summary>
Motivation: 학술 문헌의 폭발적 증가로 연구자들이 최신 문헌을 따라잡기 어려워졌고, 기존 검색 모델은 개념적·세부적 매칭에서 한계가 있어 연구 개념을 잘 반영하는 표현 단위가 필요했다.

Method: 토큰과 키프레이즈를 희소 임베딩 차원으로 사용하는 CASPER 모델을 제안. 학습을 위해 제목, 인용 문맥, 저자 핵심어, 공동 인용 등을 이용해 긍정적 쿼리-문서 쌍을 마이닝하여 학습 데이터를 생성하고, 이 데이터를 통해 모델을 학습시킴. 또한 간단한 후처리로 키프레이즈 생성에 활용.

Result: 8개의 과학 검색 벤치마크에서 강력한 희소 및 밀집 검색 베이스라인을 능가. 키프레이즈 생성에서도 CopyRNN 수준의 성능을 보이며 더 다양한 키프레이즈를 거의 4배 빠르게 생성.

Conclusion: 토큰+키프레이즈 기반 희소 표현과 학술적 참조 신호를 이용한 데이터 마이닝으로 학술 검색과 키프레이즈 생성에서 효율적이고 경쟁력 있는 성능을 달성한다.

Abstract: The exponential growth of scientific literature has made it increasingly
difficult for researchers to keep up with the literature. In an attempt to
alleviate this problem, we propose CASPER, a sparse retrieval model for
scientific search that utilizes tokens and keyphrases as representation units
(i.e. dimensions in the sparse embedding space), enabling it to represent
queries and documents with research concepts and match them at both granular
and conceptual levels. To overcome the lack of suitable training data, we
propose mining training data by leveraging scholarly references (i.e. signals
that capture how research concepts of papers are expressed in different
settings), including titles, citation contexts, author-assigned keyphrases, and
co-citations. CASPER outperforms strong dense and sparse retrieval baselines on
eight scientific retrieval benchmarks. Moreover, we demonstrate that through
simple post-processing, CASPER can be effectively used for the keyphrase
generation tasks, achieving competitive performance with the established
CopyRNN while producing more diverse keyphrases and being nearly four times
faster.

</details>


### [347] [AdaptJobRec: Enhancing Conversational Career Recommendation through an LLM-Powered Agentic System](https://arxiv.org/abs/2508.13423)
*Qixin Wang,Dawei Wang,Kun Chen,Yaowei Hu,Puneet Girdhar,Ruoteng Wang,Aadesh Gupta,Chaitanya Devella,Wenlai Guo,Shangwen Huang,Bachir Aoun,Greg Hayworth,Han Li,Xintao Wu*

Main category: cs.IR

TL;DR: AdaptJobRec는 질의 복잡도 판별로 응답 지연을 줄이고, 에이전트 기반 개인화 추천 도구를 결합해 정확도를 높인 대화형 채용 추천 시스템이다. 간단한 질문은 직접 도구 선택으로 빠르게 처리하고, 복잡한 질문은 메모리 필터링→작업 분해 계획→개인화 추천 도구 실행으로 처리해 응답 지연을 최대 53.3% 감소시키고 추천 정확도를 향상시켰다.


<details>
  <summary>Details</summary>
Motivation: 대화형 추천 시스템(CRS)은 단순 추천 목록을 넘어 주제 중심 서비스를 제공하도록 진화했으나, 고급 추론과 자기수정 능력을 갖춘 에이전트 기반 시스템은 응답 지연(latency) 문제가 심각하다. 복잡한 질의를 잘 처리하면서도 지연을 최소화하는 방법이 필요하다.

Method: AdaptJobRec는 자율 에이전트를 활용해 개인화 추천 알고리즘 도구를 통합한다. 사용자 질의 복잡도 식별기로 쿼리를 분류하고, 단순 쿼리는 적절한 도구를 바로 호출해 빠르게 응답한다. 복잡 쿼리는 메모리 처리 모듈로 대화 이력을 필터링한 뒤, 지능형 작업 분해 플래너로 세분화된 작업을 생성하고 개인화 추천 도구로 실행한다.

Result: Walmart의 실제 채용 추천 시나리오에서 평가한 결과, AdaptJobRec는 경쟁적 베이스라인 대비 평균 응답 지연을 최대 53.3%까지 줄였고 추천 정확도도 유의미하게 향상시켰다.

Conclusion: 질의 복잡도 기반 경로 분기와 에이전트-도구 통합 설계를 통해 AdaptJobRec는 대기시간과 추천 성능 사이의 균형을 효과적으로 개선하며, 실제 채용 추천 환경에서 실용적 이점을 보였다.

Abstract: In recent years, recommendation systems have evolved from providing a single
list of recommendations to offering a comprehensive suite of topic focused
services. To better accomplish this task, conversational recommendation systems
(CRS) have progressed from basic retrieval augmented LLM generation to agentic
systems with advanced reasoning and self correction capabilities. However,
agentic systems come with notable response latency, a longstanding challenge
for conversational recommendation systems. To balance the trade off between
handling complex queries and minimizing latency, we propose AdaptJobRec, the
first conversational job recommendation system that leverages autonomous agent
to integrate personalized recommendation algorithm tools. The system employs a
user query complexity identification mechanism to minimize response latency.
For straightforward queries, the agent directly selects the appropriate tool
for rapid responses. For complex queries, the agent uses the memory processing
module to filter chat history for relevant content, then passes the results to
the intelligent task decomposition planner, and finally executes the tasks
using personalized recommendation tools. Evaluation on Walmart's real world
career recommendation scenarios demonstrates that AdaptJobRec reduces average
response latency by up to 53.3% compared to competitive baselines, while
significantly improving recommendation accuracy.

</details>


### [348] [LLM-Enhanced Linear Autoencoders for Recommendation](https://arxiv.org/abs/2508.13500)
*Jaewan Moon,Seongmin Park,Jongwuk Lee*

Main category: cs.IR

TL;DR: L3AE는 LLM으로부터 얻은 아이템 임베딩으로 의미적 아이템-아이템 상관행렬을 구성하고, 협업 신호로부터 학습한 아이템-아이템 가중치 행렬에 이를 정규화로 증류하는 두 단계의 선형 오토인코더 통합 방식이다. 두 단계 모두 닫힌 형식 해(closed-form)를 사용해 전역 최적성과 효율성을 보장하며, 여러 벤치마크에서 기존 LLM 강화 모델들을 크게 앞선다.


<details>
  <summary>Details</summary>
Motivation: 기존 LAE는 텍스트 정보를 희소한 단어 동시 발생 패턴에 의존해 풍부한 텍스트 의미를 포착하지 못한다. 따라서 LLM이 제공하는 풍부한 의미 지식을 LAE에 통합해 추천 성능을 향상시킬 필요가 있다.

Method: 두 단계 최적화(1) LLM으로부터 얻은 아이템 표현으로 의미적 아이템-아이템 상관행렬을 구성(semantic correlation matrix) (2) 협업 신호로부터 아이템-아이템 가중치 행렬을 학습하되, 의미 상관을 정규화로 증류하여 학습. 각 단계는 닫힌 형식 해로 최적화되어 계산 효율 및 전역 최적성 확보.

Result: 세 개의 벤치마크 데이터셋에서 기존 LLM 기반 SOTA 모델들 대비 일관된 성능 향상. 예시로 Recall@20에서 +27.6%, NDCG@20에서 +39.3%의 향상을 보고.

Conclusion: L3AE는 LLM 기반 의미 정보를 LAE 프레임워크에 최초로 통합한 방법으로, 텍스트 의미와 협업 신호의 이질적 지식을 효과적으로 결합해 성능과 효율성을 동시에 달성한다. 소스 코드는 공개되어 있음.

Abstract: Large language models (LLMs) have been widely adopted to enrich the semantic
representation of textual item information in recommender systems. However,
existing linear autoencoders (LAEs) that incorporate textual information rely
on sparse word co-occurrence patterns, limiting their ability to capture rich
textual semantics. To address this, we propose L3AE, the first integration of
LLMs into the LAE framework. L3AE effectively integrates the heterogeneous
knowledge of textual semantics and user-item interactions through a two-phase
optimization strategy. (i) L3AE first constructs a semantic item-to-item
correlation matrix from LLM-derived item representations. (ii) It then learns
an item-to-item weight matrix from collaborative signals while distilling
semantic item correlations as regularization. Notably, each phase of L3AE is
optimized through closed-form solutions, ensuring global optimality and
computational efficiency. Extensive experiments demonstrate that L3AE
consistently outperforms state-of-the-art LLM-enhanced models on three
benchmark datasets, achieving gains of 27.6% in Recall@20 and 39.3% in NDCG@20.
The source code is available at https://github.com/jaewan7599/L3AE_CIKM2025.

</details>


### [349] [Heterogeneous Influence Maximization in User Recommendation](https://arxiv.org/abs/2508.13517)
*Hongru Hou,Jiachen Sun,Wenqing Lin,Wendong Bi,Xiangrong Wang,Deqing Yang*

Main category: cs.IR

TL;DR: Proposes HeteroIR and HeteroIM to bridge recommender systems and Influence Maximization (IM): HeteroIR is a two-stage framework estimating spread profit to unleash candidates’ dissemination potential; HeteroIM incrementally selects and reranks invitees based on counts of reverse reachable (RR) sets involving inviters and invitees, balancing interaction willingness and propagation. Shows significant offline gains (p<0.05) and online A/B improvements (8.5% and 10%) on Tencent gaming platforms. Code: https://github.com/socialalgo/HIM.


<details>
  <summary>Details</summary>
Motivation: Recommendation systems encourage users to invite others but usually model only willingness to interact and fail to exploit invitees’ spreading capability. IM methods maximize propagation but ignore invitees’ willingness. There is a need to combine both aspects to improve real-world propagation.

Method: HeteroIR: a two-stage framework that estimates spread profits of candidate invitees to better unleash dissemination potential. HeteroIM: an incremental selection and reranking algorithm that chooses the most influential invitees using counts of reverse reachable (RR) sets that contain both inviters and invitees; RR sets represent nodes that can reach a target under propagation. The approach integrates interaction willingness into IM-style selection.

Result: Extensive experiments show HeteroIR and HeteroIM significantly outperform state-of-the-art baselines (p < 0.05). Online deployment on Tencent gaming platforms yielded 8.5% (HeteroIR) and 10% (HeteroIM) improvements in A/B tests.

Conclusion: Bridging recommendation and IM via a heterogeneous framework and RR-set-based selection improves both interaction willingness and propagation coverage. The methods are effective in offline evaluation and real-world deployment; implementation is publicly available.

Abstract: User recommendation systems enhance user engagement by encouraging users to
act as inviters to interact with other users (invitees), potentially fostering
information propagation. Conventional recommendation methods typically focus on
modeling interaction willingness. Influence-Maximization (IM) methods focus on
identifying a set of users to maximize the information propagation. However,
existing methods face two significant challenges. First, recommendation methods
fail to unleash the candidates' spread capability. Second, IM methods fail to
account for the willingness to interact. To solve these issues, we propose two
models named HeteroIR and HeteroIM. HeteroIR provides an intuitive solution to
unleash the dissemination potential of user recommendation systems. HeteroIM
fills the gap between the IM method and the recommendation task, improving
interaction willingness and maximizing spread coverage. The HeteroIR introduces
a two-stage framework to estimate the spread profits. The HeteroIM
incrementally selects the most influential invitee to recommend and rerank
based on the number of reverse reachable (RR) sets containing inviters and
invitees. RR set denotes a set of nodes that can reach a target via
propagation. Extensive experiments show that HeteroIR and HeteroIM
significantly outperform the state-of-the-art baselines with the p-value <
0.05. Furthermore, we have deployed HeteroIR and HeteroIM in Tencent's online
gaming platforms and gained an 8.5\% and 10\% improvement in the online A/B
test, respectively. Implementation codes are available at
https://github.com/socialalgo/HIM.

</details>


### [350] [ENCODE: Breaking the Trade-Off Between Performance and Efficiency in Long-Term User Behavior Modeling](https://arxiv.org/abs/2508.13567)
*Wenji Zhou,Yuhang Zheng,Yinfu Feng,Yunan Ye,Rong Xiao,Long Chen,Xiaosong Yang,Jun Xiao*

Main category: cs.IR

TL;DR: 긴 사용자 행동 시퀀스에서 정확하고 효율적으로 장기 관심사를 추출하기 위해, 오프라인 클러스터링(차원 축소 포함)으로 관심사를 미리 추출하고 온라인에서는 미리 추출된 관심사와 타깃 아이템의 관련성을 빠르게 계산하는 두 단계(ENCODE) 방식 제안.


<details>
  <summary>Details</summary>
Motivation: 긴 행동 시퀀스 전체를 활용해 정보 손실을 막으면서도 온라인 서빙에서 빠르게 응답해야 함. 기존 방법들은 전체 시퀀스 정보 보존(R1)과 타깃 아이템과의 높은 관련성 추출(R2)이라는 두 요구사항을 동시에 만족하지 못함.

Method: ENCODE: (1) 오프라인 추출 단계: 전체 행동 시퀀스를 클러스터링해 정확한 관심사 집합을 추출. 클러스터링 비용을 줄이기 위해 쌍별 거리 관계를 보존하는 메트릭 러닝 기반 차원 축소 도입. (2) 온라인 추론 단계: 오프라인에서 얻은 사용자 관심사를 사용해 타깃 아이템과의 연관성을 예측. 파이프라인 전반에 걸쳐 동일한 관련성(리levance) 메트릭을 사용해 일관성 유지.

Result: 광범위한 실험에서 SOTA 대비 정확도와 효율성 면에서 개선을 보였음(구체적 수치와 실험 설정은 초록에 없음).

Conclusion: ENCODE는 R1과 R2를 모두 만족하면서 오프라인 비용과 온라인 응답 속도 사이에 바람직한 균형을 제공, 장기 사용자 관심사 모델링의 정확성과 효율성을 동시에 향상시킴.

Abstract: Long-term user behavior sequences are a goldmine for businesses to explore
users' interests to improve Click-Through Rate. However, it is very challenging
to accurately capture users' long-term interests from their long-term behavior
sequences and give quick responses from the online serving systems. To meet
such requirements, existing methods "inadvertently" destroy two basic
requirements in long-term sequence modeling: R1) make full use of the entire
sequence to keep the information as much as possible; R2) extract information
from the most relevant behaviors to keep high relevance between learned
interests and current target items. The performance of online serving systems
is significantly affected by incomplete and inaccurate user interest
information obtained by existing methods. To this end, we propose an efficient
two-stage long-term sequence modeling approach, named as EfficieNt Clustering
based twO-stage interest moDEling (ENCODE), consisting of offline extraction
stage and online inference stage. It not only meets the aforementioned two
basic requirements but also achieves a desirable balance between online service
efficiency and precision. Specifically, in the offline extraction stage, ENCODE
clusters the entire behavior sequence and extracts accurate interests. To
reduce the overhead of the clustering process, we design a metric
learning-based dimension reduction algorithm that preserves the relative
pairwise distances of behaviors in the new feature space. While in the online
inference stage, ENCODE takes the off-the-shelf user interests to predict the
associations with target items. Besides, to further ensure the relevance
between user interests and target items, we adopt the same relevance metric
throughout the whole pipeline of ENCODE. The extensive experiment and
comparison with SOTA have demonstrated the effectiveness and efficiency of our
proposed ENCODE.

</details>


### [351] [Understanding Distribution Structure on Calibrated Recommendation Systems](https://arxiv.org/abs/2508.13568)
*Diego Correa da Silva,Denis Robson Dantas Boaventura,Mayki dos Santos Oliveira,Eduardo Ferreira da Silva,Joel Machado Pires,Frederico Araújo Durão*

Main category: cs.IR

TL;DR: 전통 추천시스템은 사용자 프로필의 덜 대표적인 장르를 추천목록에서 배제할 수 있어 사용자 경험을 저해한다. 본 논문은 사용자 프로필, 후보 아이템, 추천목록의 세 분포(장르 수 G 차원)를 이용한 보정(calibrated) 추천을 연구하고, 15개 모델(특히 이상치 탐지 모델 포함)을 영화 데이터셋 3종에 적용해 구조를 분석했다. 결과는 이상치 탐지 모델이 분포 구조를 잘 드러내며, 보정된 추천목록은 전통적 목록과 유사하게 작동하면서 사용자의 선호 군집 변경 정도를 유지한다.


<details>
  <summary>Details</summary>
Motivation: 전통 추천 알고리즘은 가장 관련성 높은 항목을 순위화하지만, 이로 인해 프로필의 덜 두드러진 장르가 추천에서 누락되어 사용자 만족도와 다양성이 저해된다. 이를 해결하기 위해 추천목록에 덜 대표적인 영역을 보장하는 보정된 추천이 필요하다.

Method: 세 가지 분포(사용자 프로필, 후보 아이템, 추천목록)를 G차원(장르 수)으로 정의하고, 분포 구조를 이해하기 위해 15개의 모델을 구현하여 비교 평가했다. 특히 이상치 탐지 모델군을 포함해 분포의 패턴과 구조를 분석했으며 영화 도메인 데이터셋 3종으로 실험을 수행했다.

Result: 실험 결과 이상치 탐지 모델들이 분포 구조를 더 잘 설명하는 것으로 나타났다. 보정된 추천시스템은 추천목록을 전통적 추천과 유사한 방식으로 생성하면서도 사용자들이 선호 그룹을 변경하는 정도(유연성)를 동일하게 유지했다.

Conclusion: G차원 분포를 다루는 보정된 추천은 덜 대표적인 장르를 포함시켜 다양성과 사용자 경험을 개선할 수 있으며, 이상치 탐지 접근이 분포 구조 해석에 유용하다. 다만 고차원성 때문에 전통적 1차원 평가 지표와는 다른 평가방법이 필요하다.

Abstract: Traditional recommender systems aim to generate a recommendation list
comprising the most relevant or similar items to the user's profile. These
approaches can create recommendation lists that omit item genres from the less
prominent areas of a user's profile, thereby undermining the user's experience.
To solve this problem, the calibrated recommendation system provides a
guarantee of including less representative areas in the recommended list. The
calibrated context works with three distributions. The first is from the user's
profile, the second is from the candidate items, and the last is from the
recommendation list. These distributions are G-dimensional, where G is the
total number of genres in the system. This high dimensionality requires a
different evaluation method, considering that traditional recommenders operate
in a one-dimensional data space. In this sense, we implement fifteen models
that help to understand how these distributions are structured. We evaluate the
users' patterns in three datasets from the movie domain. The results indicate
that the models of outlier detection provide a better understanding of the
structures. The calibrated system creates recommendation lists that act
similarly to traditional recommendation lists, allowing users to change their
groups of preferences to the same degree.

</details>


### [352] [MUFFIN: Mixture of User-Adaptive Frequency Filtering for Sequential Recommendation](https://arxiv.org/abs/2508.13670)
*Ilwoong Baek,Mincheol Yoon,Seongmin Park,Jongwuk Lee*

Main category: cs.IR

TL;DR: 주파수 도메인에서 사용자별 적응형 필터를 도입한 추천 모델 MUFFIN을 제안. 글로벌 모듈과 로컬 모듈을 결합해 전체 주파수 대역을 포괄하고 사용자별 특징을 반영하여 기존 주파수 기반 SR 모델들보다 성능 향상을 보임.


<details>
  <summary>Details</summary>
Motivation: 기존 주파수 기반 SR 모델들이 제한된 주파수 대역만 다루거나 모든 사용자에게 동일한 필터를 적용해 개인별 주파수 특성을 반영하지 못함. 이로 인해 특정 행동 패턴을 놓치거나 사용자 맞춤 추천 성능이 떨어짐.

Method: MUFFIN은 세 부분으로 구성됨: (1) 글로벌 필터링 모듈(GFM)은 전체 주파수 스펙트럼을 처리해 광범위한 패턴을 캡처, (2) 로컬 필터링 모듈(LFM)은 중요한 주파수 밴드를 선택적으로 강조하되 다른 대역 정보도 완전히 배제하지 않음, (3) 두 모듈 모두에서 사용자-적응형 필터(UAF)를 사용해 각 사용자에 맞는 주파수 필터를 생성. 최종적으로 두 모듈의 출력을 결합해 다양한 사용자 행동 패턴을 포괄적으로 모델링함.

Result: 다섯 개 벤치마크 데이터셋에서 기존 최첨단 주파수 도메인 SR 모델들을 일관되게 능가하는 성능을 보였음(구체적 수치 미제시). 코드 공개 링크 제공.

Conclusion: 전체 주파수 범위를 다루는 글로벌/로컬 모듈과 사용자 특화 필터의 결합으로 주파수 기반 순차 추천의 한계를 극복, 개인화된 주파수 필터링이 SR 성능 향상에 기여함.

Abstract: Sequential recommendation (SR) aims to predict users' subsequent interactions
by modeling their sequential behaviors. Recent studies have explored frequency
domain analysis, which effectively models periodic patterns in user sequences.
However, existing frequency-domain SR models still face two major drawbacks:
(i) limited frequency band coverage, often missing critical behavioral patterns
in a specific frequency range, and (ii) lack of personalized frequency
filtering, as they apply an identical filter for all users regardless of their
distinct frequency characteristics. To address these challenges, we propose a
novel frequency-domain model, Mixture of User-adaptive Frequency FIlteriNg
(MUFFIN), operating through two complementary modules. (i) The global filtering
module (GFM) handles the entire frequency spectrum to capture comprehensive
behavioral patterns. (ii) The local filtering module (LFM) selectively
emphasizes important frequency bands without excluding information from other
ranges. (iii) In both modules, the user-adaptive filter (UAF) is adopted to
generate user-specific frequency filters tailored to individual unique
characteristics. Finally, by aggregating both modules, MUFFIN captures diverse
user behavioral patterns across the full frequency spectrum. Extensive
experiments show that MUFFIN consistently outperforms state-of-the-art
frequency-domain SR models over five benchmark datasets. The source code is
available at https://github.com/ilwoong100/MUFFIN.

</details>


### [353] [Refining Contrastive Learning and Homography Relations for Multi-Modal Recommendation](https://arxiv.org/abs/2508.13745)
*Shouxing Ma,Yawen Zeng,Shiqing Wu,Guandong Xu*

Main category: cs.IR

TL;DR: REARM은 멀티모달(이미지, 텍스트) 추천에서 대조학습과 호모그래피(동종 그래프)를 개선해 데이터 희소성을 완화하는 프레임워크다. 메타네트워크와 직교 제약을 이용해 모달-공유 특징의 노이즈를 제거하고 모달-고유 특징을 보존하며, 사용자 관심 그래프와 아이템 동시출현 그래프를 추가해 호모그래피 관계를 더 완전하게 탐색한다. 실험에서 기존 방법들보다 성능이 우수하며 시각화로 모달-공유/고유 특징 구분이 향상됨을 보였다.


<details>
  <summary>Details</summary>
Motivation: 멀티모달 추천은 아이템의 이미지·텍스트를 활용해 성능을 높이지만, 현실 데이터의 희소성 때문에 GNN 기반 방법들이 한계에 부딪힌다. 기존의 대조학습과 동종 그래프 기법은 모달간의 잡음 제거와 사용자-아이템 상호작용의 완전한 탐색에 실패한다.

Method: REARM은 두 가지 핵심 설계: (1) 메타네트워크와 직교 제약을 도입한 멀티모달 대조학습으로, 모달-공유 특징의 노이즈를 필터링하고 모달-고유 특징의 추천 관련 정보를 보존한다; (2) 기존 사용자·아이템 그래프(유저 공출현, 아이템 의미) 외에 사용자 관심 그래프와 아이템 동시출현 그래프를 새로 구성하여 호모그래피 관계를 통합한 그래프 학습을 수행한다.

Result: 세 개의 실제 데이터셋에서 다양한 최신 방법들보다 우수한 추천 성능을 보였고, 시각화 결과로 모달-공유와 모달-고유 특징의 분리가 향상된 것을 확인했다.

Conclusion: REARM은 메타네트워크·직교 제약을 통한 정제된 대조학습과 호모그래피 그래프의 확장을 통해 멀티모달 추천에서 데이터 희소성 문제를 효과적으로 완화하며 성능을 향상시킨다.

Abstract: Multi-modal recommender system focuses on utilizing rich modal information (
i.e., images and textual descriptions) of items to improve recommendation
performance. The current methods have achieved remarkable success with the
powerful structure modeling capability of graph neural networks. However, these
methods are often hindered by sparse data in real-world scenarios. Although
contrastive learning and homography ( i.e., homogeneous graphs) are employed to
address the data sparsity challenge, existing methods still suffer two main
limitations: 1) Simple multi-modal feature contrasts fail to produce effective
representations, causing noisy modal-shared features and loss of valuable
information in modal-unique features; 2) The lack of exploration of the
homograph relations between user interests and item co-occurrence results in
incomplete mining of user-item interplay.
  To address the above limitations, we propose a novel framework for
\textbf{R}\textbf{E}fining multi-mod\textbf{A}l cont\textbf{R}astive learning
and ho\textbf{M}ography relations (\textbf{REARM}). Specifically, we complement
multi-modal contrastive learning by employing meta-network and orthogonal
constraint strategies, which filter out noise in modal-shared features and
retain recommendation-relevant information in modal-unique features. To mine
homogeneous relationships effectively, we integrate a newly constructed user
interest graph and an item co-occurrence graph with the existing user
co-occurrence and item semantic graphs for graph learning. The extensive
experiments on three real-world datasets demonstrate the superiority of REARM
to various state-of-the-art baselines. Our visualization further shows an
improvement made by REARM in distinguishing between modal-shared and
modal-unique features. Code is available
\href{https://github.com/MrShouxingMa/REARM}{here}.

</details>


### [354] [UniECS: Unified Multimodal E-Commerce Search Framework with Gated Cross-modal Fusion](https://arxiv.org/abs/2508.13843)
*Zihan Liang,Yufei Ma,ZhiPeng Qian,Huangyu Dai,Zihan Wang,Ben Chen,Chenyi Lei,Yuqing Ding,Han Li*

Main category: cs.IR

TL;DR: UniECS는 이미지와 텍스트 및 혼합 쿼리를 모두 다루는 통합 전자상거래 멀티모달 검색 프레임워크로, 적응적 융합을 쓰는 게이트형 인코더와 포괄적 학습 손실 설계, 그리고 M-BEER라는 50K 제품 쌍 벤치마크를 제시한다. 소규모(0.2B) 모델로도 기존 방법들보다 우수한 성능을 보이며 실제 서비스에서 클릭율과 매출을 개선했다.


<details>
  <summary>Details</summary>
Motivation: 기존 전자상거래 멀티모달 검색 시스템은 특정 작업과 고정된 모달리티 쌍에 최적화되어 있으며, 통합적 검색 방법을 평가할 포괄적 벤치마크가 부족하다. 이를 해결해 모든 검색 시나리오(이미지, 텍스트, 혼합)를 하나의 프레임워크로 처리하고자 함.

Method: 게이트형 멀티모달 인코더(적응적 융합)로 서로 다른 모달리티 표현을 통합하고 결손 모달리티를 처리한다. 훈련은 교차-모달 정렬 손실(CMAL), 응집적 로컬 정렬 손실(CLAL), 모달 내 대조 손실(IMCL) 및 적응적 손실 가중치를 결합하여 수행된다. 또한 M-BEER 벤치를 만들어 평가했다.

Result: 네 개의 전자상거래 벤치마크에서 미세조정 및 제로샷 평가 모두에서 기존 방법보다 지속적으로 우수했다. M-BEER에서는 텍스트-이미지 검색 R@10에서 최대 28% 향상을 보였고, 모델 파라미터는 0.2B로 GME-Qwen2VL(2B)나 MM-Embed(8B)보다 작다. 실제 배포 결과 CTR +2.74%, 매출 +8.33% 향상.

Conclusion: 적응적 융합 인코더와 통합 손실 설계, 그리고 M-BEER 벤치마크를 통해 UniECS는 실험적·실무적 환경 모두에서 효과적인 통합 전자상거래 멀티모달 검색 솔루션임을 보여준다.

Abstract: Current e-commerce multimodal retrieval systems face two key limitations:
they optimize for specific tasks with fixed modality pairings, and lack
comprehensive benchmarks for evaluating unified retrieval approaches. To
address these challenges, we introduce UniECS, a unified multimodal e-commerce
search framework that handles all retrieval scenarios across image, text, and
their combinations. Our work makes three key contributions. First, we propose a
flexible architecture with a novel gated multimodal encoder that uses adaptive
fusion mechanisms. This encoder integrates different modality representations
while handling missing modalities. Second, we develop a comprehensive training
strategy to optimize learning. It combines cross-modal alignment loss (CMAL),
cohesive local alignment loss (CLAL), intra-modal contrastive loss (IMCL), and
adaptive loss weighting. Third, we create M-BEER, a carefully curated
multimodal benchmark containing 50K product pairs for e-commerce search
evaluation. Extensive experiments demonstrate that UniECS consistently
outperforms existing methods across four e-commerce benchmarks with fine-tuning
or zero-shot evaluation. On our M-BEER bench, UniECS achieves substantial
improvements in cross-modal tasks (up to 28\% gain in R@10 for text-to-image
retrieval) while maintaining parameter efficiency (0.2B parameters) compared to
larger models like GME-Qwen2VL (2B) and MM-Embed (8B). Furthermore, we deploy
UniECS in the e-commerce search platform of Kuaishou Inc. across two search
scenarios, achieving notable improvements in Click-Through Rate (+2.74\%) and
Revenue (+8.33\%). The comprehensive evaluation demonstrates the effectiveness
of our approach in both experimental and real-world settings. Corresponding
codes, models and datasets will be made publicly available at
https://github.com/qzp2018/UniECS.

</details>


### [355] [Bites of Tomorrow: Personalized Recommendations for a Healthier and Greener Plate](https://arxiv.org/abs/2508.13870)
*Jiazheng Jing,Yinan Zhang,Chunyan Miao*

Main category: cs.IR

TL;DR: Introduce GRAPE, a recommender system that nudges users to sustainable food choices while matching personal preferences; proposes two Green Loss functions for different green priority settings; shows effectiveness on real-world data.


<details>
  <summary>Details</summary>
Motivation: Extreme climate events increase urgency for sustainable living; traditional methods to change behavior are often too demanding or passive, so a proactive, personalized nudge via recommender systems is needed.

Method: Propose GRAPE (Green Recommender Aligned with Personalized Eating) that prioritizes sustainable food options aligned with evolving user preferences; design two Green Loss functions handling uniform and differentiated green priorities to adapt to various scenarios; evaluate on a real-world dataset.

Result: Extensive experiments on a real-world dataset demonstrate GRAPE's effectiveness in recommending sustainable food aligned with user preferences (improved sustainability-aware recommendation performance).

Conclusion: GRAPE provides an adaptable, effective approach to actively nudge users toward sustainable eating by integrating personalized preference alignment with green-prioritized loss functions.

Abstract: The recent emergence of extreme climate events has significantly raised
awareness about sustainable living. In addition to developing energy-saving
materials and technologies, existing research mainly relies on traditional
methods that encourage behavioral shifts towards sustainability, which can be
overly demanding or only passively engaging. In this work, we propose to employ
recommendation systems to actively nudge users toward more sustainable choices.
We introduce Green Recommender Aligned with Personalized Eating (GRAPE), which
is designed to prioritize and recommend sustainable food options that align
with users' evolving preferences. We also design two innovative Green Loss
functions that cater to green indicators with either uniform or differentiated
priorities, thereby enhancing adaptability across a range of scenarios.
Extensive experiments on a real-world dataset demonstrate the effectiveness of
our GRAPE.

</details>


### [356] [CARE: Contextual Adaptation of Recommenders for LLM-based Conversational Recommendation](https://arxiv.org/abs/2508.13889)
*Chuang Li,Yang Deng,Hengchang Hu,See-Kiong Ng,Min-Yen Kan,Haizhou Li*

Main category: cs.IR

TL;DR: 


<details>
  <summary>Details</summary>
Motivation: 

Method: 

Result: 

Conclusion: 

Abstract: We tackle the challenge of integrating large language models (LLMs) with
external recommender systems to enhance domain expertise in conversational
recommendation (CRS). Current LLM-based CRS approaches primarily rely on zero-
or few-shot methods for generating item recommendations based on user queries,
but this method faces two significant challenges: (1) without domain-specific
adaptation, LLMs frequently recommend items not in the target item space,
resulting in low recommendation accuracy; and (2) LLMs largely rely on dialogue
context for content-based recommendations, neglecting the collaborative
relationships among entities or item sequences. To address these limitations,
we introduce the CARE (Contextual Adaptation of Recommenders) framework. CARE
customizes LLMs for CRS tasks, and synergizes them with external recommendation
systems. CARE (a) integrates external recommender systems as domain experts,
producing recommendations through entity-level insights, and (b) enhances those
recommendations by leveraging contextual information for more accurate and
unbiased final recommendations using LLMs. Our results demonstrate that
incorporating external recommender systems with entity-level information
significantly enhances recommendation accuracy of LLM-based CRS by an average
of 54% and 25% for ReDial and INSPIRED datasets. The most effective strategy in
the CARE framework involves LLMs selecting and reranking candidate items that
external recommenders provide based on contextual insights. Our analysis
indicates that the CARE framework effectively addresses the identified
challenges and mitigates the popularity bias in the external recommender.

</details>


### [357] [InPars+: Supercharging Synthetic Data Generation for Information Retrieval Systems](https://arxiv.org/abs/2508.13930)
*Matey Krastev,Miklos Hamar,Danilo Toapanta,Jesse Brouwers,Yibin Lei*

Main category: cs.IR

TL;DR: 이 논문은 InPars 툴킷을 활용해 합성 질의 생성 파이프라인을 재현하고 확장한다. SciFact 벤치마크에서 InPars, InPars-V2, Promptagator를 재현·검증하고, (1) CPO로 질의 생성기 LLM을 파인튜닝해 질의 신호를 개선하고, (2) DSPy를 이용한 CoT 최적화 동적 프롬프트로 정적 템플릿을 대체한다. 두 확장은 필터링 필요성을 줄이고 검색 성능을 향상시키며 코드·모델·데이터를 공개한다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 합성 질의는 Neural IR 성능 향상에 유용하지만 재현성 문제, 과도한 필터링 필요성, 정적 프롬프트의 한계가 존재한다. 본 연구는 재현성을 검증하고 질의 품질과 프롬프트 설계 개선을 통해 NIR 성능을 높이고자 한다.

Method: (1) InPars, InPars-V2, Promptagator 파이프라인을 SciFact에서 재현하고 오픈소스 리랭커·생성기 모델로 성능을 검증. (2) 질의 생성기 LLM을 Contrastive Preference Optimization(CPO)으로 파인튜닝하여 생성 질의의 신호 품질 개선. (3) 정적 프롬프트를 DSPy 기반의 Chain-of-Thought(CoT) 최적화 프롬프트로 교체하여 동적 프롬프트 적용.

Result: 두 가지 확장 모두 공격적 필터링 의존도를 낮추면서 검색 성능을 개선함. 오픈소스 리랭커·생성기 환경에서도 원본 파이프라인의 효과를 재현했고, CPO 파인튜닝과 CoT 프롬프트가 추가 성능 향상을 가져옴.

Conclusion: CPO 기반 파인튜닝과 CoT 최적화 프롬프트는 합성 질의 파이프라인의 질을 높여 필터링을 줄이고 NIR 성능을 향상시킨다. 코드·모델·합성 데이터가 공개되어 추가 연구를 촉진한다.

Abstract: This work revisits and extends synthetic query generation pipelines for
Neural Information Retrieval (NIR) by leveraging the InPars Toolkit, a
reproducible, end-to-end framework for generating training data using large
language models (LLMs). We first assess the reproducibility of the original
InPars, InPars-V2, and Promptagator pipelines on the SciFact benchmark and
validate their effectiveness using open-source reranker and generator models.
Building on this foundation, we introduce two key extensions to the pipeline:
(1) fine-tuning a query generator LLM via Contrastive Preference Optimization
(CPO) to improve the signal quality in generated queries, and (2) replacing
static prompt templates with dynamic, Chain-of-Thought (CoT) optimized prompts
using the DSPy framework. Our results show that both extensions reduce the need
for aggressive filtering while improving retrieval performance. All code,
models, and synthetic datasets are publicly released to support further
research at: \href{https://github.com/danilotpnta/IR2-project}{this https URL}.

</details>


### [358] [Democratizing News Recommenders: Modeling Multiple Perspectives for News Candidate Generation with VQ-VAE](https://arxiv.org/abs/2508.13978)
*Hardy,Sebastian Padó,Amelie Wührl,Tanise Ceron*

Main category: cs.IR

TL;DR: A2CG는 뉴스 추천의 초기 후보 생성 단계에서 관점(정서, 정치 성향, 프레임 등)별 이산 표현을 학습하고( VQ-VAE ), 사용자 선호를 코드 수준에서 학습한 뒤 일부 쿼리 측면의 부호를 반전시켜 다양성을 직접 주입하는 방법이다. MIND 데이터셋 실험에서 개인화와 다양성 간 유연한 균형을 제공하며 더 새롭고 다양하고 뜻밖의 후보를 생성한다.


<details>
  <summary>Details</summary>
Motivation: 기존 클릭 기반 뉴스 추천은 참여도를 높이지만 추천 콘텐츠의 다양성을 제한한다. 기존의 다양성 기법들은(1) 규범적 다양성(다양한 관점에 대한 공정한 접근)을 제대로 고려하지 못하고,(2) 파이프라인 후반에 다양성을 적용해 이미 많이 걸러진 콘텐츠에만 다양성 보정을 하므로 실효성이 제한된다.

Method: Aspect-Aware Candidate Generation(A2CG)은 기사별로 여러 관점(감정, 정치 성향, 프레임 등)을 측정해 VQ-VAE로 이산적·다면적 코드로 인코딩한다. 디코더 전용 모델이 사용자별 코드 선호를 학습하고, 후보 검색 시 쿼리 벡터의 일부 측면 부호를 반전시켜 다양성을 직접 주입한다. 이로써 다양성 제약을 후보 생성 초기 단계에 적용할 수 있다.

Result: MIND 데이터셋 평가에서 A2CG는 초기 단계에서 개인화와 다양성의 유연한 트레이드오프를 가능하게 했고, 후보 집합에서 새로움, 다양성, 뜻밖성(serendipity)이 증가했다. 또한 민주적 가치와 연관된 관점들을 효과적으로 고려했다.

Conclusion: 초기 후보 생성 단계에서 다면적 관점 표현과 쿼리 측면 변형으로 다양성을 주입하는 A2CG는 규범적 다양성을 증진할 수 있는 유망한 접근이다. downstream 민주화된 뉴스 추천 시스템에 적용 가능하며 개인화 손실을 최소화하면서 다양한 시각의 접근을 향상시킨다.

Abstract: Current News Recommender Systems based on past clicks are designed for
engagement, but come at the cost of limiting diversity in the suggested
content. While diversity-aware algorithms exist, they suffer from two major
limitations. First, they fail to account for normative diversity, which
requires fair access to a broad range of perspectives. Second, they typically
apply diversity late in the system's pipeline, after a lot of content has
already been filtered out. Both limitations confine their effectiveness and
prevent them from promoting true normative diversity in news recommendations.
  We propose Aspect-Aware Candidate Generation (A2CG) to address these
limitations. Our framework introduces diversity into the earliest pipeline
stage and uses a configurable mechanism to align diversity with specific
democratic goals. A2CG represents each news article using multiple aspects of
perspectives (e.g., sentiment, political leaning, frame) and uses a Vector
Quantized Variational Autoencoder (VQ-VAE) to create a discrete, multi-faceted
representation. A decoder-only model then learns user preferences over these
aspect codes. We then inject diversity directly by reversing the sign on some
of the query vector's aspects during the candidate retrieval process, ensuring
a more diverse set of candidates.
  Our method, evaluated on the MIND dataset, enables a flexible trade-off
between personalization and diversity early in the recommendation pipeline. It
also generates more novel, diverse, and serendipitous candidates while
effectively taking into account aspects that strengthen democratic values.
These empirical results make it a promising approach for downstream
democratized news recommendation systems.

</details>


### [359] [TaoSR1: The Thinking Model for E-commerce Relevance Search](https://arxiv.org/abs/2508.12365)
*Chenhe Dong,Shaowei Yao,Pengkun Jiao,Jianhui Yang,Yiming Jin,Zerui Huang,Xiaojiang Zhou,Dan Ou,Haihong Tang*

Main category: cs.IR

TL;DR: TaoSR1 is a framework to directly deploy LLMs for query-product relevance prediction by applying Chain-of-Thought (CoT) reasoning while addressing error accumulation, discriminative hallucination, and deployment feasibility. It uses three stages—(1) Supervised Fine-Tuning with CoT, (2) Offline sampling with pass@N and Direct Preference Optimization (DPO), and (3) Difficulty-based dynamic sampling with Group Relative Policy Optimization (GRPO)—plus post-CoT processing and cumulative-probability partitioning to enable efficient online inference. The approach outperforms baselines on offline datasets and in online human evaluations.


<details>
  <summary>Details</summary>
Motivation: BERT-based models are strong at semantic matching but lack complex reasoning. Large Language Models can reason but face challenges when applied directly to relevance classification: CoT outputs can accumulate errors, LLMs can produce discriminative hallucinations, and full generative CoT is expensive and hard to deploy in production.

Method: Three-stage pipeline: (1) Supervised Fine-Tuning (SFT) with Chain-of-Thought to teach the model reasoning steps; (2) Offline sampling using pass@N to generate multiple CoT outputs and applying Direct Preference Optimization (DPO) to learn from higher-quality samples; (3) Difficulty-based dynamic sampling with Group Relative Policy Optimization (GRPO) to focus on hard examples and reduce discriminative hallucination. Also includes post-CoT processing to prune/normalize reasoning and a cumulative-probability-based partitioning for efficient online inference (likely converting generation into a lightweight classification path).

Result: TaoSR1 significantly outperforms baseline discriminative models and distilled LLMs on offline benchmarks and shows substantial gains in online side-by-side human evaluations, demonstrating the feasibility and effectiveness of deploying LLMs with CoT for relevance prediction.

Conclusion: The paper introduces a practical paradigm for applying Chain-of-Thought reasoning in relevance classification by combining SFT, preference-based optimization, and dynamic sampling, with additional techniques to make CoT inference reliable and deployable in production settings.

Abstract: Query-product relevance prediction is a core task in e-commerce search.
BERT-based models excel at semantic matching but lack complex reasoning
capabilities. While Large Language Models (LLMs) are explored, most still use
discriminative fine-tuning or distill to smaller models for deployment. We
propose a framework to directly deploy LLMs for this task, addressing key
challenges: Chain-of-Thought (CoT) error accumulation, discriminative
hallucination, and deployment feasibility. Our framework, TaoSR1, involves
three stages: (1) Supervised Fine-Tuning (SFT) with CoT to instill reasoning;
(2) Offline sampling with a pass@N strategy and Direct Preference Optimization
(DPO) to improve generation quality; and (3) Difficulty-based dynamic sampling
with Group Relative Policy Optimization (GRPO) to mitigate discriminative
hallucination. Additionally, post-CoT processing and a cumulative
probability-based partitioning method enable efficient online deployment.
TaoSR1 significantly outperforms baselines on offline datasets and achieves
substantial gains in online side-by-side human evaluations, introducing a novel
paradigm for applying CoT reasoning to relevance classification.

</details>


### [360] [TaoSR1: The Thinking Model for E-commerce Relevance Search](https://arxiv.org/abs/2508.12365)
*Chenhe Dong,Shaowei Yao,Pengkun Jiao,Jianhui Yang,Yiming Jin,Zerui Huang,Xiaojiang Zhou,Dan Ou,Haihong Tang*

Main category: cs.IR

TL;DR: TaoSR1 is a framework to directly deploy LLMs for query-product relevance prediction by applying Chain-of-Thought (CoT) reasoning while addressing error accumulation, discriminative hallucination, and deployment feasibility. It uses three stages—(1) Supervised Fine-Tuning with CoT, (2) Offline sampling with pass@N and Direct Preference Optimization (DPO), and (3) Difficulty-based dynamic sampling with Group Relative Policy Optimization (GRPO)—plus post-CoT processing and cumulative-probability partitioning to enable efficient online inference. The approach outperforms baselines on offline datasets and in online human evaluations.


<details>
  <summary>Details</summary>
Motivation: BERT-based models are strong at semantic matching but lack complex reasoning. Large Language Models can reason but face challenges when applied directly to relevance classification: CoT outputs can accumulate errors, LLMs can produce discriminative hallucinations, and full generative CoT is expensive and hard to deploy in production.

Method: Three-stage pipeline: (1) Supervised Fine-Tuning (SFT) with Chain-of-Thought to teach the model reasoning steps; (2) Offline sampling using pass@N to generate multiple CoT outputs and applying Direct Preference Optimization (DPO) to learn from higher-quality samples; (3) Difficulty-based dynamic sampling with Group Relative Policy Optimization (GRPO) to focus on hard examples and reduce discriminative hallucination. Also includes post-CoT processing to prune/normalize reasoning and a cumulative-probability-based partitioning for efficient online inference (likely converting generation into a lightweight classification path).

Result: TaoSR1 significantly outperforms baseline discriminative models and distilled LLMs on offline benchmarks and shows substantial gains in online side-by-side human evaluations, demonstrating the feasibility and effectiveness of deploying LLMs with CoT for relevance prediction.

Conclusion: The paper introduces a practical paradigm for applying Chain-of-Thought reasoning in relevance classification by combining SFT, preference-based optimization, and dynamic sampling, with additional techniques to make CoT inference reliable and deployable in production settings.

Abstract: Query-product relevance prediction is a core task in e-commerce search.
BERT-based models excel at semantic matching but lack complex reasoning
capabilities. While Large Language Models (LLMs) are explored, most still use
discriminative fine-tuning or distill to smaller models for deployment. We
propose a framework to directly deploy LLMs for this task, addressing key
challenges: Chain-of-Thought (CoT) error accumulation, discriminative
hallucination, and deployment feasibility. Our framework, TaoSR1, involves
three stages: (1) Supervised Fine-Tuning (SFT) with CoT to instill reasoning;
(2) Offline sampling with a pass@N strategy and Direct Preference Optimization
(DPO) to improve generation quality; and (3) Difficulty-based dynamic sampling
with Group Relative Policy Optimization (GRPO) to mitigate discriminative
hallucination. Additionally, post-CoT processing and a cumulative
probability-based partitioning method enable efficient online deployment.
TaoSR1 significantly outperforms baselines on offline datasets and achieves
substantial gains in online side-by-side human evaluations, introducing a novel
paradigm for applying CoT reasoning to relevance classification.

</details>


### [361] [Research on Conversational Recommender System Considering Consumer Types](https://arxiv.org/abs/2508.13209)
*Yaying Luo,Hui Fang,Zhu Sun*

Main category: cs.IR

TL;DR: CT-CRS는 소비자 유형(의사결정 스타일과 지식수준에 따른 4분류)을 실시간으로 추론해 맞춤형 대화 추천 정책을 적용하고 IRL로 정책을 최적화하여 추천 성공률을 높이고 대화 턴을 줄인다.


<details>
  <summary>Details</summary>
Motivation: 기존 대화형 추천 시스템은 사용자마다 다른 의사결정 스타일(최대화자 vs 만족화자)과 지식 수준을 반영하지 않아 추천 정확성과 효율성이 제한된다.

Method: 소비자 유형 이론에 기반해 사용자 유형(의존형, 효율형, 신중형, 전문가)을 정의하고, 상호작용 이력으로 LLM을 미세조정해 실시간 유형 추론을 수행한다. 유형을 상태 표현에 포함시키고, 유형에 적응하는 정책으로 추천의 세분성·다양성·속성 질의 복잡도를 동적으로 조절한다. 정책 학습에는 Inverse Reinforcement Learning을 사용해 전문가 유사 전략을 모방한다.

Result: LastFM, Amazon-Book, Yelp 데이터셋에서 CT-CRS는 강력한 기준선보다 추천 성공률을 개선하고 대화 턴을 감소시켰다. 소거 연구에서 소비자 유형 모델링과 IRL이 성능 향상에 유의미하게 기여함을 확인했다.

Conclusion: CT-CRS는 심리학적 사용자 모델링과 고급 정책 최적화를 통합해 CRS의 개인화, 효율성, 해석가능성을 향상시키는 확장 가능하고 해석 가능한 솔루션을 제시한다.

Abstract: Conversational Recommender Systems (CRS) provide personalized services
through multi-turn interactions, yet most existing methods overlook users'
heterogeneous decision-making styles and knowledge levels, which constrains
both accuracy and efficiency. To address this gap, we propose CT-CRS (Consumer
Type-Enhanced Conversational Recommender System), a framework that integrates
consumer type modeling into dialogue recommendation. Based on consumer type
theory, we define four user categories--dependent, efficient, cautious, and
expert--derived from two dimensions: decision-making style (maximizers vs.
satisficers) and knowledge level (high vs. low). CT-CRS employs interaction
histories and fine-tunes the large language model to automatically infer user
types in real time, avoiding reliance on static questionnaires. We incorporate
user types into state representation and design a type-adaptive policy that
dynamically adjusts recommendation granularity, diversity, and attribute query
complexity. To further optimize the dialogue policy, we adopt Inverse
Reinforcement Learning (IRL), enabling the agent to approximate expert-like
strategies conditioned on consumer type. Experiments on LastFM, Amazon-Book,
and Yelp show that CTCRS improves recommendation success rate and reduces
interaction turns compared to strong baselines. Ablation studies confirm that
both consumer type modeling and IRL contribute significantly to performance
gains. These results demonstrate that CT-CRS offers a scalable and
interpretable solution for enhancing CRS personalization through the
integration of psychological modeling and advanced policy optimization.

</details>


### [362] [LLM-Enhanced Linear Autoencoders for Recommendation](https://arxiv.org/abs/2508.13500)
*Jaewan Moon,Seongmin Park,Jongwuk Lee*

Main category: cs.IR

TL;DR: L3AE는 LLM으로부터 얻은 아이템 임베딩으로 의미적 아이템-아이템 상관행렬을 구성하고, 협업 신호로부터 학습한 아이템-아이템 가중치 행렬에 이를 정규화로 증류하는 두 단계의 선형 오토인코더 통합 방식이다. 두 단계 모두 닫힌 형식 해(closed-form)를 사용해 전역 최적성과 효율성을 보장하며, 여러 벤치마크에서 기존 LLM 강화 모델들을 크게 앞선다.


<details>
  <summary>Details</summary>
Motivation: 기존 LAE는 텍스트 정보를 희소한 단어 동시 발생 패턴에 의존해 풍부한 텍스트 의미를 포착하지 못한다. 따라서 LLM이 제공하는 풍부한 의미 지식을 LAE에 통합해 추천 성능을 향상시킬 필요가 있다.

Method: 두 단계 최적화(1) LLM으로부터 얻은 아이템 표현으로 의미적 아이템-아이템 상관행렬을 구성(semantic correlation matrix) (2) 협업 신호로부터 아이템-아이템 가중치 행렬을 학습하되, 의미 상관을 정규화로 증류하여 학습. 각 단계는 닫힌 형식 해로 최적화되어 계산 효율 및 전역 최적성 확보.

Result: 세 개의 벤치마크 데이터셋에서 기존 LLM 기반 SOTA 모델들 대비 일관된 성능 향상. 예시로 Recall@20에서 +27.6%, NDCG@20에서 +39.3%의 향상을 보고.

Conclusion: L3AE는 LLM 기반 의미 정보를 LAE 프레임워크에 최초로 통합한 방법으로, 텍스트 의미와 협업 신호의 이질적 지식을 효과적으로 결합해 성능과 효율성을 동시에 달성한다. 소스 코드는 공개되어 있음.

Abstract: Large language models (LLMs) have been widely adopted to enrich the semantic
representation of textual item information in recommender systems. However,
existing linear autoencoders (LAEs) that incorporate textual information rely
on sparse word co-occurrence patterns, limiting their ability to capture rich
textual semantics. To address this, we propose L3AE, the first integration of
LLMs into the LAE framework. L3AE effectively integrates the heterogeneous
knowledge of textual semantics and user-item interactions through a two-phase
optimization strategy. (i) L3AE first constructs a semantic item-to-item
correlation matrix from LLM-derived item representations. (ii) It then learns
an item-to-item weight matrix from collaborative signals while distilling
semantic item correlations as regularization. Notably, each phase of L3AE is
optimized through closed-form solutions, ensuring global optimality and
computational efficiency. Extensive experiments demonstrate that L3AE
consistently outperforms state-of-the-art LLM-enhanced models on three
benchmark datasets, achieving gains of 27.6% in Recall@20 and 39.3% in NDCG@20.
The source code is available at https://github.com/jaewan7599/L3AE_CIKM2025.

</details>


### [363] [AdaptJobRec: Enhancing Conversational Career Recommendation through an LLM-Powered Agentic System](https://arxiv.org/abs/2508.13423)
*Qixin Wang,Dawei Wang,Kun Chen,Yaowei Hu,Puneet Girdhar,Ruoteng Wang,Aadesh Gupta,Chaitanya Devella,Wenlai Guo,Shangwen Huang,Bachir Aoun,Greg Hayworth,Han Li,Xintao Wu*

Main category: cs.IR

TL;DR: AdaptJobRec는 질의 복잡도 판별로 응답 지연을 줄이고, 에이전트 기반 개인화 추천 도구를 결합해 정확도를 높인 대화형 채용 추천 시스템이다. 간단한 질문은 직접 도구 선택으로 빠르게 처리하고, 복잡한 질문은 메모리 필터링→작업 분해 계획→개인화 추천 도구 실행으로 처리해 응답 지연을 최대 53.3% 감소시키고 추천 정확도를 향상시켰다.


<details>
  <summary>Details</summary>
Motivation: 대화형 추천 시스템(CRS)은 단순 추천 목록을 넘어 주제 중심 서비스를 제공하도록 진화했으나, 고급 추론과 자기수정 능력을 갖춘 에이전트 기반 시스템은 응답 지연(latency) 문제가 심각하다. 복잡한 질의를 잘 처리하면서도 지연을 최소화하는 방법이 필요하다.

Method: AdaptJobRec는 자율 에이전트를 활용해 개인화 추천 알고리즘 도구를 통합한다. 사용자 질의 복잡도 식별기로 쿼리를 분류하고, 단순 쿼리는 적절한 도구를 바로 호출해 빠르게 응답한다. 복잡 쿼리는 메모리 처리 모듈로 대화 이력을 필터링한 뒤, 지능형 작업 분해 플래너로 세분화된 작업을 생성하고 개인화 추천 도구로 실행한다.

Result: Walmart의 실제 채용 추천 시나리오에서 평가한 결과, AdaptJobRec는 경쟁적 베이스라인 대비 평균 응답 지연을 최대 53.3%까지 줄였고 추천 정확도도 유의미하게 향상시켰다.

Conclusion: 질의 복잡도 기반 경로 분기와 에이전트-도구 통합 설계를 통해 AdaptJobRec는 대기시간과 추천 성능 사이의 균형을 효과적으로 개선하며, 실제 채용 추천 환경에서 실용적 이점을 보였다.

Abstract: In recent years, recommendation systems have evolved from providing a single
list of recommendations to offering a comprehensive suite of topic focused
services. To better accomplish this task, conversational recommendation systems
(CRS) have progressed from basic retrieval augmented LLM generation to agentic
systems with advanced reasoning and self correction capabilities. However,
agentic systems come with notable response latency, a longstanding challenge
for conversational recommendation systems. To balance the trade off between
handling complex queries and minimizing latency, we propose AdaptJobRec, the
first conversational job recommendation system that leverages autonomous agent
to integrate personalized recommendation algorithm tools. The system employs a
user query complexity identification mechanism to minimize response latency.
For straightforward queries, the agent directly selects the appropriate tool
for rapid responses. For complex queries, the agent uses the memory processing
module to filter chat history for relevant content, then passes the results to
the intelligent task decomposition planner, and finally executes the tasks
using personalized recommendation tools. Evaluation on Walmart's real world
career recommendation scenarios demonstrates that AdaptJobRec reduces average
response latency by up to 53.3% compared to competitive baselines, while
significantly improving recommendation accuracy.

</details>


### [364] [LLM-Enhanced Linear Autoencoders for Recommendation](https://arxiv.org/abs/2508.13500)
*Jaewan Moon,Seongmin Park,Jongwuk Lee*

Main category: cs.IR

TL;DR: L3AE는 LLM으로부터 얻은 아이템 임베딩으로 의미적 아이템-아이템 상관행렬을 구성하고, 협업 신호로부터 학습한 아이템-아이템 가중치 행렬에 이를 정규화로 증류하는 두 단계의 선형 오토인코더 통합 방식이다. 두 단계 모두 닫힌 형식 해(closed-form)를 사용해 전역 최적성과 효율성을 보장하며, 여러 벤치마크에서 기존 LLM 강화 모델들을 크게 앞선다.


<details>
  <summary>Details</summary>
Motivation: 기존 LAE는 텍스트 정보를 희소한 단어 동시 발생 패턴에 의존해 풍부한 텍스트 의미를 포착하지 못한다. 따라서 LLM이 제공하는 풍부한 의미 지식을 LAE에 통합해 추천 성능을 향상시킬 필요가 있다.

Method: 두 단계 최적화(1) LLM으로부터 얻은 아이템 표현으로 의미적 아이템-아이템 상관행렬을 구성(semantic correlation matrix) (2) 협업 신호로부터 아이템-아이템 가중치 행렬을 학습하되, 의미 상관을 정규화로 증류하여 학습. 각 단계는 닫힌 형식 해로 최적화되어 계산 효율 및 전역 최적성 확보.

Result: 세 개의 벤치마크 데이터셋에서 기존 LLM 기반 SOTA 모델들 대비 일관된 성능 향상. 예시로 Recall@20에서 +27.6%, NDCG@20에서 +39.3%의 향상을 보고.

Conclusion: L3AE는 LLM 기반 의미 정보를 LAE 프레임워크에 최초로 통합한 방법으로, 텍스트 의미와 협업 신호의 이질적 지식을 효과적으로 결합해 성능과 효율성을 동시에 달성한다. 소스 코드는 공개되어 있음.

Abstract: Large language models (LLMs) have been widely adopted to enrich the semantic
representation of textual item information in recommender systems. However,
existing linear autoencoders (LAEs) that incorporate textual information rely
on sparse word co-occurrence patterns, limiting their ability to capture rich
textual semantics. To address this, we propose L3AE, the first integration of
LLMs into the LAE framework. L3AE effectively integrates the heterogeneous
knowledge of textual semantics and user-item interactions through a two-phase
optimization strategy. (i) L3AE first constructs a semantic item-to-item
correlation matrix from LLM-derived item representations. (ii) It then learns
an item-to-item weight matrix from collaborative signals while distilling
semantic item correlations as regularization. Notably, each phase of L3AE is
optimized through closed-form solutions, ensuring global optimality and
computational efficiency. Extensive experiments demonstrate that L3AE
consistently outperforms state-of-the-art LLM-enhanced models on three
benchmark datasets, achieving gains of 27.6% in Recall@20 and 39.3% in NDCG@20.
The source code is available at https://github.com/jaewan7599/L3AE_CIKM2025.

</details>


### [365] [Heterogeneous Influence Maximization in User Recommendation](https://arxiv.org/abs/2508.13517)
*Hongru Hou,Jiachen Sun,Wenqing Lin,Wendong Bi,Xiangrong Wang,Deqing Yang*

Main category: cs.IR

TL;DR: Proposes HeteroIR and HeteroIM to bridge recommender systems and Influence Maximization (IM): HeteroIR is a two-stage framework estimating spread profit to unleash candidates’ dissemination potential; HeteroIM incrementally selects and reranks invitees based on counts of reverse reachable (RR) sets involving inviters and invitees, balancing interaction willingness and propagation. Shows significant offline gains (p<0.05) and online A/B improvements (8.5% and 10%) on Tencent gaming platforms. Code: https://github.com/socialalgo/HIM.


<details>
  <summary>Details</summary>
Motivation: Recommendation systems encourage users to invite others but usually model only willingness to interact and fail to exploit invitees’ spreading capability. IM methods maximize propagation but ignore invitees’ willingness. There is a need to combine both aspects to improve real-world propagation.

Method: HeteroIR: a two-stage framework that estimates spread profits of candidate invitees to better unleash dissemination potential. HeteroIM: an incremental selection and reranking algorithm that chooses the most influential invitees using counts of reverse reachable (RR) sets that contain both inviters and invitees; RR sets represent nodes that can reach a target under propagation. The approach integrates interaction willingness into IM-style selection.

Result: Extensive experiments show HeteroIR and HeteroIM significantly outperform state-of-the-art baselines (p < 0.05). Online deployment on Tencent gaming platforms yielded 8.5% (HeteroIR) and 10% (HeteroIM) improvements in A/B tests.

Conclusion: Bridging recommendation and IM via a heterogeneous framework and RR-set-based selection improves both interaction willingness and propagation coverage. The methods are effective in offline evaluation and real-world deployment; implementation is publicly available.

Abstract: User recommendation systems enhance user engagement by encouraging users to
act as inviters to interact with other users (invitees), potentially fostering
information propagation. Conventional recommendation methods typically focus on
modeling interaction willingness. Influence-Maximization (IM) methods focus on
identifying a set of users to maximize the information propagation. However,
existing methods face two significant challenges. First, recommendation methods
fail to unleash the candidates' spread capability. Second, IM methods fail to
account for the willingness to interact. To solve these issues, we propose two
models named HeteroIR and HeteroIM. HeteroIR provides an intuitive solution to
unleash the dissemination potential of user recommendation systems. HeteroIM
fills the gap between the IM method and the recommendation task, improving
interaction willingness and maximizing spread coverage. The HeteroIR introduces
a two-stage framework to estimate the spread profits. The HeteroIM
incrementally selects the most influential invitee to recommend and rerank
based on the number of reverse reachable (RR) sets containing inviters and
invitees. RR set denotes a set of nodes that can reach a target via
propagation. Extensive experiments show that HeteroIR and HeteroIM
significantly outperform the state-of-the-art baselines with the p-value <
0.05. Furthermore, we have deployed HeteroIR and HeteroIM in Tencent's online
gaming platforms and gained an 8.5\% and 10\% improvement in the online A/B
test, respectively. Implementation codes are available at
https://github.com/socialalgo/HIM.

</details>


### [366] [LLM-Enhanced Linear Autoencoders for Recommendation](https://arxiv.org/abs/2508.13500)
*Jaewan Moon,Seongmin Park,Jongwuk Lee*

Main category: cs.IR

TL;DR: L3AE는 LLM으로부터 얻은 아이템 임베딩으로 의미적 아이템-아이템 상관행렬을 구성하고, 협업 신호로부터 학습한 아이템-아이템 가중치 행렬에 이를 정규화로 증류하는 두 단계의 선형 오토인코더 통합 방식이다. 두 단계 모두 닫힌 형식 해(closed-form)를 사용해 전역 최적성과 효율성을 보장하며, 여러 벤치마크에서 기존 LLM 강화 모델들을 크게 앞선다.


<details>
  <summary>Details</summary>
Motivation: 기존 LAE는 텍스트 정보를 희소한 단어 동시 발생 패턴에 의존해 풍부한 텍스트 의미를 포착하지 못한다. 따라서 LLM이 제공하는 풍부한 의미 지식을 LAE에 통합해 추천 성능을 향상시킬 필요가 있다.

Method: 두 단계 최적화(1) LLM으로부터 얻은 아이템 표현으로 의미적 아이템-아이템 상관행렬을 구성(semantic correlation matrix) (2) 협업 신호로부터 아이템-아이템 가중치 행렬을 학습하되, 의미 상관을 정규화로 증류하여 학습. 각 단계는 닫힌 형식 해로 최적화되어 계산 효율 및 전역 최적성 확보.

Result: 세 개의 벤치마크 데이터셋에서 기존 LLM 기반 SOTA 모델들 대비 일관된 성능 향상. 예시로 Recall@20에서 +27.6%, NDCG@20에서 +39.3%의 향상을 보고.

Conclusion: L3AE는 LLM 기반 의미 정보를 LAE 프레임워크에 최초로 통합한 방법으로, 텍스트 의미와 협업 신호의 이질적 지식을 효과적으로 결합해 성능과 효율성을 동시에 달성한다. 소스 코드는 공개되어 있음.

Abstract: Large language models (LLMs) have been widely adopted to enrich the semantic
representation of textual item information in recommender systems. However,
existing linear autoencoders (LAEs) that incorporate textual information rely
on sparse word co-occurrence patterns, limiting their ability to capture rich
textual semantics. To address this, we propose L3AE, the first integration of
LLMs into the LAE framework. L3AE effectively integrates the heterogeneous
knowledge of textual semantics and user-item interactions through a two-phase
optimization strategy. (i) L3AE first constructs a semantic item-to-item
correlation matrix from LLM-derived item representations. (ii) It then learns
an item-to-item weight matrix from collaborative signals while distilling
semantic item correlations as regularization. Notably, each phase of L3AE is
optimized through closed-form solutions, ensuring global optimality and
computational efficiency. Extensive experiments demonstrate that L3AE
consistently outperforms state-of-the-art LLM-enhanced models on three
benchmark datasets, achieving gains of 27.6% in Recall@20 and 39.3% in NDCG@20.
The source code is available at https://github.com/jaewan7599/L3AE_CIKM2025.

</details>


### [367] [Heterogeneous Influence Maximization in User Recommendation](https://arxiv.org/abs/2508.13517)
*Hongru Hou,Jiachen Sun,Wenqing Lin,Wendong Bi,Xiangrong Wang,Deqing Yang*

Main category: cs.IR

TL;DR: Proposes HeteroIR and HeteroIM to bridge recommender systems and Influence Maximization (IM): HeteroIR is a two-stage framework estimating spread profit to unleash candidates’ dissemination potential; HeteroIM incrementally selects and reranks invitees based on counts of reverse reachable (RR) sets involving inviters and invitees, balancing interaction willingness and propagation. Shows significant offline gains (p<0.05) and online A/B improvements (8.5% and 10%) on Tencent gaming platforms. Code: https://github.com/socialalgo/HIM.


<details>
  <summary>Details</summary>
Motivation: Recommendation systems encourage users to invite others but usually model only willingness to interact and fail to exploit invitees’ spreading capability. IM methods maximize propagation but ignore invitees’ willingness. There is a need to combine both aspects to improve real-world propagation.

Method: HeteroIR: a two-stage framework that estimates spread profits of candidate invitees to better unleash dissemination potential. HeteroIM: an incremental selection and reranking algorithm that chooses the most influential invitees using counts of reverse reachable (RR) sets that contain both inviters and invitees; RR sets represent nodes that can reach a target under propagation. The approach integrates interaction willingness into IM-style selection.

Result: Extensive experiments show HeteroIR and HeteroIM significantly outperform state-of-the-art baselines (p < 0.05). Online deployment on Tencent gaming platforms yielded 8.5% (HeteroIR) and 10% (HeteroIM) improvements in A/B tests.

Conclusion: Bridging recommendation and IM via a heterogeneous framework and RR-set-based selection improves both interaction willingness and propagation coverage. The methods are effective in offline evaluation and real-world deployment; implementation is publicly available.

Abstract: User recommendation systems enhance user engagement by encouraging users to
act as inviters to interact with other users (invitees), potentially fostering
information propagation. Conventional recommendation methods typically focus on
modeling interaction willingness. Influence-Maximization (IM) methods focus on
identifying a set of users to maximize the information propagation. However,
existing methods face two significant challenges. First, recommendation methods
fail to unleash the candidates' spread capability. Second, IM methods fail to
account for the willingness to interact. To solve these issues, we propose two
models named HeteroIR and HeteroIM. HeteroIR provides an intuitive solution to
unleash the dissemination potential of user recommendation systems. HeteroIM
fills the gap between the IM method and the recommendation task, improving
interaction willingness and maximizing spread coverage. The HeteroIR introduces
a two-stage framework to estimate the spread profits. The HeteroIM
incrementally selects the most influential invitee to recommend and rerank
based on the number of reverse reachable (RR) sets containing inviters and
invitees. RR set denotes a set of nodes that can reach a target via
propagation. Extensive experiments show that HeteroIR and HeteroIM
significantly outperform the state-of-the-art baselines with the p-value <
0.05. Furthermore, we have deployed HeteroIR and HeteroIM in Tencent's online
gaming platforms and gained an 8.5\% and 10\% improvement in the online A/B
test, respectively. Implementation codes are available at
https://github.com/socialalgo/HIM.

</details>


### [368] [Understanding Distribution Structure on Calibrated Recommendation Systems](https://arxiv.org/abs/2508.13568)
*Diego Correa da Silva,Denis Robson Dantas Boaventura,Mayki dos Santos Oliveira,Eduardo Ferreira da Silva,Joel Machado Pires,Frederico Araújo Durão*

Main category: cs.IR

TL;DR: 전통 추천시스템은 사용자 프로필의 덜 대표적인 장르를 추천목록에서 배제할 수 있어 사용자 경험을 저해한다. 본 논문은 사용자 프로필, 후보 아이템, 추천목록의 세 분포(장르 수 G 차원)를 이용한 보정(calibrated) 추천을 연구하고, 15개 모델(특히 이상치 탐지 모델 포함)을 영화 데이터셋 3종에 적용해 구조를 분석했다. 결과는 이상치 탐지 모델이 분포 구조를 잘 드러내며, 보정된 추천목록은 전통적 목록과 유사하게 작동하면서 사용자의 선호 군집 변경 정도를 유지한다.


<details>
  <summary>Details</summary>
Motivation: 전통 추천 알고리즘은 가장 관련성 높은 항목을 순위화하지만, 이로 인해 프로필의 덜 두드러진 장르가 추천에서 누락되어 사용자 만족도와 다양성이 저해된다. 이를 해결하기 위해 추천목록에 덜 대표적인 영역을 보장하는 보정된 추천이 필요하다.

Method: 세 가지 분포(사용자 프로필, 후보 아이템, 추천목록)를 G차원(장르 수)으로 정의하고, 분포 구조를 이해하기 위해 15개의 모델을 구현하여 비교 평가했다. 특히 이상치 탐지 모델군을 포함해 분포의 패턴과 구조를 분석했으며 영화 도메인 데이터셋 3종으로 실험을 수행했다.

Result: 실험 결과 이상치 탐지 모델들이 분포 구조를 더 잘 설명하는 것으로 나타났다. 보정된 추천시스템은 추천목록을 전통적 추천과 유사한 방식으로 생성하면서도 사용자들이 선호 그룹을 변경하는 정도(유연성)를 동일하게 유지했다.

Conclusion: G차원 분포를 다루는 보정된 추천은 덜 대표적인 장르를 포함시켜 다양성과 사용자 경험을 개선할 수 있으며, 이상치 탐지 접근이 분포 구조 해석에 유용하다. 다만 고차원성 때문에 전통적 1차원 평가 지표와는 다른 평가방법이 필요하다.

Abstract: Traditional recommender systems aim to generate a recommendation list
comprising the most relevant or similar items to the user's profile. These
approaches can create recommendation lists that omit item genres from the less
prominent areas of a user's profile, thereby undermining the user's experience.
To solve this problem, the calibrated recommendation system provides a
guarantee of including less representative areas in the recommended list. The
calibrated context works with three distributions. The first is from the user's
profile, the second is from the candidate items, and the last is from the
recommendation list. These distributions are G-dimensional, where G is the
total number of genres in the system. This high dimensionality requires a
different evaluation method, considering that traditional recommenders operate
in a one-dimensional data space. In this sense, we implement fifteen models
that help to understand how these distributions are structured. We evaluate the
users' patterns in three datasets from the movie domain. The results indicate
that the models of outlier detection provide a better understanding of the
structures. The calibrated system creates recommendation lists that act
similarly to traditional recommendation lists, allowing users to change their
groups of preferences to the same degree.

</details>


### [369] [UniECS: Unified Multimodal E-Commerce Search Framework with Gated Cross-modal Fusion](https://arxiv.org/abs/2508.13843)
*Zihan Liang,Yufei Ma,ZhiPeng Qian,Huangyu Dai,Zihan Wang,Ben Chen,Chenyi Lei,Yuqing Ding,Han Li*

Main category: cs.IR

TL;DR: UniECS는 이미지와 텍스트 및 혼합 쿼리를 모두 다루는 통합 전자상거래 멀티모달 검색 프레임워크로, 적응적 융합을 쓰는 게이트형 인코더와 포괄적 학습 손실 설계, 그리고 M-BEER라는 50K 제품 쌍 벤치마크를 제시한다. 소규모(0.2B) 모델로도 기존 방법들보다 우수한 성능을 보이며 실제 서비스에서 클릭율과 매출을 개선했다.


<details>
  <summary>Details</summary>
Motivation: 기존 전자상거래 멀티모달 검색 시스템은 특정 작업과 고정된 모달리티 쌍에 최적화되어 있으며, 통합적 검색 방법을 평가할 포괄적 벤치마크가 부족하다. 이를 해결해 모든 검색 시나리오(이미지, 텍스트, 혼합)를 하나의 프레임워크로 처리하고자 함.

Method: 게이트형 멀티모달 인코더(적응적 융합)로 서로 다른 모달리티 표현을 통합하고 결손 모달리티를 처리한다. 훈련은 교차-모달 정렬 손실(CMAL), 응집적 로컬 정렬 손실(CLAL), 모달 내 대조 손실(IMCL) 및 적응적 손실 가중치를 결합하여 수행된다. 또한 M-BEER 벤치를 만들어 평가했다.

Result: 네 개의 전자상거래 벤치마크에서 미세조정 및 제로샷 평가 모두에서 기존 방법보다 지속적으로 우수했다. M-BEER에서는 텍스트-이미지 검색 R@10에서 최대 28% 향상을 보였고, 모델 파라미터는 0.2B로 GME-Qwen2VL(2B)나 MM-Embed(8B)보다 작다. 실제 배포 결과 CTR +2.74%, 매출 +8.33% 향상.

Conclusion: 적응적 융합 인코더와 통합 손실 설계, 그리고 M-BEER 벤치마크를 통해 UniECS는 실험적·실무적 환경 모두에서 효과적인 통합 전자상거래 멀티모달 검색 솔루션임을 보여준다.

Abstract: Current e-commerce multimodal retrieval systems face two key limitations:
they optimize for specific tasks with fixed modality pairings, and lack
comprehensive benchmarks for evaluating unified retrieval approaches. To
address these challenges, we introduce UniECS, a unified multimodal e-commerce
search framework that handles all retrieval scenarios across image, text, and
their combinations. Our work makes three key contributions. First, we propose a
flexible architecture with a novel gated multimodal encoder that uses adaptive
fusion mechanisms. This encoder integrates different modality representations
while handling missing modalities. Second, we develop a comprehensive training
strategy to optimize learning. It combines cross-modal alignment loss (CMAL),
cohesive local alignment loss (CLAL), intra-modal contrastive loss (IMCL), and
adaptive loss weighting. Third, we create M-BEER, a carefully curated
multimodal benchmark containing 50K product pairs for e-commerce search
evaluation. Extensive experiments demonstrate that UniECS consistently
outperforms existing methods across four e-commerce benchmarks with fine-tuning
or zero-shot evaluation. On our M-BEER bench, UniECS achieves substantial
improvements in cross-modal tasks (up to 28\% gain in R@10 for text-to-image
retrieval) while maintaining parameter efficiency (0.2B parameters) compared to
larger models like GME-Qwen2VL (2B) and MM-Embed (8B). Furthermore, we deploy
UniECS in the e-commerce search platform of Kuaishou Inc. across two search
scenarios, achieving notable improvements in Click-Through Rate (+2.74\%) and
Revenue (+8.33\%). The comprehensive evaluation demonstrates the effectiveness
of our approach in both experimental and real-world settings. Corresponding
codes, models and datasets will be made publicly available at
https://github.com/qzp2018/UniECS.

</details>


### [370] [InPars+: Supercharging Synthetic Data Generation for Information Retrieval Systems](https://arxiv.org/abs/2508.13930)
*Matey Krastev,Miklos Hamar,Danilo Toapanta,Jesse Brouwers,Yibin Lei*

Main category: cs.IR

TL;DR: 이 논문은 InPars 툴킷을 활용해 합성 질의 생성 파이프라인을 재현하고 확장한다. SciFact 벤치마크에서 InPars, InPars-V2, Promptagator를 재현·검증하고, (1) CPO로 질의 생성기 LLM을 파인튜닝해 질의 신호를 개선하고, (2) DSPy를 이용한 CoT 최적화 동적 프롬프트로 정적 템플릿을 대체한다. 두 확장은 필터링 필요성을 줄이고 검색 성능을 향상시키며 코드·모델·데이터를 공개한다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 합성 질의는 Neural IR 성능 향상에 유용하지만 재현성 문제, 과도한 필터링 필요성, 정적 프롬프트의 한계가 존재한다. 본 연구는 재현성을 검증하고 질의 품질과 프롬프트 설계 개선을 통해 NIR 성능을 높이고자 한다.

Method: (1) InPars, InPars-V2, Promptagator 파이프라인을 SciFact에서 재현하고 오픈소스 리랭커·생성기 모델로 성능을 검증. (2) 질의 생성기 LLM을 Contrastive Preference Optimization(CPO)으로 파인튜닝하여 생성 질의의 신호 품질 개선. (3) 정적 프롬프트를 DSPy 기반의 Chain-of-Thought(CoT) 최적화 프롬프트로 교체하여 동적 프롬프트 적용.

Result: 두 가지 확장 모두 공격적 필터링 의존도를 낮추면서 검색 성능을 개선함. 오픈소스 리랭커·생성기 환경에서도 원본 파이프라인의 효과를 재현했고, CPO 파인튜닝과 CoT 프롬프트가 추가 성능 향상을 가져옴.

Conclusion: CPO 기반 파인튜닝과 CoT 최적화 프롬프트는 합성 질의 파이프라인의 질을 높여 필터링을 줄이고 NIR 성능을 향상시킨다. 코드·모델·합성 데이터가 공개되어 추가 연구를 촉진한다.

Abstract: This work revisits and extends synthetic query generation pipelines for
Neural Information Retrieval (NIR) by leveraging the InPars Toolkit, a
reproducible, end-to-end framework for generating training data using large
language models (LLMs). We first assess the reproducibility of the original
InPars, InPars-V2, and Promptagator pipelines on the SciFact benchmark and
validate their effectiveness using open-source reranker and generator models.
Building on this foundation, we introduce two key extensions to the pipeline:
(1) fine-tuning a query generator LLM via Contrastive Preference Optimization
(CPO) to improve the signal quality in generated queries, and (2) replacing
static prompt templates with dynamic, Chain-of-Thought (CoT) optimized prompts
using the DSPy framework. Our results show that both extensions reduce the need
for aggressive filtering while improving retrieval performance. All code,
models, and synthetic datasets are publicly released to support further
research at: \href{https://github.com/danilotpnta/IR2-project}{this https URL}.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [371] [Goal-Directedness is in the Eye of the Beholder](https://arxiv.org/abs/2508.13247)
*Nina Rajcic,Anders Søgaard*

Main category: cs.MA

TL;DR: Predicting complex agents requires attributing goals; paper analyzes behavioral vs mechanistic probes and finds both face technical and conceptual problems, concluding goal-directedness cannot be measured objectively and proposing to model it as an emergent property in dynamic, multi-agent systems.


<details>
  <summary>Details</summary>
Motivation: Understanding and predicting complex agent behavior depends on attributing goals, but existing probing approaches (behavioral observation vs mechanistic probing of internal states) have unclear assumptions and limits.

Method: Careful analysis of the assumptions behind behavioral and mechanistic approaches; identification of technical and conceptual issues that arise when formalizing goals in agent systems.

Result: Both behavioral and mechanistic probes are undermined by identified problems; the authors argue that goal-directedness cannot be measured objectively.

Conclusion: Recommend new modeling directions treating goal-directedness as emergent in dynamic, multi-agent systems rather than an objectively measurable property.

Abstract: Our ability to predict the behavior of complex agents turns on the
attribution of goals. Probing for goal-directed behavior comes in two flavors:
Behavioral and mechanistic. The former proposes that goal-directedness can be
estimated through behavioral observation, whereas the latter attempts to probe
for goals in internal model states. We work through the assumptions behind both
approaches, identifying technical and conceptual problems that arise from
formalizing goals in agent systems. We arrive at the perhaps surprising
position that goal-directedness cannot be measured objectively. We outline new
directions for modeling goal-directedness as an emergent property of dynamic,
multi-agent systems.

</details>


### [372] [Self-Organizing Agent Network for LLM-based Workflow Automation](https://arxiv.org/abs/2508.13732)
*Yiming Xiong,Jian Wang,Bing Li,Yuhan Zhu,Yuqi Zhao*

Main category: cs.MA

TL;DR: SOAN은 복잡하고 중첩된 기업 워크플로우를 처리하기 위해 구조 단위를 독립 에이전트로 캡슐화하여 점진적으로 형식화된 에이전트 네트워크를 구성하는 구조 중심 오케스트레이션 프레임워크이다. 이를 통해 모듈화·명확성·내결함성·실행 효율성을 크게 개선한다.


<details>
  <summary>Details</summary>
Motivation: 현실의 기업 워크플로우는 다수의 재사용 가능한 하위 프로세스로 구성되어 깊게 중첩된 긴 실행 경로를 가지며, 이는 LLM 기반 오케스트레이션에서 긴 추론 체인과 상태 공간 폭발을 초래해 계획 효율성과 도구 호출 순서 정합성에 심각한 문제를 일으킨다. 따라서 다층 중첩을 다룰 수 있는 제어 가능한 구조의 오케스트레이션 방법이 필요하다.

Method: Self-Organizing Agent Network(SOAN)는 구조적 단위를 식별해 이를 독립 에이전트로 캡슐화하고, 점진적으로 형식화된 에이전트 네트워크를 구성한다. 이 네트워크 기반으로 모듈화된 에이전트들이 협업하여 복잡한 워크플로우를 관리하게 하여 긴 추론 체인과 상태 폭발 문제를 완화한다.

Result: 다수의 벤치마크와 실제 기업 워크플로우 데이터셋에 대한 광범위한 평가에서 SOAN은 적응성, 내결함성, 실행 효율성 측면에서 최신 기법들을 크게 능가함을 보였다.

Conclusion: 구조 기반의 점진적 에이전트 네트워크 구성은 다층 중첩 워크플로우의 오케스트레이션 문제를 효과적으로 해결하며, 기업 환경에서의 실제 적용 가능성과 성능 향상을 제공한다.

Abstract: Recent multi-agent frameworks built upon large language models (LLMs) have
demonstrated remarkable capabilities in complex task planning. However, in
real-world enterprise environments, business workflows are typically composed
through modularization and reuse of numerous subprocesses, resulting in
intricate workflows characterized by lengthy and deeply nested execution paths.
Such complexity poses significant challenges for LLM-driven orchestration, as
extended reasoning chains and state-space explosions severely impact planning
effectiveness and the proper sequencing of tool invocations. Therefore,
developing an orchestration method with controllable structures capable of
handling multi-layer nesting becomes a critical issue. To address this, we
propose a novel structure-driven orchestration framework Self-Organizing Agent
Network (SOAN). SOAN incrementally builds a formalized agent network by
identifying and encapsulating structural units as independent agents, enhancing
modularity and clarity in orchestration. Extensive evaluations were performed
using multiple benchmarks as well as a real-world enterprise workflow dataset.
Experimental results demonstrate that SOAN significantly outperforms
state-of-the-art methods in terms of adaptability, fault tolerance, and
execution efficiency.

</details>


### [373] [BetaWeb: Towards a Blockchain-enabled Trustworthy Agentic Web](https://arxiv.org/abs/2508.13787)
*Zihan Guo,Yuanjian Zhou,Chenyi Wang,Linlin You,Minjie Bian,Weinan Zhang*

Main category: cs.MA

TL;DR: BetaWeb는 블록체인을 활용해 신뢰성 있고 확장 가능한 LLM 기반 다중 에이전트 시스템(LaMAS)용 개방형 인프라를 제안한다. 기존 중앙화된 구조의 한계를 극복해 개인정보 보호, 데이터 관리, 가치 측정 문제를 해결하고, 에이전트 능력의 소유 및 지능의 수익화로 Web3에서 Web3.5로 진화하는 로드맵을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 현재 에이전트 생태계는 단절되고 폐쇄적이며, 개인 정보 보호·데이터 관리·가치 측정 등 핵심 문제로 대규모·이기종·교차 도메인 자율 상호작용을 지원하기 어렵다. Agentic Web의 개방 아키텍처도 구현상 한계가 있어 신뢰성 있고 확장 가능한 새로운 패러다임이 필요하다.

Method: 블록체인의 불변성·분산성·트러스트리스 특성을 활용해 BetaWeb라는 프레임워크를 제안하고, LaMAS의 진화 단계를 다섯 단계로 정리하며 각 단계에 필요한 기술들을 정리하였다. 또한 기존 제품과 비교 분석하고 주요 도전과제를 다각도로 논의한다.

Result: BetaWeb은 신뢰 가능한 인프라를 제공하여 에이전트 능력의 소유권·수익화 모델을 가능하게 하고, LaMAS가 보다 자율적이고 협업적인 방향으로 성장할 수 있는 로드맵을 제시한다. 구현 관련 구체적 자원(깃허브 링크)도 제시된다.

Conclusion: 블록체인과 LaMAS의 심층 통합은 회복력·신뢰성·지속가능한 인센티브를 갖춘 디지털 생태계의 토대를 마련할 수 있으며, 이를 통해 Web3에서 한 단계 진화한 Web3.5 패러다임으로 나아갈 수 있다.

Abstract: The rapid development of large language models (LLMs) has significantly
propelled the development of artificial intelligence (AI) agents, which are
increasingly evolving into diverse autonomous entities, advancing the LLM-based
multi-agent systems (LaMAS). However, current agentic ecosystems remain
fragmented and closed. Establishing an interconnected and scalable paradigm for
Agentic AI has become a critical prerequisite. Although Agentic Web proposes an
open architecture to break the ecosystem barriers, its implementation still
faces core challenges such as privacy protection, data management, and value
measurement. Existing centralized or semi-centralized paradigms suffer from
inherent limitations, making them inadequate for supporting large-scale,
heterogeneous, and cross-domain autonomous interactions. To address these
challenges, this paper introduces the blockchain-enabled trustworthy Agentic
Web (BetaWeb). By leveraging the inherent strengths of blockchain, BetaWeb not
only offers a trustworthy and scalable infrastructure for LaMAS but also has
the potential to advance the Web paradigm from Web3 (centered on data
ownership) towards Web3.5, which emphasizes ownership of agent capabilities and
the monetization of intelligence. Beyond a systematic examination of the
BetaWeb framework, this paper presents a five-stage evolutionary roadmap,
outlining the path of LaMAS from passive execution to advanced collaboration
and autonomous governance. We also conduct a comparative analysis of existing
products and discuss key challenges of BetaWeb from multiple perspectives.
Ultimately, we argue that deep integration between blockchain and LaMAS can lay
the foundation for a resilient, trustworthy, and sustainably incentivized
digital ecosystem. A summary of the enabling technologies for each stage is
available at https://github.com/MatZaharia/BetaWeb.

</details>


### [374] [COCO: Cognitive Operating System with Continuous Oversight for Multi-Agent Workflow Reliability](https://arxiv.org/abs/2508.13815)
*Churong Liang,Jinling Gan,Kairan Hong,Qiushi Tian,Zongze Wu,Runnan Li*

Main category: cs.MA

TL;DR: COCO는 다중 에이전트 워크플로우의 오류 전파 문제를 비동기적 자체 모니터링과 적응적 오류 수정으로 해결하는 프레임워크로, 오류 탐지와 실행 경로를 분리하여 복잡도에 대해 O(1) 모니터링 오버헤드를 달성한다. 주요 기법은 문맥적 롤백, 양방향 반영 프로토콜, 이종 교차 검증이며, 벤치마크에서 평균 6.5% 성능 향상을 보였다.


<details>
  <summary>Details</summary>
Motivation: 대규모 다중 에이전트 시스템에서 하류 에이전트가 상류 실패를 증폭시키며 품질 저하가 발생하는 문제를 해결하고, 품질 보증과 계산 효율성 사이의 근본적 균형을 맞추려는 목적.

Method: COCO는 오류 탐지를 실행 경로에서 분리하는 비동기 구조를 도입하고, 문맥적 롤백으로 상태와 진단 정보를 보존한 채 재계산을 수행하며, 양방향 반영으로 모니터링과 실행 모듈 간 상호 검증을 수행하고, 이종 교차 검증으로 모델 다양성을 이용해 시스템적 편향과 환상을 탐지한다.

Result: 벤치마크 다중 에이전트 작업에서 평균 6.5% 성능 향상을 달성하여 자율 워크플로우 신뢰성의 새로운 최첨단을 제시함.

Conclusion: COCO는 효율적인 모니터링 구조와 세 가지 알고리즘적 혁신을 통해 다중 에이전트 워크플로우의 오류 전파를 줄이고 신뢰성을 향상시킬 수 있음을 보였으며, 실무적 적용에서 품질-효율성 균형을 달성할 수 있는 실용적 접근을 제공한다.

Abstract: Large-scale multi-agent workflows exhibit inherent vulnerability to error
propagation and quality degradation, where downstream agents compound upstream
failures without corrective mechanisms. We introduce COCO (Cognitive Operating
System with Continuous Oversight), a theoretically-grounded framework that
implements asynchronous self-monitoring and adaptive error correction in
multi-agent driven systems. COCO addresses the fundamental trade-off between
quality assurance and computational efficiency through a novel decoupled
architecture that separates error detection from the critical execution path,
achieving $O(1)$ monitoring overhead relative to workflow complexity. COCO
employs three key algorithmic innovations to address systematic and stochastic
errors: (1) Contextual Rollback Mechanism - a stateful restart protocol that
preserves execution history and error diagnostics, enabling informed
re-computation rather than naive retry; (2) Bidirectional Reflection Protocol -
a mutual validation system between monitoring and execution modules that
prevents oscillatory behavior and ensures convergence; (3) Heterogeneous
Cross-Validation - leveraging model diversity to detect systematic biases and
hallucinations through ensemble disagreement metrics. Extensive experiments on
benchmark multi-agent tasks demonstrate 6.5\% average performance improvement,
establishing new state-of-the-art for autonomous workflow reliability.

</details>


### [375] [The Multi-Stage Assignment Problem: A Fairness Perspective](https://arxiv.org/abs/2508.13856)
*Vibulan J,Swapnil Dhamal,Shweta Jain*

Main category: cs.MA

TL;DR: 다단계 그래프에서 에이전트들에 대한 경로 할당의 공정성 문제를 연구한다. 최소 총비용 해는 큰 비용 불균형(시기심)을 초래할 수 있고, 시기심 최소화 문제는 NP-난해하다. 두 에이전트에 대해 최대 간선 가중치 M의 2M로 시기심을 보장하는 C-Balance 알고리즘을 제안하고, 비용 대비 공정성(CoF)이 2로 제한됨을 보인다. 이를 n 에이전트로 확장한 DC-Balance도 제안하며 수렴과 CoF 경계를 분석하고, ILP보다 훨씬 빠르다고 실험적으로 보인다.


<details>
  <summary>Details</summary>
Motivation: 다단계 그래프에서 여러 에이전트에게 노드-불가능한(서로 겹치지 않는) 경로를 할당할 때 단순히 전체 비용을 최소화하면 개별 에이전트 간 큰 비용 격차(시기심)가 발생할 수 있으므로 공정한 할당 방법이 필요하다.

Method: 시기심을 최소화하는 문제의 난이도를 분석( NP-hard 증명 )하고, 두 에이전트의 경우 최대 간선 가중치 M에 기반해 시기심을 2M로 보장하는 C-Balance 알고리즘을 설계한다. 이를 n 에이전트로 확장한 DC-Balance는 반복적으로 C-Balance를 호출해 수렴시키는 방식이다. 두 알고리즘에 대해 CoF(공정성 비용) 상한을 이론적으로 도출하고 실험으로 ILP 대비 속도 우위를 평가한다.

Result: 시기심 최소화는 NP-hard. C-Balance는 두 에이전트에서 시기심 ≤2M이며 이 경계는 타이트함을 보이는 예시가 있음. C-Balance의 CoF ≤2. DC-Balance는 반복으로 수렴하며 시기심을 2M에 임의로 가깝게 달성 가능. 실험에서 제안 알고리즘들은 ILP에 비해 수십~수백 배 빠름.

Conclusion: 다단계 그래프의 경로 할당에서 효율성만을 추구하면 심한 불공정이 발생할 수 있고, 제안한 C-Balance/DC-Balance 알고리즘은 제한된 비용으로 공정성을 확보하면서 실용적 효율성을 제공한다.

Abstract: This paper explores the problem of fair assignment on Multi-Stage graphs. A
multi-stage graph consists of nodes partitioned into $K$ disjoint sets (stages)
structured as a sequence of weighted bipartite graphs formed across adjacent
stages. The goal is to assign node-disjoint paths to $n$ agents starting from
the first stage and ending in the last stage. We show that an efficient
assignment that minimizes the overall sum of costs of all the agents' paths may
be highly unfair and lead to significant cost disparities (envy) among the
agents. We further show that finding an envy-minimizing assignment on a
multi-stage graph is NP-hard. We propose the C-Balance algorithm, which
guarantees envy that is bounded by $2M$ in the case of two agents, where $M$ is
the maximum edge weight. We demonstrate the algorithm's tightness by presenting
an instance where the envy is $2M$. We further show that the cost of fairness
($CoF$), defined as the ratio of the cost of the assignment given by the fair
algorithm to that of the minimum cost assignment, is bounded by $2$ for
C-Balance. We then extend this approach to $n$ agents by proposing the
DC-Balance algorithm that makes iterative calls to C-Balance. We show the
convergence of DC-Balance, resulting in envy that is arbitrarily close to $2M$.
We derive $CoF$ bounds for DC-Balance and provide insights about its dependency
on the instance-specific parameters and the desired degree of envy. We
experimentally show that our algorithm runs several orders of magnitude faster
than a suitably formulated ILP.

</details>


### [376] [Goal-Directedness is in the Eye of the Beholder](https://arxiv.org/abs/2508.13247)
*Nina Rajcic,Anders Søgaard*

Main category: cs.MA

TL;DR: Predicting complex agents requires attributing goals; paper analyzes behavioral vs mechanistic probes and finds both face technical and conceptual problems, concluding goal-directedness cannot be measured objectively and proposing to model it as an emergent property in dynamic, multi-agent systems.


<details>
  <summary>Details</summary>
Motivation: Understanding and predicting complex agent behavior depends on attributing goals, but existing probing approaches (behavioral observation vs mechanistic probing of internal states) have unclear assumptions and limits.

Method: Careful analysis of the assumptions behind behavioral and mechanistic approaches; identification of technical and conceptual issues that arise when formalizing goals in agent systems.

Result: Both behavioral and mechanistic probes are undermined by identified problems; the authors argue that goal-directedness cannot be measured objectively.

Conclusion: Recommend new modeling directions treating goal-directedness as emergent in dynamic, multi-agent systems rather than an objectively measurable property.

Abstract: Our ability to predict the behavior of complex agents turns on the
attribution of goals. Probing for goal-directed behavior comes in two flavors:
Behavioral and mechanistic. The former proposes that goal-directedness can be
estimated through behavioral observation, whereas the latter attempts to probe
for goals in internal model states. We work through the assumptions behind both
approaches, identifying technical and conceptual problems that arise from
formalizing goals in agent systems. We arrive at the perhaps surprising
position that goal-directedness cannot be measured objectively. We outline new
directions for modeling goal-directedness as an emergent property of dynamic,
multi-agent systems.

</details>


### [377] [BetaWeb: Towards a Blockchain-enabled Trustworthy Agentic Web](https://arxiv.org/abs/2508.13787)
*Zihan Guo,Yuanjian Zhou,Chenyi Wang,Linlin You,Minjie Bian,Weinan Zhang*

Main category: cs.MA

TL;DR: BetaWeb는 블록체인을 활용해 신뢰성 있고 확장 가능한 LLM 기반 다중 에이전트 시스템(LaMAS)용 개방형 인프라를 제안한다. 기존 중앙화된 구조의 한계를 극복해 개인정보 보호, 데이터 관리, 가치 측정 문제를 해결하고, 에이전트 능력의 소유 및 지능의 수익화로 Web3에서 Web3.5로 진화하는 로드맵을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 현재 에이전트 생태계는 단절되고 폐쇄적이며, 개인 정보 보호·데이터 관리·가치 측정 등 핵심 문제로 대규모·이기종·교차 도메인 자율 상호작용을 지원하기 어렵다. Agentic Web의 개방 아키텍처도 구현상 한계가 있어 신뢰성 있고 확장 가능한 새로운 패러다임이 필요하다.

Method: 블록체인의 불변성·분산성·트러스트리스 특성을 활용해 BetaWeb라는 프레임워크를 제안하고, LaMAS의 진화 단계를 다섯 단계로 정리하며 각 단계에 필요한 기술들을 정리하였다. 또한 기존 제품과 비교 분석하고 주요 도전과제를 다각도로 논의한다.

Result: BetaWeb은 신뢰 가능한 인프라를 제공하여 에이전트 능력의 소유권·수익화 모델을 가능하게 하고, LaMAS가 보다 자율적이고 협업적인 방향으로 성장할 수 있는 로드맵을 제시한다. 구현 관련 구체적 자원(깃허브 링크)도 제시된다.

Conclusion: 블록체인과 LaMAS의 심층 통합은 회복력·신뢰성·지속가능한 인센티브를 갖춘 디지털 생태계의 토대를 마련할 수 있으며, 이를 통해 Web3에서 한 단계 진화한 Web3.5 패러다임으로 나아갈 수 있다.

Abstract: The rapid development of large language models (LLMs) has significantly
propelled the development of artificial intelligence (AI) agents, which are
increasingly evolving into diverse autonomous entities, advancing the LLM-based
multi-agent systems (LaMAS). However, current agentic ecosystems remain
fragmented and closed. Establishing an interconnected and scalable paradigm for
Agentic AI has become a critical prerequisite. Although Agentic Web proposes an
open architecture to break the ecosystem barriers, its implementation still
faces core challenges such as privacy protection, data management, and value
measurement. Existing centralized or semi-centralized paradigms suffer from
inherent limitations, making them inadequate for supporting large-scale,
heterogeneous, and cross-domain autonomous interactions. To address these
challenges, this paper introduces the blockchain-enabled trustworthy Agentic
Web (BetaWeb). By leveraging the inherent strengths of blockchain, BetaWeb not
only offers a trustworthy and scalable infrastructure for LaMAS but also has
the potential to advance the Web paradigm from Web3 (centered on data
ownership) towards Web3.5, which emphasizes ownership of agent capabilities and
the monetization of intelligence. Beyond a systematic examination of the
BetaWeb framework, this paper presents a five-stage evolutionary roadmap,
outlining the path of LaMAS from passive execution to advanced collaboration
and autonomous governance. We also conduct a comparative analysis of existing
products and discuss key challenges of BetaWeb from multiple perspectives.
Ultimately, we argue that deep integration between blockchain and LaMAS can lay
the foundation for a resilient, trustworthy, and sustainably incentivized
digital ecosystem. A summary of the enabling technologies for each stage is
available at https://github.com/MatZaharia/BetaWeb.

</details>
