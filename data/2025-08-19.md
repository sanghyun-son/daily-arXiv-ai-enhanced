<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 156]
- [cs.CL](#cs.CL) [Total: 81]
- [cs.AI](#cs.AI) [Total: 55]
- [cs.DC](#cs.DC) [Total: 8]
- [cs.MA](#cs.MA) [Total: 5]
- [cs.IR](#cs.IR) [Total: 15]
- [cs.LG](#cs.LG) [Total: 110]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [A Deep Learning-Based CCTV System for Automatic Smoking Detection in Fire Exit Zones](https://arxiv.org/abs/2508.11696)
*Sami Sadat,Mohammad Irtiza Hossain,Junaid Ahmed Sifat,Suhail Haque Rafi,Md. Waseq Alauddin Alvi,Md. Khalilur Rhaman*

Main category: cs.CV

TL;DR: CCTV에서 비상구 주변의 흡연을 실시간으로 탐지하기 위해 YOLO 기반 모델(YOLOv8/11/12)을 비교하고, YOLOv8을 확장한 커스텀 모델을 제안함. 제안 모델은 recall 78.90%·mAP50 83.70%를 달성했고 Jetson Xavier NX에서 52~97ms 추론 시간을 기록함.


<details>
  <summary>Details</summary>
Motivation: 비상구 및 화재 취약 구역에서의 흡연은 즉각적인 안전 위험이므로 실시간 감시와 자동 규정 준수가 필요함.

Method: 8,124장(20개 시나리오) 데이터와 2,708개 저조도 샘플을 사용하여 YOLOv8/YOLOv11/YOLOv12를 평가하고, YOLOv8 기반에 추가 구조를 도입한 맞춤형 모델을 설계. 멀티스레드로 여러 엣지 장치에서 성능을 측정함.

Result: 제안 모델이 최상 성능을 보였으며 recall 78.90%, mAP@50 83.70%를 달성. Jetson Xavier NX에서 52~97ms/추론으로 실시간 요건 충족 가능성을 제시.

Conclusion: 다양한 환경에서 흡연 감시를 위한 견고하고 적응 가능한 플랫폼을 제공하며 공공 안전 모니터링과 규정 준수 자동화에 활용 가능함.

Abstract: A deep learning real-time smoking detection system for CCTV surveillance of
fire exit areas is proposed due to critical safety requirements. The dataset
contains 8,124 images from 20 different scenarios along with 2,708 raw samples
demonstrating low-light areas. We evaluated three advanced object detection
models: YOLOv8, YOLOv11, and YOLOv12, followed by development of a custom model
derived from YOLOv8 with added structures for challenging surveillance
contexts. The proposed model outperformed the others, achieving a recall of
78.90 percent and mAP at 50 of 83.70 percent, delivering optimal object
detection across varied environments. Performance evaluation on multiple edge
devices using multithreaded operations showed the Jetson Xavier NX processed
data at 52 to 97 milliseconds per inference, establishing its suitability for
time-sensitive operations. This system offers a robust and adaptable platform
for monitoring public safety and enabling automatic regulatory compliance.

</details>


### [2] [Separating Knowledge and Perception with Procedural Data](https://arxiv.org/abs/2508.11697)
*Adrián Rodríguez-Muñoz,Manel Baradad,Phillip Isola,Antonio Torralba*

Main category: cs.CV

TL;DR: Representations trained only on procedural (synthetic) data plus an explicit visual-memory of reference embeddings can perform competitively on real-world similarity, classification, and segmentation tasks without further model training.


<details>
  <summary>Details</summary>
Motivation: Eliminate reliance on real-image training data while retaining strong downstream performance and achieve full compartmentalization (model contains no real-image information) by using a separable visual-memory for real-image knowledge.

Method: Train representation models solely on procedurally generated images. At inference, use an explicit database of reference image embeddings (visual memory) to perform tasks (visual similarity, classification, segmentation) without further model fine-tuning; task outputs come from retrieval/label-transfer from the memory.

Result: Procedural model matches or is close to real-data-trained baselines: within 1% on NIGHTS visual similarity vs Places-trained model; +8% and +15% on CUB200 and Flowers102 fine-grained classification; within 10% on ImageNet-1K classification; COCO segmentation R^2 within 10% of real-data-trained models.

Conclusion: Procedural-only training plus visual memory yields strong, nearly competitive zero-shot performance while fully compartmentalizing real data from model weights. Remaining gap is explained by procedural models encoding different parts of the same object as dissimilar, causing incorrect memory retrievals; fixing part-level consistency may close the gap.

Abstract: We train representation models with procedural data only, and apply them on
visual similarity, classification, and semantic segmentation tasks without
further training by using visual memory -- an explicit database of reference
image embeddings. Unlike prior work on visual memory, our approach achieves
full compartmentalization with respect to all real-world images while retaining
strong performance. Compared to a model trained on Places, our procedural model
performs within $1\%$ on NIGHTS visual similarity, outperforms by $8\%$ and
$15\%$ on CUB200 and Flowers102 fine-grained classification, and is within
$10\%$ on ImageNet-1K classification. It also demonstrates strong zero-shot
segmentation, achieving an $R^2$ on COCO within $10\%$ of the models trained on
real data. Finally, we analyze procedural versus real data models, showing that
parts of the same object have dissimilar representations in procedural models,
resulting in incorrect searches in memory and explaining the remaining
performance gap.

</details>


### [3] [FusionFM: Fusing Eye-specific Foundational Models for Optimized Ophthalmic Diagnosis](https://arxiv.org/abs/2508.11721)
*Ke Zou,Jocelyn Hui Lin Goh,Yukun Zhou,Tian Lin,Samantha Min Er Yew,Sahana Srinivasan,Meng Wang,Rui Santos,Gabor M. Somfai,Huazhu Fu,Haoyu Chen,Pearse A. Keane,Ching-Yu Cheng,Yih Chung Tham*

Main category: cs.CV

TL;DR: 이 논문은 안저 영상 기반의 안과·전신 질환 예측에 쓰이는 4개 파운데이션 모델(FMs)을 비교하고, 두 가지 모델 융합 방법(FusionFM)을 제안해 평가한 연구입니다. DINORET과 RetiZero가 전반적으로 우수했고, 게이팅 기반 융합이 일부 질환(녹내장, AMD, 고혈압) 예측을 소폭 개선했습니다. 그러나 외부 코호트에서 전신 질환(특히 고혈압) 예측은 여전히 어렵습니다.


<details>
  <summary>Details</summary>
Motivation: 안저 이미지를 이용한 질병 예측에서 다양한 파운데이션 모델이 등장했으나, 어떤 모델이 가장 우수한지, 과제에 따라 성능 차이가 있는지, 모델들을 융합하면 도움이 되는지에 대한 체계적 비교가 부족합니다. 이를 해결하기 위해 단일 모델과 융합 모델을 포괄적으로 평가할 필요가 있습니다.

Method: RETFound, VisionFM, RetiZero, DINORET 등 4개 최신 안과 파운데이션 모델을 선택해, 녹내장·당뇨망막병증·연령관련황반변성(AMD) 등 안과 질환과 당뇨·고혈압 등 전신 질환 예측 과제에 대해 AUC와 F1으로 성능을 비교했습니다. 또한 두 가지 융합 전략(게이팅 기반 융합 등)을 제안해 성능 향상을 평가했으며, 다국가 표준화 데이터셋과 외부 검증도 수행했습니다.

Result: DINORET과 RetiZero가 전반적으로 우수한 성능을 보였고, RetiZero는 외부 데이터에서의 일반화 능력이 특히 좋았습니다. 게이팅 기반 융합은 녹내장, AMD, 고혈압 예측에서 소폭 성능 향상을 가져왔습니다. 반면 전신 질환 예측, 특히 외부 코호트의 고혈압 예측은 여전히 낮은 성능을 보였습니다.

Conclusion: 안과 파운데이션 모델들 간 성능 차이가 존재하며, 일부 모델 융합은 특정 질환 예측을 개선할 수 있습니다. 그러나 외부 데이터 일반화와 전신 질환(특히 고혈압) 예측은 여전히 도전적이므로, 더 큰 데이터 다양성·향상된 융합 전략·임상적 검증이 필요합니다.

Abstract: Foundation models (FMs) have shown great promise in medical image analysis by
improving generalization across diverse downstream tasks. In ophthalmology,
several FMs have recently emerged, but there is still no clear answer to
fundamental questions: Which FM performs the best? Are they equally good across
different tasks? What if we combine all FMs together? To our knowledge, this is
the first study to systematically evaluate both single and fused ophthalmic
FMs. To address these questions, we propose FusionFM, a comprehensive
evaluation suite, along with two fusion approaches to integrate different
ophthalmic FMs. Our framework covers both ophthalmic disease detection
(glaucoma, diabetic retinopathy, and age-related macular degeneration) and
systemic disease prediction (diabetes and hypertension) based on retinal
imaging. We benchmarked four state-of-the-art FMs (RETFound, VisionFM,
RetiZero, and DINORET) using standardized datasets from multiple countries and
evaluated their performance using AUC and F1 metrics. Our results show that
DINORET and RetiZero achieve superior performance in both ophthalmic and
systemic disease tasks, with RetiZero exhibiting stronger generalization on
external datasets. Regarding fusion strategies, the Gating-based approach
provides modest improvements in predicting glaucoma, AMD, and hypertension.
Despite these advances, predicting systemic diseases, especially hypertension
in external cohort remains challenging. These findings provide an
evidence-based evaluation of ophthalmic FMs, highlight the benefits of model
fusion, and point to strategies for enhancing their clinical applicability.

</details>


### [4] [UniDCF: A Foundation Model for Comprehensive Dentocraniofacial Hard Tissue Reconstruction](https://arxiv.org/abs/2508.11728)
*Chunxia Ren,Ning Zhu,Yue Lai,Gui Chen,Ruijie Wang,Yangyi Hu,Suyao Liu,Shuwen Mao,Hong Su,Yu Zhang,Li Xiao*

Main category: cs.CV

TL;DR: UniDCF는 점군(point cloud)과 다중 뷰 이미지를 융합하고 점진적 노이즈 제거(score-based denoising)를 적용해 치아·두개·안면의 경조직을 다중 모달로 재구성하는 통합 프레임워크다. 6,609명 환자의 54,555개 주석 인스턴스 규모 데이터셋으로 학습·평가했으며, 기존 방법들보다 기하학적 정밀도·구조적 완전성·공간 정확도에서 우수하고, 임상 시뮬레이션에서 설계 시간을 99% 단축하고 수용도 94% 이상을 보였다.


<details>
  <summary>Details</summary>
Motivation: 기존 딥러닝 기반 재구성 모델들은 단일 조직(single-tissue) 또는 단일 모달리티 입력에 국한되어 일반화·해상도·계산 효율성 사이에서 상충(trade-off)이 발생한다. 다중 경조직을 높은 해상도로 빠르게 재구성하는 통합적 방법이 필요하다.

Method: 점군과 다중 뷰 이미지의 멀티모달 인코딩을 결합한 통합 네트워크(UniDCF) 설계. 모달리티 간 상호보완적 정보를 활용하고, 표면 매끄러움(quality)을 개선하기 위해 score-based denoising 모듈을 포함. 대규모 멀티모달 데이터셋으로 학습·평가.

Result: 대규모 실험에서 기존 SOTA 대비 기하학 정밀도·구조적 완전성·공간 정확도 우수, 임상 시뮬레이션에서 설계 시간 99% 단축, 임상의 평가 수용도 >94%.

Conclusion: 멀티모달 융합과 점진적 노이즈 제거를 통해 단일 모달 한계를 극복하고, 고정밀·고효율의 자동화된 dentocraniofacial 경조직 재구성 파이프라인을 제시함.

Abstract: Dentocraniofacial hard tissue defects profoundly affect patients'
physiological functions, facial aesthetics, and psychological well-being,
posing significant challenges for precise reconstruction. Current deep learning
models are limited to single-tissue scenarios and modality-specific imaging
inputs, resulting in poor generalizability and trade-offs between anatomical
fidelity, computational efficiency, and cross-tissue adaptability. Here we
introduce UniDCF, a unified framework capable of reconstructing multiple
dentocraniofacial hard tissues through multimodal fusion encoding of point
clouds and multi-view images. By leveraging the complementary strengths of each
modality and incorporating a score-based denoising module to refine surface
smoothness, UniDCF overcomes the limitations of prior single-modality
approaches. We curated the largest multimodal dataset, comprising intraoral
scans, CBCT, and CT from 6,609 patients, resulting in 54,555 annotated
instances. Evaluations demonstrate that UniDCF outperforms existing
state-of-the-art methods in terms of geometric precision, structural
completeness, and spatial accuracy. Clinical simulations indicate UniDCF
reduces reconstruction design time by 99% and achieves clinician-rated
acceptability exceeding 94%. Overall, UniDCF enables rapid, automated, and
high-fidelity reconstruction, supporting personalized and precise restorative
treatments, streamlining clinical workflows, and enhancing patient outcomes.

</details>


### [5] [Ovis2.5 Technical Report](https://arxiv.org/abs/2508.11737)
*Shiyin Lu,Yang Li,Yu Xia,Yuwei Hu,Shanshan Zhao,Yanqing Ma,Zhichao Wei,Yinglun Li,Lunhao Duan,Jianshan Zhao,Yuxuan Han,Haijun Li,Wanying Chen,Junke Tang,Chengkun Hou,Zhixing Du,Tianli Zhou,Wenjie Zhang,Huping Ding,Jiahe Li,Wen Li,Gui Hu,Yiliang Gu,Siran Yang,Jiamang Wang,Hailong Sun,Yibo Wang,Hui Sun,Jinlong Huang,Yuping He,Shengze Shi,Weihong Zhang,Guodong Zheng,Junpeng Jiang,Sensen Gao,Yi-Feng Wu,Sijia Chen,Yuhui Chen,Qing-Guo Chen,Zhao Xu,Weihua Luo,Kaifu Zhang*

Main category: cs.CV

TL;DR: Ovis2.5 is an upgraded multimodal model featuring a native-resolution vision transformer and a reflection-based “thinking mode” for stronger reasoning. Trained with a five-phase curriculum including DPO and GRPO, it achieves SOTA results among open-source MLLMs <40B (Ovis2.5-9B: 78.3, Ovis2.5-2B: 73.9 on OpenCompass) and shows strong performance on STEM, grounding, video, and complex chart analysis.


<details>
  <summary>Details</summary>
Motivation: Improve visual fidelity and multimodal reasoning of Ovis2 by avoiding fixed-resolution tiling and enabling iterative self-checking and revision, thereby handling visually dense inputs and harder reasoning tasks.

Method: Introduce a native-resolution vision transformer that processes variable-resolution images; train the model with a five-phase curriculum (visual/multimodal pretraining, instruction tuning, alignment and reasoning enhancement using DPO and GRPO); expose a reflection-capable optional inference "thinking mode"; optimize training with multimodal data packing and hybrid parallelism. Release two open-source models (9B and 2B).

Result: Ovis2.5-9B scores 78.3 on OpenCompass (substantial improvement over Ovis2-8B) and leads open-source MLLMs under 40B. Ovis2.5-2B scores 73.9, setting SOTA for its scale. Additional strengths shown on STEM benchmarks, grounding/video tasks, and complex chart analysis.

Conclusion: Ovis2.5 advances visual fidelity and multimodal reasoning via native-resolution processing and reflection-based inference, delivering state-of-the-art open-source performance at multiple scales while offering an efficient training pipeline. Further evaluation details (latency/ablation/generalization) would clarify trade-offs and robustness.

Abstract: We present Ovis2.5, a successor to Ovis2 designed for native-resolution
visual perception and strong multimodal reasoning. Ovis2.5 integrates a
native-resolution vision transformer that processes images at their native,
variable resolutions, avoiding the degradation from fixed-resolution tiling and
preserving both fine detail and global layout -- crucial for visually dense
content like complex charts. To strengthen reasoning, we train the model to
move beyond linear chain-of-thought and perform reflection -- including
self-checking and revision. This advanced capability is exposed as an optional
"thinking mode" at inference time, allowing users to trade latency for enhanced
accuracy on difficult inputs. The model is trained via a comprehensive
five-phase curriculum that progressively builds its skills. The process begins
with foundational visual and multimodal pretraining, advances through
large-scale instruction tuning, and culminates in alignment and reasoning
enhancement using DPO and GRPO. To scale these upgrades efficiently, we employ
multimodal data packing and hybrid parallelism, yielding a significant
end-to-end speedup. We release two open-source models: Ovis2.5-9B and
Ovis2.5-2B. The latter continues the "small model, big performance" philosophy
of Ovis2, making it ideal for resource-constrained, on-device scenarios. On the
OpenCompass multimodal leaderboard, Ovis2.5-9B averages 78.3, marking a
substantial improvement over its predecessor, Ovis2-8B, and achieving
state-of-the-art results among open-source MLLMs in the sub-40B parameter
range; Ovis2.5-2B scores 73.9, establishing SOTA for its size. Beyond aggregate
scores, Ovis2.5 achieves leading results on STEM benchmarks, exhibits strong
capabilities on grounding and video tasks, and achieves open-source SOTA at its
scale for complex chart analysis.

</details>


### [6] [VideoAVE: A Multi-Attribute Video-to-Text Attribute Value Extraction Dataset and Benchmark Models](https://arxiv.org/abs/2508.11801)
*Ming Cheng,Tong Wu,Jiazhen Hu,Jiaying Gong,Hoda Eldardiry*

Main category: cs.CV

TL;DR: VideoAVE는 전자상거래 상품 비디오에서 속성-값을 추출하는 최초의 공개 비디오-투-텍스트 AVE 데이터셋이다. 14개 도메인, 172개 속성, CLIP 기반 MoE 필터링으로 정제해 22.4만 학습, 2.5만 평가 샘플을 제공하고, 여러 최신 비전-언어 모델을 벤치마크해 비디오 AVE의 난이도와 시간적 정보 활용의 한계를 보여준다.


<details>
  <summary>Details</summary>
Motivation: 기존 AVE 데이터셋은 텍스트-투-텍스트나 이미지-투-텍스트에 한정되고, 비디오를 다루지 못하며 속성 커버리지가 부족하고 공개 데이터가 거의 없다. 비디오에는 시간적 단서(회전, 사용 장면 등)가 있어 상품 속성 추출에 유용하므로 이를 보완할 공개 데이터셋이 필요하다.

Method: 웹에서 수집한 비디오-상품 쌍을 대상으로 CLIP 기반 Mixture of Experts(CLIP-MoE) 후처리 필터를 적용해 비디오와 상품의 불일치 쌍을 제거하고 고품질 데이터셋을 구성함. 데이터셋을 바탕으로 속성-조건 값 예측(attribute-conditioned value prediction)과 오픈 속성-값 추출(open attribute-value pair extraction) 두 과제로 최신 비디오 VLM들을 벤치마크했다.

Result: CLIP-MoE로 정제된 데이터셋은 224k 학습 샘플과 25k 평가 샘플로 구성됨. 벤치마크 결과, 최신 VLM들이 속성-조건 문제에서는 일정 성능을 보이나 오픈 설정 및 시간적 정보를 요구하는 경우 전반적으로 어려움이 크며 개선 여지가 크다.

Conclusion: VideoAVE는 비디오 기반 전자상거래 AVE 연구를 위한 첫 공개 리소스로서 가치가 크며, 특히 오픈 설정과 시간적 정보를 효과적으로 활용하는 새로운 비전-언어 모델 연구가 필요함을 시사한다.

Abstract: Attribute Value Extraction (AVE) is important for structuring product
information in e-commerce. However, existing AVE datasets are primarily limited
to text-to-text or image-to-text settings, lacking support for product videos,
diverse attribute coverage, and public availability. To address these gaps, we
introduce VideoAVE, the first publicly available video-to-text e-commerce AVE
dataset across 14 different domains and covering 172 unique attributes. To
ensure data quality, we propose a post-hoc CLIP-based Mixture of Experts
filtering system (CLIP-MoE) to remove the mismatched video-product pairs,
resulting in a refined dataset of 224k training data and 25k evaluation data.
In order to evaluate the usability of the dataset, we further establish a
comprehensive benchmark by evaluating several state-of-the-art video vision
language models (VLMs) under both attribute-conditioned value prediction and
open attribute-value pair extraction tasks. Our results analysis reveals that
video-to-text AVE remains a challenging problem, particularly in open settings,
and there is still room for developing more advanced VLMs capable of leveraging
effective temporal information. The dataset and benchmark code for VideoAVE are
available at: https://github.com/gjiaying/VideoAVE

</details>


### [7] [An MLP Baseline for Handwriting Recognition Using Planar Curvature and Gradient Orientation](https://arxiv.org/abs/2508.11803)
*Azam Nouri*

Main category: cs.CV

TL;DR: 두 번째 미분 기반 기하학적 단서(곡률 크기, 곡률 부호, 그래디언트 방향)를 입력으로 한 MLP가 MNIST에서 97%, EMNIST letters에서 89% 정확도를 보여 CNN 대안으로서 가능함을 제시함.


<details>
  <summary>Details</summary>
Motivation: CNN 기반의 자동 표현 학습 대신 해석 가능한 수공형 특징(곡률·방향 기반)이 단독으로 HCR 성능을 낼 수 있는지 검증하고자 함.

Method: 이미지에서 세 가지 특징 맵(곡률 크기, 곡률 부호, 그래디언트 방향)을 계산해 MLP에 입력. MLP 구조/하이퍼파라미터는 논문에 기술되어 있음(추정). MNIST 및 EMNIST letters 데이터셋으로 학습·평가.

Result: MNIST 97% 정확도, EMNIST letters 89% 정확도를 보고. 곡률 기반 표현이 판별력이 높음을 실험적으로 입증.

Conclusion: 해석 가능한 2차 기하학적 특징만으로도 강력한 HCR 성능을 얻을 수 있으며, 딥러닝의 이점이 반드시 복잡한 합성곱 구조에만 의존하지 않음을 시사함.

Abstract: This study investigates whether second-order geometric cues - planar
curvature magnitude, curvature sign, and gradient orientation - are sufficient
on their own to drive a multilayer perceptron (MLP) classifier for handwritten
character recognition (HCR), offering an alternative to convolutional neural
networks (CNNs). Using these three handcrafted feature maps as inputs, our
curvature-orientation MLP achieves 97 percent accuracy on MNIST digits and 89
percent on EMNIST letters. These results underscore the discriminative power of
curvature-based representations for handwritten character images and
demonstrate that the advantages of deep learning can be realized even with
interpretable, hand-engineered features.

</details>


### [8] [Labels or Input? Rethinking Augmentation in Multimodal Hate Detection](https://arxiv.org/abs/2508.11808)
*Sahajpreet Singh,Rongxin Ouyang,Subhayan Mukerjee,Kokil Jaidka*

Main category: cs.CV

TL;DR: 이 논문은 프롬프트 설계 최적화와 멀티모달 데이터 증강(혐오성 모달리티를 분리해 중립화한 합성 밈 생성)을 결합해 비전-언어 모델의 혐오 밈 탐지 성능과 일반화·공정성을 높이는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 웹에 게시된 밈은 텍스트와 이미지의 미묘한 상호작용으로 혐오 의도가 은닉되는 경우가 많아 기존 VLM들은 세밀한 감독(signals)에 취약하고 암묵적 혐오를 잘 탐지하지 못한다. 모델 크기만으로는 한계가 있어 프롬프트와 데이터 구성의 중요성을 밝힐 필요가 있다.

Method: (1) 프롬프트 최적화 프레임워크: 프롬프트 구조, 감독(라벨) 세분화, 학습 모달리티를 체계적으로 변형해 성능과 견고성을 분석. 구조화된 프롬프트와 라벨 스케일링을 적용. InternVL2 등 VLM을 비교.(2) 멀티모달 데이터 증강: 멀티에이전트 LLM–VLM 파이프라인으로 혐오 모달리티를 분리·재작성하여 2,479개의 반사실적(대조적) 중립 밈 생성, 스푸리어스 상관관계 완화 목적.

Result: 구조화된 프롬프트가 소형 모델에서도 견고성을 향상시키고, 라벨 스케일링이 성능에 영향. InternVL2가 이진·스케일드 평가 모두에서 최고 F1 점수를 기록. 증강 데이터는 스푸리어스 패턴을 줄여 분류기 일반화 성능을 개선함.

Conclusion: 프롬프트 구조와 데이터 구성은 모델 크기만큼이나 중요하며, 표적화된 합성 증강은 보다 신뢰할 수 있고 문맥 민감한 혐오 탐지기를 만드는 데 기여한다. 합성 데이터 생성은 강건하고 공정한 비전-언어 모델 훈련의 유망한 방향을 제시한다.

Abstract: The modern web is saturated with multimodal content, intensifying the
challenge of detecting hateful memes, where harmful intent is often conveyed
through subtle interactions between text and image under the guise of humor or
satire. While recent advances in Vision-Language Models (VLMs) show promise,
these models lack support for fine-grained supervision and remain susceptible
to implicit hate speech. In this paper, we present a dual-pronged approach to
improve multimodal hate detection. First, we propose a prompt optimization
framework that systematically varies prompt structure, supervision granularity,
and training modality. We show that prompt design and label scaling both
influence performance, with structured prompts improving robustness even in
small models, and InternVL2 achieving the best F1-scores across binary and
scaled settings. Second, we introduce a multimodal data augmentation pipeline
that generates 2,479 counterfactually neutral memes by isolating and rewriting
the hateful modality. This pipeline, powered by a multi-agent LLM-VLM setup,
successfully reduces spurious correlations and improves classifier
generalization. Our approaches inspire new directions for building synthetic
data to train robust and fair vision-language models. Our findings demonstrate
that prompt structure and data composition are as critical as model size, and
that targeted augmentation can support more trustworthy and context-sensitive
hate detection.

</details>


### [9] [Towards Understanding 3D Vision: the Role of Gaussian Curvature](https://arxiv.org/abs/2508.11825)
*Sherlon Almeida da Silva,Davi Geiger,Luiz Velho,Moacir Antonelli Ponti*

Main category: cs.CV

TL;DR: 저자들은 가우시안 곡률이 3D 표면 모델링에서 희소하고 압축된 표현을 제공하며, 중간베리(Middlebury) 스테레오 데이터에서 이것이 최첨단 단안·스테레오 방법들에서 암묵적으로 고려되고 있음을 보이고, 곡률을 기하학적 사전(prior)·무감독 평가 지표로 활용할 수 있음을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 딥러닝 기반의 데이터 주도적 방법들은 뛰어난 성능을 보이나, 명시적 3D 기하 모델이 없어 해석·전이·통제 실험이 어렵다. 이에 불변량인 가우시안 곡률을 통해 해석 가능하고 전이 가능한 3D 표현을 탐구하려 함.

Method: 가우시안 곡률의 성질을 분석하고 Middlebury 스테레오 데이터셋에서 실험을 수행하여(곡률의 분포·희소성 분석), 기존 단안·스테레오 방법들이 곡률 정보를 암묵적으로 학습하는지 평가하고, 곡률을 기하학적 사전 및 무감독 성능 지표로 사용하는 방안을 검증.

Result: 가우시안 곡률이 3D 표면을 희소하고 압축적으로 기술함을 보였고, 대부분 최첨단 방법들이 곡률 특성을 암묵적으로 반영하지만 명시적 모듈로 분리되진 않음. 또한 곡률 기반 사전이 재구성 성능을 개선하고, 무감독 스테레오 평가 지표로 활용 가능한 잠재력을 보임.

Conclusion: 가우시안 곡률은 관찰자 불변의 유용한 기하학적 신호로서 3D 표면 재구성에 대한 해석 가능하고 전이 가능한 사전 및 평가 기준을 제공한다. 향후 명시적 곡률 모듈 통합과 더 넓은 데이터셋·응용 검증이 필요하다.

Abstract: Recent advances in computer vision have predominantly relied on data-driven
approaches that leverage deep learning and large-scale datasets. Deep neural
networks have achieved remarkable success in tasks such as stereo matching and
monocular depth reconstruction. However, these methods lack explicit models of
3D geometry that can be directly analyzed, transferred across modalities, or
systematically modified for controlled experimentation. We investigate the role
of Gaussian curvature in 3D surface modeling. Besides Gaussian curvature being
an invariant quantity under change of observers or coordinate systems, we
demonstrate using the Middlebury stereo dataset that it offers: (i) a sparse
and compact description of 3D surfaces, (ii) state-of-the-art monocular and
stereo methods seem to implicitly consider it, but no explicit module of such
use can be extracted, (iii) a form of geometric prior that can inform and
improve 3D surface reconstruction, and (iv) a possible use as an unsupervised
metric for stereo methods.

</details>


### [10] [From Pixels to Graphs: Deep Graph-Level Anomaly Detection on Dermoscopic Images](https://arxiv.org/abs/2508.11826)
*Dehn Xu,Tim Katzke,Emmanuel Müller*

Main category: cs.CV

TL;DR: 이미지에서 그래프를 생성하는 다양한 방법(분할, 간선 구성, 노드 특성)을 체계적으로 비교하여 그래프 수준 이상치 탐지(GLAD)에 미치는 영향을 평가한 연구입니다. 색상, 질감, 형태 특성 조합이 성능을 높이며, 비지도 OCGTL에서 AUC-ROC 0.805, 약간의 라벨 포함 시 0.872, 완전 지도 시 0.914를 기록했습니다.


<details>
  <summary>Details</summary>
Motivation: 이미지를 그래프로 변환하는 방법은 다양하지만, GLAD용으로 어떤 변환이 가장 효과적인지에 대한 체계적인 비교 연구가 부족했습니다. 따라서 분할 방식, 간선 구성, 노드 특성 세트가 GLAD 성능에 미치는 영향을 규명하려 했습니다.

Method: 피부 피부 영상(dermoscopic images)을 대상으로 여러 분할 스킴(세그먼트 방식), 간선 생성 전략, 색상·질감·형태 기반 노드 특성 집합을 조합해 이미지 유래 그래프를 생성. 최첨단 GLAD 모델들(예: OCGTL 등)을 사용해 순수 비지도·약지도·완전지도 시나리오에서 성능과 효율성을 비교 실험함.

Result: 색상 특성이 단독으로 가장 좋은 성능을 보였고, 형태와 질감 특성을 추가하면 일관되게 성능이 향상됨. 비지도 OCGTL 기반 최적 구성으로 AUC-ROC 0.805, 일부 라벨 포함 시 0.872, 전체 라벨 사용 시 0.914를 달성. 또한 사전학습된 백본을 사용하지 않고도 경쟁력 있는 성능을 보였음.

Conclusion: 이미지→그래프 변환 설계(분할·간선·특성 선택)가 GLAD 성능에 큰 영향을 미치며, 색상 기반 특성이 중요하되 형태·질감의 결합이 성능을 더욱 개선함. 적은 라벨만으로도 성능이 크게 향상되므로 약지도 접근이 실용적임.

Abstract: Graph Neural Networks (GNNs) have emerged as a powerful approach for
graph-based machine learning tasks. Previous work applied GNNs to image-derived
graph representations for various downstream tasks such as classification or
anomaly detection. These transformations include segmenting images, extracting
features from segments, mapping them to nodes, and connecting them. However, to
the best of our knowledge, no study has rigorously compared the effectiveness
of the numerous potential image-to-graph transformation approaches for
GNN-based graph-level anomaly detection (GLAD). In this study, we
systematically evaluate the efficacy of multiple segmentation schemes, edge
construction strategies, and node feature sets based on color, texture, and
shape descriptors to produce suitable image-derived graph representations to
perform graph-level anomaly detection. We conduct extensive experiments on
dermoscopic images using state-of-the-art GLAD models, examining performance
and efficiency in purely unsupervised, weakly supervised, and fully supervised
regimes. Our findings reveal, for example, that color descriptors contribute
the best standalone performance, while incorporating shape and texture features
consistently enhances detection efficacy. In particular, our best unsupervised
configuration using OCGTL achieves a competitive AUC-ROC score of up to 0.805
without relying on pretrained backbones like comparable image-based approaches.
With the inclusion of sparse labels, the performance increases substantially to
0.872 and with full supervision to 0.914 AUC-ROC.

</details>


### [11] [Recent Advances in Transformer and Large Language Models for UAV Applications](https://arxiv.org/abs/2508.11834)
*Hamza Kheddar,Yassine Habchi,Mohamed Chahine Ghanem,Mustapha Hemis,Dusit Niyato*

Main category: cs.CV

TL;DR: 이 논문은 UAV(드론) 분야에 Transformer 기반 모델을 체계적으로 분류·평가하고, 응용 사례·데이터셋·성능 비교·한계와 향후 연구 방향을 제시하는 종합 리뷰입니다.


<details>
  <summary>Details</summary>
Motivation: Transformer 계열 모델들이 UAV의 인식·의사결정·자율성 향상에 유의미한 영향을 미치고 있으나, 관련 연구가 빠르게 늘어나 체계적 정리가 필요해졌기 때문입니다. 기존 리뷰들이 분야별·기법별로 분산되어 있어 통합된 분류체계와 비교분석이 요구됩니다.

Method: Transformer 아키텍처(어텐션 메커니즘, CNN-Transformer 하이브리드, 강화학습용 Transformer, 대형 언어모델 등)를 분류하고, 응용 분야(정밀 농업, 자율 항법 등)별 사례를 정리함. 관련 데이터셋, 시뮬레이터, 평가 지표를 검토하고 구조화된 표와 성능 벤치마크를 통해 비교분석을 수행함.

Result: 통합된 분류체계 구축, 주요 응용 및 성능 비교 표 제공, 계산 효율성과 실시간 적용에 대한 한계 및 연구 격차 도출. Transformer 기반 UAV 연구의 현재 지형과 실무적 고려사항을 정리함.

Conclusion: Transformer 기술이 UAV 성능 향상에 큰 잠재력을 가지지만, 계산 비용·실시간성·표준화된 평가의 부족 등 실용적 장애물이 존재하므로 경량화·효율적 어텐션·시뮬레이션-현실 격차 해소 등 연구가 필요하다는 제언을 제시함.

Abstract: The rapid advancement of Transformer-based models has reshaped the landscape
of uncrewed aerial vehicle (UAV) systems by enhancing perception,
decision-making, and autonomy. This review paper systematically categorizes and
evaluates recent developments in Transformer architectures applied to UAVs,
including attention mechanisms, CNN-Transformer hybrids, reinforcement learning
Transformers, and large language models (LLMs). Unlike previous surveys, this
work presents a unified taxonomy of Transformer-based UAV models, highlights
emerging applications such as precision agriculture and autonomous navigation,
and provides comparative analyses through structured tables and performance
benchmarks. The paper also reviews key datasets, simulators, and evaluation
metrics used in the field. Furthermore, it identifies existing gaps in the
literature, outlines critical challenges in computational efficiency and
real-time deployment, and offers future research directions. This comprehensive
synthesis aims to guide researchers and practitioners in understanding and
advancing Transformer-driven UAV technologies.

</details>


### [12] [ComplicitSplat: Downstream Models are Vulnerable to Blackbox Attacks by 3D Gaussian Splat Camouflages](https://arxiv.org/abs/2508.11854)
*Matthew Hull,Haoyang Yang,Pratham Mehta,Mansi Phute,Aeree Cho,Haorang Wang,Matthew Lau,Wenke Lee,Wilian Lunardi,Martin Andreoni,Polo Chau*

Main category: cs.CV

TL;DR: 3D Gaussian Splatting 기반의 뷰포인트 특이적 위장(시각적 색·텍스처 변화)을 악용해 물체 검출기를 블랙박스 방식으로 교란하는 첫 공격(ComplicitSplat)을 제시. 물리적·합성 데이터에서 여러 검출기 유형에 대해 성공함을 보이며 자율주행 등 안전 민감 응용에 위험을 제기.


<details>
  <summary>Details</summary>
Motivation: 3D Gaussian Splatting(3DGS)이 효율적 신뷰 합성 기술로 널리 채택되는 가운데, 특히 안전 중요 시스템에서 입력 이미지를 조작해 악영향을 미치는 공격 가능성과 그에 따른 새로운 취약성을 규명하려는 목적.

Method: 3DGS의 표준 셰이딩(shading) 메커니즘을 악용해 '뷰포인트 특정적 카무플라주'를 생성. 특정 각도에서만 보이는 색·텍스처 변화를 장면 객체에 심어, 모델 아키텍처나 가중치 접근 없이(블랙박스) 하위 객체 검출기를 기만하도록 설계.

Result: 단일·다중 스테이지 및 트랜스포머 기반 인기 검출기들에 대해 실험적 성공을 보고. 물리적 캡처(실물 객체)와 합성 장면 모두에서 일반화 성능을 보이며, 이는 실제 시스템에서의 위협을 시사.

Conclusion: 3DGS 기반 신뷰 합성 파이프라인의 셰이딩 특성을 이용한 새로운 블랙박스 공격 벡터를 처음으로 제시. 자율주행·로봇 등 미션 크리티컬 시스템에 대한 안전 위험과 방어 필요성을 강조.

Abstract: As 3D Gaussian Splatting (3DGS) gains rapid adoption in safety-critical tasks
for efficient novel-view synthesis from static images, how might an adversary
tamper images to cause harm? We introduce ComplicitSplat, the first attack that
exploits standard 3DGS shading methods to create viewpoint-specific camouflage
- colors and textures that change with viewing angle - to embed adversarial
content in scene objects that are visible only from specific viewpoints and
without requiring access to model architecture or weights. Our extensive
experiments show that ComplicitSplat generalizes to successfully attack a
variety of popular detector - both single-stage, multi-stage, and
transformer-based models on both real-world capture of physical objects and
synthetic scenes. To our knowledge, this is the first black-box attack on
downstream object detectors using 3DGS, exposing a novel safety risk for
applications like autonomous navigation and other mission-critical robotic
systems.

</details>


### [13] [Impact of Clinical Image Quality on Efficient Foundation Model Finetuning](https://arxiv.org/abs/2508.11864)
*Yucheng Tang,Pawel Rajwa,Alexander Ng,Yipei Wang,Wen Yan,Natasha Thorley,Aqua Asif,Clare Allen,Louise Dickinson,Francesco Giganti,Shonit Punwani,Daniel C. Alexander,Veeru Kasivisvanathan,Yipeng Hu*

Main category: cs.CV

TL;DR: 프로파운드(ProFound) 같은 전용 비전 파운데이션 모델은 전처리된 전립선 MRI에서 소량의 레이블로도 좋은 성능을 보일 수 있으나, 파인튜닝과 배포(테스트) 시의 영상 품질 분포 불일치가 성능에 큰 영향을 미친다. 특히 파인튜닝에 충분한 고품질 영상이 포함되어야 성능 이득이 유지된다.


<details>
  <summary>Details</summary>
Motivation: 의료 영상 분야에서 파운데이션 모델은 적은 레이블로도 강한 성능을 내는 ‘라벨 효율성’이 장점이다. 그러나 실제 임상 데이터는 획득 장비·프로토콜·운용 차이로 영상 품질이 크게 달라지며, 품질 분포가 파인튜닝과 배포 환경에서 일치하지 않으면 성능 저하가 우려된다. 저자들은 전립선 다중적성 MRI에서 이 문제를 정량적으로 평가하고자 했다.

Method: 전립선 전용 파운데이션 모델 ProFound(대규모 전립선 MRI로 사전학습)를 사용. 파인튜닝과 평가 데이터셋에서 ‘고품질’과 ‘저품질’ 영상의 비율을 체계적으로 바꿔가며 여러 다운스트림 과제(자동 판독 리포팅, 전립선암 검출 등)에 대해 라벨 효율성과 일반화 성능을 측정했다. 파인튜닝 데이터의 품질 비율과 테스트 데이터의 품질 비율 간의 불일치 영향을 비교.

Result: (1) 파인튜닝과 테스트의 품질 비율 불일치가 다운스트림 성능에 유의미한 차이를 유발함. (2) 파인튜닝에 충분한 고품질 영상이 포함되어야 강한 성능 유지가 가능하며, 고품질 샘플 부족 시 사전학습된 모델이 무작위 초기화 모델보다 우수하지 않을 수 있음. (3) 품질 분포가 일치하면 파인튜닝은 스크래치 학습 대비 훨씬 적은 레이블로도 좋은 성능을 내지만, 이 라벨 효율성은 품질 분포에 의존함. (4) 품질 일치의 중요성은 과제(리포팅 vs 암 검출 등)에 따라 다름.

Conclusion: 파운데이션 모델의 실무적 이득을 완전히 실현하려면 파인튜닝 데이터와 배포 데이터의 영상 품질 분포를 정량적으로 평가·정렬하고, 다운스트림 과제별로 필요한 품질 기준을 마련해야 한다. 영상 품질을 측정·관리하고 고품질 샘플을 확보하거나 품질 인지 학습 기법을 도입하는 것이 중요하다.

Abstract: Foundation models in medical imaging have shown promising label efficiency,
achieving high downstream performance with only a fraction of annotated data.
Here, we evaluate this in prostate multiparametric MRI using ProFound, a
domain-specific vision foundation model pretrained on large-scale prostate MRI
datasets. We investigate how variable image quality affects label-efficient
finetuning by measuring the generalisability of finetuned models. Experiments
systematically vary high-/low-quality image ratios in finetuning and evaluation
sets. Our findings indicate that image quality distribution and its
finetune-and-test mismatch significantly affect model performance. In
particular: a) Varying the ratio of high- to low-quality images between
finetuning and test sets leads to notable differences in downstream
performance; and b) The presence of sufficient high-quality images in the
finetuning set is critical for maintaining strong performance, whilst the
importance of matched finetuning and testing distribution varies between
different downstream tasks, such as automated radiology reporting and prostate
cancer detection.When quality ratios are consistent, finetuning needs far less
labeled data than training from scratch, but label efficiency depends on image
quality distribution. Without enough high-quality finetuning data, pretrained
models may fail to outperform those trained without pretraining. This
highlights the importance of assessing and aligning quality distributions
between finetuning and deployment, and the need for quality standards in
finetuning data for specific downstream tasks. Using ProFound, we show the
value of quantifying image quality in both finetuning and deployment to fully
realise the data and compute efficiency benefits of foundation models.

</details>


### [14] [AdaRing: Towards Ultra-Light Vision-Language Adaptation via Cross-Layer Tensor Ring Decomposition](https://arxiv.org/abs/2508.11870)
*Ying Huang,Yuanbin Man,Wenqi Jia,Zhengzhong Tu,Junzhou Huang,Miao Yin*

Main category: cs.CV

TL;DR: AdaRing은 텐서 링 분해로 층 간 중복을 제거하고 다양성 있는 랭크 기반 어댑터들을 협업하게 하여 VLM을 90% 적은 학습 파라미터로 SOTA 수준으로 미세조정하는 초경량 PEFT 프레임워크다.


<details>
  <summary>Details</summary>
Motivation: 기존 어댑터 기반 미세조정은 모든 층에 동형 어댑터를 삽입해 용량을 키우지만 층간 중복(크로스-레이어 레던던시)과 동일 구조 어댑터의 표현 한계로 인해 압축율과 표현력이 제한된다.

Method: 텐서 레벨 저랭크 가정을 이용해 어댑터를 층-공유 텐서 코어와 층-특이 슬라이스로 모델링(텐서 링 분해, TRD). 또한 일반화 민감도에 따라 서로 다른 랭크를 가진 어댑터들을 협업시키는 '랭크-드리븐' 다이버시티 전략을 도입하여 다양한 표현 수요를 처리한다.

Result: 다양한 비전-언어 다운스트림 과제에서 SOTA 성능을 달성하면서 평균 학습 파라미터를 약 90% 절감했다고 보고한다.

Conclusion: AdaRing은 층간 중복을 제거하고 이질적 어댑터의 협업을 통해 고압축·고성능의 어댑터 기반 PEFT를 실현하며, 향후 랭크 선택 전략·실제 지연 및 메모리 영향에 대한 추가 분석이 요구된다.

Abstract: Adapter-based fine-tuning has gained remarkable attention in adapting large
pre-trained vision language models (VLMs) for a wide range of downstream tasks
efficiently. In this paradigm, only the inserted adapters are fine-tuned,
without the need for training the original VLM backbone. Existing works scale
adapters by integrating them into every layer of VLMs to increase the capacity
of adapters. However, these methods face two primary limitations: 1) limited
compression rate due to ignoring cross-layer redundancy, and 2) limited
representational capacity across homogeneous adapters. In this paper, we
propose a novel vision-language fine-tuning framework based on cross-layer
tensor ring decomposition (TRD) with the integration and collaboration of
diverse adapters, called AdaRing, achieving ultra-light parameter-efficient
adaptation of VLMs on various tasks. To remove the high redundancy that exists
among adapters across layers, we exploit the tensor-level low-rankness to
formulate adapters as layer-shared tensor cores and layer-specific slices.
Moreover, guided by generalization-aware fine-tuning, diverse rank-driven
adapters cooperate to handle tasks that require different representations. Our
experiments show that the proposed AdaRing achieves the state-of-the-art
performance while reducing average training parameters by 90%.

</details>


### [15] [EVTP-IVS: Effective Visual Token Pruning For Unifying Instruction Visual Segmentation In Multi-Modal Large Language Models](https://arxiv.org/abs/2508.11886)
*Wenhui Zhu,Xiwen Chen,Zhipeng Wang,Shao Tang,Sayan Ghosh,Xuanzhao Dong,Rajat Koner,Yalin Wang*

Main category: cs.CV

TL;DR: IVS(지시 기반 시각 분할)에서 시각 토큰 샘플링이 분할 성능에 큰 영향을 미친다는 관찰에 기반해, 공간 정보를 통합한 k-center 기반 토큰 프루닝 기법 EVTP-IV를 제안. 20% 토큰만 사용해도 이미지에서 3.5×, 비디오에서 최대 5× 속도 향상을 얻으며 정확도 유사, 기존 프루닝 방법들보다 우수.


<details>
  <summary>Details</summary>
Motivation: 대규모 멀티모달 LLM(MLLM)의 IVS 적용 시 추론비용(특히 비디오)이 병목이므로, 적은 수의 대표적 토큰만 선택해 추론을 가속화하고자 함. 관찰: 부분 토큰의 커버리지와 분할 성능이 강하게 상관.

Method: k-center 알고리즘을 기반으로 공간 정보를 통합해 토큰의 공간적 대표성을 보장하는 토큰 프루닝 기법 EVTP-IV를 설계. 정보이론적 분석으로 방법 타당성 제시.

Result: 표준 IVS 벤치마크에서 비디오 작업 최대 5×, 이미지 작업 3.5× 가속을 달성. 전체 토큰의 20%만 사용해도 정확도 유사. 다양한 프루닝 비율에서 기존 방법 대비 일관되게 우수.

Conclusion: 공간적 커버리지를 고려한 간단한 토큰 선택 규칙만으로도 MLLM 기반 IVS의 추론 비용을 크게 절감하면서 성능을 유지할 수 있음.

Abstract: Instructed Visual Segmentation (IVS) tasks require segmenting objects in
images or videos based on natural language instructions. While recent
multimodal large language models (MLLMs) have achieved strong performance on
IVS, their inference cost remains a major bottleneck, particularly in video. We
empirically analyze visual token sampling in MLLMs and observe a strong
correlation between subset token coverage and segmentation performance. This
motivates our design of a simple and effective token pruning method that
selects a compact yet spatially representative subset of tokens to accelerate
inference. In this paper, we introduce a novel visual token pruning method for
IVS, called EVTP-IV, which builds upon the k-center by integrating spatial
information to ensure better coverage. We further provide an
information-theoretic analysis to support our design. Experiments on standard
IVS benchmarks show that our method achieves up to 5X speed-up on video tasks
and 3.5X on image tasks, while maintaining comparable accuracy using only 20%
of the tokens. Our method also consistently outperforms state-of-the-art
pruning baselines under varying pruning ratios.

</details>


### [16] [MOON: Generative MLLM-based Multimodal Representation Learning for E-commerce Product Understanding](https://arxiv.org/abs/2508.11999)
*Daoze Zhang,Zhanheng Nie,Jianyu Liu,Chenghan Fu,Wanxian Guan,Yuan Gao,Jun Song,Pengjie Wang,Jian Xu,Bo Zheng*

Main category: cs.CV

TL;DR: 저자들은 제품 이해를 위해 생성형 MLLM 기반 모델 MOON을 제안한다. MOON은 가이드된 MoE로 멀티모달·어스펙트 특화 표현을 학습하고, 이미지의 핵심 영역을 검출해 배경 노이즈를 제거하며, 난이도 높은 네거티브 샘플링을 도입한다. 또한 대규모 멀티모달 벤치마크 MBE를 공개한다. 실험에서 제로샷 설정을 포함한 다양한 다운스트림 태스크에서 경쟁력 있는 성능을 보였다.


<details>
  <summary>Details</summary>
Motivation: 기존의 판별적(dual-flow) 아키텍처는 다수의 이미지와 텍스트가 한 제품에 대응되는 many-to-one 정렬을 효과적으로 모델링하지 못함. 반면 생성형 MLLM은 일반화된 표현 학습에 잠재력이 있으나, LLM의 멀티모달·어스펙트 인식 부족, 제품 이미지의 배경 노이즈, 표준 평가 벤치마크 부재 등의 문제로 직접 적용하기 어려움.

Method: (1) 가이드된 Mixture-of-Experts(MoE) 모듈을 도입해 멀티모달 신호와 제품의 다양한 측면(aspects)을 목표 지향적으로 모델링;(2) 이미지에서 핵심 의미 영역을 탐지해 배경 간섭을 완화;(3) 샘플 난이도·다양성을 높이는 특수 네거티브 샘플링 전략을 설계. 또한 다양한 제품 이해 과제를 위한 대규모 멀티모달 벤치마크 MBE를 구축·공개함.

Result: MOON은 자체 MBE와 공개 데이터셋에서 제로샷 및 여러 다운스트림 과제(크로스모달 검색, 제품 분류, 속성 예측 등)에서 경쟁력 있는 성능을 보임. 사례 연구와 시각화로 제안 방법의 유효성을 제시.

Conclusion: 생성형 MLLM에 특화된 모듈(가이드 MoE, 핵심영역 검출, 강화된 네거티브 샘플링)을 추가하면 제품 표현 학습에서 강한 일반화 능력을 얻을 수 있으며, 공개된 MBE는 관련 연구의 표준화된 비교를 촉진함.

Abstract: With the rapid advancement of e-commerce, exploring general representations
rather than task-specific ones has attracted increasing research attention. For
product understanding, although existing discriminative dual-flow architectures
drive progress in this field, they inherently struggle to model the many-to-one
alignment between multiple images and texts of products. Therefore, we argue
that generative Multimodal Large Language Models (MLLMs) hold significant
potential for improving product representation learning. Nevertheless,
achieving this goal still remains non-trivial due to several key challenges:
the lack of multimodal and aspect-aware modeling modules in typical LLMs; the
common presence of background noise in product images; and the absence of a
standard benchmark for evaluation. To address these issues, we propose the
first generative MLLM-based model named MOON for product representation
learning. Our method (1) employs a guided Mixture-of-Experts (MoE) module for
targeted modeling of multimodal and aspect-specific product content; (2)
effectively detects core semantic regions in product images to mitigate the
distraction and interference caused by background noise; and (3) introduces the
specialized negative sampling strategy to increase the difficulty and diversity
of negative samples. In addition, we release a large-scale multimodal benchmark
MBE for various product understanding tasks. Experimentally, our model
demonstrates competitive zero-shot performance on both our benchmark and the
public dataset, showcasing strong generalization across various downstream
tasks, including cross-modal retrieval, product classification, and attribute
prediction. Furthermore, the case study and visualization illustrate the
effectiveness of MOON for product understanding.

</details>


### [17] [Large Kernel Modulation Network for Efficient Image Super-Resolution](https://arxiv.org/abs/2508.11893)
*Quanwei Hu,Yinggan Tang,Xuguang Zhang*

Main category: cs.CV

TL;DR: LKMN은 순수 CNN 기반의 경량 SR 모델로, 부분 큰 커널 스트립 합성곱과 채널 셔플·어텐션을 이용해 비지역 특성을 효율적으로 캡처하고, 교차 게이팅 FFN으로 입력·지역·비지역 특징을 동적으로 융합하여 SOTA 경량 모델보다 우수한 화질·지연 시간을 달성한다.


<details>
  <summary>Details</summary>
Motivation: 자원 제약 환경에서 SR은 성능(화질)과 지연(속도)의 균형이 필요하다. CNN은 낮은 지연을 제공하지만 비지역 정보를 잘 포착하지 못하고, Transformer는 비지역 모델링에 강하지만 추론이 느려 경량 SR에 적합하지 않다. 이를 해결하기 위해 비지역 표현을 효율적으로 처리하면서도 CNN의 속도를 유지하는 구조가 필요하다.

Method: LKMN 구조는 두 핵심 모듈로 구성된다. (1) Enhanced Partial Large Kernel Block (EPLKB): 채널 셔플로 채널 간 상호작용을 촉진하고, 채널 어텐션으로 핵심 정보에 집중하며, 일부 채널에만 큰 커널의 스트립(가로/세로) 합성곱을 적용해 비지역 특징을 저비용으로 추출한다. (2) Cross-Gate Feed-Forward Network (CGFN): 입력, 지역, 비지역 특징 사이의 차이를 학습 가능한 스케일링 인자로 조정한 뒤, 교차 게이트 전략으로 이들 특징을 조절·융합하여 상호보완성을 강화한다.

Result: 광범위한 실험에서 기존 경량 SR SOTA를 능가했다. 예: Manga109 데이터셋에서 4x 업스케일 시 LKMN-L은 DAT-light 대비 PSNR이 0.23 dB 향상되었고, 추론 속도는 약 4.8배 빠르다. 코드도 공개됨.

Conclusion: LKMN은 순수 CNN 기반으로 비지역 정보를 효율적으로 모델링하면서도 낮은 지연을 유지하여 자원 제약 SR에 적합한 실용적 대안이다.

Abstract: Image super-resolution (SR) in resource-constrained scenarios demands
lightweight models balancing performance and latency. Convolutional neural
networks (CNNs) offer low latency but lack non-local feature capture, while
Transformers excel at non-local modeling yet suffer slow inference. To address
this trade-off, we propose the Large Kernel Modulation Network (LKMN), a pure
CNN-based model. LKMN has two core components: Enhanced Partial Large Kernel
Block (EPLKB) and Cross-Gate Feed-Forward Network (CGFN). The EPLKB utilizes
channel shuffle to boost inter-channel interaction, incorporates channel
attention to focus on key information, and applies large kernel strip
convolutions on partial channels for non-local feature extraction with reduced
complexity. The CGFN dynamically adjusts discrepancies between input, local,
and non-local features via a learnable scaling factor, then employs a
cross-gate strategy to modulate and fuse these features, enhancing their
complementarity. Extensive experiments demonstrate that our method outperforms
existing state-of-the-art (SOTA) lightweight SR models while balancing quality
and efficiency. Specifically, LKMN-L achieves 0.23 dB PSNR improvement over
DAT-light on the Manga109 dataset at $\times$4 upscale, with nearly $\times$4.8
times faster. Codes are in the supplementary materials. The code is available
at https://github.com/Supereeeee/LKMN.

</details>


### [18] [A Sobel-Gradient MLP Baseline for Handwritten Character Recognition](https://arxiv.org/abs/2508.11902)
*Azam Nouri*

Main category: cs.CV

TL;DR: 손글씨 문자 인식에서 수평·수직 소벨 도함수(1차 엣지)만을 입력으로 사용하는 단순한 완전연결 MLP가 MNIST에서 98%, EMNIST Letters에서 92%의 성능을 내며 CNN에 근접한다.


<details>
  <summary>Details</summary>
Motivation: CNN 대신 메모리·해석성에서 이점이 있는 더 단순한 모델로 손글씨 인식이 가능한지, 그리고 1차 그래디언트(엣지) 정보가 분류에 충분한지를 확인하려는 목적.

Method: 이미지에 대해 수평/수직 소벨 필터로 도함수를 계산해 두 채널 입력으로 사용하고, 모든 층이 완전연결인 MLP를 MNIST·EMNIST Letters에 학습시킴. 입력은 픽셀값 대신 엣지 맵만 사용.

Result: 구성한 엣지-기반 MLP가 MNIST에서 약 98% 정확도, EMNIST Letters에서 약 92% 정확도를 달성. 모델은 CNN 대비 더 작은 메모리 요구와 직관적(엣지) 특징을 가짐.

Conclusion: 많은 손글씨 분류에 필요한 판별 정보가 1차 그래디언트에 이미 포함되어 있어, 엣지-기반 MLP가 실용적 대안이 될 수 있으나 더 복잡한 데이터·왜곡·잡음에 대한 일반화성 검증이 필요하다.

Abstract: We revisit the classical Sobel operator to ask a simple question: Are
first-order edge maps sufficient to drive an all-dense multilayer perceptron
(MLP) for handwritten character recognition (HCR), as an alternative to
convolutional neural networks (CNNs)? Using only horizontal and vertical Sobel
derivatives as input, we train an MLP on MNIST and EMNIST Letters. Despite its
extreme simplicity, the resulting network reaches 98% accuracy on MNIST digits
and 92% on EMNIST letters -- approaching CNNs while offering a smaller memory
footprint and transparent features. Our findings highlight that much of the
class-discriminative information in handwritten character images is already
captured by first-order gradients, making edge-aware MLPs a compelling option
for HCR.

</details>


### [19] [OVG-HQ: Online Video Grounding with Hybrid-modal Queries](https://arxiv.org/abs/2508.11903)
*Runhao Zeng,Jiaqi Mao,Minghao Lai,Minh Hieu Phan,Yanjie Dong,Wei Wang,Qi Chen,Xiping Hu*

Main category: cs.CV

TL;DR: 이 논문은 스트리밍(온라인) 환경과 텍스트·이미지·비디오 등 혼합 모달리티 쿼리를 다루는 새로운 과제(OVG-HQ)를 제안한다. 제약된 문맥과 훈련 시 모달리티 불균형 문제를 해결하기 위해 Parametric Memory Block(PMB)과 교차-모달 지식 증류를 결합한 단일 모델(OVG-HQ-Unify)을 제시하고, 다중모달 쿼리를 포함한 QVHighlights-Unify 데이터셋과 온라인용 평가 지표(oR@n, IoU=m, omAP)를 만든다. 실험에서 제안방법이 기존 방법들을 능가한다.


<details>
  <summary>Details</summary>
Motivation: 기존 비디오 그라운딩은 오프라인·텍스트 쿼리에 초점을 맞춰 스트리밍 환경(한정된 문맥)이나 시각적 쿼리(이미지/비디오 클립)를 제대로 처리하지 못한다. 이런 현실적 시나리오를 반영하기 위해 온라인·하이브리드 모달 쿼리를 처리하는 체계가 필요하다.

Method: OVG-HQ-Unify라는 단일 프레임워크를 제안한다. 핵심 구성은(1) 이전 지식을 보존·활용하는 Parametric Memory Block(PMB)으로 온라인 상황에서 제한된 문맥을 보완하고(2) 우세한 모달리티가 약한 모달리티를 압도하지 않도록 교차-모달 지식 증류(cross-modal distillation)를 통해 비우세 모달의 학습을 유도한다. 또한 QVHighlights-Unify 데이터셋을 구성하고 온라인 상황을 반영한 평가 지표들을 설계했다.

Result: 제안한 모델이 기존 방법들보다 전반적인 성능(정확도·온라인 적시성 지표 포함)에서 우수하다는 실험 결과를 보고한다. 공개 코드와 데이터셋을 배포한다.

Conclusion: 온라인 환경과 혼합 모달 쿼리 문제에 대해 통합적이고 실용적인 해결책을 제시하며, 새로운 데이터·지표를 통해 연구를 활성화할 수 있는 기여를 한다.

Abstract: Video grounding (VG) task focuses on locating specific moments in a video
based on a query, usually in text form. However, traditional VG struggles with
some scenarios like streaming video or queries using visual cues. To fill this
gap, we present a new task named Online Video Grounding with Hybrid-modal
Queries (OVG-HQ), which enables online segment localization using text, images,
video segments, and their combinations. This task poses two new challenges:
limited context in online settings and modality imbalance during training,
where dominant modalities overshadow weaker ones. To address these, we propose
OVG-HQ-Unify, a unified framework featuring a Parametric Memory Block (PMB)
that retain previously learned knowledge to enhance current decision and a
cross-modal distillation strategy that guides the learning of non-dominant
modalities. This design enables a single model to effectively handle
hybrid-modal queries. Due to the lack of suitable datasets, we construct
QVHighlights-Unify, an expanded dataset with multi-modal queries. Besides,
since offline metrics overlook prediction timeliness, we adapt them to the
online setting, introducing oR@n, IoU=m, and online mean Average Precision
(omAP) to evaluate both accuracy and efficiency. Experiments show that our
OVG-HQ-Unify outperforms existing models, offering a robust solution for
online, hybrid-modal video grounding. Source code and datasets are available at
https://github.com/maojiaqi2324/OVG-HQ.

</details>


### [20] [SafeCtrl: Region-Based Safety Control for Text-to-Image Diffusion via Detect-Then-Suppress](https://arxiv.org/abs/2508.11904)
*Lingyun Zhang,Yu Xie,Yanwei Fu,Ping Chen*

Main category: cs.CV

TL;DR: SafeCtrl: region-localizer + suppression module for text-to-image safety. It localizes unsafe regions and suppresses harmful semantics (not hard replacement), trained with Direct Preference Optimization on image-level preference data to enable region-guided interventions without pixel labels. Improves safety and fidelity over prior methods.


<details>
  <summary>Details</summary>
Motivation: Existing safety methods (prompt rewrite, fine-tuning) trade off image fidelity; localization-based replacements cause semantic incongruities. Need a flexible, non-intrusive control that preserves context and visual quality.

Method: Introduce a lightweight plugin that first localizes unsafe content, then suppresses harmful semantics instead of replacing concepts. Train suppression behavior using Direct Preference Optimization (DPO) with image-level preference labels, enabling nuanced, region-guided interventions without pixel-level supervision.

Result: Extensive experiments show SafeCtrl outperforms state-of-the-art in both safety efficacy and fidelity preservation. Demonstrates coherent, context-aware safe alternatives and scalability of the suppression paradigm.

Conclusion: Decoupled detect-and-suppress control is an effective, scalable approach for responsible generative models; DPO on weak preference data enables practical training without expensive annotations.

Abstract: The widespread deployment of text-to-image models is challenged by their
potential to generate harmful content. While existing safety methods, such as
prompt rewriting or model fine-tuning, provide valuable interventions, they
often introduce a trade-off between safety and fidelity. Recent
localization-based approaches have shown promise, yet their reliance on
explicit ``concept replacement" can sometimes lead to semantic incongruity. To
address these limitations, we explore a more flexible detect-then-suppress
paradigm. We introduce SafeCtrl, a lightweight, non-intrusive plugin that first
precisely localizes unsafe content. Instead of performing a hard A-to-B
substitution, SafeCtrl then suppresses the harmful semantics, allowing the
generative process to naturally and coherently resolve into a safe,
context-aware alternative. A key aspect of our work is a novel training
strategy using Direct Preference Optimization (DPO). We leverage readily
available, image-level preference data to train our module, enabling it to
learn nuanced suppression behaviors and perform region-guided interventions at
inference without requiring costly, pixel-level annotations. Extensive
experiments show that SafeCtrl significantly outperforms state-of-the-art
methods in both safety efficacy and fidelity preservation. Our findings suggest
that decoupled, suppression-based control is a highly effective and scalable
direction for building more responsible generative models.

</details>


### [21] [TimeSenCLIP: A Vision-Language Model for Remote Sensing Using Single-Pixel Time Series](https://arxiv.org/abs/2508.11919)
*Pallavi Jain,Diego Marcos,Dino Ienco,Roberto Interdonato,Tristan Berchoux*

Main category: cs.CV

TL;DR: TimeSenCLIP는 한 픽셀의 시공간(스펙트럼+시간) 정보를 이용하고 지상 사진과의 교차-뷰 학습을 통해 대형 타일과 텍스트 주석 의존성을 줄이면서 LULC·농작물·생태계 분류를 수행하는 경량 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 대형 공간 타일 사용으로 인한 계산 비용과 텍스트 기반 감독(캡션) 의존성 문제를 해결하고, 단일 픽셀의 시공간 정보를 통해 의미적 정렬을 유지하면서 확장 가능한 주제 지도화 방법을 제시하기 위함.

Method: Sentinel-2의 시계열과 스펙트럼 밴드를 단일 픽셀 입력으로 사용하고, 지오태그된 지상 사진(크로스-뷰)을 통해 캡션 없이도 위성-지상 뷰의 시맨틱 정렬을 학습하는 경량 모델(TimeSenCLIP)을 설계·학습. LUCAS와 Sen4Map 데이터셋을 활용해 LULC·작물·생태계 분류를 평가.

Result: 단일 픽셀 기반 입력에 시간·스펙트럼 정보를 결합하면 주제 지도화에 충분한 성능을 보이며, 타일 기반 접근보다 계산·확장성 측면에서 효율적임을 보고함(정확도·비교실험 상세 수치는 초록에 없음).

Conclusion: 공간 컨텍스트를 최소화하고 시공간 신호와 크로스-뷰 학습을 활용하면 캡션 의존성을 낮춘 효과적인 LULC 분류가 가능하며, 대규모 원격탐사 응용에서 확장 가능한 대안이 될 수 있다.

Abstract: Vision-language models have shown significant promise in remote sensing
applications, particularly for land-use and land-cover (LULC) via zero-shot
classification and retrieval. However, current approaches face two key
challenges: reliance on large spatial tiles that increase computational cost,
and dependence on text-based supervision, which is often not readily available.
In this work, we present TimeSenCLIP, a lightweight framework that reevaluate
the role of spatial context by evaluating the effectiveness of a single pixel
by leveraging its temporal and spectral dimensions, for classifying LULC and
ecosystem types. By leveraging spectral and temporal information from
Sentinel-2 imagery and cross-view learning with geo-tagged ground-level photos,
we minimises the need for caption-based training while preserving semantic
alignment between overhead (satellite) and ground perspectives. Our approach is
grounded in the LUCAS and Sen4Map datasets, and evaluated on classification
tasks including LULC, crop type, and ecosystem type. We demonstrate that single
pixel inputs, when combined with temporal and spectral cues, are sufficient for
thematic mapping, offering a scalable and efficient alternative for large-scale
remote sensing applications. Code is available at
https://github.com/pallavijain-pj/TimeSenCLIP

</details>


### [22] [Assessment of Using Synthetic Data in Brain Tumor Segmentation](https://arxiv.org/abs/2508.11922)
*Aditi Jahagirdar,Sameer Joshi*

Main category: cs.CV

TL;DR: GAN으로 생성한 합성 MRI를 medigan으로 사용해 U-Net 학습에 포함시킨 실험에서, 정량 지표는 실데이터만 사용한 경우와 대체로 유사하지만(전체 Dice/IoU/정밀도 등), 40% 실 + 60% 합성 조합에서 전체 종양 경계의 질적 개선이 관찰됨. 핵심(코어)·강화된 종양 영역에서는 여전히 낮은 정확도를 보이며 클래스 불균형 문제가 잔존함.


<details>
  <summary>Details</summary>
Motivation: 뇌종양 MRI의 수작업 분할은 종양 이질성, 주석 데이터 부족, 클래스 불균형 때문에 어렵다. 합성 데이터는 데이터 다양성 확대와 불충분한 표본 문제를 완화할 수 있는 잠재력이 있어 이를 검증하려 함.

Method: BraTS 2020의 실데이터와 medigan으로 생성한 합성 MRI를 사용. U-Net을 실전용, 합성전용, 다양한 혼합비(실:합성)를 가진 하이브리드 데이터로 학습. Dice, IoU, precision, recall, accuracy 등 정량평가와 질적 경계 관찰을 수행.

Result: 정량지표는 실전용과 하이브리드가 대체로 비슷함. 질적 검사에서는 40% 실 + 60% 합성이 전체 종양 경계선을 더 잘 잡는 경향을 보였음. 그러나 종양 코어와 강화 병변의 영역별 성능은 낮아 클래스 불균형이 지속됨.

Conclusion: 합성 데이터는 뇌종양 분할을 위한 데이터 증강 전략으로 실현 가능성이 있으나, 더 큰 규모의 실험, 체적(3D) 일관성 확보, 클래스 불균형 완화 등의 후속 작업이 필요함.

Abstract: Manual brain tumor segmentation from MRI scans is challenging due to tumor
heterogeneity, scarcity of annotated data, and class imbalance in medical
imaging datasets. Synthetic data generated by generative models has the
potential to mitigate these issues by improving dataset diversity. This study
investigates, as a proof of concept, the impact of incorporating synthetic MRI
data, generated using a pre-trained GAN model, into training a U-Net
segmentation network. Experiments were conducted using real data from the BraTS
2020 dataset, synthetic data generated with the medigan library, and hybrid
datasets combining real and synthetic samples in varying proportions. While
overall quantitative performance (Dice coefficient, IoU, precision, recall,
accuracy) was comparable between real-only and hybrid-trained models,
qualitative inspection suggested that hybrid datasets, particularly with 40%
real and 60% synthetic data, improved whole tumor boundary delineation.
However, region-wise accuracy for the tumor core and the enhancing tumor
remained lower, indicating a persistent class imbalance. The findings support
the feasibility of synthetic data as an augmentation strategy for brain tumor
segmentation, while highlighting the need for larger-scale experiments,
volumetric data consistency, and mitigating class imbalance in future work.

</details>


### [23] [Deep Learning For Point Cloud Denoising: A Survey](https://arxiv.org/abs/2508.11932)
*Chengwei Zhang,Xueyi Zhang,Mingrui Lao,Tao Jiang,Xinhao Xu,Wenjie Li,Fubo Zhang,Longyong Chen*

Main category: cs.CV

TL;DR: 이 논문은 딥러닝 기반 포인트 클라우드 노이즈 제거(DL-PCD) 연구를 체계적으로 정리한 설문(survey) 논문이다. 핵심은 PCD를 이상치 제거(outlier removal)와 표면 노이즈 복원(surface noise restoration)의 두 단계로 정식화하고, 기존 방법들을 분류·비교하며 향후 연구 방향을 제시하는 것이다.


<details>
  <summary>Details</summary>
Motivation: 실세계 포인트 클라우드는 다양한 강도와 형태의 노이즈를 포함하며, PCD는 다운스트림 3D 과제 성능 향상을 위해 필수적이다. 기존 딥러닝 기반 방법들이 성능을 크게 향상시켰지만, 이 분야를 체계적으로 정리한 종합적인 설문이 부족하다는 문제 인식에서 출발한다.

Method: 문헌 조사와 분석을 통해 DL 기반 PCD 방법들을 분류(taxonomy)하고, PCD 과제를 이상치 제거와 표면 노이즈 복원의 두 단계로 모델화한다. 각 방법의 유사점·차이점·장단점을 비교하고 정리한다.

Result: 기존 방법들의 핵심 아이디어와 분류 체계가 제시되며, 방법 간 비교를 통해 어떤 접근이 어떤 상황에 유리한지 통찰을 제공한다. 또한 현재 연구의 한계와 향후 연구 방향들을 도출한다.

Conclusion: 이 설문은 DL 기반 PCD 연구를 체계화하여 연구자들이 분야의 발전 흐름을 빠르게 파악하고, 향후 연구 주제(예: 현실 노이즈 모델링, 라벨 없는 학습, 효율성 향상 등)를 모색하는 데 실용적 가이드를 제공한다.

Abstract: Real-world environment-derived point clouds invariably exhibit noise across
varying modalities and intensities. Hence, point cloud denoising (PCD) is
essential as a preprocessing step to improve downstream task performance. Deep
learning (DL)-based PCD models, known for their strong representation
capabilities and flexible architectures, have surpassed traditional methods in
denoising performance. To our best knowledge, despite recent advances in
performance, no comprehensive survey systematically summarizes the developments
of DL-based PCD. To fill the gap, this paper seeks to identify key challenges
in DL-based PCD, summarizes the main contributions of existing methods, and
proposes a taxonomy tailored to denoising tasks. To achieve this goal, we
formulate PCD as a two-step process: outlier removal and surface noise
restoration, encompassing most scenarios and requirements of PCD. Additionally,
we compare methods in terms of similarities, differences, and respective
advantages. Finally, we discuss research limitations and future directions,
offering insights for further advancements in PCD.

</details>


### [24] [DynamicPose: Real-time and Robust 6D Object Pose Tracking for Fast-Moving Cameras and Objects](https://arxiv.org/abs/2508.11950)
*Tingbang Liang,Yixin Zeng,Jiatong Xie,Boyu Zhou*

Main category: cs.CV

TL;DR: DynamicPose는 재학습 없이 빠르게 움직이는 카메라와 객체 환경에서 강인한 실시간 6D 포즈 추적을 달성하는 프레임워크다. VIO, 깊이 기반 2D 트래커, VIO-유도 칼만 필터의 결합으로 ROI 이동과 객체 대이동을 보정하고 계층적 정제를 통해 최종 포즈를 결정한다.


<details>
  <summary>Details</summary>
Motivation: 기존 방법들은 정적 또는 준정적 장면에 맞춰져 있어 카메라와 객체가 동시에 빠르게 움직이면 ROI가 크게 벗어나고 추적·추정 성능이 급격히 저하된다. 이러한 빠른 운동 상황에서도 초기화 정확도와 추적 안정성을 유지할 필요가 있다.

Method: 세 가지 상호보완적 컴포넌트를 제안한다: (1) 카메라 움직임으로 인한 ROI 이동을 보정하는 비주얼-관성(VIO) 오도메트리; (2) 큰 객체 병진으로 인한 ROI 편차를 보정하는 깊이 정보 기반 2D 트래커; (3) VIO가 유도하는 칼만 필터로 객체 회전을 예측하고 다수의 후보 포즈를 생성한 뒤 계층적 정제를 통해 최종 포즈를 선택한다. 6D 포즈 결과는 2D 트래킹과 칼만 필터 업데이트에 피드백되어 폐루프를 이룬다.

Result: 시뮬레이션 및 실세계 실험에서 실시간으로 동작하며 빠르게 움직이는 카메라와 객체 상황에서 향상된 추적 강인성을 보였다.

Conclusion: 재학습이 필요 없는 폐루프 설계로 VIO와 깊이 정보, 칼만 기반 예측을 결합하면 급격한 카메라·물체 운동에서도 정확한 초기화와 정밀한 6D 포즈 추적이 가능하다.

Abstract: We present DynamicPose, a retraining-free 6D pose tracking framework that
improves tracking robustness in fast-moving camera and object scenarios.
Previous work is mainly applicable to static or quasi-static scenes, and its
performance significantly deteriorates when both the object and the camera move
rapidly. To overcome these challenges, we propose three synergistic components:
(1) A visual-inertial odometry compensates for the shift in the Region of
Interest (ROI) caused by camera motion; (2) A depth-informed 2D tracker
corrects ROI deviations caused by large object translation; (3) A VIO-guided
Kalman filter predicts object rotation, generates multiple candidate poses, and
then obtains the final pose by hierarchical refinement. The 6D pose tracking
results guide subsequent 2D tracking and Kalman filter updates, forming a
closed-loop system that ensures accurate pose initialization and precise pose
tracking. Simulation and real-world experiments demonstrate the effectiveness
of our method, achieving real-time and robust 6D pose tracking for fast-moving
cameras and objects.

</details>


### [25] [Transferable Class Statistics and Multi-scale Feature Approximation for 3D Object Detection](https://arxiv.org/abs/2508.11951)
*Hao Peng,Hong Sang,Yajing Ma,Ping Qiu,Chao Ji*

Main category: cs.CV

TL;DR: 이 논문은 단일 이웃(neighborhood) 기반으로 지식증류를 통해 다중 스케일 특징을 근사하고, 클래스-인지 통계 기반의 전달가능한 특징 임베딩과 중심 가중치 IoU로 경계박스 정렬 문제를 완화하여 연산비용을 줄이면서 포인트클라우드 객체검출 성능을 유지/향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 다중 스케일 특징은 포인트클라우드 객체검출에서 중요하나, 일반적 학습은 여러 이웃 탐색과 스케일-특이 레이어를 요구해 경량 모델 설계와 계산 자원 제약 환경에서 실용적이지 않다. 따라서 단일 이웃에서 다중 스케일 특성을 근사하고 계산을 절감하려는 동기가 있다.

Method: 다중 스케일 교사 모델로부터 지식증류를 통해 단일 이웃 특징에서 다중 스케일 특징을 근사하도록 학습한다. 감소된 구조적 다양성을 보완하기 위해 클래스-인지 통계(예: 클래스별 통계치)를 전달가능한 특징으로 설계하여 임베딩에 사용한다. 위치 최적화에서 중심 오프셋으로 인한 불일치를 줄이기 위해 중앙 가중치 IoU(central weighted IoU)를 도입한다.

Result: 공개 데이터셋에서 실험하여 제안한 방법이 계산비용을 절감하면서도 성능을 유지하거나 향상함을 보였다고 보고한다(구체적 수치·비교 대상은 초록에 없음).

Conclusion: 제안 기법은 단일 이웃 기반의 경량화된 포인트클라우드 검출기에서 다중 스케일 정보를 효과적으로 근사하고, 클래스-인지 전달특징 및 중앙 가중치 IoU로 성능 저하 없이 효율을 개선할 수 있음을 시사한다.

Abstract: This paper investigates multi-scale feature approximation and transferable
features for object detection from point clouds. Multi-scale features are
critical for object detection from point clouds. However, multi-scale feature
learning usually involves multiple neighborhood searches and scale-aware
layers, which can hinder efforts to achieve lightweight models and may not be
conducive to research constrained by limited computational resources. This
paper approximates point-based multi-scale features from a single neighborhood
based on knowledge distillation. To compensate for the loss of constructive
diversity in a single neighborhood, this paper designs a transferable feature
embedding mechanism. Specifically, class-aware statistics are employed as
transferable features given the small computational cost. In addition, this
paper introduces the central weighted intersection over union for localization
to alleviate the misalignment brought by the center offset in optimization.
Note that the method presented in this paper saves computational costs.
Extensive experiments on public datasets demonstrate the effectiveness of the
proposed method.

</details>


### [26] [UniUGG: Unified 3D Understanding and Generation via Geometric-Semantic Encoding](https://arxiv.org/abs/2508.11952)
*Yueming Xu,Jiahui Zhang,Ze Huang,Yurui Chen,Yanpeng Zhou,Zhenyu Chen,Yu-Jie Yuan,Pengxiang Xia,Guowei Huang,Xinyue Cai,Zhongang Qi,Xingyue Quan,Jianye Hao,Hang Xu,Li Zhang*

Main category: cs.CV

TL;DR: UniUGG는 LLM과 잠재 확산 기반의 공간 디코더를 결합해 3D 이해와 생성을 통합한 최초의 프레임워크를 제안한다. 레퍼런스 이미지와 임의 뷰 변환으로 3D 장면을 생성하고 공간 VQA를 지원하며, 기하-시맨틱 프리트레이닝으로 비전 인코더를 강화한다.


<details>
  <summary>Details</summary>
Motivation: 최근 통합 아키텍처가 이미지 이해·생성에서 성과를 냈지만 3D 작업 통합은 미흡하다. 3D 이해·생성 태스크를 하나의 프레임워크로 통합해 활용성과 일반화를 높이고자 함.

Method: (1) LLM을 사용해 문장과 3D 표현을 해석·디코딩. (2) 잠재 확산 모델 기반의 공간 디코더로 고품질 3D 표현 생성. (3) 레퍼런스 이미지 + 임의 뷰 변환으로 3D 장면 생성 및 공간 VQA 지원. (4) 기하-시맨틱 학습 전략으로 비전 인코더를 사전학습해 기하학·시맨틱 신호를 동시에 캡처.

Result: 광범위한 실험에서 시각 표현, 공간 이해, 3D 생성 성능이 우수하다고 보고. 정량·정성 실험으로 주장하는 우수성 입증(세부 메트릭·비교 baseline은 본문 필요).

Conclusion: LLM과 잠재 확산 기반 공간 디코더, 기하-시맨틱 프리트레이닝의 조합으로 3D 이해·생성의 통합적 접근을 제시. 코드 공개 예정.

Abstract: Despite the impressive progress on understanding and generating images shown
by the recent unified architectures, the integration of 3D tasks remains
challenging and largely unexplored. In this paper, we introduce UniUGG, the
first unified understanding and generation framework for 3D modalities. Our
unified framework employs an LLM to comprehend and decode sentences and 3D
representations. At its core, we propose a spatial decoder leveraging a latent
diffusion model to generate high-quality 3D representations. This allows for
the generation and imagination of 3D scenes based on a reference image and an
arbitrary view transformation, while remaining supports for spatial visual
question answering (VQA) tasks. Additionally, we propose a geometric-semantic
learning strategy to pretrain the vision encoder. This design jointly captures
the input's semantic and geometric cues, enhancing both spatial understanding
and generation. Extensive experimental results demonstrate the superiority of
our method in visual representation, spatial understanding, and 3D generation.
The source code will be released upon paper acceptance.

</details>


### [27] [SAMDWICH: Moment-aware Video-text Alignment for Referring Video Object Segmentation](https://arxiv.org/abs/2508.11955)
*Seunghun Lee,Jiwan Seo,Jeonghoon Kim,Siwon Kim,Haeun Yun,Hyogyeong Jeon,Wonhyeok Choi,Jaehoon Jeong,Zane Durante,Sang Hyun Park,Sunghoon Im*

Main category: cs.CV

TL;DR: SAMDWICH는 언어-비디오 정렬을 개선하기 위해 객체가 언급되는 시간 구간(모멘트)을 수작업으로 주석한 MeViS-M 데이터셋과, 모멘트 인식 기반 학습(모멘트 유도 이중 경로 전파 MDP) 및 객체 수준 선택적 감독(OSS)을 결합한 프레임워크다. 관련 프레임만 감독하고 비관련 프레임을 별도 메모리 경로로 학습해 의미적 잡음을 줄이며 MeViS에서 SOTA 성능을 달성한다.


<details>
  <summary>Details</summary>
Motivation: 기존 RVOS 방법들은 무차별적 프레임 샘플링과 모든 보이는 객체에 대한 일괄적 감독 때문에 텍스트-비디오 의미적 불일치(semantic misalignment)가 발생한다. 표현이 실제로 참조하는 객체와 시점에 대한 정보 부족이 주요 원인이다.

Method: (1) MeViS 기반의 MeViS-M: 각 표현이 참조되는 시간적 모멘트를 수동 주석. (2) SAMDWICH 프레임워크: 텍스트-클립 정렬을 이용한 모멘트 인식 기반 학습. (3) Moment-guided Dual-path Propagation(MDP): 모멘트 내/외 프레임을 분리해 모멘트 중심 메모리로 양쪽을 학습, 객체 위치화 및 추적 개선. (4) Object-level Selective Supervision(OSS): 각 학습 클립에서 표현과 시간적으로 정렬된 객체만 선택적으로 감독하여 의미적 노이즈 감소.

Result: 제안 방법은 MeViS 벤치마크에서 SOTA 성능을 보고하며, 특히 복잡한 표현과 다양한 시나리오에서 우수한 참조 이해도를 보인다. 모멘트 기반 감독은 정렬과 추적 성능을 유의미하게 향상시킨다.

Conclusion: 시간적 모멘트에 기반한 선택적 감독과 이중 경로 전파는 RVOS의 텍스트-비디오 정렬 문제를 효과적으로 완화한다. 다만 데이터셋 주석 비용, 일반화성, 모멘트 경계의 민감도 등은 후속 검증이 필요하다.

Abstract: Referring Video Object Segmentation (RVOS) aims to segment and track objects
in videos based on natural language expressions, requiring precise alignment
between visual content and textual queries. However, existing methods often
suffer from semantic misalignment, largely due to indiscriminate frame sampling
and supervision of all visible objects during training -- regardless of their
actual relevance to the expression. To address this, we introduce a
moment-aware RVOS framework named SAMDWICH, along with a newly annotated
dataset, MeViS-M, built upon the challenging MeViS benchmark. We manually
annotate temporal moments indicating when each object is referred to by the
expression, enabling semantically grounded supervision that strengthens
video-text alignment. SAMDWICH leverages these aligned text-to-clip pairs to
guide training, significantly enhancing referential understanding. Building
upon this framework, we propose Moment-guided Dual-path Propagation (MDP), a
moment-aware propagation strategy that improves both object grounding and
tracking by training on both relevant and irrelevant frames through a
moment-centric memory mechanism. In addition, we introduce Object-level
Selective Supervision (OSS), an object-level filtering strategy that supervises
only the objects temporally aligned with the expression in each training clip.
This selective supervision reduces semantic noise and reinforces
language-conditioned learning. Extensive experiments show that SAMDWICH
achieves state-of-the-art performance on challenging MeViS benchmark,
particularly excelling in complex scenarios involving diverse expressions.

</details>


### [28] [PEdger++: Practical Edge Detection via Assembling Cross Information](https://arxiv.org/abs/2508.11961)
*Yuanbin Fu,Liang Li,Xiaojie Guo*

Main category: cs.CV

TL;DR: PEdger++는 이종 아키텍처, 다양한 학습 시점, 여러 파라미터 샘플링에서 얻은 교차 정보를 협업 학습으로 통합해 경계선 검출의 정확도를 높이면서 모델 크기와 연산량을 줄이는 프레임워크다. 다양한 연산 예산에 맞춘 여러 버전을 제공하며 BSDS500, NYUD, Multicue에서 기존 방법 대비 성능 향상을 보였다.


<details>
  <summary>Details</summary>
Motivation: 엣지 검출은 많은 비전 과제의 기초지만 고정밀 딥 모델은 연산 비용이 크고 자원 제한 환경에 적용하기 어렵다. 따라서 큰 모델에 의존하지 않고 판별력 있는 특징을 효율적으로 얻는 방법이 필요하다.

Method: PEdger++는 서로 다른 아키텍처(heterogeneous), 학습 시점(snapshot들), 파라미터 샘플링으로부터의 교차-정보를 활용하는 협업 학습(framework)을 제안한다. 이러한 앙상블 관점의 정보 교환으로 경계선 검출기들을 함께 학습시켜 경계 예측 성능을 향상시키고, 경량화 버전들을 제공해 다양한 자원 제약에 적응한다.

Result: BSDS500, NYUD, Multicue 데이터셋에서 정량적·정성적으로 기존 방법들보다 우수한 성능을 보고하며, 계산량과 모델 크기 측면에서도 효율성을 보였다. 코드와 여러 모델 버전을 공개했다.

Conclusion: 교차-정보 기반 협업 학습은 대형 모델에 의존하지 않고도 엣지 검출 성능을 개선할 수 있으며, PEdger++는 정확도와 연산 효율성의 균형을 달성해 다양한 디바이스 제약에 적합한 실용적인 솔루션임을 제시한다.

Abstract: Edge detection serves as a critical foundation for numerous computer vision
applications, including object detection, semantic segmentation, and image
editing, by extracting essential structural cues that define object boundaries
and salient edges. To be viable for broad deployment across devices with
varying computational capacities, edge detectors shall balance high accuracy
with low computational complexity. While deep learning has evidently improved
accuracy, they often suffer from high computational costs, limiting their
applicability on resource-constrained devices. This paper addresses the
challenge of achieving that balance: \textit{i.e.}, {how to efficiently capture
discriminative features without relying on large-size and sophisticated
models}. We propose PEdger++, a collaborative learning framework designed to
reduce computational costs and model sizes while improving edge detection
accuracy. The core principle of our PEdger++ is that cross-information derived
from heterogeneous architectures, diverse training moments, and multiple
parameter samplings, is beneficial to enhance learning from an ensemble
perspective. Extensive experimental results on the BSDS500, NYUD and Multicue
datasets demonstrate the effectiveness of our approach, both quantitatively and
qualitatively, showing clear improvements over existing methods. We also
provide multiple versions of the model with varying computational requirements,
highlighting PEdger++'s adaptability with respect to different resource
constraints. Codes are accessible at
https://github.com/ForawardStar/EdgeDetectionviaPEdgerPlus/.

</details>


### [29] [Exploring Spatial-Temporal Dynamics in Event-based Facial Micro-Expression Analysis](https://arxiv.org/abs/2508.11988)
*Nicolas Mastropasqua,Ignacio Bugueno-Cordova,Rodrigo Verschae,Daniel Acevedo,Pablo Negri,Maria E. Buemi*

Main category: cs.CV

TL;DR: 이 작업은 RGB와 이벤트 카메라를 동기화해 가변 조명에서 미세표정(액션 유닛)을 기록한 다중 해상도·다중 모달 데이터셋을 제안하고, 이벤트 기반 입력의 효과를 평가하기 위해 액션 유닛 분류(스파이킹 신경망)와 프레임 재구성(조건부 변분 오토인코더)의 두 가지 베이스라인을 제시합니다. 이벤트 입력이 RGB보다 우수한 성능을 보였습니다.


<details>
  <summary>Details</summary>
Motivation: RGB 카메라만으로는 미세하고 빠른 얼굴 움직임을 정확히 포착하기 어렵고, 모션 블러·저조도·시간 해상도의 한계가 있음. 이벤트 카메라는 마이크로초 수준의 시간 정밀도와 넓은 동적 범위, 저지연을 제공하므로 미세표정 분석에 유망하다고 보고 이를 검증할 필요가 있음.

Method: 동기화된 RGB 및 이벤트 카메라로 다양한 조명 조건에서 다중 해상도 미세표정 데이터를 수집하여 공개 데이터셋을 구성. 베이스라인으로 (1) 스파이킹 신경망을 이용한 액션 유닛 분류, (2) 조건부 변분 오토인코더(CVAE)를 이용한 이벤트→프레임 재구성을 수행하고 성능 지표(정확도, SSIM, PSNR)를 보고.

Result: 액션 유닛 분류: 이벤트 입력으로 SNN이 51.23% 정확도, RGB는 23.12%로 이벤트가 크게 우수. 프레임 재구성: 고해상도 이벤트 입력으로 CVAE가 SSIM=0.8513, PSNR=26.89 dB를 달성. 이벤트 기반 데이터가 미세표정 인식 및 프레임 복원에 유용함을 시사.

Conclusion: 제안한 데이터셋과 초기 실험은 이벤트 카메라가 미세표정 분석에 유리하다는 가능성을 보여줌. 다만 데이터셋이 예비적이며 확장·검증·비교 실험이 필요함.

Abstract: Micro-expression analysis has applications in domains such as Human-Robot
Interaction and Driver Monitoring Systems. Accurately capturing subtle and fast
facial movements remains difficult when relying solely on RGB cameras, due to
limitations in temporal resolution and sensitivity to motion blur. Event
cameras offer an alternative, with microsecond-level precision, high dynamic
range, and low latency. However, public datasets featuring event-based
recordings of Action Units are still scarce. In this work, we introduce a
novel, preliminary multi-resolution and multi-modal micro-expression dataset
recorded with synchronized RGB and event cameras under variable lighting
conditions. Two baseline tasks are evaluated to explore the spatial-temporal
dynamics of micro-expressions: Action Unit classification using Spiking Neural
Networks (51.23\% accuracy with events vs. 23.12\% with RGB), and frame
reconstruction using Conditional Variational Autoencoders, achieving SSIM =
0.8513 and PSNR = 26.89 dB with high-resolution event input. These promising
results show that event-based data can be used for micro-expression recognition
and frame reconstruction.

</details>


### [30] [InstDrive: Instance-Aware 3D Gaussian Splatting for Driving Scenes](https://arxiv.org/abs/2508.12015)
*Hongyuan Liu,Haochen Yu,Jianfei Jiang,Qiankun Liu,Jiansheng Chen,Huimin Ma*

Main category: cs.CV

TL;DR: 대시캠 영상에서 동적 주행 장면을 인스턴스 단위로 3D로 재구성하는 InstDrive 제안. SAM 마스크를 이용한 2D 대비 학습과 3D 레귤러라이제이션, 코드북으로 연속 특징을 이산 인스턴스 ID로 연결해 복잡한 전처리 없이 3D 인스턴스 분할을 달성.


<details>
  <summary>Details</summary>
Motivation: 기존 방법들은 배경 요소를 하나의 표현으로 통합해 인스턴스 수준 이해와 편집이 어렵고, 일부는 2D 세그멘테이션을 3D로 올리려 하지만 사전 처리된 인스턴스 ID나 복잡한 파이프라인에 의존하며 주로 실내 다중시점에 최적화되어 있어 야외 주행 장면에는 부적합함.

Method: InstDrive는 3D Gaussian Splatting 기반 프레임워크로, SAM에서 생성한 마스크를 의사 레이블로 사용해 2D 특징 학습을 대비 손실 및 의사-지도 목표로 유도함. 3D 수준에서는 인스턴스 정체성을 암묵적으로 인코딩하는 정규화와 복셀 기반 손실로 일관성을 강제하고, 경량 정적 코드북을 도입해 연속 특징과 이산 ID를 매핑하되 별도 전처리나 복잡한 최적화 불필요.

Result: 정량적·정성적 실험에서 동적 개방형 주행 장면에서의 3D 인스턴스 분할 성능과 재구성 품질이 향상됨을 보임. 저자 주장으로는 해당 도메인에서 최초로 3D 인스턴스 분할을 달성한 프레임워크.

Conclusion: SAM 기반 의사 레이블과 코드북·정규화 조합으로 복잡한 전처리 없이 야외 주행 장면의 인스턴스 단위 3D 재구성이 가능하며, 인스턴스 수준 이해와 편집이 용이해짐.

Abstract: Reconstructing dynamic driving scenes from dashcam videos has attracted
increasing attention due to its significance in autonomous driving and scene
understanding. While recent advances have made impressive progress, most
methods still unify all background elements into a single representation,
hindering both instance-level understanding and flexible scene editing. Some
approaches attempt to lift 2D segmentation into 3D space, but often rely on
pre-processed instance IDs or complex pipelines to map continuous features to
discrete identities. Moreover, these methods are typically designed for indoor
scenes with rich viewpoints, making them less applicable to outdoor driving
scenarios. In this paper, we present InstDrive, an instance-aware 3D Gaussian
Splatting framework tailored for the interactive reconstruction of dynamic
driving scene. We use masks generated by SAM as pseudo ground-truth to guide 2D
feature learning via contrastive loss and pseudo-supervised objectives. At the
3D level, we introduce regularization to implicitly encode instance identities
and enforce consistency through a voxel-based loss. A lightweight static
codebook further bridges continuous features and discrete identities without
requiring data pre-processing or complex optimization. Quantitative and
qualitative experiments demonstrate the effectiveness of InstDrive, and to the
best of our knowledge, it is the first framework to achieve 3D instance
segmentation in dynamic, open-world driving scenes.More visualizations are
available at our project page.

</details>


### [31] [WiseLVAM: A Novel Framework For Left Ventricle Automatic Measurements](https://arxiv.org/abs/2508.12023)
*Durgesh Kumar Singh,Qing Cao,Sarina Thomas,Ahcène Boubekki,Robert Jenssen,Michael Kampffmeyer*

Main category: cs.CV

TL;DR: LV 선형 치수를 B-모드에서 직접 예측하면 작은 점 이동도 측정 오류를 크게 키운다. 기존 반자동 EnLVAM은 임상의가 정의한 스캔라인(SL)에 제약을 둬 이를 해결했으나 완전 자동화는 아니었다. 본 논문은 약지도 학습 기반의 B-모드 랜드마크 검출로 LV 윤곽을 추정하고, LV 장축과 기저층을 추론해 SL을 자동 배치하는 컨투어-인지 SL 배치법을 제안한다. 이를 바탕으로 AMM 모드에서 자동으로 선형 치수를 측정하는 완전 자동·수동 조정 가능 프레임워크 WiseLVAM을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 임상 가이드라인은 mitral valve leaflet tips 수준의 기저층에서 LV 장축에 수직으로 SL을 맞춘 B-모드 선형 치수를 권고한다. 그러나 자동화된 직접 랜드마크 예측은 벽을 따라 작은 위치 오차가 측정에 큰 영향을 주어 임상적 신뢰도가 떨어진다. 가이드라인에 맞춘 안정적이고 완전 자동화된 측정 방법이 필요하다.

Method: 약지도 학습 기반 B-모드 랜드마크 검출기로 LV 윤곽을 추정하고, 윤곽으로부터 LV 장축과 기저층을 추론해 임상 지침을 모사하는 SL을 자동 배치한다. SL에 제약된 상태에서 Anatomical Motion Mode(AMM) 이미지를 생성·활용해 EnLVAM의 아이디어를 확장하여, 구조 인식(B-모드)과 운동 인식(AMM)을 결합한 WiseLVAM 프레임워크로 완전 자동 및 수동 조정 가능한 측정 파이프라인을 구현한다.

Result: 추상에서는 WiseLVAM이 구조-인지와 운동-인지의 결합으로 견고성과 정확도가 향상되어 임상적 적용 가능성이 있다고 주장한다. 다만 구체적 수치(정확도, 재현율, 비교 대상 성능 등)는 제시되지 않았다.

Conclusion: WiseLVAM은 임상 권고를 모사하는 자동 SL 배치와 AMM 기반 측정을 통합해 기존 반자동 접근의 한계를 극복하려는 실용적 솔루션이다. 그러나 정량적 평가와 다양한 데이터셋·임상 환경에서의 검증이 필요하다.

Abstract: Clinical guidelines recommend performing left ventricular (LV) linear
measurements in B-mode echocardiographic images at the basal level -- typically
at the mitral valve leaflet tips -- and aligned perpendicular to the LV long
axis along a virtual scanline (SL). However, most automated methods estimate
landmarks directly from B-mode images for the measurement task, where even
small shifts in predicted points along the LV walls can lead to significant
measurement errors, reducing their clinical reliability. A recent
semi-automatic method, EnLVAM, addresses this limitation by constraining
landmark prediction to a clinician-defined SL and training on generated
Anatomical Motion Mode (AMM) images to predict LV landmarks along the same. To
enable full automation, a contour-aware SL placement approach is proposed in
this work, in which the LV contour is estimated using a weakly supervised
B-mode landmark detector. SL placement is then performed by inferring the LV
long axis and the basal level-mimicking clinical guidelines. Building on this
foundation, we introduce \textit{WiseLVAM} -- a novel, fully automated yet
manually adaptable framework for automatically placing the SL and then
automatically performing the LV linear measurements in the AMM mode.
\textit{WiseLVAM} utilizes the structure-awareness from B-mode images and the
motion-awareness from AMM mode to enhance robustness and accuracy with the
potential to provide a practical solution for the routine clinical application.

</details>


### [32] [Q-FSRU: Quantum-Augmented Frequency-Spectral Fusion for Medical Visual Question Answering](https://arxiv.org/abs/2508.12036)
*Rakesh Thakur,Yusra Tariq*

Main category: cs.CV

TL;DR: Q-FSRU는 FFT 기반 주파수 표현(FSRU)과 '양자 영감' 검색(Quantum RAG)을 결합한 의료 VQA 모델로, VQA-RAD에서 기존 모델보다 나은 성능과 설명가능성 향상을 보고함.


<details>
  <summary>Details</summary>
Motivation: 의료 영상과 텍스트를 더 효과적으로 융합하고 외부 의학 지식을 통합해 복합적 임상 질문에 대한 정확한 답변을 얻고자 함.

Method: 의료 이미지·텍스트 특징을 FFT로 주파수 도메인으로 변환해 의미 신호 강조 및 노이즈 제거(FSRU). 외부 의학 사실은 양자 기반 유사도 기법으로 검색해 RAG 방식으로 결합(Quantum RAG). 최종적으로 주파수-지식 융합 특징으로 VQA 응답 생성.

Result: VQA-RAD 데이터셋에서 기존 모델들보다 특히 복잡한 이미지-텍스트 추론 사례에서 성능 향상을 보고하며, 주파수 및 양자 정보 조합이 설명가능성에도 도움이 된다고 주장함.

Conclusion: 주파수 도메인 표상과 양자영감 기반 검색의 결합은 의료 VQA에서 유망한 접근이며, 성능·설명가능성 개선에 기여할 가능성이 높음.

Abstract: Solving tough clinical questions that require both image and text
understanding is still a major challenge in healthcare AI. In this work, we
propose Q-FSRU, a new model that combines Frequency Spectrum Representation and
Fusion (FSRU) with a method called Quantum Retrieval-Augmented Generation
(Quantum RAG) for medical Visual Question Answering (VQA). The model takes in
features from medical images and related text, then shifts them into the
frequency domain using Fast Fourier Transform (FFT). This helps it focus on
more meaningful data and filter out noise or less useful information. To
improve accuracy and ensure that answers are based on real knowledge, we add a
quantum-inspired retrieval system. It fetches useful medical facts from
external sources using quantum-based similarity techniques. These details are
then merged with the frequency-based features for stronger reasoning. We
evaluated our model using the VQA-RAD dataset, which includes real radiology
images and questions. The results showed that Q-FSRU outperforms earlier
models, especially on complex cases needing image-text reasoning. The mix of
frequency and quantum information improves both performance and explainability.
Overall, this approach offers a promising way to build smart, clear, and
helpful AI tools for doctors.

</details>


### [33] [VimoRAG: Video-based Retrieval-augmented 3D Motion Generation for Motion Language Models](https://arxiv.org/abs/2508.12081)
*Haidong Xu,Guangwei Xu,Zhedong Zheng,Xiatian Zhu,Wei Ji,Xiangtai Li,Ruijie Guo,Meishan Zhang,Min zhang,Hao Fei*

Main category: cs.CV

TL;DR: VimoRAG는 대규모 in-the-wild 비디오에서 2D 인간 모션 신호를 검색해 텍스트만 입력 가능한 모션 LLM의 3D 동작 생성 성능을 향상시키는 비디오 기반 RAG 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 모션 LLM은 주로 라벨링된 3D 데이터가 적어 도메인/어휘 외 문제에 취약하다. 대규모 비디오 데이터에서 유용한 2D 모션 정보를 가져와 이 한계를 보완하려는 목적.

Method: (1) Gemini Motion Video Retriever로 포즈와 행동을 구분하는 모션 중심의 비디오 검색을 수행하고, (2) Motion-centric Dual-alignment DPO Trainer로 부정확한 검색 결과로 인한 오류 전파를 완화하여 검색-생성 파이프라인을 정렬한다.

Result: 텍스트만 입력을 허용하는 모션 LLM에 대해 VimoRAG를 적용하면 생성 성능이 유의미하게 향상되었다고 보고한다.

Conclusion: 비디오 기반 RAG 접근은 모션 LLM의 데이터 제약을 완화하는 유망한 방향이지만, 구현 세부사항(데이터, 정렬 방법, 정량적 성능, 강건성)에 대한 추가 검증이 필요하다.

Abstract: This paper introduces VimoRAG, a novel video-based retrieval-augmented motion
generation framework for motion large language models (LLMs). As motion LLMs
face severe out-of-domain/out-of-vocabulary issues due to limited annotated
data, VimoRAG leverages large-scale in-the-wild video databases to enhance 3D
motion generation by retrieving relevant 2D human motion signals. While
video-based motion RAG is nontrivial, we address two key bottlenecks: (1)
developing an effective motion-centered video retrieval model that
distinguishes human poses and actions, and (2) mitigating the issue of error
propagation caused by suboptimal retrieval results. We design the Gemini Motion
Video Retriever mechanism and the Motion-centric Dual-alignment DPO Trainer,
enabling effective retrieval and generation processes. Experimental results
show that VimoRAG significantly boosts the performance of motion LLMs
constrained to text-only input.

</details>


### [34] [Automated Model Evaluation for Object Detection via Prediction Consistency and Reliablity](https://arxiv.org/abs/2508.12082)
*Seungju Yoo,Hyuk Kwon,Joong-Won Hwang,Kibok Lee*

Main category: cs.CV

TL;DR: 라벨 없이 객체 검출기 성능을 추정하는 AutoEval 프레임워크와 PCR 지표를 제안. NMS 전후의 후보 박스들의 공간적 일관성과 중첩 박스들의 신뢰도(스코어)를 결합해 성능을 추정하고, 이미지 왜곡 수준을 변화시킨 메타-데이터셋으로 평가한다. 기존 AutoEval보다 추정 정확도가 높음.


<details>
  <summary>Details</summary>
Motivation: 실제 응용에서 객체 검출기 성능 평가가 사람의 수동 주석에 의존하면 비용과 시간이 크므로, 라벨이 없는 상태에서도 신뢰할 수 있는 자동 성능 추정 방법이 필요하다.

Method: Prediction Consistency and Reliability(PCR): 1) NMS 전후 후보 박스의 위치 일관성(공간적 일관성) 측정, 2) 유지된 박스의 신뢰도를 중첩된 박스들의 confidence로 평가. 이 두 요소를 결합하여 라벨 없이 검출 성능(예: AP)을 추정. 또한 이미지 왜곡(강도별)으로 메타-데이터셋을 구성해 현실적이고 확장성 있는 평가를 수행.

Result: 제안한 PCR이 기존 AutoEval 기법들보다 성능 추정에서 더 높은 정확도를 보였고, 제안된 메타-데이터셋이 검출 성능 변화를 더 넓은 범위에서 커버함.

Conclusion: PCR은 라벨 없는 환경에서 객체 검출 성능을 실용적이고 정확하게 추정할 수 있는 유망한 접근법이며, 배포·모니터링 상황에서 유용할 수 있다.

Abstract: Recent advances in computer vision have made training object detectors more
efficient and effective; however, assessing their performance in real-world
applications still relies on costly manual annotation. To address this
limitation, we develop an automated model evaluation (AutoEval) framework for
object detection. We propose Prediction Consistency and Reliability (PCR),
which leverages the multiple candidate bounding boxes that conventional
detectors generate before non-maximum suppression (NMS). PCR estimates
detection performance without ground-truth labels by jointly measuring 1) the
spatial consistency between boxes before and after NMS, and 2) the reliability
of the retained boxes via the confidence scores of overlapping boxes. For a
more realistic and scalable evaluation, we construct a meta-dataset by applying
image corruptions of varying severity. Experimental results demonstrate that
PCR yields more accurate performance estimates than existing AutoEval methods,
and the proposed meta-dataset covers a wider range of detection performance.
The code is available at https://github.com/YonseiML/autoeval-det.

</details>


### [35] [Generic Event Boundary Detection via Denoising Diffusion](https://arxiv.org/abs/2508.12084)
*Jaejun Hwang,Dayoung Gong,Manjin Kim,Minsu Cho*

Main category: cs.CV

TL;DR: DiffGEBD는 이벤트 경계 예측을 확률적(생성적) 관점으로 접근한 방법으로, 확산 모델을 이용해 다양한 가능한 경계들을 생성하고, 분기(denoising) 과정에서 다양성 제어가 가능하다. 표준 벤치마크에서 양호한 성능을 보이며 다양성과 재현성(fidelity)을 동시에 평가하는 새로운 지표를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 비디오의 이벤트 경계는 주관적이고 여러 타당한 분할이 존재하지만, 기존 GEBD 연구는 주로 단일 결정론적 예측에만 집중해 가능한 다양한 해답을 무시했다. 다양성과 불확실성을 모델링하는 생성적 접근의 필요성이 있다.

Method: DiffGEBD는 인접 프레임 간의 변화 정보를 시간적 자기유사성(temporal self-similarity)으로 인코딩하고, 노이즈에서 시작해 조건부 확산(denoising diffusion) 과정을 통해 그 인코딩에 조건화된 다양한 경계 샘플을 생성한다. classifier-free guidance를 도입해 디노이징 시 다양성-충실도 트레이드오프를 제어한다. 또한 다양성과 충실도를 동시에 고려하는 새로운 평가 지표를 제안한다.

Result: Kinetics-GEBD와 TAPOS에서 강한 성능을 보고하며, 생성된 경계들이 다양하고 그럴듯하다는 정성/정량 증거를 제시한다.

Conclusion: GEBD에 생성적(확률적) 패러다임을 도입하면 주관적 모호성을 더 잘 포착할 수 있으며, 다양성 제어와 새로운 평가 지표로 실용성이 향상된다.

Abstract: Generic event boundary detection (GEBD) aims to identify natural boundaries
in a video, segmenting it into distinct and meaningful chunks. Despite the
inherent subjectivity of event boundaries, previous methods have focused on
deterministic predictions, overlooking the diversity of plausible solutions. In
this paper, we introduce a novel diffusion-based boundary detection model,
dubbed DiffGEBD, that tackles the problem of GEBD from a generative
perspective. The proposed model encodes relevant changes across adjacent frames
via temporal self-similarity and then iteratively decodes random noise into
plausible event boundaries being conditioned on the encoded features.
Classifier-free guidance allows the degree of diversity to be controlled in
denoising diffusion. In addition, we introduce a new evaluation metric to
assess the quality of predictions considering both diversity and fidelity.
Experiments show that our method achieves strong performance on two standard
benchmarks, Kinetics-GEBD and TAPOS, generating diverse and plausible event
boundaries.

</details>


### [36] [Enhancing 3D point accuracy of laser scanner through multi-stage convolutional neural network for applications in construction](https://arxiv.org/abs/2508.12089)
*Qinyuan Fan,Clemens Gühmann*

Main category: cs.CV

TL;DR: MSCNN 기반 통합 방법으로, 고정밀 레이저 스캐너(HAS)를 레퍼런스로 저가 스캐너(LAS) 오차를 학습·보정하여 실내 3D 포인트 정확도를 크게 향상시킴. MSE 70% 이상 감소, PSNR 약 6dB 향상 보고.


<details>
  <summary>Details</summary>
Motivation: 하이엔드와 저가 레이저 스캐너 간의 위치 오차로 인해 실내 고정밀 기하 모델 생성·보수에 어려움이 있음. 저가 장비의 측정 불확실도를 소프트웨어적으로 감소시켜 비용 효율적인 고정밀 측정을 실현하려는 목적.

Method: 동일 환경에서 HAS와 LAS로 얻은 측정치 쌍을 구성하고, 측정 차이를 공간 분포와 통계적으로 매핑하는 프레임워크를 제안. 전통적 기하 처리(정합·전처리 등)와 다단계 합성곱 신경망(MSCNN)을 결합해 체계적 오차를 회귀(감소)하도록 지도학습 수행. 중요한 기하학적 특징은 보존하도록 설계.

Result: 제안 방법을 자체 'rough indoor rooms' 데이터셋에서 평가하여 MSE가 70% 이상 감소하고 PSNR이 약 6dB 향상됨을 보고. 저가 스캐너가 하이엔드 수준의 측정 불확실도에 근접할 수 있음을 시사.

Conclusion: 하드웨어 변경 없이 소프트웨어 기반 보정으로 저가 LS의 측정 품질을 크게 개선 가능. 체계적 오차를 학습 문제로 전환하여 정밀한 교정이 가능하며, 실무적 개조 시 비용 절감 효과가 기대됨.

Abstract: We propose a multi-stage convolutional neural network (MSCNN) based
integrated method for reducing uncertainty of 3D point accuracy of lasar
scanner (LS) in rough indoor rooms, providing more accurate spatial
measurements for high-precision geometric model creation and renovation. Due to
different equipment limitations and environmental factors, high-end and low-end
LS have positional errors. Our approach pairs high-accuracy scanners (HAS) as
references with corresponding low-accuracy scanners (LAS) of measurements in
identical environments to quantify specific error patterns. By establishing a
statistical relationship between measurement discrepancies and their spatial
distribution, we develop a correction framework that combines traditional
geometric processing with targeted neural network refinement. This method
transforms the quantification of systematic errors into a supervised learning
problem, allowing precise correction while preserving critical geometric
features. Experimental results in our rough indoor rooms dataset show
significant improvements in measurement accuracy, with mean square error (MSE)
reductions exceeding 70% and peak signal-to-noise ratio (PSNR) improvements of
approximately 6 decibels. This approach enables low-end devices to achieve
measurement uncertainty levels approaching those of high-end devices without
hardware modifications.

</details>


### [37] [Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion](https://arxiv.org/abs/2508.12094)
*Songwei Liu,Hong Liu,Fangmin Chen,Xurui Peng,Chenqian Yan,Lean Fu,Xing Mei*

Main category: cs.CV

TL;DR: 저자들은 확산모델의 반복적 노이즈 제거 과정에서 PTQ(사후 훈련 양자화)로 인한 단계적 양자화 오차가 누적되는 문제를 수학적으로 정식화하고, 각 시간 단계별 오류 전파 방정식과 누적 오류의 닫힌형 해를 유도했다. 이를 바탕으로 시간 단계 인지 누적 오류 보정(timestep-aware cumulative error compensation) 기법을 제안하여 저정밀도 확산모델에서 출력 품질을 크게 회복했다.


<details>
  <summary>Details</summary>
Motivation: 확산모델은 고품질 이미지 합성을 제공하지만 반복적 샘플링 과정 때문에 계산 비용이 크다. PTQ는 샘플링 가속의 현실적 수단이나, 반복 샘플링에서 양자화 오차가 단계별로 누적되어 생성 품질을 저하시킨다. 이러한 누적 오류를 이론적으로 이해하고 보정하는 방법이 필요하다.

Method: 확산모델의 단계적 생성 과정을 수학적으로 모델링하여 per-step 양자화 오차 전파 방정식을 도출하고, 누적 오류에 대한 첫 번째 닫힌형 해를 제시한다. 이 이론을 근거로 시간(timestep)을 고려한 누적 오류 보정 스킴을 설계하여 각 샘플링 스텝에서의 양자화 영향력을 보정한다.

Result: 여러 이미지 데이터셋에서 광범위한 실험을 수행한 결과, 제안한 보정 전략이 오류 누적을 효과적으로 완화하여 기존 PTQ 방법들의 성능을 크게 향상시켰다. 저정밀도(quantized) 확산모델에서 SOTA 수준의 결과를 달성했다고 보고한다.

Conclusion: 수학적 오류 모델링과 시간 인지 보정 기법을 결합하면 PTQ로 인한 누적 양자화 오류를 실질적으로 줄일 수 있으며, 이는 저정밀 확산모델의 실용적 배포에 기여한다.

Abstract: Diffusion models have transformed image synthesis by establishing
unprecedented quality and creativity benchmarks. Nevertheless, their
large-scale deployment faces challenges due to computationally intensive
iterative denoising processes. Although post-training quantization(PTQ)
provides an effective pathway for accelerating sampling, the iterative nature
of diffusion models causes stepwise quantization errors to accumulate
progressively during generation, inevitably compromising output fidelity. To
address this challenge, we develop a theoretical framework that mathematically
formulates error propagation in Diffusion Models (DMs), deriving per-step
quantization error propagation equations and establishing the first closed-form
solution for cumulative error. Building on this theoretical foundation, we
propose a timestep-aware cumulative error compensation scheme. Extensive
experiments across multiple image datasets demonstrate that our compensation
strategy effectively mitigates error propagation, significantly enhancing
existing PTQ methods to achieve state-of-the-art(SOTA) performance on
low-precision diffusion models.

</details>


### [38] [VELVET-Med: Vision and Efficient Language Pre-training for Volumetric Imaging Tasks in Medicine](https://arxiv.org/abs/2508.12108)
*Ziyang Zhang,Yang Yu,Xulei Yang,Si Yong Yeo*

Main category: cs.CV

TL;DR: VELVET-Med은 제한된 수량의 3D CT-리포트 페어(≈38.9k)에서 효과적으로 학습하기 위해 단일-모달 자기지도 학습, 다층 텍스트 인코더(TriBERT), 계층적 대조학습을 결합한 볼류메트릭 의료용 VLP 프레임워크이다. 저자들은 이를 통해 3D 분할, 교차모달 검색, VQA, 리포트 생성 등에서 SOTA 성능을 보고한다.


<details>
  <summary>Details</summary>
Motivation: 의료 분야에서 3D 볼류메트릭 데이터(예: CT)는 텍스트 페어링을 대규모로 모으기 어렵고, 이에 따라 비전-언어 모델의 일반화 성능이 제한된다. 대규모 데이터 수집이 불가능할 때도 강한 표현학습을 하는 방법이 필요하다.

Method: (1) 단일-모달 자기지도 학습을 VLP에 포함해 각 모달의 표현력을 높임. (2) TriBERT라는 다층 텍스트 인코더로 문서-문장-토큰 수준의 다중 의미를 학습. (3) 계층적 대조학습(hierarchical contrastive learning)으로 멀티-레벨(예: 슬라이스/볼륨/문장/문서) 간의 시맨틱 정렬을 학습.

Result: 약 38,875 scan-report 쌍만으로 학습한 모델이 3D 분할, 크로스모달 검색, VQA, 리포트 생성 등 다양한 다운스트림에서 기존 방법들을 능가하는 결과를 제시함.

Conclusion: 데이터가 제한된 의료 3D 도메인에서도 적절한 자기지도 목표와 계층적 정렬 전략, 텍스트 모델 설계로 강한 일반화 성능을 얻을 수 있음을 보였으나, 방법적 세부사항·비교 실험·재현 가능성 검증이 중요하다.

Abstract: Vision-and-language models (VLMs) have been increasingly explored in the
medical domain, particularly following the success of CLIP in general domain.
However, unlike the relatively straightforward pairing of 2D images and text,
curating large-scale paired data in the medical field for volumetric modalities
such as CT scans remains a challenging and time-intensive process. This
difficulty often limits the performance on downstream tasks. To address these
challenges, we propose a novel vision-language pre-training (VLP) framework,
termed as \textbf{VELVET-Med}, specifically designed for limited volumetric
data such as 3D CT and associated radiology reports. Instead of relying on
large-scale data collection, our method focuses on the development of effective
pre-training objectives and model architectures. The key contributions are: 1)
We incorporate uni-modal self-supervised learning into VLP framework, which are
often underexplored in the existing literature. 2) We propose a novel language
encoder, termed as \textbf{TriBERT}, for learning multi-level textual
semantics. 3) We devise the hierarchical contrastive learning to capture
multi-level vision-language correspondence. Using only 38,875 scan-report
pairs, our approach seeks to uncover rich spatial and semantic relationships
embedded in volumetric medical images and corresponding clinical narratives,
thereby enhancing the generalization ability of the learned encoders. The
resulting encoders exhibit strong transferability, achieving state-of-the-art
performance across a wide range of downstream tasks, including 3D segmentation,
cross-modal retrieval, visual question answering, and report generation.

</details>


### [39] [Simple o3: Towards Interleaved Vision-Language Reasoning](https://arxiv.org/abs/2508.12109)
*Ye Wang,Qianglong Chen,Zejun Li,Siyuan Wang,Shijie Guo,Zhirui Zhang,Zhongyu Wei*

Main category: cs.CV

TL;DR: Simple o3는 이미지 기반 도구 조작(크롭, 확대, 재사용)을 언어 추론과 교차하여 학습시키는 간단한 end-to-end 프레임워크다. 'observe–reason–act' 사이클로 합성한 고품질 체인과 실행 가능한 시각 연산을 포함한 TWI-Tools-146K 데이터셋을 활용해 SFT로 훈련하여 멀티모달 추론 성능을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 기존 MLLM들이 시각-언어 과제에서 성능이 뛰어나지만, 멀티모달 상황에서의 장기 Chain-of-Thought(CoT)와 도구 기반 반복적 시각 조작 능력은 충분히 탐구되지 않았다. 인간의 '이미지로 생각하기'를 모사하는 o3의 아이디어에서 출발해, 모델이 이미지 조작과 언어 추론을 교차적으로 수행하도록 만들고자 함.

Method: 'observe–reason–act' 루프에 따라 시각 연산(크롭, 줌, 재사용 등)과 언어적 추론이 뒤섞인 인터리브 체인을 합성하는 데이터 파이프라인을 구축했다. 생성된 체인은 실행 가능한 시각 연산 명세와 검증 절차를 포함하며, 이를 바탕으로 SFT로 모델을 학습시켜 interleaved vision-language reasoning을 가능하게 한다. 결과물로 공개된 TWI-Tools-146K 데이터셋을 제공.

Result: 다양한 벤치마크에서 기존 방법들보다 우수한 성능을 보였으며, 특히 추가적인 시각 토큰 도입, 이미지 재사용·확대, 정확한 시각적 그라운딩 기반 크롭 전략이 미세한 시각 추론 능력과 핵심 객체 집중 능력을 각각 크게 향상시켰다.

Conclusion: Simple o3는 계산 비용 부담을 크게 높이지 않으면서도 도구 상호작용을 통한 교차적 시각-언어 추론 능력을 향상시키는 실용적 패러다임을 제시한다. 또한 서로 다른 인터리브 전략에 대한 처음이자 심층적인 분석을 제공하여 향후 멀티모달 CoT 연구의 방향을 제시한다.

Abstract: Multimodal Large Language Models (MLLMs) have shown impressive performance on
vision-language tasks, but their long Chain-of-Thought (CoT) capabilities in
multimodal scenarios remain underexplored. Inspired by OpenAI's o3 model, which
emulates human-like ''thinking with image'' through iterative visual
transformations and linguistic reasoning, we propose Simple o3, an end-to-end
framework that integrates dynamic tool interactions (e.g., cropping, zooming,
and reusing) into interleaved vision-language reasoning via supervised
fine-tuning (SFT). Our approach features a scalable data synthesis pipeline
that generates high-quality interleaved vision-language reasoning chains via an
''observe-reason-act'' cycle, complete with executable visual operations and
rigorous verification, yielding the open-source TWI-Tools-146K dataset.
Experimental results demonstrate Simple o3's superior performance on diverse
benchmarks, outperforming existing approaches. By combining enhanced reasoning
capabilities, Simple o3 establishes a powerful yet computationally affordable
paradigm for advancing multimodal reasoning. Remarkably, we provide the first
in-depth analysis of different interleaved reasoning strategies, offering
insights into their impact on model performance. We found that by introducing
additional visual tokens for interleaved vision-language reasoning, reusing and
magnifying the original image significantly improves the model's visual
reasoning and fine-grained perception, while image cropping based on precise
visual grounding allows the model to effectively focus on key entities or
regions, further enhancing its capabilities.

</details>


### [40] [DualFit: A Two-Stage Virtual Try-On via Warping and Synthesis](https://arxiv.org/abs/2508.12131)
*Minh Tran,Johnmark Clements,Annie Prasanna,Tri Nguyen,Ngan Le*

Main category: cs.CV

TL;DR: DualFit은 2단계 하이브리드 VTON 파이프라인으로, 먼저 학습된 플로우로 의류를 정렬(워프)해 고주파 디테일을 보존하고, 이후 보존 영역 입력과 인페인팅 마스크를 활용한 합성 모듈로 최종 이미지를 생성해 로고·프린트 등의 세부묘사를 유지하면서 시각적으로 자연스러운 착용 결과를 만든다.


<details>
  <summary>Details</summary>
Motivation: 확산기반(warp-free) 최신 기법들이 전반적 지각 품질을 향상시켰지만, 브랜드 로고나 프린트 같은 미세한 의류 디테일을 보존하지 못해 상업적 신뢰성과 재현성이 떨어진다. 이 문제를 해결해 고주파 정보를 유지하면서도 자연스러운 합성을 달성하려는 목적이 있다.

Method: 두 단계 접근: (1) 학습된 flow 필드를 이용한 워핑 단계로 타깃 의류를 인물에 정렬하여 고주파(로고·텍스트 등)를 충실히 보존한다. (2) 보존성 유지(fidelity-preserving) try-on 모듈에서, warped 의류와 사람이 보존된 영역을 혼합해 최종 이미지를 합성한다. 특히 보존 영역 입력(preserved-region input)과 인페인팅 마스크를 도입해 재생성이 필요한 부분(예: 솔기 주변)만 선택적으로 다시 생성하도록 유도한다.

Result: 정성적 실험에서 DualFit은 시각적으로 이음새가 자연스럽고, 로고·프린트 같은 고주파 디테일을 잘 유지하며 재현 정확도와 지각적 현실감 사이에서 균형을 이룸을 보였다. 기존 워프-프리 확산 기법에서 발생하던 디테일 손실 문제를 크게 완화한다.

Conclusion: DualFit은 고주파 디테일 보존과 전체적 합성 품질을 동시에 개선하는 실용적 해법을 제시한다. 향후 정량평가(정확도·FID·사용자 연구), 다양한 포즈·의류 타입에 대한 일반화, 연산 효율성 개선 등이 필요한 후속 연구 방향이다.

Abstract: Virtual Try-On technology has garnered significant attention for its
potential to transform the online fashion retail experience by allowing users
to visualize how garments would look on them without physical trials. While
recent advances in diffusion-based warping-free methods have improved
perceptual quality, they often fail to preserve fine-grained garment details
such as logos and printed text elements that are critical for brand integrity
and customer trust. In this work, we propose DualFit, a hybrid VTON pipeline
that addresses this limitation by two-stage approach. In the first stage,
DualFit warps the target garment to align with the person image using a learned
flow field, ensuring high-fidelity preservation. In the second stage, a
fidelity-preserving try-on module synthesizes the final output by blending the
warped garment with preserved human regions. Particularly, to guide this
process, we introduce a preserved-region input and an inpainting mask, enabling
the model to retain key areas and regenerate only where necessary, particularly
around garment seams. Extensive qualitative results show that DualFit achieves
visually seamless try-on results while faithfully maintaining high-frequency
garment details, striking an effective balance between reconstruction accuracy
and perceptual realism.

</details>


### [41] [TriQDef: Disrupting Semantic and Gradient Alignment to Prevent Adversarial Patch Transferability in Quantized Neural Networks](https://arxiv.org/abs/2508.12132)
*Amira Guesmi,Bassem Ouni,Muhammad Shafique*

Main category: cs.CV

TL;DR: TriQDef는 QNN에서 패치 기반 공격의 비트-폭 간 전이 가능성을 차단하기 위해 제안된 삼중 레벨 양자화 인지 방어 프레임워크이다. 중간 표현의 의미 불일치(FDP), 입력 기울기 불일치(GPDP: Edge IoU + HOG Cosine), 그리고 다중 비트 공유 가중치 훈련을 결합해, CIFAR-10 및 ImageNet에서 보이지 않는 패치·양자화 조합에 대해 공격 성공률을 40% 이상 감소시키면서 깨끗한 정확도를 유지한다.


<details>
  <summary>Details</summary>
Motivation: QNN은 연산·메모리 효율 때문에 엣지에 널리 배치되지만, 패치 기반 적대적 공격은 서로 다른 비트-폭 모델 간에 놀랍도록 잘 전이된다. 기존 방어는 특정 양자화 설정에 과적합되거나 비트-폭 간 일반화 취약점을 해결하지 못함. 이를 해결하려면 의미적 표현과 기울기 정렬을 동시에 교란해 전이 가능성을 낮춰야 한다.

Method: (1) Feature Disalignment Penalty(FDP): 중간 계층 표현의 지각적 유사도를 페널티로 적용하여 의미적 일관성 파괴; (2) Gradient Perceptual Dissonance Penalty(GPDP): 입력 기울기의 구조·방향 일치를 최소화(Edge IoU, HOG Cosine 사용)해 기울기 정렬을 억제; (3) Joint Quantization-Aware Training: 여러 양자화 레벨을 공유 가중치로 동시에 훈련하며 위 페널티를 통합.

Result: CIFAR-10과 ImageNet 실험에서, TriQDef는 보이지 않는 패치·양자화 조합에 대해 공격 성공률을 40% 이상 줄였고, 동시에 깨끗한(비공격) 정확도를 높은 수준으로 유지함.

Conclusion: 패치 전이성을 낮추려면 중간 표현의 의미적 불일치와 기울기(지각) 정렬을 동시에 차단하는 것이 중요하다. TriQDef는 이 원리를 실행 가능한 트레이닝 프로토콜로 구현하여 QNN의 교차-비트 강인성을 향상시킴.

Abstract: Quantized Neural Networks (QNNs) are increasingly deployed in edge and
resource-constrained environments due to their efficiency in computation and
memory usage. While shown to distort the gradient landscape and weaken
conventional pixel-level attacks, it provides limited robustness against
patch-based adversarial attacks-localized, high-saliency perturbations that
remain surprisingly transferable across bit-widths. Existing defenses either
overfit to fixed quantization settings or fail to address this cross-bit
generalization vulnerability. We introduce \textbf{TriQDef}, a tri-level
quantization-aware defense framework designed to disrupt the transferability of
patch-based adversarial attacks across QNNs. TriQDef consists of: (1) a Feature
Disalignment Penalty (FDP) that enforces semantic inconsistency by penalizing
perceptual similarity in intermediate representations; (2) a Gradient
Perceptual Dissonance Penalty (GPDP) that explicitly misaligns input gradients
across bit-widths by minimizing structural and directional agreement via Edge
IoU and HOG Cosine metrics; and (3) a Joint Quantization-Aware Training
Protocol that unifies these penalties within a shared-weight training scheme
across multiple quantization levels. Extensive experiments on CIFAR-10 and
ImageNet demonstrate that TriQDef reduces Attack Success Rates (ASR) by over
40\% on unseen patch and quantization combinations, while preserving high clean
accuracy. Our findings underscore the importance of disrupting both semantic
and perceptual gradient alignment to mitigate patch transferability in QNNs.

</details>


### [42] [Infusing fine-grained visual knowledge to Vision-Language Models](https://arxiv.org/abs/2508.12137)
*Nikolaos-Antonios Ypsilantis,Kaifeng Chen,André Araujo,Ondřej Chum*

Main category: cs.CV

TL;DR: 대규모 대비 학습된 VLM을 미세 조정해 세부적 오픈셋 검색 성능을 높이되, 지속적 학습 기반의 정규화 조합과 검증/하이퍼파라미터 설계로 기존 멀티모달 지식을 보존하는 방법을 제안한다. 텍스트 데이터나 텍스트 인코더 없이도 시각-텍스트 정렬을 유지하며 광범위한 벤치마크에서 강한 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 대규모 대비 학습 VLM은 범용 임베딩을 제공하지만, 세부적(fine-grained) 오픈셋 검색에서는 도메인 특정 샘플로 비전 인코더를 미세조정해야 최첨단 성능에 도달한다. 그러나 무분별한 미세조정은 파국적 망각을 초래해 원래의 범용 멀티모달 능력을 상실시킨다.

Method: 지속적 학습(continual learning) 문헌에서 영감을 받아 기존 정규화 기법들을 체계적으로 분석하고, 지식 보존과 도메인 적응 간 균형을 이루는 효율적·효과적 조합 전략을 제안한다. 또한 검증 세트 설계와 하이퍼파라미터 튜닝의 중요성을 강조해 재현성과 일반화 성능을 확보한다. 미세조정 시 텍스트 데이터나 원본 텍스트 인코더를 사용하지 않음에도 시각-텍스트 정렬을 유지하도록 설계되었다.

Result: 세부 및 거시 단위의 이미지-이미지, 이미지-텍스트 검색 벤치마크에서 일관되게 우수한 성능을 기록한다. 특히 사전학습된 멀티모달 지식을 유지하면서 도메인 특화 성능을 확보했고, 코드 및 체크포인트를 공개했다.

Conclusion: 적절한 정규화 기법의 조합과 검증/튜닝 전략을 통해, 텍스트 없이도 비전 인코더를 안전하게 미세조정하여 fine-grained 검색 성능을 향상시키면서도 VLM의 범용 멀티모달 역량을 보존할 수 있음을 보였다.

Abstract: Large-scale contrastive pre-training produces powerful Vision-and-Language
Models (VLMs) capable of generating representations (embeddings) effective for
a wide variety of visual and multimodal tasks. However, these pretrained
embeddings remain suboptimal for fine-grained open-set visual retrieval, where
state-of-the-art results require fine-tuning the vision encoder using annotated
domain-specific samples. Naively performing such fine-tuning typically leads to
catastrophic forgetting, severely diminishing the model's general-purpose
visual and cross-modal capabilities.
  In this work, we propose a fine-tuning method explicitly designed to achieve
optimal balance between fine-grained domain adaptation and retention of the
pretrained VLM's broad multimodal knowledge. Drawing inspiration from continual
learning literature, we systematically analyze standard regularization
techniques aimed at knowledge retention and propose an efficient and effective
combination strategy. Additionally, we address the commonly overlooked yet
critical aspects of validation set design and hyperparameter tuning to ensure
reproducibility and robust generalization across datasets and pretrained
models. We extensively evaluate our method on both fine-grained and
coarse-grained image-image and image-text retrieval benchmarks. Our approach
consistently achieves strong results, notably retaining the visual-text
alignment without utilizing any text data or the original text encoder during
fine-tuning. Code and model checkpoints: https://github.com/nikosips/infusing .

</details>


### [43] [KP-INR: A Dual-Branch Implicit Neural Representation Model for Cardiac Cine MRI Reconstruction](https://arxiv.org/abs/2508.12147)
*Donghang Lyu,Marius Staring,Mariya Doneva,Hildo J. Lamb,Nicola Pezzotti*

Main category: cs.CV

TL;DR: 제안된 KP-INR은 k-공간에서 좌표 임베딩과 다중 스케일 로컬 특성 브랜치를 병렬로 둔 듀얼-브랜치 INR로, 교차 상호작용을 통해 언더샘플된 cardiac cine MRI의 k-공간 값을 복원한다. CMRxRecon2024 데이터셋에서 베이스라인보다 성능 향상을 보고함.


<details>
  <summary>Details</summary>
Motivation: 심장 cine MRI의 빠른 획득은 스캔 시간을 줄이나 이미지 품질 저하를 초래한다. 기존 INR 방법은 좌표 기반 임베딩에만 의존해 목표 점과 이웃 맥락의 특성 표현을 충분히 반영하지 못함. 이를 극복해 고품질 복원을 달성하려는 동기.

Method: k-공간에서 동작하는 듀얼-브랜치 INR 구조(KP-INR)를 제안. 한 브랜치는 k-공간 좌표의 positional embedding을 처리하고, 다른 브랜치는 해당 좌표의 로컬 다중 스케일 k-공간 특성을 학습. 두 브랜치 간 교차 상호작용과 결합을 통해 목표 k-공간 값을 근사화하여 재구성.

Result: CMRxRecon2024 데이터셋에서 제안 방법이 베이스라인 모델들보다 우수한 성능을 보였다고 보고. 구체적 수치(예: PSNR/SSIM 등)는 초록에 없음.

Conclusion: 로컬 특성 정보를 보강한 k-공간 기반 듀얼-브랜치 INR은 언더샘플된 cardiac cine MRI 재구성에서 성능 향상이 가능함을 보여주며, 더 자세한 실험·분석을 통해 임상 적용 가능성을 평가할 필요가 있음.

Abstract: Cardiac Magnetic Resonance (CMR) imaging is a non-invasive method for
assessing cardiac structure, function, and blood flow. Cine MRI extends this by
capturing heart motion, providing detailed insights into cardiac mechanics. To
reduce scan time and breath-hold discomfort, fast acquisition techniques have
been utilized at the cost of lowering image quality. Recently, Implicit Neural
Representation (INR) methods have shown promise in unsupervised reconstruction
by learning coordinate-to-value mappings from undersampled data, enabling
high-quality image recovery. However, current existing INR methods primarily
focus on using coordinate-based positional embeddings to learn the mapping,
while overlooking the feature representations of the target point and its
neighboring context. In this work, we propose KP-INR, a dual-branch INR method
operating in k-space for cardiac cine MRI reconstruction: one branch processes
the positional embedding of k-space coordinates, while the other learns from
local multi-scale k-space feature representations at those coordinates. By
enabling cross-branch interaction and approximating the target k-space values
from both branches, KP-INR can achieve strong performance on challenging
Cartesian k-space data. Experiments on the CMRxRecon2024 dataset confirms its
improved performance over baseline models and highlights its potential in this
field.

</details>


### [44] [Demystifying Foreground-Background Memorization in Diffusion Models](https://arxiv.org/abs/2508.12148)
*Jimmy Z. Di,Yiwei Lu,Yaoliang Yu,Gautam Kamath,Adam Dziedzic,Franziska Boenisch*

Main category: cs.CV

TL;DR: FB-Mem은 생성 이미지의 영역 단위(전경/배경)로 기억(메모리제이션)을 분류·정량화하는 세분화 기반 지표다. 이를 통해 부분적·클러스터화된 기억 패턴을 드러내고, 기존의 뉴런 비활성화·가지치기 같은 모델 수준 완화법이 전경의 국소 기억을 제거하지 못함을 보인다. 군집 기반 완화법을 제안해 더 강한 억제가 가능함을 주장한다.


<details>
  <summary>Details</summary>
Motivation: 현행 검출법은 훈련 이미지의 완전 복제(문자 그대로의 중복)만 식별하며, 이미지의 작은 부분에서 일어나는 부분적 기억과 특정 프롬프트-이미지 한 쌍을 넘는 복잡한 기억 패턴(클러스터)을 포착하지 못한다. 이러한 한계를 극복하기 위한 정량적·영역 기반 측정법이 필요하다.

Method: 생성 이미지와 훈련 이미지 간 유사도를 영역(전경/배경) 수준으로 평가하는 세분화 기반 지표(FB-Mem)를 설계한다. 생성물의 전경/배경을 분리한 뒤 각 영역에서 훈련 데이터와의 근접도·유사도 분석을 수행하여 '기억된' 영역을 분류·정량화한다. 또한 여러 훈련 이미지와의 유사성 클러스터를 분석해 한-대-다수(many-to-one) 패턴을 탐지하고, 기존 완화법(뉴런 비활성화, 가지치기)과 새로 제안한 군집 기반 완화법을 비교 평가한다.

Result: FB-Mem 적용 결과 기억 현상은 이전보다 더 넓게 분포한다는 것이 드러났다: 개별 프롬프트의 생성물은 종종 여러 유사 훈련 이미지와 연결되는 클러스터에 속하며, 특히 전경 영역에서 부분적 기억이 지속적으로 관찰된다. 기존 모델 수준 완화법은 전역적 지표상 효과가 있더라도 전경의 국소 기억을 충분히 제거하지 못한다. 군집 기반 완화법은 이 국소 기억을 더 효과적으로 줄였다.

Conclusion: 영역 수준의 정량화(전경/배경 기반)는 확산모델의 부분적·클러스터화된 기억을 더 잘 드러낸다. 기존 완화 기법은 불충분하며, 훈련 샘플의 클러스터 정보를 반영한 강한 완화 전략이 필요하다. FB-Mem은 연구·윤리적 검증을 위한 실용적 프레임워크를 제공한다.

Abstract: Diffusion models (DMs) memorize training images and can reproduce
near-duplicates during generation. Current detection methods identify verbatim
memorization but fail to capture two critical aspects: quantifying partial
memorization occurring in small image regions, and memorization patterns beyond
specific prompt-image pairs. To address these limitations, we propose
Foreground Background Memorization (FB-Mem), a novel segmentation-based metric
that classifies and quantifies memorized regions within generated images. Our
method reveals that memorization is more pervasive than previously understood:
(1) individual generations from single prompts may be linked to clusters of
similar training images, revealing complex memorization patterns that extend
beyond one-to-one correspondences; and (2) existing model-level mitigation
methods, such as neuron deactivation and pruning, fail to eliminate local
memorization, which persists particularly in foreground regions. Our work
establishes an effective framework for measuring memorization in diffusion
models, demonstrates the inadequacy of current mitigation approaches, and
proposes a stronger mitigation method using a clustering approach.

</details>


### [45] [RealTalk: Realistic Emotion-Aware Lifelike Talking-Head Synthesis](https://arxiv.org/abs/2508.12163)
*Wenqing Wang,Yun Fu*

Main category: cs.CV

TL;DR: 이 논문은 오디오로부터 정교한 감정 표현을 가진 리얼리스틱 토킹헤드를 생성하는 RealTalk를 제안한다. VAE로 3D 랜드마크를 생성하고, 감정 임베딩과 결합한 ResNet 기반 랜드마크 변형 모델(LDM)로 감정 랜드마크를 얻어 tri-plane attention NeRF와 블렌드쉐이프 계수를 조건으로 고품질 렌더링을 수행한다. 기존 방법보다 감정 정확도, 제어성, 정체성 보존에서 우수하다.


<details>
  <summary>Details</summary>
Motivation: 현재 토킹헤드 합성 방법은 립 싱크와 이미지 품질은 좋지만 감정 표현의 정확성·제어성·정체성 보존에서 한계를 보인다. 사회적 지능을 갖춘 AI를 위해 감정 표현을 정교하게 제어하면서 피사체 정체성을 유지하는 방법이 필요하다.

Method: 오디오를 입력으로 VAE를 통해 3D 얼굴 랜드마크를 생성한다. 생성된 랜드마크에 감정 라벨 임베딩을 결합하고, ResNet 기반의 랜드마크 변형 모델(LDM)을 통해 감정 랜드마크를 생성한다. 이 감정 랜드마크와 얼굴 블렌드쉐이프 계수를 함께 조건으로 삼는 tri-plane attention NeRF를 새로 설계하여 감정이 반영된 고품질 토킹헤드를 렌더링한다.

Result: 광범위한 실험에서 RealTalk는 감정 정확도, 감정 제어성, 정체성 보존에서 기존 방법들보다 우수한 성능을 보였다.

Conclusion: RealTalk는 감정 정확성과 제어성, 정체성 보존을 개선하여 사회적 지능을 향상시키는 토킹헤드 합성에 기여한다.

Abstract: Emotion is a critical component of artificial social intelligence. However,
while current methods excel in lip synchronization and image quality, they
often fail to generate accurate and controllable emotional expressions while
preserving the subject's identity. To address this challenge, we introduce
RealTalk, a novel framework for synthesizing emotional talking heads with high
emotion accuracy, enhanced emotion controllability, and robust identity
preservation. RealTalk employs a variational autoencoder (VAE) to generate 3D
facial landmarks from driving audio, which are concatenated with emotion-label
embeddings using a ResNet-based landmark deformation model (LDM) to produce
emotional landmarks. These landmarks and facial blendshape coefficients jointly
condition a novel tri-plane attention Neural Radiance Field (NeRF) to
synthesize highly realistic emotional talking heads. Extensive experiments
demonstrate that RealTalk outperforms existing methods in emotion accuracy,
controllability, and identity preservation, advancing the development of
socially intelligent AI systems.

</details>


### [46] [Scalable RF Simulation in Generative 4D Worlds](https://arxiv.org/abs/2508.12176)
*Zhiwei Zheng,Dongyin Hu,Mingmin Zhao*

Main category: cs.CV

TL;DR: WaveVerse는 텍스트와 공간 제약을 입력으로 받아 현실적인 4D 실내 장면과 사람 동작을 생성하고, 위상 일관성을 보장하는 레이 트레이싱 기반 RF 시뮬레이터로 고품질 RF 데이터를 합성해 RF 이미징·활동 인식 등에서 성능 향상을 보이는 프롬프트 기반 RF 데이터 생성 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 실내에서의 RF 기반 인식 연구는 개인정보 보호와 조명·가시성 제약 완화 등 장점이 있으나, 다양한 동적 환경에서 고품질·위상 일관성을 가진 RF 데이터를 수집하기 어렵고 레이블링 비용이 높아 데이터 부족 문제가 심각하다. 이를 해결하기 위해 합성 데이터 생성의 필요성이 제기된다.

Method: (1) 언어 지시와 공간 제약을 입력으로 받는 4D 월드 생성기: 상태 인지형 인과적(transformer) 모델로 사람의 연속적 동작을 생성한다. (2) 위상 일관성(phase-coherence)을 유지하는 레이 트레이싱 RF 시뮬레이터: 전파 경로와 위상 정보를 보존해 빔포밍·호흡 모니터링 등 위상 민감 응용에 적합한 신호를 합성한다. 프롬프트 기반 파이프라인으로 다양한 장면과 동작을 확장 가능하다.

Result: 조건부 인간 동작 생성에서 좋은 성능을 보였고, 합성 신호의 위상 일관성이 빔포밍 및 호흡 신호 분석에 유의미하게 적용됨을 확인했다. 사례 연구로 고해상도 RF 이미징과 인간 활동 인식에서 합성 데이터 사용 시 데이터가 적거나 충분한 상황 모두에서 성능 향상을 기록했다. 또한 RF 이미징용 데이터 생성에 처음으로 적용되었다고 주장한다.

Conclusion: WaveVerse는 언어-조건 기반 4D 시뮬레이션과 위상 일관성 유지 레이 트레이싱을 결합해 현실적이고 응용 가능성이 높은 RF 합성 데이터를 제공함으로써 RF 인식 연구의 데이터 제약을 완화하고, 다양한 RF 응용(이미징·활동 인식·생체 신호 모니터링)에서 성능 개선을 이끈다.

Abstract: Radio Frequency (RF) sensing has emerged as a powerful, privacy-preserving
alternative to vision-based methods for indoor perception tasks. However,
collecting high-quality RF data in dynamic and diverse indoor environments
remains a major challenge. To address this, we introduce WaveVerse, a
prompt-based, scalable framework that simulates realistic RF signals from
generated indoor scenes with human motions. WaveVerse introduces a
language-guided 4D world generator, which includes a state-aware causal
transformer for human motion generation conditioned on spatial constraints and
texts, and a phase-coherent ray tracing simulator that enables the simulation
of accurate and coherent RF signals. Experiments demonstrate the effectiveness
of our approach in conditioned human motion generation and highlight how phase
coherence is applied to beamforming and respiration monitoring. We further
present two case studies in ML-based high-resolution imaging and human activity
recognition, demonstrating that WaveVerse not only enables data generation for
RF imaging for the first time, but also consistently achieves performance gain
in both data-limited and data-adequate scenarios.

</details>


### [47] [Splat Feature Solver](https://arxiv.org/abs/2508.12216)
*Butian Xiong,Rong Liu,Kenneth Xu,Meida Chen,Andrew Feng*

Main category: cs.CV

TL;DR: 스플랫(splat) 기반 3D 표현에 DINO·CLIP 같은 이미지 특징을 부착하는 문제를 희소 선형 역문제로 통합해 닫힌형 해법을 제시한다. 볼록 손실 하의 전역 최적 오차 상한을 보장하며, 수치적 안정화를 위한 Tikhonov Guidance와 노이즈 필터링을 위한 Post-Lifting Aggregation이라는 두 정규화를 도입해 실무적으로 빠르고 고성능의 리프팅을 달성한다.


<details>
  <summary>Details</summary>
Motivation: 스플랫 기반 3D 장면 이해에서 풍부한 이미지 특징을 3D 원시 요소에 정확히 할당하는 것이 핵심이나, 다수의 뷰에서 관측 불일치·노이즈 때문에 일관성 있고 고품질의 특징 리프팅이 어렵다. 기존 학습 기반·그룹핑 기반·휴리스틱 방법들의 한계(학습 비용·일반화·정확도)를 극복하려는 동기에서 출발한다.

Method: 커널·특징 불가지론적(agnostic)인 형식으로 특징 리프팅을 희소 선형 역문제로 정식화하고, 닫힌형(효율적) 해를 구한다. 볼록 손실 하에서 전역 최적 오차의 상한을 이론적으로 제시한다. 수치적 불안정성과 다중뷰 노이즈를 완화하기 위해 두 가지 정규화 전략을 도입: (1) Tikhonov Guidance — 소프트 대각 우세성으로 수치 안정성 부여, (2) Post-Lifting Aggregation — 특징 클러스터링으로 노이즈 필터링. 알고리즘은 특징·커널 종류에 구애받지 않고 빠르게 실행된다.

Result: 오픈 보캐뷸러리 3D 분할 벤치마크에서 학습 기반·그룹핑 기반·휴리스틱 포워드 베이스라인들을 능가하는 SOTA 성능을 보이며, 리프팅 작업을 수 분 내에 완료한다고 보고한다.

Conclusion: 원리적(이론적 보장 포함)이고 실용적인 비학습적 리프팅 프레임워크로, 일반화성과 속도에서 장점을 가지며 다중뷰 불일치 문제에 대해 두 가지 보강 기법으로 강건성을 확보한다. 다만 선형 모델·볼록 손실 가정, 입력 특징 품질·클러스터링 하이퍼파라미터 등에 의존하는 한계가 있을 수 있다.

Abstract: Feature lifting has emerged as a crucial component in 3D scene understanding,
enabling the attachment of rich image feature descriptors (e.g., DINO, CLIP)
onto splat-based 3D representations. The core challenge lies in optimally
assigning rich general attributes to 3D primitives while addressing the
inconsistency issues from multi-view images. We present a unified, kernel- and
feature-agnostic formulation of the feature lifting problem as a sparse linear
inverse problem, which can be solved efficiently in closed form. Our approach
admits a provable upper bound on the global optimal error under convex losses
for delivering high quality lifted features. To address inconsistencies and
noise in multi-view observations, we introduce two complementary regularization
strategies to stabilize the solution and enhance semantic fidelity. Tikhonov
Guidance enforces numerical stability through soft diagonal dominance, while
Post-Lifting Aggregation filters noisy inputs via feature clustering. Extensive
experiments demonstrate that our approach achieves state-of-the-art performance
on open-vocabulary 3D segmentation benchmarks, outperforming training-based,
grouping-based, and heuristic-forward baselines while producing the lifted
features in minutes. Code is available at
\href{https://github.com/saliteta/splat-distiller.git}{\textbf{github}}. We
also have a \href{https://splat-distiller.pages.dev/}

</details>


### [48] [C2PSA-Enhanced YOLOv11 Architecture: A Novel Approach for Small Target Detection in Cotton Disease Diagnosis](https://arxiv.org/abs/2508.12219)
*Kaiyuan Wang,Jixing Liu,Xiaobo Cai*

Main category: cs.CV

TL;DR: Deep learning optimization of YOLOv11 for cotton disease detection improves small-spot detection and field robustness via C2PSA, dynamic category weighting, and Mosaic-MixUp scaling, yielding mAP50 0.820, mAP50-95 0.705 and 158 FPS on a 4,078-image dataset.


<details>
  <summary>Details</summary>
Motivation: Address three practical problems in cotton-disease detection: poor early (small-spot) detection, degraded accuracy under field conditions, and high errors in multi-disease scenes.

Method: Introduce C2PSA module to strengthen small-target features, apply dynamic category weighting to mitigate class imbalance, and enhance augmentation with Mosaic-MixUp scaling. Integrate these into an optimized YOLOv11 and deploy on mobile.

Result: On a 4,078-image dataset: mAP50 improved by +8.0% to 0.820; mAP50-95 improved by +10.5% to 0.705; inference speed 158 FPS. Reported reductions in leakage and multi-disease error rates.

Conclusion: The optimized model and mobile system enable real-time, precision monitoring and treatment in agricultural settings by improving detection accuracy (especially for small lesions) and robustness in field deployments.

Abstract: This study presents a deep learning-based optimization of YOLOv11 for cotton
disease detection, developing an intelligent monitoring system. Three key
challenges are addressed: (1) low precision in early spot detection (35%
leakage rate for sub-5mm2 spots), (2) performance degradation in field
conditions (25% accuracy drop), and (3) high error rates (34.7%) in
multi-disease scenarios. The proposed solutions include: C2PSA module for
enhanced small-target feature extraction; Dynamic category weighting to handle
sample imbalance; Improved data augmentation via Mosaic-MixUp scaling.
Experimental results on a 4,078-image dataset show: mAP50: 0.820 (+8.0%
improvement); mAP50-95: 0.705 (+10.5% improvement); Inference speed: 158 FPS.
The mobile-deployed system enables real-time disease monitoring and precision
treatment in agricultural applications.

</details>


### [49] [In vivo 3D ultrasound computed tomography of musculoskeletal tissues with generative neural physics](https://arxiv.org/abs/2508.12226)
*Zhijun Zeng,Youjia Zheng,Chang Su,Qianhang Wu,Hao Hu,Zeyuan Dong,Shan Gao,Yang Lv,Rui Tang,Ligang Cui,Zhiyong Hou,Weijun Lin,Zuoqiang Shi,Yubing Li,He Sun*

Main category: cs.CV

TL;DR: 파동물리 기반의 생성 신경망을 결합한 ‘신경 물리(Neural Physics)’ 프레임워크로 3D 초음파 전산단층촬영(USCT)의 강산란 환경에서도 빠르고 고충실도 정량 재구성을 달성함. 수십 장의 교차 모달리티 이미지로 초음파 파동전파의 컴팩트한 대리모델을 학습해 10분 내외에 조직 음향 특성 맵을 복원.


<details>
  <summary>Details</summary>
Motivation: 기존의 광선기반(ray-based) 재구성은 강한 산란을 무시하여 근골격계와 같은 산란이 큰 조직에서는 정확도가 떨어짐. 정밀한 파동모델은 정확하지만 계산비용이 커 실시간/임상 적용이 어려움.

Method: 생성 네트워크와 물리정보(physics-informed) 신경 시뮬레이션을 결합. 수십 장의 교차-모달 이미지로부터 초음파 파동전파의 컴팩트한 surrogate 모델을 학습하여 정교한 파동물리의 정확성과 딥러닝의 계산 효율·안정성을 통합한 엔드투엔드 정량 재구성 파이프라인을 구성.

Result: 합성 및 실험(in vivo: 유방, 팔, 다리) 데이터에서 10분 이내에 3D 조직 매개변수 지도(음속, 감쇠 등)를 재구성. 근육·뼈의 생체역학적 특성에 민감하며 해상도는 MRI에 준함.

Conclusion: 강산란 영역에서의 계산 병목을 해소하여 USCT의 근골격계 임상 적용 가능성을 크게 높임 — 방사선 없이 조직의 정량적 평가가 가능한 실용적 접근 제공.

Abstract: Ultrasound computed tomography (USCT) is a radiation-free, high-resolution
modality but remains limited for musculoskeletal imaging due to conventional
ray-based reconstructions that neglect strong scattering. We propose a
generative neural physics framework that couples generative networks with
physics-informed neural simulation for fast, high-fidelity 3D USCT. By learning
a compact surrogate of ultrasonic wave propagation from only dozens of
cross-modality images, our method merges the accuracy of wave modeling with the
efficiency and stability of deep learning. This enables accurate quantitative
imaging of in vivo musculoskeletal tissues, producing spatial maps of acoustic
properties beyond reflection-mode images. On synthetic and in vivo data
(breast, arm, leg), we reconstruct 3D maps of tissue parameters in under ten
minutes, with sensitivity to biomechanical properties in muscle and bone and
resolution comparable to MRI. By overcoming computational bottlenecks in
strongly scattering regimes, this approach advances USCT toward routine
clinical assessment of musculoskeletal disease.

</details>


### [50] [WXSOD: A Benchmark for Robust Salient Object Detection in Adverse Weather Conditions](https://arxiv.org/abs/2508.12250)
*Quan Chen,Xiong Yang,Rongfeng Lu,Qianyu Zhang,Yu Liu,Xiaofei Zhou,Bolun Zheng*

Main category: cs.CV

TL;DR: 기상 노이즈가 있는 상황에서의 SOD 성능 저하 문제를 해결하기 위해, 다양한 기상 노이즈가 포함된 픽셀 단위 주석의 대규모 데이터셋(WXSOD, 14,945장)을 제안하고, 기상 예측 분기와 SOD 분기를 결합한 두-분기 감독형 네트워크 WFANet를 제안한다. 합성/실제 테스트셋으로 일반화 성능을 평가하며, 기존 17개 SOD 방법과 비교해 우수한 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 기상 노이즈(비, 눈, 안개 등)가 SOD 성능을 저하시킬 수 있으나, 이에 대한 픽셀 단위 주석 데이터셋이 부족해 연구가 미흡하다. 이에 따라 기상 노이즈 조건에서의 SOD 성능 평가와 개선을 위한 데이터셋과 방법이 필요하다.

Method: WXSOD 데이터셋: 14,945개의 RGB 이미지, 기상 라벨 및 정답 마스크를 포함. 테스트는 합성 테스트셋(깨끗한 이미지에 노이즈 합성)과 실제 테스트셋(실제 기상 노이즈)으로 구성. WFANet 구조: 두 분기(기상 예측 분기와 SOD 분기)를 갖춘 완전 감독형 네트워크. 기상 분기에서 기상 관련 심층 특징을 추출하고 SOD 분기에서 백본에서 추출한 의미론적 특징과 결합해 최종 예측을 수행.

Result: WFANet은 WXSOD에서 기존 17개 SOD 방법들과 비교하여 더 우수한 성능을 기록했다. 두 테스트셋(합성/실제)에서의 포괄적 비교를 통해 일반화 능력을 검증.

Conclusion: WXSOD는 기상 노이즈 상황에서 SOD 연구를 촉진할 수 있는 중요한 벤치마크이며, WFANet은 기상 인지를 통한 특징 집계가 노이즈가 있는 환경에서의 SOD 성능을 향상시킴을 보여준다.

Abstract: Salient object detection (SOD) in complex environments remains a challenging
research topic. Most existing methods perform well in natural scenes with
negligible noise, and tend to leverage multi-modal information (e.g., depth and
infrared) to enhance accuracy. However, few studies are concerned with the
damage of weather noise on SOD performance due to the lack of dataset with
pixel-wise annotations. To bridge this gap, this paper introduces a novel
Weather-eXtended Salient Object Detection (WXSOD) dataset. It consists of
14,945 RGB images with diverse weather noise, along with the corresponding
ground truth annotations and weather labels. To verify algorithm
generalization, WXSOD contains two test sets, i.e., a synthesized test set and
a real test set. The former is generated by adding weather noise to clean
images, while the latter contains real-world weather noise. Based on WXSOD, we
propose an efficient baseline, termed Weather-aware Feature Aggregation Network
(WFANet), which adopts a fully supervised two-branch architecture.
Specifically, the weather prediction branch mines weather-related deep
features, while the saliency detection branch fuses semantic features extracted
from the backbone with weather features for SOD. Comprehensive comparisons
against 17 SOD methods shows that our WFANet achieves superior performance on
WXSOD. The code and benchmark results will be made publicly available at
https://github.com/C-water/WXSOD

</details>


### [51] [Superpixel-informed Continuous Low-Rank Tensor Representation for Multi-Dimensional Data Recovery](https://arxiv.org/abs/2508.12261)
*Zhizhou Wang,Ruijing Zheng,Zhenyu Wu,Jianli Wang*

Main category: cs.CV

TL;DR: 제안된 SCTR은 슈퍼픽셀을 단위로 삼고 비대칭 저랭크 텐서 분해와 공유 신경망 헤드를 결합해 연속적·유연한 저랭크 텐서 표현을 구현한다. 그 결과 다중 스펙트럼 영상, 비디오, 컬러 이미지 등에서 기존 LRTR 기반 기법 대비 3–5 dB PSNR 향상을 보였다.


<details>
  <summary>Details</summary>
Motivation: 전통적 저랭크 텐서 표현은 전체 데이터가 저랭크라는 가정을 전제로 하며 격자(meshgrid) 데이터에만 적용 가능하다. 하지만 현실 데이터는 공간적 변동성이 커 전체 저랭크 가정이 깨지고, 비격자 연속형 데이터나 지역별 특성이 큰 경우에도 유연하게 적용하기 어렵다.

Method: SCTR는 (1) 의미적으로 동질적인 영역이 더 강한 저랭크 성질을 보인다는 관찰에서 슈퍼픽셀을 기본 단위로 사용하고, (2) 비대칭 저랭크 텐서 분해(ALTF)를 도입해 슈퍼픽셀별 인자 행렬을 공유 신경망으로 파라미터화하되 각 슈퍼픽셀용 전문화 헤드를 둔다. 이렇게 글로벌 패턴 학습(공유 네트워크)과 로컬 적응(헤드)을 분리해 교차 영역 공통성 및 영역 내 변이를 효율적으로 캡처한다. 또한 연속적 모델링을 허용해 격자 제약을 벗어난 입력에도 적용 가능하다.

Result: 여러 벤치마크(다중 스펙트럼 이미지, 비디오, 컬러 이미지)에서 기존 LRTR 기반 방법들보다 PSNR이 3–5 dB 향상되었음.

Conclusion: 슈퍼픽셀 기반 분해와 공유-특화 헤드 구조를 결합한 SCTR는 표현력과 컴팩트함을 동시에 달성하며, 공간적 변동성과 비격자 데이터에 대해 더 강건하고 유연한 저랭크 텐서 모델링을 제공한다.

Abstract: Low-rank tensor representation (LRTR) has emerged as a powerful tool for
multi-dimensional data processing. However, classical LRTR-based methods face
two critical limitations: (1) they typically assume that the holistic data is
low-rank, this assumption is often violated in real-world scenarios with
significant spatial variations; and (2) they are constrained to discrete
meshgrid data, limiting their flexibility and applicability. To overcome these
limitations, we propose a Superpixel-informed Continuous low-rank Tensor
Representation (SCTR) framework, which enables continuous and flexible modeling
of multi-dimensional data beyond traditional grid-based constraints. Our
approach introduces two main innovations: First, motivated by the observation
that semantically coherent regions exhibit stronger low-rank characteristics
than holistic data, we employ superpixels as the basic modeling units. This
design not only encodes rich semantic information, but also enhances
adaptability to diverse forms of data streams. Second, we propose a novel
asymmetric low-rank tensor factorization (ALTF) where superpixel-specific
factor matrices are parameterized by a shared neural network with specialized
heads. By strategically separating global pattern learning from local
adaptation, this framework efficiently captures both cross-superpixel
commonalities and within-superpixel variations. This yields a representation
that is both highly expressive and compact, balancing model efficiency with
adaptability. Extensive experiments on several benchmark datasets demonstrate
that SCTR achieves 3-5 dB PSNR improvements over existing LRTR-based methods
across multispectral images, videos, and color images.

</details>


### [52] [Region-Level Context-Aware Multimodal Understanding](https://arxiv.org/abs/2508.12263)
*Hongliang Wei,Xianqi Zhang,Xingtao Wang,Xiaopeng Fan,Debin Zhao*

Main category: cs.CV

TL;DR: 이 논문은 객체에 연결된 텍스트(레이블/메타데이터)를 바탕으로 이미지의 특정 영역을 문맥적으로 이해하는 '영역 수준 문맥 인지 멀티모달 이해(RCMU)' 문제를 정의하고, 객체 정보(텍스트+바운딩박스)를 입력으로 넣어 학습하는 RCVIT 방법과 대규모 RCMU 데이터셋·평가벤치·무참조 평가 지표를 제안한다. Qwen2-VL에 적용한 RC-Qwen2-VL이 RCMU 및 멀티모달 RAG, 개인화 대화에서 우수한 성능을 보였으며 데이터·모델·벤치마크를 공개한다.


<details>
  <summary>Details</summary>
Motivation: 기존 MLLM 연구는 주로 전반적 비주얼 이해에 집중해 왔고, 객체와 연계된 텍스트(예: 상품 태그, OCR, 메타데이터 등)를 통합해 영역 단위로 문맥을 이해하는 능력(RCMU)은 충분히 다뤄지지 않았다. 실제 응용(멀티모달 검색, 개인화, RAG 등)에서는 영역-텍스트 결합 이해가 중요하다.

Method: RCVIT(Region-level Context-aware Visual Instruction Tuning):
- 입력에 객체의 텍스트 정보와 바운딩 박스 좌표를 포함시켜 모델이 시각적 영역과 텍스트를 대응시키도록 유도.
- 대규모 RCMU 데이터셋을 구축해 다양한 영역-텍스트 통합 과제를 포함한 시각 명령 튜닝을 수행.
- RC&P-Bench로 RCMU 및 개인화 멀티모달 이해를 평가하며, 레퍼런스 없는 평가 지표로 영역 수준 설명을 정밀 평가.

Result: Qwen2-VL에 RCVIT를 적용해 RC-Qwen2-VL을 얻음. 실험에서 여러 RCMU 태스크에서 우수한 성능을 보였고, 멀티모달 RAG와 개인화 대화 애플리케이션에서도 성공적임을 보고. 데이터·모델·벤치마크·코드 공개.

Conclusion: 객체 텍스트와 바운딩박스 정보를 입력으로 포함하는 접근은 영역 수준의 문맥 인지 멀티모달 이해 능력을 크게 향상시킨다. 제안된 데이터셋과 벤치마크는 해당 분야 연구를 촉진할 수 있으며, 공개 자원은 실무적 응용(검색·RAG·개인화)에 유용하다.

Abstract: Despite significant progress, existing research on Multimodal Large Language
Models (MLLMs) mainly focuses on general visual understanding, overlooking the
ability to integrate textual context associated with objects for a more
context-aware multimodal understanding -- an ability we refer to as
Region-level Context-aware Multimodal Understanding (RCMU). To address this
limitation, we first formulate the RCMU task, which requires models to respond
to user instructions by integrating both image content and textual information
of regions or objects. To equip MLLMs with RCMU capabilities, we propose
Region-level Context-aware Visual Instruction Tuning (RCVIT), which
incorporates object information into the model input and enables the model to
utilize bounding box coordinates to effectively associate objects' visual
content with their textual information. To address the lack of datasets, we
introduce the RCMU dataset, a large-scale visual instruction tuning dataset
that covers multiple RCMU tasks. We also propose RC\&P-Bench, a comprehensive
benchmark that can evaluate the performance of MLLMs in RCMU and multimodal
personalized understanding tasks. Additionally, we propose a reference-free
evaluation metric to perform a comprehensive and fine-grained evaluation of the
region-level context-aware image descriptions. By performing RCVIT on Qwen2-VL
models with the RCMU dataset, we developed RC-Qwen2-VL models. Experimental
results indicate that RC-Qwen2-VL models not only achieve outstanding
performance on multiple RCMU tasks but also demonstrate successful applications
in multimodal RAG and personalized conversation. Our data, model and benchmark
are available at https://github.com/hongliang-wei/RC-MLLM

</details>


### [53] [SNNSIR: A Simple Spiking Neural Network for Stereo Image Restoration](https://arxiv.org/abs/2508.12271)
*Ronghua Xu,Jin Xie,Jing Nie,Jiale Cao,Yanwei Pang*

Main category: cs.CV

TL;DR: 완전 스파이크 기반 SNN 아키텍처 SNNSIR 제안; SRBB, SSCM, SSCA 모듈로 이진 스파이크로도 스테레오 이미지 복원(비·빗방울 제거, 저조도 개선, 초해상도)에서 경쟁력 있는 성능과 낮은 연산 비용 달성.


<details>
  <summary>Details</summary>
Motivation: SNN의 저전력·이벤트 기반 특성으로 실시간 스테레오 복원에 적합하지만 기존 하이브리드 모델은 부동소수 연산을 사용해 하드웨어 비호환성 문제.

Method: 완전 스파이크 기반 구조; SRBB로 잔차 학습, SSCM으로 요소별 곱을 통한 비선형성 및 교차-뷰 강조, SSCA로 뷰 간 쌍방향 스파이크 특성 상호작용 구현.

Result: 다양한 복원 태스크에서 경쟁 성능을 보이면서 연산 오버헤드 크게 감소; 실시간 저전력 응용 가능성 시사.

Conclusion: 이진 스파이크 신경망으로 실용적 스테레오 복원이 가능하며 하드웨어 친화적 설계가 잠재적 영향력.

Abstract: Spiking Neural Networks (SNNs), characterized by discrete binary activations,
offer high computational efficiency and low energy consumption, making them
well-suited for computation-intensive tasks such as stereo image restoration.
In this work, we propose SNNSIR, a simple yet effective Spiking Neural Network
for Stereo Image Restoration, specifically designed under the spike-driven
paradigm where neurons transmit information through sparse, event-based binary
spikes. In contrast to existing hybrid SNN-ANN models that still rely on
operations such as floating-point matrix division or exponentiation, which are
incompatible with the binary and event-driven nature of SNNs, our proposed
SNNSIR adopts a fully spike-driven architecture to achieve low-power and
hardware-friendly computation. To address the expressiveness limitations of
binary spiking neurons, we first introduce a lightweight Spike Residual Basic
Block (SRBB) to enhance information flow via spike-compatible residual
learning. Building on this, the Spike Stereo Convolutional Modulation (SSCM)
module introduces simplified nonlinearity through element-wise multiplication
and highlights noise-sensitive regions via cross-view-aware modulation.
Complementing this, the Spike Stereo Cross-Attention (SSCA) module further
improves stereo correspondence by enabling efficient bidirectional feature
interaction across views within a spike-compatible framework. Extensive
experiments on diverse stereo image restoration tasks, including rain streak
removal, raindrop removal, low-light enhancement, and super-resolution
demonstrate that our model achieves competitive restoration performance while
significantly reducing computational overhead. These results highlight the
potential for real-time, low-power stereo vision applications. The code will be
available after the article is accepted.

</details>


### [54] [TSLA: A Task-Specific Learning Adaptation for Semantic Segmentation on Autonomous Vehicles Platform](https://arxiv.org/abs/2508.12279)
*Jun Liu,Zhenglun Kong,Pu Zhao,Weihao Zeng,Hao Tang,Xuan Shen,Changdi Yang,Wenbin Zhang,Geng Yuan,Wei Niu,Xue Lin,Yanzhi Wang*

Main category: cs.CV

TL;DR: 자율주행 하드웨어 제약(예: NVIDIA DRIVE PX2)에 맞춰 세그멘테이션 네트워크를 동적으로 조정하는 접근을 제안. 폭(width), 분류기 깊이, 분류기 커널의 3단계 제어와 베이지안 최적화를 결합해 MACs와 정확도 사이의 트레이드오프를 탐색하여 Task-Specific Learning Adaptation(TSLA) 구성 생성.


<details>
  <summary>Details</summary>
Motivation: 임베디드 자율주행 플랫폼의 한정된 계산 자원과 시나리오별(작업별) 서로 다른 정밀도 요구를 충족하기 위해 모델을 하드웨어·작업 특성에 맞춰 자동으로 맞춤화할 필요.

Method: (1) 모델 스케일링을 위한 width multiplier, (2) 최종 레이어 정교화를 위한 classifier depth, (3) 시나리오별 최적화를 위한 classifier kernel 크기라는 3가지 제어 변수를 도입. (4) 제한된 계산 예산 안에서 베이지안 최적화(서로게이트 모델)를 사용해 하이퍼파라미터 공간을 효율적으로 탐색하고 MACs 기반의 TSLA 구성을 산출.

Result: 서술된 방법은 다양한 하드웨어 제약과 작업 요구에 맞춘 여러 대체 구성(alternatives)을 도출하고, 하드웨어 이용률과 모델 정확도를 향상시키는 것으로 주장됨(초록에서는 정량적 수치·비교는 제시되지 않음).

Conclusion: 하드웨어 제약을 반영한 자동 맞춤화와 베이지안 탐색의 결합은 실용적 접근이지만, 정량적 평가·재현성·비교 실험이 부족해 기여도를 정확히 판단하려면 추가 정보가 필요하다.

Abstract: Autonomous driving platforms encounter diverse driving scenarios, each with
varying hardware resources and precision requirements. Given the computational
limitations of embedded devices, it is crucial to consider computing costs when
deploying on target platforms like the NVIDIA\textsuperscript{\textregistered}
DRIVE PX 2. Our objective is to customize the semantic segmentation network
according to the computing power and specific scenarios of autonomous driving
hardware. We implement dynamic adaptability through a three-tier control
mechanism -- width multiplier, classifier depth, and classifier kernel --
allowing fine-grained control over model components based on hardware
constraints and task requirements. This adaptability facilitates broad model
scaling, targeted refinement of the final layers, and scenario-specific
optimization of kernel sizes, leading to improved resource allocation and
performance.
  Additionally, we leverage Bayesian Optimization with surrogate modeling to
efficiently explore hyperparameter spaces under tight computational budgets.
Our approach addresses scenario-specific and task-specific requirements through
automatic parameter search, accommodating the unique computational complexity
and accuracy needs of autonomous driving. It scales its Multiply-Accumulate
Operations (MACs) for Task-Specific Learning Adaptation (TSLA), resulting in
alternative configurations tailored to diverse self-driving tasks. These TSLA
customizations maximize computational capacity and model accuracy, optimizing
hardware utilization.

</details>


### [55] [CLAIR: CLIP-Aided Weakly Supervised Zero-Shot Cross-Domain Image Retrieval](https://arxiv.org/abs/2508.12290)
*Chor Boon Tan,Conghui Hu,Gim Hee Lee*

Main category: cs.CV

TL;DR: CLIP 기반의 노이즈한 의사 라벨을 신뢰도 점수로 정제하고, 인스턴스·클러스터·도메인 단위의 대조 손실과 CLIP 텍스트 임베딩을 이용한 닫힌형 크로스도메인 사상으로 이미지 피처를 정렬해 제로샷 크로스도메인 이미지 검색 성능을 개선한 방법(CLAIR).


<details>
  <summary>Details</summary>
Motivation: 대규모 파운데이션 모델(예: CLIP)이 생성한 방대한 의사 라벨은 유용하지만 노이즈가 많아 기존의 완전 비지도 ZS-CDIR 접근이 한계를 갖는다. 따라서 노이즈를 감안한 약지도(weakly supervised) 설정에서 라벨 정제와 도메인 정렬이 필요함.

Method: (1) CLIP 텍스트·이미지 유사도 기반의 신뢰도 점수로 의사 라벨을 정제, (2) 클래스 인지(class-aware) 잠재공간을 만들기 위한 inter-instance 및 inter-cluster 대조 손실, (3) 도메인 차이를 완화하는 inter-domain 대조 손실, (4) CLIP 텍스트 임베딩만으로 이미지 피처를 한 도메인에서 다른 도메인으로 사영하는 닫힌형(cosed-form) 크로스도메인 매핑 학습, (5) 제로샷 일반화를 위한 추가 학습 가능한 프롬프트 도입.

Result: TUBerlin, Sketchy, Quickdraw, DomainNet의 제로샷 실험에서 기존 SOTA 대비 일관된 성능 향상 보고.

Conclusion: CLIP 기반 의사 라벨의 신뢰도 보정과 다중 수준의 대조 학습, 텍스트 기반 닫힌형 매핑 및 프롬프트 학습을 결합하면 노이즈한 의사 라벨 환경에서 WSZS-CDIR 성능을 크게 향상시킬 수 있다.

Abstract: The recent growth of large foundation models that can easily generate
pseudo-labels for huge quantity of unlabeled data makes unsupervised Zero-Shot
Cross-Domain Image Retrieval (UZS-CDIR) less relevant. In this paper, we
therefore turn our attention to weakly supervised ZS-CDIR (WSZS-CDIR) with
noisy pseudo labels generated by large foundation models such as CLIP. To this
end, we propose CLAIR to refine the noisy pseudo-labels with a confidence score
from the similarity between the CLIP text and image features. Furthermore, we
design inter-instance and inter-cluster contrastive losses to encode images
into a class-aware latent space, and an inter-domain contrastive loss to
alleviate domain discrepancies. We also learn a novel cross-domain mapping
function in closed-form, using only CLIP text embeddings to project image
features from one domain to another, thereby further aligning the image
features for retrieval. Finally, we enhance the zero-shot generalization
ability of our CLAIR to handle novel categories by introducing an extra set of
learnable prompts. Extensive experiments are carried out using TUBerlin,
Sketchy, Quickdraw, and DomainNet zero-shot datasets, where our CLAIR
consistently shows superior performance compared to existing state-of-the-art
methods.

</details>


### [56] [Improving Densification in 3D Gaussian Splatting for High-Fidelity Rendering](https://arxiv.org/abs/2508.12313)
*Xiaobin Deng,Changyu Diao,Min Li,Ruohan Yu,Duanqing Xu*

Main category: cs.CV

TL;DR: 3D Gaussian Splatting의 densification 파이프라인을 세 가지(언제, 어떻게, 과적합 완화) 관점에서 개선해 Edge-Aware Score로 분할 후보를 선별하고 Long-Axis Split으로 기하 왜곡을 줄이며 Recovery-Aware Pruning, Multi-step Update, Growth Control로 과적합을 막아 적은 가우시안으로 SOTA 성능을 달성한다.


<details>
  <summary>Details</summary>
Motivation: 기존 3DGS의 densification(가우시안 증식/분할) 방식이 단순하거나 무차별적으로 이루어져 재구성 품질이 떨어지고 과적합이 발생하기 쉬움. 실시간 렌더링 성능을 유지하면서 더 적은 수의 가우시안으로 더 높은 시각 품질을 얻고자 함.

Method: 1) Edge-Aware Score: 경계/엣지 정보를 반영해 분할 대상 가우시안을 효과적으로 선별. 2) Long-Axis Split: 클론/스플릿 과정에서 기하학적 왜곡을 줄이기 위해 장축을 따라 분할. 3) Overfitting 완화: Recovery-Aware Pruning(복구 가능성을 고려한 가지치기), Multi-step Update(다단계 갱신으로 안정화), Growth Control(성장 제어) 등을 도입.

Result: 추가적인 학습이나 추론 오버헤드 없이 렌더링 충실도 향상. 가우시안 수를 줄이면서 SOTA 성능 달성(실험적으로 개선된 재구성 품질과 효율성 보고).

Conclusion: densification 전략의 정교한 설계(선별, 분할 방식, 과적합 제어)를 통해 3DGS의 품질-효율 균형을 개선할 수 있으며, 적은 가우시안으로 실시간 영역에서 높은 재구성 품질을 달성한다.

Abstract: Although 3D Gaussian Splatting (3DGS) has achieved impressive performance in
real-time rendering, its densification strategy often results in suboptimal
reconstruction quality. In this work, we present a comprehensive improvement to
the densification pipeline of 3DGS from three perspectives: when to densify,
how to densify, and how to mitigate overfitting. Specifically, we propose an
Edge-Aware Score to effectively select candidate Gaussians for splitting. We
further introduce a Long-Axis Split strategy that reduces geometric distortions
introduced by clone and split operations. To address overfitting, we design a
set of techniques, including Recovery-Aware Pruning, Multi-step Update, and
Growth Control. Our method enhances rendering fidelity without introducing
additional training or inference overhead, achieving state-of-the-art
performance with fewer Gaussians.

</details>


### [57] [Neural Cellular Automata for Weakly Supervised Segmentation of White Blood Cells](https://arxiv.org/abs/2508.12322)
*Michael Deutges,Chen Yang,Raheleh Salehi,Nassir Navab,Carsten Marr,Ario Sadafi*

Main category: cs.CV

TL;DR: NCA-WSS는 분류에 사용한 신경세포자동자(NCA)의 특징 맵을 이용해 재학습 없이 약지도(weakly supervised) 분할 마스크를 추출하는 방법으로, 세 개의 백혈구 데이터셋에서 기존 약지도 기법들보다 성능이 우수하다고 보고한다.


<details>
  <summary>Details</summary>
Motivation: 의료 영상에서 백혈구 검출·분할은 진단에 필수적이지만 높은 품질의 분할 라벨은 획득 비용이 크고 시간 소모적이다. 따라서 라벨 비용을 줄이면서도 신뢰할 만한 분할을 얻는 약지도 접근이 필요하다.

Method: 분류 목적으로 학습된 NCA의 내부 feature map을 활용하여 별도의 분할용 재학습 없이 마스크를 추출하는 파이프라인(NCA-WSS)을 제안한다. 구체적 추출 방법(예: 특징 선택, 임계치 처리, 후처리)은 초록에서 구체적으로 기술되지는 않았으나 NCA의 특성 맵을 직접 활용하는 점이 핵심이다.

Result: 세 가지 백혈구 현미경 데이터셋에서 평가하여 기존 약지도 분할 기법들보다 유의미하게 높은 성능을 보고한다(정량적 수치와 통계적 유의성은 초록에 없음).

Conclusion: NCA는 분류뿐 아니라 약지도 분할에서도 유용하며, 라벨 비용을 줄이고 확장 가능한 의료 영상 분석 솔루션으로 활용될 수 있음을 시사한다.

Abstract: The detection and segmentation of white blood cells in blood smear images is
a key step in medical diagnostics, supporting various downstream tasks such as
automated blood cell counting, morphological analysis, cell classification, and
disease diagnosis and monitoring. Training robust and accurate models requires
large amounts of labeled data, which is both time-consuming and expensive to
acquire. In this work, we propose a novel approach for weakly supervised
segmentation using neural cellular automata (NCA-WSS). By leveraging the
feature maps generated by NCA during classification, we can extract
segmentation masks without the need for retraining with segmentation labels. We
evaluate our method on three white blood cell microscopy datasets and
demonstrate that NCA-WSS significantly outperforms existing weakly supervised
approaches. Our work illustrates the potential of NCA for both classification
and segmentation in a weakly supervised framework, providing a scalable and
efficient solution for medical image analysis.

</details>


### [58] [Attention Pooling Enhances NCA-based Classification of Microscopy Images](https://arxiv.org/abs/2508.12324)
*Chen Yang,Michael Deutges,Jingsong Liu,Han Li,Nassir Navab,Carsten Marr,Ario Sadafi*

Main category: cs.CV

TL;DR: NCA에 어텐션 풀링을 결합해 현미경 이미지 분류 성능을 개선했다. 파라미터 효율적이며 설명 가능성을 유지하면서 기존 NCA 및 경량 CNN/ViT보다 우수한 성능을 보였다고 주장.


<details>
  <summary>Details</summary>
Motivation: NCA는 해석 가능하고 견고하지만 더 큰 모델들에 비해 분류 성능에서 열세다. 특히 미시경 이미지 분석 분야에서 성능을 끌어올리면서 모델의 설명 가능성과 파라미터 효율성을 유지할 필요가 있다.

Method: NCA 아키텍처에 어텐션 풀링 모듈을 통합하여 중요한 영역에 가중치를 집중시키는 방식으로 특징 추출을 개선. 8개의 다양한 현미경 이미지 데이터셋에서 실험하여 기존 NCA, 경량 CNN, 경량 ViT와 비교 평가.

Result: 어텐션 풀링을 결합한 NCA가 기존 NCA 방법들을 유의미하게 능가했으며, 경량 CNN/ViT보다 높은 성능을 보이면서도 파라미터 수는 훨씬 적었다고 보고.

Conclusion: 어텐션 풀링을 적용한 NCA는 설명 가능성과 파라미터 효율성을 유지하면서 현미경 이미지 분류에서 경쟁력 있는 대안이 될 수 있다.

Abstract: Neural Cellular Automata (NCA) offer a robust and interpretable approach to
image classification, making them a promising choice for microscopy image
analysis. However, a performance gap remains between NCA and larger, more
complex architectures. We address this challenge by integrating attention
pooling with NCA to enhance feature extraction and improve classification
accuracy. The attention pooling mechanism refines the focus on the most
informative regions, leading to more accurate predictions. We evaluate our
method on eight diverse microscopy image datasets and demonstrate that our
approach significantly outperforms existing NCA methods while remaining
parameter-efficient and explainable. Furthermore, we compare our method with
traditional lightweight convolutional neural network and vision transformer
architectures, showing improved performance while maintaining a significantly
lower parameter count. Our results highlight the potential of NCA-based models
an alternative for explainable image classification.

</details>


### [59] [DoppDrive: Doppler-Driven Temporal Aggregation for Improved Radar Object Detection](https://arxiv.org/abs/2508.12330)
*Yuval Haitman,Oded Bialer*

Main category: cs.CV

TL;DR: 도플러 정보를 이용해 과거 프레임의 점들을 반경 방향으로 보정하고 각 점에 도플러·각도 기반의 고유한 집계 지속시간을 부여해 횡방향 산란을 최소화하는 사전 점군 밀도 향상 기법. 검출기와 독립적으로 적용 가능하며 여러 데이터셋과 검출기에서 검출 성능을 유의미하게 향상시킴.


<details>
  <summary>Details</summary>
Motivation: 레이더는 장거리 검출에 유리하지만 장거리에서 점군이 매우 희박해 물체 검출 성능이 저하된다. 기존의 시간적 집계(ego-motion 보정 포함)는 동적 물체 때문에 방사상·횡방향의 산란(scatter)을 유발해 성능을 떨어뜨린다.

Method: DoppDrive는 이전 프레임 점들을 각 점의 동적 도플러 성분에 따라 반경 방향으로 이동시켜 방사상 산란을 제거한다. 추가로 각 점에 대해 도플러와 관측 각도에 기반한 고유한 집계 지속시간을 할당해 횡방향 산란을 최소화한다. 이 과정은 검출기 앞단의 점군 밀도 향상 단계로 설계되어 어떤 검출기에도 적용 가능하다.

Result: 여러 검출기와 데이터셋에서 적용 시 점군 밀도가 증가하고, 동적 물체로 인한 산란이 감소하며, 최종 물체 검출 성능이 유의미하게 향상됨을 보고함.

Conclusion: 도플러 기반 보정과 점별 집계 지속시간 전략은 레이더 점군의 시간적 집계를 보다 정확하게 만들어 검출 성능을 높인다. 다만 도플러 측정 오차, 복잡한 비선형 운동, 부분 가림/새로운 등장 등 현실적 조건에서의 한계와 런타임·파라미터 민감도는 추가 검증이 필요하다.

Abstract: Radar-based object detection is essential for autonomous driving due to
radar's long detection range. However, the sparsity of radar point clouds,
especially at long range, poses challenges for accurate detection. Existing
methods increase point density through temporal aggregation with ego-motion
compensation, but this approach introduces scatter from dynamic objects,
degrading detection performance. We propose DoppDrive, a novel Doppler-Driven
temporal aggregation method that enhances radar point cloud density while
minimizing scatter. Points from previous frames are shifted radially according
to their dynamic Doppler component to eliminate radial scatter, with each point
assigned a unique aggregation duration based on its Doppler and angle to
minimize tangential scatter. DoppDrive is a point cloud density enhancement
step applied before detection, compatible with any detector, and we demonstrate
that it significantly improves object detection performance across various
detectors and datasets.

</details>


### [60] [Geometry-Aware Video Inpainting for Joint Headset Occlusion Removal and Face Reconstruction in Social XR](https://arxiv.org/abs/2508.12336)
*Fatemeh Ghorbani Lohesara,Karen Eguiazarian,Sebastian Knorr*

Main category: cs.CV

TL;DR: HMD로 가려진 얼굴을 단일 뷰 RGB 영상에서 복원하고 3D 얼굴 기하를 재구성하는 프레임워크. GAN 기반 비디오 인페인팅(밀집 랜드마크 + 한 장의 비가림 프레임 참조)으로 외형을 복원하고, SynergyNet 기반 모듈로 3DMM 파라미터를 회귀시켜 완전한 3D 얼굴을 얻음. 밀집 랜드마크 최적화로 인페인팅과 기하 복원 품질 향상.


<details>
  <summary>Details</summary>
Motivation: HMD가 얼굴 상부를 가려 사회적 XR(원격회의 등)에서 표정·시선 정보 손실로 몰입감과 의사소통에 큰 제약을 줌. 단일 뷰 RGB로 현실적인 복원과 3D 재구성이 필요함.

Method: GAN 기반 비디오 인페인팅(밀집 랜드마크와 단일 비가림 자유 참조 프레임 가이드) → SynergyNet 계열의 3DMM 파라미터 회귀 모듈로 프레임별 3D 재구성 → 전체 파이프라인에서 밀집 랜드마크 최적화 반복 적용으로 품질 향상.

Result: RGB 영상에서 HMD 제거와 신원 보존을 동시에 달성하며 포토리얼한 3D 얼굴 기하를 산출. 희소 랜드마크 상황에서도 소폭 품질 저하로 견고함을 보임.

Conclusion: 밀집 랜드마크와 참조 기반 비디오 인페인팅을 3DMM 회귀와 결합하면 단일 뷰 영상에서 실용적인 HMD 제거 및 3D 얼굴 복원이 가능하며, 랜드마크 밀도 변화에 대해 비교적 강건하다.

Abstract: Head-mounted displays (HMDs) are essential for experiencing extended reality
(XR) environments and observing virtual content. However, they obscure the
upper part of the user's face, complicating external video recording and
significantly impacting social XR applications such as teleconferencing, where
facial expressions and eye gaze details are crucial for creating an immersive
experience. This study introduces a geometry-aware learning-based framework to
jointly remove HMD occlusions and reconstruct complete 3D facial geometry from
RGB frames captured from a single viewpoint. The method integrates a GAN-based
video inpainting network, guided by dense facial landmarks and a single
occlusion-free reference frame, to restore missing facial regions while
preserving identity. Subsequently, a SynergyNet-based module regresses 3D
Morphable Model (3DMM) parameters from the inpainted frames, enabling accurate
3D face reconstruction. Dense landmark optimization is incorporated throughout
the pipeline to improve both the inpainting quality and the fidelity of the
recovered geometry. Experimental results demonstrate that the proposed
framework can successfully remove HMDs from RGB facial videos while maintaining
facial identity and realism, producing photorealistic 3D face geometry outputs.
Ablation studies further show that the framework remains robust across
different landmark densities, with only minor quality degradation under sparse
landmark configurations.

</details>


### [61] [Semantic Discrepancy-aware Detector for Image Forgery Identification](https://arxiv.org/abs/2508.12341)
*Ziye Wang,Minghang Yu,Chunyan Xu,Zhen Cui*

Main category: cs.CV

TL;DR: 제안된 SDD는 시각적 재구성 기반으로 사기(위조) 증거와 사전학습 비전-언어 모델의 의미 개념 공간을 정렬해 위조 이미지 검출 성능을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 사전학습 모델이 보유한 의미 개념은 위조 이미지 식별에 유용하지만, 위조 특징 공간과 의미 개념 공간 간의 불일치가 검출 성능을 저해한다는 문제의식에서 출발한다.

Method: (1) 의미 토큰 샘플링 모듈로 비(非)관련 특징을 제거해 공간 이동을 완화, (2) 시각적 재구성 패러다임 기반의 개념 수준 위조 불일치 학습 모듈로 의미 개념과 위조 흔적의 상호작용을 강화, (3) 저수준 위조 특징 강화기로 학습된 개념 수준 불일치를 통합하여 불필요한 위조 정보를 최소화한다.

Result: 두 개의 표준 이미지 위조 데이터셋에서 기존 방법들보다 우수한 성능을 달성했다(구체적 수치 미기재). 코드 공개 링크 제공.

Conclusion: 의미 개념과 위조 흔적의 세밀한 정렬이 위조 검출 성능을 개선하며, SDD는 이 정렬을 재구성 학습으로 효과적으로 달성한다.

Abstract: With the rapid advancement of image generation techniques, robust forgery
detection has become increasingly imperative to ensure the trustworthiness of
digital media. Recent research indicates that the learned semantic concepts of
pre-trained models are critical for identifying fake images. However, the
misalignment between the forgery and semantic concept spaces hinders the
model's forgery detection performance. To address this problem, we propose a
novel Semantic Discrepancy-aware Detector (SDD) that leverages reconstruction
learning to align the two spaces at a fine-grained visual level. By exploiting
the conceptual knowledge embedded in the pre-trained vision language model, we
specifically design a semantic token sampling module to mitigate the space
shifts caused by features irrelevant to both forgery traces and semantic
concepts. A concept-level forgery discrepancy learning module, built upon a
visual reconstruction paradigm, is proposed to strengthen the interaction
between visual semantic concepts and forgery traces, effectively capturing
discrepancies under the concepts' guidance. Finally, the low-level forgery
feature enhancemer integrates the learned concept level forgery discrepancies
to minimize redundant forgery information. Experiments conducted on two
standard image forgery datasets demonstrate the efficacy of the proposed SDD,
which achieves superior results compared to existing methods. The code is
available at https://github.com/wzy1111111/SSD.

</details>


### [62] [AquaFeat: A Features-Based Image Enhancement Model for Underwater Object Detection](https://arxiv.org/abs/2508.12343)
*Emanuel C. Silva,Tatiana T. Schein,Stephanie L. Brião,Guilherme L. M. Costa,Felipe G. Oliveira,Gustavo P. Almeida,Eduardo L. Silva,Sam S. Devincenzi,Karina S. Machado,Paulo L. J. Drews-Jr*

Main category: cs.CV

TL;DR: AquaFeat는 탐지기 손실과 함께 엔드투엔드로 학습되는 멀티스케일의 플러그인 특성 향상 모듈로, 수중 영상의 열화를 탐지 친화적 특징으로 보정하여 YOLOv8m과 결합 시 높은 정밀도·재현율과 실시간 처리 속도(46.5 FPS)를 달성한다.


<details>
  <summary>Details</summary>
Motivation: 수중 환경에서의 심한 영상 열화는 객체 탐지 성능을 크게 저해하며, 기존의 화질 개선 방법은 탐지 성능을 직접 최적화하지 않아 다운스트림 성능 향상에 한계가 있다. 따라서 탐지 과제에 직접적으로 기여하는 특성 수준의 개선이 필요하다.

Method: 멀티스케일 특성 향상 네트워크를 플러그인 형태로 제안하고, 탐지기의 손실과 함께 엔드투엔드로 학습시켜(탐지 손실에 의해 향상 과정이 직접 지도됨) 탐지에 중요한 특징을 선택적으로 정제한다. YOLOv8m에 통합하여 실험을 수행했다.

Result: 도전적인 수중 데이터셋에서 Precision 0.877, Recall 0.624를 기록하여 최첨단 성능을 달성했고, mAP@0.5=0.677, mAP@[0.5:0.95]=0.421의 경쟁력 있는 성능을 보였다. 처리 속도는 46.5 FPS로 실용적이다.

Conclusion: AquaFeat는 수중 객체 탐지를 위해 설계된 효율적이고 실용적인 특성 수준의 향상 모듈로, 정확도와 속도 모두를 만족시켜 해양 생태계 모니터링 및 인프라 점검 같은 실제 응용에 적합하다.

Abstract: The severe image degradation in underwater environments impairs object
detection models, as traditional image enhancement methods are often not
optimized for such downstream tasks. To address this, we propose AquaFeat, a
novel, plug-and-play module that performs task-driven feature enhancement. Our
approach integrates a multi-scale feature enhancement network trained
end-to-end with the detector's loss function, ensuring the enhancement process
is explicitly guided to refine features most relevant to the detection task.
When integrated with YOLOv8m on challenging underwater datasets, AquaFeat
achieves state-of-the-art Precision (0.877) and Recall (0.624), along with
competitive mAP scores (mAP@0.5 of 0.677 and mAP@[0.5:0.95] of 0.421). By
delivering these accuracy gains while maintaining a practical processing speed
of 46.5 FPS, our model provides an effective and computationally efficient
solution for real-world applications, such as marine ecosystem monitoring and
infrastructure inspection.

</details>


### [63] [MBMamba: When Memory Buffer Meets Mamba for Structure-Aware Image Deblurring](https://arxiv.org/abs/2508.12346)
*Hu Gao,Depeng Dang*

Main category: cs.CV

TL;DR: Mamba 아키텍처의 flatten-and-scan 한계(국소 픽셀 망각·채널 중복)를 바꾸지 않고 메모리 버퍼와 Ising 영감 정규화 손실을 추가해 구조 보존·공간 정보 집계를 개선한 MBMamba를 제안, 벤치마크에서 SOTA를 능가함.


<details>
  <summary>Details</summary>
Motivation: Mamba의 flatten-and-scan 전략은 2D 공간 정보 집계에 취약해 국소 정보 소실과 채널 중복을 초래한다. 기존 해결책은 스캔 전략이나 지역 모듈을 수정하지만 계산 비용이 커져 실시간 성능에 불리하다.

Method: 원본 Mamba 아키텍처를 변경하지 않고(1) 과거 특징을 보존·융합하는 메모리 버퍼 메커니즘을 설계해 인접 특징 간 관련성 모델링을 강화하고, (2) 픽셀 간 '상호 인력(mutual attraction)'을 물리 시스템의 에너지 최소화 관점에서 모사한 Ising-영감 정규화 손실을 도입해 이미지 구조와 일관성을 유지하도록 유도. 이를 결합한 네트워크 MBMamba를 제시.

Result: 제안된 방법이 널리 사용되는 디블러링 벤치마크에서 기존 최첨단 기법들을 능가하는 성능을 보였음(정량적 비교와 실험 결과 제시됨).

Conclusion: 원래 Mamba 구조를 변경하지 않으면서 메모리 버퍼와 Ising 기반 정규화로 구조 보존을 달성하여 성능·효율성 측면에서 개선된 이미지 디블러링 모델 MBMamba를 제안함.

Abstract: The Mamba architecture has emerged as a promising alternative to CNNs and
Transformers for image deblurring. However, its flatten-and-scan strategy often
results in local pixel forgetting and channel redundancy, limiting its ability
to effectively aggregate 2D spatial information. Although existing methods
mitigate this by modifying the scan strategy or incorporating local feature
modules, it increase computational complexity and hinder real-time performance.
In this paper, we propose a structure-aware image deblurring network without
changing the original Mamba architecture. Specifically, we design a memory
buffer mechanism to preserve historical information for later fusion, enabling
reliable modeling of relevance between adjacent features. Additionally, we
introduce an Ising-inspired regularization loss that simulates the energy
minimization of the physical system's "mutual attraction" between pixels,
helping to maintain image structure and coherence. Building on this, we develop
MBMamba. Experimental results show that our method outperforms state-of-the-art
approaches on widely used benchmarks.

</details>


### [64] [EgoLoc: A Generalizable Solution for Temporal Interaction Localization in Egocentric Videos](https://arxiv.org/abs/2508.12349)
*Junyi Ma,Erhang Zhang,Yin-Dong Zheng,Yuchen Xie,Yixuan Zhou,Hesheng Wang*

Main category: cs.CV

TL;DR: EgoLoc은 손-물체 접촉/분리 시점을 제로샷으로 국지화하는 방법으로, 손 동작 기반 샘플링과 비전-언어 모델을 결합해 마스크나 동사-명사 분류 없이 타임스탬프를 찾아내고 반복적 피드백으로 정제한다. 공개 데이터셋과 새 벤치에서 타당성을 보였으며 VR/AR 및 로보틱스 응용에서 유용함을 보였다.


<details>
  <summary>Details</summary>
Motivation: 몰입형 MR과 로봇 모션 플래닝에는 ‘어떨게’ 상호작용하는지뿐 아니라 ‘언제’ 접촉/분리가 발생하는지의 정밀한 시점 정보가 중요하다. 기존 연구는 주로 행동 패러다임(어떻게)이나 물체 마스크·카테고리 의존(정확한 접지 어려움)에 집중해 시점 국지화 문제(TIL)를 충분히 다루지 못함.

Method: 핵심은 손-동역학(손 움직임) 기반 샘플링으로 고품질의 시각적 프롬프트를 생성하고, 비전-언어 모델을 사용해 접촉/분리 속성(언제)을 판단·로컬라이즈한 뒤 폐쇄루프 피드백으로 타임스탬프를 정제하는 제로샷 파이프라인.

Result: 마스크나 동사-명사 어휘가 없어도 공개 데이터와 저자 제공 벤치에서 타당한 TIL 성능을 달성했고, 여러 후속 egocentric·로보틱 응용에서 효과를 입증함.

Conclusion: EgoLoc은 범용적 제로샷 접근으로 손-물체 접촉/분리 시점을 정밀하게 찾을 수 있어 MR 경험과 로봇 조작 전이에서 유용하며 코드·데이터 공개 예정.

Abstract: Analyzing hand-object interaction in egocentric vision facilitates VR/AR
applications and human-robot policy transfer. Existing research has mostly
focused on modeling the behavior paradigm of interactive actions (i.e., ``how
to interact''). However, the more challenging and fine-grained problem of
capturing the critical moments of contact and separation between the hand and
the target object (i.e., ``when to interact'') is still underexplored, which is
crucial for immersive interactive experiences in mixed reality and robotic
motion planning. Therefore, we formulate this problem as temporal interaction
localization (TIL). Some recent works extract semantic masks as TIL references,
but suffer from inaccurate object grounding and cluttered scenarios. Although
current temporal action localization (TAL) methods perform well in detecting
verb-noun action segments, they rely on category annotations during training
and exhibit limited precision in localizing hand-object contact/separation
moments. To address these issues, we propose a novel zero-shot approach dubbed
EgoLoc to localize hand-object contact and separation timestamps in egocentric
videos. EgoLoc introduces hand-dynamics-guided sampling to generate
high-quality visual prompts. It exploits the vision-language model to identify
contact/separation attributes, localize specific timestamps, and provide
closed-loop feedback for further refinement. EgoLoc eliminates the need for
object masks and verb-noun taxonomies, leading to generalizable zero-shot
implementation. Comprehensive experiments on the public dataset and our novel
benchmarks demonstrate that EgoLoc achieves plausible TIL for egocentric
videos. It is also validated to effectively facilitate multiple downstream
applications in egocentric vision and robotic manipulation tasks. Code and
relevant data will be released at https://github.com/IRMVLab/EgoLoc.

</details>


### [65] [Synthetic Data is Sufficient for Zero-Shot Visual Generalization from Offline Data](https://arxiv.org/abs/2508.12356)
*Ahmet H. Güzel,Ilija Bogunovic,Jack Parker-Holder*

Main category: cs.CV

TL;DR: 오프라인 비전 기반 강화학습에서 데이터 다양성 부족으로 인한 일반화 실패를, 원본 데이터 증강 + 잠재공간에서의 확산모델을 이용한 합성 데이터 생성의 두 단계 방법으로 해결하여 Visual D4RL(연속)과 Procgen(이산)에서 일반화 성능을 크게 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 오프라인 RL 에이전트는 수집된 데이터에만 의존하므로 시각적 잡음·방해·우연 상관관계 등으로 인해 다양한 상태를 접하지 못하면 일반화에 실패하기 쉬움. 비전 기반 데이터의 복잡성은 과적합 위험을 높이며, 이를 완화할 추가적인 다양한 학습 데이터가 필요함.

Method: (1) 원본 오프라인 데이터를 다양성 향상 목적의 데이터 증강을 통해 먼저 확장하여 제로샷 일반화를 개선하고, (2) 이어서 잠재공간(latent space)에서 확산(diffusion) 모델을 사용해 추가 합성 데이터를 생성하여 학습 데이터 풀을 더욱 확장함. 기존 모델-프리 오프라인 RL 알고리즘에는 구조적 변경을 가하지 않음.

Result: Visual D4RL(연속 액션)과 Procgen(이산 액션) 환경에서 합성 데이터가 포함된 학습이 일반화 성능을 크게 향상시키고 테스트 시 일반화 격차를 줄였으며, 계산 효율성도 유지함을 보였음.

Conclusion: 단순한 두 단계 데이터 생성 프로세스가 비전 기반 오프라인 RL의 일반화 문제를 완화하며, 합성 데이터 생성이 향후 더 일반적인 에이전트 학습에 유용한 방향임을 시사함.

Abstract: Offline reinforcement learning (RL) offers a promising framework for training
agents using pre-collected datasets without the need for further environment
interaction. However, policies trained on offline data often struggle to
generalise due to limited exposure to diverse states. The complexity of visual
data introduces additional challenges such as noise, distractions, and spurious
correlations, which can misguide the policy and increase the risk of
overfitting if the training data is not sufficiently diverse. Indeed, this
makes it challenging to leverage vision-based offline data in training robust
agents that can generalize to unseen environments. To solve this problem, we
propose a simple approach generating additional synthetic training data. We
propose a two-step process, first augmenting the originally collected offline
data to improve zero-shot generalization by introducing diversity, then using a
diffusion model to generate additional data in latent space. We test our method
across both continuous action spaces (Visual D4RL) and discrete action spaces
(Procgen), demonstrating that it significantly improves generalization without
requiring any algorithmic changes to existing model-free offline RL methods. We
show that our method not only increases the diversity of the training data but
also significantly reduces the generalization gap at test time while
maintaining computational efficiency. We believe this approach could fuel
additional progress in generating synthetic data to train more general agents
in the future.

</details>


### [66] [IPGPhormer: Interpretable Pathology Graph-Transformer for Survival Analysis](https://arxiv.org/abs/2508.12381)
*Guo Tang,Songhan Jiang,Jinpeng Lu,Linghan Cai,Yongbing Zhang*

Main category: cs.CV

TL;DR: IPGPhormer는 그래프와 트랜스포머를 결합해 조직학적 패치 간 장·단거리 공간관계를 모델링하고, 조직·세포 수준의 해석가능성을 자동으로 제공하여 WSI 기반 생존분석에서 SOTA 성능을 달성한 방법이다.


<details>
  <summary>Details</summary>
Motivation: 기존 다중 인스턴스 러닝 기반 생존분석은 장거리 공간관계와 지역 문맥을 동시에 잘 포착하지 못하고, 임상 활용에 필요한 내재적 해석력을 갖추지 못했다. 임상 신뢰도를 높이기 위해 공간적 의존성과 미세환경 특징을 통합해 자동 해석 가능한 모델이 필요하다.

Method: IPGPhormer는 WSI의 패치/세포 수준 표현을 그래프로 구성하고, 그래프 구조를 트랜스포머로 처리해 장거리 및 지역 의존성을 동시에 모델링한다. 추가로 조직·세포 수준의 중요도·상호작용 지표를 출력해 포스트호크 주석 없이 해석성을 제공한다.

Result: 4개의 공개 벤치마크 데이터셋에서 기존 방법들보다 예측 정확도와 해석가능성 지표 모두에서 우수한 성능을 보고함. WSI 단위 및 코호트 간 분석에서 세부적인 기여요인 확인이 가능하다고 주장.

Conclusion: IPGPhormer는 생존 예측 성능과 해석가능성을 동시에 향상시킨 유망한 도구로, 병리학적 의사결정지원 시스템에 기여할 수 있으나 해석성 검증·일반화성 관련 추가 평가가 필요하다.

Abstract: Pathological images play an essential role in cancer prognosis, while
survival analysis, which integrates computational techniques, can predict
critical clinical events such as patient mortality or disease recurrence from
whole-slide images (WSIs). Recent advancements in multiple instance learning
have significantly improved the efficiency of survival analysis. However,
existing methods often struggle to balance the modeling of long-range spatial
relationships with local contextual dependencies and typically lack inherent
interpretability, limiting their clinical utility. To address these challenges,
we propose the Interpretable Pathology Graph-Transformer (IPGPhormer), a novel
framework that captures the characteristics of the tumor microenvironment and
models their spatial dependencies across the tissue. IPGPhormer uniquely
provides interpretability at both tissue and cellular levels without requiring
post-hoc manual annotations, enabling detailed analyses of individual WSIs and
cross-cohort assessments. Comprehensive evaluations on four public benchmark
datasets demonstrate that IPGPhormer outperforms state-of-the-art methods in
both predictive accuracy and interpretability. In summary, our method,
IPGPhormer, offers a promising tool for cancer prognosis assessment, paving the
way for more reliable and interpretable decision-support systems in pathology.
The code is publicly available at
https://anonymous.4open.science/r/IPGPhormer-6EEB.

</details>


### [67] [ViT-EnsembleAttack: Augmenting Ensemble Models for Stronger Adversarial Transferability in Vision Transformers](https://arxiv.org/abs/2508.12384)
*Hanwen Cao,Haobo Lu,Xiaosen Wang,Kun He*

Main category: cs.CV

TL;DR: ViT-EnsembleAttack: surrogate ViT들에 대한 적대적 증강(adversarial augmentation)을 통해 앙상블 모델의 일반화와 전이성(transferability)을 높이는 방법을 제안. Multi-head dropping, attention score scaling, MLP feature mixing의 세 전략으로 증강된 모델들을 베이지안 최적화로 파라미터를 찾아 앙상블하고, 자동 재가중치(Automatic Reweighting)와 스텝 사이즈 확대 모듈을 도입해 전이 공격 성능을 크게 향상시킴.


<details>
  <summary>Details</summary>
Motivation: 기존 앙상블 기반 공격은 앙상블 가중치나 경로 최적화에는 주목했으나, 앙상블에 사용되는 개별 모델들의 다양성(또는 탐색)을 확대하여 전이성을 개선하는 시도는 부족함. 특히 ViT에 특화된 앙상블 공격 연구가 미흡하여 이를 보완하려는 목적.

Method: 각 예비(서로게이트) ViT에 대해 세 가지 적대적 증강을 적용: (1) Multi-head dropping: 일부 헤드 제거로 다양성 유발, (2) Attention score scaling: 어텐션 스코어 조정으로 행동 변화 유도, (3) MLP feature mixing: MLP 특성 혼합으로 표현 변형. 각 증강의 파라미터는 베이지안 최적화로 탐색. 이렇게 생성된 증강 모델들을 앙상블해 적대적 예시를 생성하고, 자동 재가중치 및 스텝 사이즈 확대 모듈로 전이성을 추가 향상.

Result: 광범위한 실험에서 ViT-EnsembleAttack이 기존 방법들보다 ViT에 대한 적대적 전이성에서 큰 폭의 성능 향상을 보였음(구체적 수치 요약 없음). 공개 코드 제공.

Conclusion: ViT 특화의 적대적 증강 기반 앙상블 공격은 앙상블 모델의 일반화와 전이성을 실질적으로 개선하며, ViT에 대한 전이 공격 연구의 새로운 방향을 제시함.

Abstract: Ensemble-based attacks have been proven to be effective in enhancing
adversarial transferability by aggregating the outputs of models with various
architectures. However, existing research primarily focuses on refining
ensemble weights or optimizing the ensemble path, overlooking the exploration
of ensemble models to enhance the transferability of adversarial attacks. To
address this gap, we propose applying adversarial augmentation to the surrogate
models, aiming to boost overall generalization of ensemble models and reduce
the risk of adversarial overfitting. Meanwhile, observing that ensemble Vision
Transformers (ViTs) gain less attention, we propose ViT-EnsembleAttack based on
the idea of model adversarial augmentation, the first ensemble-based attack
method tailored for ViTs to the best of our knowledge. Our approach generates
augmented models for each surrogate ViT using three strategies: Multi-head
dropping, Attention score scaling, and MLP feature mixing, with the associated
parameters optimized by Bayesian optimization. These adversarially augmented
models are ensembled to generate adversarial examples. Furthermore, we
introduce Automatic Reweighting and Step Size Enlargement modules to boost
transferability. Extensive experiments demonstrate that ViT-EnsembleAttack
significantly enhances the adversarial transferability of ensemble-based
attacks on ViTs, outperforming existing methods by a substantial margin. Code
is available at https://github.com/Trustworthy-AI-Group/TransferAttack.

</details>


### [68] [DeCoT: Decomposing Complex Instructions for Enhanced Text-to-Image Generation with Large Language Models](https://arxiv.org/abs/2508.12396)
*Xiaochuan Lin,Xiangyong Chen,Xuan Li,Yichen Su*

Main category: cs.CV

TL;DR: DeCoT는 LLM을 활용해 복잡한 텍스트-투-이미지 지시문을 구조화·명확화하고, 이를 계층적/최적화된 프롬프트로 변환해 기존 T2I 모델의 성능을 향상시키는 프레임워크다. LongBench-T2I에서 특히 '텍스트'와 '구성' 항목에서 유의미한 개선을 보였다.


<details>
  <summary>Details</summary>
Motivation: 현행 T2I 모델들은 복잡하고 장문의 지시문에서 세부·공간관계·특정 제약을 정확히 반영하지 못해 실용성이 떨어진다. 이를 개선하기 위해 지시문을 분해하고 의미를 보강해 모델 입력으로 적합한 프롬프트를 생성할 필요가 있다.

Method: 두 단계: (1) LLM 기반의 복잡 지시문 분해 및 의미 보강 — 지시문을 구조화된 실행 단위로 분해하고 애매함을 해소; (2) 다단계 프롬프트 통합 및 적응적 생성 — 분해된 단위를 계층적 또는 최적화된 단일 프롬프트로 재구성해 기존 T2I 모델에 입력. 또한 구성 요소별 기여도를 분석하는 소거 실험을 수행.

Result: LongBench-T2I에서 다양한 T2I 모델(예: Infinity-8B)에 적용 시 전반적 점수 향상 관찰(예: 3.44→3.52). MLLM 평가자와 인간 평가 모두에서 지시 충실도 및 지각 품질 개선이 보고됨.

Conclusion: LLM 기반 지시문 분해·보강 및 프롬프트 통합은 복잡한 사용자 의도와 T2I 모델 요구사항 간 격차를 줄여 보다 충실한 이미지 생성을 가능하게 한다.

Abstract: Despite remarkable advancements, current Text-to-Image (T2I) models struggle
with complex, long-form textual instructions, frequently failing to accurately
render intricate details, spatial relationships, or specific constraints. This
limitation is highlighted by benchmarks such as LongBench-T2I, which reveal
deficiencies in handling composition, specific text, and fine textures. To
address this, we propose DeCoT (Decomposition-CoT), a novel framework that
leverages Large Language Models (LLMs) to significantly enhance T2I models'
understanding and execution of complex instructions. DeCoT operates in two core
stages: first, Complex Instruction Decomposition and Semantic Enhancement,
where an LLM breaks down raw instructions into structured, actionable semantic
units and clarifies ambiguities; second, Multi-Stage Prompt Integration and
Adaptive Generation, which transforms these units into a hierarchical or
optimized single prompt tailored for existing T2I models. Extensive experiments
on the LongBench-T2I dataset demonstrate that DeCoT consistently and
substantially improves the performance of leading T2I models across all
evaluated dimensions, particularly in challenging aspects like "Text" and
"Composition". Quantitative results, validated by multiple MLLM evaluators
(Gemini-2.0-Flash and InternVL3-78B), show that DeCoT, when integrated with
Infinity-8B, achieves an average score of 3.52, outperforming the baseline
Infinity-8B (3.44). Ablation studies confirm the critical contribution of each
DeCoT component and the importance of sophisticated LLM prompting. Furthermore,
human evaluations corroborate these findings, indicating superior perceptual
quality and instruction fidelity. DeCoT effectively bridges the gap between
high-level user intent and T2I model requirements, leading to more faithful and
accurate image generation.

</details>


### [69] [Federated Cross-Modal Style-Aware Prompt Generation](https://arxiv.org/abs/2508.12399)
*Suraj Prasad,Navyansh Mahla,Sunny Gupta,Amit Sethi*

Main category: cs.CV

TL;DR: FedCSAP은 CLIP의 다중 수준 비전 특징(저·중·고레벨)과 배치 기반 스타일 지표를 결합해 프롬프트 토큰을 생성하는 연합학습 프레임워크로, 개인 클라이언트의 도메인 스타일과 멀티스케일 시각 정보를 활용하여 일반화 성능을 향상시키고 데이터 프라이버시를 보장한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 연합 프롬프트 학습은 주로 최종 레이어 특징만 사용해 멀티스케일 시각 신호와 클라이언트별 스타일 변이를 반영하지 못해 성능과 일반화에 한계가 있음. 이를 해결해 분산된 이기종 데이터에서 더 강건한 프롬프트를 얻고자 함.

Method: CLIP 비전 인코더의 저·중·고레벨 특징을 추출하고, 클라이언트 배치 통계로부터 스타일 지표를 계산해 텍스트 컨텍스트와 결합. 중복을 줄인 고유한 프롬프트 토큰을 생성하고, 로컬 학습 후 전역 집계(연합학습)를 통해 모델을 공유·업데이트함.

Result: 여러 이미지 분류 데이터셋에서 기존 연합 프롬프트 학습 방법들보다 정확도와 일반화 능력이 향상됨(보여진/보이지 않은 클래스 모두).

Conclusion: 멀티스케일 특징과 클라이언트별 스타일을 통합한 프롬프트 생성은 연합 환경에서 프라이버시를 유지하면서도 더 나은 범용성·성능을 달성할 수 있음을 보임.

Abstract: Prompt learning has propelled vision-language models like CLIP to excel in
diverse tasks, making them ideal for federated learning due to computational
efficiency. However, conventional approaches that rely solely on final-layer
features miss out on rich multi-scale visual cues and domain-specific style
variations in decentralized client data. To bridge this gap, we introduce
FedCSAP (Federated Cross-Modal Style-Aware Prompt Generation). Our framework
harnesses low, mid, and high-level features from CLIP's vision encoder
alongside client-specific style indicators derived from batch-level statistics.
By merging intricate visual details with textual context, FedCSAP produces
robust, context-aware prompt tokens that are both distinct and non-redundant,
thereby boosting generalization across seen and unseen classes. Operating
within a federated learning paradigm, our approach ensures data privacy through
local training and global aggregation, adeptly handling non-IID class
distributions and diverse domain-specific styles. Comprehensive experiments on
multiple image classification datasets confirm that FedCSAP outperforms
existing federated prompt learning methods in both accuracy and overall
generalization.

</details>


### [70] [MPCAR: Multi-Perspective Contextual Augmentation for Enhanced Visual Reasoning in Large Vision-Language Models](https://arxiv.org/abs/2508.12400)
*Amirul Rahman,Qiang Xu,Xueying Huang*

Main category: cs.CV

TL;DR: MPCAR은 LVLM의 생성 능력을 이용해 서로 다른 N개의 시각적 설명·추론 경로를 생성하고 이를 질문과 결합한 컨텍스트-증강 프롬프트로 다시 입력하여 추론 성능을 향상시키는 추론 시(피팅 없음) 기법이다. GQA, VQA-CP v2, ScienceQA 등에서 유의한 정확도 향상을 보였다.


<details>
  <summary>Details</summary>
Motivation: 단일 샷 이미지 인코딩과 프롬프트가 복잡한 시각 추론에서 세부 정보·다중 시점·심층 맥락을 포착하는 데 한계가 있어, 모델이 스스로 생성한 추가적이고 보완적인 정보로 입력 컨텍스트를 확장하면 성능 개선이 가능하리라는 가정.

Method: (1) LVLM으로부터 서로 다르고 보완적인 N개의 설명 또는 예비 추론 경로 생성, (2) 이들 설명을 원래 질문과 지능적으로 통합해 컨텍스트-증강 프롬프트 구성, (3) 강화된 프롬프트로 최종 LVLM에게 심층 추론과 정답 생성 지시. 모든 과정은 추론 시점에 수행되며 파라미터 미세조정 불필요.

Result: 여러 VQA 데이터셋에서 기존 베이스라인보다 일관된 성능 향상 관찰. 특히 맥락 이해가 중요한 문제에서 정확도 상승이 두드러졌고, 인간 평가에서 응답의 일관성·완전성 개선이 확인됨. 템플릿 다양성·생성 관점 수의 영향이 실험적으로 입증됨.

Conclusion: LVLM의 생성 능력으로 입력 컨텍스트를 풍부히 하면 복잡한 다중모달 추론에서 미세조정 없이도 잠재적 추론 능력을 끌어낼 수 있다. 다만 생성된 관점의 품질·노이즈, 계산 비용·응답 지연, 환각 위험 등이 한계로 남으며 필터링·선별 전략과 자동화된 관점 선택 등이 향후 과제다.

Abstract: Despite significant advancements, Large Vision-Language Models (LVLMs)
continue to face challenges in complex visual reasoning tasks that demand deep
contextual understanding, multi-angle analysis, or meticulous detail
recognition. Existing approaches often rely on single-shot image encoding and
prompts, limiting their ability to fully capture nuanced visual information.
Inspired by the notion that strategically generated "additional" information
can serve as beneficial contextual augmentation, we propose Multi-Perspective
Contextual Augmentation for Reasoning (MPCAR), a novel inference-time strategy
designed to enhance LVLM performance. MPCAR operates in three stages: first, an
LVLM generates N diverse and complementary descriptions or preliminary
reasoning paths from various angles; second, these descriptions are
intelligently integrated with the original question to construct a
comprehensive context-augmented prompt; and finally, this enriched prompt
guides the ultimate LVLM for deep reasoning and final answer generation.
Crucially, MPCAR achieves these enhancements without requiring any fine-tuning
of the underlying LVLM's parameters. Extensive experiments on challenging
Visual Question Answering (VQA) datasets, including GQA, VQA-CP v2, and
ScienceQA (Image-VQA), demonstrate that MPCAR consistently outperforms
established baseline methods. Our quantitative results show significant
accuracy gains, particularly on tasks requiring robust contextual
understanding, while human evaluations confirm improved coherence and
completeness of the generated answers. Ablation studies further highlight the
importance of diverse prompt templates and the number of generated
perspectives. This work underscores the efficacy of leveraging LVLMs' inherent
generative capabilities to enrich input contexts, thereby unlocking their
latent reasoning potential for complex multimodal tasks.

</details>


### [71] [LMAD: Integrated End-to-End Vision-Language Model for Explainable Autonomous Driving](https://arxiv.org/abs/2508.12404)
*Nan Song,Bozhou Zhang,Xiatian Zhu,Jiankang Deng,Li Zhang*

Main category: cs.CV

TL;DR: LMAD는 자율주행에 특화된 비전-언어 프레임워크로, 예비 장면 상호작용(preliminary scene interaction)과 과제 전용(expert) 어댑터를 도입해 기존 VLM을 자율주행 상황에 더 잘 정렬시킨다. DriveLM과 nuScenes-QA에서 기존 VLM 성능을 크게 향상시켰다.


<details>
  <summary>Details</summary>
Motivation: 기존 방법들은 온보드 다중뷰 이미지와 텍스트 추론으로 VLM을 미세조정하지만, 자율주행이 요구하는 전체론적·미세한 장면 인식과 강력한 공간 인식 능력이 부족하다. 특히 복잡한 상황에서 한계가 있다.

Method: 모던 엔드-투-엔드 주행 패러다임을 모사하여 VLM에 포괄적 장면 이해와 과제 특화 구조를 결합한다. 구체적으로 예비 장면 상호작용 모듈과 과제 전용 전문가 어댑터를 동일한 주행 과제 구조 내에 삽입하며, 기존 VLM과 계획 지향(planning-oriented) 주행 시스템과의 호환성을 유지한다.

Result: DriveLM 및 nuScenes-QA 데이터셋에서 기존 VLM들의 주행 추론 성능을 유의미하게 향상시켰으며, 설명 가능한 자율주행 분야에서 새로운 기준을 제시한다고 보고한다.

Conclusion: LMAD는 VLM을 자율주행 시나리오에 더 잘 맞추어 설명가능성·공간 인식·장면 이해를 개선하고, 계획 기반 주행 시스템과 연동 가능한 실용적 프레임워크를 제안한다.

Abstract: Large vision-language models (VLMs) have shown promising capabilities in
scene understanding, enhancing the explainability of driving behaviors and
interactivity with users. Existing methods primarily fine-tune VLMs on on-board
multi-view images and scene reasoning text, but this approach often lacks the
holistic and nuanced scene recognition and powerful spatial awareness required
for autonomous driving, especially in complex situations. To address this gap,
we propose a novel vision-language framework tailored for autonomous driving,
called LMAD. Our framework emulates modern end-to-end driving paradigms by
incorporating comprehensive scene understanding and a task-specialized
structure with VLMs. In particular, we introduce preliminary scene interaction
and specialized expert adapters within the same driving task structure, which
better align VLMs with autonomous driving scenarios. Furthermore, our approach
is designed to be fully compatible with existing VLMs while seamlessly
integrating with planning-oriented driving systems. Extensive experiments on
the DriveLM and nuScenes-QA datasets demonstrate that LMAD significantly boosts
the performance of existing VLMs on driving reasoning tasks,setting a new
standard in explainable autonomous driving.

</details>


### [72] [S5: Scalable Semi-Supervised Semantic Segmentation in Remote Sensing](https://arxiv.org/abs/2508.12409)
*Liang Lv,Di Wang,Jing Zhang,Lefei Zhang*

Main category: cs.CV

TL;DR: S5 is a scalable semi-supervised semantic segmentation framework for remote sensing that builds RS4P-1M via entropy-based filtering and diversity expansion, pretrains RS foundation models at scale, and uses MoE-based multi-dataset fine-tuning to achieve state-of-the-art results on segmentation and detection benchmarks.


<details>
  <summary>Details</summary>
Motivation: Existing semi-supervised segmentation (S4) work in remote sensing relies on small datasets and model sizes, limiting practical value; vast unlabeled Earth observation data remain underused due to costly pixel-level annotations, motivating a scalable S4 framework.

Method: Create RS4P-1M by combining entropy-based filtering with diversity expansion to select unlabeled samples; pretrain RS foundation models (various sizes) on this corpus; fine-tune using a Mixture-of-Experts (MoE) multi-dataset strategy to adapt efficiently to multiple benchmarks with fewer trainable parameters.

Result: Pretrained RSFMs significantly improve land cover segmentation and object detection performance; MoE fine-tuning enhances generalization and versatility across diverse RS benchmarks; models reach state-of-the-art across evaluated datasets.

Conclusion: Scaling semi-supervised learning in remote sensing is feasible and effective: large unlabeled corpora plus targeted selection and efficient multi-dataset fine-tuning yield strong, general RS foundation models. Public release of datasets, code, and models will aid reproducibility.

Abstract: Semi-supervised semantic segmentation (S4) has advanced remote sensing (RS)
analysis by leveraging unlabeled data through pseudo-labeling and consistency
learning. However, existing S4 studies often rely on small-scale datasets and
models, limiting their practical applicability. To address this, we propose S5,
the first scalable framework for semi-supervised semantic segmentation in RS,
which unlocks the potential of vast unlabeled Earth observation data typically
underutilized due to costly pixel-level annotations. Built upon existing
large-scale RS datasets, S5 introduces a data selection strategy that
integrates entropy-based filtering and diversity expansion, resulting in the
RS4P-1M dataset. Using this dataset, we systematically scales S4 methods by
pre-training RS foundation models (RSFMs) of varying sizes on this extensive
corpus, significantly boosting their performance on land cover segmentation and
object detection tasks. Furthermore, during fine-tuning, we incorporate a
Mixture-of-Experts (MoE)-based multi-dataset fine-tuning approach, which
enables efficient adaptation to multiple RS benchmarks with fewer parameters.
This approach improves the generalization and versatility of RSFMs across
diverse RS benchmarks. The resulting RSFMs achieve state-of-the-art performance
across all benchmarks, underscoring the viability of scaling semi-supervised
learning for RS applications. All datasets, code, and models will be released
at https://github.com/MiliLab/S5

</details>


### [73] [SRMA-Mamba: Spatial Reverse Mamba Attention Network for Pathological Liver Segmentation in MRI Volumes](https://arxiv.org/abs/2508.12410)
*Jun Zeng,Yannan Huang,Elif Keles,Halil Ertugrul Aktas,Gorkem Durak,Nikhil Kumar Tomar,Quoc-Huy Trinh,Deepak Ranjan Nayak,Ulas Bagci,Debesh Jha*

Main category: cs.CV

TL;DR: SRMA-Mamba는 축별(시상·관상·축상) 해부학 정보를 융합하는 SABMamba와 계층 인코딩과 조합된 Spatial Reverse Attention(SRMA)를 통해 3D 간경변 병변의 공간적 문맥과 세부를 효율적으로 포착해 기존 기법을 능가하는 3D 분할 성능을 보이는 네트워크다.


<details>
  <summary>Details</summary>
Motivation: 간경변의 조기 탐지·정확한 병변 분할은 환자 예후 개선에 필수적이나, 간의 복잡한 해부학·병리 변화 때문에 MRI 볼륨에서 병변을 정확히 탐지·설명하기 어렵다. 기존 기법은 체적 데이터의 공간적 해부학 정보를 충분히 활용하지 못한다.

Method: SRMA-Mamba는 Spatial Anatomy-Based Mamba(SABMamba)를 통해 시상·관상·축상 평면에서 선택적 Mamba 스캔을 수행하고 이들을 융합해 전역 공간 문맥을 구성한다. 또한 Spatial Reverse Attention(SRMA) 모듈로 조잡한(거친) 분할 맵과 계층적 인코딩 피처를 이용해 병변 경계와 세부를 점진적으로 정제한다.

Result: 광범위한 실험에서 SRMA-Mamba는 기존 최첨단 방법들을 능가하는 3D 병리 간 분할 성능을 달성했다고 보고하며, 코드가 공개되어 재현 가능성을 높였다.

Conclusion: 평면별 해부학적 정보를 결합한 Mamba 기반 구조와 역방향 주의 정제 모듈은 체적 MRI에서 간경변 병변 분할의 정확도·설명력을 향상시킨다.

Abstract: Liver Cirrhosis plays a critical role in the prognosis of chronic liver
disease. Early detection and timely intervention are critical in significantly
reducing mortality rates. However, the intricate anatomical architecture and
diverse pathological changes of liver tissue complicate the accurate detection
and characterization of lesions in clinical settings. Existing methods
underutilize the spatial anatomical details in volumetric MRI data, thereby
hindering their clinical effectiveness and explainability. To address this
challenge, we introduce a novel Mamba-based network, SRMA-Mamba, designed to
model the spatial relationships within the complex anatomical structures of MRI
volumes. By integrating the Spatial Anatomy-Based Mamba module (SABMamba),
SRMA-Mamba performs selective Mamba scans within liver cirrhotic tissues and
combines anatomical information from the sagittal, coronal, and axial planes to
construct a global spatial context representation, enabling efficient
volumetric segmentation of pathological liver structures. Furthermore, we
introduce the Spatial Reverse Attention module (SRMA), designed to
progressively refine cirrhotic details in the segmentation map, utilizing both
the coarse segmentation map and hierarchical encoding features. Extensive
experiments demonstrate that SRMA-Mamba surpasses state-of-the-art methods,
delivering exceptional performance in 3D pathological liver segmentation. Our
code is available for public:
{\color{blue}{https://github.com/JunZengz/SRMA-Mamba}}.

</details>


### [74] [TiP4GEN: Text to Immersive Panorama 4D Scene Generation](https://arxiv.org/abs/2508.12415)
*Ke Xing,Hanwen Liang,Dejia Xu,Yuyang Yin,Konstantinos N. Plataniotis,Yao Zhao,Yunchao Wei*

Main category: cs.CV

TL;DR: TiP4GEN은 텍스트로부터 360° 동적 파노라마 장면을 생성하고, 전역/지역 생성을 위한 이중 분기 모델과 기하 정렬된 3D Gaussian Splatting 기반 재구성으로 모션-일관성 있고 기하학적으로 일관된 4D 파노라마를 만든다.


<details>
  <summary>Details</summary>
Motivation: VR/AR용 몰입형 동적 장면 수요가 증가하지만 기존 연구는 정적 장면이나 제한된 시점의 동적 장면에 머물러 360° 전시점을 지원하지 못함.

Method: 비디오 생성부에 파노라마 분기(전역)와 원근 분기(지역)를 가진 Dual-branch 모델을 도입하고, 양방향 교차어텐션으로 분기 간 정보 교환을 수행. 재구성부는 메트릭 깊이 맵으로 시공간 포인트클라우드를 정렬하고 추정 포즈로 카메라 초기화한 Geometry-aligned 3D Gaussian Splatting 모델을 사용해 기하학적 일관성과 시간적 연속성 확보.

Result: 다양한 실험에서 제안 기법이 시각적으로 우수하고 모션-일관성 있는 동적 파노라마 장면을 생성함을 보였음(정량·정성 우수성 주장).

Conclusion: TiP4GEN은 텍스트-투-동적 파노라마 생성과 4D 장면 재구성의 통합으로 360° 몰입형 환경을 생성하는 실용적인 접근을 제시하며, 제안 요소들이 성능 향상에 기여함.

Abstract: With the rapid advancement and widespread adoption of VR/AR technologies,
there is a growing demand for the creation of high-quality, immersive dynamic
scenes. However, existing generation works predominantly concentrate on the
creation of static scenes or narrow perspective-view dynamic scenes, falling
short of delivering a truly 360-degree immersive experience from any viewpoint.
In this paper, we introduce \textbf{TiP4GEN}, an advanced text-to-dynamic
panorama scene generation framework that enables fine-grained content control
and synthesizes motion-rich, geometry-consistent panoramic 4D scenes. TiP4GEN
integrates panorama video generation and dynamic scene reconstruction to create
360-degree immersive virtual environments. For video generation, we introduce a
\textbf{Dual-branch Generation Model} consisting of a panorama branch and a
perspective branch, responsible for global and local view generation,
respectively. A bidirectional cross-attention mechanism facilitates
comprehensive information exchange between the branches. For scene
reconstruction, we propose a \textbf{Geometry-aligned Reconstruction Model}
based on 3D Gaussian Splatting. By aligning spatial-temporal point clouds using
metric depth maps and initializing scene cameras with estimated poses, our
method ensures geometric consistency and temporal coherence for the
reconstructed scenes. Extensive experiments demonstrate the effectiveness of
our proposed designs and the superiority of TiP4GEN in generating visually
compelling and motion-coherent dynamic panoramic scenes. Our project page is at
https://ke-xing.github.io/TiP4GEN/.

</details>


### [75] [Illusions in Humans and AI: How Visual Perception Aligns and Diverges](https://arxiv.org/abs/2508.12422)
*Jianyi Yang,Junyi Ye,Ankan Dash,Guiling Wang*

Main category: cs.CV

TL;DR: 인간과 인공지능(AI) 시각 체계를 착시 현상(visual illusions)을 통해 비교한 연구로, 일부 고전적 착시가 AI 모델에서도 나타나지만 AI 고유의 착시(픽셀 민감성, 환각 등)도 존재한다는 주장이다. 이러한 차이는 인간-친화적 AI 비전 설계에 함의를 준다.


<details>
  <summary>Details</summary>
Motivation: 인간 지각은 맥락적 가정에 기반하며 생긴 착시를 통해 이를 드러낸다. AI가 인간과 유사한 시각 작업을 수행할수록, AI도 착시를 경험하는지와 인간과 다른 취약점이 있는지를 규명해 인간과 정렬된, 해석 가능하고 안전한 비전 시스템 설계에 기여하려는 목적이다.

Method: 고전적 색·크기·형태·운동 착시 자극을 AI 모델에 적용해 반응을 관찰하고, 표적 훈련(targeted training)이나 패턴 인식의 부산물로 나타나는 현상을 분석한다. 또한 인간 반응과의 체계적 비교로 정렬 격차와 AI 특유의 취약점을 도출한다.

Result: 일부 착시 효과는 모델 학습 과정에서 재현되거나 표적 학습으로 유도될 수 있었다. 동시에 픽셀 수준의 민감성, 과잉일반화로 인한 환각(hallucination) 등 인간에는 없는 AI 고유의 착시와 취약점이 확인되었다. 이러한 차이는 인간 지각과의 불일치(정렬 격차)로 이어진다.

Conclusion: 착시 비교는 인간-우호적 편향을 보존하면서 신뢰와 안전을 해치는 왜곡은 피하는 비전 시스템 설계에 유용한 통찰을 제공한다. 후속 연구로 정량적 비교, 다양한 아키텍처·학습 조건 테스트, 인간-데이터 기반 규제 방법 개발이 필요하다.

Abstract: By comparing biological and artificial perception through the lens of
illusions, we highlight critical differences in how each system constructs
visual reality. Understanding these divergences can inform the development of
more robust, interpretable, and human-aligned artificial intelligence (AI)
vision systems. In particular, visual illusions expose how human perception is
based on contextual assumptions rather than raw sensory data. As artificial
vision systems increasingly perform human-like tasks, it is important to ask:
does AI experience illusions, too? Does it have unique illusions? This article
explores how AI responds to classic visual illusions that involve color, size,
shape, and motion. We find that some illusion-like effects can emerge in these
models, either through targeted training or as by-products of pattern
recognition. In contrast, we also identify illusions unique to AI, such as
pixel-level sensitivity and hallucinations, that lack human counterparts. By
systematically comparing human and AI responses to visual illusions, we uncover
alignment gaps and AI-specific perceptual vulnerabilities invisible to human
perception. These findings provide insights for future research on vision
systems that preserve human-beneficial perceptual biases while avoiding
distortions that undermine trust and safety.

</details>


### [76] [Adversarial Attacks on VQA-NLE: Exposing and Alleviating Inconsistencies in Visual Question Answering Explanations](https://arxiv.org/abs/2508.12430)
*Yahsin Yeh,Yilun Wu,Bokai Ruan,Honghan Shuai*

Main category: cs.CV

TL;DR: VQA-NLE 시스템의 설명 일관성 및 견고성을 공격-방어 관점에서 분석. 질문 교란과 최소한의 이미지 변형을 이용해 모순된/허위 출력을 유도하고, 외부 지식을 활용한 방어 방법으로 불일치 완화.


<details>
  <summary>Details</summary>
Motivation: VQA-NLE 모델이 생성하는 자연어 설명이 실제 이해를 반영하지 못하고 취약점이 있어 신뢰성·보안 문제를 초래할 수 있음. 이를 입증하고 방어책을 제시할 필요.

Method: (1) 기존 질문 교란(adversarial question) 전략 사용, (2) 제안된 최소 이미지 변형(minimal image perturbation)으로 모순/허위 출력 유도, (3) 외부 지식 기반의 완화 기법을 도입해 설명 일관성 및 모델 견고성 향상.

Result: 두 개의 표준 벤치마크와 두 개의 VQA-NLE 모델에서 공격의 효과를 입증하고, 지식 기반 방어가 불일치를 감소시키며 모델의 견고성 개선 가능성을 보임.

Conclusion: 현재 VQA-NLE 시스템은 보안·신뢰성 취약점이 존재하며, 외부 지식을 활용한 방어가 유망하지만 추가적인 적응형 공격·실제성 평가가 필요하다.

Abstract: Natural language explanations in visual question answering (VQA-NLE) aim to
make black-box models more transparent by elucidating their decision-making
processes. However, we find that existing VQA-NLE systems can produce
inconsistent explanations and reach conclusions without genuinely understanding
the underlying context, exposing weaknesses in either their inference pipeline
or explanation-generation mechanism. To highlight these vulnerabilities, we not
only leverage an existing adversarial strategy to perturb questions but also
propose a novel strategy that minimally alters images to induce contradictory
or spurious outputs. We further introduce a mitigation method that leverages
external knowledge to alleviate these inconsistencies, thereby bolstering model
robustness. Extensive evaluations on two standard benchmarks and two widely
used VQA-NLE models underscore the effectiveness of our attacks and the
potential of knowledge-based defenses, ultimately revealing pressing security
and reliability concerns in current VQA-NLE systems.

</details>


### [77] [X-Ray-CoT: Interpretable Chest X-ray Diagnosis with Vision-Language Models via Chain-of-Thought Reasoning](https://arxiv.org/abs/2508.12455)
*Chee Ng,Liliang Sun,Shaoqing Tang*

Main category: cs.CV

TL;DR: X-Ray-CoT integrates vision-language large models with a structured chain-of-thought prompting pipeline to generate interpretable chest X‑ray diagnoses and reports, achieving slightly better quantitative disease detection and producing explainable natural-language outputs.


<details>
  <summary>Details</summary>
Motivation: Chest X‑ray interpretation needs experienced radiologists and suffers inter-observer variability; deep models are accurate but opaque, so an interpretable, clinically actionable system is required.

Method: Extract multi-modal features and visual concepts from images, fuse them, then use a large language model with structured Chain-of-Thought prompting to reason and produce detailed diagnostic reports.

Result: On CORDA, Balanced Accuracy 80.52% and F1 78.65%—marginally better than black-box baselines—and human evaluation indicates higher-quality, explainable reports. Ablation studies show multi-modal fusion and CoT are important.

Conclusion: Provides a promising, more transparent approach for chest X‑ray AI; still needs broader validation, more detailed evaluation, and deployment considerations before clinical use.

Abstract: Chest X-ray imaging is crucial for diagnosing pulmonary and cardiac diseases,
yet its interpretation demands extensive clinical experience and suffers from
inter-observer variability. While deep learning models offer high diagnostic
accuracy, their black-box nature hinders clinical adoption in high-stakes
medical settings. To address this, we propose X-Ray-CoT (Chest X-Ray
Chain-of-Thought), a novel framework leveraging Vision-Language Large Models
(LVLMs) for intelligent chest X-ray diagnosis and interpretable report
generation. X-Ray-CoT simulates human radiologists' "chain-of-thought" by first
extracting multi-modal features and visual concepts, then employing an
LLM-based component with a structured Chain-of-Thought prompting strategy to
reason and produce detailed natural language diagnostic reports. Evaluated on
the CORDA dataset, X-Ray-CoT achieves competitive quantitative performance,
with a Balanced Accuracy of 80.52% and F1 score of 78.65% for disease
diagnosis, slightly surpassing existing black-box models. Crucially, it
uniquely generates high-quality, explainable reports, as validated by
preliminary human evaluations. Our ablation studies confirm the integral role
of each proposed component, highlighting the necessity of multi-modal fusion
and CoT reasoning for robust and transparent medical AI. This work represents a
significant step towards trustworthy and clinically actionable AI systems in
medical imaging.

</details>


### [78] [Inverse-LLaVA: Eliminating Alignment Pre-training Through Text-to-Vision Mapping](https://arxiv.org/abs/2508.12466)
*Xuhui Zhan,Tyler Derr*

Main category: cs.CV

TL;DR: Inverse-LLaVA는 정렬(얼라인먼트) 사전학습을 제거하고, 시각 -> 텍스트가 아닌 텍스트 임베딩을 연속적 시각 표현 공간으로 매핑해 중간 transformer 레이어에서 융합하는 역방향 멀티모달 접근법이다. 연산량을 45% 절감하면서 추론·인지 과제 성능은 상승하고(일부 벤치마크에서 유의미한 향상), 기억 기반 인식·OCR 같은 인지된 시각-텍스트 연관을 요구하는 과제에서는 성능 하락이 크다.


<details>
  <summary>Details</summary>
Motivation: 시각-언어 모달리티를 잇는 대규모 얼라인먼트 사전학습은 비용이 크고 시각·언어의 고유 특성을 침해할 수 있다는 문제의식에서 출발. 얼라인먼트 없이도 고차원적 추론 능력을 보존하거나 향상시킬 수 있는 대안적 융합 방식을 제안하려는 목적.

Method: 텍스트 임베딩을 연속적 시각 표현 공간으로 투사한 뒤 transformer의 중간 레이어에서 선택적 가산(attention additive) 구성요소를 통해 동적으로 시각·문자열 표현을 융합한다. 시각-텍스트 정렬 데이터 없이도 학습 가능하도록 설계되어 계산량을 절감함.

Result: 9개 멀티모달 벤치마크에서 실험: 추론·인지 중심 과제(예: MM-VET, VizWiz, ScienceQA, 'cognitive reasoning')에서 성능 개선(예: cognitive reasoning +27.2%)을 보였으나, 연상·암기 기반 시각인식 과제(연예인 인식 -49.5%, OCR -21.3%)에서는 큰 성능 저하를 보인다. 전체적으로 얼라인먼트 사전학습이 필수는 아니라는 경험적 근거를 제시.

Conclusion: 얼라인먼트 없이도 복잡한 추론 능력을 유지하거나 향상시킬 수 있음을 보이며, 연산 비용 절감과 모달리티 특성 보존 측면에서 새로운 패러다임 가능성을 제시. 다만 인식·기억 기반 작업에는 한계가 있어 하이브리드 설계나 추가적 보완이 필요하다.

Abstract: Traditional multimodal learning approaches require expensive alignment
pre-training to bridge vision and language modalities, typically projecting
visual features into discrete text token spaces. We challenge both fundamental
assumptions underlying this paradigm by proposing Inverse-LLaVA, a novel
approach that eliminates alignment pre-training entirely while inverting the
conventional mapping direction. Rather than projecting visual features to text
space, our method maps text embeddings into continuous visual representation
space and performs fusion within transformer intermediate layers. Through
selective additive components in attention mechanisms, we enable dynamic
integration of visual and textual representations without requiring massive
image-text alignment datasets. Comprehensive experiments across nine multimodal
benchmarks demonstrate nuanced performance trade-offs: Inverse-LLaVA achieves
notable improvements on reasoning-intensive and cognitive tasks (MM-VET: +0.2%,
VizWiz: +1.8%, ScienceQA: +0.2%, cognitive reasoning: +27.2%), while showing
expected decreases in perception tasks requiring memorized visual-text
associations (celebrity recognition: -49.5%, OCR: -21.3%). These results
provide the first empirical evidence that alignment pre-training is not
necessary for effective multimodal learning, particularly for complex reasoning
tasks. Our work establishes the feasibility of a new paradigm that reduces
computational requirements by 45%, challenges conventional wisdom about
modality fusion, and opens new research directions for efficient multimodal
architectures that preserve modality-specific characteristics. Our project
website with code and additional resources is available at
https://inverse-llava.github.io.

</details>


### [79] [Standardization of Neuromuscular Reflex Analysis -- Role of Fine-Tuned Vision-Language Model Consortium and OpenAI gpt-oss Reasoning LLM Enabled Decision Support System](https://arxiv.org/abs/2508.12473)
*Eranga Bandara,Ross Gore,Sachin Shetty,Ravi Mukkamala,Christopher Rhea,Atmaram Yarlagadda,Shaifali Kaushik,L. H. M. P. De Silva,Andriy Maznychenko,Inna Sokolowska,Amin Hass,Kasun De Zoysa*

Main category: cs.CV

TL;DR: H-반사(EMG) 파형 분석을 위해 다수의 미세조정된 비전-언어 모델(VLM) 컨소시엄과 추론형 대형언어모델(LLM)을 결합한 자동화·설명가능한 진단 지원 시스템을 제안함.


<details>
  <summary>Details</summary>
Motivation: 임상의와 연구자 간의 해석 편차와 주관성을 줄여 H-반사 평가의 신뢰성·표준화를 높이기 위함.

Method: 임상 주석·회복 기간·운동선수 메타데이터가 포함된 파형 이미지로 각 VLM를 미세조정하고, VLM들의 진단을 합의 기반으로 집계한 뒤 추론형 LLM이 이를 정제·설명하는 엔드투엔드 플랫폼을 구성함. LLM 에이전트를 통한 프롬프트엔지니어링·자동 추론 워크플로우를 통합함.

Result: 실험에서 높은 정확도·일관성·해석 가능성을 보였고 H-반사 평가의 자동화와 표준화를 의미있게 향상시킴.

Conclusion: 미세조정된 VLM 컨소시엄과 추론형 LLM의 결합을 통해 영상기반 H-반사 분석의 첫 통합 사례를 제시하며 향후 AI 기반 신경근 평가·선수 모니터링 플랫폼의 토대를 마련함.

Abstract: Accurate assessment of neuromuscular reflexes, such as the H-reflex, plays a
critical role in sports science, rehabilitation, and clinical neurology.
Traditional analysis of H-reflex EMG waveforms is subject to variability and
interpretation bias among clinicians and researchers, limiting reliability and
standardization. To address these challenges, we propose a Fine-Tuned
Vision-Language Model (VLM) Consortium and a reasoning Large-Language Model
(LLM)-enabled Decision Support System for automated H-reflex waveform
interpretation and diagnosis. Our approach leverages multiple VLMs, each
fine-tuned on curated datasets of H-reflex EMG waveform images annotated with
clinical observations, recovery timelines, and athlete metadata. These models
are capable of extracting key electrophysiological features and predicting
neuromuscular states, including fatigue, injury, and recovery, directly from
EMG images and contextual metadata. Diagnostic outputs from the VLM consortium
are aggregated using a consensus-based method and refined by a specialized
reasoning LLM, which ensures robust, transparent, and explainable decision
support for clinicians and sports scientists. The end-to-end platform
orchestrates seamless communication between the VLM ensemble and the reasoning
LLM, integrating prompt engineering strategies and automated reasoning
workflows using LLM Agents. Experimental results demonstrate that this hybrid
system delivers highly accurate, consistent, and interpretable H-reflex
assessments, significantly advancing the automation and standardization of
neuromuscular diagnostics. To our knowledge, this work represents the first
integration of a fine-tuned VLM consortium with a reasoning LLM for image-based
H-reflex analysis, laying the foundation for next-generation AI-assisted
neuromuscular assessment and athlete monitoring platforms.

</details>


### [80] [Skin Cancer Classification: Hybrid CNN-Transformer Models with KAN-Based Fusion](https://arxiv.org/abs/2508.12484)
*Shubhi Agarwal,Amulya Kumar Mahto*

Main category: cs.CV

TL;DR: 하이브리드 CNN-Transformer에 CKAN을 결합해 피부암 분류 성능을 높였다는 연구. 결과는 여러 데이터셋에서 높은 정확도와 F1-score를 보고하지만, 실험·재현성·평가 지표의 구체성에 관한 설명이 부족함.


<details>
  <summary>Details</summary>
Motivation: 정밀한 지역(로컬) 정보와 전역적(컨텍스트) 정보를 동시에 캡처하여 피부 병변 분류 성능을 개선하고, 비선형적 특징 융합을 통해 더 판별력 있는 표현을 얻고자 함.

Method: 전이학습된 CNN으로 로컬 특성 추출, Transformer로 전역 의존성 모델링, CKAN(Convolutional Kolmogorov-Arnold Network)을 통해 비선형 피처 융합을 수행하는 순차적 및 병렬 하이브리드 아키텍처를 설계. 데이터 증강과 전이학습을 적용해 여러 공개 데이터셋(HAM10000, BCN20000, PAD-UFES)에서 평가.

Result: HAM10000: 정확도 92.81%, F1 92.47%; PAD-UFES: 정확도·F1 97.83%; BCN20000: 정확도 91.17%, F1 91.79%. 하이브리드 구조와 CKAN이 표현력 및 분류 성능을 향상시킨다고 주장.

Conclusion: 공간적·문맥적 특징을 모두 포착하는 하이브리드 모델과 CKAN 기반 융합이 피부암 분류에서 경쟁력 있는 성능과 일반화 능력을 제공한다는 결론.

Abstract: Skin cancer classification is a crucial task in medical image analysis, where
precise differentiation between malignant and non-malignant lesions is
essential for early diagnosis and treatment. In this study, we explore
Sequential and Parallel Hybrid CNN-Transformer models with Convolutional
Kolmogorov-Arnold Network (CKAN). Our approach integrates transfer learning and
extensive data augmentation, where CNNs extract local spatial features,
Transformers model global dependencies, and CKAN facilitates nonlinear feature
fusion for improved representation learning. To assess generalization, we
evaluate our models on multiple benchmark datasets (HAM10000,BCN20000 and
PAD-UFES) under varying data distributions and class imbalances. Experimental
results demonstrate that hybrid CNN-Transformer architectures effectively
capture both spatial and contextual features, leading to improved
classification performance. Additionally, the integration of CKAN enhances
feature fusion through learnable activation functions, yielding more
discriminative representations. Our proposed approach achieves competitive
performance in skin cancer classification, demonstrating 92.81% accuracy and
92.47% F1-score on the HAM10000 dataset, 97.83% accuracy and 97.83% F1-score on
the PAD-UFES dataset, and 91.17% accuracy with 91.79% F1- score on the BCN20000
dataset highlighting the effectiveness and generalizability of our model across
diverse datasets. This study highlights the significance of feature
representation and model design in advancing robust and accurate medical image
classification.

</details>


### [81] [Design and Validation of a Responsible Artificial Intelligence-based System for the Referral of Diabetic Retinopathy Patients](https://arxiv.org/abs/2508.12506)
*E. Ulises Moya-Sánchez,Abraham Sánchez-Perez,Raúl Nanclares Da Veiga,Alejandro Zarate-Macías,Edgar Villareal,Alejandro Sánchez-Montes,Edtna Jauregui-Ulloa,Héctor Moreno,Ulises Cortés*

Main category: cs.CV

TL;DR: RAIS-DR는 윤리적 원칙을 AI 생애주기에 통합한 당뇨망막병증(DR) 선별 시스템으로, 전처리·품질평가·세 가지 특화 분류 모델을 사용해 FDA 승인 시스템(EyeArt)보다 로컬 데이터(1,046명)에서 F1 5–12%p, 정확도 6–19%p, 특이도 10–20%p 향상을 보였고, Disparate Impact와 Equal Opportunity Difference 측정에서 인구통계 하위그룹 간 공정성 지표도 양호했다. 코드와 가중치는 공개되어 있다.


<details>
  <summary>Details</summary>
Motivation: 망막사진 기반 DR 자동화는 조기 발견으로 실명 위험을 크게 낮출 수 있으나, 망막전문의 부족과 저품질/편향 데이터로 인해 임상 도입에 제약이 있다. 따라서 기술적 성능뿐 아니라 윤리·공정성을 고려한 책임 있는 AI 시스템이 필요하다.

Method: RAIS-DR은 효율적 합성곱(Convolutional) 모델을 활용해 이미지 전처리와 화질평가를 수행하고, DR 단계별로 특화된 3개의 분류 모델을 배치한 파이프라인을 구성했다. 개발 전 과정에 윤리 원칙(RAI)을 적용했고, 로컬 검증 데이터(1,046명, EyeArt와 동일하게 미검증)를 통해 성능 및 공정성 지표를 비교 평가했다.

Result: RAIS-DR은 로컬 데이터에서 EyeArt 대비 F1 점수 5–12%p, 정확도 6–19%p, 특이도 10–20%p 향상을 기록했다. 공정성 측면에서는 Disparate Impact와 Equal Opportunity Difference에서 하위집단 간 성능 격차가 작아 형평성이 개선된 것으로 보고되었다.

Conclusion: RAIS-DR는 기술적 성능 향상과 더불어 공정성 고려를 결합한 DR 선별 솔루션으로서 임상 적용 가능성이 높다. 다만 결과의 일반화(외부 검증·다기관·전향적 연구)와 규제·임상 평가가 필요하다.

Abstract: Diabetic Retinopathy (DR) is a leading cause of vision loss in working-age
individuals. Early detection of DR can reduce the risk of vision loss by up to
95%, but a shortage of retinologists and challenges in timely examination
complicate detection. Artificial Intelligence (AI) models using retinal fundus
photographs (RFPs) offer a promising solution. However, adoption in clinical
settings is hindered by low-quality data and biases that may lead AI systems to
learn unintended features. To address these challenges, we developed RAIS-DR, a
Responsible AI System for DR screening that incorporates ethical principles
across the AI lifecycle. RAIS-DR integrates efficient convolutional models for
preprocessing, quality assessment, and three specialized DR classification
models. We evaluated RAIS-DR against the FDA-approved EyeArt system on a local
dataset of 1,046 patients, unseen by both systems. RAIS-DR demonstrated
significant improvements, with F1 scores increasing by 5-12%, accuracy by
6-19%, and specificity by 10-20%. Additionally, fairness metrics such as
Disparate Impact and Equal Opportunity Difference indicated equitable
performance across demographic subgroups, underscoring RAIS-DR's potential to
reduce healthcare disparities. These results highlight RAIS-DR as a robust and
ethically aligned solution for DR screening in clinical settings. The code,
weights of RAIS-DR are available at
https://gitlab.com/inteligencia-gubernamental-jalisco/jalisco-retinopathy with
RAIL.

</details>


### [82] [LangVision-LoRA-NAS: Neural Architecture Search for Variable LoRA Rank in Vision Language Models](https://arxiv.org/abs/2508.12512)
*Krishna Teja Chitty-Venkata,Murali Emani,Venkatram Vishwanath*

Main category: cs.CV

TL;DR: VLM(비전-언어 모델)에서 LoRA의 고정 랭크 한계를 보완하기 위해 NAS를 이용해 LoRA의 가중치 랭크를 동적으로 탐색하는 프레임워크를 제안한다. LLaMA-3.2-11B 기반 실험에서 성능 향상과 파인튜닝 비용 절감을 보였고, 코드와 모델을 공개했다.


<details>
  <summary>Details</summary>
Motivation: LoRA는 효율적 파인튜닝 방법이나 고정된 저랭크 설정이 작업별로 비효율적일 수 있어, 작업에 맞춘 가변 랭크 설정이 필요하다. NAS로 최적의 랭크를 자동 탐색하면 성능-비용 균형을 개선할 수 있다는 점이 동기이다.

Method: LangVision-LoRA-NAS는 ViT+LLM 기반 VLM에 대해 LoRA의 랭크를 NAS로 검색한다. 구체적으로는 LLaMA-3.2-11B 비전 지시형 모델에서 층별/모듈별 LoRA 랭크를 탐색하여 성능과 연산·메모리 비용을 균형 있게 최적화한다. 검색된 구성으로 파인튜닝을 수행하고 성능을 비교한다.

Result: 여러 데이터셋에서 검색된 LoRA 랭크 구성은 베이스(고정 랭크) 대비 모델 성능을 높였고, 파인튜닝 비용(파라미터 업데이트/연산량)을 절감했다. 구현 및 파인튜닝된 모델과 코드가 공개되었다.

Conclusion: 가변 랭크 LoRA를 위한 NAS 통합은 VLM 파인튜닝에서 효율성과 성능을 동시에 개선할 수 있는 유망한 접근이다. 다만 추상에는 검색 비용, 검색 알고리즘 세부, 평가 지표·데이터셋 등의 구체적 정보가 부족해 재현성·일반화성 평가가 필요하다.

Abstract: Vision Language Models (VLMs) integrate visual and text modalities to enable
multimodal understanding and generation. These models typically combine a
Vision Transformer (ViT) as an image encoder and a Large Language Model (LLM)
for text generation. LoRA (Low-Rank Adaptation) is an efficient fine-tuning
method to adapt pre-trained models to new tasks by introducing low-rank updates
to their weights. While LoRA has emerged as a powerful technique for
fine-tuning large models by introducing low-rank updates, current
implementations assume a fixed rank, potentially limiting flexibility and
efficiency across diverse tasks. This paper introduces
\textit{LangVision-LoRA-NAS}, a novel framework that integrates Neural
Architecture Search (NAS) with LoRA to optimize VLMs for variable-rank
adaptation. Our approach leverages NAS to dynamically search for the optimal
LoRA rank configuration tailored to specific multimodal tasks, balancing
performance and computational efficiency. Through extensive experiments using
the LLaMA-3.2-11B model on several datasets, LangVision-LoRA-NAS demonstrates
notable improvement in model performance while reducing fine-tuning costs. Our
Base and searched fine-tuned models on LLaMA-3.2-11B-Vision-Instruct can be
found
\href{https://huggingface.co/collections/krishnateja95/llama-32-11b-vision-instruct-langvision-lora-nas-6786cac480357a6a6fcc59ee}{\textcolor{blue}{here}}
and the code for LangVision-LoRA-NAS can be found
\href{https://github.com/krishnateja95/LangVision-NAS}{\textcolor{blue}{here}}.

</details>


### [83] [An Initial Study of Bird's-Eye View Generation for Autonomous Vehicles using Cross-View Transformers](https://arxiv.org/abs/2508.12520)
*Felipe Carlos dos Santos,Eric Aislan Antonelo,Gustavo Claudio Karl Couto*

Main category: cs.CV

TL;DR: 카메라 입력을 Cross-View Transformer로 변환해 BEV의 도로, 차선표시, 주행경로 3가지 채널을 예측. 단일 도시 데이터로 학습했을 때 네 대 카메라와 L1 손실 조합이 보편적으로 가장 강건한 성능을 보임.


<details>
  <summary>Details</summary>
Motivation: 자율주행에서 위-아래(BEV) 지도는 주행 판단에 유리한 구조화된 표현을 제공한다. 카메라만으로도 신뢰할 수 있는 BEV 지도를 얻을 수 있는지를 CVT로 검증하고, 보편화(다른 도시)에 대한 일반화, 카메라 배치 영향, 손실함수 선택을 조사하려 함.

Method: 현실적 도시 시뮬레이터를 사용해 카메라 영상을 세 가지 BEV 채널(도로, 차선표시, 계획경로)로 매핑하도록 Cross-View Transformer(CVT)를 학습. 카메라 레이아웃(다수 카메라 구성)과 두 종류의 손실(focal vs L1)을 비교 평가. 주로 단일 도시 훈련 데이터로 일반화 성능을 테스트.

Result: 단일 도시로 학습했을 때, 4-카메라 CVT 모델이 L1 손실을 사용하면 새로운(보지 못한) 도시에서 가장 견고한 테스트 성능을 보임. 전반적으로 CVT는 카메라 입력을 합리적으로 정확한 BEV 맵으로 매핑하는 데 유망함을 보임.

Conclusion: CVT는 카메라 기반 BEV 예측에 효과적이며, 손실함수 및 카메라 구성 선택이 일반화 성능에 큰 영향을 미친다. 단일 도시 학습만으로도 어느 정도 이전 가능한 모델을 얻을 수 있으나 추가적 데이터 다양화가 필요할 수 있다.

Abstract: Bird's-Eye View (BEV) maps provide a structured, top-down abstraction that is
crucial for autonomous-driving perception. In this work, we employ Cross-View
Transformers (CVT) for learning to map camera images to three BEV's channels -
road, lane markings, and planned trajectory - using a realistic simulator for
urban driving. Our study examines generalization to unseen towns, the effect of
different camera layouts, and two loss formulations (focal and L1). Using
training data from only a town, a four-camera CVT trained with the L1 loss
delivers the most robust test performance, evaluated in a new town. Overall,
our results underscore CVT's promise for mapping camera inputs to reasonably
accurate BEV maps.

</details>


### [84] [MuSACo: Multimodal Subject-Specific Selection and Adaptation for Expression Recognition with Co-Training](https://arxiv.org/abs/2508.12522)
*Muhammad Osama Zeeshan,Natacha Gillet,Alessandro Lameiras Koerich,Marco Pedersoli,Francois Bremond,Eric Granger*

Main category: cs.CV

TL;DR: MuSACo는 멀티모달 정보를 이용해 대상(타깃) 피험자에 맞춰 관련 소스 피험자들을 선택하고, 우세 모달리티 기반의 의사라벨과 클래스-비의존적 손실을 결합해 주제별 적응을 수행하는 MSDA 방법이다. BioVid와 StressID에서 종래 방식들을 능가한다.


<details>
  <summary>Details</summary>
Motivation: 개인마다 감정 표현이 크게 달라 개인화된 표현 인식(ER)이 필요하다. 기존 MSDA는 종종 모달리티를 무시하거나 모든 소스를 섞어(subject-blending) 개인별 특성을 제대로 포착하지 못한다.

Method: (1) 타깃에 관련된 소스 피험자 선택, (2) 우세(지배) 모달리티로부터 의사라벨 생성해 클래스-의존 학습 수행, (3) 덜 확신 있는 타깃 샘플에는 클래스-비의존 손실 적용, (4) 각 모달리티별로 소스 특징 정렬, 확신 있는 타깃 특징만 결합. 방법론은 코트레이닝을 기반으로 다중 모달과 다중 소스를 함께 활용함.

Result: BioVid와 StressID의 멀티모달 ER 실험에서 UDA(소스 블렌딩)와 최신 MSDA 기법들보다 성능 우수성을 보였다.

Conclusion: MuSACo는 모달리티 보완성과 주제별 선택을 결합해_subject-specific_ 적응을 향상시키며, 특히 디지털 헬스(스트레스·통증 평가) 같은 응용에 적합하다.

Abstract: Personalized expression recognition (ER) involves adapting a machine learning
model to subject-specific data for improved recognition of expressions with
considerable interpersonal variability. Subject-specific ER can benefit
significantly from multi-source domain adaptation (MSDA) methods, where each
domain corresponds to a specific subject, to improve model accuracy and
robustness. Despite promising results, state-of-the-art MSDA approaches often
overlook multimodal information or blend sources into a single domain, limiting
subject diversity and failing to explicitly capture unique subject-specific
characteristics. To address these limitations, we introduce MuSACo, a
multi-modal subject-specific selection and adaptation method for ER based on
co-training. It leverages complementary information across multiple modalities
and multiple source domains for subject-specific adaptation. This makes MuSACo
particularly relevant for affective computing applications in digital health,
such as patient-specific assessment for stress or pain, where subject-level
nuances are crucial. MuSACo selects source subjects relevant to the target and
generates pseudo-labels using the dominant modality for class-aware learning,
in conjunction with a class-agnostic loss to learn from less confident target
samples. Finally, source features from each modality are aligned, while only
confident target features are combined. Our experimental results on challenging
multimodal ER datasets: BioVid and StressID, show that MuSACo can outperform
UDA (blending) and state-of-the-art MSDA methods.

</details>


### [85] [REVEAL -- Reasoning and Evaluation of Visual Evidence through Aligned Language](https://arxiv.org/abs/2508.12543)
*Ipsita Praharaj,Yukta Butala,Yash Butala*

Main category: cs.CV

TL;DR: 제안된 REVEAL은 대형 비전-언어 모델의 시맨틱 정렬 능력을 활용해 이미지 위변조 탐지를 프롬프트 기반 시각 추론 문제로 재구성한다. 장면 수준의 물리·시맨틱 검증과 영역 단위 이상치 탐지를 병행해 다양한 도메인(포토샵, 딥페이크, AIGC 편집)에서의 일반화 성능을 평가한다.


<details>
  <summary>Details</summary>
Motivation: 생성모델 발달로 이미지 위변조 판별·설명·국소화가 중요해졌지만, 기존의 감독학습이나 임베딩 이상치 탐지는 도메인 일반화와 추론 설명에서 한계가 있음. VLM의 시맨틱 정렬과 언어적 추론을 이용하면 더 일반화 가능한 탐지 및 근거 제시가 가능하다는 점을 동기화함.

Method: REVEAL 프레임워크: (1) Holistic Scene-level Evaluation — 이미지 전체의 물리성, 시맨틱 일관성, 원근·현실성 등을 검사하는 지침 기반 프롬프트를 VLM에 제시; (2) Region-wise Anomaly Detection — 이미지를 여러 영역으로 분할해 각 영역의 이상징후를 개별적으로 분석. 결과로 탐지(진위), 국소화(오류영역), 그리고 텍스트 근거(추론)를 출력.

Result: 여러 도메인의 데이터셋(포토샵 편집, 딥페이크, AIGC 편집)에서 VLM 기반 접근을 경쟁기준과 비교 평가. 전반적으로 VLM이 설명 가능성 측면에서 장점이 있고, 일부 도메인에서 유의미한 탐지 성능을 보였으나 구체적 수치·일반화 한계는 데이터셋·프롬프트에 민감함.

Conclusion: 프롬프트 기반 VLM 활용은 위변조 탐지에 유망하나, 영역 분할 전략, 프롬프트 설계, 도메인 다양성에 따라 성능 편차가 크다. REVEAL은 설명 가능한 탐지 프레임워크로서 가능성을 보이나, 정량적 일반화와 신뢰성 확보를 위한 추가 연구가 필요함.

Abstract: The rapid advancement of generative models has intensified the challenge of
detecting and interpreting visual forgeries, necessitating robust frameworks
for image forgery detection while providing reasoning as well as localization.
While existing works approach this problem using supervised training for
specific manipulation or anomaly detection in the embedding space,
generalization across domains remains a challenge. We frame this problem of
forgery detection as a prompt-driven visual reasoning task, leveraging the
semantic alignment capabilities of large vision-language models. We propose a
framework, `REVEAL` (Reasoning and Evaluation of Visual Evidence through
Aligned Language), that incorporates generalized guidelines. We propose two
tangential approaches - (1) Holistic Scene-level Evaluation that relies on the
physics, semantics, perspective, and realism of the image as a whole and (2)
Region-wise anomaly detection that splits the image into multiple regions and
analyzes each of them. We conduct experiments over datasets from different
domains (Photoshop, DeepFake and AIGC editing). We compare the Vision Language
Models against competitive baselines and analyze the reasoning provided by
them.

</details>


### [86] [Structure-preserving Feature Alignment for Old Photo Colorization](https://arxiv.org/abs/2508.12570)
*Yingxue Pang,Xin Jin,Jun Fu,Zhibo Chen*

Main category: cs.CV

TL;DR: 두 장(대상 오래된 사진 + 참조)만으로 학습해 오래된 사진의 도메인 갭을 극복하고 의미 대응 기반으로 색을 전달하는 CNN 기반 방법(SFAC)을 제안. 구조 왜곡을 줄이기 위해 특성 수준의 지각 제약과 픽셀 수준의 frozen-updated 피라미드 도입.


<details>
  <summary>Details</summary>
Motivation: 기존 참조 기반 컬러라이제이션은 대규모 데이터에 의존하거나 자연 흑백 이미지와 오래된 사진 간의 도메인 갭 때문에 성능이 떨어짐. 실제 오래된 사진에는 정답(ground truth)이 없어 감독 학습이 어려움.

Method: 두 장의 이미지(대상+참조)만으로 학습. 의미적 대응을 확보하기 위해 특성 분포 정렬 손실(feature distribution alignment loss)을 사용하며, 구조 보존을 위해 특성 수준의 지각(perceptual) 제약과 픽셀 수준의 frozen-updated 피라미드 구조를 도입해 색 전달 중 구조 왜곡을 억제함.

Result: 질적·양적 실험에서 오래된 사진 색채화에 효과적이라고 주장. 제시된 손실은 거리(metric) 선택에 대해 견고하며, 구조 보존 메커니즘이 왜곡을 줄였다고 보고.

Conclusion: 대규모 데이터 없이도 오래된 사진 도메인에 직접 적용 가능한 실용적 방법을 제안하며, 의미적 일치와 구조 보존의 조합이 성능 향상에 기여한다고 결론지음.

Abstract: Deep learning techniques have made significant advancements in
reference-based colorization by training on large-scale datasets. However,
directly applying these methods to the task of colorizing old photos is
challenging due to the lack of ground truth and the notorious domain gap
between natural gray images and old photos. To address this issue, we propose a
novel CNN-based algorithm called SFAC, i.e., Structure-preserving Feature
Alignment Colorizer. SFAC is trained on only two images for old photo
colorization, eliminating the reliance on big data and allowing direct
processing of the old photo itself to overcome the domain gap problem. Our
primary objective is to establish semantic correspondence between the two
images, ensuring that semantically related objects have similar colors. We
achieve this through a feature distribution alignment loss that remains robust
to different metric choices. However, utilizing robust semantic correspondence
to transfer color from the reference to the old photo can result in inevitable
structure distortions. To mitigate this, we introduce a structure-preserving
mechanism that incorporates a perceptual constraint at the feature level and a
frozen-updated pyramid at the pixel level. Extensive experiments demonstrate
the effectiveness of our method for old photo colorization, as confirmed by
qualitative and quantitative metrics.

</details>


### [87] [Foundation Model for Skeleton-Based Human Action Understanding](https://arxiv.org/abs/2508.12586)
*Hongsong Wang,Wanjiang Weng,Junbo Wang,Fang Zhao,Guo-Sen Xie,Xin Geng,Liang Wang*

Main category: cs.CV

TL;DR: USDRL은 스켈레톤 기반 행동 이해를 위한 파운데이션 모델로, Transformer 기반의 Dense Spatio-Temporal Encoder(DSTE), Multi-Grained Feature Decorrelation(MG-FD), Multi-Perspective Consistency Training(MPCT)을 결합하여 시간·공간·인스턴스 차원에서 특징 비중복화와 다중 뷰/다중 모달 일관성 학습을 수행한다. 25개 벤치마크, 9개 작업에서 기존 최첨단 대비 우수한 성능을 보였다.


<details>
  <summary>Details</summary>
Motivation: 기존 연구는 다양한 행동 이해 과제를 한 모델로 처리할 수 있는 확장성·일반화 능력이 부족하며, 특히 밀집 예측(dense prediction) 작업을 포괄하는 스켈레톤 파운데이션 모델이 부재하다. 이를 해결하기 위한 범용적 표현 학습 필요성이 본 논문의 동기다.

Method: DSTE: 시간적 동역학과 공간적 구조를 각각 병렬 스트림으로 학습하는 Transformer 기반 인코더. MG-FD: 시간·공간·인스턴스 도메인 전반에서 특징의 상관성을 낮춰 차원 중복을 줄이고 표현 효율을 높이는 데코릴레이션 기법. MPCT: 다중 뷰(self-view augmentation)와 다중 모달(스켈레톤 외 다른 모달) 간의 자기 지도 일관성 학습으로 고수준 의미론과 유익한 멀티모달 특징을 확보함.

Result: 광범위한 실험(25개 벤치마크, 9개 작업: coarse, dense, transferred prediction 포함)에서 기존 방법들을 유의미하게 능가. 특히 밀집 예측 작업에서의 성능 향상을 강조.

Conclusion: USDRL은 스켈레톤 기반 행동 이해의 범위를 넓히고 밀집 예측을 포함한 다양한 과제에 적응 가능한 파운데이션 모델을 제시한다. 향후 로봇 제어·상호작용 등 응용에 기여할 전망이다.

Abstract: Human action understanding serves as a foundational pillar in the field of
intelligent motion perception. Skeletons serve as a modality- and
device-agnostic representation for human modeling, and skeleton-based action
understanding has potential applications in humanoid robot control and
interaction. \RED{However, existing works often lack the scalability and
generalization required to handle diverse action understanding tasks. There is
no skeleton foundation model that can be adapted to a wide range of action
understanding tasks}. This paper presents a Unified Skeleton-based Dense
Representation Learning (USDRL) framework, which serves as a foundational model
for skeleton-based human action understanding. USDRL consists of a
Transformer-based Dense Spatio-Temporal Encoder (DSTE), Multi-Grained Feature
Decorrelation (MG-FD), and Multi-Perspective Consistency Training (MPCT). The
DSTE module adopts two parallel streams to learn temporal dynamic and spatial
structure features. The MG-FD module collaboratively performs feature
decorrelation across temporal, spatial, and instance domains to reduce
dimensional redundancy and enhance information extraction. The MPCT module
employs both multi-view and multi-modal self-supervised consistency training.
The former enhances the learning of high-level semantics and mitigates the
impact of low-level discrepancies, while the latter effectively facilitates the
learning of informative multimodal features. We perform extensive experiments
on 25 benchmarks across across 9 skeleton-based action understanding tasks,
covering coarse prediction, dense prediction, and transferred prediction. Our
approach significantly outperforms the current state-of-the-art methods. We
hope that this work would broaden the scope of research in skeleton-based
action understanding and encourage more attention to dense prediction tasks.

</details>


### [88] [Multimodal Chain of Continuous Thought for Latent-Space Reasoning in Vision-Language Models](https://arxiv.org/abs/2508.12587)
*Tan-Hanh Pham,Chris Ngo*

Main category: cs.CV

TL;DR: 제안된 MCOUT는 자연어가 아닌 공동 잠재 공간에서 연속적 추론 상태를 유지하고 반복적으로 정제해 다중 모달 추론 성능을 향상시키는 방법이다. 두 변형(MCOUT-Base, MCOUT-Multi)을 통해 시각·텍스트 정렬을 강화하고 여러 벤치마크에서 최대 약 8% 포인트의 정확도, BLEU 향상을 보고한다.


<details>
  <summary>Details</summary>
Motivation: CoT 같은 언어 기반 추론은 텍스트에선 효과적이지만 오디오·비주얼 등 다중 모달 정보를 동적으로 정렬해 추론하는 데 한계가 있어, 자연어에 의존하지 않는 잠재 연속 추론 방식을 탐구하려 함.

Method: 추론 상태를 연속적 히든 벡터로 유지하고 반복적으로 정제·정렬한다. MCOUT-Base는 언어모델의 마지막 히든 스테이트를 재사용해 연속적 사고로 활용하고, MCOUT-Multi는 멀티모달 잠재 어텐션을 도입해 시각·텍스트 간 크로스모달 정렬을 강화함.

Result: MMMU, ScienceQA, MMStar 등에서 기존 강력한 베이스라인 대비 최대 8.23% 정확도 향상과 최대 8.27% BLEU 향상을 보고함. 전반적으로 다중 모달 추론 성능이 일관되게 개선됨.

Conclusion: 언어에 묶이지 않는 잠재연속 추론은 LMM(대형 멀티모달 모델)의 다중 모달 추론 향상에 유망한 방향이며, 인간의 성찰적 인지 방식을 모사하는 확장 가능한 프레임워크를 제시함.

Abstract: Many reasoning techniques for large multimodal models adapt language model
approaches, such as Chain-of-Thought (CoT) prompting, which express reasoning
as word sequences. While effective for text, these methods are suboptimal for
multimodal contexts, struggling to align audio, visual, and textual information
dynamically. To explore an alternative paradigm, we propose the Multimodal
Chain of Continuous Thought (MCOUT), which enables reasoning directly in a
joint latent space rather than in natural language. In MCOUT, the reasoning
state is represented as a continuous hidden vector, iteratively refined and
aligned with visual and textual embeddings, inspired by human reflective
cognition. We develop two variants: MCOUT-Base, which reuses the language
model`s last hidden state as the continuous thought for iterative reasoning,
and MCOUT-Multi, which integrates multimodal latent attention to strengthen
cross-modal alignment between visual and textual features. Experiments on
benchmarks including MMMU, ScienceQA, and MMStar show that MCOUT consistently
improves multimodal reasoning, yielding up to 8.23% accuracy gains over strong
baselines and improving BLEU scores up to 8.27% across multiple-choice and
open-ended tasks. These findings highlight latent continuous reasoning as a
promising direction for advancing LMMs beyond language-bound CoT, offering a
scalable framework for human-like reflective multimodal inference. Code is
available at https://github.com/Hanhpt23/OmniMod.

</details>


### [89] [ViLaD: A Large Vision Language Diffusion Framework for End-to-End Autonomous Driving](https://arxiv.org/abs/2508.12603)
*Can Cui,Yupeng Zhou,Juntong Peng,Sung-Yeon Park,Zichong Yang,Prashanth Sankaranarayanan,Jiaru Zhang,Ruqi Zhang,Ziran Wang*

Main category: cs.CV

TL;DR: ViLaD는 마스킹된 확산 기반의 대형 비전-언어 확산 모델(LVLD)로, 운전 결정을 토큰 단위가 아니라 전체 시퀀스 병렬 생성하여 지연을 크게 줄이고, 과거·미래를 동시에 고려하는 양방향 추론과 점진적 easy-first 개선을 지원한다. nuScenes 실험과 실제 주차 실차 배치에서 기존 자기회귀 VLM보다 정확도·속도 면에서 우수하고 실패율이 거의 0에 가까웠다.


<details>
  <summary>Details</summary>
Motivation: 기존의 자기회귀 VLM은 토큰 단위 순차 생성으로 추론 지연이 크고 양방향(과거·미래 동시) 추론이 불가능해 동적·안전중심의 자율주행에 부적합하다.

Method: 마스킹된 확산(masked diffusion) 기반의 LVLD 프레임워크(ViLaD)를 제안. 전체 운전 결정 시퀀스를 병렬로 생성하고, 마스킹과 반복적 재구성을 통해 양방향 추론 및 점진적 easy-first 생성으로 품질을 향상시킨다.

Result: nuScenes에서 자기회귀 VLM 기반 최첨단 모델들보다 계획 정확도와 추론 속도에서 우수한 성능을 보였고 실패율은 거의 0에 근접. 또한 실제 자율차량에서의 인터랙티브 주차 태스크 배치로 실용성 검증 완료.

Conclusion: ViLaD는 낮은 지연, 양방향 추론, 반복적 개선을 통해 실무적 제약을 해소한 새로운 VLM 기반 종단간 자율주행 패러다임을 제시하며 시뮬레이션과 실제 환경에서 유의미한 이점을 입증했다.

Abstract: End-to-end autonomous driving systems built on Vision Language Models (VLMs)
have shown significant promise, yet their reliance on autoregressive
architectures introduces some limitations for real-world applications. The
sequential, token-by-token generation process of these models results in high
inference latency and cannot perform bidirectional reasoning, making them
unsuitable for dynamic, safety-critical environments. To overcome these
challenges, we introduce ViLaD, a novel Large Vision Language Diffusion (LVLD)
framework for end-to-end autonomous driving that represents a paradigm shift.
ViLaD leverages a masked diffusion model that enables parallel generation of
entire driving decision sequences, significantly reducing computational
latency. Moreover, its architecture supports bidirectional reasoning, allowing
the model to consider both past and future simultaneously, and supports
progressive easy-first generation to iteratively improve decision quality. We
conduct comprehensive experiments on the nuScenes dataset, where ViLaD
outperforms state-of-the-art autoregressive VLM baselines in both planning
accuracy and inference speed, while achieving a near-zero failure rate.
Furthermore, we demonstrate the framework's practical viability through a
real-world deployment on an autonomous vehicle for an interactive parking task,
confirming its effectiveness and soundness for practical applications.

</details>


### [90] [ViDA-UGC: Detailed Image Quality Analysis via Visual Distortion Assessment for UGC Images](https://arxiv.org/abs/2508.12605)
*Wenjie Liao,Jieyu Yuan,Yifang Xu,Chunle Guo,Zilong Zhang,Jihong Li,Jiachen Fu,Haotian Fan,Tao Li,Junhui Cui,Chongyi Li*

Main category: cs.CV

TL;DR: ViDA-UGC는 사용자 생성 이미지(UGC)를 위해 구축한 대규모 왜곡 평가 및 설명 데이터셋이다(11K 이미지). 사람 주석과 Chain-of-Thought(CoT)를 이용해 GPT-4o로 세밀한 왜곡 분석·설명 데이터를 생성하고, 전문가가 검수한 476장·6,149 QA로 ViDA-UGC-Bench 벤치마크를 만들었다. 이를 통해 여러 MLLM의 설명 가능한 이미지 품질 평가 능력이 향상되며 일부 경우 GPT-4o를 능가한다.


<details>
  <summary>Details</summary>
Motivation: 기존 설명 가능한 IQA 연구들이 UGC와 AIGC에 동일한 왜곡 기준을 적용하고, 품질 모니터링·복원 지침을 위한 세부적 품질 분석이 부족하다는 문제를 해결하려 함.

Method: 왜곡 지향 파이프라인을 설계해 사람 주석을 수집하고, CoT 평가 프레임워크로 GPT-4o가 저수준 시각 특징과 왜곡 패턴을 식별·분석해 상세 품질 설명을 생성하도록 함. 생성 데이터 중 476장을 선별해 전문가가 수정·검수하여 벤치마크를 구축.

Result: ViDA-UGC 데이터셋(11K)과 ViDA-UGC-Bench(476장·6,149 QA)를 공개하고, 다수의 기본 MLLM에 대해 학습시켰을 때 설명형 IQA 능력이 일관되게 향상됨. 일부 실험에서 GPT-4o 성능을 초과.

Conclusion: UGC에 특화된 왜곡 중심의 CoT 기반 지침 튜닝은 설명 가능한 IQA 능력을 크게 개선하며, 품질 모니터링·복원 가이드용 실용적 자원을 제공한다.

Abstract: Recent advances in Multimodal Large Language Models (MLLMs) have introduced a
paradigm shift for Image Quality Assessment (IQA) from unexplainable image
quality scoring to explainable IQA, demonstrating practical applications like
quality control and optimization guidance. However, current explainable IQA
methods not only inadequately use the same distortion criteria to evaluate both
User-Generated Content (UGC) and AI-Generated Content (AIGC) images, but also
lack detailed quality analysis for monitoring image quality and guiding image
restoration. In this study, we establish the first large-scale Visual
Distortion Assessment Instruction Tuning Dataset for UGC images, termed
ViDA-UGC, which comprises 11K images with fine-grained quality grounding,
detailed quality perception, and reasoning quality description data. This
dataset is constructed through a distortion-oriented pipeline, which involves
human subject annotation and a Chain-of-Thought (CoT) assessment framework.
This framework guides GPT-4o to generate quality descriptions by identifying
and analyzing UGC distortions, which helps capturing rich low-level visual
features that inherently correlate with distortion patterns. Moreover, we
carefully select 476 images with corresponding 6,149 question answer pairs from
ViDA-UGC and invite a professional team to ensure the accuracy and quality of
GPT-generated information. The selected and revised data further contribute to
the first UGC distortion assessment benchmark, termed ViDA-UGC-Bench.
Experimental results demonstrate the effectiveness of the ViDA-UGC and CoT
framework for consistently enhancing various image quality analysis abilities
across multiple base MLLMs on ViDA-UGC-Bench and Q-Bench, even surpassing
GPT-4o.

</details>


### [91] [OpenMoCap: Rethinking Optical Motion Capture under Real-world Occlusion](https://arxiv.org/abs/2508.12610)
*Chen Qian,Danyang Li,Xinran Yu,Zheng Yang,Qiang Ma*

Main category: cs.CV

TL;DR: 대규모 마커 가림(occlusion) 상황에서 강인한 모션 캡처를 목표로, 현실적 가림 패턴을 시뮬레이션한 CMU-Occlu 데이터셋과 마커-관절 체인 추론을 활용해 긴 종속성을 학습하는 OpenMoCap 모델을 제안한다. OpenMoCap은 다양한 시나리오에서 기존 방법들을 일관되게 능가하며 실제 시스템(MoSen)에 통합되어 공개 코드로 제공된다.


<details>
  <summary>Details</summary>
Motivation: 현재 모션 솔빙 모델들은 (i) 현실적 마커 가림 패턴을 반영한 학습 데이터 부족, (ii) 마커 간 장거리 의존성을 포착하는 학습 전략 부재로 인해 가림 상황에서 성능이 크게 저하된다는 문제를 해결하고자 함.

Method: CMU-Occlu 데이터셋: 광선추적(ray tracing)을 사용해 실제에 가까운 마커 가림 패턴을 생성. OpenMoCap 모델: 마커-관절(chain) 추론 메커니즘을 도입해 마커와 관절 사이의 심층 제약을 동시에 구성하고 최적화함으로써 장거리 의존성 학습 및 가림 상황에 대한 강인성을 확보. 실제 MoSen MoCap 시스템에 통합하여 적용성을 검증함.

Result: 광범위한 비교 실험에서 OpenMoCap은 가림이 많은 환경에서 기존 방법들보다 일관되게 우수한 성능을 보였음. CMU-Occlu는 향후 강인한 모션 솔빙 연구를 촉진할 수 있는 벤치마크를 제공함.

Conclusion: 현실적 가림 시나리오를 반영한 데이터셋과 마커-관절 체인 기반 학습 전략을 결합함으로써 대규모 마커 가림 환경에서의 모션 캡처 성능을 크게 향상시키며, 코드·시스템 통합으로 실무 적용 가능성을 입증하였다.

Abstract: Optical motion capture is a foundational technology driving advancements in
cutting-edge fields such as virtual reality and film production. However,
system performance suffers severely under large-scale marker occlusions common
in real-world applications. An in-depth analysis identifies two primary
limitations of current models: (i) the lack of training datasets accurately
reflecting realistic marker occlusion patterns, and (ii) the absence of
training strategies designed to capture long-range dependencies among markers.
To tackle these challenges, we introduce the CMU-Occlu dataset, which
incorporates ray tracing techniques to realistically simulate practical marker
occlusion patterns. Furthermore, we propose OpenMoCap, a novel motion-solving
model designed specifically for robust motion capture in environments with
significant occlusions. Leveraging a marker-joint chain inference mechanism,
OpenMoCap enables simultaneous optimization and construction of deep
constraints between markers and joints. Extensive comparative experiments
demonstrate that OpenMoCap consistently outperforms competing methods across
diverse scenarios, while the CMU-Occlu dataset opens the door for future
studies in robust motion solving. The proposed OpenMoCap is integrated into the
MoSen MoCap system for practical deployment. The code is released at:
https://github.com/qianchen214/OpenMoCap.

</details>


### [92] [WIPES: Wavelet-based Visual Primitives](https://arxiv.org/abs/2508.12615)
*Wenhao Zhang,Hao Zhu,Delong Wu,Di Kang,Linchao Bao,Zhan Ma,Xun Cao*

Main category: cs.CV

TL;DR: WIPES는 웨이블릿 기반의 다차원 시각 프리미티브로, 저·고주파를 동시에 포착하고 웨이블릿 기반 미분 가능한 래스터라이저로 빠르게 렌더링하여 INR보다 빠르고 Gaussian 기반보다 화질이 우수하다고 주장한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 연속적 시각 표현은 주파수 유도 또는 복잡한 신경망 디코더에 의존해 스펙트럼 손실이나 느린 렌더링을 초래한다. 이에 대한 해결책으로 주파수와 공간을 동시에 잘 포착하는 표현이 필요하다.

Method: 웨이블릿의 시공간-주파수 국지화 장점을 이용한 WIPES(웨이블릿 기반 시각 프리미티브)를 제안하고, 이를 빠른 렌더링을 위한 웨이블릿 기반 미분 가능 래스터라이저와 결합했다. 다차원(2D, 5D 정적, 6D 동적) 신호에 적용 가능한 범용 표현을 목표로 한다.

Result: 실험에서 WIPES는 INR(implicit neural representations) 기반 기법보다 렌더링 품질이 높고 추론 속도가 빠르며, Gaussian 기반 표현보다 렌더링 품질이 우수하다고 보고한다.

Conclusion: 웨이블릿 기반 프리미티브와 미분 가능 래스터라이저 조합은 주파수 조절이 유연하고 빠른 렌더링을 제공해 다양한 시각 작업에서 실용적인 대안이 될 수 있다.

Abstract: Pursuing a continuous visual representation that offers flexible frequency
modulation and fast rendering speed has recently garnered increasing attention
in the fields of 3D vision and graphics. However, existing representations
often rely on frequency guidance or complex neural network decoding, leading to
spectrum loss or slow rendering. To address these limitations, we propose
WIPES, a universal Wavelet-based vIsual PrimitivES for representing
multi-dimensional visual signals. Building on the spatial-frequency
localization advantages of wavelets, WIPES effectively captures both the
low-frequency "forest" and the high-frequency "trees." Additionally, we develop
a wavelet-based differentiable rasterizer to achieve fast visual rendering.
Experimental results on various visual tasks, including 2D image
representation, 5D static and 6D dynamic novel view synthesis, demonstrate that
WIPES, as a visual primitive, offers higher rendering quality and faster
inference than INR-based methods, and outperforms Gaussian-based
representations in rendering quality.

</details>


### [93] [Creative4U: MLLMs-based Advertising Creative Image Selector with Comparative Reasoning](https://arxiv.org/abs/2508.12628)
*Yukang Lin,Xiang Zhang,Shichang Jia,Bowen Wan,Chenghan Fu,Xudong Ren,Yueran Liu,Wanxian Guan,Pengji Wang,Jian Xu,Bo Zheng,Baolin Liu*

Main category: cs.CV

TL;DR: 멀티모달 LLM을 이용한 설명 가능한 광고 크리에이티브 이미지 평가·선택 패러다임 제안, 비교 데이터셋(CreativePair)과 사용자 관심 반영 선택기(Creative4U) 및 CoT 기반 SFT+강화학습(GRPO)으로 성능 개선.


<details>
  <summary>Details</summary>
Motivation: AIGC로 대량의 광고 크리에이티브 제작이 쉬워졌지만, 어떤 이미지를 선택할지에 대한 설명 가능하고 신뢰할 수 있는 평가 수단이 부족하여 플랫폼·광고주가 고품질 이미지를 고르기 어려움.

Method: MLLM을 자연어 생성 문제로 재구성해 이미지 비교·선택을 설명 가능하게 수행. 비교 기반 라벨이 포함된 8k 쌍의 CreativePair 데이터셋 구축. Creative4U 모델은 사용자 관심 반영, Reason-to-Select RFT 파이프라인(Chain-of-Thought SFT + Group Relative Policy Optimization 강화학습)을 사용해 선택기 학습.

Result: 오프라인·온라인 실험에서 Creative4U가 정확하고 설명 가능한 이미지 평가·선택 성능을 보임(구체적 수치 미기재). 데이터셋·코드 공개 예정.

Conclusion: 설명 가능한 크리에이티브 선택을 위한 최초의 패러다임과 실용적 도구·데이터셋을 제시해 관련 연구 및 산업 적용에 기여함.

Abstract: Creative image in advertising is the heart and soul of e-commerce platform.
An eye-catching creative image can enhance the shopping experience for users,
boosting income for advertisers and advertising revenue for platforms. With the
advent of AIGC technology, advertisers can produce large quantities of creative
images at minimal cost. However, they struggle to assess the creative quality
to select. Existing methods primarily focus on creative ranking, which fails to
address the need for explainable creative selection.
  In this work, we propose the first paradigm for explainable creative
assessment and selection. Powered by multimodal large language models (MLLMs),
our approach integrates the assessment and selection of creative images into a
natural language generation task. To facilitate this research, we construct
CreativePair, the first comparative reasoning-induced creative dataset
featuring 8k annotated image pairs, with each sample including a label
indicating which image is superior. Additionally, we introduce Creative4U
(pronounced Creative for You), a MLLMs-based creative selector that takes into
account users' interests. Through Reason-to-Select RFT, which includes
supervised fine-tuning with Chain-of-Thought (CoT-SFT) and Group Relative
Policy Optimization (GRPO) based reinforcement learning, Creative4U is able to
evaluate and select creative images accurately. Both offline and online
experiments demonstrate the effectiveness of our approach. Our code and dataset
will be made public to advance research and industrial applications.

</details>


### [94] [SpotVLM: Cloud-edge Collaborative Real-time VLM based on Context Transfer](https://arxiv.org/abs/2508.12638)
*Chen Qian,Xinran Yu,Zewen Huang,Danyang Li,Qiang Ma,Fan Dang,Xuan Ding,Guangyong Shang,Zheng Yang*

Main category: cs.CV

TL;DR: 제안된 Context Transfer 패러다임은 지연되어 도착하는 대형 VLM(LVLM)의 출력을 '과거 컨텍스트'로 취급하여 경계 단의 소형 VLM(SVLM) 추론을 실시간으로 안내한다. SpotVLM은 컨텍스트 교체(context replacement)와 시각 집중(visual focus) 모듈을 도입해 과거 텍스트 입력을 정제하고 시각적 그라운딩 일관성을 향상한다. 실험에서 실시간 비전 과제 3종, 4개 데이터셋에 대해 유의미한 성능 향상을 보였다.


<details>
  <summary>Details</summary>
Motivation: 실시간 애플리케이션(예: 자율주행, HCI)은 빠르고 신뢰할 수 있는 인지 응답이 필요하나 클라우드-엣지 분산 환경에서는 클라우드 LVLM의 지연 변동으로 인해 일관된 성능을 유지하기 어렵다. 기존의 모델 분할 혹은 LVLM/SVLM 오프로드 전략은 지연 변동을 충분히 고려하지 못하고, 지연된 LVLM의 정확한 응답을 유용한 자원으로 활용하지 못한다.

Method: Context Transfer라는 컴퓨팅 패러다임을 정의하고, 이를 구현하는 SpotVLM을 제안함. 핵심은 (1) 지연되어 도착한 LVLM의 출력을 ‘과거 컨텍스트’로 보관하고, (2) 컨텍스트 교체 모듈로 불필요/오류 텍스트를 정제하며, (3) 시각 집중 모듈로 이미지-텍스트 그라운딩을 보강해 SVLM의 실시간 추론에 반영하는 파이프라인이다. 이로써 SVLM은 현재 입력과 과거 정확한 LVLM 피드백을 결합해 더 신뢰도 높은 응답을 생성한다.

Result: 세 가지 실시간 비전 태스크(논문은 구체 태스크 표기 필요)와 네 개 데이터셋에서 평가해 제안 방법이 기존 클라우드-엣지 협력 방식 대비 성능 향상 및 레이턴시 변화에 대한 견고성을 보였다고 보고함. 정량적 지표와 사례 분석으로 개선 효과를 제시함.

Conclusion: 지연된 LVLM 출력을 단순 대기물이 아니라 유용한 역사적 컨텍스트로 활용하는 Context Transfer 패러다임은, 클라우드-엣지 협력 기반 VLM 시스템의 레이턴시 인식 협업을 위한 새로운 방향을 제시한다. SpotVLM의 모듈 구조은 실시간 응용에서 성능과 일관성 향상에 기여한다.

Abstract: Vision-Language Models (VLMs) are increasingly deployed in real-time
applications such as autonomous driving and human-computer interaction, which
demand fast and reliable responses based on accurate perception. To meet these
requirements, existing systems commonly employ cloud-edge collaborative
architectures, such as partitioned Large Vision-Language Models (LVLMs) or task
offloading strategies between Large and Small Vision-Language Models (SVLMs).
However, these methods fail to accommodate cloud latency fluctuations and
overlook the full potential of delayed but accurate LVLM responses. In this
work, we propose a novel cloud-edge collaborative paradigm for VLMs, termed
Context Transfer, which treats the delayed outputs of LVLMs as historical
context to provide real-time guidance for SVLMs inference. Based on this
paradigm, we design SpotVLM, which incorporates both context replacement and
visual focus modules to refine historical textual input and enhance visual
grounding consistency. Extensive experiments on three real-time vision tasks
across four datasets demonstrate the effectiveness of the proposed framework.
The new paradigm lays the groundwork for more effective and latency-aware
collaboration strategies in future VLM systems.

</details>


### [95] [Synthesizing Accurate and Realistic T1-weighted Contrast-Enhanced MR Images using Posterior-Mean Rectified Flow](https://arxiv.org/abs/2508.12640)
*Bastian Brandstötter,Erich Kobler*

Main category: cs.CV

TL;DR: 두 단계의 Posterior-Mean Rectified Flow(PMRF)를 이용해 비조영 T1w MRI에서 조영증강(CE) T1w 볼륨을 합성: 3D U-Net으로 후방평균(posterior mean)을 예측한 뒤, 시계열 조건화된 3D rectified flow로 텍스처를 보정해 현실성을 높임. 테스트에서 FID 12.46, KID 0.007을 달성하며 구조 충실도를 크게 해치지 않음.


<details>
  <summary>Details</summary>
Motivation: 가돌리늄 기반 조영제는 비용·검사시간·환경·환자 위험 문제를 유발하므로, 조영제를 사용하지 않고도 임상적으로 유용한 CE 이미지를 합성하려는 필요가 있음.

Method: 1) 패치 기반 3D U-Net으로 각 복셀의 posterior mean(평균 제곱오차 최소화) 추정. 2) 시간 조건화된 3D rectified flow(난수-시간 기반 확률적 복원)으로 초기 추정을 고해상도 텍스처와 현실성으로 정제. BraTS 2023–2025 다기관 쌍대(pre/post) T1w 볼륨으로 학습. 평가 지표: axial FID, KID, volumetric MSE 등.

Result: 보정된(정제된) 출력: axial FID=12.46, KID=0.007 (posterior mean 대비 FID 약 68.7% 감소), volumetric MSE=0.057 (posterior mean 대비 약 27% 증가). 정성평가에서 병변 경계와 혈관 디테일 복원이 현실적임을 보고. 지각-왜곡(perception–distortion) 트레이드오프를 잘 조절함.

Conclusion: PMRF는 구조적 충실도를 유지하면서 시각적 현실성을 크게 개선해 임상적 적용 가능성이 높음. 추가 외적검증과 안전성/임상유효성 평가가 필요함.

Abstract: Contrast-enhanced (CE) T1-weighted MRI is central to neuro-oncologic
diagnosis but requires gadolinium-based agents, which add cost and scan time,
raise environmental concerns, and may pose risks to patients. In this work, we
propose a two-stage Posterior-Mean Rectified Flow (PMRF) pipeline for
synthesizing volumetric CE brain MRI from non-contrast inputs. First, a
patch-based 3D U-Net predicts the voxel-wise posterior mean (minimizing MSE).
Then, this initial estimate is refined by a time-conditioned 3D rectified flow
to incorporate realistic textures without compromising structural fidelity. We
train this model on a multi-institutional collection of paired pre- and
post-contrast T1w volumes (BraTS 2023-2025). On a held-out test set of 360
diverse volumes, our best refined outputs achieve an axial FID of $12.46$ and
KID of $0.007$ ($\sim 68.7\%$ lower FID than the posterior mean) while
maintaining low volumetric MSE of $0.057$ ($\sim 27\%$ higher than the
posterior mean). Qualitative comparisons confirm that our method restores
lesion margins and vascular details realistically, effectively navigating the
perception-distortion trade-off for clinical deployment.

</details>


### [96] [Vision-G1: Towards General Vision Language Reasoning with Multi-Domain Data Curation](https://arxiv.org/abs/2508.12680)
*Yuheng Zha,Kun Zhou,Yujia Wu,Yushu Wang,Jie Feng,Zhi Xu,Shibo Hao,Zhengzhong Liu,Eric P. Xing,Zhiting Hu*

Main category: cs.CV

TL;DR: Built a large RL-ready visual reasoning dataset from 46 sources across 8 domains and used influence-function data selection plus difficulty filtering; trained Vision-G1 with multi-round RL + curriculum and achieved SOTA on multiple visual reasoning benchmarks, reportedly outperforming similar-sized VLMs and proprietary models.


<details>
  <summary>Details</summary>
Motivation: Current VLM training focuses on narrow reasoning tasks (math/logical), so models fail to generalize due to scarce, verifiable reward data beyond those areas and uncertain compatibility among domain datasets.

Method: Assemble dataset covering infographic, mathematical, spatial, cross-image, GUI, medical, common-sense, and general science; use influence functions to select high-quality samples and difficulty-based filtering; train Vision-G1 via iterative multi-round RL with a data curriculum.

Result: Vision-G1 obtains state-of-the-art performance across various visual reasoning benchmarks, outperforming similar-sized open models and reportedly beating proprietary systems like GPT-4o and Gemini-1.5 Flash; dataset, code and model released.

Conclusion: A diversified, carefully curated RL-ready dataset combined with curriculum-based multi-round RL can significantly improve cross-domain visual reasoning in VLMs and enables broader generalization beyond traditional narrow benchmarks.

Abstract: Despite their success, current training pipelines for reasoning VLMs focus on
a limited range of tasks, such as mathematical and logical reasoning. As a
result, these models face difficulties in generalizing their reasoning
capabilities to a wide range of domains, primarily due to the scarcity of
readily available and verifiable reward data beyond these narrowly defined
areas. Moreover, integrating data from multiple domains is challenging, as the
compatibility between domain-specific datasets remains uncertain. To address
these limitations, we build a comprehensive RL-ready visual reasoning dataset
from 46 data sources across 8 dimensions, covering a wide range of tasks such
as infographic, mathematical, spatial, cross-image, graphic user interface,
medical, common sense and general science. We propose an influence function
based data selection and difficulty based filtering strategy to identify
high-quality training samples from this dataset. Subsequently, we train the
VLM, referred to as Vision-G1, using multi-round RL with a data curriculum to
iteratively improve its visual reasoning capabilities. Our model achieves
state-of-the-art performance across various visual reasoning benchmarks,
outperforming similar-sized VLMs and even proprietary models like GPT-4o and
Gemini-1.5 Flash. The model, code and dataset are publicly available at
https://github.com/yuh-zha/Vision-G1.

</details>


### [97] [Learn Faster and Remember More: Balancing Exploration and Exploitation for Continual Test-time Adaptation](https://arxiv.org/abs/2508.12643)
*Pinci Yang,Peisong Wen,Ke Ma,Qianqian Xu*

Main category: cs.CV

TL;DR: BEE는 mean teacher 기반으로 중간층 특징 정합(MCR)과 과거 체크포인트 재사용(CAR)을 결합해 지속적 테스트 시간 적응(CTTA)에서 빠른 적응(탐색)과 과거 지식 유지(활용)를 동시에 달성한다.


<details>
  <summary>Details</summary>
Motivation: CTTA는 계속 변화하는 타깃 도메인에 추론 중 적응해야 한다. 기존 방법은 주로 심층 출력(predictions)만 조정해 도메인 변화에 주로 영향을 받는 얕은 특징을 효율적으로 수정하지 못하고 적응이 느리며, 단일 모델은 새로운 도메인 탐색 중 이전 도메인 지식을 잃어 장기적 활용에 취약하다.

Method: mean teacher 프레임워크를 채택하고, (1) Multi-level Consistency Regularization(MCR)로 학생·교사 모델의 중간층 특징을 정렬해 얕은 특징 수준에서 빠르게 적응하도록 유도, (2) Complementary Anchor Replay(CAR)로 과거 체크포인트(anchors)를 보관·재사용하여 다양한 도메인에 대한 보완적 지식을 복구 및 활용함으로써 망각을 줄인다.

Result: 여러 벤치마크에서 기존 최첨단 방법들을 상당히 상회하는 성능을 보였으며, 빠른 적응 속도와 이전 도메인 성능 유지 측면에서 개선을 입증했다.

Conclusion: BEE는 중간층 정합과 보조 앵커 재생을 결합해 CTTA에서 탐색과 활용의 균형을 효과적으로 맞추며, 적응 속도 향상과 망각 완화 두 마리 토끼를 잡는다.

Abstract: Continual Test-Time Adaptation (CTTA) aims to adapt a source pre-trained
model to continually changing target domains during inference. As a fundamental
principle, an ideal CTTA method should rapidly adapt to new domains
(exploration) while retaining and exploiting knowledge from previously
encountered domains to handle similar domains in the future. Despite
significant advances, balancing exploration and exploitation in CTTA is still
challenging: 1) Existing methods focus on adjusting predictions based on
deep-layer outputs of neural networks. However, domain shifts typically affect
shallow features, which are inefficient to be adjusted from deep predictions,
leading to dilatory exploration; 2) A single model inevitably forgets knowledge
of previous domains during the exploration, making it incapable of exploiting
historical knowledge to handle similar future domains. To address these
challenges, this paper proposes a mean teacher framework that strikes an
appropriate Balance between Exploration and Exploitation (BEE) during the CTTA
process. For the former challenge, we introduce a Multi-level Consistency
Regularization (MCR) loss that aligns the intermediate features of the student
and teacher models, accelerating adaptation to the current domain. For the
latter challenge, we employ a Complementary Anchor Replay (CAR) mechanism to
reuse historical checkpoints (anchors), recovering complementary knowledge for
diverse domains. Experiments show that our method significantly outperforms
state-of-the-art methods on several benchmarks, demonstrating its effectiveness
for CTTA tasks.

</details>


### [98] [DyCrowd: Towards Dynamic Crowd Reconstruction from a Large-scene Video](https://arxiv.org/abs/2508.12644)
*Hao Wen,Hongbo Kang,Jian Ma,Jing Huang,Yuanwang Yang,Haozhe Lin,Yu-Kun Lai,Kun Li*

Main category: cs.CV

TL;DR: DyCrowd는 대규모 장면 비디오에서 수백 명의 사람에 대해 시공간적으로 일관된 3D 포즈·위치·형상을 복원하는 최초의 프레임워크로, 그룹 기반의 coarse-to-fine 모션 최적화, VAE 모션 프라이어, 세그먼트 수준의 그룹 최적화와 Asynchronous Motion Consistency(AMC) 손실을 결합해 가려짐(occlusion)에 강한 복원을 달성한다. VirtualCrowd라는 가상 벤치마크도 제안한다.


<details>
  <summary>Details</summary>
Motivation: 정적 이미지 기반 3D 군중 복원은 시간적 일관성이 부족하고 가려짐 문제를 완화할 수 없어, 대규모 장면에서 수백 명의 동적 군중을 시공간적으로 일관되게 복원할 필요가 있다.

Method: (1) 그룹 유도형 coarse-to-fine 모션 최적화로 대규모 장면에 대한 가려짐에 강한 복원 수행, (2) VAE 기반 인간 모션 프라이어 도입 및 세그먼트 수준 그룹 최적화로 시간적 불안정성과 심한 가려짐 해결, (3) 유사한 모션 세그먼트들을 공동 최적화하고 AMC 손실로 비동기성·리듬 불일치 상황에서 가려진 모션을 비가려진 고품질 세그먼트로부터 복구하도록 유도.

Result: 제안법이 대규모 동적 군중 복원 과제에서 SOTA 성능을 보이며, VirtualCrowd 데이터셋과 코드가 연구용으로 공개될 예정.

Conclusion: 집단 행동 정보를 활용한 그룹 기반 최적화와 VAE 모션 프라이어, AMC 손실의 결합은 시공간적 일관성과 가려짐 강건성을 확보하여 대규모 동적 군중의 3D 복원 문제를 효과적으로 해결한다.

Abstract: 3D reconstruction of dynamic crowds in large scenes has become increasingly
important for applications such as city surveillance and crowd analysis.
However, current works attempt to reconstruct 3D crowds from a static image,
causing a lack of temporal consistency and inability to alleviate the typical
impact caused by occlusions. In this paper, we propose DyCrowd, the first
framework for spatio-temporally consistent 3D reconstruction of hundreds of
individuals' poses, positions and shapes from a large-scene video. We design a
coarse-to-fine group-guided motion optimization strategy for occlusion-robust
crowd reconstruction in large scenes. To address temporal instability and
severe occlusions, we further incorporate a VAE (Variational Autoencoder)-based
human motion prior along with a segment-level group-guided optimization. The
core of our strategy leverages collective crowd behavior to address long-term
dynamic occlusions. By jointly optimizing the motion sequences of individuals
with similar motion segments and combining this with the proposed Asynchronous
Motion Consistency (AMC) loss, we enable high-quality unoccluded motion
segments to guide the motion recovery of occluded ones, ensuring robust and
plausible motion recovery even in the presence of temporal desynchronization
and rhythmic inconsistencies. Additionally, in order to fill the gap of no
existing well-annotated large-scene video dataset, we contribute a virtual
benchmark dataset, VirtualCrowd, for evaluating dynamic crowd reconstruction
from large-scene videos. Experimental results demonstrate that the proposed
method achieves state-of-the-art performance in the large-scene dynamic crowd
reconstruction task. The code and dataset will be available for research
purposes.

</details>


### [99] [Stable Diffusion-Based Approach for Human De-Occlusion](https://arxiv.org/abs/2508.12663)
*Seung Young Noh,Ju Yong Chang*

Main category: cs.CV

TL;DR: 사람의 가려진 신체 부위를 복원하는 작업을 두 단계(마스크 복원 → RGB 복원)로 나누어, 확산모형 기반 몸체 프라이어와 가려진 관절 히트맵으로 아모달 마스크를 복원하고 이를 조건으로 Stable Diffusion(디코더 파인튜닝 포함)와 VQA→CLIP로 얻은 인간특화 텍스트 특징을 결합해 고품질의 RGB 복원을 수행하는 방법을 제안한다. 기존 방법보다 마스크·RGB 복원 성능이 우수하며 2D 포즈·3D 복원 같은 다운스트림 작업 성능도 향상된다.


<details>
  <summary>Details</summary>
Motivation: 심한 부분 가림(occlusion) 상황에서도 사람의 구조와 외관을 신뢰성 있게 재구성하는 것은 비전 응용(포즈 추정, 3D 복원 등)에서 중요하지만 기존 딥러닝 모델은 보이는 단서와 사전지식 결합이 어려워 품질이 낮았다. 본 연구는 사람 특정(prior)과 명시적 공간 단서(가려진 관절 히트맵), 텍스트 특징을 활용해 이 문제를 개선하고자 한다.

Method: 1) 마스크 복원: 확산 기반의 인간 신체 프라이어(바디 프라이어)와 가려진 관절 히트맵을 결합해 아모달(전체) 마스크를 재구성. 2) RGB 복원: 재구성된 마스크를 조건으로 Stable Diffusion을 사용하여 색·외관을 복원하되, 가시 영역의 픽셀 열화를 줄이기 위해 디코더를 파인튜닝. 또한 VQA 모델로부터 얻은 인간 관련 텍스트 정보를 CLIP 인코더로 임베딩해 조건에 포함시켜 사람 특화 세부 표현을 강화.

Result: 심한 가림 상황에서도 아모달 마스크와 RGB 복원에서 기존 기법들을 일관되게 능가. 복원된(비가려진) 이미지는 2D 포즈 추정 및 3D 사람 복원 성능도 개선. 코드 공개 예정.

Conclusion: 사람 전용 확산 프라이어와 명시적 관절 단서, 텍스트 특징을 결합하고 디코더 파인튜닝을 적용한 두 단계 복원 파이프라인은 사람 가림 복원 문제에서 실용적 성능 향상을 제공하며 다운스트림 응용에도 유의미한 이득을 줌.

Abstract: Humans can infer the missing parts of an occluded object by leveraging prior
knowledge and visible cues. However, enabling deep learning models to
accurately predict such occluded regions remains a challenging task.
De-occlusion addresses this problem by reconstructing both the mask and RGB
appearance. In this work, we focus on human de-occlusion, specifically
targeting the recovery of occluded body structures and appearances. Our
approach decomposes the task into two stages: mask completion and RGB
completion. The first stage leverages a diffusion-based human body prior to
provide a comprehensive representation of body structure, combined with
occluded joint heatmaps that offer explicit spatial cues about missing regions.
The reconstructed amodal mask then serves as a conditioning input for the
second stage, guiding the model on which areas require RGB reconstruction. To
further enhance RGB generation, we incorporate human-specific textual features
derived using a visual question answering (VQA) model and encoded via a CLIP
encoder. RGB completion is performed using Stable Diffusion, with decoder
fine-tuning applied to mitigate pixel-level degradation in visible regions -- a
known limitation of prior diffusion-based de-occlusion methods caused by latent
space transformations. Our method effectively reconstructs human appearances
even under severe occlusions and consistently outperforms existing methods in
both mask and RGB completion. Moreover, the de-occluded images generated by our
approach can improve the performance of downstream human-centric tasks, such as
2D pose estimation and 3D human reconstruction. The code will be made publicly
available.

</details>


### [100] [WP-CLIP: Leveraging CLIP to Predict Wölfflin's Principles in Visual Art](https://arxiv.org/abs/2508.12668)
*Abhijay Ghildyal,Li-Yun Wang,Feng Liu*

Main category: cs.CV

TL;DR: 저자들은 CLIP이 Wölfflin의 미술 형식 원리 다섯 가지를 그대로 예측하지 못하므로, 미술 이미지에 주석을 달아 CLIP을 미세조정한 WP-CLIP을 제안해 각 원리별 점수를 예측하도록 했다. GAN 생성 회화와 Pandora-18K에서 일반화 성능을 확인했다.


<details>
  <summary>Details</summary>
Motivation: Wölfflin의 다섯 원리는 미술 형식 분석에 구조화된 틀을 제공하지만, 이를 자동으로 예측하는 계산적 메트릭은 부재하다. 최근 VLM의 추상적 속성 평가 능력을 활용해 시각적 스타일 속성을 자동 분석하려는 동기가 있다.

Method: 사전학습된 CLIP을 기반으로, 실제 미술 이미지에 Wölfflin 원리별 주석을 달아 회귀(또는 분류) 레이블로 사용해 CLIP을 미세조정했다. 모델명은 WP-CLIP이며, 학습 후 GAN 생성 회화와 Pandora-18K 데이터셋에서 성능을 평가했다.

Result: 원본 CLIP은 Wölfflin의 미묘한 스타일 요소를 내재적으로 포착하지 못했으나, 미세조정된 WP-CLIP은 다양한 화풍에 대해 원리별 점수를 예측할 수 있었고, GAN 이미지와 대규모 미술 데이터에서도 어느 정도 일반화하는 모습을 보였다.

Conclusion: VLM(특히 CLIP)의 미세조정을 통해 전통적 미술 이론(예: Wölfflin 원리)의 자동화된 분석이 가능함을 보였다. 하지만 초기 CLIP은 이런 세부적 스타일을 바로 이해하지 못하므로 도메인 주석/미세조정이 필요하다.

Abstract: W\"olfflin's five principles offer a structured approach to analyzing
stylistic variations for formal analysis. However, no existing metric
effectively predicts all five principles in visual art. Computationally
evaluating the visual aspects of a painting requires a metric that can
interpret key elements such as color, composition, and thematic choices. Recent
advancements in vision-language models (VLMs) have demonstrated their ability
to evaluate abstract image attributes, making them promising candidates for
this task. In this work, we investigate whether CLIP, pre-trained on
large-scale data, can understand and predict W\"olfflin's principles. Our
findings indicate that it does not inherently capture such nuanced stylistic
elements. To address this, we fine-tune CLIP on annotated datasets of real art
images to predict a score for each principle. We evaluate our model, WP-CLIP,
on GAN-generated paintings and the Pandora-18K art dataset, demonstrating its
ability to generalize across diverse artistic styles. Our results highlight the
potential of VLMs for automated art analysis.

</details>


### [101] [Refine-and-Contrast: Adaptive Instance-Aware BEV Representations for Multi-UAV Collaborative Object Detection](https://arxiv.org/abs/2508.12684)
*Zhongyao Li,Peirui Cheng,Liangjin Zhao,Chen Chen,Yundu Li,Zhechao Wang,Xue Yang,Xian Sun,Zhirui Wang*

Main category: cs.CV

TL;DR: AdaBEV는 BEV 격자 전체를 균일하게 처리하지 않고, 박스 기반 정제(BG-RM)로 전경 관련 격자만 정밀하게 보정하고 BEV 공간에서의 전경-배경 분리를 위한 대조학습(IBCL)을 결합해, 연산 제약이 있는 다중 UAV 환경에서 낮은 해상도의 BEV로도 높은 정확도-연산 효율을 달성하는 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 다중 UAV 협업 3D 검출은 넓은 시야와 가림 처리 이점이 있으나, UAV의 연산·전력 제약 때문에 전체 BEV를 동등하게 고해상도로 처리하기 어렵다. 따라서 전경 인스턴스에만 계산을 집중시키는 효율적이고 판별력 있는 BEV 표현이 필요하다.

Method: (1) Box-Guided Refinement Module (BG-RM): 2D 감독과 공간 분할을 이용해 전경 인스턴스와 연관된 BEV 그리드만 선택적으로 정제한다. (2) Instance-Background Contrastive Learning (IBCL): BEV 공간에서 전경과 배경 특징의 분리를 강화하기 위해 대조학습을 적용한다. 전체적으로 ‘refine-and-contrast’ 패러다임으로 인스턴스 인식성과 특징 판별력을 높인다.

Result: Air-Co-Pred 데이터셋에서 다양한 모델 스케일에서 연산 대비 정확도(trade-off)를 개선했으며, 저해상도 BEV 입력에서 다른 SOTA 방법들을 능가하고, 오버헤드는 거의 없이 상한 성능에 근접하는 결과를 보였다.

Conclusion: 전경 중심의 선택적 정제와 BEV 대조학습의 결합이 다중 UAV 협업 3D 검출에서 효율성과 성능을 동시에 끌어올리는 실용적 접근임을 제시한다.

Abstract: Multi-UAV collaborative 3D detection enables accurate and robust perception
by fusing multi-view observations from aerial platforms, offering significant
advantages in coverage and occlusion handling, while posing new challenges for
computation on resource-constrained UAV platforms. In this paper, we present
AdaBEV, a novel framework that learns adaptive instance-aware BEV
representations through a refine-and-contrast paradigm. Unlike existing methods
that treat all BEV grids equally, AdaBEV introduces a Box-Guided Refinement
Module (BG-RM) and an Instance-Background Contrastive Learning (IBCL) to
enhance semantic awareness and feature discriminability. BG-RM refines only BEV
grids associated with foreground instances using 2D supervision and spatial
subdivision, while IBCL promotes stronger separation between foreground and
background features via contrastive learning in BEV space. Extensive
experiments on the Air-Co-Pred dataset demonstrate that AdaBEV achieves
superior accuracy-computation trade-offs across model scales, outperforming
other state-of-the-art methods at low resolutions and approaching upper bound
performance while maintaining low-resolution BEV inputs and negligible
overhead.

</details>


### [102] [TTA-DAME: Test-Time Adaptation with Domain Augmentation and Model Ensemble for Dynamic Driving Conditions](https://arxiv.org/abs/2508.12690)
*Dongjae Jeon,Taeheon Kim,Seongwon Cho,Minhyuk Seo,Jonghyun Choi*

Main category: cs.CV

TL;DR: TTA-DAME은 출발 도메인(source) 데이터 증강을 이용하고 도메인 판별기와 도메인 감지기를 도입해 주행 장면에서 빈번한 날씨·조명(domain) 변화, 특히 주간→야간 같은 급격한 변화에 적응하는 테스트 시 적응(Test-time Adaptation) 방법이다. 다수의 감지기를 학습해 비최대 억제(NMS)로 예측을 통합하며, SHIFT 벤치마크에서 성능 향상을 보인다.


<details>
  <summary>Details</summary>
Motivation: 현실 주행 환경에서는 날씨·조명 등 도메인이 자주 변하며, 모델이 테스트 시 동적으로 적응해야 성능을 유지할 수 있다. 특히 주간과 야간처럼 극단적 도메인 변화가 발생하면 기존 TTA 방법의 성능 저하가 심하다.

Method: (1) 출발 도메인 데이터를 목표 도메인으로의 증강으로 활용(소스→타깃 증강). (2) 도메인 판별기(domain discriminator)를 도입해 도메인 차이를 완화. (3) 급격한 변화(예: 주간→야간)를 탐지하는 전용 도메인 감지기(domain detector)를 설계. (4) 여러 감지기를 학습하고 비최대 억제(NMS)로 이들의 예측을 통합해 안정적 탐지를 얻음.

Result: 제안 기법은 SHIFT 벤치마크에서 유의미한 성능 향상을 보고한다(추상에선 정확한 수치 미제공).

Conclusion: 증강 기반 소스 활용과 판별기·감지기 조합 및 감지기 앙상블(NMS)을 통해 주행 장면의 동적 도메인 변화에 대응하는 효과적인 TTA 방법을 제시한다.

Abstract: Test-time Adaptation (TTA) poses a challenge, requiring models to dynamically
adapt and perform optimally on shifting target domains. This task is
particularly emphasized in real-world driving scenes, where weather domain
shifts occur frequently. To address such dynamic changes, our proposed method,
TTA-DAME, leverages source domain data augmentation into target domains.
Additionally, we introduce a domain discriminator and a specialized domain
detector to mitigate drastic domain shifts, especially from daytime to
nighttime conditions. To further improve adaptability, we train multiple
detectors and consolidate their predictions through Non-Maximum Suppression
(NMS). Our empirical validation demonstrates the effectiveness of our method,
showing significant performance enhancements on the SHIFT Benchmark.

</details>


### [103] [Multi-Level Knowledge Distillation and Dynamic Self-Supervised Learning for Continual Learning](https://arxiv.org/abs/2508.12692)
*Taeheon Kim,San Kim,Minhyuk Seo,Dongjae Jeon,Wonje Jeong,Jonghyun Choi*

Main category: cs.CV

TL;DR: CIR(반복 등장 클래스) 환경에서 대량의 외부 무라벨 데이터를 활용해 안정성(stability)과 가소성(plasticity)을 유지하는 방법을 제안. 다중 수준 지식증류(MLKD)로 여러 이전 모델의 특징·로짓을 증류하고, 동적 자기지도학습(SSL)으로 무라벨 데이터를 신속히 학습에 활용하면서 가중치를 동적으로 조절해 주과제에 집중. CVPR CLVISION 챌린지에서 2위 달성.


<details>
  <summary>Details</summary>
Motivation: 현실적 시나리오인 CIR에서는 이전에 학습한 클래스가 이후 작업에 반복 등장하고, 인터넷 등에서 풍부한 무라벨 데이터를 쉽게 얻을 수 있으므로 이를 효율적으로 이용해 모델의 안정성과 새로운 클래스 학습 능력을 동시에 보장할 필요가 있다.

Method: (1) MLKD: 여러 과거 모델로부터 특징(feature)과 로짓(logit) 수준에서 지식을 다중 관점으로 증류해 다양한 이전 지식을 유지. (2) 동적 SSL: 무라벨 데이터를 이용해 신속히 새 클래스를 학습시키되, SSL 손실의 가중치를 동적으로 조절해 주요 유사과제에 집중하도록 설계.

Result: 제안 기법들이 CIR 성능을 크게 향상시켰고, 해당 챌린지에서 2위 성적을 기록.

Conclusion: MLKD와 동적 SSL의 결합은 외부 무라벨 데이터를 활용해 CIR에서 안정성과 가소성을 모두 개선하는 효과적인 방법임을 실험적으로 보였다.

Abstract: Class-incremental with repetition (CIR), where previously trained classes
repeatedly introduced in future tasks, is a more realistic scenario than the
traditional class incremental setup, which assumes that each task contains
unseen classes. CIR assumes that we can easily access abundant unlabeled data
from external sources, such as the Internet. Therefore, we propose two
components that efficiently use the unlabeled data to ensure the high stability
and the plasticity of models trained in CIR setup. First, we introduce
multi-level knowledge distillation (MLKD) that distills knowledge from multiple
previous models across multiple perspectives, including features and logits, so
the model can maintain much various previous knowledge. Moreover, we implement
dynamic self-supervised loss (SSL) to utilize the unlabeled data that
accelerates the learning of new classes, while dynamic weighting of SSL keeps
the focus of training to the primary task. Both of our proposed components
significantly improve the performance in CIR setup, achieving 2nd place in the
CVPR 5th CLVISION Challenge.

</details>


### [104] [Neural Rendering for Sensor Adaptation in 3D Object Detection](https://arxiv.org/abs/2508.12695)
*Felix Embacher,David Holtz,Jonas Uhrig,Marius Cordts,Markus Enzweiler*

Main category: cs.CV

TL;DR: CamShift라는 CARLA 기반 데이터셋을 통해 차량별 카메라 배치 차이로 발생하는 '크로스-센서 도메인 갭'이 최첨단 3D 객체 검출기의 성능을 크게 저하시함을 보이고, 신경 렌더링 기반의 데이터 변환(센서 적응)으로 이 갭을 실질적으로 완화할 수 있음을 보였다.


<details>
  <summary>Details</summary>
Motivation: 자율주행 차량은 차종마다 카메라 위치·수·구성이 달라 동일한 인식 모델이라도 서로 다른 센서 배치에서 성능 저하가 발생한다. 새로운 센서 구성마다 데이터 수집·주석을 새로 하는 것은 비용이 크므로, 센서 구성 변화에 강한 모델이나 기존 데이터를 재사용할 수 있는 방법이 필요하다.

Method: nuScenes에서 영감을 얻어 CARLA로 구축한 CamShift 데이터셋을 사용해 서브콤팩트와 SUV 간의 센서 구성 차이를 시뮬레이션했다. 여러 최첨단 3D 객체 검출기를 다양한 센서 설정에서 평가하여 아키텍처별 강건성 차이를 분석하고, 신경 렌더링 기반의 데이터 주도적 센서 적응 파이프라인을 제안해 전체 데이터셋을 목표 센서 구성에 맞게 변환했다.

Result: 센서 구성 변경 시 검출 성능이 크게 떨어짐을 확인했으며, 밀집 BEV 표현과 역투영(backward projection)을 사용하는 BEVFormer 계열 아키텍처가 가장 강건했다. 제안한 신경 렌더링 기반 센서 적응을 적용하면 모든 평가한 3D 검출기의 성능이 향상되고 도메인 갭이 크게 줄어들었다.

Conclusion: CamShift와 센서 적응 벤치마크는 서로 다른 차량 센서 구성 간 데이터 재사용을 가능하게 하여 새로운 데이터 수집 필요성을 줄이고, 모델 설계(예: BEV 기반)에 대한 실무적 지침을 제공한다.

Abstract: Autonomous vehicles often have varying camera sensor setups, which is
inevitable due to restricted placement options for different vehicle types.
Training a perception model on one particular setup and evaluating it on a new,
different sensor setup reveals the so-called cross-sensor domain gap, typically
leading to a degradation in accuracy. In this paper, we investigate the impact
of the cross-sensor domain gap on state-of-the-art 3D object detectors. To this
end, we introduce CamShift, a dataset inspired by nuScenes and created in CARLA
to specifically simulate the domain gap between subcompact vehicles and sport
utility vehicles (SUVs). Using CamShift, we demonstrate significant
cross-sensor performance degradation, identify robustness dependencies on model
architecture, and propose a data-driven solution to mitigate the effect. On the
one hand, we show that model architectures based on a dense Bird's Eye View
(BEV) representation with backward projection, such as BEVFormer, are the most
robust against varying sensor configurations. On the other hand, we propose a
novel data-driven sensor adaptation pipeline based on neural rendering, which
can transform entire datasets to match different camera sensor setups. Applying
this approach improves performance across all investigated 3D object detectors,
mitigating the cross-sensor domain gap by a large margin and reducing the need
for new data collection by enabling efficient data reusability across vehicles
with different sensor setups. The CamShift dataset and the sensor adaptation
benchmark are available at https://dmholtz.github.io/camshift/.

</details>


### [105] [Has GPT-5 Achieved Spatial Intelligence? An Empirical Study](https://arxiv.org/abs/2508.13142)
*Zhongang Cai,Yubo Wang,Qingping Sun,Ruisi Wang,Chenyang Gu,Wanqi Yin,Zhiqian Lin,Zhitao Yang,Chen Wei,Xuanke Shi,Kewang Deng,Xiaoyang Han,Zukai Chen,Jiaqi Li,Xiangyu Fan,Hanming Deng,Lewei Lu,Bo Li,Ziwei Liu,Quan Wang,Dahua Lin,Lei Yang*

Main category: cs.CV

TL;DR: GPT-5는 공간 지능에서 현저한 진전을 보이지만 인간 수준에는 미치지 못하며, 일부 어려운 공간 문제에서는 소유권(권한) 있는 모델이 뚜렷한 우위를 보이지 않는다.


<details>
  <summary>Details</summary>
Motivation: 다중모달 모델들이 급속히 발달했으나 여전히 공간 이해와 추론 능력에서 한계가 있어, 최신 모델들(특히 GPT-5)을 대상으로 공간 지능의 현황을 체계적으로 평가하고자 함.

Method: 기존 벤치마크를 통합한 포괄적 공간 과제 분류법을 제시하고 공정한 평가의 쟁점을 논의함. 그 후 사유·오픈 소스 최첨단 모델들을 8개 핵심 벤치마크에서 평가(총 토큰 소모량 10억 건 이상)하고, 직관적이지만 모델들이 실패하는 다양한 정성적 시나리오도 분석함.

Result: (1) GPT-5는 이전 모델 대비 비약적인 성능 향상을 보임. (2) 그럼에도 인간 성능에는 못 미침. (3) 모델들이 특히 어려워하는 공간 문제 유형을 규명함(예: 복합적 공간 추론, 부분 가림/원근, 다중 객체 상호작용 등). (4) 가장 어려운 문제들에서는 사유 모델이 결정적 우위를 갖지 않음.

Conclusion: 다중모달 모델의 공간 지능은 크게 발전했으나 중요한 갭이 남아 있어, 표적화된 벤치마크·공정한 평가·개선된 공간적 추론/대응 전략이 필요하다.

Abstract: Multi-modal models have achieved remarkable progress in recent years.
Nevertheless, they continue to exhibit notable limitations in spatial
understanding and reasoning, which are fundamental capabilities to achieving
artificial general intelligence. With the recent release of GPT-5, allegedly
the most powerful AI model to date, it is timely to examine where the leading
models stand on the path toward spatial intelligence. First, we propose a
comprehensive taxonomy of spatial tasks that unifies existing benchmarks and
discuss the challenges in ensuring fair evaluation. We then evaluate
state-of-the-art proprietary and open-source models on eight key benchmarks, at
a cost exceeding one billion total tokens. Our empirical study reveals that (1)
GPT-5 demonstrates unprecedented strength in spatial intelligence, yet (2)
still falls short of human performance across a broad spectrum of tasks.
Moreover, we (3) identify the more challenging spatial intelligence problems
for multi-modal models, and (4) proprietary models do not exhibit a decisive
advantage when facing the most difficult problems. In addition, we conduct a
qualitative evaluation across a diverse set of scenarios that are intuitive for
humans yet fail even the most advanced multi-modal models.

</details>


### [106] [Drifting Away from Truth: GenAI-Driven News Diversity Challenges LVLM-Based Misinformation Detection](https://arxiv.org/abs/2508.12711)
*Fanxiao Li,Jiaying Wu,Tingchao Fu,Yunyun Dong,Bingbing Song,Wei Zhou*

Main category: cs.CV

TL;DR: LVLM 기반의 다중모달 허위정보 감지기는 GenAI가 만들어내는 뉴스 다양성으로 인해 성능이 크게 저하된다. 저자들은 이 문제를 '다중수준 드리프트'로 규정하고, 이를 평가하기 위한 대규모 벤치마크 DriftBench와 세 가지 평가 과제를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 생성형 AI 도구의 등장으로 뉴스 텍스트·이미지 등이 매우 다양해지면서 기존 LVLM 기반 MMD 시스템의 견고성이 떨어지고, 스타일·표현의 변화가 내부 추론과 외부 증거 검색의 품질을 동시에 해친다는 문제가 제기된다.

Method: 저자들은 6가지 다양화 카테고리로 구성된 16,000개 뉴스 인스턴스의 대규모 벤치마크(DriftBench)를 구축하고, (1) 다중수준 드리프트 하의 진실 검증 견고성, (2) GenAI가 생성한 악의적 증거 혼입에 대한 취약성, (3) 다양한 입력에 대한 추론 일관성 분석이라는 세 가지 평가 과제를 설계하여 6개 최신 LVLM 기반 탐지기를 실험한다.

Result: 평균 F1이 약 14.8%p 하락하는 등 성능이 크게 저하되고, 추론 로그가 불안정해지며 악의적 증거 주입 시 더 심각한 실패가 관찰된다. 이는 모델 수준의 오인식 드리프트와 증거 수준의 드리프트가 실무적 취약점을 초래함을 보여준다.

Conclusion: 현행 LVLM 기반 MMD 시스템은 GenAI 시대의 뉴스 다양성 앞에서 근본적 취약성을 가지고 있으며, 보다 견고하고 증거-강건한 방법론 개발이 시급하다.

Abstract: The proliferation of multimodal misinformation poses growing threats to
public discourse and societal trust. While Large Vision-Language Models (LVLMs)
have enabled recent progress in multimodal misinformation detection (MMD), the
rise of generative AI (GenAI) tools introduces a new challenge: GenAI-driven
news diversity, characterized by highly varied and complex content. We show
that this diversity induces multi-level drift, comprising (1) model-level
misperception drift, where stylistic variations disrupt a model's internal
reasoning, and (2) evidence-level drift, where expression diversity degrades
the quality or relevance of retrieved external evidence. These drifts
significantly degrade the robustness of current LVLM-based MMD systems. To
systematically study this problem, we introduce DriftBench, a large-scale
benchmark comprising 16,000 news instances across six categories of
diversification. We design three evaluation tasks: (1) robustness of truth
verification under multi-level drift; (2) susceptibility to adversarial
evidence contamination generated by GenAI; and (3) analysis of reasoning
consistency across diverse inputs. Experiments with six state-of-the-art
LVLM-based detectors show substantial performance drops (average F1 -14.8%) and
increasingly unstable reasoning traces, with even more severe failures under
adversarial evidence injection. Our findings uncover fundamental
vulnerabilities in existing MMD systems and suggest an urgent need for more
resilient approaches in the GenAI era.

</details>


### [107] [Real-Time Sign Language Gestures to Speech Transcription using Deep Learning](https://arxiv.org/abs/2508.12713)
*Brandone Fonya*

Main category: cs.CV

TL;DR: 웹캠으로 촬영한 수어 제스처를 CNN( Sign Language MNIST로 학습)으로 실시간 분류해 텍스트 및 음성으로 변환하는 보조기술을 제안. 높은 정확도와 실시간 성능(일부 지연)을 보고하지만 데이터·태스크 범위의 한계가 있음.


<details>
  <summary>Details</summary>
Motivation: 청각·언어 장애인의 일상 상호작용 장벽을 낮추고 자율성·사회적 통합을 돕기 위한 접근성 도구 개발.

Method: Sign Language MNIST 데이터로 CNN을 학습하고 웹캠으로 입력된 손 제스처를 실시간 분류하여 대응 의미를 매핑, 텍스트-투-스피치로 출력.

Result: 저자 주장으로는 높은 모델 정확도와 실시간 처리 성능을 달성했으나 구체적 수치·실험 설정은 추정 필요. 일부 지연(latency) 존재.

Conclusion: 프로토타입으로서 유용성과 실용성이 입증될 가능성이 있으나, 데이터셋 한계(정적 알파벳 중심), 연속 수어·화자 일반화·환경 변화에 대한 검증 부족 등으로 실제 배포 전 보완 필요.

Abstract: Communication barriers pose significant challenges for individuals with
hearing and speech impairments, often limiting their ability to effectively
interact in everyday environments. This project introduces a real-time
assistive technology solution that leverages advanced deep learning techniques
to translate sign language gestures into textual and audible speech. By
employing convolution neural networks (CNN) trained on the Sign Language MNIST
dataset, the system accurately classifies hand gestures captured live via
webcam. Detected gestures are instantaneously translated into their
corresponding meanings and transcribed into spoken language using
text-to-speech synthesis, thus facilitating seamless communication.
Comprehensive experiments demonstrate high model accuracy and robust real-time
performance with some latency, highlighting the system's practical
applicability as an accessible, reliable, and user-friendly tool for enhancing
the autonomy and integration of sign language users in diverse social settings.

</details>


### [108] [Single-Reference Text-to-Image Manipulation with Dual Contrastive Denoising Score](https://arxiv.org/abs/2508.12718)
*Syed Muhmmad Israr,Feng Zhao*

Main category: cs.CV

TL;DR: 저자들은 텍스트-투-이미지 확산모델의 풍부한 생성 prior를 활용하여 실제 이미지 편집 문제를 해결하는 'Dual Contrastive Denoising Score'(DCDS)를 제안한다. DCDS는 자체-어텐션 중간 표현에서 얻은 공간 정보를 활용한 이중 대조 손실을 도입해 원하는 영역만 수정하고 구조를 보존하며, 별도의 보조 네트워크나 추가 훈련 없이 사전학습된 모델로 제로샷 이미지-투-이미지 변환을 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: 실제 이미지 편집에 있어서 완벽한 텍스트 프롬프트를 작성하기 어렵고, 기존 모델들이 원하는 영역만 변경하지 못하고 원치 않는 영역까지 크게 변경하는 문제가 있다. 이를 해결하기 위해 사전학습된 텍스트-투-이미지 확산모델의 내부 표현을 활용해 세밀한 제어와 구조 보존을 목표로 한다.

Method: 본 논문은 'Dual Contrastive Denoising Score' 프레임워크를 제안한다. 핵심은 확산 과정에서의 중간 노이즈 복원 예측들에 대해 이중 대조 손실(dual contrastive loss)을 적용하는 것이다. 구체적으로, 라텐트 확산 모델의 자기-어텐션 레이어에서 추출한 공간적 특징을 이용해 패치 단위의 쌍별 대조를 수행하고, 입력 이미지와 출력 이미지 사이의 대응을 유지하도록 유도한다. 보조 네트워크 없이 사전학습된 모델의 내부 표현만 사용해 구조 보존과 선택적 내용 변경을 가능하게 한다.

Result: 광범위한 실험에서 제안된 방법은 기존의 실제 이미지 편집 기법들보다 구조 보존과 원하는 영역의 내용 수정에서 우수한 성능을 보였다. 또한 추가적 학습 없이 사전학습된 텍스트-투-이미지 확산모델을 직접 사용해 제로샷 이미지-투-이미지 번역이 가능함을 시연했다.

Conclusion: DCDS는 확산모델의 내부 자기-어텐션 표현을 활용한 이중 대조 학습으로 실제 이미지 편집 문제에서 실용적이고 효과적인 솔루션을 제공한다. 사용자 친화적인 제어와 구조 보존을 동시에 달성하며, 별도 훈련 없이 사전학습 모델의 강력한 생성력을 활용할 수 있다.

Abstract: Large-scale text-to-image generative models have shown remarkable ability to
synthesize diverse and high-quality images. However, it is still challenging to
directly apply these models for editing real images for two reasons. First, it
is difficult for users to come up with a perfect text prompt that accurately
describes every visual detail in the input image. Second, while existing models
can introduce desirable changes in certain regions, they often dramatically
alter the input content and introduce unexpected changes in unwanted regions.
To address these challenges, we present Dual Contrastive Denoising Score, a
simple yet powerful framework that leverages the rich generative prior of
text-to-image diffusion models. Inspired by contrastive learning approaches for
unpaired image-to-image translation, we introduce a straightforward dual
contrastive loss within the proposed framework. Our approach utilizes the
extensive spatial information from the intermediate representations of the
self-attention layers in latent diffusion models without depending on auxiliary
networks. Our method achieves both flexible content modification and structure
preservation between input and output images, as well as zero-shot
image-to-image translation. Through extensive experiments, we show that our
approach outperforms existing methods in real image editing while maintaining
the capability to directly utilize pretrained text-to-image diffusion models
without further training.

</details>


### [109] [Quantifying and Alleviating Co-Adaptation in Sparse-View 3D Gaussian Splatting](https://arxiv.org/abs/2508.12720)
*Kangjie Chen,Yingji Zhong,Zhihao Li,Jiaqi Lin,Youyu Chen,Minghan Qin,Haoqian Wang*

Main category: cs.CV

TL;DR: 3D Gaussian Splatting(3DGS)는 다수의 뷰에서 우수하지만, sparse-view에서는 Gaussians들이 서로 과도하게 결합(co-adaptation)해 학습 뷰에만 맞추며 새로운 뷰에 외관 아티팩트를 유발한다. 이를 정량화하는 Co-Adaptation Score(CA)를 제안하고, 랜덤 Gaussian 드롭아웃과 투명도에 곱해지는 잡음 주입의 두 가지 경량 전략으로 co-adaptation을 완화해 sparse-view 성능을 개선한다.


<details>
  <summary>Details</summary>
Motivation: Sparse-view 상황에서 3DGS가 훈련 뷰에서는 그럴듯하지만 novel view에서 외관 아티팩트를 보이는 문제의 원인을 규명하고, 이를 정량화·완화할 수 있는 실용적 방법을 제시하기 위함.

Method: (1) Co-Adaptation Score(CA)를 정의: 동일한 시점에서 서로 다른 임의 Gaussian 부분집합으로 렌더링한 픽-단위 분산으로 co-adaptation 정도를 측정. (2) 분석: CA가 훈련 뷰 수가 많아질수록 자연스럽게 낮아짐을 확인. (3) 제안 기법: a) 랜덤 Gaussian 드롭아웃, b) 불투명도(opacity)에 대한 곱셈형 노이즈 주입 — 둘 다 플러그앤플레이 방식으로 기존 3DGS 훈련에 적용.

Result: CA 분석을 통해 sparse-view에서 co-adaptation이 심함을 입증했고, 제안한 두 전략이 다양한 방법과 벤치마크에서 co-adaptation을 감소시키고 novel view 품질을 개선함을 보였다.

Conclusion: co-adaptation이 sparse-view 3DGS의 핵심 한계이며, 단순한 랜덤 드롭아웃과 opacity 노이즈만으로도 이를 완화하고 일반화 성능을 향상시킬 수 있다. 이 인사이트는 향후 sparse-view 3DGS 연구의 방향을 제시한다.

Abstract: 3D Gaussian Splatting (3DGS) has demonstrated impressive performance in novel
view synthesis under dense-view settings. However, in sparse-view scenarios,
despite the realistic renderings in training views, 3DGS occasionally manifests
appearance artifacts in novel views. This paper investigates the appearance
artifacts in sparse-view 3DGS and uncovers a core limitation of current
approaches: the optimized Gaussians are overly-entangled with one another to
aggressively fit the training views, which leads to a neglect of the real
appearance distribution of the underlying scene and results in appearance
artifacts in novel views. The analysis is based on a proposed metric, termed
Co-Adaptation Score (CA), which quantifies the entanglement among Gaussians,
i.e., co-adaptation, by computing the pixel-wise variance across multiple
renderings of the same viewpoint, with different random subsets of Gaussians.
The analysis reveals that the degree of co-adaptation is naturally alleviated
as the number of training views increases. Based on the analysis, we propose
two lightweight strategies to explicitly mitigate the co-adaptation in
sparse-view 3DGS: (1) random gaussian dropout; (2) multiplicative noise
injection to the opacity. Both strategies are designed to be plug-and-play, and
their effectiveness is validated across various methods and benchmarks. We hope
that our insights into the co-adaptation effect will inspire the community to
achieve a more comprehensive understanding of sparse-view 3DGS.

</details>


### [110] [Frequency-Driven Inverse Kernel Prediction for Single Image Defocus Deblurring](https://arxiv.org/abs/2508.12736)
*Ying Zhang,Xiongxin Tang,Chongyi Li,Qiao Chen,Yuquan Wu*

Main category: cs.CV

TL;DR: 주파수 영역을 활용해 공간적으로 변하는 블러 커널 추정 정확도를 높인 뒤 위치 적응 합성과 스케일 반복적 융합으로 디포커스 복원을 개선한 방법(FDIKP). 기존의 공간 기반 방법이 심한 블러에서 단점이 있어 주파수-공간 병렬 추정과 위치 적응형 컨볼루션(PAC), 이중 도메인 스케일 반복 모듈(DSRM)을 제안함.


<details>
  <summary>Details</summary>
Motivation: 심하게 블러된 영역에서는 로컬 고주파 성분이 사라져 공간 특징만으로는 블러 커널을 정확히 추정하기 어려움. 주파수 도메인은 블러 식별에 더 구별력이 있어 이를 이용해 구조적 식별성을 확보하려는 동기.

Method: 주파수-공간 이중 분기(DIKP)로 역(逆) 커널을 예측해 안정성과 정확도를 향상시키고, 예측되는 역 커널 수가 제한적인 문제를 해결하기 위해 위치 적응 합성(PAC)을 도입하여 지역별 디컨볼루션 적응성 향상. 마지막으로 이중 도메인 스케일 반복 모듈(DSRM)으로 거칠게부터 점차 정교하게 디블러 결과를 융합 및 개선.

Result: 다양한 실험에서 기존 방법들보다 성능 우수성을 보였으며, 코드 공개 예정이라고 명시.

Conclusion: 주파수 정보를 결합한 역 커널 예측과 위치 적응 합성, 스케일 반복 융합이 합쳐져 심한 디포커스 블러 복원에서 효과적임을 주장함.

Abstract: Single image defocus deblurring aims to recover an all-in-focus image from a
defocus counterpart, where accurately modeling spatially varying blur kernels
remains a key challenge. Most existing methods rely on spatial features for
kernel estimation, but their performance degrades in severely blurry regions
where local high-frequency details are missing. To address this, we propose a
Frequency-Driven Inverse Kernel Prediction network (FDIKP) that incorporates
frequency-domain representations to enhance structural identifiability in
kernel modeling. Given the superior discriminative capability of the frequency
domain for blur modeling, we design a Dual-Branch Inverse Kernel Prediction
(DIKP) strategy that improves the accuracy of kernel estimation while
maintaining stability. Moreover, considering the limited number of predicted
inverse kernels, we introduce a Position Adaptive Convolution (PAC) to enhance
the adaptability of the deconvolution process. Finally, we propose a
Dual-Domain Scale Recurrent Module (DSRM) to fuse deconvolution results and
progressively improve deblurring quality from coarse to fine. Extensive
experiments demonstrate that our method outperforms existing approaches. Code
will be made publicly available.

</details>


### [111] [DCSCR: A Class-Specific Collaborative Representation based Network for Image Set Classification](https://arxiv.org/abs/2508.12745)
*Xizhan Gao,Wei Hu*

Main category: cs.CV

TL;DR: Proposes DCSCR, a few-shot image-set classification network that jointly learns frame- and concept-level features and an adaptive class-specific collaborative representation metric via a new CSCR-based contrastive loss, improving few-shot ISC performance.


<details>
  <summary>Details</summary>
Motivation: Image set classification requires both effective feature learning and accurate set-to-set similarity measures. Traditional ISC often uses raw pixels; existing deep ISC learns features but does not adapt features when measuring set distances, limiting few-shot performance.

Method: DCSCR combines a fully convolutional deep feature extractor, a global feature learning module for frame-level representations, and a class-specific collaborative representation (CSCR) based metric learning module to produce concept-level set representations. A new CSCR-based contrastive loss is used to learn adaptive set distances.

Result: Extensive experiments on several few-shot ISC benchmarks show DCSCR outperforms state-of-the-art ISC algorithms.

Conclusion: Jointly learning local/global frame features and an adaptive CSCR metric enables improved few-shot image-set classification; DCSCR is an effective approach in this setting.

Abstract: Image set classification (ISC), which can be viewed as a task of comparing
similarities between sets consisting of unordered heterogeneous images with
variable quantities and qualities, has attracted growing research attention in
recent years. How to learn effective feature representations and how to explore
the similarities between different image sets are two key yet challenging
issues in this field. However, existing traditional ISC methods classify image
sets based on raw pixel features, ignoring the importance of feature learning.
Existing deep ISC methods can learn deep features, but they fail to adaptively
adjust the features when measuring set distances, resulting in limited
performance in few-shot ISC. To address the above issues, this paper combines
traditional ISC methods with deep models and proposes a novel few-shot ISC
approach called Deep Class-specific Collaborative Representation (DCSCR)
network to simultaneously learn the frame- and concept-level feature
representations of each image set and the distance similarities between
different sets. Specifically, DCSCR consists of a fully convolutional deep
feature extractor module, a global feature learning module, and a
class-specific collaborative representation-based metric learning module. The
deep feature extractor and global feature learning modules are used to learn
(local and global) frame-level feature representations, while the
class-specific collaborative representation-based metric learning module is
exploit to adaptively learn the concept-level feature representation of each
image set and thus obtain the distance similarities between different sets by
developing a new CSCR-based contrastive loss function. Extensive experiments on
several well-known few-shot ISC datasets demonstrate the effectiveness of the
proposed method compared with some state-of-the-art image set classification
algorithms.

</details>


### [112] [D2-Mamba: Dual-Scale Fusion and Dual-Path Scanning with SSMs for Shadow Removal](https://arxiv.org/abs/2508.12750)
*Linhao Li,Boya Jin,Zizhe Li,Lanqing Guo,Hao Cheng,Bo Li,Yongfeng Dong*

Main category: cs.CV

TL;DR: 그림자 제거를 위해 비그림자 영역의 정보를 지역별 변환 유사성에 따라 선택적으로 전파하는 Mamba 기반의 네트워크(DFMB, DPMG)를 제안하여 경계 아티팩트 감소와 구조 연속성 향상을 달성, 벤치마크에서 SOTA를 앞섰다.


<details>
  <summary>Details</summary>
Motivation: 그림자 제거는 전역적 열화가 아닌 지역적으로 비균일한 열화를 복원해야 하며, 비그림자 영역의 풍부한 정보를 활용할 수 있지만 그림자와 비그림자에 요구되는 보정이 달라 동일한 보정 전략은 한계가 있다. 따라서 비국소적 문맥 통합과 영역별 적응형 변환 모델링이 필요하다.

Method: Mamba 블록 기반의 네트워크를 설계. Dual-Scale Fusion Mamba Block(DFMB)은 원본 피처와 저해상도 피처를 융합해 멀티스케일 표현을 강화하고 경계 아티팩트를 줄인다. Dual-Path Mamba Group(DPMG)은 수평 스캐닝으로 전역 특징을 포착하고, 마스크 인식(adaptive scanning) 스캐닝 전략을 도입해 구조적 연속성과 세밀한 영역 모델링을 향상시킨다.

Result: 제안 기법이 벤치마크(논문 언급된 shadow removal 데이터셋들)에서 기존 최첨단 방법들보다 유의미하게 우수한 성능을 보였다고 보고된다.

Conclusion: 영역 간 변환 유사성에 기반한 선택적 문맥 전파와 이중 규모·이중 경로 설계가 그림자 제거에서 경계 처리와 구조 보존을 개선하며, 실험적으로 SOTA 성능을 달성했다.

Abstract: Shadow removal aims to restore images that are partially degraded by shadows,
where the degradation is spatially localized and non-uniform. Unlike general
restoration tasks that assume global degradation, shadow removal can leverage
abundant information from non-shadow regions for guidance. However, the
transformation required to correct shadowed areas often differs significantly
from that of well-lit regions, making it challenging to apply uniform
correction strategies. This necessitates the effective integration of non-local
contextual cues and adaptive modeling of region-specific transformations. To
this end, we propose a novel Mamba-based network featuring dual-scale fusion
and dual-path scanning to selectively propagate contextual information based on
transformation similarity across regions. Specifically, the proposed Dual-Scale
Fusion Mamba Block (DFMB) enhances multi-scale feature representation by fusing
original features with low-resolution features, effectively reducing boundary
artifacts. The Dual-Path Mamba Group (DPMG) captures global features via
horizontal scanning and incorporates a mask-aware adaptive scanning strategy,
which improves structural continuity and fine-grained region modeling.
Experimental results demonstrate that our method significantly outperforms
existing state-of-the-art approaches on shadow removal benchmarks.

</details>


### [113] [CLAIRE-DSA: Fluoroscopic Image Classification for Quality Assurance of Computer Vision Pipelines in Acute Ischemic Stroke](https://arxiv.org/abs/2508.12755)
*Cristo J. van den Berg,Frank G. te Nijenhuis,Mirre J. Blaauboer,Daan T. W. van Erp,Carlijn M. Keppels,Matthijs van der Sluijs,Bob Roozenbeek,Wim van Zwam,Sandra Cornelissen,Danny Ruijters,Ruisheng Su,Theo van Walsum*

Main category: cs.CV

TL;DR: CLAIRE-DSA는 기계적 혈전제거 중 획득한 최소강도투영(MinIP) 혈관조영영상(DSA)의 영상 품질·속성(예: 조영제 존재, 투영각, 움직임 아티팩트 등)을 분류하기 위해 사전학습된 ResNet 기반 분류기를 미세조정한 딥러닝 프레임워크다. 1,758장 주석 데이터로 학습해 ROC-AUC 0.91–0.98, 정밀도 0.70–1.00을 달성했으며, 품질이 낮은 영상을 걸러내면 분할(segmentation) 성공률이 42%에서 69%로 유의하게 향상됐다.


<details>
  <summary>Details</summary>
Motivation: 기계적 혈전제거(MT) 중 획득되는 혈관조영(DSA) 영상은 임상 보조용 컴퓨터비전 모델에 유용하지만, 저화질(조영제 누락, 움직임, 부적절한 투영각 등)로 인해 자동화 성능이 떨어진다. 자동 품질·속성 분류기는 워크플로우 최적화와 데이터 전처리(예: 주석·분할 파이프라인에서의 필터링)에 필요하다.

Method: 사전학습된 ResNet 백본을 사용해 MinIP 프레임(1,758장)에 대해 9개 라벨(조영제 존재, 투영각, 움직임 아티팩트 심각도 등)을 예측하도록 미세조정된 별도 분류기들을 학습시켰다. 분류 성능은 ROC-AUC, 정밀도 등으로 평가했고, 품질 필터링이 다운스트림 분할 작업에 미치는 영향을 비교 실험으로 평가했다.

Result: 모든 라벨에서 우수한 성능(ROC-AUC 0.91–0.98, 정밀도 0.70–1.00)을 보였고, 품질이 낮은 이미지를 필터링한 경우 분할 성공률이 42%에서 69%로 유의하게 증가(p<0.001)했다.

Conclusion: CLAIRE-DSA는 DSA MinIP의 영상 속성·품질을 자동 분류해 임상·연구용 데이터 품질관리 및 주석 작업을 지원할 수 있는 유망한 도구이다. 구현 코드는 공개되어 있어 재현 및 확장 연구가 가능하다.

Abstract: Computer vision models can be used to assist during mechanical thrombectomy
(MT) for acute ischemic stroke (AIS), but poor image quality often degrades
performance. This work presents CLAIRE-DSA, a deep learning--based framework
designed to categorize key image properties in minimum intensity projections
(MinIPs) acquired during MT for AIS, supporting downstream quality control and
workflow optimization. CLAIRE-DSA uses pre-trained ResNet backbone models,
fine-tuned to predict nine image properties (e.g., presence of contrast,
projection angle, motion artefact severity). Separate classifiers were trained
on an annotated dataset containing $1,758$ fluoroscopic MinIPs. The model
achieved excellent performance on all labels, with ROC-AUC ranging from $0.91$
to $0.98$, and precision ranging from $0.70$ to $1.00$. The ability of
CLAIRE-DSA to identify suitable images was evaluated on a segmentation task by
filtering poor quality images and comparing segmentation performance on
filtered and unfiltered datasets. Segmentation success rate increased from
$42%$ to $69%$, $p < 0.001$. CLAIRE-DSA demonstrates strong potential as an
automated tool for accurately classifying image properties in DSA series of
acute ischemic stroke patients, supporting image annotation and quality control
in clinical and research applications. Source code is available at
https://gitlab.com/icai-stroke-lab/wp3_neurointerventional_ai/claire-dsa.

</details>


### [114] [Harnessing Group-Oriented Consistency Constraints for Semi-Supervised Semantic Segmentation in CdZnTe Semiconductors](https://arxiv.org/abs/2508.12766)
*Peihao Li,Yan Fang,Man Liu,Huihui Bai,Anhong Wang,Yunchao Wei,Yao Zhao*

Main category: cs.CV

TL;DR: CdZnTe 반도체 이미지의 ‘many-to-one’ 그룹 특성을 이용한 그룹 지향 준지도 분할 프레임워크 ICAF 제안. IVS로 그룹 기반 기준을 세우고, PCN(VAM+VCM)으로 의사라벨을 보정해 경계 복원. DeepLabV3+ (ResNet-101) 기반으로 2개 그룹(데이터의 5‰)만으로 70.6% mIoU 달성.


<details>
  <summary>Details</summary>
Motivation: CdZnTe 이미지의 결함 경계가 저대비여서 주석자가 여러 뷰를 교차참조해야 하고, 여러 뷰가 단일 GT를 공유하는 ‘many-to-one’ 관계가 존재함. 기존 SSS는 개별 이미지-GT의 ‘one-to-one’ 가정에 머물러 저대비 영역에서 오류 누적과 확인 편향을 초래함.

Method: 그룹 지향 파이프라인: (1) Intra-group View Sampling(IVS)으로 그룹 내 일관성 제시(기준선); (2) Pseudo-label Correction Network(PCN): View Augmentation Module(VAM)으로 여러 뷰를 집계해 경계 민감 합성 뷰 생성, View Correction Module(VCM)으로 합성 뷰와 다른 뷰를 쌍으로 정보 상호작용시켜 유의 영역 강조·노이즈 억제 및 의사라벨 보정.

Result: CdZnTe 데이터셋에서 제안 기법이 유의미한 성능 향상을 보임. DeepLabV3+ (ResNet-101) 사용 시 제한된 그룹 주석(2개 그룹, 전체의 0.5%)만으로 70.6% mIoU 기록.

Conclusion: 그룹 기반의 일관성 제약과 뷰 합성·교정 전략이 저대비 반도체 이미지의 준지도 분할 문제에 효과적임. 다만 도메인 특이성, 그룹 주석의 품질 및 일반화 가능성 등 한계가 존재한다.

Abstract: Labeling Cadmium Zinc Telluride (CdZnTe) semiconductor images is challenging
due to the low-contrast defect boundaries, necessitating annotators to
cross-reference multiple views. These views share a single ground truth (GT),
forming a unique ``many-to-one'' relationship. This characteristic renders
advanced semi-supervised semantic segmentation (SSS) methods suboptimal, as
they are generally limited by a ``one-to-one'' relationship, where each image
is independently associated with its GT. Such limitation may lead to error
accumulation in low-contrast regions, further exacerbating confirmation bias.
To address this issue, we revisit the SSS pipeline from a group-oriented
perspective and propose a human-inspired solution: the Intra-group Consistency
Augmentation Framework (ICAF). First, we experimentally validate the inherent
consistency constraints within CdZnTe groups, establishing a group-oriented
baseline using the Intra-group View Sampling (IVS). Building on this insight,
we introduce the Pseudo-label Correction Network (PCN) to enhance consistency
representation, which consists of two key modules. The View Augmentation Module
(VAM) improves boundary details by dynamically synthesizing a boundary-aware
view through the aggregation of multiple views. In the View Correction Module
(VCM), this synthesized view is paired with other views for information
interaction, effectively emphasizing salient regions while minimizing noise.
Extensive experiments demonstrate the effectiveness of our solution for CdZnTe
materials. Leveraging DeepLabV3+ with a ResNet-101 backbone as our segmentation
model, we achieve a 70.6\% mIoU on the CdZnTe dataset using only 2
group-annotated data (5\textperthousand). The code is available at
\href{https://github.com/pipixiapipi/ICAF}{https://github.com/pipixiapipi/ICAF}.

</details>


### [115] [SocialTrack: Multi-Object Tracking in Complex Urban Traffic Scenes Inspired by Social Behavior](https://arxiv.org/abs/2508.12777)
*Wenguang Tao,Xiaotian Wang,Tian Yan,Jie Yan,Guodong Li,Kun Bai*

Main category: cs.CV

TL;DR: UAV 기반 다중물체추적(MOT)용 프레임워크 SocialTrack을 제안. 소형 타깃용 탐지기, 속도 적응 큐버처 칼만 필터(VACKF), 그룹 운동 보정(GMCS), 시공간 메모리 예측(STMP)을 결합해 소형·가림·교차·블러 상황에서 ID 유지와 추적 정확도를 높임. UAVDT와 MOT17에서 MOTA·IDF1 등에서 SOTA를 상회.


<details>
  <summary>Details</summary>
Motivation: UAV 관점의 복잡한 장면(작은 스케일, 가림, 비선형 교차 이동, 모션 블러)에서 기존 MOT 기법이 추적 안정성과 ID 일관성 측면에서 취약하므로 이를 보완할 필요가 있음.

Method: (1) 소형 타깃 특화 멀티스케일 특징 강화 탐지기; (2) 속도 동력학을 도입한 VACKF로 궤적 예측 정확도 향상; (3) 그룹 운동 사전(GMCS)으로 저품질 트랙의 상태 업데이트 보정하여 어소시에이션 개선; (4) 과거 궤적 기반 STMP로 미래 상태 예측해 ID 스위칭 감소.

Result: UAVDT와 MOT17에서 MOTA·IDF1 등 핵심 지표에서 기존 SOTA 대비 유의한 개선을 보고. 모듈식 설계로 기존 트래커에 통합 가능.

Conclusion: 소형 목표 및 복잡한 도시 교통 상황에서 추적의 강건성·정확도를 향상시키며, 모듈화로 확장·적용성이 높음.

Abstract: As a key research direction in the field of multi-object tracking (MOT),
UAV-based multi-object tracking has significant application value in the
analysis and understanding of urban intelligent transportation systems.
However, in complex UAV perspectives, challenges such as small target scale
variations, occlusions, nonlinear crossing motions, and motion blur severely
hinder the stability of multi-object tracking. To address these challenges,
this paper proposes a novel multi-object tracking framework, SocialTrack, aimed
at enhancing the tracking accuracy and robustness of small targets in complex
urban traffic environments. The specialized small-target detector enhances the
detection performance by employing a multi-scale feature enhancement mechanism.
The Velocity Adaptive Cubature Kalman Filter (VACKF) improves the accuracy of
trajectory prediction by incorporating a velocity dynamic modeling mechanism.
The Group Motion Compensation Strategy (GMCS) models social group motion priors
to provide stable state update references for low-quality tracks, significantly
improving the target association accuracy in complex dynamic environments.
Furthermore, the Spatio-Temporal Memory Prediction (STMP) leverages historical
trajectory information to predict the future state of low-quality tracks,
effectively mitigating identity switching issues. Extensive experiments on the
UAVDT and MOT17 datasets demonstrate that SocialTrack outperforms existing
state-of-the-art (SOTA) methods across several key metrics. Significant
improvements in MOTA and IDF1, among other core performance indicators,
highlight its superior robustness and adaptability. Additionally, SocialTrack
is highly modular and compatible, allowing for seamless integration with
existing trackers to further enhance performance.

</details>


### [116] [Leveraging Diffusion Models for Stylization using Multiple Style Images](https://arxiv.org/abs/2508.12784)
*Dan Ruta,Abdelaziz Djelouah,Raphael Ortiz,Christopher Schroers*

Main category: cs.CV

TL;DR: 다중 스타일 이미지와 어텐션-단위 통계 정렬을 결합해 잠재 확산모델 기반 스타일 전이의 정확성·표현력·콘텐츠 누수 문제를 개선하는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기존 잠재 확산 기반 스타일 전이는 스타일 일치도가 낮고, 사용할 수 있는 스타일 이미지 수가 제한적이며, 스타일 이미지로부터 원치 않는 콘텐츠가 유입되는(콘텐츠 누수) 문제를 겪는다. 이를 해결해 더 충실한 스타일 전이를 목표로 한다.

Method: 여러 스타일 이미지를 활용해 스타일 특징을 더 잘 대표하도록 하고, 이미지 프롬프트 어댑터(image prompt adapters)와 디노이징 과정 중 특징의 통계 정렬(statistical alignment)을 결합한다. 이 개입은 디노이징 UNet의 크로스-어텐션과 셀프-어텐션 계층 모두에서 이루어지며, 많은 수의 스타일 어텐션 값들로부터 클러스터링을 통해 소수의 대표 어텐션 특징을 추출해 통계 정렬에 사용한다.

Result: 제안한 방식은 스타일 일치도와 콘텐츠-스타일 분리 측면에서 실험적으로 우수한 결과를 보여주며, 제시된 실험에서 최첨단 수준의 스타일라이제이션 성능을 달성한다고 보고한다.

Conclusion: 다중 스타일 샘플과 어텐션 수준에서의 통계적 정렬을 결합하면 스타일 표현력이 향상되고 콘텐츠 누수가 감소한다. 클러스터링으로 요약된 어텐션 특징을 사용해 확장성과 효율성도 확보한다.

Abstract: Recent advances in latent diffusion models have enabled exciting progress in
image style transfer. However, several key issues remain. For example, existing
methods still struggle to accurately match styles. They are often limited in
the number of style images that can be used. Furthermore, they tend to entangle
content and style in undesired ways. To address this, we propose leveraging
multiple style images which helps better represent style features and prevent
content leaking from the style images. We design a method that leverages both
image prompt adapters and statistical alignment of the features during the
denoising process. With this, our approach is designed such that it can
intervene both at the cross-attention and the self-attention layers of the
denoising UNet. For the statistical alignment, we employ clustering to distill
a small representative set of attention features from the large number of
attention values extracted from the style samples. As demonstrated in our
experimental section, the resulting method achieves state-of-the-art results
for stylization.

</details>


### [117] [Vehicle detection from GSV imagery: Predicting travel behaviour for cycling and motorcycling using Computer Vision](https://arxiv.org/abs/2508.12794)
*Kyriaki,Kokka,Rahul Goel,Ali Abbas,Kerry A. Nice,Luca Martial,SM Labib,Rihuan Ke,Carola Bibiane Schönlieb,James Woodcock*

Main category: cs.CV

TL;DR: 전 세계 185개 도시의 구글 스트리트뷰(GSV) 이미지를 YOLOv4로 자동 검출해 자전거·오토바이 사용 비중을 추정한 연구. 오토바이 검출과 모드쉐어 예측은 강한 상관(0.78)·높은 설명력(R^2≈0.61)을 보였고, 자전거는 중간 수준(상관 0.51). GSV+컴퓨터 비전이 전통적 조사자료를 보완하는 유용한 방법임을 제시.


<details>
  <summary>Details</summary>
Motivation: 글로벌 규모의 자전거·오토바이 행동 비교 데이터가 부족하고, 스트리트뷰+컴퓨터비전이 대규모·저비용으로 여행행태를 포착할 수 있다는 점을 활용하려는 동기.

Method: 185개 도시에서 도시당 약 8000장씩 GSV 이미지 샘플링. 자전거·오토바이 검출을 위해 6개 도시 이미지로 YOLOv4 파인튜닝(검출 mAP 89%). 각 도시에서 검출 건수를 로그 변환해 인구밀도로 통제한 베타 회귀모형으로 도시 수준의 모드쉐어(설문/센서·인구조사 기준)를 예측.

Result: 오토바이 검출 카운트와 모드쉐어 상관 0.78, 자전거는 0.51. 베타회귀 R^2: 자전거 0.614, 오토바이 0.612. MDAE: 자전거 1.3%, 오토바이 1.4%. 몇몇 도시(예: Utrecht, Cali)는 예측 오차가 컸고, 모형을 60개 데이터 없는 도시에 적용해 추정값 제공.

Conclusion: GSV 기반 컴퓨터비전은 도시 간 이동모드 수준을 추정하는 실용적 보완수단. 다만 GSV의 공간·시간적 편향, 파인튜닝 데이터 한정, 도시내 이질성 등 한계를 갖고 있어 추가 개선·검증이 필요.

Abstract: Transportation influence health by shaping exposure to physical activity, air
pollution and injury risk.Comparative data on cycling and motorcycling
behaviours is scarce, particularly at a global scale.Street view imagery, such
as Google Street View (GSV), combined with computer vision, is a valuable
resource for efficiently capturing travel behaviour data.This study
demonstrates a novel approach using deep learning on street view images to
estimate cycling and motorcycling levels across diverse cities worldwide.We
utilized data from 185 global cities.The data on mode shares of cycling and
motorcycling estimated using travel surveys or censuses.We used GSV images to
detect cycles and motorcycles in sampled locations, using 8000 images per
city.The YOLOv4 model, fine-tuned using images from six cities, achieved a mean
average precision of 89% for detecting cycles and motorcycles in GSV images.A
global prediction model was developed using beta regression with city-level
mode shares as outcome, with log transformed explanatory variables of counts of
GSV-detected images with cycles and motorcycles, while controlling for
population density.We found strong correlations between GSV motorcycle counts
and motorcycle mode share (0.78) and moderate correlations between GSV cycle
counts and cycling mode share (0.51).Beta regression models predicted mode
shares with $R^2$ values of 0.614 for cycling and 0.612 for motorcycling,
achieving median absolute errors (MDAE) of 1.3% and 1.4%,
respectively.Scatterplots demonstrated consistent prediction accuracy, though
cities like Utrecht and Cali were outliers.The model was applied to 60 cities
globally for which we didn't have recent mode share data.We provided estimates
for some cities in the Middle East, Latin America and East Asia.With computer
vision, GSV images capture travel modes and activity, providing insights
alongside traditional data sources.

</details>


### [118] [Morphological classification of eclipsing binary stars using computer vision methods](https://arxiv.org/abs/2508.12802)
*Štefan Parimucha,Maksim Gabdeev,Yanna Markus,Martin Vaňko,Pavol Gajdoš*

Main category: cs.CV

TL;DR: 합성 광도곡선을 극좌표 + 헥스빈 이미지로 변환해 사전학습된 ResNet50 및 ViT 모델을 미세조정하여 이클립싱 이진성의 형태(분리형/오버컨택트)와 스폿 유무를 계층적으로 분류함. 형태 분류는 검증 및 관측 데이터에서 높은 정확도를 보였으나(>94%) 스폿 검출 성능은 저조함.


<details>
  <summary>Details</summary>
Motivation: 대규모 시간탐사에서 수많은 이클립싱 이진성의 형태를 자동으로 분류하고, 미세한 광변화(예: 스폿)를 자동으로 식별하여 후속 관측과 물리분석의 우선순위를 정하기 위함.

Method: 주기 접힘된 광도곡선을 극좌표계로 변환하고 헥스빈 시각화를 적용해 이미지로 생성. 합성 데이터로 ResNet50 및 ViT 사전학습 모델을 파인튜닝. 2단계 계층적 분류: 1단계(분리형 vs 오버컨택트), 2단계(스폿 유무). 다양한 필터(Gaia G, I, TESS) 및 실관측 카탈로그(OGLE, DEBCat, WUMaCat)에서 평가.

Result: 유효성 검증에서 이진분류 정확도 >96%. 실관측 데이터 테스트에서도 >94% (TESS는 최대 100%) 성능을 기록. 반면 스폿 검출은 전반적으로 낮은 성능을 보임.

Conclusion: 이미지 기반 컴퓨터비전 접근은 EB 형태 분류에 유망하지만, 미세한 광학 신호(스폿) 검출에는 현재 방법이 부족하며 추가적인 데이터, 표현 방식 및 도메인 적응 연구가 필요하다.

Abstract: We present an application of computer vision methods to classify the light
curves of eclipsing binaries (EB). We have used pre-trained models based on
convolutional neural networks ($\textit{ResNet50}$) and vision transformers
($\textit{vit\_base\_patch16\_224}$), which were fine-tuned on images created
from synthetic datasets. To improve model generalisation and reduce
overfitting, we developed a novel image representation by transforming
phase-folded light curves into polar coordinates combined with hexbin
visualisation. Our hierarchical approach in the first stage classifies systems
into detached and overcontact types, and in the second stage identifies the
presence or absence of spots. The binary classification models achieved high
accuracy ($>96\%$) on validation data across multiple passbands (Gaia~$G$, $I$,
and $TESS$) and demonstrated strong performance ($>94\%$, up to $100\%$ for
$TESS$) when tested on extensive observational data from the OGLE, DEBCat, and
WUMaCat catalogues. While the primary binary classification was highly
successful, the secondary task of automated spot detection performed poorly,
revealing a significant limitation of our models for identifying subtle
photometric features. This study highlights the potential of computer vision
for EB morphological classification in large-scale surveys, but underscores the
need for further research into robust, automated spot detection.

</details>


### [119] [Next Visual Granularity Generation](https://arxiv.org/abs/2508.12811)
*Yikai Wang,Zhouxia Wang,Zhonghua Wu,Qingyi Tao,Kang Liao,Chen Change Loy*

Main category: cs.CV

TL;DR: Introduce Next Visual Granularity (NVG), a generation framework that decomposes images into a sequence of layers at the same spatial resolution but different token counts, progressively refining from coarse layout to fine detail; yields improved FID vs VAR on ImageNet and shows scaling.


<details>
  <summary>Details</summary>
Motivation: Provide a structured, hierarchical image generation process that gives fine-grained control over generation at multiple visual granularities and improves sample quality by progressive refinement.

Method: Decompose each image into a structured sequence of elements sharing spatial resolution but using different numbers of unique tokens (different granularity levels). NVG generates this sequence autoregressively from an empty image, iteratively adding and refining layers (global layout -> mid-level -> fine details), forming a hierarchical layered representation. Train class-conditional NVG models on ImageNet and compare with the VAR series.

Result: NVG models display clear scaling behavior and consistently better FID scores than VAR variants on ImageNet: e.g. 3.30 -> 3.03, 2.57 -> 2.44, 2.09 -> 2.06. Extensive analyses demonstrate capabilities and potential of the framework.

Conclusion: NVG is a promising approach for controllable, hierarchical image synthesis that improves quantitative quality metrics over comparable methods. Future work should consider broader benchmarks, computational cost, and perceptual evaluations.

Abstract: We propose a novel approach to image generation by decomposing an image into
a structured sequence, where each element in the sequence shares the same
spatial resolution but differs in the number of unique tokens used, capturing
different level of visual granularity. Image generation is carried out through
our newly introduced Next Visual Granularity (NVG) generation framework, which
generates a visual granularity sequence beginning from an empty image and
progressively refines it, from global layout to fine details, in a structured
manner. This iterative process encodes a hierarchical, layered representation
that offers fine-grained control over the generation process across multiple
granularity levels. We train a series of NVG models for class-conditional image
generation on the ImageNet dataset and observe clear scaling behavior. Compared
to the VAR series, NVG consistently outperforms it in terms of FID scores (3.30
-> 3.03, 2.57 ->2.44, 2.09 -> 2.06). We also conduct extensive analysis to
showcase the capability and potential of the NVG framework. Our code and models
will be released.

</details>


### [120] [SIS-Challenge: Event-based Spatio-temporal Instance Segmentation Challenge at the CVPR 2025 Event-based Vision Workshop](https://arxiv.org/abs/2508.12813)
*Friedhelm Hamann,Emil Mededovic,Fabian Gülhan,Yuli Wu,Johannes Stegmaier,Jing He,Yiqing Wang,Kexin Zhang,Lingling Li,Licheng Jiao,Mengru Ma,Hongxiang Huang,Yuhao Yan,Hongwei Ren,Xiaopeng Lin,Yulong Huang,Bojun Cheng,Se Hyun Lee,Gyu Sung Ham,Kanghan Oh,Gi Hyun Lim,Boxuan Yang,Bowen Du,Guillermo Gallego*

Main category: cs.CV

TL;DR: CVPR 2025 Event-based Vision 워크숍에서 열린 Spatio-temporal Instance Segmentation(SIS) 챌린지 개요: 이벤트 카메라와 그레이스케일 카메라의 시공간 정렬 데이터를 입력으로 픽셀 수준 인스턴스 세그멘테이션 마스크를 예측하는 과제, 데이터셋·평가·상위 5개 팀의 방법과 결과를 정리하고 코드·자료를 공개.


<details>
  <summary>Details</summary>
Motivation: 이벤트 카메라는 높은 시간 해상도와 저지연 특성으로 급속한 장면 변화 포착에 강점이 있으나, 기존 프레임 기반 세그멘테이션과 결합해 정밀한 픽셀 단위 인스턴스 분할을 수행하는 표준 벤치마크와 비교·분석이 부족함. 본 챌린지는 이벤트 데이터와 그레이스케일 영상을 시공간 정렬해 다중 모달리티 기반 인스턴스 세그멘테이션 성능을 측정하고, 방법들을 비교·공유하려는 목적.

Method: 시공간 정렬된 이벤트+그레이스케일 데이터셋과 명확한 태스크 정의(픽셀 수준 인스턴스 마스크 예측), 평가 지표·리더보드 운영. 참가팀들은 이벤트 인코딩(이벤트 이미지·타입·히스토그램 등), 모달 융합(초기 채널 융합·중간 특징 융합), 시계열 처리(시퀀스 모델·Temporal Conv/Transformer), U-Net/Mask R-CNN 계열 구조 및 전처리·데이터 증강 기법을 활용해 모델을 제출.

Result: 챌린지 결과와 상위 5개 팀의 방법·설계 선택을 정리하여 비교 제공. 정성·정량 분석을 통해 멀티모달 융합과 시공간적 처리 전략이 성능에 중요한 역할을 함을 제시. 추가 코드·자세한 결과는 공개 레포지토리에 수록.

Conclusion: SIS 챌린지는 이벤트 기반 비전과 프레임 기반 비전을 통합한 픽셀 수준 인스턴스 세그멘테이션 연구를 촉진하는 벤치마크를 제공하고, 상위 방법들의 설계 통찰과 공개 코드로 후속 연구·개발을 지원함.

Abstract: We present an overview of the Spatio-temporal Instance Segmentation (SIS)
challenge held in conjunction with the CVPR 2025 Event-based Vision Workshop.
The task is to predict accurate pixel-level segmentation masks of defined
object classes from spatio-temporally aligned event camera and grayscale camera
data. We provide an overview of the task, dataset, challenge details and
results. Furthermore, we describe the methods used by the top-5 ranking teams
in the challenge. More resources and code of the participants' methods are
available here:
https://github.com/tub-rip/MouseSIS/blob/main/docs/challenge_results.md

</details>


### [121] [DEEP-SEA: Deep-Learning Enhancement for Environmental Perception in Submerged Aquatics](https://arxiv.org/abs/2508.12824)
*Shuang Chen,Ronald Thenius,Farshad Arvin,Amir Atapour-Abarghouei*

Main category: cs.CV

TL;DR: DEEP-SEA는 주파수 분해와 자기-어텐션을 결합한 Dual-Frequency Enhanced Self-Attention Spatial and Frequency Modulator를 도입해 저주파·고주파 정보를 동시에 강화하고 공간 구조를 보존하는 딥러닝 기반 수중 영상 복원 모델이다. EUVP·LSUI에서 SOTA 대비 정밀한 디테일과 구조 일관성에서 우수한 성능을 보였다.


<details>
  <summary>Details</summary>
Motivation: 수중 영상은 빛의 산란·흡수·혼탁으로 인해 색상 왜곡과 선명도 저하가 심해 생태 관측·종 식별·자율 탐사에 어려움을 준다. 그러므로 저·고주파 성분을 균형 있게 복원하고 공간 구조를 보존하는 고성능 복원 기법이 필요하다.

Method: 제안된 모듈은 주파수 도메인에서 특징을 적응적으로 정제하는 ‘Dual-Frequency Enhanced Self-Attention’과 공간 정보를 함께 다루는 ‘Spatial and Frequency Modulator’를 결합한다. 이를 통해 저주파(색·조명)와 고주파(엣지·세부) 정보를 동시에 향상시키고 공간적 연속성을 유지하도록 학습한다. 모델은 EUVP·LSUI 데이터로 훈련되며 구조·디테일 보존을 강조하는 손실로 최적화된 것으로 보인다.

Result: 실험에서 제안모델은 EUVP·LSUI 상에서 기존 기법보다 세밀한 디테일 복원과 구조적 일관성에서 개선된 성능을 보였다고 보고한다(정량·정성 모두 우수).

Conclusion: DEEP-SEA는 수중 시각 열화를 효과적으로 완화하여 해양 모니터링 플랫폼의 관측·종 식별·자율 항해 신뢰도를 높일 잠재력이 있다.

Abstract: Continuous and reliable underwater monitoring is essential for assessing
marine biodiversity, detecting ecological changes and supporting autonomous
exploration in aquatic environments. Underwater monitoring platforms rely on
mainly visual data for marine biodiversity analysis, ecological assessment and
autonomous exploration. However, underwater environments present significant
challenges due to light scattering, absorption and turbidity, which degrade
image clarity and distort colour information, which makes accurate observation
difficult. To address these challenges, we propose DEEP-SEA, a novel deep
learning-based underwater image restoration model to enhance both low- and
high-frequency information while preserving spatial structures. The proposed
Dual-Frequency Enhanced Self-Attention Spatial and Frequency Modulator aims to
adaptively refine feature representations in frequency domains and
simultaneously spatial information for better structural preservation. Our
comprehensive experiments on EUVP and LSUI datasets demonstrate the superiority
over the state of the art in restoring fine-grained image detail and structural
consistency. By effectively mitigating underwater visual degradation, DEEP-SEA
has the potential to improve the reliability of underwater monitoring platforms
for more accurate ecological observation, species identification and autonomous
navigation.

</details>


### [122] [Multi-source Multimodal Progressive Domain Adaption for Audio-Visual Deception Detection](https://arxiv.org/abs/2508.12842)
*Ronghao Lin,Sijie Mai,Ying Zeng,Qiaolin He,Aolin Xiong,Haifeng Hu*

Main category: cs.CV

TL;DR: 다중 소스·멀티모달 점진적 도메인 적응(MMPDA)을 통해 오디오-비주얼 지식을 다양한 소스 도메인에서 목표 도메인으로 이전해 기만성(Deception) 검출의 도메인 편차를 완화한 방법으로, 대회에서 Top-2를 기록(Accuracy 60.43%, F1 56.99%).


<details>
  <summary>Details</summary>
Motivation: 다양한 멀티모달 데이터셋(소스)과 목표 도메인 간의 분포 차이(domain shift)가 기만성 검출 성능을 저해하므로, 여러 소스 도메인으로부터 지식을 효과적으로 이전해 목표 도메인 성능을 개선하고자 함.

Method: Multi-source Multimodal Progressive Domain Adaptation(MMPDA) 프레임워크를 제안. 소스와 타깃 도메인을 점진적으로(feature 및 decision level 모두에서) 정렬하여 다양한 멀티모달 도메인 간의 격차를 줄임. 오디오와 비주얼 정보를 통합하여 적응 과정에서 점진적 정렬을 수행하는 것으로 보임.

Result: 대회 스테이지2에서 Accuracy 60.43%, F1-score 56.99%를 달성해 Top-2를 확보. F1은 1위보다 5.59% 높고, Accuracy는 3위보다 6.75% 높음. 코드 공개(https://github.com/RH-Lin/MMPDA).

Conclusion: MMPDA는 다중 소스와 멀티모달 정보를 활용한 점진적 도메인 적응이 도메인 편차가 큰 기만성 검출 문제에서 실효성이 있음을 보여줌. 다만 초록만으로는 구현 세부(특징 유형, 손실, 점진적 전략, 소스 도메인 목록 등)가 부족해 재현·확장 연구를 위해 본문·코드 확인이 필요함.

Abstract: This paper presents the winning approach for the 1st MultiModal Deception
Detection (MMDD) Challenge at the 1st Workshop on Subtle Visual Computing
(SVC). Aiming at the domain shift issue across source and target domains, we
propose a Multi-source Multimodal Progressive Domain Adaptation (MMPDA)
framework that transfers the audio-visual knowledge from diverse source domains
to the target domain. By gradually aligning source and the target domain at
both feature and decision levels, our method bridges domain shifts across
diverse multimodal datasets. Extensive experiments demonstrate the
effectiveness of our approach securing Top-2 place. Our approach reaches 60.43%
on accuracy and 56.99\% on F1-score on competition stage 2, surpassing the 1st
place team by 5.59% on F1-score and the 3rd place teams by 6.75% on accuracy.
Our code is available at https://github.com/RH-Lin/MMPDA.

</details>


### [123] [Cross-Domain Few-Shot Learning via Multi-View Collaborative Optimization with Vision-Language Models](https://arxiv.org/abs/2508.12861)
*Dexia Chen,Wentao Zhang,Qianjie Zhu,Ping Hu,Weibing Li,Tong Zhang,Ruixuan Wang*

Main category: cs.CV

TL;DR: 자연 이미지로 사전학습된 VLM(예: CLIP)은 표준 데이터셋에서 강하지만 도메인이 다른 교차-도메인 소수샷에서는 성능이 떨어진다. 저자들은 CoMuCo라는 미세조정 기법을 제안해, 두 개의 상호보완적 전문가 모듈로 다중 뷰 특징을 추출하고 사전지식 기반 일관성 제약 및 정보기하학 기반 합의 메커니즘을 적용해 특징 학습의 강건성을 높인다. 새로운 교차-도메인 소수샷 벤치마크도 제시하며, 광범위한 실험에서 기존 방법들보다 일관되게 우수한 성능을 보였다고 주장한다.


<details>
  <summary>Details</summary>
Motivation: 기존 VLM 전이/미세조정 방법들이 자연 이미지와 다른 도메인(의료영상, 위성, 산업용 등)으로 일반화되지 못해 소수샷 상황에서 성능 저하가 발생한다. 도메인 갭을 극복하고 VLM의 사전지식을 안전하고 견고하게 활용할 방법이 필요하다.

Method: CoMuCo는 두 개의 기능적으로 보완되는 전문가 모듈을 도입해 다중 뷰(multi-view) 특징을 추출한다. 추출된 뷰들에 대해 사전 지식(프롬프트나 클래스 임베딩 등)에 기반한 일관성 제약을 부과하고, 정보기하학(information geometry)을 이용한 합의(consensus) 메커니즘으로 뷰 간 불일치를 완화해 강건한 특징을 학습한다. 전체적으로 VLM을 효율적으로 미세조정하는 전략이다.

Result: 새로 제안한 교차-도메인 소수샷 벤치마크와 기존 벤치마크에서 광범위한 실험을 수행했고, CoMuCo가 여러 기존 미세조정/전이 방법보다 일관되게 우수한 성능을 달성했다고 보고한다. 코드와 벤치마크 공개 예정.

Conclusion: CoMuCo는 교차-도메인 소수샷 문제에 대한 실용적이고 강건한 미세조정 방법을 제시한다. 다만 논문에서 모듈 구체 구조, 일관성 제약의 정확한 형태, 계산 비용 및 벤치마크의 범위·공정성에 대한 자세한 검증을 확인할 필요가 있다.

Abstract: Vision-language models (VLMs) pre-trained on natural image and language data,
such as CLIP, have exhibited significant potential in few-shot image
recognition tasks, leading to development of various efficient transfer
learning methods. These methods exploit inherent pre-learned knowledge in VLMs
and have achieved strong performance on standard image datasets. However, their
effectiveness is often limited when confronted with cross-domain tasks where
imaging domains differ from natural images. To address this limitation, we
propose Consistency-guided Multi-view Collaborative Optimization (CoMuCo), a
novel fine-tuning strategy for VLMs. This strategy employs two functionally
complementary expert modules to extract multi-view features, while
incorporating prior knowledge-based consistency constraints and information
geometry-based consensus mechanisms to enhance the robustness of feature
learning. Additionally, a new cross-domain few-shot benchmark is established to
help comprehensively evaluate methods on imaging domains distinct from natural
images. Extensive empirical evaluations on both existing and newly proposed
benchmarks suggest CoMuCo consistently outperforms current methods in few-shot
tasks. The code and benchmark will be released.

</details>


### [124] [Preserve and Sculpt: Manifold-Aligned Fine-tuning of Vision-Language Models for Few-Shot Learning](https://arxiv.org/abs/2508.12877)
*Dexia Chen,Qianjie Zhu,Weibing Li,Yue Yu,Tong Zhang,Ruixuan Wang*

Main category: cs.CV

TL;DR: 저자들은 VLM 미세조정 시 특징 공간의 기하구조(semantic manifold)를 보존하면서 클래스 간 분리도를 향상시키는 MPS-Tuning을 제안한다. Gram 행렬 정렬로 매니폴드의 미시·거시 구조를 보존하고, 이미지-텍스트 페어 유사성 최적화로 판별력을 높여 성능을 향상시켰다.


<details>
  <summary>Details</summary>
Motivation: 기존 VLM 미세조정 방법은 파라미터 효율성 또는 일관성 제약으로 과적합을 줄이지만, 데이터 분포의 기하학적 구조를 무시해 전체 의미 표현이 왜곡될 수 있다. 이를 보완해 미세조정 과정에서 의미 매니폴드의 위상 구조를 보존하면서 판별성을 개선하려는 필요성이 있다.

Method: MPS-Tuning은 특징 공간을 의미 매니폴드로 간주하고, 미세조정 전후의 Gram 행렬을 정렬하여 매니폴드의 거시·미시 위상 구조를 보존한다. 이 제약은 이론적으로 Gromov-Wasserstein 거리의 상한을 근사함을 보인다. 추가로 이미지와 텍스트 모달리티의 특징을 페어링하고 페어 간 유사도를 최적화해 클래스 분리도를 조각(sculpt)한다.

Result: 다양한 실험에서 MPS-Tuning은 모델 성능을 유의미하게 향상시키면서 의미 매니폴드의 구조를 효과적으로 보존함을 보였다(구체적 수치와 데이터셋은 초록에 없음). 코드 공개 예정.

Conclusion: 매니폴드 구조 보존과 판별성 향상을 동시에 달성하는 실용적 미세조정 방법을 제시하며, 기하학적 정규화가 VLM 전이학습에 유용함을 입증한다.

Abstract: Pretrained vision-language models (VLMs), such as CLIP, have shown remarkable
potential in few-shot image classification and led to numerous effective
transfer learning strategies. These methods leverage the pretrained knowledge
of VLMs to enable effective domain adaptation while mitigating overfitting
through parameter-efficient tuning or instance-based consistency constraints.
However, such regularizations often neglect the geometric structure of data
distribution, which may lead to distortion of the overall semantic
representation. To overcome this limitation, we propose a novel fine-tuning
method, Manifold-Preserving and Sculpting Tuning (MPS-Tuning). Regarding the
data distribution in feature space as a semantic manifold, MPS-Tuning
explicitly constrains the intrinsic geometry of this manifold while further
sculpting it to enhance class separability. Specifically, MPS-Tuning preserves
both macroscopic and microscopic topological structures of the original
manifold by aligning Gram matrices of features before and after fine-tuning.
Theoretically, this constraint is shown to approximate an upper bound of the
Gromov-Wasserstein distance. Furthermore, features from the image and text
modalities are paired, and pairwise similarities are optimized to enhance the
manifold's class discriminability. Extensive experiments demonstrate that
MPS-Tuning significantly improves model performance while effectively
preserving the structure of the semantic manifold. The code will be released.

</details>


### [125] [S^2-Guidance: Stochastic Self Guidance for Training-Free Enhancement of Diffusion Models](https://arxiv.org/abs/2508.12880)
*Chubin Chen,Jiashu Zhu,Xiaokun Feng,Nisha Huang,Meiqi Wu,Fangyuan Mao,Jiahong Wu,Xiangxiang Chu,Xiu Li*

Main category: cs.CV

TL;DR: 이 논문은 Classifier-free Guidance(CFG)의 한계 — 모델이 서브옵티멀한 예측에 과도히 의존해 의미적 일관성 및 샘플 품질이 떨어지는 문제 — 을 지적하고, 모델 자체의 서브네트워크(sub-network)를 활용해 이를 개선하는 S^2-Guidance라는 새 방법을 제안한다. S^2-Guidance는 순전파 과정에서 블록을 확률적으로 드롭해(스톡캐스틱 블록-드로핑) 다양한 서브네트워크를 구성하고, 이를 통해 저품질 예측을 회피하여 고품질 출력을 유도한다. 실험(텍스트-투-이미지·비디오)에서 CFG와 다른 기법들을 일관되게 능가함을 보였다.


<details>
  <summary>Details</summary>
Motivation: CFG는 확률적 생성 모델의 품질을 개선하는 데 널리 쓰이지만, 저차원 Gaussian 혼합 모델의 닫힌 형태 해석에서도 CFG가 지면한 결과는 최적이 아니며, 모델이 이런 서브옵티멀한 예측에 과도하게 의존하면 의미적 불일치와 저품질 생성물이 발생한다. 이를 해결할 수 있는 실용적이면서도 모델 내부에서 실행 가능한 개선책(서브네트워크 이용)이 필요하다.

Method: 저자들은 모델의 서브네트워크(모델 내부 일부 블록을 확률적으로 드롭한 네트워크)가 원래 모델이 만든 서브옵티멀한 예측을 효과적으로 정제할 수 있음을 실험적으로 보였다. 이를 바탕으로 S^2-Guidance를 제안한다. S^2-Guidance는 순전파 중 블록을 랜덤하게 드롭해 여러 확률적 서브네트워크를 구성하고, 이들 예측을 이용해 원 모델의 방향을 교정(또는 가중평균 등으로 결합)하여 저품질 예측을 회피하고 고품질 예측을 유도한다.

Result: 텍스트-투-이미지와 텍스트-투-비디오 생성에서 질적·양적 평가 모두 S^2-Guidance가 CFG 및 다른 고급 가이던스 기법을 일관되게 능가함을 보여준다. 자세한 수치(예: FID, CLIP 점수 등)는 초록에 없으나 '광범위한' 실험에서 우수성을 주장한다.

Conclusion: S^2-Guidance는 모델 내부의 확률적 서브네트워크를 활용해 CFG의 한계를 극복하고 더 높은 품질, 더 높은 프롬프트 일치도를 달성한다. 실제 적용 가능하며 코드 공개 예정.

Abstract: Classifier-free Guidance (CFG) is a widely used technique in modern diffusion
models for enhancing sample quality and prompt adherence. However, through an
empirical analysis on Gaussian mixture modeling with a closed-form solution, we
observe a discrepancy between the suboptimal results produced by CFG and the
ground truth. The model's excessive reliance on these suboptimal predictions
often leads to semantic incoherence and low-quality outputs. To address this
issue, we first empirically demonstrate that the model's suboptimal predictions
can be effectively refined using sub-networks of the model itself. Building on
this insight, we propose S^2-Guidance, a novel method that leverages stochastic
block-dropping during the forward process to construct stochastic sub-networks,
effectively guiding the model away from potential low-quality predictions and
toward high-quality outputs. Extensive qualitative and quantitative experiments
on text-to-image and text-to-video generation tasks demonstrate that
S^2-Guidance delivers superior performance, consistently surpassing CFG and
other advanced guidance strategies. Our code will be released.

</details>


### [126] [ONG: One-Shot NMF-based Gradient Masking for Efficient Model Sparsification](https://arxiv.org/abs/2508.12891)
*Sankar Behera,Yamuna Prasad*

Main category: cs.CV

TL;DR: ONG은 훈련 시작 시 비음수행렬분해(NMF)로 중요 가중치 구조를 한 번에 식별해 원샷(pruning)하고, 이후 정밀한 그래디언트 마스킹으로 오로지 남은 가중치만 갱신해 목표 희소도를 훈훈하게 유지하는 방법이다. CIFAR-10/100의 ResNet 계열에서 기존 안정적 희소화 기법들과 비슷하거나 더 나은 성능을 보였다.


<details>
  <summary>Details</summary>
Motivation: 대형 DNN의 배포 어려움으로 모델 경량화가 필요하지만, 많은 기존 가지치기(pruning) 기법은 반복적·복잡하거나 훈련 중 희소도를 유지하지 못하는 문제가 있다. 초기부터 목표 희소도를 엄격히 보장하는 간단하고 예측 가능한 방법이 필요하다.

Method: 훈련 시작 전 가중치 행렬에 NMF를 적용해 중요 구조(요소)를 식별하고, 이를 바탕으로 원샷 마스크를 생성해 불필요한 가중치를 제거한다. 훈련 중에는 정밀한 그래디언트 마스킹을 적용해 마스크된(제거된) 가중치의 업데이트를 차단함으로써 희소도를 엄격히 유지한다. BIMP 비교 프레임워크에 통합해 ResNet56/34/18을 CIFAR-10/100에서 평가했다.

Result: 다양한 희소도 수준에서 기존의 안정적 희소화 방법들과 비교해 동등하거나 더 우수한 정확도를 달성했으며, 가지치기 후 구조적 무결성(예: 채널/블록 단위 보존)을 유지하고 목표 희소도를 명확히 달성했다.

Conclusion: ONG는 단순하면서도 목표 희소도를 훈련 내내 보장하는 실용적 방법이다. 다만 NMF 적용 방식(계층/채널 단위, rank 선택), NMF의 계산 비용, 대규모 데이터·아키텍처로의 확장성, 초기화·난수 시드 민감도 등에 대한 추가 정보가 필요하다.

Abstract: Deep Neural Networks (DNNs) have achieved remarkable success but their large
size poses deployment challenges. While various pruning techniques exist, many
involve complex iterative processes, specialized criteria, or struggle to
maintain sparsity effectively during training. We introduce ONG (One-shot
NMF-based Gradient Masking), a novel sparsification strategy that identifies
salient weight structures using Non-negative Matrix Factorization (NMF) for
one-shot pruning at the outset of training. Subsequently, ONG employs a precise
gradient masking mechanism to ensure that only unpruned weights are updated,
strictly preserving the target sparsity throughout the training phase. We
integrate ONG into the BIMP comparative framework and evaluate it on CIFAR-10
and CIFAR-100 with ResNet56, ResNet34, and ResNet18 against established stable
sparsification methods. Our experiments demonstrate ONG's ability to achieve
comparable or superior performance at various sparsity levels while maintaining
structural integrity post-pruning and offering a clear mechanism for targeting
desired sparsities.

</details>


### [127] [CTFlow: Video-Inspired Latent Flow Matching for 3D CT Synthesis](https://arxiv.org/abs/2508.12900)
*Jiayi Wang,Hadrien Reynaud,Franciskus Xaverius Erick,Bernhard Kainz*

Main category: cs.CV

TL;DR: CTFlow는 CT-RATE 데이터셋의 임상 리포트를 조건으로 전체 3D CT 볼륨을 생성하는 0.5B 파라미터급 latent flow-matching 트랜스포머다. A-VAE(FLUX)의 잠재공간과 CT-CLIP 텍스트 인코더를 사용하며, 메모리 제약을 줄이기 위해 시퀀스별 자가회귀(slice-wise autoregressive) 생성 전략을 도입해 시간적 일관성과 텍스트-이미지 정렬을 개선한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 3D CT와 임상 리포트 페어(CT-RATE)의 공개로 텍스트 조건부 전체 CT 볼륨 생성이 현실화되었다. 이런 모델은 데이터 증강, 개인정보 보호 합성, 연구 접근성 향상 등에서 이점을 제공할 수 있다.

Method: 0.5B latent flow-matching 트랜스포머를 설계하고 FLUX의 A-VAE로 정의한 잠재공간을 사용한다. 임상 리포트는 CT-CLIP으로 인코딩한다. 메모리 제약을 해결하기 위해 볼륨을 연속된 슬라이스 시퀀스로 나누어, 첫 시퀀스는 텍스트만으로 생성하고 이후 시퀀스는 이전에 생성된 슬라이스들과 텍스트를 조건으로 예측하는 맞춤형 자가회귀 방식을 채택한다.

Result: 기존 최첨단(SoTA) CT 생성 모델과 비교해 FID, FVD, IS, CLIP 점수 등에서 우수한 성능을 보였으며 특히 시간적 일관성(temporal coherence), 이미지 다양성, 텍스트-이미지 정렬 측면에서 향상되었다.

Conclusion: CTFlow는 메모리 효율적인 자가회귀 전략과 강력한 잠재표현·텍스트 인코더 결합을 통해 임상 리포트로부터 일관된 전체 CT 볼륨을 생성하는 데 성공했다. 다만 임상 유효성 검증, 잠재적 편향·안전성 문제, 규제 측면의 추가 검토가 필요하다.

Abstract: Generative modelling of entire CT volumes conditioned on clinical reports has
the potential to accelerate research through data augmentation,
privacy-preserving synthesis and reducing regulator-constraints on patient data
while preserving diagnostic signals. With the recent release of CT-RATE, a
large-scale collection of 3D CT volumes paired with their respective clinical
reports, training large text-conditioned CT volume generation models has become
achievable. In this work, we introduce CTFlow, a 0.5B latent flow matching
transformer model, conditioned on clinical reports. We leverage the A-VAE from
FLUX to define our latent space, and rely on the CT-Clip text encoder to encode
the clinical reports. To generate consistent whole CT volumes while keeping the
memory constraints tractable, we rely on a custom autoregressive approach,
where the model predicts the first sequence of slices of the volume from
text-only, and then relies on the previously generated sequence of slices and
the text, to predict the following sequence. We evaluate our results against
state-of-the-art generative CT model, and demonstrate the superiority of our
approach in terms of temporal coherence, image diversity and text-image
alignment, with FID, FVD, IS scores and CLIP score.

</details>


### [128] [CMF-IoU: Multi-Stage Cross-Modal Fusion 3D Object Detection with IoU Joint Prediction](https://arxiv.org/abs/2508.12917)
*Zhiwei Ning,Zhaojiang Liu,Xuanang Gao,Yifan Zuo,Jie Yang,Yuming Fang,Wei Liu*

Main category: cs.CV

TL;DR: 카메라-라이다 다중 모달 정보를 깊이 보완으로 3D 가상 포인트(슈도 포인트)로 통일한 뒤, 이들을 라이다 포인트와 함께 이중 분기(희소 강화 S2D, 잔차 뷰 일관성 ResVC) 백본에서 인코딩하고 반복적 포인트-복셀 풀링과 IoU 기반 제안 정제를 통해 3개 벤치마크(KITTI, nuScenes, Waymo)에서 우수한 성능을 얻는 다단계 교차 모달 융합 3D 검출 프레임워크(CMF-IOU).


<details>
  <summary>Details</summary>
Motivation: 2D 카메라의 풍부한 텍스처(의미) 정보와 3D 라이다의 정확한 거리(공간) 정보를 효과적으로 정렬·융합해야 하는데, 기존 연구들은 단일 또는 일부 단계의 융합에 머물러 특징 추출이 불충분하고 성능이 제한됨.

Method: (1) 깊이 보완 네트워크로 이미지 픽셀을 3D 공간으로 투영해 슈도 포인트 생성; (2) 라이다 포인트와 슈도 포인트를 함께 인코딩하는 양방향 교차 뷰 강화 3D 백본 설계: S2D 분기(엔코더-디코더로 희소 라이다 보강)와 ResVC 분기(부정확한 슈도 포인트 영향 완화, 3D/2D 컨볼루션 사용); (3) 반복적 복셀-포인트 인식 정밀 풀링으로 제안 단계에서 공간·텍스처 정보 결합; (4) IoU 공동 예측 분기와 새로운 제안 생성 기법으로 IoU·분류 점수 모두 높은 박스 보존.

Result: KITTI, nuScenes, Waymo에서 광범위한 실험을 통해 제안한 CMF-IOU가 우수한 3D 검출 성능을 달성함을 보고.

Conclusion: 다단계 교차 모달 융합(슈도 포인트+양분기 백본+반복 정제+IoU 인식)을 통해 2D 의미와 3D 공간 정렬 문제가 개선되어 검출 정확도·정밀도가 향상되며, 각 구성요소의 조합이 성능 향상에 기여함을 시사함.

Abstract: Multi-modal methods based on camera and LiDAR sensors have garnered
significant attention in the field of 3D detection. However, many prevalent
works focus on single or partial stage fusion, leading to insufficient feature
extraction and suboptimal performance. In this paper, we introduce a
multi-stage cross-modal fusion 3D detection framework, termed CMF-IOU, to
effectively address the challenge of aligning 3D spatial and 2D semantic
information. Specifically, we first project the pixel information into 3D space
via a depth completion network to get the pseudo points, which unifies the
representation of the LiDAR and camera information. Then, a bilateral
cross-view enhancement 3D backbone is designed to encode LiDAR points and
pseudo points. The first sparse-to-distant (S2D) branch utilizes an
encoder-decoder structure to reinforce the representation of sparse LiDAR
points. The second residual view consistency (ResVC) branch is proposed to
mitigate the influence of inaccurate pseudo points via both the 3D and 2D
convolution processes. Subsequently, we introduce an iterative voxel-point
aware fine grained pooling module, which captures the spatial information from
LiDAR points and textural information from pseudo points in the proposal
refinement stage. To achieve more precise refinement during iteration, an
intersection over union (IoU) joint prediction branch integrated with a novel
proposals generation technique is designed to preserve the bounding boxes with
both high IoU and classification scores. Extensive experiments show the
superior performance of our method on the KITTI, nuScenes and Waymo datasets.

</details>


### [129] [7Bench: a Comprehensive Benchmark for Layout-guided Text-to-image Models](https://arxiv.org/abs/2508.12919)
*Elena Izzo,Luca Parolari,Davide Vezzaro,Lamberto Ballan*

Main category: cs.CV

TL;DR: 7Bench는 텍스트·레이아웃 조건의 텍스트→이미지 생성에서 의미적 일치(텍스트)와 공간적 일치(레이아웃)를 동시에 평가하는 최초의 벤치마크다. 7가지 도전 시나리오의 텍스트·레이아웃 쌍과 ‘레이아웃 정렬 점수’를 포함한 평가 프로토콜로 여러 최신 확산모델을 비교했다.


<details>
  <summary>Details</summary>
Motivation: 레이아웃 기반 생성은 공간 제어가 필수지만 기존 벤치마크는 텍스트-이미지 정렬만 평가하고 레이아웃 일치는 간과되어 실제 응용(특히 합성 데이터 생성)에서 공간적 오류가 데이터 품질을 저하시킬 수 있다.

Method: 텍스트·레이아웃 페어로 구성된 7가지 시나리오(객체 생성, 색상 충실성, 속성 인식, 객체 간 관계, 공간 제어 등)를 수집·설계하고, 기존 평가 프레임워크를 확장해 레이아웃 정렬 점수를 포함하는 프로토콜을 제안. 여러 SOTA 확산 모델에 대해 정량·정성 실험을 수행.

Result: 다수의 최신 모델에 대해 시나리오별 성능 차이를 드러내어 각 모델의 강점과 약점을 규명함(예: 텍스트 일치는 잘해도 레이아웃 정렬이 약한 경우 등).

Conclusion: 7Bench는 공간적 충실도를 평가하는 일관된 기준을 제공해 레이아웃-가이드 생성 연구와 합성 데이터 품질 향상을 촉진한다. 코드와 데이터는 공개되어 있다.

Abstract: Layout-guided text-to-image models offer greater control over the generation
process by explicitly conditioning image synthesis on the spatial arrangement
of elements. As a result, their adoption has increased in many computer vision
applications, ranging from content creation to synthetic data generation. A
critical challenge is achieving precise alignment between the image, textual
prompt, and layout, ensuring semantic fidelity and spatial accuracy. Although
recent benchmarks assess text alignment, layout alignment remains overlooked,
and no existing benchmark jointly evaluates both. This gap limits the ability
to evaluate a model's spatial fidelity, which is crucial when using
layout-guided generation for synthetic data, as errors can introduce noise and
degrade data quality. In this work, we introduce 7Bench, the first benchmark to
assess both semantic and spatial alignment in layout-guided text-to-image
generation. It features text-and-layout pairs spanning seven challenging
scenarios, investigating object generation, color fidelity, attribute
recognition, inter-object relationships, and spatial control. We propose an
evaluation protocol that builds on existing frameworks by incorporating the
layout alignment score to assess spatial accuracy. Using 7Bench, we evaluate
several state-of-the-art diffusion models, uncovering their respective
strengths and limitations across diverse alignment tasks. The benchmark is
available at https://github.com/Elizzo/7Bench.

</details>


### [130] [Towards High-Resolution Industrial Image Anomaly Detection](https://arxiv.org/abs/2508.12931)
*Ximiao Zhang,Min Xu,Xiuzhuang Zhou*

Main category: cs.CV

TL;DR: HiAD는 고해상도 이미지에서 미세 및 대형 이상 영역을 동시에 탐지하기 위해 이중-브랜치 구조, 다중 해상도 특징 융합, 그리고 패치별로 경량 탐지기를 적응적으로 할당하는 '탐지기 풀'을 결합한 프레임워크로, MVTec-HD/VisA-HD/RealIAD-HD 벤치마크에서 우수한 성능을 보였다고 주장한다.


<details>
  <summary>Details</summary>
Motivation: 기존 이상 탐지법은 저해상도에 최적화되어 있어 고해상도에서의 미세 이상(세부 특징 손실으로 탐지 누락)을 놓치며, 경량 네트워크나 타일링·앙상블만으로는 산업적 요구(정확도·효율)를 동시에 만족시키기 어렵다.

Method: (1) 이중-브랜치 아키텍처로 서로 다른 스케일의 이상 신호를 통합, (2) 다중 해상도 특징 융합으로 고해상도 텍스처 변동에 대응, (3) 탐지기 풀과 다양한 탐지기 배치 전략으로 패치 특성에 따라 탐지기를 적응적 할당하여 성능 유지와 연산 비용 제어를 달성.

Result: 제안한 HiAD는 저자들이 구축한 고해상도 벤치마크(MVTec-HD, VisA-HD, RealIAD-HD)에서 기존 방법들보다 우수한 탐지 성능을 보였으며, 코드가 공개되었다.

Conclusion: HiAD는 고해상도 산업용 이상 탐지 요구를 위해 정확도와 효율성 사이의 균형을 제공하는 실용적 접근법이며, 다중 스케일 통합과 적응적 탐지기 할당이 핵심 기여이다.

Abstract: Current anomaly detection methods primarily focus on low-resolution
scenarios. For high-resolution images, conventional downsampling often results
in missed detections of subtle anomalous regions due to the loss of
fine-grained discriminative information. Despite some progress, recent studies
have attempted to improve detection resolution by employing lightweight
networks or using simple image tiling and ensemble methods. However, these
approaches still struggle to meet the practical demands of industrial scenarios
in terms of detection accuracy and efficiency. To address the above issues, we
propose HiAD, a general framework for high-resolution anomaly detection. HiAD
is capable of detecting anomalous regions of varying sizes in high-resolution
images under limited computational resources. Specifically, HiAD employs a
dual-branch architecture that integrates anomaly cues across different scales
to comprehensively capture both subtle and large-scale anomalies. Furthermore,
it incorporates a multi-resolution feature fusion strategy to tackle the
challenges posed by fine-grained texture variations in high-resolution images.
To enhance both adaptability and efficiency, HiAD utilizes a detector pool in
conjunction with various detector assignment strategies, enabling detectors to
be adaptively assigned based on patch features, ensuring detection performance
while effectively controlling computational costs. We conduct extensive
experiments on our specifically constructed high-resolution anomaly detection
benchmarks, including MVTec-HD, VisA-HD, and the real-world benchmark
RealIAD-HD, demonstrating the superior performance of HiAD. The code is
available at https://github.com/cnulab/HiAD.

</details>


### [131] [SEDEG:Sequential Enhancement of Decoder and Encoder's Generality for Class Incremental Learning with Small Memory](https://arxiv.org/abs/2508.12932)
*Hongyang Chen,Shaoling Pu,Lingyu Zheng,Zhongwu Sun*

Main category: cs.CV

TL;DR: SEDEG는 ViT 기반의 증분 학습에서 디코더와 인코더의 일반성을 순차적으로 향상시키는 두 단계 프레임워크로, ensembled encoder로 특징을 부스팅한 뒤 지식 증류로 압축하여 장기 기억 소실을 완화한다.


<details>
  <summary>Details</summary>
Motivation: 증분 학습에서 고유한 문제는 새로운 데이터에 적응하면서 기존 지식을 유지하는 것인데, 엔코더-디코더 구조에서 두 구성요소의 일반성 모두를 개선해야 장기 지식 저하(망각)를 줄일 수 있음. 특히 저장 메모리가 작은 시나리오에서는 기존 방법들이 약하므로 양쪽을 모두 강화할 필요가 있음.

Method: SEDEG는 두 단계로 동작: (1) ensembled encoder를 feature boosting으로 학습해 일반화된 표현을 얻고 이로써 디코더(및 분류기)를 균형 있게 개선; (2) 그 ensembled encoder를 지식 증류(KD)로 압축하여 새로운 더 일반화된 단일 encoder를 생성. 압축 단계에서 balanced KD와 feature KD를 사용해 효과적 전송을 달성.

Result: 세 개의 벤치마크 데이터셋에서 SEDEG가 기존 방법들보다 우수한 성능을 보였고, 소규모 메모리 설정에서도 개선 효과가 뚜렷함. 구성요소별 절단(ablation) 실험으로 각 요소의 유효성 확인.

Conclusion: 인코더와 디코더의 일반성을 순차적으로 향상시키는 접근은 증분 학습의 망각 완화에 유효하며, SEDEG는 실험적으로 이를 입증. 코드 공개로 재현성 제공.

Abstract: In incremental learning, enhancing the generality of knowledge is crucial for
adapting to dynamic data inputs. It can develop generalized representations or
more balanced decision boundaries, preventing the degradation of long-term
knowledge over time and thus mitigating catastrophic forgetting. Some emerging
incremental learning methods adopt an encoder-decoder architecture and have
achieved promising results. In the encoder-decoder achitecture, improving the
generalization capabilities of both the encoder and decoder is critical, as it
helps preserve previously learned knowledge while ensuring adaptability and
robustness to new, diverse data inputs. However, many existing continual
methods focus solely on enhancing one of the two components, which limits their
effectiveness in mitigating catastrophic forgetting. And these methods perform
even worse in small-memory scenarios, where only a limited number of historical
samples can be stored. To mitigate this limitation, we introduces SEDEG, a
two-stage training framework for vision transformers (ViT), focusing on
sequentially improving the generality of both Decoder and Encoder. Initially,
SEDEG trains an ensembled encoder through feature boosting to learn generalized
representations, which subsequently enhance the decoder's generality and
balance the classifier. The next stage involves using knowledge distillation
(KD) strategies to compress the ensembled encoder and develop a new, more
generalized encoder. This involves using a balanced KD approach and feature KD
for effective knowledge transfer. Extensive experiments on three benchmark
datasets show SEDEG's superior performance, and ablation studies confirm the
efficacy of its components. The code is available at
https://github.com/ShaolingPu/CIL.

</details>


### [132] [Fully Automated Segmentation of Fiber Bundles in Anatomic Tracing Data](https://arxiv.org/abs/2508.12942)
*Kyriaki-Margarita Bintsi,Yaël Balbastre,Jingjing Wu,Julia F. Lehman,Suzanne N. Haber,Anastasia Yendiki*

Main category: cs.CV

TL;DR: 머리말: 본 논문은 마카크(마카크 원숭이) 트레이서 데이터의 섬유 번들 분할을 위해 U-Net 기반의 대형 패치, 전경 인식 샘플링, 준지도 사전학습을 결합한 완전 자동화 프레임워크를 제시한다. Sparse 번들 검출을 20% 이상 개선하고 FDR을 40% 낮추며, 독립 슬라이스 단위 분석을 허용한다.


<details>
  <summary>Details</summary>
Motivation: 해부학적 트레이서 연구는 dMRI 트랙토그래피 검증에 필수적이나, 히스토로지 슬라이드에서 번들 수동 주석은 매우 노동집약적이다. 기존 자동화 방법은 희소 번들을 놓치거나 연속 섹션 간 복잡한 후처리를 요구해 대규모 분석에 제약이 있다.

Method: U-Net 아키텍처에 큰 패치 크기(large patch), 전경(섬유) 중심 샘플링(foreground aware sampling), 및 준지도(semi-supervised) 사전학습을 적용하여 슬라이스 단위의 완전 자동 번들 분할을 수행한다. 별도의 섹션 정렬이나 후처리 없이도 독립 슬라이스에서 동작하도록 설계되었다.

Result: 제안 방법은 단말(terminal)을 번들로 오표시하는 오류를 줄이고, 희소 번들 검출률을 기존보다 20% 이상 향상시키며, False Discovery Rate를 약 40% 감소시켰다고 보고한다. 또한 독립 슬라이스 분석을 통해 대규모 자동화 주석을 가능하게 한다.

Conclusion: 이 프레임워크는 해부학적 트레이서 데이터의 대규모 자동 분석을 촉진하여 dMRI 트랙토그래피 검증을 위한 더 많은 정답(ground-truth) 자료를 생성할 수 있게 해준다. 연구의 적용성 확대 및 반복학습 기반 개선에 기여할 전망이다.

Abstract: Anatomic tracer studies are critical for validating and improving diffusion
MRI (dMRI) tractography. However, large-scale analysis of data from such
studies is hampered by the labor-intensive process of annotating fiber bundles
manually on histological slides. Existing automated methods often miss sparse
bundles or require complex post-processing across consecutive sections,
limiting their flexibility and generalizability. We present a streamlined,
fully automated framework for fiber bundle segmentation in macaque tracer data,
based on a U-Net architecture with large patch sizes, foreground aware
sampling, and semisupervised pre-training. Our approach eliminates common
errors such as mislabeling terminals as bundles, improves detection of sparse
bundles by over 20% and reduces the False Discovery Rate (FDR) by 40% compared
to the state-of-the-art, all while enabling analysis of standalone slices. This
new framework will facilitate the automated analysis of anatomic tracing data
at a large scale, generating more ground-truth data that can be used to
validate and optimize dMRI tractography methods.

</details>


### [133] [Lumen: Consistent Video Relighting and Harmonious Background Replacement with Video Generative Models](https://arxiv.org/abs/2508.12945)
*Jianshu Zeng,Yuxuan Liu,Yutong Feng,Chenxuan Miao,Zixiang Gao,Jiwang Qu,Jianzhang Zhang,Bin Wang,Kun Yuan*

Main category: cs.CV

TL;DR: Lumen은 텍스트 조건으로 배경 교체와 전경의 조명 재조정을 동시에 수행하는 비디오 리라이팅(end-to-end) 프레임워크로, 대규모 합성·실제 비디오쌍 데이터와 도메인 분리 어댑터, 공동 학습 커리큘럼을 통해 시간적 일관성과 전경 보존을 달성한다.


<details>
  <summary>Details</summary>
Motivation: 비디오 리라이팅은 배경 교체와 전경의 조명 재조정을 조화롭게 반영해야 하며, 전경 속성(예: 알베도) 보존과 시간적 일관성 유지가 필수이나, 동일 전경의 다양한 조명 조건을 가진 고품질 페어 데이터가 부족하다.

Method: 대규모 데이터 구성(합성: 3D 렌더링으로 다양한 환경에서 비디오 페어 생성, 실제: HDR 기반 조명 시뮬레이션으로 페어 보완), 합성·실제 도메인의 장점을 끌어내는 공동 학습 커리큘럼 설계, 도메인 인식 어댑터를 모델에 삽입해 리라이팅과 도메인 외형 분포 학습을 분리, 텍스트로 조명·배경 제어 가능한 대규모 비디오 생성기 기반 엔드투엔드 학습.

Result: 종합 벤치마크에서 전경 보존과 비디오 일관성 측면의 평가를 수행했고, 제안한 Lumen이 일관된 조명 재현과 엄격한 전경 보존을 가진 ‘시네마틱’ 리라이트 결과를 보여준다고 보고함.

Conclusion: 합성·실제 데이터를 결합한 대규모 학습과 도메인 인식 모듈로 비디오 리라이팅 성능을 크게 개선했으며, 벤치마크와 실험을 통해 실용적이고 일관된 리라이팅을 달성했으나 시뮬레이션-실제 갭, 복잡한 반사/굴절/강한 그림자 상황 등의 한계가 남아있다.

Abstract: Video relighting is a challenging yet valuable task, aiming to replace the
background in videos while correspondingly adjusting the lighting in the
foreground with harmonious blending. During translation, it is essential to
preserve the original properties of the foreground, e.g., albedo, and propagate
consistent relighting among temporal frames. In this paper, we propose Lumen,
an end-to-end video relighting framework developed on large-scale video
generative models, receiving flexible textual description for instructing the
control of lighting and background. Considering the scarcity of high-qualified
paired videos with the same foreground in various lighting conditions, we
construct a large-scale dataset with a mixture of realistic and synthetic
videos. For the synthetic domain, benefiting from the abundant 3D assets in the
community, we leverage advanced 3D rendering engine to curate video pairs in
diverse environments. For the realistic domain, we adapt a HDR-based lighting
simulation to complement the lack of paired in-the-wild videos. Powered by the
aforementioned dataset, we design a joint training curriculum to effectively
unleash the strengths of each domain, i.e., the physical consistency in
synthetic videos, and the generalized domain distribution in realistic videos.
To implement this, we inject a domain-aware adapter into the model to decouple
the learning of relighting and domain appearance distribution. We construct a
comprehensive benchmark to evaluate Lumen together with existing methods, from
the perspectives of foreground preservation and video consistency assessment.
Experimental results demonstrate that Lumen effectively edit the input into
cinematic relighted videos with consistent lighting and strict foreground
preservation. Our project page: https://lumen-relight.github.io/

</details>


### [134] [MaskSem: Semantic-Guided Masking for Learning 3D Hybrid High-Order Motion Representation](https://arxiv.org/abs/2508.12948)
*Wei Wei,Shaojie Zhang,Yonghao Dang,Jianqin Yin*

Main category: cs.CV

TL;DR: Introduce MaskSem, a semantic-guided masking method for self-supervised 3D skeleton action recognition that uses Grad-CAM on relative motion to select informative joints to mask and reconstructs hybrid high-order motion (velocity + acceleration) with a transformer backbone, improving performance on NTU60/120 and PKU-MMD.


<details>
  <summary>Details</summary>
Motivation: Existing mask-based self-supervised skeleton models focus on limited joints and low-order motion, which restricts learning of complex motion patterns needed for robust action understanding in human-robot collaboration.

Method: MaskSem uses Grad-CAM computed from relative motion signals to identify semantically rich joints/timesteps for masking, encouraging the model to attend discriminative regions. The reconstruction target is hybrid high-order motion combining low-order (velocity) and high-order (acceleration) signals. A vanilla transformer encoder-decoder learns to reconstruct masked motion, promoting multi-order temporal representations.

Result: On NTU60, NTU120, and PKU-MMD datasets, MaskSem combined with a vanilla transformer yields improved skeleton-based action recognition accuracy compared to baseline mask-reconstruction methods (exact numbers not provided in abstract).

Conclusion: Semantic-guided masking plus hybrid high-order reconstruction enhances self-supervised skeleton representation learning, leading to better action recognition and potential benefits for human-robot interaction scenarios.

Abstract: Human action recognition is a crucial task for intelligent robotics,
particularly within the context of human-robot collaboration research. In
self-supervised skeleton-based action recognition, the mask-based
reconstruction paradigm learns the spatial structure and motion patterns of the
skeleton by masking joints and reconstructing the target from unlabeled data.
However, existing methods focus on a limited set of joints and low-order motion
patterns, limiting the model's ability to understand complex motion patterns.
To address this issue, we introduce MaskSem, a novel semantic-guided masking
method for learning 3D hybrid high-order motion representations. This novel
framework leverages Grad-CAM based on relative motion to guide the masking of
joints, which can be represented as the most semantically rich temporal
orgions. The semantic-guided masking process can encourage the model to explore
more discriminative features. Furthermore, we propose using hybrid high-order
motion as the reconstruction target, enabling the model to learn multi-order
motion patterns. Specifically, low-order motion velocity and high-order motion
acceleration are used together as the reconstruction target. This approach
offers a more comprehensive description of the dynamic motion process,
enhancing the model's understanding of motion patterns. Experiments on the
NTU60, NTU120, and PKU-MMD datasets show that MaskSem, combined with a vanilla
transformer, improves skeleton-based action recognition, making it more
suitable for applications in human-robot interaction.

</details>


### [135] [Breaking Reward Collapse: Adaptive Reinforcement for Open-ended Medical Reasoning with Enhanced Semantic Discrimination](https://arxiv.org/abs/2508.12957)
*Yizhou Liu,Jingwei Wei,Zizhi Chen,Minghao Han,Xukun Zhang,Keliang Liu,Lihua Zhang*

Main category: cs.CV

TL;DR: 제안된 ARMed는 의료 오픈엔디드 VQA를 위해 체인-오브-생각(SFT)과 적응형 의미 보상(semantic reward)을 결합한 강화학습 프레임워크로, 보상 분별력을 개선하여 임상 추론 성능과 일반화 능력을 크게 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 의료 영상에서 RL 기반 규칙 보상은 VLM/LLM의 추론·일반화 능력을 높이지만, 기존 연구는 주로 폐쇠형 VQA에 한정되어 실제 임상 추론을 반영하는 개방형 VQA에는 적용이 부족하다. 또한 의미 기반 보상이 보상 붕괴(reward collapse)를 겪어 서로 다른 응답에 유사한 점수를 부여하는 문제가 관찰된다.

Method: ARMed는 먼저 체인-오브-생각 데이터로 SFT(지도 미세조정)를 수행해 도메인 지식을 주입하고, 이후 텍스트 정답성(textual correctness)과 적응형 의미 보상(adaptive semantic rewards)을 결합한 강화학습으로 추론 품질을 향상시킨다. 의미 보상은 보상 분별력을 유지하도록 적응적으로 조정된다.

Result: 6개 의료 VQA 벤치마크에서 평가해 인도메인 과제에서 평균 32.64% 향상, 도메인 외 벤치마크에서 11.65% 증가를 달성했고, 정확도와 일반화가 일관되게 개선되었다.

Conclusion: 의료 RL에서 보상 분별력(reward discriminability)이 성능에 결정적이며, 적응형 의미 보상을 포함한 세만틱 가이드 보상은 견고하고 임상적으로 의미있는 다중모달 추론을 가능하게 한다.

Abstract: Reinforcement learning (RL) with rule-based rewards has demonstrated strong
potential in enhancing the reasoning and generalization capabilities of
vision-language models (VLMs) and large language models (LLMs), while reducing
computational overhead. However, its application in medical imaging remains
underexplored. Existing reinforcement fine-tuning (RFT) approaches in this
domain primarily target closed-ended visual question answering (VQA), limiting
their applicability to real-world clinical reasoning. In contrast, open-ended
medical VQA better reflects clinical practice but has received limited
attention. While some efforts have sought to unify both formats via
semantically guided RL, we observe that model-based semantic rewards often
suffer from reward collapse, where responses with significant semantic
differences receive similar scores. To address this, we propose ARMed (Adaptive
Reinforcement for Medical Reasoning), a novel RL framework for open-ended
medical VQA. ARMed first incorporates domain knowledge through supervised
fine-tuning (SFT) on chain-of-thought data, then applies reinforcement learning
with textual correctness and adaptive semantic rewards to enhance reasoning
quality. We evaluate ARMed on six challenging medical VQA benchmarks. Results
show that ARMed consistently boosts both accuracy and generalization, achieving
a 32.64% improvement on in-domain tasks and an 11.65% gain on out-of-domain
benchmarks. These results highlight the critical role of reward
discriminability in medical RL and the promise of semantically guided rewards
for enabling robust and clinically meaningful multimodal reasoning.

</details>


### [136] [Multi-Phase Automated Segmentation of Dental Structures in CBCT Using a Lightweight Auto3DSeg and SegResNet Implementation](https://arxiv.org/abs/2508.12962)
*Dominic LaBella,Keshav Jha,Jared Robbins,Esther Yu*

Main category: cs.CV

TL;DR: MONAI Auto3DSeg(3D SegResNet)을 사용해 63개 CBCT로 5-폴드 학습, 0.6 mm 재샘플링·강도 클리핑, 5-폴드 예측을 Multi-Label STAPLE로 앙상블, Phase1으로 턱뼈(mandible) 세그먼트하고 이를 바탕으로 Phase2에서 작은 신경 구조를 타이트 크롭해 추가 세그먼트. 검증에서 평균 Dice 0.87 달성.


<details>
  <summary>Details</summary>
Motivation: 치과·두경부 방사선종양학에서 CBCT 자동 다중 클래스 치아·구조 분할은 병변 탐지·치료계획을 빠르고 일관되게 지원해 임상 효율성과 안전성을 높임.

Method: MONAI Auto3DSeg의 3D SegResNet을 5-폴드 CV로 학습. 입력은 0.6 mm 등방성으로 재샘플링하고 강도 클리핑. 5-폴드 예측을 Multi-Label STAPLE로 융합해 Phase1 분할을 얻고, mandible을 기준으로 타이트 크롭하여 작은 신경 구조를 별도(Phase2)로 세분화.

Result: ToothFairy3 챌린지 외부 검증 세트에서 평균 Dice 0.87 보고. 파이프라인은 앙상블과 크롭을 통해 작은 구조(nerve) 분할 성능을 개선하도록 설계됨.

Conclusion: 실용적인 파이프라인으로 제한된 데이터에서 안정적 결과를 보였지만 데이터 크기·클래스 불균형·금속 아티팩트·일반화 등 추가 검증과 개선 여지가 있음.

Abstract: Cone-beam computed tomography (CBCT) has become an invaluable imaging
modality in dentistry, enabling 3D visualization of teeth and surrounding
structures for diagnosis and treatment planning. Automated segmentation of
dental structures in CBCT can efficiently assist in identifying pathology
(e.g., pulpal or periapical lesions) and facilitate radiation therapy planning
in head and neck cancer patients. We describe the DLaBella29 team's approach
for the MICCAI 2025 ToothFairy3 Challenge, which involves a deep learning
pipeline for multi-class tooth segmentation. We utilized the MONAI Auto3DSeg
framework with a 3D SegResNet architecture, trained on a subset of the
ToothFairy3 dataset (63 CBCT scans) with 5-fold cross-validation. Key
preprocessing steps included image resampling to 0.6 mm isotropic resolution
and intensity clipping. We applied an ensemble fusion using Multi-Label STAPLE
on the 5-fold predictions to infer a Phase 1 segmentation and then conducted
tight cropping around the easily segmented Phase 1 mandible to perform Phase 2
segmentation on the smaller nerve structures. Our method achieved an average
Dice of 0.87 on the ToothFairy3 challenge out-of-sample validation set. This
paper details the clinical context, data preparation, model development,
results of our approach, and discusses the relevance of automated dental
segmentation for improving patient care in radiation oncology.

</details>


### [137] [GazeDETR: Gaze Detection using Disentangled Head and Gaze Representations](https://arxiv.org/abs/2508.12966)
*Ryan Anthony Jalova de Belen,Gelareh Mohammadi,Arcot Sowmya*

Main category: cs.CV

TL;DR: GazeDETR은 헤드 위치 탐지와 시선 대상 예측을 분리된 두 디코더로 처리하는 end-to-end DETR 계열 아키텍처로, 표현의 얽힘을 줄여 GazeFollow, VideoAttentionTarget, ChildPlay 데이터셋에서 기존 end-to-end 모델을 능가하는 SOTA 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 기존 단일 디코더 멀티태스크 접근은 헤드 로컬라이제이션과 시선 위치 예측을 하나의 통합 표현으로 학습해 두 하위과제 간 표현 충돌과 성능 저하를 초래할 수 있다. 시선 예측에는 전역 문맥이, 헤드 탐지는 국소 정보가 중요하므로 두 작업을 분리해 각자에 적합한 주의 영역을 학습할 필요가 있다.

Method: DETR 기반 end-to-end 프레임워크에 두 개의 분리된 디코더를 도입. 헤드 디코더는 주로 로컬 정보에 관여하는 주의 필드를 학습하고, 시선 디코더는 로컬과 전역 정보를 모두 통합하는 주의 메커니즘을 사용해 각 작업에 특화된 표현을 획득한다. 각 디코더는 독립적인 예측 헤드(예: 머리 바운딩박스/점과 시선 점/히트맵)를 출력한다.

Result: 제안 모델이 GazeFollow, VideoAttentionTarget, ChildPlay에서 기존 end-to-end 모델들보다 유의미한 성능 향상을 달성하고 SOTA를 갱신함. 추가 분석으로 헤드 디코더는 로컬 정보를, 시선 디코더는 전역 정보를 더 많이 활용함을 보임.

Conclusion: 디코더 분리를 통한 표현 분리 전략은 멀티태스크 시선 예측 문제에서 효과적이며, 제안 아키텍처는 실제 응용(휴먼-컴퓨터 상호작용, 디지털 표현형 분석 등)에 유용하다. 향후 일반화, 효율성(계산 비용), 약한 레이블 환경 및 시계열 모델링 검증이 필요하다.

Abstract: Gaze communication plays a crucial role in daily social interactions.
Quantifying this behavior can help in human-computer interaction and digital
phenotyping. While end-to-end models exist for gaze target detection, they only
utilize a single decoder to simultaneously localize human heads and predict
their corresponding gaze (e.g., 2D points or heatmap) in a scene. This
multitask learning approach generates a unified and entangled representation
for human head localization and gaze location prediction. Herein, we propose
GazeDETR, a novel end-to-end architecture with two disentangled decoders that
individually learn unique representations and effectively utilize coherent
attentive fields for each subtask. More specifically, we demonstrate that its
human head predictor utilizes local information, while its gaze decoder
incorporates both local and global information. Our proposed architecture
achieves state-of-the-art results on the GazeFollow, VideoAttentionTarget and
ChildPlay datasets. It outperforms existing end-to-end models with a notable
margin.

</details>


### [138] [Compact Attention: Exploiting Structured Spatio-Temporal Sparsity for Fast Video Generation](https://arxiv.org/abs/2508.12969)
*Qirui Li,Guangcong Zheng,Qi Zhao,Jie Li,Bin Dong,Yiwu Yao,Xi Li*

Main category: cs.CV

TL;DR: 비디오 디퓨전 트랜스포머의 어텐션은 다양한 구조적 희소성을 갖고 있으며, 이를 하드웨어 친화적으로 가속하는 Compact Attention을 제안한다. 적응형 타일링, 시간별 윈도우 조정, 자동 구성 검색으로 GPU에서 어텐션 계산을 1.6~2.5배 가속하면서 시각 품질을 유지한다.


<details>
  <summary>Details</summary>
Motivation: 초장기 비디오 합성에서 트랜스포머의 자기어텐션 계산 비용이 병목이 되며, 기존의 고정 희소패턴이나 분해된 어텐션은 비디오의 시공간 중복성을 충분히 활용하지 못함.

Method: 세 가지 핵심 기술: 1) 동적 타일 그룹화를 통한 적응형 타일링으로 다양한 공간 상호작용 패턴을 근사, 2) 프레임 간 근접성에 따라 희소성 수준을 조정하는 시간 가변 윈도우 적용, 3) 중요한 어텐션 경로를 보존하면서 희소 패턴을 최적화하는 자동 구성 검색 알고리즘.

Result: 단일 GPU 환경에서 어텐션 계산을 1.6~2.5배 가속했고, 전체 어텐션 기준선과 유사한 시각 품질을 유지함.

Conclusion: 구조화된 희소성을 활용하면 하드웨어 친화적 방식으로 초장기 비디오 생성의 어텐션 병목을 효과적으로 완화할 수 있으며, Compact Attention은 실용적인 가속안과 자동 최적화 도구를 제시함.

Abstract: The computational demands of self-attention mechanisms pose a critical
challenge for transformer-based video generation, particularly in synthesizing
ultra-long sequences. Current approaches, such as factorized attention and
fixed sparse patterns, fail to fully exploit the inherent spatio-temporal
redundancies in video data. Through systematic analysis of video diffusion
transformers (DiT), we uncover a key insight: Attention matrices exhibit
structured, yet heterogeneous sparsity patterns, where specialized heads
dynamically attend to distinct spatiotemporal regions (e.g., local pattern,
cross-shaped pattern, or global pattern). Existing sparse attention methods
either impose rigid constraints or introduce significant overhead, limiting
their effectiveness. To address this, we propose Compact Attention, a
hardware-aware acceleration framework featuring three innovations: 1) Adaptive
tiling strategies that approximate diverse spatial interaction patterns via
dynamic tile grouping, 2) Temporally varying windows that adjust sparsity
levels based on frame proximity, and 3) An automated configuration search
algorithm that optimizes sparse patterns while preserving critical attention
pathways. Our method achieves 1.6~2.5x acceleration in attention computation on
single-GPU setups while maintaining comparable visual quality with
full-attention baselines. This work provides a principled approach to unlocking
efficient long-form video generation through structured sparsity exploitation.
Project Page: https://yo-ava.github.io/Compact-Attention.github.io/

</details>


### [139] [Dextr: Zero-Shot Neural Architecture Search with Singular Value Decomposition and Extrinsic Curvature](https://arxiv.org/abs/2508.12977)
*Rohan Asthana,Joschua Conrad,Maurits Ortmanns,Vasileios Belagiannis*

Main category: cs.CV

TL;DR: 레이블 없는(single-sample) 데이터만으로 네트워크 초기화 시점의 특징(SVD 기반 컬리니어리티)과 출력의 외적 곡률을 결합해 네트워크 성능을 예측하는 제로-코스트 NAS 프록시를 제안한다. 이 프록시는 수렴성·일반화·표현력을 통합하며 여러 NAS 벤치마크에서 높은 상관도를 보였다.


<details>
  <summary>Details</summary>
Motivation: 기존 제로-코스트 프록시들은 레이블 데이터가 필요하거나(실무에서 불가) 수렴성·일반화와 표현력 중 일부 속성만 고려해 아키텍처 평가에서 한계가 있다. 채널 컬리니어리티가 수렴·일반화에 미치는 영향을 규명하고 이를 반영한 라벨 프리 프록시가 필요하다.

Method: 단일 레이블-프리 샘플로 각 레이어의 피처에 대해 SVD를 수행해 피처 조건수(채널 컬리니어리티 관련)를 평가하고, 네트워크 출력의 외적(curvature) 정보를 계산한다. 두 구성요소(피처 조건수의 역합과 외적 곡률)의 로그값을 단순 조화평균으로 결합한 스코어를 제안한다.

Result: 제안 프록시는 NAS-Bench-101/201, TransNAS-Bench-101-micro 및 DARTS·AutoFormer 검색공간에서 높은 상관관계와 효율성을 보였다. 단일 라벨-프리 샘플로도 테스트 성능을 정확히 예측할 수 있다고 주장한다.

Conclusion: 채널 컬리니어리티와 출력 곡률을 결합한 라벨-프리 제로-코스트 프록시는 NAS에서 수렴성·일반화·표현력을 동시에 고려하는 실용적이고 효율적인 평가 지표가 될 수 있다.

Abstract: Zero-shot Neural Architecture Search (NAS) typically optimises the
architecture search process by exploiting the network or gradient properties at
initialisation through zero-cost proxies. The existing proxies often rely on
labelled data, which is usually unavailable in real-world settings.
Furthermore, the majority of the current methods focus either on optimising the
convergence and generalisation attributes or solely on the expressivity of the
network architectures. To address both limitations, we first demonstrate how
channel collinearity affects the convergence and generalisation properties of a
neural network. Then, by incorporating the convergence, generalisation and
expressivity in one approach, we propose a zero-cost proxy that omits the
requirement of labelled data for its computation. In particular, we leverage
the Singular Value Decomposition (SVD) of the neural network layer features and
the extrinsic curvature of the network output to design our proxy. %As a
result, the proposed proxy is formulated as the simplified harmonic mean of the
logarithms of two key components: the sum of the inverse of the feature
condition number and the extrinsic curvature of the network output. Our
approach enables accurate prediction of network performance on test data using
only a single label-free data sample. Our extensive evaluation includes a total
of six experiments, including the Convolutional Neural Network (CNN) search
space, i.e. DARTS and the Transformer search space, i.e. AutoFormer. The
proposed proxy demonstrates a superior performance on multiple correlation
benchmarks, including NAS-Bench-101, NAS-Bench-201, and
TransNAS-Bench-101-micro; as well as on the NAS task within the DARTS and the
AutoFormer search space, all while being notably efficient. The code is
available at https://github.com/rohanasthana/Dextr.

</details>


### [140] [Omni Survey for Multimodality Analysis in Visual Object Tracking](https://arxiv.org/abs/2508.13000)
*Zhangyong Tang,Tianyang Xu,Xuefeng Zhu,Hui Li,Shaochuan Zhao,Tao Zhou,Chunyang Cheng,Xiaojun Wu,Josef Kittler*

Main category: cs.CV

TL;DR: 이 논문은 스마트시티 환경에서의 다중모달 시각 객체추적(MMVOT)을 데이터 수집·정렬·모델 설계·평가 관점에서 종합적으로 정리한 서베이로, 6개 태스크와 338개 참고문헌을 아우른다.


<details>
  <summary>Details</summary>
Motivation: 스마트시티에서 다양한 센서로 생성되는 대규모 다중모달 데이터에 대해 단일모달 추적의 한계를 보완하고, 모달 간 융합·정합·주석 문제를 체계화하여 MMVOT 연구의 전반적 현황과 과제를 정리하려는 목적.

Method: RGB와 보조 X(열·깊이·이벤트·NIR·언어·소나 등)를 다루는 방법론들을 ‘복제/비복제 실험 설정’ 관점으로 분류하고, 데이터 모달리티별 설명, 수집·정렬·주석의 난제, 모델 카테고리화, 평가·벤치마크 문제를 체계적으로 정리.

Result: 338개 참고문헌을 기반으로 6개 MMVOT 태스크를 검토하고, 기존 데이터셋의 객체 카테고리 분포가 롱테일을 보이며 동물 카테고리가 상대적으로 부족하다는 정량적 분석 결과를 제시.

Conclusion: MMVOT는 항상 단일모달 보다 우월하지 않으며, 모달 품질·정렬·비용·특정 시나리오에 따라 유리성이 달라짐을 논의하고, 데이터·평가·설계 측면의 향후 연구 방향을 제안한다.

Abstract: The development of smart cities has led to the generation of massive amounts
of multi-modal data in the context of a range of tasks that enable a
comprehensive monitoring of the smart city infrastructure and services. This
paper surveys one of the most critical tasks, multi-modal visual object
tracking (MMVOT), from the perspective of multimodality analysis. Generally,
MMVOT differs from single-modal tracking in four key aspects, data collection,
modality alignment and annotation, model designing, and evaluation.
Accordingly, we begin with an introduction to the relevant data modalities,
laying the groundwork for their integration. This naturally leads to a
discussion of challenges of multi-modal data collection, alignment, and
annotation. Subsequently, existing MMVOT methods are categorised, based on
different ways to deal with visible (RGB) and X modalities: programming the
auxiliary X branch with replicated or non-replicated experimental
configurations from the RGB branch. Here X can be thermal infrared (T), depth
(D), event (E), near infrared (NIR), language (L), or sonar (S). The final part
of the paper addresses evaluation and benchmarking. In summary, we undertake an
omni survey of all aspects of multi-modal visual object tracking (VOT),
covering six MMVOT tasks and featuring 338 references in total. In addition, we
discuss the fundamental rhetorical question: Is multi-modal tracking always
guaranteed to provide a superior solution to unimodal tracking with the help of
information fusion, and if not, in what circumstances its application is
beneficial. Furthermore, for the first time in this field, we analyse the
distributions of the object categories in the existing MMVOT datasets,
revealing their pronounced long-tail nature and a noticeable lack of animal
categories when compared with RGB datasets.

</details>


### [141] [Empirical Evidences for the Effects of Feature Diversity in Open Set Recognition and Continual Learning](https://arxiv.org/abs/2508.13005)
*Jiawen Xu,Odej Kao*

Main category: cs.CV

TL;DR: 이 논문은 특징 다양성(feature diversity)을 인위적으로 높이면 오픈셋 인식(Open Set Recognition) 성능과 연속 학습(Continual Learning)의 유지 및 새로운 클래스 통합 능력이 실질적으로 향상된다는 실증적 증거를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 오픈셋 인식은 추론 시 미지 클래스 식별을, 연속 학습은 새로운 클래스를 잊지 않고 통합하는 문제를 다룬다. 기존 연구들은 주로 휴리스틱하게 특징 다양성을 촉진해왔으나, 다양성이 두 문제 해결에 실제로 어떤 역할을 하는지는 명확히 규명되지 않았다.

Method: 다양성 수준을 조절하거나 다양성 촉진 기법을 적용해 여러 데이터셋과 기준에서 실험을 수행하고, 다양성 지표와 오픈셋 탐지 성능 및 연속학습 시 기억(remembering)·통합(forgetting/learning) 지표 간의 상관관계를 분석한다. 다양한 베이스라인 및 규제기법과 비교 평가한다.

Result: 특징 다양성이 증가하면 오픈셋 샘플의 식별 능력이 개선되고, 연속학습에서는 과거 데이터의 유지(망각 감소)와 신규 데이터의 통합이 용이해진다는 일관된 향상을 관측했다. 정량적 개선과 함께 몇몇 실험에서 다양성 촉진 기법이 기존 방법을 능가했다.

Conclusion: 특징 다양성은 오픈셋 인식과 연속학습 모두에서 중요한 조절 변수로 작용하며, 이를 활용한 실용적 방법 개발과 이론적 분석이 향후 연구에 유망한 방향임을 시사한다.

Abstract: Open set recognition (OSR) and continual learning are two critical challenges
in machine learning, focusing respectively on detecting novel classes at
inference time and updating models to incorporate the new classes. While many
recent approaches have addressed these problems, particularly OSR, by
heuristically promoting feature diversity, few studies have directly examined
the role that feature diversity plays in tackling them. In this work, we
provide empirical evidence that enhancing feature diversity improves the
recognition of open set samples. Moreover, increased feature diversity also
facilitates both the retention of previously learned data and the integration
of new data in continual learning. We hope our findings can inspire further
research into both practical methods and theoretical understanding in these
domains.

</details>


### [142] [SlimComm: Doppler-Guided Sparse Queries for Bandwidth-Efficient Cooperative 3-D Perception](https://arxiv.org/abs/2508.13007)
*Melih Yazgan,Qiyuan Wu,Iramm Hamdard,Shiqi Li,J. Marius Zoellner*

Main category: cs.CV

TL;DR: SlimComm는 4D 레이더 도플러와 쿼리 기반 희소 전송으로 BEV 피처 전송량을 최대 90% 줄이면서 동적 객체 중심의 쿼리만 교환해 협업 지각 성능을 유지하거나 향상시키는 통신 효율적 CAV 협업 프레임워크다.


<details>
  <summary>Details</summary>
Motivation: 전체 BEV 맵 공유는 대역폭을 포화시켜 현실적 제약이 크므로, 움직임 정보(도플러)를 활용해 통신할 피처를 선택·압축함으로써 대역폭을 절약하면서도 가려진(occluded) 영역을 보완하려는 목적.

Method: (1) 4D 레이더 도플러로 동적-정적 영역을 구분하는 모션 중심 맵을 생성, (2) 동적·고신뢰 영역에 대한 reference 쿼리와 가려진 영역을 탐색하는 exploratory 쿼리(2단계 오프셋)를 생성, (3) 쿼리별 BEV 피처만 교환하고 멀티스케일 게이티드 디폼러블 어텐션으로 융합하여 페이로드 감소와 정보 보존을 달성.

Result: CARLA 기반의 OPV2V-R 및 Adver-City-R 데이터셋(포인트 도플러 포함)에서 전체 맵 전송 대비 최대 90% 통신량 절감, 다양한 교통 밀도와 가려짐 상황에서 기존 기준선들과 동등하거나 우수한 성능을 보고.

Conclusion: 도플러 기반 모션 정보와 쿼리 기반 희소 전송을 결합하면 협업 지각에서 통신 비용을 크게 줄이면서 성능을 유지할 수 있으며, 공개 데이터셋과 코드로 재현 가능성을 제공함.

Abstract: Collaborative perception allows connected autonomous vehicles (CAVs) to
overcome occlusion and limited sensor range by sharing intermediate features.
Yet transmitting dense Bird's-Eye-View (BEV) feature maps can overwhelm the
bandwidth available for inter-vehicle communication. We present SlimComm, a
communication-efficient framework that integrates 4D radar Doppler with a
query-driven sparse scheme. SlimComm builds a motion-centric dynamic map to
distinguish moving from static objects and generates two query types: (i)
reference queries on dynamic and high-confidence regions, and (ii) exploratory
queries probing occluded areas via a two-stage offset. Only query-specific BEV
features are exchanged and fused through multi-scale gated deformable
attention, reducing payload while preserving accuracy. For evaluation, we
release OPV2V-R and Adver-City-R, CARLA-based datasets with per-point Doppler
radar. SlimComm achieves up to 90% lower bandwidth than full-map sharing while
matching or surpassing prior baselines across varied traffic densities and
occlusions. Dataset and code will be available at: https://url.fzi.de/SlimComm.

</details>


### [143] [Matrix-Game 2.0: An Open-Source, Real-Time, and Streaming Interactive World Model](https://arxiv.org/abs/2508.13009)
*Xianglong He,Chunli Peng,Zexiang Liu,Boyang Wang,Yifan Zhang,Qi Cui,Fei Kang,Biao Jiang,Mengyin An,Yangyang Ren,Baixin Xu,Hao-Xiang Guo,Kaixiong Gong,Cyrus Wu,Wei Li,Xuchen Song,Yang Liu,Eric Li,Yahui Zhou*

Main category: cs.CV

TL;DR: Matrix-Game 2.0은 프레임 단위 액션 조건을 받아 몇 단계의 자기회귀 확산(few-step autoregressive diffusion)으로 실시간(25 FPS) 분 단위 비디오를 생성하는 인터랙티브 월드 모델이다. 대규모 Unreal/GTA5 데이터(약 1200시간)와 액션 주입 모듈, 인과적 구조의 몇-스텝 증류를 결합해 기존 모델의 느린 추론·양방향 어텐션 문제를 해결한다.


<details>
  <summary>Details</summary>
Motivation: 기존 인터랙티브 월드 모델은 양방향 어텐션과 긴 추론 단계에 의존해 실시간 업데이트가 어려워 실제 환경에서 즉각적으로 과거 문맥과 현재 행동에 따라 결과를 생성해야 하는 요구를 충족하지 못한다.

Method: (1) Unreal Engine과 GTA5를 이용한 대규모 데이터 생산 파이프라인(약 1200시간, 상호작용 주석 포함), (2) 프레임 단위 마우스·키보드 입력을 조건으로 주입하는 액션 인젝션 모듈, (3) 인과적(causal) 아키텍처 기반의 few-step 증류를 통한 초저지연 자기회귀 확산 생성.

Result: 다양한 장면에서 고화질 분 단위 비디오를 초고속으로(25 FPS) 생성할 수 있으며, 모델 가중치와 코드베이스를 공개했다.

Conclusion: Matrix-Game 2.0은 대규모 합성 데이터와 액션 조건·인과적 증류를 결합해 실시간 상호작용 세계 모델링의 속도와 연속성을 크게 개선, 실제 환경 시뮬레이션 및 관련 연구에 유용한 기반을 제공한다.

Abstract: Recent advances in interactive video generations have demonstrated diffusion
model's potential as world models by capturing complex physical dynamics and
interactive behaviors. However, existing interactive world models depend on
bidirectional attention and lengthy inference steps, severely limiting
real-time performance. Consequently, they are hard to simulate real-world
dynamics, where outcomes must update instantaneously based on historical
context and current actions. To address this, we present Matrix-Game 2.0, an
interactive world model generates long videos on-the-fly via few-step
auto-regressive diffusion. Our framework consists of three key components: (1)
A scalable data production pipeline for Unreal Engine and GTA5 environments to
effectively produce massive amounts (about 1200 hours) of video data with
diverse interaction annotations; (2) An action injection module that enables
frame-level mouse and keyboard inputs as interactive conditions; (3) A few-step
distillation based on the casual architecture for real-time and streaming video
generation. Matrix Game 2.0 can generate high-quality minute-level videos
across diverse scenes at an ultra-fast speed of 25 FPS. We open-source our
model weights and codebase to advance research in interactive world modeling.

</details>


### [144] [EgoTwin: Dreaming Body and View in First Person](https://arxiv.org/abs/2508.13013)
*Jingqiao Xiu,Fangzhou Hong,Yicong Li,Mengze Li,Wentao Wang,Sirui Han,Liang Pan,Ziwei Liu*

Main category: cs.CV

TL;DR: Introduce EgoTwin: a diffusion-transformer framework that jointly generates egocentric video and human motion using a head-centric motion representation and cybernetics-inspired attention to align camera/head trajectories and enforce causal video-motion interplay.


<details>
  <summary>Details</summary>
Motivation: Existing work focuses on exocentric video synthesis; egocentric generation needs to model first-person visuals and camera motion tied to wearer’s body. A joint generation of video and human motion is needed to ensure consistent, causally aligned outputs.

Method: EgoTwin uses a diffusion transformer backbone, encodes motion in a head-centric coordinate anchored to the head joint, and integrates a cybernetics-inspired interaction mechanism inside attention to model causal interplay between adjacent frames and motion. It jointly conditions video and motion synthesis, and trains on synchronized text–video–motion triplets.

Result: They curate a large-scale real-world dataset of synchronized triplets and design new metrics for video-motion consistency. Experiments show EgoTwin produces better aligned camera trajectories and causally consistent human motions compared to baselines, demonstrating improved video-motion consistency.

Conclusion: EgoTwin effectively addresses viewpoint alignment and causal interplay for joint egocentric video and motion generation; head-centric representation and interaction in attention are key. The dataset and metrics enable comprehensive evaluation and future research.

Abstract: While exocentric video synthesis has achieved great progress, egocentric
video generation remains largely underexplored, which requires modeling
first-person view content along with camera motion patterns induced by the
wearer's body movements. To bridge this gap, we introduce a novel task of joint
egocentric video and human motion generation, characterized by two key
challenges: 1) Viewpoint Alignment: the camera trajectory in the generated
video must accurately align with the head trajectory derived from human motion;
2) Causal Interplay: the synthesized human motion must causally align with the
observed visual dynamics across adjacent video frames. To address these
challenges, we propose EgoTwin, a joint video-motion generation framework built
on the diffusion transformer architecture. Specifically, EgoTwin introduces a
head-centric motion representation that anchors the human motion to the head
joint and incorporates a cybernetics-inspired interaction mechanism that
explicitly captures the causal interplay between video and motion within
attention operations. For comprehensive evaluation, we curate a large-scale
real-world dataset of synchronized text-video-motion triplets and design novel
metrics to assess video-motion consistency. Extensive experiments demonstrate
the effectiveness of the EgoTwin framework.

</details>


### [145] [HierAdaptMR: Cross-Center Cardiac MRI Reconstruction with Hierarchical Feature Adapters](https://arxiv.org/abs/2508.13026)
*Ruru Xu,Ilkay Oksuz*

Main category: cs.CV

TL;DR: HierAdaptMR은 프로토콜 수준과 센터(스캐너) 수준의 파라미터 효율적 어댑터를 계층적으로 도입해 다중 센터·다중 스캐너 환경에서 심장 MRI 재구성의 도메인 쉬프트를 완화하는 프레임워크다. 변분 언롤링 백본 위에 프로토콜-어댑터, 센터-어댑터, 그리고 미지 센터 일반화를 위한 유니버설 어댑터를 구성하며, 주파수 강조와 대비 적응 가중치를 포함한 다중 스케일 SSIM 손실로 학습한다.


<details>
  <summary>Details</summary>
Motivation: 심장 MRI 재구성 모델은 센터별 스캐너, 시퀀스, 프로토콜 차이로 인해 도메인 쉬프트 문제가 심각하며, 모든 센터별로 모델을 재학습하거나 큰 네트워크를 유지하는 것은 비용과 데이터 제한 때문에 현실적이지 않다. 따라서 파라미터 효율적이고 계층적 적응 메커니즘으로 다양한 수준의 변이를 처리할 필요가 있다.

Method: 변분 언롤링 백본을 사용하고, 시퀀스(프로토콜) 특성 적응을 위한 Protocol-Level Adapter와 스캐너/센터 특성 적응을 위한 Center-Level Adapter를 계층적으로 추가한다. 미지의 센터에 대해선 확률적(스토캐스틱) 학습을 통해 센터 불변 표현을 학습하는 Universal Adapter를 도입한다. 손실은 다중 스케일 SSIM에 주파수 도메인 강조와 대비 적응 가중치를 결합해 최적화의 강인성을 높인다.

Result: CMRxRecon2025 데이터셋(5+ 센터, 10+ 스캐너, 9 모달리티)에서 평가해 크로스-센터 일반화 성능이 개선되었으며 재구성 품질을 유지 또는 향상시켰다고 보고한다. 코드 공개로 재현 가능성을 제공한다.

Conclusion: 계층적 어댑터 설계와 손실 개선을 통해 다중 센터·스캐너 환경에서 효율적으로 도메인 적응을 달성하며, 파라미터 효율성과 미지 센터 일반화 측면에서 실용적 기여를 한다.

Abstract: Deep learning-based cardiac MRI reconstruction faces significant domain shift
challenges when deployed across multiple clinical centers with heterogeneous
scanner configurations and imaging protocols. We propose HierAdaptMR, a
hierarchical feature adaptation framework that addresses multi-level domain
variations through parameter-efficient adapters. Our method employs
Protocol-Level Adapters for sequence-specific characteristics and Center-Level
Adapters for scanner-dependent variations, built upon a variational unrolling
backbone. A Universal Adapter enables generalization to entirely unseen centers
through stochastic training that learns center-invariant adaptations. The
framework utilizes multi-scale SSIM loss with frequency domain enhancement and
contrast-adaptive weighting for robust optimization. Comprehensive evaluation
on the CMRxRecon2025 dataset spanning 5+ centers, 10+ scanners, and 9
modalities demonstrates superior cross-center generalization while maintaining
reconstruction quality. code: https://github.com/Ruru-Xu/HierAdaptMR

</details>


### [146] [IntelliCap: Intelligent Guidance for Consistent View Sampling](https://arxiv.org/abs/2508.13043)
*Ayaka Yasunaga,Hideo Saito,Dieter Schmalstieg,Shohei Mori*

Main category: cs.CV

TL;DR: 사람이 촬영하는 입력 이미지의 균일·밀집 샘플링 문제를 해결하기 위해, 시맨틱·비전-랭귀지 모델로 중요 객체를 식별하고 다중 스케일 구형 프록시를 제시하여 스캔 중 사용자를 안내하는 기법을 제안한다. 실장면에서 기존 샘플링보다 우수한 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 최신 뷰 합성(예: 3D Gaussian splatting)은 고품질 렌더링이 가능해졌으나, 이를 위해선 균일하고 밀집한 뷰 샘플링이 필요하다. 일반 사용자가 이러한 샷을 체계적으로 수집하기는 어렵고, 기존 가이드 방식은 단일 객체에 국한되거나 뷰 의존적 재질 특성을 무시한다.

Method: 스캔 도중 시맨틱 분할과 비전-랭귀지 모델을 통해 장면 내 객체들을 식별·우선순위화한다. 우선순위가 높은 객체 주변에 다중 스케일의 구형(스페리컬) 프록시를 생성하여 사용자가 해당 영역에서 더 많은 이미지 커버리지를 얻도록 시각적으로 안내한다.

Result: 실제 장면에서 기존의 획일적 혹은 무작위 뷰 샘플링 전략보다 더 나은 커버리지와 뷰 의존적 외형 재현 성능을 보였다.

Conclusion: 제안된 상황적(현장) 시각화 기반 스캔 가이드는 사용자가 효율적으로 중요한 객체를 촬영하도록 유도해 뷰 의존성 있는 재질을 포함한 고품질 뷰 합성 결과를 얻도록 한다.

Abstract: Novel view synthesis from images, for example, with 3D Gaussian splatting,
has made great progress. Rendering fidelity and speed are now ready even for
demanding virtual reality applications. However, the problem of assisting
humans in collecting the input images for these rendering algorithms has
received much less attention. High-quality view synthesis requires uniform and
dense view sampling. Unfortunately, these requirements are not easily addressed
by human camera operators, who are in a hurry, impatient, or lack understanding
of the scene structure and the photographic process. Existing approaches to
guide humans during image acquisition concentrate on single objects or neglect
view-dependent material characteristics. We propose a novel situated
visualization technique for scanning at multiple scales. During the scanning of
a scene, our method identifies important objects that need extended image
coverage to properly represent view-dependent appearance. To this end, we
leverage semantic segmentation and category identification, ranked by a
vision-language model. Spherical proxies are generated around highly ranked
objects to guide the user during scanning. Our results show superior
performance in real scenes compared to conventional view sampling strategies.

</details>


### [147] [Odo: Depth-Guided Diffusion for Identity-Preserving Body Reshaping](https://arxiv.org/abs/2508.13065)
*Siddharth Khandelwal,Sridhar Kamath,Arjun Jain*

Main category: cs.CV

TL;DR: 새 데이터셋(18,573장, 1523명)을 공개하고, 하나의 입력 이미지에서 의상·배경·포즈·정체성을 유지하면서 신체 형태(마른·근육·비만 등)를 조작하는 확산 기반 방법 Odo를 제안. 고정된 UNet으로 외형과 배경을 보존하고 ControlNet으로 SMPL 깊이 지도를 통해 형태 변형을 유도해, 기준선보다 낮은 평균 정점 오차(7.5mm vs 13.6mm)를 달성.


<details>
  <summary>Details</summary>
Motivation: 기존 신체 형태 편집은 3D 모프 모델이나 이미지 워핑에 의존해 비현실적 비율, 텍스처 왜곡, 배경 불일치 문제를 일으키고, 대규모 공개 데이터셋의 부재로 학습·평가가 제한됨. 이를 해결하기 위해 통제된 대규모 데이터셋과 새로운 모델이 필요함.

Method: 대규모 통제 데이터셋을 수집·구성(다양한 체형, 동일 인물·의상·배경 조건). 모델 Odo는 고정된(동결된) UNet을 사용해 입력 이미지의 세부 외형과 배경을 보존하고, ControlNet을 추가해 목표 SMPL 깊이 지도(target SMPL depth maps)를 입력으로 형태 변형을 유도하는 확산 모델 엔드투엔드 설계.

Result: 제안한 방법은 기존 방법들보다 우수한 성능을 보임. 정점 재구성 오차가 평균 7.5mm로 기준선의 13.6mm보다 현저히 낮음. 시각적 결과도 목표 체형과 높은 일치성을 보이며 텍스처·배경 보존이 잘 됨.

Conclusion: 통제된 대규모 데이터셋과 확산+ControlNet 기반의 설계로 현실적이고 정밀한 신체 형태 편집이 가능함. 다만 데이터셋 조건(동일 의상·배경 등)과 일반화, 윤리적 측면(신체 이미지 조작)의 고려가 필요하다.

Abstract: Human shape editing enables controllable transformation of a person's body
shape, such as thin, muscular, or overweight, while preserving pose, identity,
clothing, and background. Unlike human pose editing, which has advanced
rapidly, shape editing remains relatively underexplored. Current approaches
typically rely on 3D morphable models or image warping, often introducing
unrealistic body proportions, texture distortions, and background
inconsistencies due to alignment errors and deformations. A key limitation is
the lack of large-scale, publicly available datasets for training and
evaluating body shape manipulation methods. In this work, we introduce the
first large-scale dataset of 18,573 images across 1523 subjects, specifically
designed for controlled human shape editing. It features diverse variations in
body shape, including fat, muscular and thin, captured under consistent
identity, clothing, and background conditions. Using this dataset, we propose
Odo, an end-to-end diffusion-based method that enables realistic and intuitive
body reshaping guided by simple semantic attributes. Our approach combines a
frozen UNet that preserves fine-grained appearance and background details from
the input image with a ControlNet that guides shape transformation using target
SMPL depth maps. Extensive experiments demonstrate that our method outperforms
prior approaches, achieving per-vertex reconstruction errors as low as 7.5mm,
significantly lower than the 13.6mm observed in baseline methods, while
producing realistic results that accurately match the desired target shapes.

</details>


### [148] [Eyes on the Image: Gaze Supervised Multimodal Learning for Chest X-ray Diagnosis and Report Generation](https://arxiv.org/abs/2508.13068)
*Tanjim Islam Riju,Shuchismita Anwar,Saman Sarker Joy,Farig Sadeque,Swakkhar Shatabda*

Main category: cs.CV

TL;DR: MIMIC-Eye의 시선 데이터를 활용한 2단계 다중모달 프레임워크로, 1) 시선-지도 대조학습으로 질병 분류 성능과 해석 가능성 향상, 2) 진단 키워드를 해부학적 영역에 정렬해 리포트 문장 생성. 시선 정보 투입 시 F1·AUC 개선 및 임상 키워드 재현성 증가를 보고함.


<details>
  <summary>Details</summary>
Motivation: 흉부 X선 자동화 시스템의 진단 정확도와 생성 리포트의 지역 정렬(어디에 병변이 있는지)을 동시에 개선하고, 방사선과 전문의의 시선(eye-tracking)을 활용해 모델의 주의(attention)를 인간의 판독 과정과 정렬하려는 목적.

Method: 두 단계: (1) 시선-유도 대조학습: 시선 히트맵(고정점), 바운딩박스, 시각 피쳐, 라벨을 통합하고, MSE, KL, 상관계수, 중심 질량 정렬을 결합한 다중 항목 시선-어텐션 손실을 추가해 임베딩 정렬. (2) 모듈식 리포트 생성: 신뢰도 가중 진단 키워드 추출 → 도메인 사전으로 키워드를 해부학적 영역에 매핑 → 구조화된 프롬프트로 영역 정렬 문장 생성. 평가: 분류(F1, AUC, 정밀·재현) 및 리포트(임상 키워드 재현율, ROUGE).

Result: 시선 정보 추가로 F1 0.597→0.631(+5.7%), AUC 0.821→0.849(+3.41%), 정밀도·재현율 향상. 리포트 품질은 임상 키워드 재현 및 ROUGE 향상 보고. 시선 데이터가 분류 성능 및 생성 리포트의 해석 가능성 개선에 기여.

Conclusion: 방사선과 전문의의 시선 데이터를 대조학습과 어텐션 감독에 활용하면 흉부 X선 질병 분류 성능과 리포트의 지역 정렬·임상 관련성 모두 개선 가능. 다만 일반화성·데이터 한계 및 추가 검증 필요.

Abstract: We propose a two-stage multimodal framework that enhances disease
classification and region-aware radiology report generation from chest X-rays,
leveraging the MIMIC-Eye dataset. In the first stage, we introduce a
gaze-guided contrastive learning architecture for disease classification. It
integrates visual features, clinical labels, bounding boxes, and radiologist
eye-tracking signals and is equipped with a novel multi-term gaze-attention
loss combining MSE, KL divergence, correlation, and center-of-mass alignment.
Incorporating fixations improves F1 score from 0.597 to 0.631 (+5.70%) and AUC
from 0.821 to 0.849 (+3.41%), while also improving precision and recall,
highlighting the effectiveness of gaze-informed attention supervision. In the
second stage, we present a modular report generation pipeline that extracts
confidence-weighted diagnostic keywords, maps them to anatomical regions using
a curated dictionary constructed from domain-specific priors, and generates
region-aligned sentences via structured prompts. This pipeline improves report
quality as measured by clinical keyword recall and ROUGE overlap. Our results
demonstrate that integrating gaze data improves both classification performance
and the interpretability of generated medical reports.

</details>


### [149] [ID-Card Synthetic Generation: Toward a Simulated Bona fide Dataset](https://arxiv.org/abs/2508.13078)
*Qingwen Zeng,Juan E. Tapia,Izan Garcia,Juan M. Espin,Christoph Busch*

Main category: cs.CV

TL;DR: 신분증 PAD(프레젠테이션 공격 탐지)에서 진짜 이미지 부족 문제를 해결하기 위해 Stable Diffusion으로 진짜(바나파이드) 신분증 이미지를 합성해 학습데이터를 확장하고, 자체학습 모델 및 상용 솔루션에서 효과를 검증한 연구.


<details>
  <summary>Details</summary>
Motivation: 실제(바나파이드) 신분증 이미지가 적고 공격 유형이 다양해 PAD 일반화가 어려움. 기존 연구는 주로 공격 샘플 생성에 집중해 바나파이드 부족 문제를 간과함.

Method: Stable Diffusion을 이용해 바나파이드 신분증 이미지를 합성(진짜 모방). 합성 이미지로 PAD 시스템(새로 학습한 모델)과 상용 솔루션을 평가하여 합성 이미지가 바나파이드로 인식되는지, 검출 성능에 미치는 영향을 분석.

Result: 합성된 이미지는 PAD 시스템에서 바나파이드로 식별되었고, 이를 데이터 증강으로 활용하면 검출 성능 향상과 데이터 제약 완화에 긍정적 영향이 관찰됨.

Conclusion: Stable Diffusion 기반 바나파이드 합성은 PAD 데이터 부족 문제를 완화하고 일반화 성능을 개선할 잠재력이 있으나, 합성 이미지의 다양성·현실성, 보안·윤리적 리스크, 교차 도메인 일반화성 등에 대한 추가 검증이 필요함.

Abstract: Nowadays, the development of a Presentation Attack Detection (PAD) system for
ID cards presents a challenge due to the lack of images available to train a
robust PAD system and the increase in diversity of possible attack instrument
species. Today, most algorithms focus on generating attack samples and do not
take into account the limited number of bona fide images. This work is one of
the first to propose a method for mimicking bona fide images by generating
synthetic versions of them using Stable Diffusion, which may help improve the
generalisation capabilities of the detector. Furthermore, the new images
generated are evaluated in a system trained from scratch and in a commercial
solution. The PAD system yields an interesting result, as it identifies our
images as bona fide, which has a positive impact on detection performance and
data restrictions.

</details>


### [150] [Checkmate: interpretable and explainable RSVQA is the endgame](https://arxiv.org/abs/2508.13086)
*Lucrezia Tosato,Christel Tartini Chappuis,Syrielle Montariol,Flora Weissgerber,Sylvain Lobry,Devis Tuia*

Main category: cs.CV

TL;DR: 새로운 균형형 RSVQA 데이터셋 'Chessboard'(3,123,253 질문)과 설명 가능한 모델 'Checkmate'를 제안해, 답을 이미지의 특정 셀과 연결하여 시각적 근거를 제공하고 해석성·신뢰성을 높임.


<details>
  <summary>Details</summary>
Motivation: 기존 RSVQA 모델들은 해석 가능성·설명가능성이 부족하고 데이터 분포 편향으로 인해 단축학습(shortcut learning)에 취약함. 시각적 근거에 기반한 투명한 의사결정이 필요함.

Method: 데이터셋: 3,123,253개의 질문, 균형 잡힌 답 분포, 각 답에 대해 이미지 내 하나 이상 셀(cell)과 연결된 정밀한 라벨링을 제공. 모델: Checkmate는 모델의 결정을 뒷받침하는 관련 이미지 셀을 식별하도록 설계되어, 다양한 아키텍처에서 시각적 근거를 생성하고 해석 가능성을 향상시킴.

Result: 여러 모델 아키텍처에 걸친 광범위한 실험에서 접근법이 투명성과 해석성을 개선함. 정량적 수치(예: 정확도, 설명 질 지표)는 초록에 명시되지 않음. 제안된 데이터·모델 조합이 신뢰 가능한 RSVQA 의사결정에 기여함.

Conclusion: Chessboard 데이터셋과 Checkmate 모델은 RSVQA에서 편향 완화와 세밀한 시각적 추론을 가능하게 하며, 더 신뢰할 수 있는 의사결정을 지원함. 다만 구체적 성능 지표와 일반화성, 설명의 질에 대한 추가 검증이 필요함.

Abstract: Remote Sensing Visual Question Answering (RSVQA) presents unique challenges
in ensuring that model decisions are both understandable and grounded in visual
content. Current models often suffer from a lack of interpretability and
explainability, as well as from biases in dataset distributions that lead to
shortcut learning. In this work, we tackle these issues by introducing a novel
RSVQA dataset, Chessboard, designed to minimize biases through 3'123'253
questions and a balanced answer distribution. Each answer is linked to one or
more cells within the image, enabling fine-grained visual reasoning.
  Building on this dataset, we develop an explainable and interpretable model
called Checkmate that identifies the image cells most relevant to its
decisions. Through extensive experiments across multiple model architectures,
we show that our approach improves transparency and supports more trustworthy
decision-making in RSVQA systems.

</details>


### [151] [DMS:Diffusion-Based Multi-Baseline Stereo Generation for Improving Self-Supervised Depth Estimation](https://arxiv.org/abs/2508.13091)
*Zihua Liu,Yizhou Li,Songyan Zhang,Masatoshi Okutomi*

Main category: cs.CV

TL;DR: 자기지도 스테레오 및 단안 깊이 추정에서, 확산 모델의 기하학적 프라이어를 이용해 에피폴라 방향의 새로운 뷰를 합성하여 가려진 픽셀을 보완함으로써 포토메트릭 재구성 모호성을 줄이고 성능을 크게 향상시키는 DMS 기법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 포토메트릭 재구성은 폐색(occlusion)·프레임 외 영역 등으로 인해 대응 픽셀이 존재하지 않아 모호성이 발생하며, 자기지도 학습에서 명시적 대응관계 부재가 성능 한계로 작용한다. 이를 해결하기 위해 외부 레이블 없이도 가려진 픽셀을 보완할 수 있는 방법이 필요하다.

Method: Stable Diffusion을 방향성 프롬프트로 파인튜닝하여 에피폴라 방향의 새로운 뷰를 합성(좌-좌, 우-우, 좌우 사이의 중간 뷰 등). 합성된 뷰를 이용해 가려진 픽셀을 보충하고 명시적 포토메트릭 재구성을 수행. 모델-무관(plug-and-play)하며 레이블 없는 스테레오 쌍만으로 학습 및 합성 진행.

Result: 광범위한 실험에서 최대 약 35%의 아웃라이어(outlier) 감소를 기록했고, 여러 벤치마크에서 최첨단 성능을 달성함. 스테레오 매칭과 단안 깊이 추정 모두에서 유의미한 향상을 보임.

Conclusion: 확산 모델의 기하학적 사전지식을 활용해 자기지도 포토메트릭 제약의 한계를 극복한 실용적 접근. 통합이 용이하고 별도 레이블이 필요 없지만, 생성된 뷰의 아티팩트·도메인 편차·계산 비용(파인튜닝·합성)이 잠재적 한계로 남아 있으며, 일관성·속도 개선이 향후 과제이다.

Abstract: While supervised stereo matching and monocular depth estimation have advanced
significantly with learning-based algorithms, self-supervised methods using
stereo images as supervision signals have received relatively less focus and
require further investigation. A primary challenge arises from ambiguity
introduced during photometric reconstruction, particularly due to missing
corresponding pixels in ill-posed regions of the target view, such as
occlusions and out-of-frame areas. To address this and establish explicit
photometric correspondences, we propose DMS, a model-agnostic approach that
utilizes geometric priors from diffusion models to synthesize novel views along
the epipolar direction, guided by directional prompts. Specifically, we
finetune a Stable Diffusion model to simulate perspectives at key positions:
left-left view shifted from the left camera, right-right view shifted from the
right camera, along with an additional novel view between the left and right
cameras. These synthesized views supplement occluded pixels, enabling explicit
photometric reconstruction. Our proposed DMS is a cost-free, ''plug-and-play''
method that seamlessly enhances self-supervised stereo matching and monocular
depth estimation, and relies solely on unlabeled stereo image pairs for both
training and synthesizing. Extensive experiments demonstrate the effectiveness
of our approach, with up to 35% outlier reduction and state-of-the-art
performance across multiple benchmark datasets.

</details>


### [152] [Real-Time Beach Litter Detection and Counting: A Comparative Analysis of RT-DETR Model Variants](https://arxiv.org/abs/2508.13101)
*Miftahul Huda,Arsyiah Azahra,Putri Maulida Chairani,Dimas Rizky Ramadhani,Nabila Azhari,Ade Lailani*

Main category: cs.CV

TL;DR: RT-DETR-X가 정확도에서 미세하게 우세하지만( mAP@50 0.816 vs 0.810, mAP@50-95 0.612 vs 0.606) RT-DETR-L이 추론 속도에서 큰 이점을 보이며(20.1 ms vs 34.5 ms) 실시간 현장배치에는 더 현실적인 선택이다.


<details>
  <summary>Details</summary>
Motivation: 해안 쓰레기 감지·계수를 자동화해 대규모·실시간 환경 모니터링을 구현하고, Transformer 기반 최신 객체검출기의 적용 가능성 평가.

Method: 공개 해안 잔해 데이터셋을 사용해 RT-DETR의 두 변종(RT-DETR-L, RT-DETR-X)을 학습·평가. 평가 지표로 mAP@50, mAP@50-95와 추론 시간(밀리초)을 사용해 정확도-속도 균형 비교.

Result: RT-DETR-X가 미세한 정확도 향상을 보였으나 계산 비용(추론시간)은 상당히 증가. RT-DETR-L은 거의 동등한 정확도에 훨씬 빠른 처리속도를 제공.

Conclusion: 실시간·현장 배치 관점에서는 RT-DETR-L이 더 실용적. 향후 연구로는 경량화·양자화·에지 배포, 클래스별 AP·오탐 분석, 다양한 환경(조명·해상도·가려짐)에서의 강건성 평가가 필요하다.

Abstract: Coastal pollution is a pressing global environmental issue, necessitating
scalable and automated solutions for monitoring and management. This study
investigates the efficacy of the Real-Time Detection Transformer (RT-DETR), a
state-of-the-art, end-to-end object detection model, for the automated
detection and counting of beach litter. A rigorous comparative analysis is
conducted between two model variants, RT-DETR-Large (RT-DETR-L) and
RT-DETR-Extra-Large (RT-DETR-X), trained on a publicly available dataset of
coastal debris. The evaluation reveals that the RT-DETR-X model achieves
marginally superior accuracy, with a mean Average Precision at 50\% IoU
(mAP@50) of 0.816 and a mAP@50-95 of 0.612, compared to the RT-DETR-L model's
0.810 and 0.606, respectively. However, this minor performance gain is realized
at a significant computational cost; the RT-DETR-L model demonstrates a
substantially faster inference time of 20.1 ms versus 34.5 ms for the
RT-DETR-X. The findings suggest that the RT-DETR-L model offers a more
practical and efficient solution for real-time, in-field deployment due to its
superior balance of processing speed and detection accuracy. This research
provides valuable insights into the application of advanced Transformer-based
detectors for environmental conservation, highlighting the critical trade-offs
between model complexity and operational viability.

</details>


### [153] [Precise Action-to-Video Generation Through Visual Action Prompts](https://arxiv.org/abs/2508.13104)
*Yuang Wang,Chao Wen,Haoyu Guo,Sida Peng,Minghan Qin,Hujun Bao,Xiaowei Zhou,Ruizhen Hu*

Main category: cs.CV

TL;DR: 시각적 액션 프롬프트(visual skeleton)를 이용해, 정밀한 액션 제어와 도메인 간 동적 전이성(transferability)을 모두 확보한 액션→비디오 생성 방법을 제안한다. HOI와 로봇 조작 데이터에서 스켈레톤을 구축하고, 사전학습된 비디오 생성기 모델에 경량 파인튜닝으로 통합해 복잡한 고자유도 상호작용을 정확하게 생성한다.


<details>
  <summary>Details</summary>
Motivation: 기존 액션 기반 비디오 생성은 정밀성(정확한 제어)과 일반성(도메인 전이성) 사이에 상충 관계가 있음. 텍스트·원시 프리미티브·조잡한 마스크는 일반성이 있으나 정밀성이 떨어지고, 에이전트 중심 신호는 정밀하지만 도메인 전이가 어렵다.

Method: 행동을 도메인에 무관한 시각적 프롬프트(시각적 스켈레톤)로 렌더링한다. HOI(사람-물체 상호작용)와 섬세한 로봇 조작 데이터에서 스켈레톤을 추출하는 강건한 파이프라인을 설계하고, 이를 사전학습된 비디오 생성 모델에 경량 파인튜닝으로 통합해 동적 전이성과 기하학적 정밀성을 동시에 보존한다.

Result: EgoVid, RT-1, DROID 데이터셋에서 실험하여 복잡한 상호작용에 대해 정밀한 액션 제어와 도메인 간 전이가 가능함을 보임.

Conclusion: 시각적 액션 프롬프트(스켈레톤)는 액션→비디오 생성에서 정밀성·전이성 균형을 달성하는 효과적인 표현이며, 크로스도메인 학습과 실세계 로봇·사람 상호작용 모델에 적용 가능하다.

Abstract: We present visual action prompts, a unified action representation for
action-to-video generation of complex high-DoF interactions while maintaining
transferable visual dynamics across domains. Action-driven video generation
faces a precision-generality trade-off: existing methods using text, primitive
actions, or coarse masks offer generality but lack precision, while
agent-centric action signals provide precision at the cost of cross-domain
transferability. To balance action precision and dynamic transferability, we
propose to "render" actions into precise visual prompts as domain-agnostic
representations that preserve both geometric precision and cross-domain
adaptability for complex actions; specifically, we choose visual skeletons for
their generality and accessibility. We propose robust pipelines to construct
skeletons from two interaction-rich data sources - human-object interactions
(HOI) and dexterous robotic manipulation - enabling cross-domain training of
action-driven generative models. By integrating visual skeletons into
pretrained video generation models via lightweight fine-tuning, we enable
precise action control of complex interaction while preserving the learning of
cross-domain dynamics. Experiments on EgoVid, RT-1 and DROID demonstrate the
effectiveness of our proposed approach. Project page:
https://zju3dv.github.io/VAP/.

</details>


### [154] [Motion2Motion: Cross-topology Motion Transfer with Sparse Correspondence](https://arxiv.org/abs/2508.13139)
*Ling-Hao Chen,Yuhong Zhang,Zixin Yin,Zhiyang Dou,Xin Chen,Jingbo Wang,Taku Komura,Lei Zhang*

Main category: cs.CV

TL;DR: Motion2Motion은 훈련이 필요 없는 모션 리타게팅 프레임워크로, 서로 다른 골격 토폴로지를 가진 캐릭터 간의 애니메이션 전송을 위해 소수의 뼈 대응과 대상 스켈레톤의 한두 개 예제 모션만으로 작동한다. 동일 토폴로지와 종간(cross-species) 전송에서 모두 효율적이고 신뢰할 만한 성능을 보이며 코드와 데이터가 공개되어 있다.


<details>
  <summary>Details</summary>
Motivation: 서로 다른 스켈레톤 토폴로지 때문에 발생하는 일대일 뼈 대응의 부재와, 다양한 토폴로지를 아우르는 대규모 페어 모션 데이터셋의 부재가 데이터 기반 리타게팅 연구를 제약한다. 이에 데이터 소모가 적고 토폴로지 불일치에 강한 방법이 필요하다.

Method: 훈련 불필요(즉 학습 기반 모델을 요구하지 않음)한 예제 기반 방법을 제안한다. 소스·타깃 스켈레톤 사이의 희소한 뼈 대응 정보와 타깃에서의 한두 개 예제 모션만으로 변환을 수행한다(추정·정렬·보정 단계로 요약 가능).

Result: 정성적·정량적 평가에서 동일 스켈레톤 및 이종 스켈레톤 전송 모두에서 효율적이고 안정적인 성능을 달성했으며, 실제 응용 및 사용자 인터페이스에 통합되는 등 실용성도 입증했다.

Conclusion: Motion2Motion은 데이터가 거의 없거나 뼈 대응이 제한적인 상황에서도 실무적 용도로 쓸 수 있는 실용적이고 데이터 효율적인 모션 리타게팅 솔루션을 제시한다.

Abstract: This work studies the challenge of transfer animations between characters
whose skeletal topologies differ substantially. While many techniques have
advanced retargeting techniques in decades, transfer motions across diverse
topologies remains less-explored. The primary obstacle lies in the inherent
topological inconsistency between source and target skeletons, which restricts
the establishment of straightforward one-to-one bone correspondences. Besides,
the current lack of large-scale paired motion datasets spanning different
topological structures severely constrains the development of data-driven
approaches. To address these limitations, we introduce Motion2Motion, a novel,
training-free framework. Simply yet effectively, Motion2Motion works with only
one or a few example motions on the target skeleton, by accessing a sparse set
of bone correspondences between the source and target skeletons. Through
comprehensive qualitative and quantitative evaluations, we demonstrate that
Motion2Motion achieves efficient and reliable performance in both
similar-skeleton and cross-species skeleton transfer scenarios. The practical
utility of our approach is further evidenced by its successful integration in
downstream applications and user interfaces, highlighting its potential for
industrial applications. Code and data are available at
https://lhchen.top/Motion2Motion.

</details>


### [155] [IGFuse: Interactive 3D Gaussian Scene Reconstruction via Multi-Scans Fusion](https://arxiv.org/abs/2508.13153)
*Wenhao Hu,Zesheng Li,Haonan Zhou,Liu Liu,Xuexiang Wen,Zhizhong Su,Xi Li,Gaoang Wang*

Main category: cs.CV

TL;DR: IGFuse fuses multiple partial scans of a scene—taken with different object rearrangements—into a single, manipulable Gaussian-field scene representation by using segmentation-aware Gaussian fields, bi-directional photometric and semantic consistency, a pseudo-intermediate alignment state, and co-pruning strategies to refine geometry, enabling high-fidelity rendering and object-level manipulation without dense scans or complex pipelines.


<details>
  <summary>Details</summary>
Motivation: Single-scan or single-configuration multiview captures miss occluded geometry; existing multi-stage pipelines (segmentation, completion, inpainting) or per-object dense scanning are error-prone and hard to scale. Leveraging natural object rearrangement across scans can reveal unseen regions for more complete reconstruction.

Method: Construct segmentation-aware Gaussian fields for scene representation; enforce bi-directional photometric and semantic consistency across scans; introduce a pseudo-intermediate scene state to align spatially misaligned scans; apply collaborative co-pruning to remove spurious geometry and refine shapes; fuse observations from multiple scans into an interactive Gaussian scene.

Result: IGFuse produces high-fidelity rendering and supports object-level manipulation from sparse, rearranged multi-scan data. Experiments show strong generalization to novel scene configurations and effectiveness in real-world 3D reconstruction and real-to-simulation transfer.

Conclusion: Fusing multiple scans with rearranged object layouts and enforcing combined photometric/semantic consistency in a segmentation-aware Gaussian representation, plus alignment and co-pruning mechanisms, yields robust, scalable reconstruction and interactive scene representations without requiring dense per-object scans or complex multi-stage pipelines.

Abstract: Reconstructing complete and interactive 3D scenes remains a fundamental
challenge in computer vision and robotics, particularly due to persistent
object occlusions and limited sensor coverage. Multiview observations from a
single scene scan often fail to capture the full structural details. Existing
approaches typically rely on multi stage pipelines, such as segmentation,
background completion, and inpainting or require per-object dense scanning,
both of which are error-prone, and not easily scalable. We propose IGFuse, a
novel framework that reconstructs interactive Gaussian scene by fusing
observations from multiple scans, where natural object rearrangement between
captures reveal previously occluded regions. Our method constructs segmentation
aware Gaussian fields and enforces bi-directional photometric and semantic
consistency across scans. To handle spatial misalignments, we introduce a
pseudo-intermediate scene state for unified alignment, alongside collaborative
co-pruning strategies to refine geometry. IGFuse enables high fidelity
rendering and object level scene manipulation without dense observations or
complex pipelines. Extensive experiments validate the framework's strong
generalization to novel scene configurations, demonstrating its effectiveness
for real world 3D reconstruction and real-to-simulation transfer. Our project
page is available online.

</details>


### [156] [4DNeX: Feed-Forward 4D Generative Modeling Made Easy](https://arxiv.org/abs/2508.13154)
*Zhaoxi Chen,Tianqi Liu,Long Zhuo,Jiawei Ren,Zeng Tao,He Zhu,Fangzhou Hong,Liang Pan,Ziwei Liu*

Main category: cs.CV

TL;DR: 4DNeX는 단일 이미지에서 효율적으로 4D(동적 3D) 장면을 생성하는 최초의 피드포워드 프레임워크로, 사전학습된 비디오 확산모델을 미세조정하고 대규모 합성 4D 데이터(4DNeX-10M)와 6D(RGB+XYZ) 표현을 활용해 고품질 동적 포인트클라우드와 신규뷰 비디오 합성을 생성한다.


<details>
  <summary>Details</summary>
Motivation: 기존 4D 생성방법들은 다수의 영상 입력이나 비용이 큰 최적화 절차에 의존해 확장성과 효율성이 낮다. 단일 이미지에서 동적 3D 표현을 빠르고 일반화 가능하게 생성할 방법이 필요하다.

Method: (1) 고품질 4D 주석을 대량으로 제공하는 4DNeX-10M 데이터셋 구축, (2) RGB와 XYZ 시퀀스를 통합한 통일된 6D 비디오 표현 제안, (3) 사전학습된 비디오 확산모델을 4D 모델링에 재활용하기 위한 간단한 적응 전략들(미세조정 등) 적용하여 피드포워드 이미지→4D 파이프라인 구축.

Result: 4DNeX는 효율성과 일반화 측면에서 기존 4D 생성 기법들을 능가하며, 고품질 동적 포인트클라우드를 생성해 신규뷰 비디오 합성을 수행한다. 대규모 데이터와 사전학습 재활용으로 확장성이 뛰어남을 보임.

Conclusion: 사전학습된 비디오 확산모델과 대규모 4D 데이터, 6D 표현을 결합하면 단일 이미지로부터 실용적이고 확장 가능한 4D 장면 모델을 생성할 수 있다. 이는 생성적 4D 월드 모델 연구의 기초를 마련한다.

Abstract: We present 4DNeX, the first feed-forward framework for generating 4D (i.e.,
dynamic 3D) scene representations from a single image. In contrast to existing
methods that rely on computationally intensive optimization or require
multi-frame video inputs, 4DNeX enables efficient, end-to-end image-to-4D
generation by fine-tuning a pretrained video diffusion model. Specifically, 1)
to alleviate the scarcity of 4D data, we construct 4DNeX-10M, a large-scale
dataset with high-quality 4D annotations generated using advanced
reconstruction approaches. 2) we introduce a unified 6D video representation
that jointly models RGB and XYZ sequences, facilitating structured learning of
both appearance and geometry. 3) we propose a set of simple yet effective
adaptation strategies to repurpose pretrained video diffusion models for 4D
modeling. 4DNeX produces high-quality dynamic point clouds that enable
novel-view video synthesis. Extensive experiments demonstrate that 4DNeX
outperforms existing 4D generation methods in efficiency and generalizability,
offering a scalable solution for image-to-4D modeling and laying the foundation
for generative 4D world models that simulate dynamic scene evolution.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [157] [Deep Language Geometry: Constructing a Metric Space from LLM Weights](https://arxiv.org/abs/2508.11676)
*Maksym Shamrai,Vladyslav Hamolia*

Main category: cs.CL

TL;DR: LLM 내부 가중치 기반으로 언어들의 고차원 벡터 공간을 구성해 전통적 특성 기반 방법과 달리 자동으로 언어 간 유사성을 추정한다.


<details>
  <summary>Details</summary>
Motivation: 전통적 수작업 언어 특성(typology)이나 표면적 통계에 의존하지 않고, 대형 언어 모델 내부 표현에서 언어 고유의 구조적·역사적 신호를 자동으로 추출하려는 동기.

Method: 다국어 LLM의 내부 가중치 활성화에 적응형 가지치기(pruning) 알고리즘을 적용해 가중치 중요도 점수를 계산하고, 이를 이용해 각 언어를 고차원 벡터로 임베딩하여 언어 간 거리/유사도 공간을 구성.

Result: 106개 언어와 다양한 데이터셋, 복수 LLM에서 검증한 결과 전통적 언어 계통 및 계열과 잘 정렬되었고, 일부 예상치 못한 언어 간 연결도 발견되었다.

Conclusion: LLM 가중치 기반의 데이터 주도적 언어 지리학(geometry)은 언어 관계 탐지와 역사적·접촉적 신호 포착에 유망하며, 코드와 벡터·시각화 도구를 공개해 재현 가능성을 높였다.

Abstract: We introduce a novel framework that utilizes the internal weight activations
of modern Large Language Models (LLMs) to construct a metric space of
languages. Unlike traditional approaches based on hand-crafted linguistic
features, our method automatically derives high-dimensional vector
representations by computing weight importance scores via an adapted pruning
algorithm. Our approach captures intrinsic language characteristics that
reflect linguistic phenomena. We validate our approach across diverse datasets
and multilingual LLMs, covering 106 languages. The results align well with
established linguistic families while also revealing unexpected inter-language
connections that may indicate historical contact or language evolution. The
source code, computed language latent vectors, and visualization tool are made
publicly available at https://github.com/mshamrai/deep-language-geometry.

</details>


### [158] [Can we Evaluate RAGs with Synthetic Data?](https://arxiv.org/abs/2508.11758)
*Jonas van Elburg,Peter van der Putten,Maarten Marx*

Main category: cs.CL

TL;DR: LLM으로 만든 합성 QA 데이터는 리트리버 변형 비교에는 인간 레이블 기준과 잘 일치하나, 생성기(Generator) 아키텍처 비교에는 신뢰할 수 없는 결과를 낸다.


<details>
  <summary>Details</summary>
Motivation: 인간 라벨이 없을 때 LLM이 생성한 합성 QA 데이터가 실제 인간 평가를 대신할 수 있는지, 특히 RAG(retrieval-augmented generation) 구성 요소 비교에서 대체 지표로 사용 가능한지를 검증하려는 목적.

Method: 두 실험 설정: (1) 생성기 고정, 리트리버 파라미터 변화 비교; (2) 리트리버 고정, 생성기 아키텍처 변화 비교. 네 개 데이터셋(오픈도메인 2종, 비공개 2종)을 사용해 합성 벤치마크와 인간 레이블 벤치마크 상의 RAG 성능 순위를 비교.

Result: 리트리버를 바꿔가며 평가할 때 합성 데이터 기반 벤치마크는 인간 레이블 결과와 높은 정렬도를 보였음. 반면 생성기 아키텍처를 비교할 때는 합성 벤치마크가 일관된 순위를 제공하지 못해 불일치가 나타남.

Conclusion: 합성 QA 데이터는 리트리버 튜닝·선택에 유익한 대체 지표가 될 수 있으나, 생성기 간 비교에는 신뢰성이 떨어진다. 원인으로는 합성 태스크와 인간 벤치마크 간의 작업 불일치와 생성기별 스타일 편향이 제시된다.

Abstract: We investigate whether synthetic question-answer (QA) data generated by large
language models (LLMs) can serve as an effective proxy for human-labeled
benchmarks when such data is unavailable. We assess the reliability of
synthetic benchmarks across two experiments: one varying retriever parameters
while keeping the generator fixed, and another varying the generator with fixed
retriever parameters. Across four datasets, of which two open-domain and two
proprietary, we find that synthetic benchmarks reliably rank the RAGs varying
in terms of retriever configuration, aligning well with human-labeled benchmark
baselines. However, they fail to produce consistent RAG rankings when comparing
generator architectures. The breakdown possibly arises from a combination of
task mismatch between the synthetic and human benchmarks, and stylistic bias
favoring certain generators.

</details>


### [159] [Limitation Learning: Catching Adverse Dialog with GAIL](https://arxiv.org/abs/2508.11767)
*Noah Kasmanoff,Rahul Zalkikar*

Main category: cs.CL

TL;DR: 대화 분야에 모방학습을 적용하여 전문가 대화 시연으로부터 정책(대화 모델)과 전문가·합성 대화를 구분하는 판별기를 학습함. 정책은 프롬프트에 따라 대화 가능하나 판별기 결과는 현재 대화모델의 한계를 드러내며, 이 기법으로 유해하거나 부적절한 동작을 식별할 수 있음을 주장함.


<details>
  <summary>Details</summary>
Motivation: 보상 신호가 없거나 정의하기 어려운 대화 생성 문제에서 전문가 시연을 통해 합리적 정책을 확보하고, 동시에 모델의 부작용(유해성·비일관성 등)을 판별할 방법을 제시하려는 목적.

Method: 전문가 시연 데이터를 이용한 모방학습으로 대화 정책을 학습하고, 전문가 대화와 합성 대화를 구분하는 판별기를 함께 학습하여 정책과 판별기의 성능을 분석함.

Result: 학습된 정책은 사용자 프롬프트에 응답하는 데 성공했으나, 판별기는 대화모델의 약점(일관성, 사실성, 안전성 등)을 드러냄. 판별기 출력은 대화모델의 부적절 행동 식별에 유용했음.

Conclusion: 모방학습+판별기 조합은 대화 정책 생성과 모델 행태 분석에 유용하며, 특히 판별기를 활용해 대화 모델의 유해하거나 이상한 동작을 찾아내는 도구로 활용 가능함.

Abstract: Imitation learning is a proven method for creating a policy in the absence of
rewards, by leveraging expert demonstrations. In this work, we apply imitation
learning to conversation. In doing so, we recover a policy capable of talking
to a user given a prompt (input state), and a discriminator capable of
classifying between expert and synthetic conversation. While our policy is
effective, we recover results from our discriminator that indicate the
limitations of dialog models. We argue that this technique can be used to
identify adverse behavior of arbitrary data models common for dialog oriented
tasks.

</details>


### [160] [Every 28 Days the AI Dreams of Soft Skin and Burning Stars: Scaffolding AI Agents with Hormones and Emotions](https://arxiv.org/abs/2508.11829)
*Leigh Levinson,Christopher J. Agostino*

Main category: cs.CL

TL;DR: Authors propose embedding simulated menstrual and circadian hormone cycles into LLMs via system prompts to act as contextual relevance filters; they report linguistic and performance variations that align with biological phases.


<details>
  <summary>Details</summary>
Motivation: Address the frame problem by using biological rhythms as inherent relevance filters to reduce contextual search space and modulate model behavior in a biologically interpretable way.

Method: Generate system prompts from periodic functions modeling estrogen, testosterone, cortisol cycles; inject these prompts into various state-of-the-art LLMs; analyze language (emotion, style) and benchmark performance on SQuAD, MMLU, Hellaswag, AI2-ARC across simulated phases.

Result: Observed emotional and stylistic shifts corresponding to phases (e.g., sadness during menstruation, happiness at ovulation; morning optimism vs nocturnal introspection) and modest but consistent benchmark performance variations, with peak performance in moderate hormone ranges.

Conclusion: Periodic biological signaling as a prompting mechanism offers a novel, interpretable context filter for AI, but also exposes gendered and biological biases encoded in LLMs.

Abstract: Despite significant advances, AI systems struggle with the frame problem:
determining what information is contextually relevant from an exponentially
large possibility space. We hypothesize that biological rhythms, particularly
hormonal cycles, serve as natural relevance filters that could address this
fundamental challenge. We develop a framework that embeds simulated menstrual
and circadian cycles into Large Language Models through system prompts
generated from periodic functions modeling key hormones including estrogen,
testosterone, and cortisol. Across multiple state-of-the-art models, linguistic
analysis reveals emotional and stylistic variations that track biological
phases; sadness peaks during menstruation while happiness dominates ovulation
and circadian patterns show morning optimism transitioning to nocturnal
introspection. Benchmarking on SQuAD, MMLU, Hellaswag, and AI2-ARC demonstrates
subtle but consistent performance variations aligning with biological
expectations, including optimal function in moderate rather than extreme
hormonal ranges. This methodology provides a novel approach to contextual AI
while revealing how societal biases regarding gender and biology are embedded
within language models.

</details>


### [161] [Investigating Transcription Normalization in the Faetar ASR Benchmark](https://arxiv.org/abs/2508.11771)
*Leo Peckham,Michael Ong,Naomi Nagy,Ewan Dunbar*

Main category: cs.CL

TL;DR: 저자들은 낮은 자원(low-resource)인 Faetar ASR 벤치마크에서 전사 불일치(transcription inconsistencies)가 주요 난제인지 검증했다. 소규모 수작업 사전(lexicon)을 사용해 분석한 결과 전사 불일치가 존재하지만 핵심 문제는 아니며, 바이그램 단어 기반 언어모델은 성능 향상에 기여하지 못했고 유한한 사전으로 디코딩을 제한하는 것은 유익하다고 결론지었다.


<details>
  <summary>Details</summary>
Motivation: Faetar 데이터의 낮은 자원성과 전사 품질(일관성)이 ASR 성능 저하의 주 원인인지 규명하고, 전사 오류를 줄이는 것이 실제로 도움이 되는지 확인하려 함.

Method: 소규모 수작업 사전을 제작해 전사와 어휘 간 정합성을 분석하고, 바이그램(word-based) 언어모델 도입 및 사전 제약(decoding constrained to finite lexicon)이 디코딩에 미치는 영향을 비교 실험함.

Result: 전사 불일치는 관찰되었으나 ASR 난이도의 주된 원인으로 보기 어렵고, 바이그램 단어 기반 LM은 추가 이득을 주지 못했음. 반면 유한 사전으로 디코딩을 제한하면 이득이 있음.

Conclusion: 전사 정합성 개선만으로는 충분치 않으며, Faetar ASR 문제는 여전히 매우 어려움. 향후에는 어쿠스틱 모델 개선, 더 큰/정교한 사전, 서브워드/문자 기반 접근, 또는 대규모 사전학습 기법을 검토해야 함.

Abstract: We examine the role of transcription inconsistencies in the Faetar Automatic
Speech Recognition benchmark, a challenging low-resource ASR benchmark. With
the help of a small, hand-constructed lexicon, we conclude that find that,
while inconsistencies do exist in the transcriptions, they are not the main
challenge in the task. We also demonstrate that bigram word-based language
modelling is of no added benefit, but that constraining decoding to a finite
lexicon can be beneficial. The task remains extremely difficult.

</details>


### [162] [A Multi-Task Evaluation of LLMs' Processing of Academic Text Input](https://arxiv.org/abs/2508.11779)
*Tianyi Li,Yu Qin,Olivia R. Liu Sheng*

Main category: cs.CL

TL;DR: 이 논문은 LLM이 학술 텍스트를 처리해 동료심사 보조에 얼마나 유용한지 평가하기 위해 재현·비교·채점·성찰의 네 단계 작업으로 구성된 워크플로우를 제안하고, 구글의 Gemini를 대상으로 다층적(내부 메트릭·외부 정답·사람 평가) 평가를 수행해 요약·패러프레이즈는 괜찮지만 비교·채점·깊이 있는 성찰 등 고차원 과제에는 한계가 있음을 보고한다.


<details>
  <summary>Details</summary>
Motivation: LLM의 연구 보조·동료심사 활용 가능성에 대한 낙관론과 회의론이 공존하는 가운데, 개별 과제를 통합한 실용적이고 점진적 평가체계로 실제 적용 가능성을 엄밀히 검증할 필요가 있다.

Method: 학술 텍스트 입력에 대해 네 가지 역할(오라클/판단자/지식 판단자/협력자)에 대응하는 네 가지 과제(요약·비교·채점·성찰)를 설계하고, 상위 정보시스템(Is) 저널의 논문들을 입력으로 삼아 다양한 텍스트 지표와 외부·인간 평가를 통해 구글 Gemini의 성능을 검증. 프롬프트는 상세히 제시하고 변형에 따른 안정성도 확인.

Result: Gemini는 요약·패러프레이즈에서 수용 가능한 신뢰도를 보였으나, 쌍대 비교를 통한 순위화는 확장성이 낮고, 학술 텍스트 채점은 분별력이 떨어지며, 질적 성찰은 자가 일관적이나 통찰은 부족했다. 이러한 판정은 내부·외부 메트릭과 인간 평가에서 일관되게 관찰됨.

Conclusion: 현재 상태의 LLM을 동료심사에 무검증으로 투입하는 것을 권하지 않으며, 요약 등 일부 보조적 작업에는 활용 가능하나 채점·평가·창의적 피드백 역할은 인간 감독·추가 방법론(교정·앙상블·검증 데이터 등)이 필요하다.

Abstract: How much large language models (LLMs) can aid scientific discovery, notably
in assisting academic peer review, is in heated debate. Between a literature
digest and a human-comparable research assistant lies their practical
application potential. We organize individual tasks that computer science
studies employ in separate terms into a guided and robust workflow to evaluate
LLMs' processing of academic text input. We employ four tasks in the
assessment: content reproduction/comparison/scoring/reflection, each demanding
a specific role of the LLM (oracle/judgmental arbiter/knowledgeable
arbiter/collaborator) in assisting scholarly works, and altogether testing LLMs
with questions that increasingly require intellectual capabilities towards a
solid understanding of scientific texts to yield desirable solutions. We
exemplify a rigorous performance evaluation with detailed instructions on the
prompts. Adopting first-rate Information Systems articles at three top journals
as the input texts and an abundant set of text metrics, we record a compromised
performance of the leading LLM - Google's Gemini: its summary and paraphrase of
academic text is acceptably reliable; using it to rank texts through pairwise
text comparison is faintly scalable; asking it to grade academic texts is prone
to poor discrimination; its qualitative reflection on the text is
self-consistent yet hardly insightful to inspire meaningful research. This
evidence against an endorsement of LLMs' text-processing capabilities is
consistent across metric-based internal (linguistic assessment), external
(comparing to the ground truth), and human evaluation, and is robust to the
variations of the prompt. Overall, we do not recommend an unchecked use of LLMs
in constructing peer reviews.

</details>


### [163] [LLM-Guided Planning and Summary-Based Scientific Text Simplification: DS@GT at CLEF 2025 SimpleText](https://arxiv.org/abs/2508.11816)
*Krishna Chaitanya Marturi,Heba H. Elwazzan*

Main category: cs.CL

TL;DR: 제안된 방법은 문장 수준에서 LLM으로 구조화된 계획을 생성하고 이를 기반으로 문장 단위 단순화를 수행하며, 문서 수준에서는 LLM으로 간결한 요약을 만들어 이를 단순화에 활용하는 2단계 LLM 기반 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 과학 텍스트의 문장·문서 단위 단순화에서 단순화의 일관성과 문맥적 충실도를 확보하려는 필요성.

Method: 문장 수준: LLM으로 '구조화된 계획(plan)' 생성 → 계획에 따라 개별 문장 단순화. 문서 수준: LLM으로 요약 생성 → 요약을 단순화 안내(signal)로 사용해 문서 전체 단순화. 두 단계(계획/요약 → 단순화)로 구성된 파이프라인.

Result: 초록에서는 구체적 실험 결과나 수치가 제시되지 않음. 다만 제안된 파이프라인이 더 일관되고 문맥에 충실한 단순화를 가능하게 한다고 서술.

Conclusion: 2단계 LLM 기반 접근은 과학 텍스트 단순화의 일관성·충실성 향상에 유망하지만, 실제 성능과 안정성(예: 환각, 정보손실)은 실험·평가를 통해 입증되어야 한다.

Abstract: In this paper, we present our approach for the CLEF 2025 SimpleText Task 1,
which addresses both sentence-level and document-level scientific text
simplification. For sentence-level simplification, our methodology employs
large language models (LLMs) to first generate a structured plan, followed by
plan-driven simplification of individual sentences. At the document level, we
leverage LLMs to produce concise summaries and subsequently guide the
simplification process using these summaries. This two-stage, LLM-based
framework enables more coherent and contextually faithful simplifications of
scientific text.

</details>


### [164] [Hallucination Detection and Mitigation in Scientific Text Simplification using Ensemble Approaches: DS@GT at CLEF 2025 SimpleText](https://arxiv.org/abs/2508.11823)
*Krishna Chaitanya Marturi,Heba H. Elwazzan*

Main category: cs.CL

TL;DR: CLEF 2025 SimpleText Task 2용 시스템: BERT 분류기, 의미 유사도, NLI, LLM 추론을 앙상블하고 메타-분류기로 결합. LLM 기반 후편집으로 원문에 근거한 생성 개선을 시도.


<details>
  <summary>Details</summary>
Motivation: 과학 텍스트 단순화 과정에서 발생하는 창의적 생성(불필요한 추가 서술)과 정보 왜곡(사실적 일탈)을 자동으로 탐지·평가하려는 문제 의식.

Method: BERT 기반 분류기, 의미 유사도 측정, 자연어추론(NLI) 결과, LLM의 추론 신호들을 다중 신호로 수집하여 메타-분류기로 통합하는 앙상블 프레임워크. 근거성 보장을 위해 LLM 기반의 후편집(post-editing) 모듈로 단순문장을 원문에 맞게 수정.

Result: 초록에는 구체적 수치나 벤치마크 결과가 제시되지 않음. 저자들은 다양한 신호 결합이 왜곡·스푸리어스 생성 탐지의 강건성을 높이고, LLM 후편집이 근거 기반 생성을 개선한다고 보고함.

Conclusion: 여러 검증 신호를 통합하고 LLM 후편집을 결합하는 접근은 CLEF 2025 SimpleText Task 2 문제에 대해 실용적이고 유망한 솔루션으로 보이나, 정량적 평가와 오류 사례 분석이 필요하다.

Abstract: In this paper, we describe our methodology for the CLEF 2025 SimpleText Task
2, which focuses on detecting and evaluating creative generation and
information distortion in scientific text simplification. Our solution
integrates multiple strategies: we construct an ensemble framework that
leverages BERT-based classifier, semantic similarity measure, natural language
inference model, and large language model (LLM) reasoning. These diverse
signals are combined using meta-classifiers to enhance the robustness of
spurious and distortion detection. Additionally, for grounded generation, we
employ an LLM-based post-editing system that revises simplifications based on
the original input texts.

</details>


### [165] [A Survey of Idiom Datasets for Psycholinguistic and Computational Research](https://arxiv.org/abs/2508.11828)
*Michael Flor,Xinyi Liu,Anna Feldman*

Main category: cs.CL

TL;DR: A survey of 53 idiom datasets from psycholinguistics and computational linguistics, comparing content, annotation (familiarity, transparency, compositionality), task framing, and coverage; finds growing language/task diversity but little integration between psycholinguistic norms and computational use.


<details>
  <summary>Details</summary>
Motivation: Idioms are hard for both NLP and human experiments because their meanings are non-compositional; a systematic review of available datasets can clarify resources, annotation practices, and gaps between communities.

Method: Surveyed 53 datasets, categorized by intended use (psycholinguistic vs computational), analyzed annotation dimensions, coverage (languages, forms), and task framings (idiomaticity detection, paraphrasing, cross-lingual modeling), and distilled trends in practices.

Result: Psycholinguistic datasets mainly provide normed ratings on familiarity, transparency, compositionality; computational datasets target detection, paraphrase generation, cross-lingual tasks. Recent work increased language and task diversity, but there is no apparent linkage between psycholinguistic norms and computational datasets.

Conclusion: Calls for better integration: shared annotation standards, combined datasets that include psycholinguistic norms for computational tasks, more cross-lingual and evaluation benchmarks to align research and improve model interpretability.

Abstract: Idioms are figurative expressions whose meanings often cannot be inferred
from their individual words, making them difficult to process computationally
and posing challenges for human experimental studies. This survey reviews
datasets developed in psycholinguistics and computational linguistics for
studying idioms, focusing on their content, form, and intended use.
Psycholinguistic resources typically contain normed ratings along dimensions
such as familiarity, transparency, and compositionality, while computational
datasets support tasks like idiomaticity detection/classification,
paraphrasing, and cross-lingual modeling. We present trends in annotation
practices, coverage, and task framing across 53 datasets. Although recent
efforts expanded language coverage and task diversity, there seems to be no
relation yet between psycholinguistic and computational research on idioms.

</details>


### [166] [When Does Language Transfer Help? Sequential Fine-Tuning for Cross-Lingual Euphemism Detection](https://arxiv.org/abs/2508.11831)
*Julia Sammartino,Libby Barak,Jing Peng,Anna Feldman*

Main category: cs.CL

TL;DR: 연속 파인튜닝(sequential fine-tuning)은 고자원 언어(L1)에서 학습한 뒤 저자원(L2)에 파인튜닝하면 완곡어법(euphemism) 탐지 성능을 향상시킨다. XLM-R은 더 큰 이득을 보이나 사전학습 커버리지 격차와 망각(catastrophic forgetting)에 민감하고, mBERT는 더 안정적이지만 성능 향폭이 작다.


<details>
  <summary>Details</summary>
Motivation: 완곡어법은 문화마다 다르고 모호함이 커서 언어 모델이 탐지하기 어렵다. 특히 데이터가 부족한 언어에서는 문제 해결이 더 어렵다. 따라서 다국어 전이 학습이 어떻게 저자원 완곡어법 탐지에 도움이 되는지, 그리고 모델·언어 특성(형태·사전학습 커버리지 등)이 결과에 어떠한 영향을 미치는지 조사할 필요가 있다.

Method: 영어·스페인어·중국어·터키어·요루바 등 5개 언어를 대상으로 XLM-R과 mBERT를 사용해 세 가지 파인튜닝 전략(단일 언어(monolingual), 동시 다중언어(simultaneous), 연속(sequential))을 비교했다. 실험에서는 고자원 L1로 먼저 파인튜닝한 뒤 L2에 연속 파인튜닝하는 방식, 다양한 언어 쌍과 유형학적 특성·사전학습 커버리지 차이를 교차 분석했다.

Result: 연속 파인튜닝은 특히 요루바·터키어처럼 저자원 언어에서 L2 성능을 유의하게 개선했다. XLM-R은 더 큰 성능 향상을 보였으나 사전학습에서의 커버리지 격차와 연속 파인튜닝 시의 망각에 더 민감했다. 반면 mBERT는 전반적으로 더 안정적(성능 변동성 낮음)이나 절대 성능 향폭은 작았다.

Conclusion: 연속 파인튜닝은 저자원 언어의 완곡어법 탐지 성능을 간단하면서도 효과적으로 끌어올리는 전략이다. 다만 모델 선택(XLM-R vs mBERT), 사전학습 커버리지 차이와 망각 문제를 고려해 보완(정규화·어댑터·계속학습 기법 등)을 병행해야 한다.

Abstract: Euphemisms are culturally variable and often ambiguous, posing challenges for
language models, especially in low-resource settings. This paper investigates
how cross-lingual transfer via sequential fine-tuning affects euphemism
detection across five languages: English, Spanish, Chinese, Turkish, and
Yoruba. We compare sequential fine-tuning with monolingual and simultaneous
fine-tuning using XLM-R and mBERT, analyzing how performance is shaped by
language pairings, typological features, and pretraining coverage. Results show
that sequential fine-tuning with a high-resource L1 improves L2 performance,
especially for low-resource languages like Yoruba and Turkish. XLM-R achieves
larger gains but is more sensitive to pretraining gaps and catastrophic
forgetting, while mBERT yields more stable, though lower, results. These
findings highlight sequential fine-tuning as a simple yet effective strategy
for improving euphemism detection in multilingual models, particularly when
low-resource languages are involved.

</details>


### [167] [SupraTok: Cross-Boundary Tokenization for Enhanced Language Model Performance](https://arxiv.org/abs/2508.11857)
*Andrei-Valentin Tănase,Elena Pelican*

Main category: cs.CL

TL;DR: SupraTok은 BPE를 확장해 다단어 'superword'를 학습하고, 경계 간 패턴 학습·엔트로피 기반 데이터 큐레이션·다단계 커리큘럼 학습을 결합한 새로운 토크나이저이다. 영어에서 문자당 토큰 효율을 약 30% 개선하고(5.91→4.51 chars/token 비교), GPT-2(124M)로 10B 토큰 학습 시 HellaSWAG·MMLU에서 각각 8.4%·9.5% 향상을 보고했다. 대규모 모델에서의 검증은 추가 필요하다.


<details>
  <summary>Details</summary>
Motivation: 토크나이제이션이 NLP 성능의 병목으로 남아 있고, 기존 방법들은 정적이며 다단어 의미 단위를 포착하지 못한다는 문제 인식에서 출발함.

Method: BPE를 기반으로 'superword' 토큰을 학습하도록 확장. 경계 간 패턴 학습으로 다단어 표현을 발견하고, 엔트로피 기반 데이터 큐레이션으로 학습 코퍼스 품질을 최적화하며, 다단계 커리큘럼 학습으로 안정적 수렴을 도모한다. 256k 어휘 등 다양한 설정에서 비교 평가를 수행.

Result: 영어 토큰화 효율 31% 개선(대조군: OpenAI o200k), Gemma 3 대비 30% 개선. 38개 언어에서 경쟁력 유지. GPT-2 규모 실험에서 HellaSWAG 8.4%, MMLU 9.5% 향상.

Conclusion: 효율적 토크나이제이션은 아키텍처 개선을 보완하는 실용적 경로가 될 수 있음. 다만 더 큰 모델 규모에서의 추가 검증 필요.

Abstract: Tokenization remains a fundamental yet underexplored bottleneck in natural
language processing, with strategies largely static despite remarkable progress
in model architectures. We present SupraTok, a novel tokenization architecture
that reimagines subword segmentation through three innovations: cross-boundary
pattern learning that discovers multi-word semantic units, entropy-driven data
curation that optimizes training corpus quality, and multi-phase curriculum
learning for stable convergence. Our approach extends Byte-Pair Encoding by
learning "superword" tokens, coherent multi-word expressions that preserve
semantic unity while maximizing compression efficiency. SupraTok achieves 31%
improvement in English tokenization efficiency (5.91 versus 4.51 characters per
token) compared to OpenAI's o200k tokenizer and 30% improvement over Google's
Gemma 3 tokenizer (256k vocabulary), while maintaining competitive performance
across 38 languages. When integrated with a GPT-2 scale model (124M parameters)
trained on 10 billion tokens from the FineWeb-Edu dataset, SupraTok yields 8.4%
improvement on HellaSWAG and 9.5% on MMLU benchmarks without architectural
modifications. While these results are promising at this scale, further
validation at larger model scales is needed. These findings suggest that
efficient tokenization can complement architectural innovations as a path to
improved language model performance.

</details>


### [168] [In-Context Examples Matter: Improving Emotion Recognition in Conversation with Instruction Tuning](https://arxiv.org/abs/2508.11889)
*Hui Ma,Bo Zhang,Jinpeng Hu,Zenglin Shi*

Main category: cs.CL

TL;DR: InitERC는 발화자 특성·대화 맥락·감정 상태의 정렬을 단일 단계의 인컨텍스트(in-context) 지시 튜닝으로 학습해 ERC 성능을 끌어올린 방법이다. 데모 풀 구성, 예제 선택, 프롬프트 설계, 인컨텍스트 튜닝의 네 가지 요소를 사용하며, 검색 전략·예제 순서·예제 수가 성능에 미치는 영향을 실험적으로 분석해 세 데이터셋에서 SOTA보다 우수한 성능을 보였다.


<details>
  <summary>Details</summary>
Motivation: 기존의 다단계(먼저 화자 특성 부여 → 문맥 인지 튜닝) 접근은 화자 정보와 대화 문맥의 동적 상호작용을 공동으로 포착하지 못해 화자·문맥·감정 간의 통합적 정렬(alignment)이 약하다는 한계가 있다. 이를 하나의 단계에서 해결하려는 동기에서 출발한다.

Method: 한 단계(in-context) 지시 튜닝 프레임워크인 InitERC를 제안한다. 구성 요소는 (1) demonstration pool 구성, (2) 인컨텍스트 예제 선택(검색 전략 포함), (3) 프롬프트 템플릿 설계, (4) 인컨텍스트 지시 튜닝이다. 또한 검색(strategy), 예제 순서(ordering), 예제 수(k) 등 세 가지 요소가 성능에 미치는 영향을 체계적으로 연구한다.

Result: 세 개의 널리 쓰이는 ERC 데이터셋에서 광범위한 실험을 수행해 기존 최첨단 기법들보다 유의미한 성능 향상을 기록했다. 특히 적절한 예제 선택·정렬·수 조절이 성능에 큰 영향을 미침을 보였다.

Conclusion: 간단한 한 단계의 인컨텍스트 지시 튜닝으로 화자-문맥-감정 정렬을 효과적으로 학습할 수 있으며, InitERC는 ERC에서 강력한 성능을 제공한다. 다만 데이터·도메인 확장성, 계산 비용, 다양한 LLM 크기에서의 일반화성 등은 추가 검증이 필요하다.

Abstract: Emotion recognition in conversation (ERC) aims to identify the emotion of
each utterance in a conversation, playing a vital role in empathetic artificial
intelligence. With the growing of large language models (LLMs), instruction
tuning has emerged as a critical paradigm for ERC. Existing studies mainly
focus on multi-stage instruction tuning, which first endows LLMs with speaker
characteristics, and then conducts context-aware instruction tuning to
comprehend emotional states. However, these methods inherently constrains the
capacity to jointly capture the dynamic interaction between speaker
characteristics and conversational context, resulting in weak alignment among
speaker identity, contextual cues, and emotion states within a unified
framework. In this paper, we propose InitERC, a simple yet effective one-stage
in-context instruction tuning framework for ERC. InitERC adapts LLMs to learn
speaker-context-emotion alignment from context examples via in-context
instruction tuning. Specifically, InitERC comprises four components, i.e.,
demonstration pool construction, in-context example selection, prompt template
design, and in-context instruction tuning. To explore the impact of in-context
examples, we conduct a comprehensive study on three key factors: retrieval
strategy, example ordering, and the number of examples. Extensive experiments
on three widely used datasets demonstrate that our proposed InitERC achieves
substantial improvements over the state-of-the-art baselines.

</details>


### [169] [CORE: Measuring Multi-Agent LLM Interaction Quality under Game-Theoretic Pressures](https://arxiv.org/abs/2508.11915)
*Punya Syon Pandey,Yongjin Yang,Jiarui Liu,Zhijing Jin*

Main category: cs.CL

TL;DR: 이 논문은 다중 에이전트 LLM 대화에서 언어 사용의 다양성과 반복성을 측정하기 위해 CORE(Conversational Robustness Evaluation Score)를 제안한다. CORE는 군집 엔트로피, 어휘 반복성, 의미 유사도를 결합하여 대화 품질을 정량화하고, 경쟁·협력·중립 게임 설정에서 Zipf 법칙과 Heaps 법칙을 활용해 실험적으로 검증한다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 환경에서 LLM 간 상호작용이 급증하고 있으나, 대화의 언어학적 다양성과 적응 양상이 체계적으로 정량화되지 않았음. 사회적 인센티브(경쟁/협력)가 언어에 미치는 영향을 계량화할 필요.

Method: CORE 지표를 정의: (1) 군집 엔트로피(cluster entropy)로 대화 내 주제·표현 분포 측정, (2) 어휘 반복성(lexical repetition) 측정, (3) 의미 유사도(semantic similarity)로 발화 간 의미적 근접성 평가. Pairwise LLM 대화를 경쟁/협력/중립 설정에서 수집하여 CORE와 전통적 분포 분석(Zipf, Heaps)을 적용.

Result: 협력 설정에서 Zipf 지수는 더 가파르고 Heaps 지수는 높아 '반복성 증가 + 어휘 확장' 패턴을 보였다. 경쟁적 설정은 낮은 Zipf·Heaps 지수를 보여 반복이 적고 어휘가 제한적이었다. CORE는 다양한 설정에서 대화 품질 변화를 포착.

Conclusion: 사회적 인센티브가 언어 적응에 유의미한 영향을 미치며, CORE는 다중 에이전트 LLM 시스템에서 언어적 견고성(robustness)을 진단하는 유용한 도구가 될 수 있다.

Abstract: Game-theoretic interactions between agents with Large Language Models (LLMs)
have revealed many emergent capabilities, yet the linguistic diversity of these
interactions has not been sufficiently quantified. In this paper, we present
the Conversational Robustness Evaluation Score: CORE, a metric to quantify the
effectiveness of language use within multi-agent systems across different
game-theoretic interactions. CORE integrates measures of cluster entropy,
lexical repetition, and semantic similarity, providing a direct lens of dialog
quality. We apply CORE to pairwise LLM dialogs across competitive, cooperative,
and neutral settings, further grounding our analysis in Zipf's and Heaps' Laws
to characterize word frequency distributions and vocabulary growth. Our
findings show that cooperative settings exhibit both steeper Zipf distributions
and higher Heap exponents, indicating more repetition alongside greater
vocabulary expansion. In contrast, competitive interactions display lower Zipf
and Heaps exponents, reflecting less repetition and more constrained
vocabularies. These results provide new insights into how social incentives
influence language adaptation, and highlight CORE as a robust diagnostic for
measuring linguistic robustness in multi-agent LLM systems. Our code is
available at https://github.com/psyonp/core.

</details>


### [170] [LLMs Struggle with NLI for Perfect Aspect: A Cross-Linguistic Study in Chinese and Japanese](https://arxiv.org/abs/2508.11927)
*Jie Lu,Du Jin,Hitomi Yanaka*

Main category: cs.CL

TL;DR: The paper builds template-based NLI datasets (1,350 pairs each) for Chinese and Japanese perfect aspect to probe temporal inference; experiments show major LLM failures with subtle tense/reference-time shifts, urging cross-linguistic temporal evaluation.


<details>
  <summary>Details</summary>
Motivation: English marks perfect aspect across tenses with distinct forms, but Chinese and Japanese lack tense marking within the perfect, making temporal inference in NLI more complex; authors aim to probe model competence on this cross-linguistic phenomenon.

Method: Construct linguistically motivated, template-based NLI pairs focused on the perfect aspect in Chinese and Japanese (1,350 pairs per language); evaluate several advanced LLMs on temporal inference, especially tense and reference-time shifts.

Result: LLMs performed poorly at temporal inference involving subtle tense/reference-time differences; models struggle to detect shifts in reference time and tense implications in these languages.

Conclusion: Current LLMs have limitations in cross-linguistic temporal semantics; the dataset reveals the need for targeted, cross-linguistic evaluation and resources (dataset released).

Abstract: Unlike English, which uses distinct forms (e.g., had, has, will have) to mark
the perfect aspect across tenses, Chinese and Japanese lack separate
grammatical forms for tense within the perfect aspect, which complicates
Natural Language Inference (NLI). Focusing on the perfect aspect in these
languages, we construct a linguistically motivated, template-based NLI dataset
(1,350 pairs per language). Experiments reveal that even advanced LLMs struggle
with temporal inference, particularly in detecting subtle tense and
reference-time shifts. These findings highlight model limitations and
underscore the need for cross-linguistic evaluation in temporal semantics. Our
dataset is available at https://github.com/Lujie2001/CrossNLI.

</details>


### [171] [CAMF: Collaborative Adversarial Multi-agent Framework for Machine Generated Text Detection](https://arxiv.org/abs/2508.11933)
*Yue Wang,Liesheng Wei,Yuxiang Wang*

Main category: cs.CL

TL;DR: CAMF은 다중 LLM 기반 에이전트가 협력·적대적 방식으로 문장을 다차원(스타일·의미·논리)으로 분석하고 최종 판정을 집계하는 제로샷 MGT(머신생성텍스트) 탐지 프레임워크로, 기존 기법보다 우수한 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 거짓정보·학술부정 등 위험에 대응하기 위해 현대 LLM이 생성한 텍스트를 탐지해야 하나, 기존 제로샷 기법은 텍스트의 표면적 속성에만 의존하거나 스타일·의미·논리 간 일관성 검증을 충분히 하지 못함.

Method: 세 단계: (1) 다차원 언어특성 추출—스타일, 의미, 논리 등 각 차원에 특화된 에이전트가 특징을 추출; (2) 적대적 일관성 탐색—에이전트들 간에 질문·반박을 통해 교차-차원 불일치 탐지; (3) 종합판단 집계—여러 에이전트의 판단을 통합해 최종 MGT 여부 결정.

Result: 실험적으로 CAMF가 기존 제로샷 MGT 탐지 기법들보다 유의미하게 우수한 성능을 기록함.

Conclusion: 협력적·적대적 다중에이전트 구조는 인간과 다른 미묘한 교차-차원 불일치를 잘 포착하여 제로샷 환경에서의 MGT 탐지 성능을 향상시킨다.

Abstract: Detecting machine-generated text (MGT) from contemporary Large Language
Models (LLMs) is increasingly crucial amid risks like disinformation and
threats to academic integrity. Existing zero-shot detection paradigms, despite
their practicality, often exhibit significant deficiencies. Key challenges
include: (1) superficial analyses focused on limited textual attributes, and
(2) a lack of investigation into consistency across linguistic dimensions such
as style, semantics, and logic. To address these challenges, we introduce the
\textbf{C}ollaborative \textbf{A}dversarial \textbf{M}ulti-agent
\textbf{F}ramework (\textbf{CAMF}), a novel architecture using multiple
LLM-based agents. CAMF employs specialized agents in a synergistic three-phase
process: \emph{Multi-dimensional Linguistic Feature Extraction},
\emph{Adversarial Consistency Probing}, and \emph{Synthesized Judgment
Aggregation}. This structured collaborative-adversarial process enables a deep
analysis of subtle, cross-dimensional textual incongruities indicative of
non-human origin. Empirical evaluations demonstrate CAMF's significant
superiority over state-of-the-art zero-shot MGT detection techniques.

</details>


### [172] [Learning Wisdom from Errors: Promoting LLM's Continual Relation Learning through Exploiting Error Cases](https://arxiv.org/abs/2508.12031)
*Shaozhe Yin,Jinyu Guo,Kai Shuang,Xia Liu,Ruize Ou*

Main category: cs.CL

TL;DR: 제안된 방법은 CRE에서 오류 사례에 집중하는 ‘지시 기반 이중-작업 대조 튜닝(instruction-based dual-task contrastive tuning)’으로, 각 작업의 학습·메모리 데이터를 초깃값 응답의 정오(正誤)로 분할해 다르게 처리하고, LLM의 지시 추종 능력을 이용한 대조적 지시-튜닝으로 이전 데이터가 현재의 인지적 편향을 지속적으로 보정하도록 한다. TACRED·FewRel에서 SOTA 성능을 달성했다.


<details>
  <summary>Details</summary>
Motivation: 기존 CRE는 메모리 리플레이와 대조학습으로 망각을 방지하지만, 모델의 인지적 편향을 잘 드러내는 오류 사례(error cases)에 충분한 비중을 두지 않아 근본적 편향 보정에 한계가 있다는 점을 해결하려 함.

Method: 각 태스크의 학습 데이터와 메모리 데이터를 초깃값(모델의 초기 응답)의 정오로 분리해 '정답군'과 '오류군'으로 구분하고, 이를 서로 다르게 취급하는 이중-작업(dual-task) 파인튜닝을 수행. 더불어 LLM의 지시-추종(instruction-following) 능력을 활용해 이전 데이터로 현재의 오류 편향을 대조적(in contrastive)으로 교정하는 지시 기반 대조 튜닝 전략을 도입.

Result: TACRED와 FewRel에서 기존 CRE 기법들보다 유의미한 성능 향상으로 새로운 SOTA를 보고. 특히 오류 사례를 특화 활용한 접근이 효과적이라는 실험적 근거를 제시.

Conclusion: 오류 사례를 분리·강화하여 LLM을 지시 기반 대조 튜닝하면 CRE에서 망각 방지와 관계 간 갭 완화에 효과적이며, 오류 중심 학습이 CRE에 중요한 역할을 함을 보였다.

Abstract: Continual Relation Extraction (CRE) aims to continually learn new emerging
relations while avoiding catastrophic forgetting. Existing CRE methods mainly
use memory replay and contrastive learning to mitigate catastrophic forgetting.
However, these methods do not attach importance to the error cases that can
reveal the model's cognitive biases more effectively. To address this issue, we
propose an instruction-based continual contrastive tuning approach for Large
Language Models (LLMs) in CRE. Different from existing CRE methods that
typically handle the training and memory data in a unified manner, this
approach splits the training and memory data of each task into two parts
respectively based on the correctness of the initial responses and treats them
differently through dual-task fine-tuning. In addition, leveraging the
advantages of LLM's instruction-following ability, we propose a novel
instruction-based contrastive tuning strategy for LLM to continuously correct
current cognitive biases with the guidance of previous data in an
instruction-tuning manner, which mitigates the gap between old and new
relations in a more suitable way for LLMs. We experimentally evaluate our model
on TACRED and FewRel, and the results show that our model achieves new
state-of-the-art CRE performance with significant improvements, demonstrating
the importance of specializing in exploiting error cases.

</details>


### [173] [A Question Answering Dataset for Temporal-Sensitive Retrieval-Augmented Generation](https://arxiv.org/abs/2508.12282)
*Ziyang Chen,Erxue Min,Xiang Zhao,Yunxin Li,Xin Jia,Jinzhi Liao,Jichao Li,Shuaiqiang Wang,Baotian Hu,Dawei Yin*

Main category: cs.CL

TL;DR: ChronoQA는 2019–2024년 신문기사 30만 편을 바탕으로 만든 중국어 시계열 질의응답 벤치마크로, 5,176개의 시점 관련(절대·집계·상대) 질문을 포함하고 단·다중 문서 시나리오와 구조적 주석, 규칙·LLM·인간 검증을 거쳐 RAG 시스템의 시간 추론 평가를 목표로 한다.


<details>
  <summary>Details</summary>
Motivation: 현실 세계의 정보는 시간에 민감하고 RAG(검색–생성) 시스템은 최신성·시간 정렬·논리적 일관성을 요구한다. 기존 QA 벤치마크는 시간적 제약을 충분히 다루지 못해 시점 추론 능력을 별도 평가할 필요가 있다.

Method: 2019–2024년 기사에서 질문을 수집·생성하고 절대/집계/상대·명시/암시 시간 표현을 포함하도록 설계했으며, 단문서·다문서 사례를 마련하고 구조적 주석을 달았다. 데이터 품질 확보를 위해 규칙 기반 검증, 대형 언어모델 검사, 인간 평가의 다단계 검증 파이프라인을 적용했다.

Result: 5,176개의 고품질 문항과 풍부한 주석을 갖춘 데이터셋이 완성되었으며, RAG 시스템의 시간 관련 질의응답 성능을 체계적으로 측정할 수 있는 벤치마크로 제시되었다.

Conclusion: ChronoQA는 시간 민감성 평가를 위한 신뢰성 있고 확장 가능한 중국어 리소스로, 시간 정렬·논리 일관성·다문서 추론을 요구하는 연구와 시스템 개발을 촉진할 것으로 기대된다.

Abstract: We introduce ChronoQA, a large-scale benchmark dataset for Chinese question
answering, specifically designed to evaluate temporal reasoning in
Retrieval-Augmented Generation (RAG) systems. ChronoQA is constructed from over
300,000 news articles published between 2019 and 2024, and contains 5,176
high-quality questions covering absolute, aggregate, and relative temporal
types with both explicit and implicit time expressions. The dataset supports
both single- and multi-document scenarios, reflecting the real-world
requirements for temporal alignment and logical consistency. ChronoQA features
comprehensive structural annotations and has undergone multi-stage validation,
including rule-based, LLM-based, and human evaluation, to ensure data quality.
By providing a dynamic, reliable, and scalable resource, ChronoQA enables
structured evaluation across a wide range of temporal tasks, and serves as a
robust benchmark for advancing time-sensitive retrieval-augmented question
answering systems.

</details>


### [174] [Mind the Generation Process: Fine-Grained Confidence Estimation During LLM Generation](https://arxiv.org/abs/2508.12040)
*Jinyi Han,Tingyun Li,Shisong Chen,Jie Shi,Xinyi Wang,Guanglei Yue,Jiaqing Liang,Xin Lin,Liqian Wen,Zulong Chen,Yanghua Xiao*

Main category: cs.CL

TL;DR: FineCE는 텍스트 생성 중에 정확하고 세밀한 연속적 신뢰도(확신도) 점수를 제공하는 방법으로, 학습 데이터 파이프라인과 감독 학습 기반 신뢰도 예측기, 그리고 이후 문맥을 활용하는 Backward Confidence Integration(BCI)를 도입해 기존 기법들보다 성능이 우수함을 보인다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLM)은 높은 성능에도 불구하고 자체 인식(self-awareness)이 부족해 잘못된 예측에 과도한 확신을 부여하는 경향이 있다. 기존 신뢰도 추정 방법들은 거친(비세밀) 점수화에 머물러 생성 과정 전반에 걸친 연속적 신뢰도를 제공하지 못한다.

Method: (1) LLM 응답의 확률분포를 잘 포착하는 학습 데이터 생성 파이프라인을 설계한다. (2) 임의 텍스트 시퀀스에 대해 신뢰도 점수를 예측하도록 감독학습 모델을 학습한다. (3) 추론 시 이후 생성 토큰의 정보를 활용해 현재 시퀀스의 신뢰도를 개선하는 Backward Confidence Integration(BCI) 기법을 도입한다. (4) 생성 과정에서 신뢰도 추정을 수행할 최적 위치를 찾기 위한 세 가지 전략을 제안한다.

Result: 다수의 벤치마크에서 기존 고전적 신뢰도 추정 기법들을 지속적으로 능가하는 성능을 기록했으며, 코드와 비교 대상 모델들을 공개함.

Conclusion: FineCE는 텍스트 생성 중 세밀하고 연속적인 신뢰도 추정을 가능하게 해 LLM 출력의 신뢰성·안전성을 향상시키며 실험적으로 우수함을 입증했다.

Abstract: While large language models (LLMs) have demonstrated remarkable performance
across diverse tasks, they fundamentally lack self-awareness and frequently
exhibit overconfidence, assigning high confidence scores to incorrect
predictions. Accurate confidence estimation is therefore critical for enhancing
the trustworthiness and reliability of LLM-generated outputs. However, existing
approaches suffer from coarse-grained scoring mechanisms that fail to provide
fine-grained, continuous confidence estimates throughout the generation
process. To address these limitations, we introduce FineCE, a novel confidence
estimation method that delivers accurate, fine-grained confidence scores during
text generation. Specifically, we first develop a comprehensive pipeline for
constructing training data that effectively captures the underlying
probabilistic distribution of LLM responses, and then train a model to predict
confidence scores for arbitrary text sequences in a supervised manner.
Furthermore, we propose a Backward Confidence Integration (BCI) strategy that
leverages information from the subsequent text to enhance confidence estimation
for the current sequence during inference. We also introduce three strategies
for identifying optimal positions to perform confidence estimation within the
generation process. Extensive experiments on multiple benchmark datasets
demonstrate that FineCE consistently outperforms existing classical confidence
estimation methods. Our code and all baselines used in the paper are available
on GitHub.

</details>


### [175] [All for law and law for all: Adaptive RAG Pipeline for Legal Research](https://arxiv.org/abs/2508.13107)
*Figarri Keisha,Prince Singh,Pallavi,Dion Fernandes,Aravindh Manivannan,Ilham Wicaksono,Faisal Ahmad*

Main category: cs.CL

TL;DR: 법률 분야 RAG 파이프라인을 개선하여 문맥 인식 질의 변환, SBERT/GTE 기반 오픈소스 검색, 복합 평가체계를 도입함으로써 비용 효율적으로 검색 품질과 응답 충실도를 높인 연구.


<details>
  <summary>Details</summary>
Motivation: 대형 언어모델의 환각 문제를 완화하고, 법률 리서치에 적합한 근거 기반(RAG) 출력 제공을 위해 오픈소스·비용 효율적인 엔드투엔드 솔루션 개발이 필요하다.

Method: (i) 문서 레퍼런스와 자연어 질문을 분리하는 컨텍스트 인식 질의 변환기, (ii) SBERT와 GTE 임베딩을 이용한 오픈소스 검색 전략, (iii) RAGAS, BERTScore-F1, ROUGE-Recall을 결합한 평가·생성 프레임워크를 적용해 성능을 비교·평가.

Result: 오픈소스 검색은 Recall@K를 30–95% 향상시키고, K>4에서 Precision@K를 약 2.5배 개선했으며, 맞춤형 법률 기반 프롬프트가 더 충실하고 문맥에 적합한 응답을 생성함을 보였다.

Conclusion: 구성 요소별·태스크별 튜닝을 통해 재현 가능하고 비용 효율적인 법률용 RAG 시스템을 구축할 수 있으며, 오픈소스 방식이 상용 접근법과 대등하거나 능가할 수 있음을 시사한다.

Abstract: Retrieval-Augmented Generation (RAG) mitigates hallucinations by grounding
large language model outputs in cited sources, a capability that is especially
critical in the legal domain. We present an end-to-end RAG pipeline that
revisits and extends the LegalBenchRAG baseline with three targeted
enhancements: (i) a context-aware query translator that disentangles document
references from natural-language questions and adapts retrieval depth and
response style based on expertise and specificity, (ii) open-source retrieval
strategies using SBERT and GTE embeddings that achieve substantial performance
gains (improving Recall@K by 30-95\% and Precision@K by $\sim$2.5$\times$ for
$K>4$) while remaining cost-efficient, and (iii) a comprehensive evaluation and
generation framework that combines RAGAS, BERTScore-F1, and ROUGE-Recall to
assess semantic alignment and faithfulness across models and prompt designs.
Our results show that carefully designed open-source pipelines can rival or
outperform proprietary approaches in retrieval quality, while a custom
legal-grounded prompt consistently produces more faithful and contextually
relevant answers than baseline prompting. Taken together, these contributions
demonstrate the potential of task-aware, component-level tuning to deliver
legally grounded, reproducible, and cost-effective RAG systems for legal
research assistance.

</details>


### [176] [J6: Jacobian-Driven Role Attribution for Multi-Objective Prompt Optimization in LLMs](https://arxiv.org/abs/2508.12086)
*Yao Wu*

Main category: cs.CL

TL;DR: J6는 LLM 적응 시 여러 목표(사실성, 확신 등)의 그래디언트 상호작용을 야코비안 행렬 분해로 ‟6개 성분”으로 나누어 충돌/상호시너지를 인지한 동적 업데이트(하드·소프트)를 수행하는 방법이다.


<details>
  <summary>Details</summary>
Motivation: 여러 최적화 목적이 충돌하거나 상호작용할 때, 단일 스칼라 그래디언트 합성은 파라미터 간·목표 간 기하학적 구조를 무시한다. 특히 숨겨진 층 삽입(h)과 임베딩 수정(w) 같은 프롬프트 파라미터가 복잡하게 상호작용할 때 더 정교한 해석과 조정이 필요하다.

Method: J6는 그래디언트 상호작용(야코비안) 행렬을 6개의 해석 가능한 구성요소로 분해한다. 각 성분은 업데이트 방향 기여를 나타내며, argmax 같은 하드 결정이나 softmax 기반 가중치처럼 소프트 전략으로 합성할 수 있는 동적 프레임워크를 제공한다. 이를 통해 지역적 충돌·시너지에 따라 업데이트를 조정하고 파라미터 귀속 및 작업 간 간섭을 해석할 수 있다.

Result: J6는 충돌 감지 및 기하학 정렬 적응을 가능하게 하는 원리적 메커니즘을 제시하며, 프롬프트 최적화에서 충돌을 인지한 업데이트를 수행할 수 있다고 주장한다. 또한 확장성과 해석 가능성을 통해 파라미터 기여와 간섭을 분석하는 통찰을 제공한다.

Conclusion: 구조화된 야코비안 분해는 다목적 LLM 튜닝에서 스칼라 합성의 한계를 넘어서며, 충돌 인식·해석 가능·동적 적응을 가능하게 하는 새로운 접근을 연다.

Abstract: In large language model (LLM) adaptation, balancing multiple optimization
objectives such as improving factuality (heat) and increasing confidence (via
low entropy) poses a fundamental challenge, especially when prompt parameters
(e.g., hidden-layer insertions h and embedding modifications w) interact in
non-trivial ways. Existing multi-objective optimization strategies often rely
on scalar gradient aggregation, ignoring the deeper geometric structure between
objectives and parameters. We propose J6, a structured Jacobian-based method
that decomposes the gradient interaction matrix into six interpretable
components. This decomposition enables both hard decision-making (e.g.,
choosing the dominant update direction via argmax) and soft strategies (e.g.,
attention-style weighting via softmax over J6), forming a dynamic update
framework that adapts to local conflict and synergy. Moreover, the
interpretable structure of J6 provides insight into parameter attribution, task
interference, and geometry-aligned adaptation. Our work introduces a principled
and extensible mechanism for conflict-aware prompt optimization, and opens a
new avenue for incorporating structured Jacobian reasoning into multi-objective
neural tuning.

</details>


### [177] [STEM: Efficient Relative Capability Evaluation of LLMs through Structured Transition Samples](https://arxiv.org/abs/2508.12096)
*Haiquan Hu,Jiazhi Jiang,Shiyou Xu,Ruhan Zeng,Tian Wang*

Main category: cs.CL

TL;DR: STEM은 동일 아키텍처의 서로 다른 규모 모델들 사이에서 일관된 성능 전환을 보이는 샘플(STS)을 추출해, 소수의 샘플로 알려지지 않은 모델의 상대적 능력을 효율적으로 추정하는 경량 해석 가능 평가 방법이다. Qwen3 계열을 이용해 6개 벤치마크에서 STS 풀을 구성했고, 실험에서 실제 성능 순위와 잘 정렬됨을 보였다.


<details>
  <summary>Details</summary>
Motivation: 공개 벤치마크에 대한 오버피팅, 고비용의 전체 평가, 표준 점수와 실제 추론 능력 간 불일치 때문에 빠르고 신뢰성 있게 모델 간 능력을 구별할 방법이 필요하다.

Method: 같은 아키텍처에서 파라미터 규모가 다른 모델들에 대해 각 샘플별 성능 변화를 분석해 ‘유의미한 전환 샘플(STS)’을 선정한다. 이 STS 집합을 이용해 소수의 샘플로 미지 모델의 능력 위치를 추정한다. Qwen3 모델군으로 STS를 구축하고 6개 벤치마크에서 검증했다.

Result: STEM은 성능 추세를 안정적으로 포착하고, 지상(ground-truth) 성능 순위와 일치한다는 실험적 증거를 제시한다. 비용과 시간 측면에서 효율적이며 아키텍처에 무관하게 적용 가능함을 보였다.

Conclusion: STEM은 세밀하고 확장 가능한 모델 평가를 위한 실용적 대안으로, 전체 벤치 평가의 비용을 줄이고 해석 가능성을 제공한다.

Abstract: Evaluating large language models (LLMs) has become increasingly challenging
as model capabilities advance rapidly. While recent models often achieve higher
scores on standard benchmarks, these improvements do not consistently reflect
enhanced real-world reasoning capabilities. Moreover, widespread overfitting to
public benchmarks and the high computational cost of full evaluations have made
it both expensive and less effective to distinguish meaningful differences
between models. To address these challenges, we propose the \textbf{S}tructured
\textbf{T}ransition \textbf{E}valuation \textbf{M}ethod (STEM), a lightweight
and interpretable evaluation framework for efficiently estimating the relative
capabilities of LLMs. STEM identifies \textit{significant transition samples}
(STS) by analyzing consistent performance transitions among LLMs of the same
architecture but varying parameter scales. These samples enable STEM to
effectively estimate the capability position of an unknown model. Qwen3 model
family is applied to construct the STS pool on six diverse and representative
benchmarks. To assess generalizability. Experimental results indicate that STEM
reliably captures performance trends, aligns with ground-truth rankings of
model capability. These findings highlight STEM as a practical and scalable
method for fine-grained, architecture-agnostic evaluation of LLMs.

</details>


### [178] [Exploring Efficiency Frontiers of Thinking Budget in Medical Reasoning: Scaling Laws between Computational Resources and Reasoning Quality](https://arxiv.org/abs/2508.12140)
*Ziqian Bi,Lu Chen,Junhao Song,Hongying Luo,Enze Ge,Junmin Huang,Tianyang Wang,Keyu Chen,Chia Xin Liang,Zihan Wei,Huafeng Liu,Chunjie Tian,Jibin Guan,Joe Yeong,Yongzhi Xu,Peng Wang,Junfeng Hao*

Main category: cs.CL

TL;DR: 의료 추론에서 '생각 예산(thinking budget)' 제어를 처음으로 종합적으로 평가하여 계산 자원(토큰 수)과 추론 성능 간의 로그-스케일 관계를 규명함. Qwen3(1.7B–235B)와 DeepSeek-R1(1.5B–70B)을 15개 의료 데이터셋에서 실험해 세 가지 효율성 구간(0–256, 256–512, >512 토큰)을 제안하고, 작은 모델이 추가 예산으로 더 큰 상대적 이득을 얻는 등 모델 규모·도메인별 차이를 보고함.


<details>
  <summary>Details</summary>
Motivation: 의료 환경에서 계산 자원(응답 지연, 비용)과 추론 정확도 간의 상충관계를 체계적으로 이해하고, 동적 자원 할당으로 임상 요구에 맞춘 투명하고 효율적인 AI 운영을 가능하게 하기 위함.

Method: Qwen3와 DeepSeek-R1 계열 모델들을 15개 전문 분야 및 난이도별 의료 데이터셋으로 평가. 생각 예산을 0부터 무제한까지 제어하며 정확도 변화를 측정. Qwen3의 네이티브 API와 DeepSeek-R1에 대한 토큰 절단(truncation) 방법을 비교해 방법 일반화성 검증.

Result: 정확도는 생각 예산과 모델 크기에 대해 로그 형태의 규칙성을 보였음. 3개 효율성 구간이 관찰되었고(실시간·균형·고정밀), 작은 모델은 추가 예산에서 15–20% 개선을 보인 반면 큰 모델은 5–10% 수준의 개선을 보였음. 신경과·위장과 같이 더 깊은 추론이 필요한 도메인도 확인. 두 구현 방식 간 일관성으로 개념의 일반화성 확보.

Conclusion: 생각 예산 제어는 의료 AI 시스템에서 임상 목적에 맞춘 동적 자원 배분을 가능하게 하는 핵심 메커니즘이며, 비용-성능 트레이드오프 관리와 투명성 확보를 통해 실제 배포에 유용하다.

Abstract: This study presents the first comprehensive evaluation of thinking budget
mechanisms in medical reasoning tasks, revealing fundamental scaling laws
between computational resources and reasoning quality. We systematically
evaluated two major model families, Qwen3 (1.7B to 235B parameters) and
DeepSeek-R1 (1.5B to 70B parameters), across 15 medical datasets spanning
diverse specialties and difficulty levels. Through controlled experiments with
thinking budgets ranging from zero to unlimited tokens, we establish
logarithmic scaling relationships where accuracy improvements follow a
predictable pattern with both thinking budget and model size. Our findings
identify three distinct efficiency regimes: high-efficiency (0 to 256 tokens)
suitable for real-time applications, balanced (256 to 512 tokens) offering
optimal cost-performance tradeoffs for routine clinical support, and
high-accuracy (above 512 tokens) justified only for critical diagnostic tasks.
Notably, smaller models demonstrate disproportionately larger benefits from
extended thinking, with 15 to 20% improvements compared to 5 to 10% for larger
models, suggesting a complementary relationship where thinking budget provides
greater relative benefits for capacity-constrained models. Domain-specific
patterns emerge clearly, with neurology and gastroenterology requiring
significantly deeper reasoning processes than cardiovascular or respiratory
medicine. The consistency between Qwen3 native thinking budget API and our
proposed truncation method for DeepSeek-R1 validates the generalizability of
thinking budget concepts across architectures. These results establish thinking
budget control as a critical mechanism for optimizing medical AI systems,
enabling dynamic resource allocation aligned with clinical needs while
maintaining the transparency essential for healthcare deployment.

</details>


### [179] [LLM-as-a-Judge for Privacy Evaluation? Exploring the Alignment of Human and LLM Perceptions of Privacy in Textual Data](https://arxiv.org/abs/2508.12158)
*Stephen Meisenbacher,Alexandra Klymenko,Florian Matthes*

Main category: cs.CL

TL;DR: 저자들은 ‘LLM-as-a-Judge’ 패러다임을 개인정보 민감도 평가에 적용해, 10개 데이터셋·13개 LLM·677명의 인간 참가자 비교를 통해 LLM이 전반적(글로벌) 인간 관점을 잘 모사하지만 개인정보 평가는 주관성으로 인해 인간 간 합의가 낮다고 보고한다.


<details>
  <summary>Details</summary>
Motivation: 정확한 개인정보 민감도 평가가 어렵고, LLM이 다른 평가 작업에서 인간과 높은 일치도를 보인 점에서 LLM을 개인정보 평가자로 사용하는 가능성을 탐색하려 함.

Method: 10개 텍스트 데이터셋과 13개의 LLM을 사용하여 텍스트의 개인정보 민감도 라벨링을 수행하고, 677명의 인간 설문 응답자와 비교하여 LLM·인간 간 일치도와 추론 패턴을 분석함.

Result: 일반적으로 인간 간 합의도는 낮았지만, 여러 LLM은 전반적 인간 관점을 정확히 모델링했으며 인간과 LLM의 추론 패턴에서 장단점과 한계가 관찰됨.

Conclusion: LLM-as-a-Judge는 텍스트 개인정보 평가에 있어 유망하지만, 개인정보의 주관성·정의 문제와 낮은 인간 합의도 때문에 단독 평가자로 사용하기보다는 보조적·검토적 도구로 활용하는 것이 바람직함.

Abstract: Despite advances in the field of privacy-preserving Natural Language
Processing (NLP), a significant challenge remains the accurate evaluation of
privacy. As a potential solution, using LLMs as a privacy evaluator presents a
promising approach $\unicode{x2013}$ a strategy inspired by its success in
other subfields of NLP. In particular, the so-called $\textit{LLM-as-a-Judge}$
paradigm has achieved impressive results on a variety of natural language
evaluation tasks, demonstrating high agreement rates with human annotators.
Recognizing that privacy is both subjective and difficult to define, we
investigate whether LLM-as-a-Judge can also be leveraged to evaluate the
privacy sensitivity of textual data. Furthermore, we measure how closely LLM
evaluations align with human perceptions of privacy in text. Resulting from a
study involving 10 datasets, 13 LLMs, and 677 human survey participants, we
confirm that privacy is indeed a difficult concept to measure empirically,
exhibited by generally low inter-human agreement rates. Nevertheless, we find
that LLMs can accurately model a global human privacy perspective, and through
an analysis of human and LLM reasoning patterns, we discuss the merits and
limitations of LLM-as-a-Judge for privacy evaluation in textual data. Our
findings pave the way for exploring the feasibility of LLMs as privacy
evaluators, addressing a core challenge in solving pressing privacy issues with
innovative technical solutions.

</details>


### [180] [Arabic Multimodal Machine Learning: Datasets, Applications, Approaches, and Challenges](https://arxiv.org/abs/2508.12227)
*Abdelhamid Haouhat,Slimane Bellaouar,Attia Nehar,Hadda Cherroun,Ahmed Abdelali*

Main category: cs.CL

TL;DR: Survey of Arabic Multimodal Machine Learning (MML) presenting a new taxonomy (datasets, applications, approaches, challenges), summarizing literature, and identifying gaps and future directions.


<details>
  <summary>Details</summary>
Motivation: Arabic MML has matured to a point where a comprehensive, structured survey is needed to map progress and open problems.

Method: Proposes a novel taxonomy organizing efforts into four topics (datasets, applications, approaches, challenges) and analyzes existing Arabic MML research under this taxonomy.

Result: Provides a structured overview of the current state, catalogs datasets and applications, analyzes methodological trends, and highlights underinvestigated areas and critical research gaps.

Conclusion: The survey equips researchers with a roadmap of opportunities and challenges to guide future work in Arabic MML.

Abstract: Multimodal Machine Learning (MML) aims to integrate and analyze information
from diverse modalities, such as text, audio, and visuals, enabling machines to
address complex tasks like sentiment analysis, emotion recognition, and
multimedia retrieval. Recently, Arabic MML has reached a certain level of
maturity in its foundational development, making it time to conduct a
comprehensive survey. This paper explores Arabic MML by categorizing efforts
through a novel taxonomy and analyzing existing research. Our taxonomy
organizes these efforts into four key topics: datasets, applications,
approaches, and challenges. By providing a structured overview, this survey
offers insights into the current state of Arabic MML, highlighting areas that
have not been investigated and critical research gaps. Researchers will be
empowered to build upon the identified opportunities and address challenges to
advance the field.

</details>


### [181] [SEA-BED: Southeast Asia Embedding Benchmark](https://arxiv.org/abs/2508.12243)
*Wuttikorn Ponwitayarat,Raymond Ng,Jann Railey Montalan,Thura Aung,Jian Gang Ngui,Yosephine Susanto,William Tjhi,Panuthep Tasawong,Erik Cambria,Ekapol Chuangsuwanich,Sarana Nutanong,Peerat Limkonchotiwat*

Main category: cs.CL

TL;DR: SEA 지역을 위한 최초의 대규모 문장 임베딩 벤치마크 SEA-BED(169개 데이터셋, 9개 과제, 10개 언어)를 제안하고 17개 임베딩 모델을 평가해 기계 번역 기반 데이터의 한계와 인간 큐레이션의 중요성을 보여줌.


<details>
  <summary>Details</summary>
Motivation: 동남아시아(SEA)는 약 7억 명의 사용자가 있으나 다언어 임베딩 평가에서 저평가되어 왔고, 기존 벤치마크는 기계번역된 데이터가 많아 토착 언어의 특성을 반영하지 못함. 지역 특화 벤치마크가 필요함.

Method: SEA-BED를 구축(169개 데이터셋, 9개 태스크, 10개 언어; 71%는 인간 제작)하고 17개 임베딩 모델을 대상으로 6가지 연구(태스크·언어 난이도 분석, 크로스 벤치마크 비교, 인간 vs 기계 번역 영향 등)를 수행함.

Result: 모델 순위가 크게 변동하며 SEA 언어들 간 성능 일관성이 낮고, 저자원 언어(예: 버마어)에서 인간 큐레이션 데이터가 평가 신뢰도에 큰 영향을 미침. 기계 번역 기반 평가는 오탐·성능 과대/과소평가 가능.

Conclusion: SEA-BED는 지역 특화 평가의 필요성을 입증하며, 인간 제작 데이터의 확보와 언어·태스크별 세밀한 평가가 임베딩 연구·배포에 필수적임.

Abstract: Sentence embeddings are essential for NLP tasks such as semantic search,
re-ranking, and textual similarity. Although multilingual benchmarks like MMTEB
broaden coverage, Southeast Asia (SEA) datasets are scarce and often
machine-translated, missing native linguistic properties. With nearly 700
million speakers, the SEA region lacks a region-specific embedding benchmark.
We introduce SEA-BED, the first large-scale SEA embedding benchmark with 169
datasets across 9 tasks and 10 languages, where 71% are formulated by humans,
not machine generation or translation. We address three research questions: (1)
which SEA languages and tasks are challenging, (2) whether SEA languages show
unique performance gaps globally, and (3) how human vs. machine translations
affect evaluation. We evaluate 17 embedding models across six studies,
analyzing task and language challenges, cross-benchmark comparisons, and
translation trade-offs. Results show sharp ranking shifts, inconsistent model
performance among SEA languages, and the importance of human-curated datasets
for low-resource languages like Burmese.

</details>


### [182] [What do Speech Foundation Models Learn? Analysis and Applications](https://arxiv.org/abs/2508.12255)
*Ankita Pasad*

Main category: cs.CL

TL;DR: 경량의 통계적·학습-free 분석 프레임워크로 SFM(음성 파운더리 모델)의 층별 음향·언어 지식을 조사하고, SLU(특히 음성 NER/NEL)용 데이터셋과 E2E SFM 기반 방법을 제안해 E2E가 기존 cascaded 접근을 능가함을 보인 논문군.


<details>
  <summary>Details</summary>
Motivation: SFM의 수는 빠르게 증가하지만 내부에 어떤 지식이 어떻게 저장되는지, 그리고 이러한 모델들이 단순 ASR을 넘어 심층 SLU에 얼마나 유용한지에 대한 이해가 부족함. 또한 SLU 평가용 적절한 데이터셋이 부족함.

Method: 훈련이 필요 없는(statistics + training-free tasks) 경량 분석 도구를 개발해 여러 SFM의 층별 표현을 비교·분석. Spoken NER/NEL 태스크를 SLUE 벤치마크에 추가하고, SFM 기반 E2E 및 비교용 cascaded 모델들을 설계·평가. 다양한 적응 전략도 비교.

Result: 층별로 음향·언어적 특징의 분포와 모델 간 차이를 도출했고, 이러한 분석이 downstream 성능(특히 SLU)과 상관관계가 있음을 확인. 개발한 NER/NEL 태스크에서 E2E SFM 모델이 종종 cascaded 접근을 능가. 적응 전략에 따라 성능 편차 관찰.

Conclusion: SFM 내부 지식에 대한 접근성 있는 분석 도구와 SLU용 데이터셋을 제공해 연구자들이 모델 선택·적응 전략을 더 잘 결정할 수 있도록 함. 향후 SFM 설계·활용에 실용적 가이드라인을 제공함.

Abstract: Speech foundation models (SFMs) are designed to serve as general-purpose
representations for a wide range of speech-processing tasks. The last five
years have seen an influx of increasingly successful self-supervised and
supervised pre-trained models with impressive performance on various downstream
tasks.
  Although the zoo of SFMs continues to grow, our understanding of the
knowledge they acquire lags behind. This thesis presents a lightweight analysis
framework using statistical tools and training-free tasks to investigate the
acoustic and linguistic knowledge encoded in SFM layers. We conduct a
comparative study across multiple SFMs and statistical tools. Our study also
shows that the analytical insights have concrete implications for downstream
task performance.
  The effectiveness of an SFM is ultimately determined by its performance on
speech applications. Yet it remains unclear whether the benefits extend to
spoken language understanding (SLU) tasks that require a deeper understanding
than widely studied ones, such as speech recognition. The limited exploration
of SLU is primarily due to a lack of relevant datasets. To alleviate that, this
thesis contributes tasks, specifically spoken named entity recognition (NER)
and named entity localization (NEL), to the Spoken Language Understanding
Evaluation benchmark. We develop SFM-based approaches for NER and NEL, and find
that end-to-end (E2E) models leveraging SFMs can surpass traditional cascaded
(speech recognition followed by a text model) approaches. Further, we evaluate
E2E SLU models across SFMs and adaptation strategies to assess the impact on
task performance.
  Collectively, this thesis tackles previously unanswered questions about SFMs,
providing tools and datasets to further our understanding and to enable the
community to make informed design choices for future model development and
adoption.

</details>


### [183] [Structuring the Unstructured: A Systematic Review of Text-to-Structure Generation for Agentic AI with a Universal Evaluation Framework](https://arxiv.org/abs/2508.12257)
*Zheye Deng,Chunkit Chan,Tianshi Zheng,Wei Fan,Weiqi Wang,Yangqiu Song*

Main category: cs.CL

TL;DR: 이 논문은 비정형 텍스트를 표·지식그래프·차트 등 구조화된 형식으로 변환하는 기법들을 체계적으로 정리하고, 데이터셋·평가척도 한계를 분석한 뒤 범용 구조화 출력 평가 프레임워크를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 에이전트형 AI와 문맥 인지형 검색·응답이 보편화되며 비정형 텍스트를 기계가 활용 가능한 구조로 변환하는 기술이 핵심 인프라로 부상했다. 그러나 기법·데이터·평가 기준에 대한 종합적 정리가 부족해 연구와 실무 적용에 장애가 있다.

Method: 텍스트→구조 변환 기법들을 분류(예: 표 추출, 관계 추출, 엔티티 링크, 차트 생성), 관련 데이터셋과 평가 지표를 수집·비교·분석하고, 공통적 문제점(표현 불일치, 오답 전파, 평가 불균형 등)을 도출한 뒤 범용 평가 프레임워크를 설계·제안한다.

Result: 기존 방법론과 데이터셋의 강·약점을 규명하고, 구조화 출력의 일관성·정밀도·재현성 등을 포괄하는 평가 기준 세트를 제안했다. 또한 향후 연구 과제로 다국어·다중모달·인간검증 통합, 신뢰성·공정성 문제 해결을 제시했다.

Conclusion: 텍스트→구조 변환은 차세대 AI 시스템의 기반 인프라로 자리잡을 가능성이 크며, 제안된 범용 평가 프레임워크는 연구 비교·실용화 촉진을 위해 유용한 출발점이 된다.

Abstract: The evolution of AI systems toward agentic operation and context-aware
retrieval necessitates transforming unstructured text into structured formats
like tables, knowledge graphs, and charts. While such conversions enable
critical applications from summarization to data mining, current research lacks
a comprehensive synthesis of methodologies, datasets, and metrics. This
systematic review examines text-to-structure techniques and the encountered
challenges, evaluates current datasets and assessment criteria, and outlines
potential directions for future research. We also introduce a universal
evaluation framework for structured outputs, establishing text-to-structure as
foundational infrastructure for next-generation AI systems.

</details>


### [184] [Fast, Slow, and Tool-augmented Thinking for LLMs: A Review](https://arxiv.org/abs/2508.12265)
*Xinda Jia,Jinpeng Li,Zezhong Wang,Jingjing Li,Xingshan Zeng,Yasheng Wang,Weinan Zhang,Yong Yu,Weiwen Liu*

Main category: cs.CL

TL;DR: LLM의 추론 전략을 두 개의 경계(빠름/느림, 내부/외부)로 분류하는 새로운 분류법을 제안하고, 관련 연구를 체계적으로 검토해 적응형 추론의 핵심 결정요인과 향후 과제를 정리한다.


<details>
  <summary>Details</summary>
Motivation: 실제 문제는 요구에 따라 빠르고 직관적인 응답부터 느리고 단계적이며 도구를 활용한 추론까지 다양한 전략을 필요로 한다. 인지심리학에서 영감을 받아 LLM이 작업 특성에 맞게 추론 전략을 적응시켜야 한다는 점에서 출발한다.

Method: 두 경계(빠름/느림, 내부/외부)에 기반한 2차원 분류체계를 제시하고, 최근 연구들을 이 틀에 맞춰 체계적으로 분류·분석했다. 또한 적응적 추론을 결정하는 요인들(불확실성, 비용·시간 제약, 도구 가용성 등)을 정리했다.

Result: 분류법을 통해 다양한 방법(빠른 휴리스틱, chain-of-thought, 반성/재추론, 검색·회수 증강, 도구 연동 등)을 4개 범주로 매핑하고, 각 접근의 장단점과 적용 상황을 도출했다. 또한 적응형 전략을 위한 설계 고려사항과 기존 연구의 한계를 식별했다.

Conclusion: 적응적이고 효율적이며 신뢰할 수 있는 LLM 추론을 위해서는 자동화된 전략 선택(메타-컨트롤러), 실용적 평가기준, 도구 통합의 견고성 확보 등이 필요하다. 향후 연구로는 평가 벤치마크, 비용-성능 균형, 인간-기계 협업 모델 등이 제안된다.

Abstract: Large Language Models (LLMs) have demonstrated remarkable progress in
reasoning across diverse domains. However, effective reasoning in real-world
tasks requires adapting the reasoning strategy to the demands of the problem,
ranging from fast, intuitive responses to deliberate, step-by-step reasoning
and tool-augmented thinking. Drawing inspiration from cognitive psychology, we
propose a novel taxonomy of LLM reasoning strategies along two knowledge
boundaries: a fast/slow boundary separating intuitive from deliberative
processes, and an internal/external boundary distinguishing reasoning grounded
in the model's parameters from reasoning augmented by external tools. We
systematically survey recent work on adaptive reasoning in LLMs and categorize
methods based on key decision factors. We conclude by highlighting open
challenges and future directions toward more adaptive, efficient, and reliable
LLMs.

</details>


### [185] [The Self-Execution Benchmark: Measuring LLMs' Attempts to Overcome Their Lack of Self-Execution](https://arxiv.org/abs/2508.12277)
*Elon Ezra,Ariel Weizman,Amos Azaria*

Main category: cs.CL

TL;DR: LLM이 자기 출력의 속성을 예측하는 능력을 측정하는 Self-Execution Benchmark를 제안하고 평가한 결과, 대부분의 모델이 자기예측에 취약하며 모델 크기/능력 향상이 일관된 개선을 주지 못함을 보임.


<details>
  <summary>Details</summary>
Motivation: 기존 평가가 주로 지식·추론 능력을 테스트하는 반면, 모델이 자신의 답변을 예측(메타인지·자기모델링)할 수 있는지를 확인하는 새로운 평가 축이 필요하다고 봄. LLM은 스스로 실행할 수 없으므로 외부적 자기예측 능력을 측정해야 함.

Method: Self-Execution Benchmark를 설계해 질문 난이도 예측, 응답 거부 여부 예측, 생성될 연관(associations) 예측 등 다양한 속성을 모델에게 묻고 실제 출력과 비교. 여러 모델·크기에서 실험하여 성능을 측정하고 스케일링 효과를 분석.

Result: 대부분의 모델이 자기예측에서 낮은 성능을 보였고, 모델 크기나 전반적 성능이 증가해도 자기예측 능력은 일관되게 향상되지 않음.

Conclusion: LLM이 자신의 행동을 표현·추론하는 방식에 근본적 한계가 있음을 시사하며, 자기모델링 능력 향상을 위해 아키텍처·학습목표·추론메커니즘 재고가 필요함.

Abstract: Large language models (LLMs) are commonly evaluated on tasks that test their
knowledge or reasoning abilities. In this paper, we explore a different type of
evaluation: whether an LLM can predict aspects of its own responses. Since LLMs
lack the ability to execute themselves, we introduce the Self-Execution
Benchmark, which measures a model's ability to anticipate properties of its
output, such as whether a question will be difficult for it, whether it will
refuse to answer, or what kinds of associations it is likely to produce. Our
experiments show that models generally perform poorly on this benchmark, and
that increased model size or capability does not consistently lead to better
performance. These results suggest a fundamental limitation in how LLMs
represent and reason about their own behavior.

</details>


### [186] [Legal$Δ$: Enhancing Legal Reasoning in LLMs via Reinforcement Learning with Chain-of-Thought Guided Information Gain](https://arxiv.org/abs/2508.12281)
*Xin Dai,Buqiang Xu,Zhenghao Liu,Yukun Yan,Huiyuan Xie,Xiaoyuan Yi,Shuo Wang,Ge Yu*

Main category: cs.CL

TL;DR: LegalΔ는 법률 LLM의 해석 가능성·정확성을 높이기 위한 강화학습 프레임워크로, ‘직답 모드’와 ‘추론 보강 모드’ 사이의 정보 이득을 최대화하여 의미있는 체인-오브-생각(reasoning) 패턴을 학습한다. DeepSeek-R1이라는 강력한 대규모 추론모델에서 잠재적 추론 능력을 증류하고, 차등 비교와 다차원 보상(구조적 일관성·법률 특이성 등)으로 추론 품질을 정제한다. 레이블된 선호 데이터 없이 여러 법률 추론 과제에서 정확도와 해석 가능성 모두에서 강력한 베이스라인을 능가했다고 보고함.


<details>
  <summary>Details</summary>
Motivation: 기존 법률 특화 LLM들은 복잡한 법적 판단에서 엄격한 정당화가 필요한데도 빠른-생각(fast-thinking) 방식으로 직접 답변을 내놓고 명시적 다단계 추론을 생략해 신뢰성과 해석가능성이 떨어진다. 이를 개선하여 신뢰할 수 있는 법률 추론을 얻는 것이 동기이다.

Method: 강화학습 기반의 두-모드 입력 설계(직답 모드와 추론 보강 모드)를 사용해 두 모드 간의 정보 이득을 최대화함으로써 진정한 추론 패턴을 유도한다. 절차는 (1) 강력한 대규모 추론모델(LRM: DeepSeek-R1)로부터 잠재 추론 능력 증류, (2) 차등 비교(differential comparisons)와 다차원 보상(구조적 일관성·법률 도메인 특이성 등)으로 추론 품질을 정제하는 두 단계로 구성된다.

Result: 여러 법률 추론 태스크에서 강력한 베이스라인을 능가하며 정확도와 해석가능성에서 우수한 성능을 보였다고 보고. 레이블된 선호 데이터에 의존하지 않고도 더 견고하고 신뢰 가능한 법적 판단을 생성했다고 주장.

Conclusion: LegalΔ는 체인-오브-생각 유도 정보 이득을 통해 법률 LLM의 추론 품질과 해석가능성을 개선하는 실용적 접근을 제시하며, 공개된 코드·데이터를 통해 재현성과 검증 가능성을 제공할 예정임.

Abstract: Legal Artificial Intelligence (LegalAI) has achieved notable advances in
automating judicial decision-making with the support of Large Language Models
(LLMs). However, existing legal LLMs still struggle to generate reliable and
interpretable reasoning processes. They often default to fast-thinking behavior
by producing direct answers without explicit multi-step reasoning, limiting
their effectiveness in complex legal scenarios that demand rigorous
justification. To address this challenge, we propose Legal$\Delta$, a
reinforcement learning framework designed to enhance legal reasoning through
chain-of-thought guided information gain. During training, Legal$\Delta$
employs a dual-mode input setup-comprising direct answer and
reasoning-augmented modes-and maximizes the information gain between them. This
encourages the model to acquire meaningful reasoning patterns rather than
generating superficial or redundant explanations. Legal$\Delta$ follows a
two-stage approach: (1) distilling latent reasoning capabilities from a
powerful Large Reasoning Model (LRM), DeepSeek-R1, and (2) refining reasoning
quality via differential comparisons, combined with a multidimensional reward
mechanism that assesses both structural coherence and legal-domain specificity.
Experimental results on multiple legal reasoning tasks demonstrate that
Legal$\Delta$ outperforms strong baselines in both accuracy and
interpretability. It consistently produces more robust and trustworthy legal
judgments without relying on labeled preference data. All code and data will be
released at https://github.com/NEUIR/LegalDelta.

</details>


### [187] [Incorporating Legal Logic into Deep Learning: An Intelligent Approach to Probation Prediction](https://arxiv.org/abs/2508.12286)
*Qinghua Wang,Xu Zhang,Lingyan Yang,Rui Shao,Bonan Wang,Fang Wang,Cunquan Qu*

Main category: cs.CL

TL;DR: 논문은 보호관찰 예측을 위해 법적 요소(Probation Legal Elements)와 처벌의 이중경로 이론(Dual-Track Theory)을 딥러닝에 통합한 MT-DT 모델과 전용 데이터셋을 제안해, 기존 데이터 중심 접근보다 예측 성능과 법리적 타당성을 개선했다고 보고한다.


<details>
  <summary>Details</summary>
Motivation: 현행 지능형 사법보조시스템(IJAS)은 보호관찰 예측 전용 방법이 부족하고, 범죄 경위와 반성(뉘우침)을 함께 고려해야 하는 보호관찰 판정의 법리를 데이터 중심 모델이 충분히 반영하지 못함.

Method: 세 단계 접근: (1) 사실 진술과 보호관찰 법적 요소(PLE)를 포함한 전용 데이터셋 구축, (2) 법리와 Dual-Track Theory에 기반한 멀티태스크 모델인 Multi-Task Dual-Theory(MT-DT) 설계 및 구현, (3) 해당 데이터셋에서 베이스라인과 비교 평가 및 법리 기반 해석 분석 수행.

Result: MT-DT 모델이 제시된 데이터셋에서 베이스라인을 능가했으며, 법리 분석을 통해 모델 예측의 법적 타당성과 설명 가능성이 강화됨을 주장.

Conclusion: 법리(legal logic)를 딥러닝에 통합하는 방식이 보호관찰 예측에서 유용하며, IJAS에 법적 논리를 반영한 모델 설계가 실무적·학술적 의미를 가짐.

Abstract: Probation is a crucial institution in modern criminal law, embodying the
principles of fairness and justice while contributing to the harmonious
development of society. Despite its importance, the current Intelligent
Judicial Assistant System (IJAS) lacks dedicated methods for probation
prediction, and research on the underlying factors influencing probation
eligibility remains limited. In addition, probation eligibility requires a
comprehensive analysis of both criminal circumstances and remorse. Much of the
existing research in IJAS relies primarily on data-driven methodologies, which
often overlooks the legal logic underpinning judicial decision-making. To
address this gap, we propose a novel approach that integrates legal logic into
deep learning models for probation prediction, implemented in three distinct
stages. First, we construct a specialized probation dataset that includes fact
descriptions and probation legal elements (PLEs). Second, we design a distinct
probation prediction model named the Multi-Task Dual-Theory Probation
Prediction Model (MT-DT), which is grounded in the legal logic of probation and
the \textit{Dual-Track Theory of Punishment}. Finally, our experiments on the
probation dataset demonstrate that the MT-DT model outperforms baseline models,
and an analysis of the underlying legal logic further validates the
effectiveness of the proposed approach.

</details>


### [188] [CarelessWhisper: Turning Whisper into a Causal Streaming Model](https://arxiv.org/abs/2508.12301)
*Tomer Krichli,Bhiksha Raj,Joseph Keshet*

Main category: cs.CL

TL;DR: Transformers 기반의 오프라인 SOTA ASR 모델을 저지연(스트리밍)용으로 전환하기 위해, 비인과(enc->causal) 인코더로의 파인튜닝(LoRA + 약하게 정렬된 데이터)과 새로운 인퍼런스 방식을 제안하여 300ms 미만 청크에서 기존 비파인튜닝 스트리밍 기법들보다 성능·복잡도 면에서 우수함을 보였고, 단어 수준 타임스탬프 추출도 용이함.


<details>
  <summary>Details</summary>
Motivation: Whisper, Canary 같은 최신 transformer 기반 ASR은 오프라인 전사에서 SOTA를 달성했지만, 구조와 학습 방식 때문에 실시간(스트리밍) 전사에 직접 사용하기 어렵다. 실시간 전사에 필요한 낮은 지연과 미래 컨텍스트 무시 성능을 확보하려는 필요성이 동기임.

Method: (1) 기존 비인과(전역 컨텍스트) 인코더를 인과(causal) 인코더로 변환하기 위해 인코더·디코더를 LoRA로 파인튜닝, (2) 약하게 정렬된(weakly aligned) 데이터 사용으로 스트리밍 친화적 학습, (3) 파인튜닝된 인코더·디코더를 활용하는 갱신된 인퍼런스 알고리즘(그리디·빔서치 모두 지원) 제안 — 이 인퍼런스는 지역적 최적성을 만족하도록 설계됨.

Result: 저지연(청크 <300 ms) 환경에서 제안된 파인튜닝 모델이 비파인튜닝 스트리밍 기법들보다 대부분의 경우 더 좋은 성능을 보였고, 계산 복잡도는 낮음. 또한 학습 과정에서 정렬(align)이 개선되어 단어 단위 타임스탬프를 간단히 추출할 수 있게 됨. 학습/인퍼런스 코드와 파인튜닝 모델을 공개함.

Conclusion: LoRA 기반의 경량 파인튜닝과 약한 정렬 데이터, 그리고 변경된 인퍼런스로 encoder-decoder 트랜스포머를 실시간 스트리밍용으로 효과적으로 바꿀 수 있으며, 낮은 지연에서도 실용적 성능과 타임스탬핑 기능을 제공한다.

Abstract: Automatic Speech Recognition (ASR) has seen remarkable progress, with models
like OpenAI Whisper and NVIDIA Canary achieving state-of-the-art (SOTA)
performance in offline transcription. However, these models are not designed
for streaming (online or real-time) transcription, due to limitations in their
architecture and training methodology. We propose a method to turn the
transformer encoder-decoder model into a low-latency streaming model that is
careless about future context. We present an analysis explaining why it is not
straightforward to convert an encoder-decoder transformer to a low-latency
streaming model. Our proposed method modifies the existing (non-causal) encoder
to a causal encoder by fine-tuning both the encoder and decoder using Low-Rank
Adaptation (LoRA) and a weakly aligned dataset. We then propose an updated
inference mechanism that utilizes the fine-tune causal encoder and decoder to
yield greedy and beam-search decoding, and is shown to be locally optimal.
Experiments on low-latency chunk sizes (less than 300 msec) show that our
fine-tuned model outperforms existing non-fine-tuned streaming approaches in
most cases, while using a lower complexity. Additionally, we observe that our
training process yields better alignment, enabling a simple method for
extracting word-level timestamps. We release our training and inference code,
along with the fine-tuned models, to support further research and development
in streaming ASR.

</details>


### [189] [Consensus or Conflict? Fine-Grained Evaluation of Conflicting Answers in Question-Answering](https://arxiv.org/abs/2508.12355)
*Eviatar Nachshoni,Arie Cattan,Shmuel Amar,Ori Shapira,Ido Dagan*

Main category: cs.CL

TL;DR: 본 논문은 여러 정답이 존재할 수 있는 다중정답 질문(MAQA)에서 서로 충돌하는 답 쌍까지 식별하도록 확장한 새로운 벤치마크 NATCONFQA를 제시한다. 사실검증 데이터셋을 활용한 비용 효율적 구축법을 제안하고, 8개 고성능 LLM 평가 결과 모델들이 다양한 충돌 유형에 취약함을 보임.


<details>
  <summary>Details</summary>
Motivation: 기존 QA는 일관된 증거를 전제로 하는 경우가 많지만 현실의 MAQA는 상충하는 정답들을 포함한다. 충돌 정보를 갖춘 현실적인 데이터셋 생성은 비용·노력이 크고, 기존 벤치마크는 합성 데이터·yes/no 제한·자동 라벨링 검증 부족 등의 한계가 있다. 따라서 모델이 모든 유효 답변을 찾는 것뿐 아니라 특정 답 쌍의 충돌 여부까지 판별할 수 있어야 한다.

Method: 사실검증(fact-checking) 데이터셋을 비용 효율적으로 재활용하여, 모든 답변 쌍에 대해 상세한 충돌 레이블을 부여한 NATCONFQA를 구축한다. 충돌 인지 MAQA 문제 정의를 확장하고, 이를 평가할 수 있는 데이터 파이프라인과 레이블링 방식을 도입했다.

Result: NATCONFQA에서 8개 고급 LLM들을 평가한 결과, 모델들이 다양한 충돌 유형을 제대로 처리하지 못하고 잘못된 해결전략(예: 불확실성을 과도히 회피하거나 임의로 정합화)을 사용함을 확인했다.

Conclusion: 충돌을 명시적으로 다루는 MAQA는 중요하며, NATCONFQA는 현실적이고 상세한 충돌 레이블을 제공해 관련 연구를 촉진한다. 현행 LLM은 이 과제를 해결하기엔 취약하므로 향후 충돌 탐지·통합 전략 연구가 필요하다.

Abstract: Large Language Models (LLMs) have demonstrated strong performance in question
answering (QA) tasks. However, Multi-Answer Question Answering (MAQA), where a
question may have several valid answers, remains challenging. Traditional QA
settings often assume consistency across evidences, but MAQA can involve
conflicting answers. Constructing datasets that reflect such conflicts is
costly and labor-intensive, while existing benchmarks often rely on synthetic
data, restrict the task to yes/no questions, or apply unverified automated
annotation. To advance research in this area, we extend the conflict-aware MAQA
setting to require models not only to identify all valid answers, but also to
detect specific conflicting answer pairs, if any. To support this task, we
introduce a novel cost-effective methodology for leveraging fact-checking
datasets to construct NATCONFQA, a new benchmark for realistic, conflict-aware
MAQA, enriched with detailed conflict labels, for all answer pairs. We evaluate
eight high-end LLMs on NATCONFQA, revealing their fragility in handling various
types of conflicts and the flawed strategies they employ to resolve them.

</details>


### [190] [ReaLM: Reflection-Enhanced Autonomous Reasoning with Small Language Models](https://arxiv.org/abs/2508.12387)
*Yuanfeng Xu,Zehui Dai,Jian Liang,Jiapeng Guan,Guangrun Wang,Liang Lin,Xiaohui Lv*

Main category: cs.CL

TL;DR: ReaLM은 소형 언어모델(SLM)을 대상으로 강화학습 기반의 추론 강화 프레임워크로, 긍정·부정 추론 경로를 대비시켜 결정적 패턴을 추출하는 MRPV, 외부 신호를 점진적으로 줄이는 EAAI, 도메인 규칙을 모델 파라미터에 내재화하는 가이드된 chain-of-thought 증류를 결합해 추론 능력·자율성·일반화 성능을 동시에 개선한다.


<details>
  <summary>Details</summary>
Motivation: SLM은 비용 면에서 유리하지만 복합 추론에서 용량 부족과 다단계 추론 중 오류·불일치 문제에 취약하다. 기존 접근법은 부정적 사례 학습 배제, 외부 신호 의존, 교사 특화 패턴 과적합 등으로 추론 능력·자율성·일반화 중 적어도 하나를 희생한다는 한계가 있다.

Method: (1) MRPV: 긍정·부정 추론 경로를 대비시켜 결정적 특징을 학습하도록 보상·검증 메커니즘을 도입. (2) EAAI: 학습 과정에서 외부(교사) 신호를 점진적으로 약화시켜 자율적 추론 정책으로 수렴시키는 훈련 스케줄. (3) Guided CoT Distillation: 도메인 규칙·전문가 지식을 chain-of-thought 형태로 증류하여 SLM 파라미터에 내재화함으로써 일반화 촉진.

Result: 수직 도메인(vertically specialized) 및 일반 추론 과제에서 기존 방법 대비 SLM의 정확도·일관성·자율성이 유의하게 상승. MRPV로 부정적 경로를 활용해 오류 억제, EAAI로 외부 의존성 감소, 증류로 도메인 특화 규칙이 모델에 통합되는 효과 보고.

Conclusion: ReaLM은 MRPV, EAAI, guided CoT 증류를 결합해 SLM의 복합 추론 능력과 자율성, 일반화를 동시에 개선하는 실용적 접근을 제시한다. 다만 보상 설계, 부정 경로 생성 방식, 실험 세부(비교 대상·계산 비용) 등에 대한 명확한 기술이 논문의 재현성과 적용성에 중요하다.

Abstract: Small Language Models (SLMs) are a cost-effective alternative to Large
Language Models (LLMs), but often struggle with complex reasoning due to their
limited capacity and a tendency to produce mistakes or inconsistent answers
during multi-step reasoning. Existing efforts have improved SLM performance,
but typically at the cost of one or more of three key aspects: (1) reasoning
capability, due to biased supervision that filters out negative reasoning paths
and limits learning from errors; (2) autonomy, due to over-reliance on
externally generated reasoning signals; and (3) generalization, which suffers
when models overfit to teacher-specific patterns. In this paper, we introduce
ReaLM, a reinforcement learning framework for robust and self-sufficient
reasoning in vertical domains. To enhance reasoning capability, we propose
Multi-Route Process Verification (MRPV), which contrasts both positive and
negative reasoning paths to extract decisive patterns. To reduce reliance on
external guidance and improve autonomy, we introduce Enabling Autonomy via
Asymptotic Induction (EAAI), a training strategy that gradually fades external
signals. To improve generalization, we apply guided chain-of-thought
distillation to encode domain-specific rules and expert knowledge into SLM
parameters, making them part of what the model has learned. Extensive
experiments on both vertical and general reasoning tasks demonstrate that ReaLM
significantly improves SLM performance across aspects (1)-(3) above.

</details>


### [191] [MedKGent: A Large Language Model Agent Framework for Constructing Temporally Evolving Medical Knowledge Graph](https://arxiv.org/abs/2508.12393)
*Duzhen Zhang,Zixiao Wang,Zhong-Zhi Li,Yahan Yu,Shuncheng Jia,Jiahua Dong,Haotian Xu,Xing Wu,Yingying Zhang,Tielin Zhang,Jie Yang,Xiuying Chen,Le Song*

Main category: cs.CL

TL;DR: MedKGent는 1975–2023년 PubMed 초록(1,000만+건)을 일별로 시뮬레이트하여 Qwen2.5-32B 기반의 추출/구성 에이전트로 시간적·신뢰도 정보를 반영한 점진적 의료 지식그래프를 구축한 프레임워크로, 약 15만6천개 엔티티·297만여 관계를 생성하고 평가에서 약 90% 정확도 및 여러 QA·약물재창출 과제에서 성능 향상을 보고한다.


<details>
  <summary>Details</summary>
Motivation: 의학 문헌의 폭발적 증가로 인해 지식의 구조화·통합이 어렵고, 기존 KG 구축법은 일반화 능력이 떨어지거나 LLM 출력 단순 집계로 시간성·불확실성을 무시한다. 따라서 시간에 따라 변하는 의료 지식을 반영하고 추출 불확실성을 처리하는 방법이 필요하다.

Method: MedKGent는 Qwen2.5-32B-Instruct 기반의 두 에이전트(Extractor, Constructor)를 사용해 1975–2023년 PubMed 초록을 일별 시계열로 처리한다. Extractor는 샘플링 기반 신뢰도 점수를 포함한 지식 삼중항을 추출하고 낮은 신뢰도는 필터링한다. Constructor는 신뢰도와 타임스탬프를 활용해 점진적으로 그래프에 통합하여 반복적 지식은 강화하고 충돌은 해결한다.

Result: 최종 KG: 156,275개 엔티티, 2,971,384개 관계. 평가: 두 SOTA LLM 및 세 명의 도메인 전문가 평가에서 약 90% 정확도와 높은 평가자 일치도. downstream: 5개 주요 LLM을 대상으로 한 7개 의학 QA 벤치마크에서 RAG 보조 시 비증강 베이스라인 대비 일관된 성능 향상. 사례 연구: 신뢰도 인지 인과추론을 통한 문헌 기반 약물 재창출 사례 제시.

Conclusion: 시간적 역학과 불확실성을 반영한 LLM 에이전트 기반 점진적 KG 구축은 의학 문헌 기반의 검색·추론·지식발견에 실질적 이점을 제공한다. 다만 LLM 편향·추출 누락·계산 비용·전문가 검증 필요성 등 한계가 남아 있으며, 향후 교차모달 소스 통합, 더 많은 인간 피드백, 효율적 확장성 개선이 필요하다.

Abstract: The rapid expansion of medical literature presents growing challenges for
structuring and integrating domain knowledge at scale. Knowledge Graphs (KGs)
offer a promising solution by enabling efficient retrieval, automated
reasoning, and knowledge discovery. However, current KG construction methods
often rely on supervised pipelines with limited generalizability or naively
aggregate outputs from Large Language Models (LLMs), treating biomedical
corpora as static and ignoring the temporal dynamics and contextual uncertainty
of evolving knowledge. To address these limitations, we introduce MedKGent, a
LLM agent framework for constructing temporally evolving medical KGs.
Leveraging over 10 million PubMed abstracts published between 1975 and 2023, we
simulate the emergence of biomedical knowledge via a fine-grained daily time
series. MedKGent incrementally builds the KG in a day-by-day manner using two
specialized agents powered by the Qwen2.5-32B-Instruct model. The Extractor
Agent identifies knowledge triples and assigns confidence scores via
sampling-based estimation, which are used to filter low-confidence extractions
and inform downstream processing. The Constructor Agent incrementally
integrates the retained triples into a temporally evolving graph, guided by
confidence scores and timestamps to reinforce recurring knowledge and resolve
conflicts. The resulting KG contains 156,275 entities and 2,971,384 relational
triples. Quality assessments by two SOTA LLMs and three domain experts
demonstrate an accuracy approaching 90\%, with strong inter-rater agreement. To
evaluate downstream utility, we conduct RAG across seven medical question
answering benchmarks using five leading LLMs, consistently observing
significant improvements over non-augmented baselines. Case studies further
demonstrate the KG's value in literature-based drug repurposing via
confidence-aware causal inference.

</details>


### [192] [Extracting Post-Acute Sequelae of SARS-CoV-2 Infection Symptoms from Clinical Notes via Hybrid Natural Language Processing](https://arxiv.org/abs/2508.12405)
*Zilong Bai,Zihan Xu,Cong Sun,Chengxi Zang,H. Timothy Bunnell,Catherine Sinfield,Jacqueline Rutter,Aaron Thomas Martinez,L. Charles Bailey,Mark Weiner,Thomas R. Campion,Thomas Carton,Christopher B. Forrest,Rainu Kaushal,Fei Wang,Yifan Peng*

Main category: cs.CL

TL;DR: Hybrid NLP pipeline combining rule-based NER and BERT-based assertion detection to extract PASC symptoms from clinical notes; clinician-curated lexicon; 160 notes for development/evaluation and 47,654 notes for prevalence study; F1 0.82 internal, 0.76 external; runtime 2.448±0.812 s/note; strong Spearman correlations (>0.83 positive, >0.72 negative).


<details>
  <summary>Details</summary>
Motivation: PASC has myriad, temporally variable symptoms that make diagnosis from structured EHR fields unreliable; clinical notes contain relevant symptom information that requires robust extraction and assertion detection.

Method: Built a comprehensive PASC lexicon with clinicians. Pipeline: rule-based named-entity recognition for symptom mentions + BERT-based modules for assertion (presence/absence) classification. Curated 160 intake notes for model development and multi-site evaluation across 11 RECOVER health systems; applied pipeline to 47,654 notes for prevalence estimation.

Result: Assertion detection F1=0.82 (internal one-site) and 0.76 (10-site external). Processing time ~2.45 s per note. Spearman correlations for positive mentions ρ>0.83 and negative mentions ρ>0.72 (P<0.0001).

Conclusion: Pipeline shows promising accuracy and acceptable throughput for research-scale PASC extraction; demonstrates cross-site generalizability but would benefit from larger labeled sets, per-symptom metrics, error analysis, and operational optimization for large-scale deployment.

Abstract: Accurately and efficiently diagnosing Post-Acute Sequelae of COVID-19 (PASC)
remains challenging due to its myriad symptoms that evolve over long- and
variable-time intervals. To address this issue, we developed a hybrid natural
language processing pipeline that integrates rule-based named entity
recognition with BERT-based assertion detection modules for PASC-symptom
extraction and assertion detection from clinical notes. We developed a
comprehensive PASC lexicon with clinical specialists. From 11 health systems of
the RECOVER initiative network across the U.S., we curated 160 intake progress
notes for model development and evaluation, and collected 47,654 progress notes
for a population-level prevalence study. We achieved an average F1 score of
0.82 in one-site internal validation and 0.76 in 10-site external validation
for assertion detection. Our pipeline processed each note at $2.448\pm 0.812$
seconds on average. Spearman correlation tests showed $\rho >0.83$ for positive
mentions and $\rho >0.72$ for negative ones, both with $P <0.0001$. These
demonstrate the effectiveness and efficiency of our models and their potential
for improving PASC diagnosis.

</details>


### [193] [ZigzagAttention: Efficient Long-Context Inference with Exclusive Retrieval and Streaming Heads](https://arxiv.org/abs/2508.12407)
*Zhuorui Liu,Chen Zhang,Dawei Song*

Main category: cs.CL

TL;DR: KV 캐시 메모리 절약을 위해 어텐션 헤드를 '검색(retrieval)'과 '스트리밍(streaming)'으로 분류하고, 한 레이어에는 오직 한 종류의 헤드만 배치하도록 제약해 레이턴시를 줄이는 방법(ZigzagAttention)을 제안함. 성능 저하 거의 없이 메모리와 지연시간을 개선함.


<details>
  <summary>Details</summary>
Motivation: 긴 컨텍스트를 처리할 때 KV 캐시 메모리와 이에 따른 비용이 크게 증가한다. 기존 접근법은 중요하지 않은 스트리밍 헤드에서 KV 캐시를 생략해 메모리를 줄이지만, 한 레이어에 두 타입이 섞이면 어텐션 계산이 분할되어 텐서 접근/인덱싱 비용이 늘어나 레이턴시가 상승한다는 문제가 있다.

Method: 헤드 식별 기준을 개선해 한 레이어에 검색 헤드 또는 스트리밍 헤드만 존재하도록 강제하는 제약을 설계한다. 이를 통해 KV 캐시를 생략하는 이점은 살리되, 어텐션 연산의 분할로 인한 추가 레이턴시를 제거한다. 방법명은 ZigzagAttention.

Result: 제안 방법은 고려된 기준선들 대비 레이턴시를 줄이면서 성능(예: 정확도/언어 모델 성능) 저하를 미미하게 유지하여 경쟁력 있는 성능을 보임.

Conclusion: 헤드 타입을 레이어 단위로 분리하는 간단한 제약만으로도 KV 캐시 관련 메모리·레이턴시 문제를 효율적으로 완화할 수 있으며, 실무 적용 가능성이 높음.

Abstract: With the rapid development of large language models (LLMs), handling long
context has become one of the vital abilities in LLMs. Such long-context
ability is accompanied by difficulties in deployment, especially due to the
increased consumption of KV cache. There is certain work aiming to optimize the
memory footprint of KV cache, inspired by the observation that attention heads
can be categorized into retrieval heads that are of great significance and
streaming heads that are of less significance. Typically, identifying the
streaming heads and and waiving the KV cache in the streaming heads would
largely reduce the overhead without hurting the performance that much. However,
since employing both retrieval and streaming heads in one layer decomposes one
large round of attention computation into two small ones, it may unexpectedly
bring extra latency on accessing and indexing tensors. Based on this intuition,
we impose an important improvement to the identification process of retrieval
and streaming heads, in which we design a criterion that enforces exclusively
retrieval or streaming heads gathered in one unique layer. In this way, we
further eliminate the extra latency and only incur negligible performance
degradation. Our method named \textsc{ZigzagAttention} is competitive among
considered baselines owing to reduced latency and comparable performance.

</details>


### [194] [The Cultural Gene of Large Language Models: A Study on the Impact of Cross-Corpus Training on Model Values and Biases](https://arxiv.org/abs/2508.12411)
*Emanuel Z. Fenech-Borg,Tilen P. Meznaric-Kos,Milica D. Lekovic-Bojovic,Arni J. Hentze-Djurhuus*

Main category: cs.CL

TL;DR: LLM들이 학습 코퍼스에 담긴 체계적 가치경향(‘문화유전자’)을 반영하는지 CPD(200문항)를 사용해 GPT-4(서구중심)와 ERNIE Bot(동아시아중심)을 비교·검증했다. 두 모델은 개인주의·권력거리에서 유의미하게 다른 성향을 보였고, 각자 미국·중국의 호프스테데 지표와 높은 정렬을 보였다.


<details>
  <summary>Details</summary>
Motivation: 대형언어모델이 전 세계적으로 배포되지만, 이들의 문화적·윤리적 전제(가치지향)가 학습데이터를 통해 어떻게 스며드는지 체계적으로 규명할 필요가 있음. 알고리즘 문화적 패권 문제를 방지하고 다문화 환경에 맞는 평가·배치를 촉진하려는 목적.

Method: ‘문화유전자’ 개념을 제안하고, IDV(개인주의-집단주의)와 PDI(권력거리) 두 차원을 겨냥한 200개 프롬프트로 구성된 Cultural Probe Dataset(CPD)을 제작. 표준화된 제로샷 프롬프트로 GPT-4와 ERNIE Bot 응답을 수집하고 인간 주석으로 라벨링. 통계분석(유의성 검정) 및 호프스테데 국가점수 대비 Cultural Alignment Index(CAI) 계산. 질적 사례분석 병행.

Result: GPT-4는 개인주의·저권력거리 성향, ERNIE Bot은 집단주의·고권력거리 성향을 보였음(각 차이 p<0.001). CAI 결과 GPT-4는 미국 지표와, ERNIE Bot은 중국 지표와 높은 정렬을 나타냄. 질적 분석에서 딜레마 해결 방식과 권위 판단에서 차이가 드러남.

Conclusion: LLM은 학습 코퍼스의 문화적 가치경향을 통계적으로 반영하는 ‘거울’로 작동한다는 증거를 제시. 문화적 편향을 고려한 평가·배치·정책 설계가 필요함.

Abstract: Large language models (LLMs) are deployed globally, yet their underlying
cultural and ethical assumptions remain underexplored. We propose the notion of
a "cultural gene" -- a systematic value orientation that LLMs inherit from
their training corpora -- and introduce a Cultural Probe Dataset (CPD) of 200
prompts targeting two classic cross-cultural dimensions:
Individualism-Collectivism (IDV) and Power Distance (PDI). Using standardized
zero-shot prompts, we compare a Western-centric model (GPT-4) and an
Eastern-centric model (ERNIE Bot). Human annotation shows significant and
consistent divergence across both dimensions. GPT-4 exhibits individualistic
and low-power-distance tendencies (IDV score approx 1.21; PDI score approx
-1.05), while ERNIE Bot shows collectivistic and higher-power-distance
tendencies (IDV approx -0.89; PDI approx 0.76); differences are statistically
significant (p < 0.001). We further compute a Cultural Alignment Index (CAI)
against Hofstede's national scores and find GPT-4 aligns more closely with the
USA (e.g., IDV CAI approx 0.91; PDI CAI approx 0.88) whereas ERNIE Bot aligns
more closely with China (IDV CAI approx 0.85; PDI CAI approx 0.81). Qualitative
analyses of dilemma resolution and authority-related judgments illustrate how
these orientations surface in reasoning. Our results support the view that LLMs
function as statistical mirrors of their cultural corpora and motivate
culturally aware evaluation and deployment to avoid algorithmic cultural
hegemony.

</details>


### [195] [Uncovering Emergent Physics Representations Learned In-Context by Large Language Models](https://arxiv.org/abs/2508.12448)
*Yeongwoo Song,Jaeyong Bae,Dong-Kyum Kim,Hawoong Jeong*

Main category: cs.CL

TL;DR: 이 논문은 물리 기반 역학 예측을 통해 대형언어모델(LLM)의 인컨텍스트 학습(ICL) 능력을 조사한다. 입력 문맥이 길어질수록 예측 성능이 향상됨을 보이고, 잔여 스트림 활성화(residual stream)를 희소 오토인코더(SAE)로 분석해 에너지 같은 물리량과 상관관계가 있는 내재적 피처를 발견했다. 이는 LLM이 문맥 학습 중 물리적 개념을 내부에 인코딩함을 시사한다.


<details>
  <summary>Details</summary>
Motivation: LLM의 ICL 메커니즘이 다양한 실제 도메스틱 작업에서 어떻게 작동하는지 불명확하다. 물리 기반 태스크는 실험적으로 제어 가능한 실제 데이터와 구조적 역학을 제공하므로 ICL의 내적 구조와 의미론적 개념 인코딩을 탐구하기에 적합하다.

Method: 물리 시스템의 dynamics forecasting 태스크를 사용해 LLM의 ICL 성능을 평가. 입력 문맥 길이를 변형하며 성능 변화를 측정하고, 모델의 residual stream 활성화를 추출해 희소 오토인코더(SAE)로 학습시켜 잠재 피처를 분석했다. 이 피처들과 물리 변수 간 상관관계를 분석하여 의미 있는 개념의 존재를 검증.

Result: 긴 문맥에서 dynamics forecasting 성능이 향상되었고, SAE로 추출한 피처들이 에너지 같은 주요 물리 변수와 유의미한 상관관계를 보였다. 이는 모델이 문맥으로부터 물리적 개념을 학습했음을 시사한다.

Conclusion: LLM은 인컨텍스트 학습 중 내부 표현에 물리적 개념을 형성하며, SAE 기반 분석을 통해 이러한 개념을 식별할 수 있다. 물리 기반 태스크는 ICL의 메커니즘을 연구하기 위한 유용한 테스트베드가 된다.

Abstract: Large language models (LLMs) exhibit impressive in-context learning (ICL)
abilities, enabling them to solve wide range of tasks via textual prompts
alone. As these capabilities advance, the range of applicable domains continues
to expand significantly. However, identifying the precise mechanisms or
internal structures within LLMs that allow successful ICL across diverse,
distinct classes of tasks remains elusive. Physics-based tasks offer a
promising testbed for probing this challenge. Unlike synthetic sequences such
as basic arithmetic or symbolic equations, physical systems provide
experimentally controllable, real-world data based on structured dynamics
grounded in fundamental principles. This makes them particularly suitable for
studying the emergent reasoning behaviors of LLMs in a realistic yet tractable
setting. Here, we mechanistically investigate the ICL ability of LLMs,
especially focusing on their ability to reason about physics. Using a dynamics
forecasting task in physical systems as a proxy, we evaluate whether LLMs can
learn physics in context. We first show that the performance of dynamics
forecasting in context improves with longer input contexts. To uncover how such
capability emerges in LLMs, we analyze the model's residual stream activations
using sparse autoencoders (SAEs). Our experiments reveal that the features
captured by SAEs correlate with key physical variables, such as energy. These
findings demonstrate that meaningful physical concepts are encoded within LLMs
during in-context learning. In sum, our work provides a novel case study that
broadens our understanding of how LLMs learn in context.

</details>


### [196] [M3PO: Multimodal-Model-Guided Preference Optimization for Visual Instruction Following](https://arxiv.org/abs/2508.12458)
*Ruirui Gao,Emily Johnson,Bowen Tan,Yanfei Qian*

Main category: cs.CL

TL;DR: M3PO는 LVLM이 스스로 생성한 후보들 중에서 Multimodal Alignment Score(MAS)와 모델의 자신감(로그확률)을 결합한 M3P-Score로 학습 가치가 높은 선호(Preference) 쌍—특히 ‘hard negative’—을 선별해 Direct Preference Optimization(DPO)으로 효율적 미세조정하는 방법이다. LLaVA-1.5(7B/13B)+LoRA 실험에서 SFT, RLHF/시뮬레이션, vanilla DPO, RM-DPO보다 우수한 성능을 보였다.


<details>
  <summary>Details</summary>
Motivation: LVLM의 멀티모달 지시 수행 능력을 향상시키려면 많은 일관된 인간 레이블이 필요하지만, 비용과 일관성 문제로 제약된다. 기존 SFT와 선호 최적화 기법들은 모델 자체의 생성 공간에서 학습에 가치 있는 hard negative 샘플을 효율적으로 발굴하지 못한다.

Method: M3PO는 LVLM이 생성한 다양한 후보 응답 풀에서 외부 품질 신호(Multimodal Alignment Score, MAS)와 내부 신념(자기일관성/로그확률)을 결합해 M3P-Score를 계산한다. 이 점수를 통해 선호되는 답변과 모델이 자신 있게 잘못 생성할 가능성이 있는 어려운 비선호 답변을 선별하고, 이들 쌍으로 DPO(LoRA) 기반 미세조정을 수행한다.

Result: 다양한 멀티모달 지시 수행 벤치마크(MME-Bench, POPE, IFT, Human Preference Score)에서 SFT, 시뮬레이션 RLHF, vanilla DPO, RM-DPO를 일관되게 능가함을 보였다.

Conclusion: M3PO는 데이터 효율적이고 실용적인 방식으로 LVLM의 선호 정렬과 지시 수행 능력을 개선한다. 모델 내부 신념과 외부 정렬 신호의 결합을 통해 유익한 hard negative를 찾아내는 것이 핵심이다.

Abstract: Large Vision-Language Models (LVLMs) hold immense potential for complex
multimodal instruction following, yet their development is often hindered by
the high cost and inconsistency of human annotation required for effective
fine-tuning and preference alignment. Traditional supervised fine-tuning (SFT)
and existing preference optimization methods like RLHF and DPO frequently
struggle to efficiently leverage the model's own generation space to identify
highly informative "hard negative" samples. To address these challenges, we
propose Multimodal-Model-Guided Preference Optimization (M3PO), a novel and
data-efficient method designed to enhance LVLMs' capabilities in visual
instruction following. M3PO intelligently selects the most "learning-valuable"
preference sample pairs from a diverse pool of LVLM-generated candidates. This
selection is driven by a sophisticated mechanism that integrates two crucial
signals: a Multimodal Alignment Score (MAS) to assess external quality and the
model's Self-Consistency / Confidence (log-probability) to gauge internal
belief. These are combined into a novel M3P-Score, which specifically
identifies preferred responses and challenging dispreferred responses that the
model might confidently generate despite being incorrect. These high-quality
preference pairs are then used for efficient Direct Preference Optimization
(DPO) fine-tuning on base LVLMs like LLaVA-1.5 (7B/13B) using LoRA. Our
extensive experiments demonstrate that M3PO consistently outperforms strong
baselines, including SFT, simulated RLHF, vanilla DPO, and RM-DPO, across a
comprehensive suite of multimodal instruction following benchmarks (MME-Bench,
POPE, IFT, Human Pref. Score).

</details>


### [197] [LoraxBench: A Multitask, Multilingual Benchmark Suite for 20 Indonesian Languages](https://arxiv.org/abs/2508.12459)
*Alham Fikri Aji,Trevor Cohn*

Main category: cs.CL

TL;DR: LoraxBench는 인도네시아의 20개 언어(일부는 두 가지 격식 레지스터 포함)를 대상으로 6개 NLP 태스크로 구성된 저자원 언어 전용 벤치마크로, 평가에서 현행 다국어·지역 모델들 모두에 대해 도전적인 결과를 보였고 특히 인도네시아어 vs 저자원 언어 간 큰 성능 격차와 레지스터(예: 자바어 Krama)의 성능 민감성을 관찰했다.


<details>
  <summary>Details</summary>
Motivation: 인구가 많고 언어 다양성이 높지만 NLP 자원이 부족한 인도네시아어권의 실제 언어·문화 특성을 반영한 포괄적 벤치마크가 필요하다.

Method: 20개 언어(세 언어는 두 가지 격식 레지스터 포함)에서 독해, 개방형 QA, 언어추론, 인과추론, 번역, 문화 QA 등 6개 태스크를 수집·정의하고, 다양한 범용 다국어 모델과 지역 특화 대형언어모델(LLM)을 대상으로 성능 평가를 수행.

Result: 대부분 모델이 여전히 성능이 낮아 벤치마크가 도전적임을 보였고, 인도네시아어와 다른(특히 저자원) 언어들 간에 큰 성능 차이가 있었으며, 지역특화 모델이 항상 우세하지는 않았고, 레지스터 변화(예: Krama)는 모델 성능에 큰 영향을 미쳤다.

Conclusion: 인도네시아 저자원 언어와 사회문화적 레지스터를 다루는 연구 필요성을 강조하며, 모델·데이터 개선(저자원 전이학습, 레지스터 적응 등)과 더 정교한 평가의 필요성을 시사한다.

Abstract: As one of the world's most populous countries, with 700 languages spoken,
Indonesia is behind in terms of NLP progress. We introduce LoraxBench, a
benchmark that focuses on low-resource languages of Indonesia and covers 6
diverse tasks: reading comprehension, open-domain QA, language inference,
causal reasoning, translation, and cultural QA. Our dataset covers 20
languages, with the addition of two formality registers for three languages. We
evaluate a diverse set of multilingual and region-focused LLMs and found that
this benchmark is challenging. We note a visible discrepancy between
performance in Indonesian and other languages, especially the low-resource
ones. There is no clear lead when using a region-specific model as opposed to
the general multilingual model. Lastly, we show that a change in register
affects model performance, especially with registers not commonly found in
social media, such as high-level politeness `Krama' Javanese.

</details>


### [198] [Is GPT-OSS Good? A Comprehensive Evaluation of OpenAI's Latest Open Source Models](https://arxiv.org/abs/2508.12461)
*Ziqian Bi,Keyu Chen,Chiung-Yi Tseng,Danyang Zhang,Tianyang Wang,Hongying Luo,Lu Chen,Junming Huang,Jibin Guan,Junfeng Hao,Junhao Song*

Main category: cs.CL

TL;DR: GPT-OSS(20B)이 120B보다 여러 벤치마크에서 우수하며, 모형 규모를 늘린 MoE(혼합 전문가) 아키텍처의 성능 향상은 비례적이지 않다는 증거를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 오픈소스 대형언어모델 생태계에서 OpenAI의 새로운 공개 가중치 모델(GPT-OSS)의 성능을 현행 오픈 소스 모델들과 비교해, 희소(MoE) 아키텍처의 확장이 실제 성능 향상으로 이어지는지 평가하려는 목적.

Method: GPT-OSS 120B·20B(모두 MoE)와 6개 오픈소스 모델(14.7B–235B, 밀집·희소 포함)을 10개 벤치마크(일반 지식, 수학 추론, 코드 생성, 다국어 이해, 대화능력)에서 정규화된 추론 설정으로 비양자화 상태에서 평가. 통계적 유의성은 McNemar 검정과 효과크기 분석으로 검증.

Result: gpt-oss-20B가 HumanEval과 MMLU 등 여러 벤치마크에서 gpt-oss-120B보다 일관되게 우수. 20B는 응답 당 메모리·에너지 비용이 훨씬 낮음. 두 모델 모두 오픈소스 전체 군에서 중간 수준의 성능이며 코드 생성 강점, 다국어 약점이 관찰됨.

Conclusion: 희소 아키텍처에서 단순한 파라미터 수 확장은 비례적 성능 향상을 보장하지 않음. 효율성과 최적화 전략에 대한 추가 연구가 필요하며, 향후 오픈소스 배포 시 더 작은 모델의 선택이 비용·성능 측면에서 타당할 수 있음을 시사한다.

Abstract: In August 2025, OpenAI released GPT-OSS models, its first open weight large
language models since GPT-2 in 2019, comprising two mixture of experts
architectures with 120B and 20B parameters. We evaluated both variants against
six contemporary open source large language models ranging from 14.7B to 235B
parameters, representing both dense and sparse designs, across ten benchmarks
covering general knowledge, mathematical reasoning, code generation,
multilingual understanding, and conversational ability. All models were tested
in unquantised form under standardised inference settings, with statistical
validation using McNemars test and effect size analysis. Results show that
gpt-oss-20B consistently outperforms gpt-oss-120B on several benchmarks, such
as HumanEval and MMLU, despite requiring substantially less memory and energy
per response. Both models demonstrate mid-tier overall performance within the
current open source landscape, with relative strength in code generation and
notable weaknesses in multilingual tasks. These findings provide empirical
evidence that scaling in sparse architectures may not yield proportional
performance gains, underscoring the need for further investigation into
optimisation strategies and informing more efficient model selection for future
open source deployments.

</details>


### [199] [The Structural Sources of Verb Meaning Revisited: Large Language Models Display Syntactic Bootstrapping](https://arxiv.org/abs/2508.12482)
*Xiaomeng Zhu,R. Thomas McCoy,Robert Frank*

Main category: cs.CL

TL;DR: 대형 언어모델( RoBERTa, GPT-2 )이 구문 정보를 사용해 동사 의미를 학습하는지 실험. 구문 정보를 제거한 학습에서 동사 표현이 더 크게 손상되며, 특히 ‘정신 동사(mental verbs)’가 더 민감함. 반면 명사는 공기(공동출현) 교란에 더 민감. 결과는 구문 부트스트래핑 가설을 모델 수준에서 지지하고, LLM 학습 환경 조작을 통해 발달 심리학적 가설을 대규모로 테스트할 수 있음을 시사.


<details>
  <summary>Details</summary>
Motivation: 인간 언어 발달 이론(구문 부트스트래핑)이 아동의 동사 의미 학습에 구문 단서가 핵심적이라는 주장임. 이를 대형 언어모델에도 적용해 모델도 유사한 학습 전략을 쓰는지 확인하고, 구문 대 공동출현(코오커런스)의 상대적 중요성을 평가하려는 동기.

Method: RoBERTa와 GPT-2를 사용해 학습 데이터에서 구문 정보를 제거(구문 소거)하거나 단어 공동출현을 교란하는 방식으로 데이터 변형을 수행. 변형된 환경에서 학습한 모델들의 단어(특히 동사·명사) 표현(embedding/representation) 품질 변화를 비교 분석. 정신 동사 vs 물리 동사로 세부 비교.

Result: 구문 단서가 제거된 학습 환경에서 동사 표현의 손상이 공동출현 교란 때보다 더 큼. 정신 동사의 표현은 구문 소거의 영향을 물리 동사보다 더 크게 받음. 반대로 명사는 공동출현 교란에 더 민감하게 반응.

Conclusion: 동사 학습에서 구문 단서의 중요성(구문 부트스트래핑)이 LLM에도 나타나며, 학습 환경을 조작해 발달 이론을 대규모로 검증하는 접근이 실용적임.

Abstract: Syntactic bootstrapping (Gleitman, 1990) is the hypothesis that children use
the syntactic environments in which a verb occurs to learn its meaning. In this
paper, we examine whether large language models exhibit a similar behavior. We
do this by training RoBERTa and GPT-2 on perturbed datasets where syntactic
information is ablated. Our results show that models' verb representation
degrades more when syntactic cues are removed than when co-occurrence
information is removed. Furthermore, the representation of mental verbs, for
which syntactic bootstrapping has been shown to be particularly crucial in
human verb learning, is more negatively impacted in such training regimes than
physical verbs. In contrast, models' representation of nouns is affected more
when co-occurrences are distorted than when syntax is distorted. In addition to
reinforcing the important role of syntactic bootstrapping in verb learning, our
results demonstrated the viability of testing developmental hypotheses on a
larger scale through manipulating the learning environments of large language
models.

</details>


### [200] [Mitigating Hallucinations in Large Language Models via Causal Reasoning](https://arxiv.org/abs/2508.12495)
*Yuangang Li,Yiqing Shen,Yi Nian,Jiechao Gao,Ziyi Wang,Chenxiao Yu,Shawn Li,Jie Wang,Xiyang Hu,Yue Zhao*

Main category: cs.CL

TL;DR: LLM에 명시적 변수 수준의 인과 DAG 생성과 그래프 기반 추론을 학습시켜 논리적 불일치(환각)를 줄이고 인과 추론 성능을 향상시킨다. 새로운 CausalDR 데이터셋(25,368 샘플)을 제시하고 CDCR-SFT로 CLADDER에서 SOTA(95.33%) 및 HaluEval 환각 감소를 달성한다.


<details>
  <summary>Details</summary>
Motivation: 기존 CoT 등 문장·토큰 수준 추론은 변수 간 인과관계나 조건부 독립성 등을 포착하지 못해 LLM의 논리적 불일치(환각)를 유발한다는 문제 인식. 인과 구조를 명시적으로 모델링하면 추론의 일관성과 타당성이 개선될 것이라는 가정.

Method: CDCR-SFT: 지도학습 파인튜닝으로 LLM이 입력에서 변수 수준의 DAG를 구성하고, 그 DAG 위에서 그래프 기반 추론 트레이스를 생성하도록 학습. CausalDR 데이터셋은 각 샘플에 질문, 명시적 인과 DAG, 그래프 추론 트레이스, 검증된 정답을 포함.

Result: 여러 LLM과 8개 과제에서 평가하여 CLADDER에서 95.33%로 인간 성능(94.8%)을 최초로 초과하고, HaluEval에서 환각을 약 10% 감소시킴. 전반적으로 인과 구조 명시가 추론 일관성 및 성능 향상에 기여함.

Conclusion: 변수 수준의 인과 구조를 명시적으로 생성·활용하게 하면 LLM의 인과 추론 능력과 논리적 일관성을 크게 개선할 수 있으며, CDCR-SFT와 CausalDR 데이터셋이 이를 실증한다.

Abstract: Large language models (LLMs) exhibit logically inconsistent hallucinations
that appear coherent yet violate reasoning principles, with recent research
suggesting an inverse relationship between causal reasoning capabilities and
such hallucinations. However, existing reasoning approaches in LLMs, such as
Chain-of-Thought (CoT) and its graph-based variants, operate at the linguistic
token level rather than modeling the underlying causal relationships between
variables, lacking the ability to represent conditional independencies or
satisfy causal identification assumptions. To bridge this gap, we introduce
causal-DAG construction and reasoning (CDCR-SFT), a supervised fine-tuning
framework that trains LLMs to explicitly construct variable-level directed
acyclic graph (DAG) and then perform reasoning over it. Moreover, we present a
dataset comprising 25,368 samples (CausalDR), where each sample includes an
input question, explicit causal DAG, graph-based reasoning trace, and validated
answer. Experiments on four LLMs across eight tasks show that CDCR-SFT improves
the causal reasoning capability with the state-of-the-art 95.33% accuracy on
CLADDER (surpassing human performance of 94.8% for the first time) and reduces
the hallucination on HaluEval with 10% improvements. It demonstrates that
explicit causal structure modeling in LLMs can effectively mitigate logical
inconsistencies in LLM outputs. Code is available at
https://github.com/MrLYG/CDCR-SFT.

</details>


### [201] [CorrSteer: Steering Improves Task Performance and Safety in LLMs through Correlation-based Sparse Autoencoder Feature Selection](https://arxiv.org/abs/2508.12535)
*Seonglae Cho,Zekun Wu,Adriano Koshiyama*

Main category: cs.CL

TL;DR: CorrSteer는 추론 시 생성된 토큰의 SAE 활성화와 샘플 정답 여부의 상관관계를 이용해 의미있는 특징을 자동으로 선택하고 조절 계수를 계산함으로써 감독 신호나 대규모 활성화 저장 없이 SAE 기반 스티어링 성능을 크게 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 기존의 Sparse Autoencoders 기반 특징 선택은 대조 데이터셋이나 전체 활성화 저장을 필요로 해 실용성과 확장성이 떨어진다. 따라서 추론 시점의 정보만으로도 downstream 스티어링에 사용할 관련된 특징을 자동으로 뽑는 방법이 필요하다.

Method: 추론 중 생성된 토큰의 SAE 활성화와 샘플의 정답(또는 원하는 출력 속성) 사이의 상관관계를 계산해 유의미한 피처를 선택한다. 선택된 피처들의 평균 활성화로부터 스티어링 계수를 산출해 모델 출력 조정(억제/증강)을 수행한다. 전체 파이프라인은 대조표나 대규모 저장 없이 자동화됨.

Result: Gemma 2 2B 및 LLaMA 3.1 8B에서 QA, 편향 완화, jailbreaking 방지, 추론력 벤치마크에 대해 개선을 보고함. 예: MMLU +4.1%, HarmBench +22.9% (4,000 샘플). 선택된 피처는 각 태스크와 일치하는 의미적 패턴을 보임.

Conclusion: 추론 시 활성화-정답 상관 기반의 피처 선택은 SAE 스티어링에 대해 효과적이고 확장 가능하며, 라벨 샘플 수가 제한된 상황에서도 실용적인 향상을 제공한다.

Abstract: Sparse Autoencoders (SAEs) can extract interpretable features from large
language models (LLMs) without supervision. However, their effectiveness in
downstream steering tasks is limited by the requirement for contrastive
datasets or large activation storage. To address these limitations, we propose
CorrSteer, which selects features by correlating sample correctness with SAE
activations from generated tokens at inference time. This approach uses only
inference-time activations to extract more relevant features, thereby avoiding
spurious correlations. It also obtains steering coefficients from average
activations, automating the entire pipeline. Our method shows improved task
performance on QA, bias mitigation, jailbreaking prevention, and reasoning
benchmarks on Gemma 2 2B and LLaMA 3.1 8B, notably achieving a +4.1%
improvement in MMLU performance and a +22.9% improvement in HarmBench with only
4000 samples. Selected features demonstrate semantically meaningful patterns
aligned with each task's requirements, revealing the underlying capabilities
that drive performance. Our work establishes correlationbased selection as an
effective and scalable approach for automated SAE steering across language
model applications.

</details>


### [202] [Beyond Modality Limitations: A Unified MLLM Approach to Automated Speaking Assessment with Effective Curriculum Learning](https://arxiv.org/abs/2508.12591)
*Yu-Hsuan Fang,Tien-Hong Lo,Yao-Ting Sung,Berlin Chen*

Main category: cs.CL

TL;DR: MLLM(오디오+텍스트) 기반의 종합 자동 말하기 평가(ASA)를 처음으로 체계적으로 연구해, 내용(content)과 언어 사용(language use)에서는 성능이 우수하나 전달력(delivery) 평가는 어려워 SFMT라는 ‘음성 우선 커리큘럼 학습’으로 보완해 전체 PCC를 0.783→0.846으로 향상시키고, 전달력 평가에서 기존 대비 절대 4% 포인트 향상시켰다.


<details>
  <summary>Details</summary>
Motivation: 기존 ASA는 텍스트 기반이면 음향 정보가, 오디오 기반이면 의미 정보가 부족해 각 모달리티의 한계가 존재한다. MLLM은 오디오와 텍스트를 통합 처리할 수 있어 종합적 평가 가능성을 열지만 전달력 등 일부 측면에서는 도전이 필요하다.

Method: MLLM을 ASA에 적용해 내용·언어·전달 등 여러 평가 측면을 실험적으로 비교하고, 전달력 평가를 강화하기 위해 음성 표현을 먼저 학습한 뒤 교차 모달 융합을 진행하는 Speech-First Multimodal Training(SFMT)라는 커리큘럼 학습 전략을 제안.

Result: 벤치마크 데이터셋에서 MLLM 기반 시스템이 전체 종합 평가의 PCC를 0.783에서 0.846으로 개선. 특히 SFMT는 전달력 평가에서 기존 학습법 대비 절대 4% 포인트의 정확도 향상을 달성.

Conclusion: MLLM은 내용·언어 사용 평가에서 유망하며, 전달력 평가는 특별한 학습 전략이 필요하다. SFMT가 그 문제를 효과적으로 완화해 ASA 연구의 새로운 방향을 제시한다.

Abstract: Traditional Automated Speaking Assessment (ASA) systems exhibit inherent
modality limitations: text-based approaches lack acoustic information while
audio-based methods miss semantic context. Multimodal Large Language Models
(MLLM) offer unprecedented opportunities for comprehensive ASA by
simultaneously processing audio and text within unified frameworks. This paper
presents a very first systematic study of MLLM for comprehensive ASA,
demonstrating the superior performance of MLLM across the aspects of content
and language use . However, assessment on the delivery aspect reveals unique
challenges, which is deemed to require specialized training strategies. We thus
propose Speech-First Multimodal Training (SFMT), leveraging a curriculum
learning principle to establish more robust modeling foundations of speech
before cross-modal synergetic fusion. A series of experiments on a benchmark
dataset show MLLM-based systems can elevate the holistic assessment performance
from a PCC value of 0.783 to 0.846. In particular, SFMT excels in the
evaluation of the delivery aspect, achieving an absolute accuracy improvement
of 4% over conventional training approaches, which also paves a new avenue for
ASA.

</details>


### [203] [Semantic Anchoring in Agentic Memory: Leveraging Linguistic Structures for Persistent Conversational Context](https://arxiv.org/abs/2508.12630)
*Maitreyi Chatterjee,Devansh Agarwal*

Main category: cs.CL

TL;DR: Semantic Anchoring augments retrieval-augmented generation by storing dialogue history not only as dense vectors but also as structured linguistic cues (dependency parses, discourse relations, coreference), improving long-term factual recall and coherence.


<details>
  <summary>Details</summary>
Motivation: LLMs show strong short-term conversational ability but suffer in multi-session/long-term interactions because dense-vector memories capture semantic similarity but miss fine-grained linguistic structure needed to recall nuanced context-rich exchanges.

Method: Create hybrid memory entries combining dense embeddings with explicit linguistic annotations: dependency parsing, discourse relation tagging, and coreference resolution. Use these structured entries during retrieval to better match and reconstruct prior dialogue content.

Result: On adapted long-term dialogue datasets, Semantic Anchoring improves factual recall and discourse coherence by up to 18% over strong RAG baselines. The paper includes ablation studies, human evaluations, and error analysis demonstrating robustness and interpretability.

Conclusion: Adding explicit linguistic structure to vector-based memory improves recall and coherence in long-term dialogue agents and provides more interpretable memory traces, though trade-offs in complexity and parser robustness remain.

Abstract: Large Language Models (LLMs) have demonstrated impressive fluency and task
competence in conversational settings. However, their effectiveness in
multi-session and long-term interactions is hindered by limited memory
persistence. Typical retrieval-augmented generation (RAG) systems store
dialogue history as dense vectors, which capture semantic similarity but
neglect finer linguistic structures such as syntactic dependencies, discourse
relations, and coreference links. We propose Semantic Anchoring, a hybrid
agentic memory architecture that enriches vector-based storage with explicit
linguistic cues to improve recall of nuanced, context-rich exchanges. Our
approach combines dependency parsing, discourse relation tagging, and
coreference resolution to create structured memory entries. Experiments on
adapted long-term dialogue datasets show that semantic anchoring improves
factual recall and discourse coherence by up to 18% over strong RAG baselines.
We further conduct ablation studies, human evaluations, and error analysis to
assess robustness and interpretability.

</details>


### [204] [Beyond GPT-5: Making LLMs Cheaper and Better via Performance-Efficiency Optimized Routing](https://arxiv.org/abs/2508.12631)
*Yiqun Zhang,Hao Li,Jianhao Chen,Hangfan Zhang,Peng Ye,Lei Bai,Shuyue Hu*

Main category: cs.CL

TL;DR: Avengers-Pro는 질의 임베딩·클러스터링을 통해 런타임에 질의를 적절한 모델로 동적 라우팅하는 앙상블 프레임워크로, 성능·비용 간 트레이드오프 조절 파라미터로 다양한 배치의 성능-효율성을 달성한다. 여러 벤치마크에서 단일 최고 모델보다 더 높은 정확도 및 낮은 비용으로 동작하며, 비용-정확도 관점에서 파레토 프론티어를 달성한다.


<details>
  <summary>Details</summary>
Motivation: LLM 발전에서 높은 성능과 효율성(비용/지연)은 상충하는 목표다. 단일 대형 모델은 성능은 우수하지만 비용이 크고, 소형 모델은 저비용이나 성능이 낮다. 이를 런타임 라우팅으로 균형 있게 해결하려는 동기가 있다.

Method: 입력 질의를 임베딩하고 클러스터링하여 질의별 특성을 파악한 뒤, 성능-효율성 점수(조절 가능한 트레이드오프 파라미터에 기반)를 계산해 각 클러스터/질의를 가장 적합한 모델에 라우팅한다. 앙상블로 여러 용량·효율성의 LLM을 결합하고 라우팅 정책을 통해 비용과 성능을 제어한다.

Result: 6개 챌린징 벤치마크와 GPT-5-medium, Gemini-2.5-pro, Claude-opus-4.1 등을 포함한 8개 모델에서 평가하여, 트레이드오프 파라미터 조절 시 GPT-5-medium 대비 평균 정확도 +7% 달성, 같은 정확도를 27% 낮은 비용으로 유지, 약 90% 성능을 63% 낮은 비용으로 달성. 주어진 비용에서 최고 정확도, 주어진 정확도에서 최저 비용이라는 파레토 우위 결과를 보고한다.

Conclusion: Avengers-Pro는 런타임 라우팅과 모델 앙상블로 성능·비용 트레이드오프를 통합적으로 관리하는 실용적 프레임워크다. 다양한 모델 조합과 파라미터로 유연한 운영점을 제공하며, 코드가 공개되어 재현 가능성을 지원한다.

Abstract: Balancing performance and efficiency is a central challenge in large language
model (LLM) advancement. GPT-5 addresses this with test-time routing,
dynamically assigning queries to either an efficient or a high-capacity model
during inference. In this work, we present Avengers-Pro, a test-time routing
framework that ensembles LLMs of varying capacities and efficiencies, providing
a unified solution for all performance-efficiency tradeoffs. The Avengers-Pro
embeds and clusters incoming queries, then routes each to the most suitable
model based on a performance-efficiency score. Across 6 challenging benchmarks
and 8 leading models -- including GPT-5-medium, Gemini-2.5-pro, and
Claude-opus-4.1 -- Avengers-Pro achieves state-of-the-art results: by varying a
performance-efficiency trade-off parameter, it can surpass the strongest single
model (GPT-5-medium) by +7% in average accuracy. Moreover, it can match the
average accuracy of the strongest single model at 27% lower cost, and reach
~90% of that performance at 63% lower cost. Last but not least, it achieves a
Pareto frontier, consistently yielding the highest accuracy for any given cost,
and the lowest cost for any given accuracy, among all single models. Code is
available at https://github.com/ZhangYiqun018/AvengersPro.

</details>


### [205] [Prompt-Induced Linguistic Fingerprints for LLM-Generated Fake News Detection](https://arxiv.org/abs/2508.12632)
*Chi Wang,Min Gao,Zongwei Wang,Junwei Yin,Kai Shu,Chenghua Lin*

Main category: cs.CL

TL;DR: LIFE는 LLM이 악의적 프롬프트로 생성한 가짜뉴스에서 유발되는 단어 수준 확률 분포의 통계적 편이를 '언어적 지문'으로 추출해 검출하는 방법이다. 확률분포 재구성과 키-프래그먼트 기법으로 미세한 차이를 증폭시켜 SOTA 성능을 달성했다.


<details>
  <summary>Details</summary>
Motivation: 대형언어모델의 발전으로 가짜뉴스 생성이 쉬워졌고, 텍스트 자체만으로는 일관성 있고 사실적인 문장이 많아 기존 탐지법으로는 미세한 위조 흔적을 잡기 어렵다. 이에 프롬프트가 유발하는 분포적 편이에서 단서를 찾고자 한다.

Method: LLM에 악의적 프롬프트를 줬을 때 생성 텍스트의 단어 수준 확률분포에서 실제 뉴스와 가짜 뉴스가 보이는 통계적 차이를 분석한다. 단어별 확률분포를 재구성해 판별 가능한 패턴(언어적 지문)을 추출하고, 키-프래그먼트 기법으로 미세한 차이를 증폭시켜 분류에 활용한다.

Result: 제안한 LIFE가 LLM 기반 가짜뉴스 검출에서 SOTA 성능을 기록했으며, 인간 작성 가짜뉴스에 대해서도 높은 성능을 유지했다. 코드와 데이터 공개(링크 제공).

Conclusion: 프롬프트 유도 분포 편이를 이용한 언어적 지문은 LLM 생성 가짜뉴스 검출에 유용하지만, 접근 방식(모델 로그잇/블랙박스 여부), 일반화성, 적대적 회피에 대한 추가 검증이 필요하다.

Abstract: With the rapid development of large language models, the generation of fake
news has become increasingly effortless, posing a growing societal threat and
underscoring the urgent need for reliable detection methods. Early efforts to
identify LLM-generated fake news have predominantly focused on the textual
content itself; however, because much of that content may appear coherent and
factually consistent, the subtle traces of falsification are often difficult to
uncover. Through distributional divergence analysis, we uncover prompt-induced
linguistic fingerprints: statistically distinct probability shifts between
LLM-generated real and fake news when maliciously prompted. Based on this
insight, we propose a novel method named Linguistic Fingerprints Extraction
(LIFE). By reconstructing word-level probability distributions, LIFE can find
discriminative patterns that facilitate the detection of LLM-generated fake
news. To further amplify these fingerprint patterns, we also leverage
key-fragment techniques that accentuate subtle linguistic differences, thereby
improving detection reliability. Our experiments show that LIFE achieves
state-of-the-art performance in LLM-generated fake news and maintains high
performance in human-written fake news. The code and data are available at
https://anonymous.4open.science/r/LIFE-E86A.

</details>


### [206] [Breaking Language Barriers: Equitable Performance in Multilingual Language Models](https://arxiv.org/abs/2508.12662)
*Tanay Nagar,Grigorii Khvatskii,Anna Sokol,Nitesh V. Chawla*

Main category: cs.CL

TL;DR: 저자들은 합성 코드스위칭 텍스트로 LLM을 미세조정하면, 상용·저자원 언어(LRL)의 상식 추론 성능을 크게 향상시키고 고자원 언어(HRL) 성능은 유지·향상시킬 수 있음을 보였다. CommonSenseQA 기반의 세 가지 언어 혼합 비율 구성 합성 데이터셋도 공개한다.


<details>
  <summary>Details</summary>
Motivation: LLM이 저자원 언어로 프롬프트될 때 상식 추론 성능이 HRL(예: 영어)에 비해 낮아 공정성 문제가 발생한다. 동일한 품질의 LLM 출력을 다양한 언어 사용자에게 보장하기 위함.

Method: 제어된 언어 혼합(controlled language-mixing) 기법으로 CommonSenseQA 문항을 기반으로 합성 코드스위칭 텍스트를 생성한다. 이 합성 데이터셋의 세 가지 언어 비율 설정을 만들어 LLM을 미세조정(fine-tune)하여 LRL 성능 향상을 유도한다.

Result: 합성 코드스위칭 데이터로 미세조정한 모델은 저자원 언어에서 성능이 크게 향상되며, 동시에 고자원 언어의 성능도 유지하거나 향상된다는 실험적 근거를 제시한다.

Conclusion: 합성 코드스위칭으로 미세조정하는 접근법은 LRL과 HRL 간의 성능 격차를 줄이는 실용적 방법이며, 제시한 데이터셋은 관련 연구와 평가에 유용하다.

Abstract: Cutting-edge LLMs have emerged as powerful tools for multilingual
communication and understanding. However, LLMs perform worse in Common Sense
Reasoning (CSR) tasks when prompted in low-resource languages (LRLs) like Hindi
or Swahili compared to high-resource languages (HRLs) like English. Equalizing
this inconsistent access to quality LLM outputs is crucial to ensure fairness
for speakers of LRLs and across diverse linguistic communities. In this paper,
we propose an approach to bridge this gap in LLM performance. Our approach
involves fine-tuning an LLM on synthetic code-switched text generated using
controlled language-mixing methods. We empirically demonstrate that fine-tuning
LLMs on synthetic code-switched datasets leads to substantial improvements in
LRL model performance while preserving or enhancing performance in HRLs.
Additionally, we present a new dataset of synthetic code-switched text derived
from the CommonSenseQA dataset, featuring three distinct language ratio
configurations.

</details>


### [207] [Leveraging Large Language Models for Predictive Analysis of Human Misery](https://arxiv.org/abs/2508.12669)
*Bishanka Seal,Rahul Seetharaman,Aman Bansal,Abhilash Nandy*

Main category: cs.CL

TL;DR: 이 논문은 자연어로 표현된 상황에서 인간이 느끼는 '고통(불행) 점수'를 0-100 범위의 연속값으로 예측하는 작업에 LLM을 적용한 연구다. 제로샷, 고정 컨텍스트 몇 가지 예시, BERT 임베딩 기반 검색-기반 프롬프트를 비교했으며, few-shot이 제로샷보다 우수했다. 또한 "Misery Game Show"라는 게임화된 평가 프레임워크를 제안해 모델의 순위 비교, 이진 분류, 스칼라 추정, 피드백 기반 추론 적응 능력을 평가했다.


<details>
  <summary>Details</summary>
Motivation: 정적 회귀 평가를 넘어, LLM이 감정적·정서적 판단을 얼마나 잘 수행하고 교정 피드백을 통해 적응할 수 있는지 평가하고자 함. 또한 프롬프트 전략(특히 예시 제공과 검색기반 샘플링)이 예측 성능에 미치는 영향을 탐구하려 함.

Method: 작업을 0-100 연속 스칼라 회귀로 정의. 프롬프트 전략으로 제로샷, 고정-context few-shot, BERT 문장 임베딩을 이용한 검색 기반 few-shot을 적용. 평가를 위해 새로운 게임화된 절차인 'Misery Game Show'를 고안: 여러 라운드(순서 비교, 이진 분류, 스칼라 추정, 피드백 라운드)를 통해 정확도와 피드백 적응력을 측정.

Result: few-shot(특히 검색 기반 샘플 선택 포함)이 제로샷보다 일관되게 성능이 좋았음. 게임쇼 평가에서 LLM은 표준 회귀 지표(예: MAE, MSE)뿐 아니라 피드백을 반영하여 예측을 조정하는 능력을 보여, 동적 감정 추론 과제에서도 잠재력 시사.

Conclusion: 문맥 예시(특히 검색 기반 예시 선택)는 감정적 스칼라 예측에서 중요하며, 게임화된 피드백 기반 평가로 LLM의 적응적 감정 추론 능력을 효과적으로 측정할 수 있다. 향후 작업에서는 더 다양한 도메인과 인간-모델 상호작용 실험이 필요하다.

Abstract: This study investigates the use of Large Language Models (LLMs) for
predicting human-perceived misery scores from natural language descriptions of
real-world scenarios. The task is framed as a regression problem, where the
model assigns a scalar value from 0 to 100 to each input statement. We evaluate
multiple prompting strategies, including zero-shot, fixed-context few-shot, and
retrieval-based prompting using BERT sentence embeddings. Few-shot approaches
consistently outperform zero-shot baselines, underscoring the value of
contextual examples in affective prediction. To move beyond static evaluation,
we introduce the "Misery Game Show", a novel gamified framework inspired by a
television format. It tests LLMs through structured rounds involving ordinal
comparison, binary classification, scalar estimation, and feedback-driven
reasoning. This setup enables us to assess not only predictive accuracy but
also the model's ability to adapt based on corrective feedback. The gamified
evaluation highlights the broader potential of LLMs in dynamic emotional
reasoning tasks beyond standard regression. Code and data link:
https://github.com/abhi1nandy2/Misery_Data_Exps_GitHub

</details>


### [208] [ToolACE-MT: Non-Autoregressive Generation for Agentic Multi-Turn Interaction](https://arxiv.org/abs/2508.12685)
*Xingshan Zeng,Weiwen Liu,Lingzhi Wang,Liangyou Li,Fei Mi,Yasheng Wang,Lifeng Shang,Xin Jiang,Qun Liu*

Main category: cs.CL

TL;DR: ToolACE-MT는 비자동회귀(Non-Autoregressive) 반복 생성 프레임워크로, 툴을 사용하는 다중턴 에이전트 대화를 세 단계(초기 골격 생성, 마스크-앤-필 기반 반복 정제, 오프라인 검증)로 만들어 고품질·저비용의 시뮬레이션 데이터를 생성한다.


<details>
  <summary>Details</summary>
Motivation: 에이전트형 과제(멀티턴·멀티스텝, 복잡한 함수 호출 등)는 현실적 시뮬레이션 데이터가 필요한데, 기존 방법은 여러 LLM 간의 고비용 자동회귀 상호작용에 의존해 확장성과 실제 성능을 제한한다.

Method: ToolACE-MT는 (1) 구조적으로 완전하지만 의미상 거친 대화 골격을 초기화, (2) 마스크-앤-필(mask-and-fill) 연산을 통해 현실적 복잡성을 점진적으로 도입하며 반복 정제, (3) 규칙·모델 기반의 오프라인 검증으로 정확성·일관성 확보 — 이 과정을 통해 전체 대화 궤적을 비자동회귀 방식으로 생성한다.

Result: 실험에서 ToolACE-MT는 데이터 생성 효율성과 품질, 일반화 측면에서 이점을 보였고, 툴 보강 LLM 시나리오에서 고품질 데이터 구축의 새로운 패러다임을 제시한다.

Conclusion: ToolACE-MT는 계산 비용을 낮추면서 현실감 있고 정확한 다중턴 에이전트 대화 데이터를 대규모로 생성할 수 있는 실용적 방법을 제공해, 툴-증강 LLM 연구·응용의 데이터 병목을 완화할 잠재력이 있다.

Abstract: Agentic task-solving with Large Language Models (LLMs) requires multi-turn,
multi-step interactions, often involving complex function calls and dynamic
user-agent exchanges. Existing simulation-based data generation methods for
such scenarios rely heavily on costly autoregressive interactions between
multiple LLM agents, thereby limiting real-world performance of agentic tasks.
In this paper, we propose a novel Non-Autoregressive Iterative Generation
framework, called ToolACE-MT, for constructing high-quality multi-turn agentic
dialogues. ToolACE-MT generates full conversational trajectories through three
stages: coarse-grained initialization, iterative refinement, and offline
verification. The initialization phase builds a structurally complete yet
semantically coarse dialogue skeleton; the iterative refinement phase
introduces realistic complexities and continued refinement via mask-and-fill
operations; and the offline verification phase ensures correctness and
coherence via rule- and model-based checks. Experiments demonstrate that
ToolACE-MT enables efficient, effective and generalizable agentic data
generation, offering a new paradigm for high-quality data construction in
tool-augmented LLM scenarios.

</details>


### [209] [DESIGNER: Design-Logic-Guided Multidisciplinary Data Synthesis for LLM Reasoning](https://arxiv.org/abs/2508.12726)
*Weize Liu,Yongchi Zhao,Yijia Luo,Mingyu Xu,Jiaheng Liu,Yanan Li,Xiguo Hu,Yuchi Xu,Wenbo Su,Bo Zheng*

Main category: cs.CL

TL;DR: DESIGNER는 ‘Design Logic’ 개념을 도입해 책·웹 코퍼스에서 역설계한 12만개 이상의 설계 논리를 활용, 75개 학문에 걸쳐 총 4.7M개(책 3.04M, 웹 1.66M)의 다단계 추론 문제를 합성한 파이프라인이다. 합성 데이터는 난이도·다양성에서 기존 데이터셋을 능가하며, Qwen3-8B/4B 기반의 SFT 실험에서 성능 향상을 입증했다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어모델은 다단계·학제간 추론에서 약점을 보이나, 기존 데이터셋은 학문적 범위나 문제 구조의 깊이에서 한계가 있어 더 어렵고 다양한 추론 문제가 필요하다.

Method: ‘Design Logic’(문제 설계 논리) 개념을 도입하여 LLM로부터 기존 문제들로부터 12만개 이상의 설계 논리를 역추출하고, 이를 책 및 웹 소스와 매칭해 높은 난이도의 질문을 자동 합성하는 DESIGNER 파이프라인을 설계·구현. 결과로 DLR-Book(3.04M)과 DLR-Web(1.66M)을 생성.

Result: 합성된 문제들은 난이도와 다양성 면에서 기준 데이터셋을 크게 상회. Qwen3-8B-Base 및 Qwen3-4B-Base에 SFT를 수행한 결과, 동일 규모의 기존 다분야 데이터셋보다 유의미한 성능 향상을 보였고, 전체 데이터로 학습시 공식 Qwen3 모델 성능을 능가함.

Conclusion: DESIGNER와 DLR 데이터셋은 학제간·다단계 추론 능력 향상에 효과적이며, 대규모·다양한 추론 학습 자료로 활용 가능. 다만 LLM 기반 역설계 과정의 품질·편향·노이즈 검증과 실제 인간 출제자 기준과의 일치성 등 추가 검증이 필요하다.

Abstract: Large language models (LLMs) have achieved remarkable success in many natural
language tasks but still struggle with complex, multi-step reasoning,
particularly across diverse disciplines. Existing reasoning datasets often
either lack disciplinary breadth or the structural depth necessary to elicit
robust reasoning behaviors. We propose DESIGNER: a DESIGN-logic-guidEd
Reasoning data synthesis pipeline that leverages naturally available, extensive
raw documents (book corpus and web corpus) to generate multidisciplinary
challenging questions. A core innovation of our approach is the introduction of
a Design Logic concept, which mimics the question-creation process of human
educators. We use LLMs to reverse-engineer and abstract over 120,000 design
logics from existing questions across various disciplines. By matching these
design logics with disciplinary source materials, we are able to create
reasoning questions that far surpass the difficulty and diversity of existing
datasets. Based on this pipeline, we synthesized two large-scale reasoning
datasets that span 75 disciplines: Design-Logic-Reasoning-Book (DLR-Book),
containing 3.04 million challenging questions synthesized from the book corpus,
and Design-Logic-Reasoning-Web (DLR-Web), with 1.66 million challenging
questions from the web corpus. Our data analysis demonstrates that the
questions synthesized by our method exhibit substantially greater difficulty
and diversity than those in the baseline datasets. We validate the
effectiveness of these datasets by conducting SFT experiments on the
Qwen3-8B-Base and Qwen3-4B-Base models. The results show that our dataset
significantly outperforms existing multidisciplinary datasets of the same
volume. Training with the full datasets further enables the models to surpass
the multidisciplinary reasoning performance of the official Qwen3-8B and
Qwen3-4B models.

</details>


### [210] [LinguaSafe: A Comprehensive Multilingual Safety Benchmark for Large Language Models](https://arxiv.org/abs/2508.12733)
*Zhiyuan Ning,Tianle Gu,Jiaxin Song,Shixin Hong,Lingyu Li,Huacan Liu,Jie Li,Yixu Wang,Meng Lingyu,Yan Teng,Yingchun Wang*

Main category: cs.CL

TL;DR: LinguaSafe는 12개 언어(헝가리어→말레이어 포함)로 구성된 45k 항목의 다국어 안전성 벤치마크로, 번역·재창작·원어민 소스 혼합으로 구축되었으며 직접·간접 안전성 평가와 과민반응(oversensitivity) 검사를 포함한 다차원 정밀 평가 프레임워크를 제공한다. 평가 결과는 도메인·언어별로 크게 달라지며 데이터와 코드가 공개된다.


<details>
  <summary>Details</summary>
Motivation: 기존 다국어 LLM 안전성 평가가 데이터 다양성·언어적 정통성에서 부족하여 다문화·저자원 언어에 대한 안전성 정렬이 불충분하다는 문제를 해결하고자 함.

Method: 12개 언어, 총 45k 샘플을 번역(translated), 재창작(transcreated), 원어민 수집(natively-sourced) 방식으로 큐레이션. 직접·간접 유해성 평가 지표를 포함한 세부적·다차원 안전성 프레임워크 설계 및 과민반응(oversensitivity) 추가 평가 수행. 종합적 평가 메트릭스 제공.

Result: 모델의 안전성·도움됨 평가가 언어와 도메인에 따라 크게 다르며, 유사 자원 수준의 언어들 사이에서도 편차가 존재함. 벤치마크는 상세한 측정값을 제공하여 다국어 안전성 정렬의 불균형을 드러냄.

Conclusion: LinguaSafe는 저자원·다양한 언어에 대한 LLM 안전성 평가 공백을 메우며, 공개 데이터·코드를 통해 후속 연구와 보다 균형 잡힌 다국어 안전성 정렬을 촉진할 수 있다.

Abstract: The widespread adoption and increasing prominence of large language models
(LLMs) in global technologies necessitate a rigorous focus on ensuring their
safety across a diverse range of linguistic and cultural contexts. The lack of
a comprehensive evaluation and diverse data in existing multilingual safety
evaluations for LLMs limits their effectiveness, hindering the development of
robust multilingual safety alignment. To address this critical gap, we
introduce LinguaSafe, a comprehensive multilingual safety benchmark crafted
with meticulous attention to linguistic authenticity. The LinguaSafe dataset
comprises 45k entries in 12 languages, ranging from Hungarian to Malay. Curated
using a combination of translated, transcreated, and natively-sourced data, our
dataset addresses the critical need for multilingual safety evaluations of
LLMs, filling the void in the safety evaluation of LLMs across diverse
under-represented languages from Hungarian to Malay. LinguaSafe presents a
multidimensional and fine-grained evaluation framework, with direct and
indirect safety assessments, including further evaluations for oversensitivity.
The results of safety and helpfulness evaluations vary significantly across
different domains and different languages, even in languages with similar
resource levels. Our benchmark provides a comprehensive suite of metrics for
in-depth safety evaluation, underscoring the critical importance of thoroughly
assessing multilingual safety in LLMs to achieve more balanced safety
alignment. Our dataset and code are released to the public to facilitate
further research in the field of multilingual LLM safety.

</details>


### [211] [CRED-SQL: Enhancing Real-world Large Scale Database Text-to-SQL Parsing through Cluster Retrieval and Execution Description](https://arxiv.org/abs/2508.12769)
*Shaoming Duan,Zirui Wang,Chuanyi Liu,Zhibin Zhu,Yuhao Zhang,Peiyi Han,Liang Yan,Zewu Penge*

Main category: cs.CL

TL;DR: CRED-SQL은 대규모 DB에서 NL 질문과 SQL 간의 의미 불일치를 줄이기 위해 군집 기반 스키마 검색과 중간 자연어 표현(Execution Description Language, EDL)을 결합한 프레임워크다. Text-to-EDL과 EDL-to-SQL의 두 단계로 분해하여 LLM의 추론력을 활용하고 의미 편향을 완화한다.


<details>
  <summary>Details</summary>
Motivation: 대규모·교차 도메인 데이터베이스에서는 유사한 속성들이 많아 스키마 연결이 어렵고, LLM이 질문 의도에서 벗어나 SQL을 생성하는 의미적 이탈(semantic drift)이 발생해 정확도가 떨어진다.

Method: (1) 클러스터 기반 대규모 스키마 검색으로 NLQ에 관련된 테이블·컬럼을 우선 선별하여 스키마 불일치를 완화한다. (2) 중간 표현인 EDL(Execution Description Language)을 도입해 NLQ→EDL, EDL→SQL의 두 단계로 분해함으로써 LLM의 일반적 추론능력을 활용하고 의미적 편향을 줄인다.

Result: SpiderUnion 및 BirdUnion의 대규모 교차 도메인 벤치마크에서 SOTA 성능을 달성했다(논문 주장). 스케일과 효과성 측면에서 유효함을 보였으며 코드가 공개되어 있다.

Conclusion: 스키마 검색과 중간 자연어 표현의 결합은 대규모 DB의 Text-to-SQL에서 의미 일치 문제를 효과적으로 완화하고, LLM 기반 파이프라인의 정확도와 확장성을 개선한다.

Abstract: Recent advances in large language models (LLMs) have significantly improved
the accuracy of Text-to-SQL systems. However, a critical challenge remains: the
semantic mismatch between natural language questions (NLQs) and their
corresponding SQL queries. This issue is exacerbated in large-scale databases,
where semantically similar attributes hinder schema linking and semantic drift
during SQL generation, ultimately reducing model accuracy. To address these
challenges, we introduce CRED-SQL, a framework designed for large-scale
databases that integrates Cluster Retrieval and Execution Description. CRED-SQL
first performs cluster-based large-scale schema retrieval to pinpoint the
tables and columns most relevant to a given NLQ, alleviating schema mismatch.
It then introduces an intermediate natural language representation-Execution
Description Language (EDL)-to bridge the gap between NLQs and SQL. This
reformulation decomposes the task into two stages: Text-to-EDL and EDL-to-SQL,
leveraging LLMs' strong general reasoning capabilities while reducing semantic
deviation. Extensive experiments on two large-scale, cross-domain
benchmarks-SpiderUnion and BirdUnion-demonstrate that CRED-SQL achieves new
state-of-the-art (SOTA) performance, validating its effectiveness and
scalability. Our code is available at https://github.com/smduan/CRED-SQL.git

</details>


### [212] [From SALAMANDRA to SALAMANDRATA: BSC Submission for WMT25 General Machine Translation Shared Task](https://arxiv.org/abs/2508.12774)
*Javier Garcia Gilabert,Xixian Liao,Severino Da Dalt,Ella Bohman,Audrey Mash,Francesca De Luca Fornaciari,Irene Baucells,Joan Llop,Miguel Claramunt Argote,Carlos Escolano,Maite Melero*

Main category: cs.CL

TL;DR: SALAMANDRATA는 병렬 데이터로의 연속 사전학습과 고품질 지침 기반 감독 미세조정을 결합한 2B/7B 규모의 번역 특화 LLM 계열로, WMT25에 7B 모델로 참가했고 다양한 언어·디코딩 전략(MBR, 재순위)을 사용해 성능을 최적화함.


<details>
  <summary>Details</summary>
Motivation: 기존 SALAMANDRA LLM을 개선하여 유럽어 38개 및 추가 비유럽어를 포함한 번역 품질을 크게 끌어올리려는 목적. 특히 WMT25 다방향 번역 태스크에서 경쟁력 확보가 목표.

Method: 두 단계 학습: (1) 병렬 코퍼스를 이용한 연속(pre-)사전학습으로 번역 능력 강화, (2) 고품질 지침 데이터로 감독 미세조정. 어휘를 확장해 비유럽어 지원을 추가하고, 디코딩 시 MBR과 COMET/COMET-KIWI 기반의 튜닝된 재순위 기법을 도입.

Result: 초록에는 구체적인 수치가 없음. 저자들은 7B 모델을 WMT25 제출 모델로 사용했고, 모델(2B/7B/버전2)을 공개했다고 명시.

Conclusion: 학습 파이프라인(병렬 데이터 지속학습 + 지침 기반 미세조정)과 디코딩 후처리(MBR·재순위)를 결합해 번역 전용 LLM을 구축했으며, 실전 대회(WMT25) 출전을 통해 실용성을 증명하려 함.

Abstract: In this paper, we present the SALAMANDRATA family of models, an improved
iteration of SALAMANDRA LLMs (Gonzalez-Agirre et al., 2025) specifically
trained to achieve strong performance in translation-related tasks for 38
European languages. SALAMANDRATA comes in two scales: 2B and 7B parameters. For
both versions, we applied the same training recipe with a first step of
continual pre-training on parallel data, and a second step of supervised
fine-tuning on high-quality instructions. The BSC submission to the WMT25
General Machine Translation shared task is based on the 7B variant of
SALAMANDRATA. We first adapted the model vocabulary to support the additional
non-European languages included in the task. This was followed by a second
phase of continual pre-training and supervised fine-tuning, carefully designed
to optimize performance across all translation directions for this year's
shared task. For decoding, we employed two quality-aware strategies: Minimum
Bayes Risk Decoding and Tuned Re-ranking using COMET and COMET-KIWI
respectively. We publicly release both the 2B and 7B versions of SALAMANDRATA,
along with the newer SALAMANDRATA-V2 model, on Hugging Face1

</details>


### [213] [HeteroRAG: A Heterogeneous Retrieval-Augmented Generation Framework for Medical Vision Language Tasks](https://arxiv.org/abs/2508.12778)
*Zhe Chen,Yusheng Liao,Shuyang Jiang,Zhiyuan Zhu,Haolin Li,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: Med-LVLM(의료 대형 비전-언어 모델)은 진단에 유망하지만 사실성 오류와 신뢰성 문제가 있어 위험. 기존 RAG(검색 보강 생성)은 이종(heterogeneous) 출처 간의 효과적 검색에 실패. 이를 해결하기 위해 MedAtlas(멀티모달 보고서 저장소)와 HeteroRAG(모델)를 제안. HeteroRAG는 모달리티-특화 CLIP으로 보고서 검색을 개선하고, 다중 코퍼스 질의 생성기로 다양한 코퍼스에 맞춰 동적 질의 생성. Heterogeneous Knowledge Preference Tuning으로 다원 지식을 통합해 Med-LVLM을 학습. 12개 데이터셋과 3개 모달리티에서 SOTA 성능 달성, 사실성 및 신뢰성 크게 향상.


<details>
  <summary>Details</summary>
Motivation: 의료 비전-언어 모델의 사실성 오류와 신뢰도 부족은 임상 활용에서 위험을 초래하므로, 다양한 출처에서 정확한 지식을 검색하고 통합하는 효과적인 RAG 시스템이 필요.

Method: 1) MedAtlas: 멀티모달 보고서 저장소와 다양한 텍스트 코퍼스 구축. 2) Modality-specific CLIPs: 각 모달리티 특화된 CLIP 모델로 관련 보고서 효율적 검색. 3) Multi-corpora Query Generator: 다양한 코퍼스 특성에 맞춰 동적 질의를 생성하여 검색 성능 향상. 4) Heterogeneous Knowledge Preference Tuning: 교차 모달리티 및 다원 출처 지식 정렬을 위한 학습 프로세스. 5) Med-LVLM에 검색된 지식을 통합하여 생성 성능 향상.

Result: 12개 데이터셋, 3개 모달리티에서 실험하여 대부분의 의료 비전-언어 벤치마크에서 SOTA 달성. 사실성(factuality) 및 신뢰성(reliability) 지표에서 유의미한 향상 보고.

Conclusion: HeteroRAG와 MedAtlas를 통한 다원적 지식 통합은 의료 LVLM의 사실성 및 신뢰성을 크게 향상시키며, 임상 응용에서의 안전성과 실용성 향상에 기여할 수 있음.

Abstract: Medical large vision-language Models (Med-LVLMs) have shown promise in
clinical applications but suffer from factual inaccuracies and unreliable
outputs, posing risks in real-world diagnostics. While retrieval-augmented
generation has emerged as a potential solution, current medical multimodal RAG
systems are unable to perform effective retrieval across heterogeneous sources.
The irrelevance of retrieved reports affects the factuality of analysis, while
insufficient knowledge affects the credibility of clinical decision-making. To
bridge the gap, we construct MedAtlas, which includes extensive multimodal
report repositories and diverse text corpora. Based on it, we present
HeteroRAG, a novel framework that enhances Med-LVLMs through heterogeneous
knowledge sources. The framework introduces Modality-specific CLIPs for
effective report retrieval and a Multi-corpora Query Generator for dynamically
constructing queries for diverse corpora. Incorporating knowledge from such
multifaceted sources, Med-LVLM is then trained with Heterogeneous Knowledge
Preference Tuning to achieve cross-modality and multi-source knowledge
alignment. Extensive experiments across 12 datasets and 3 modalities
demonstrate that the proposed HeteroRAG achieves state-of-the-art performance
in most medical vision language benchmarks, significantly improving factual
accuracy and reliability of Med-LVLMs.

</details>


### [214] [Atom-Searcher: Enhancing Agentic Deep Research via Fine-Grained Atomic Thought Reward](https://arxiv.org/abs/2508.12800)
*Yong Deng,Guoqing Wang,Zhenzhe Ying,Xiaofeng Wu,Jinzhen Lin,Wenwen Xiong,Yuqin Dai,Shuo Yang,Zhanwei Zhang,Qiwen Wang,Yang Qin,Changhua Meng*

Main category: cs.CL

TL;DR: LLM의 복잡한 문제 해결을 위해 추론을 원자 단위로 분해하는 'Atomic Thought'와 이를 보상하는 Reasoning Reward Models를 도입하고, 과정 기반 보상에서 결과 기반 보상으로 전환하는 커리큘럼적 보상 스케줄을 가진 RL 프레임워크 'Atom-Searcher'를 제안한다. 다수의 벤치마크에서 기존 기법 대비 개선을 보였고, 해석가능성 및 테스트 시 계산 확장이 가능하다고 주장한다.


<details>
  <summary>Details</summary>
Motivation: 일반적인 RAG와 기존 에이전트 학습은 다중 홉 추론과 전략적 탐색에서 한계가 있으며, 결과 기반 RL은 보상 희소성과 상충하는 그래디언트 문제로 학습 효율이 떨어진다. 더 세분화된 과정 보상과 이를 활용한 훈련 전략이 필요하다.

Method: 추론을 작은 기능적 단위(Atomic Thought)로 분해하고, 각 단위에 대해 Reasoning Reward Models(RRM)을 학습해 Atomic Thought Reward(ATR)를 제공한다. Atom-Searcher는 ATR을 우선하여 과정 수준의 보상으로 학습을 시작하고, 점차 결과 보상으로 전환하는 커리큘럼형 보상 스케줄을 적용하는 RL 프레임워크다.

Result: 7개 벤치마크에서 SOTA 대비 일관된 성능 향상을 보고하며, 테스트 시 계산 확장성, RRM을 통한 감독 앵커 제공, 인간 유사한 해석 가능한 추론 패턴을 장점으로 제시한다.

Conclusion: Atomic Thought와 ATR 기반의 커리큘럼 보상 전략은 결과 중심 RL의 한계를 완화하고, 에이전트 기반 심층 연구(autonomous deep research) 성능과 해석가능성을 개선할 가능성이 높다. 다만 RRM 학습 방법, 보상 설계 민감도, 계산비용에 대한 자세한 분석이 필요하다.

Abstract: Large language models (LLMs) exhibit remarkable problem-solving abilities,
but struggle with complex tasks due to static internal knowledge.
Retrieval-Augmented Generation (RAG) enhances access to external information,
yet remains limited in multi-hop reasoning and strategic search due to rigid
workflows. Recent advancements in agentic deep research empower LLMs to
autonomously reason, search, and synthesize information. However, current
approaches relying on outcome-based reinforcement learning (RL) face critical
issues such as conflicting gradients and reward sparsity, limiting performance
gains and training efficiency. To address these, we first propose Atomic
Thought, a novel LLM thinking paradigm that decomposes reasoning into
fine-grained functional units. These units are supervised by Reasoning Reward
Models (RRMs), which provide Atomic Thought Rewards (ATR) for fine-grained
guidance. Building on this, we propose Atom-Searcher, a novel RL framework for
agentic deep research that integrates Atomic Thought and ATR. Atom-Searcher
uses a curriculum-inspired reward schedule, prioritizing process-level ATR
early and transitioning to outcome rewards, accelerating convergence on
effective reasoning paths. Experiments on seven benchmarks show consistent
improvements over the state-of-the-art. Key advantages include: (1)
Atom-Searcher scales computation at test-time. (2) Atomic Thought provides
supervision anchors for RRMs, bridging deep research tasks and RRMs. (3)
Atom-Searcher exhibits more interpretable, human-like reasoning patterns.

</details>


### [215] [When Alignment Hurts: Decoupling Representational Spaces in Multilingual Models](https://arxiv.org/abs/2508.12803)
*Ahmed Elshabrawy,Hour Kaing,Haiyue Song,Alham Fikri Aji,Hideki Tanaka,Masao Utiyama,Raj Dabre*

Main category: cs.CL

TL;DR: Excessive representational entanglement with a high-resource standard (MSA) can harm generative modeling of related low-resource dialects; online variational probing plus projection-based decoupling during fine-tuning improves dialect MT across 25 Arabic dialects.


<details>
  <summary>Details</summary>
Motivation: To test whether aligning LLM representations to a dominant standard language always helps related low-resource varieties, and to develop a method to control harmful entanglement when it occurs.

Method: Introduce an online variational probing framework that continuously estimates the standard-variety subspace during fine-tuning and applies projection-based decoupling from that subspace; evaluate on Arabic dialect MT across 25 dialects.

Result: Intervention yields up to +4.9 chrF++ and +2.0 chrF++ on average versus standard fine-tuning, though with a tradeoff in standard-language (MSA) performance.

Conclusion: Provides causal evidence that dominant-variety subspace dominance can restrict generative capacity for related varieties; proposes practical subspace-level interventions to reallocate representational capacity in multilingual/multi-domain LLMs.

Abstract: Alignment with high-resource standard languages is often assumed to aid the
modeling of related low-resource varieties. We challenge this assumption by
demonstrating that excessive representational entanglement with a dominant
variety, such as Modern Standard Arabic (MSA) in relation to Arabic dialects,
can actively hinder generative modeling. We present the first comprehensive
causal study of this phenomenon by analyzing and directly intervening in the
internal representation geometry of large language models (LLMs). Our key
contribution is an online variational probing framework that continuously
estimates the subspace of the standard variety during fine-tuning, enabling
projection-based decoupling from this space. While our study uses Arabic as a
case due to its unusually rich parallel resources across 25 dialects, the
broader motivation is methodological: dialectal MT serves as a controlled proxy
for generative tasks where comparable multi-variety corpora are unavailable.
Across 25 dialects, our intervention improves generation quality by up to +4.9
chrF++ and +2.0 on average compared to standard fine-tuning, despite a measured
tradeoff in standard-language performance. These results provide causal
evidence that subspace dominance by high-resource varieties can restrict
generative capacity for related varieties. More generally, we unify geometric
and information-theoretic probing with subspace-level causal interventions,
offering practical tools for improving generative modeling in closely related
language families and, more broadly, for controlling representational
allocation in multilingual and multi-domain LLMs. Code will be released.

</details>


### [216] [ding-01 :ARG0: An AMR Corpus for Spontaneous French Dialogue](https://arxiv.org/abs/2508.12819)
*Jeongwoo Kang,Maria Boritchev,Maximin Coavoux*

Main category: cs.CL

TL;DR: 프랑스어 대화(DinG) 전사를 AMR로 주석화한 코퍼스를 구축하고, 자발적 발화와 프랑스어 특유 문장구조를 다루기 위해 AMR를 확장했으며, 확장된 주석 지침을 제공하고 코퍼스를 CC‑SA‑BY로 공개. 또한 학습된 AMR 파서를 통해 주석 보조 도구를 제시함.


<details>
  <summary>Details</summary>
Motivation: 프랑스어 대화 의미 자원이 부족하고, 기존 AMR이 자발적 발화의 동적 현상 및 프랑스어 특정 구조를 충분히 표현하지 못함.

Method: Catan 보드게임 중 녹음된 DinG 대화 전사를 AMR로 수작업 주석. 자발적 발화와 프랑스어 구조를 표현하기 위해 AMR 프레임워크를 확장하고, 일관성 유지를 위한 주석 가이드라인을 작성. 주석 데이터를 사용해 AMR 파서를 학습·평가함.

Result: 확장된 AMR 규칙과 주석 가이드를 포함한 주석 코퍼스 공개(오픈 라이선스). 학습된 파서는 초기 자동 주석을 제공해 인간 주석자 보조에 활용 가능.

Conclusion: 프랑스어 대화 의미 자원과 주석 도구의 발전에 기여하였으나, 추후 작업(주석자 간 합의도, 코퍼스 크기와 도메인 일반화성, 파서 성능 상세 수치 및 에러 분석 등)이 필요함.

Abstract: We present our work to build a French semantic corpus by annotating French
dialogue in Abstract Meaning Representation (AMR). Specifically, we annotate
the DinG corpus, consisting of transcripts of spontaneous French dialogues
recorded during the board game Catan. As AMR has insufficient coverage of the
dynamics of spontaneous speech, we extend the framework to better represent
spontaneous speech and sentence structures specific to French. Additionally, to
support consistent annotation, we provide an annotation guideline detailing
these extensions. We publish our corpus under a free license (CC-SA-BY). We
also train and evaluate an AMR parser on our data. This model can be used as an
assistance annotation tool to provide initial annotations that can be refined
by human annotators. Our work contributes to the development of semantic
resources for French dialogue.

</details>


### [217] [Context Matters: Incorporating Target Awareness in Conversational Abusive Language Detection](https://arxiv.org/abs/2508.12828)
*Raneem Alharthi,Rajwa Alharthi,Aiqi Jiang,Arkaitz Zubiaga*

Main category: cs.CL

TL;DR: Using the parent tweet as conversational context improves abusive-reply detection; content-based contextual features (what is said) drive most of the gain and combining diverse content features works best.


<details>
  <summary>Details</summary>
Motivation: Prior work mostly classifies social media posts in isolation, ignoring conversational context; the authors aim to test whether leveraging the parent tweet helps detect abusive replies and which contextual features matter most.

Method: Build a dataset of parent–reply tweet pairs with replies labeled abusive/non-abusive. Extract content-based and account-based features from both reply and parent. Train and compare four classification models, evaluating reply-only features versus context-augmented features and analyzing feature contributions.

Result: Contextual features substantially boost classification performance over reply-only models. Content-based contextual features contribute more than account-based ones. Combining multiple content features yields better performance than using fewer selective features.

Conclusion: Abusive language detection benefits from conversational context; practical systems should incorporate content-based context and a diverse set of features for improved robustness in conversation settings.

Abstract: Abusive language detection has become an increasingly important task as a
means to tackle this type of harmful content in social media. There has been a
substantial body of research developing models for determining if a social
media post is abusive or not; however, this research has primarily focused on
exploiting social media posts individually, overlooking additional context that
can be derived from surrounding posts. In this study, we look at conversational
exchanges, where a user replies to an earlier post by another user (the parent
tweet). We ask: does leveraging context from the parent tweet help determine if
a reply post is abusive or not, and what are the features that contribute the
most? We study a range of content-based and account-based features derived from
the context, and compare this to the more widely studied approach of only
looking at the features from the reply tweet. For a more generalizable study,
we test four different classification models on a dataset made of
conversational exchanges (parent-reply tweet pairs) with replies labeled as
abusive or not. Our experiments show that incorporating contextual features
leads to substantial improvements compared to the use of features derived from
the reply tweet only, confirming the importance of leveraging context. We
observe that, among the features under study, it is especially the
content-based features (what is being posted) that contribute to the
classification performance rather than account-based features (who is posting
it). While using content-based features, it is best to combine a range of
different features to ensure improved performance over being more selective and
using fewer features. Our study provides insights into the development of
contextualized abusive language detection models in realistic settings
involving conversations.

</details>


### [218] [It takes a village to write a book: Mapping anonymous contributions in Stephen Langton's Quaestiones Theologiae](https://arxiv.org/abs/2508.12830)
*Jan Maliszewski*

Main category: cs.CL

TL;DR: 스티븐 랭턴의 Quaestiones Theologiae(중세 reportationes)에 대해 HTR(Transformer 기반 OCR) + 자동 정렬과 전통적 수작업 전사 데이터를 비교하면서, 빈도 단어·품사·의사 접미사(가칭) 등 스타일 측정(feature)으로 편집층(editorial layers)을 추출·검증하려는 연구 설계안.


<details>
  <summary>Details</summary>
Motivation: 초기 스콜라주의의 구술기록 기반 문헌(reportationes)에 대한 편집·편집층 연구가 드물고 직접적 근거가 부족하므로, 계산적·통계적 방법으로 텍스트의 다층적 형성(process of formation)을 밝히려는 목적.

Method: HTR 파이프라인(Transformer 기반 OCR 포함) 구현 → 자동·수동 전사 비교 → 특징 추출(최빈어, POS 시퀀스, pseudo-affixes) → 저자·편집층 식별을 위한 스타일로메트릭 기법(군집·분류·거리기반 측정 등) 적용 → 결과 검증 및 템플릿화.

Result: 성공 시: 자동 파이프라인이 수작업 전사와 경쟁 가능한지, 편집층을 식별할 유의미한 스타일 신호 존재 여부, 대학 중심 협업 산출물 분석을 위한 재사용 가능 템플릿 제공.

Conclusion: 방법론적으로 유효한 접근이며, HTR 잡음에 대한 강건성·평가 지표·재현 가능한 데이터·실험 설계가 필수적. 성공하면 중세 라틴 코퍼스의 자동화된 탐색에 기여할 가능성이 큼.

Abstract: While the indirect evidence suggests that already in the early scholastic
period the literary production based on records of oral teaching (so-called
reportationes) was not uncommon, there are very few sources commenting on the
practice. This paper details the design of a study applying stylometric
techniques of authorship attribution to a collection developed from
reportationes -- Stephen Langton's Quaestiones Theologiae -- aiming to uncover
layers of editorial work and thus validate some hypotheses regarding the
collection's formation. Following Camps, Cl\'erice, and Pinche (2021), I
discuss the implementation of an HTR pipeline and stylometric analysis based on
the most frequent words, POS tags, and pseudo-affixes. The proposed study will
offer two methodological gains relevant to computational research on the
scholastic tradition: it will directly compare performance on manually composed
and automatically extracted data, and it will test the validity of
transformer-based OCR and automated transcription alignment for workflows
applied to scholastic Latin corpora. If successful, this study will provide an
easily reusable template for the exploratory analysis of collaborative literary
production stemming from medieval universities.

</details>


### [219] [Word Meanings in Transformer Language Models](https://arxiv.org/abs/2508.12863)
*Jumbly Grindrod,Peter Grindrod*

Main category: cs.CL

TL;DR: RoBERTa-base의 토큰 임베딩을 k-means(200개)로 군집화한 결과, 임베딩 공간에 다양한 의미 정보가 명확히 인코딩되어 있음을 보였다. 군집은 감정(valence), 구체성(concreteness), 상징성(iconicity), 금기성(taboo), 습득연령(AoA) 같은 심리언어학적 척도들과 유의미한 관계를 보였다.


<details>
  <summary>Details</summary>
Motivation: 트랜스포머 언어모델이 단어별 의미를 저장하는 ‘어휘 저장소(lexical store)’와 유사한 구조를 갖는지, 또는 의미가 전혀 고정된 형태로 저장되지 않는지(meaning eliminativist 주장)를 검증하고자 함.

Method: RoBERTa-base의 토큰 임베딩을 추출하고 k-means로 200개 군집을 만듦. 연구1: 생성된 군집을 수동으로 검토해 의미적 일관성 평가. 연구2: 각 군집이 valence, concreteness, iconicity, taboo, age of acquisition 등 다섯 심리언어학적 척도에 민감한지 통계적으로 검증.

Result: 토큰 임베딩 군집에서 다양한 의미적 패턴이 관찰됨. 여러 군집이 감정, 구체성 등 다섯 척도와 유의한 연관을 보였으며, 이는 단어 의미 정보가 임베딩 공간에 분명히 존재함을 시사함.

Conclusion: 트랜스포머의 토큰 임베딩은 풍부한 의미 정보를 내포하고 있어 강한 의미 제거론(meaning eliminativism)을 기각할 근거를 제공한다. 이는 LLM의 의미 표현이 분산적이지만 탐색·해석 가능한 구조를 가진다는 점을 시사하며, 의미 관련 프로빙 및 모델 해석 연구에 중요한 근거를 제공한다.

Abstract: We investigate how word meanings are represented in the transformer language
models. Specifically, we focus on whether transformer models employ something
analogous to a lexical store - where each word has an entry that contains
semantic information. To do this, we extracted the token embedding space of
RoBERTa-base and k-means clustered it into 200 clusters. In our first study, we
then manually inspected the resultant clusters to consider whether they are
sensitive to semantic information. In our second study, we tested whether the
clusters are sensitive to five psycholinguistic measures: valence,
concreteness, iconicity, taboo, and age of acquisition. Overall, our findings
were very positive - there is a wide variety of semantic information encoded
within the token embedding space. This serves to rule out certain "meaning
eliminativist" hypotheses about how transformer LLMs process semantic
information.

</details>


### [220] [An LLM Agent-Based Complex Semantic Table Annotation Approach](https://arxiv.org/abs/2508.12868)
*Yilin Geng,Shujing Wang,Chuan Wang,Keqing He,Yanfei Lv,Ying Wang,Zaiwen Feng,Xiaoying Bai*

Main category: cs.CL

TL;DR: 제안된 LLM 기반 ReAct 에이전트가 표의 열·셀 주석(CTA·CEA)을 동적 도구 선택과 Levenshtein 기반 중복 제거로 처리하여 SemTab의 Tough Tables와 BiodivTab에서 기존 기법보다 우수한 성능과 시간·토큰 비용 절감(각각 약 70%/60%)을 보였음.


<details>
  <summary>Details</summary>
Motivation: 복잡한 표에서 열 이름·셀 값의 의미 손실, 온톨로지 계층 요구, 동음이의어, 철자 오류, 약어 등으로 인해 STA(표 주석) 작업의 정확도가 낮아지는 문제를 해결하려 함.

Method: ReAct 프레임워크 기반으로 설계된 LLM 에이전트를 제안. 다섯 개의 외부 도구(상세 불명)와 맞춤 프롬프트를 사용해 표 특성에 따라 동적으로 주석 전략을 선택. Levenshtein 거리로 중복 주석을 줄여 비용을 절감.

Result: SemTab의 Tough Tables, BiodivTab 데이터셋에서 기존 방법들보다 전반적으로 우수한 성능을 보고. 중복 제거로 시간 비용 약 70%, LLM 토큰 사용량 약 60% 절감.

Conclusion: 동적 도구 선택과 간단한 문자열 유사도 기반 최적화로 STA에서 효율성과 정확도를 동시에 개선. 다만 도구·프롬프트 세부사항, 안정성·일반화 검증 등이 추가로 필요함.

Abstract: The Semantic Table Annotation (STA) task, which includes Column Type
Annotation (CTA) and Cell Entity Annotation (CEA), maps table contents to
ontology entities and plays important roles in various semantic applications.
However, complex tables often pose challenges such as semantic loss of column
names or cell values, strict ontological hierarchy requirements, homonyms,
spelling errors, and abbreviations, which hinder annotation accuracy. To
address these issues, this paper proposes an LLM-based agent approach for CTA
and CEA. We design and implement five external tools with tailored prompts
based on the ReAct framework, enabling the STA agent to dynamically select
suitable annotation strategies depending on table characteristics. Experiments
are conducted on the Tough Tables and BiodivTab datasets from the SemTab
challenge, which contain the aforementioned challenges. Our method outperforms
existing approaches across various metrics. Furthermore, by leveraging
Levenshtein distance to reduce redundant annotations, we achieve a 70%
reduction in time costs and a 60% reduction in LLM token usage, providing an
efficient and cost-effective solution for STA.

</details>


### [221] [A Stitch in Time Saves Nine: Proactive Self-Refinement for Language Models](https://arxiv.org/abs/2508.12903)
*Jinyi Han,Xinyi Wang,Haiquan Zhao,Tingyun li,Zishang Jiang,Sihang Jiang,Jiaqing Liang,Xin Lin,Weikang Zhou,Zeye Sun,Fei Yu,Yanghua Xiao*

Main category: cs.CL

TL;DR: PASR은 생성 도중 모델의 내부 상태와 문맥 변화를 바탕으로 언제, 어떻게 출력을 능동적으로 개선할지 결정하는 '능동적 자기-정제' 기법이다. 전체 재생성이 아니라 부분적이고 시의적절한 정제를 통해 토큰 소비를 줄이고 정확도를 높인다.


<details>
  <summary>Details</summary>
Motivation: 기존 자기-정제 방법들은 고정 반복 횟수의 반응적 프로세스에 의존해 정제 시점과 내용을 문맥 변화에 맞춰 결정하기 어렵다. 사람처럼 실행 중에 동적으로 사고를 다듬는 방식을 모사하면 효율성과 성능을 동시에 개선할 수 있다는 점이 동기다.

Method: 모델 내부 상태(예: 불확실성, 토큰 확률 분포 등)와 생성 중 변하는 문맥을 모니터링하여 정제 필요성을 판정하고, 언제(정제 시점), 어디를(부분적 범위), 어떻게(정제 전략)를 결정해 부분적 수정을 수행한다. 전체 응답을 재생성하는 대신 선택적 정제를 적용한다.

Result: 10개 과제 전반에서 성능 향상을 관찰했다. 예: Qwen3-8B에서 표준 생성 대비 평균 토큰 소비를 41.6% 절감하고 정확도를 8.2% 향상시켰다. 코드와 비교군을 공개했다.

Conclusion: PASR은 실행 중 능동적 정제로 토큰 효율성과 문제 해결 성능을 모두 개선할 수 있음을 보여준다.

Abstract: Recent advances in self-refinement have demonstrated significant potential
for improving the outputs of large language models (LLMs) through iterative
refinement. However, most existing self-refinement methods rely on a reactive
process with a fixed number of iterations, making it difficult to determine the
optimal timing and content of refinement based on the evolving generation
context. Inspired by the way humans dynamically refine their thoughts during
execution, we propose ProActive Self-Refinement (PASR), a novel method that
enables LLMs to refine their outputs during the generation process. Unlike
methods that regenerate entire responses, PASR proactively decides whether,
when, and how to refine based on the model's internal state and evolving
context. We conduct extensive experiments on a diverse set of 10 tasks to
evaluate the effectiveness of PASR. Experimental results show that PASR
significantly enhances problem-solving performance. In particular, on Qwen3-8B,
PASR reduces average token consumption by 41.6 percent compared to standard
generation, while also achieving an 8.2 percent improvement in accuracy. Our
code and all baselines used in the paper are available in the GitHub.

</details>


### [222] [Analyzing Information Sharing and Coordination in Multi-Agent Planning](https://arxiv.org/abs/2508.12981)
*Tianyue Ou,Saujas Vaduguru,Daniel Fried*

Main category: cs.CL

TL;DR: LLM 기반 다중 에이전트 시스템(MAS)을 여행 계획 과제에 적용해, 공유 노트북(정보 공유)과 오케스트레이터(조정자)를 도입한 결과 단일 에이전트 대비 성능이 개선됨. 노트북으로 환각 오류 18% 감소, 오케스트레이터로 특정 하위 영역 오류 최대 13.5% 추가 감소, 둘 결합 시 최종 통과율 25% 달성(단일 에이전트 7.5%).


<details>
  <summary>Details</summary>
Motivation: 장기간·다중 제약을 가진 계획 문제는 상세한 조건을 유지하고 복잡한 상호의존 제약을 만족시켜야 하므로, LLM 기반 에이전트들이 단일 자유형 대화만으로는 실수(환각, 정보 손실, 조정 실패)를 범하기 쉬움. 이를 해결하기 위해 구조화된 정보 공유와 조정 메커니즘의 효과를 평가하려 함.

Method: 여행 계획 태스크(TravelPlanner 벤치마크)를 설정하고 LLM 기반 MAS를 구성. 정보 공유를 위한 중앙 '노트북'과 에이전트 간 대화를 감독·유도하는 '오케스트레이터'를 설계하여 각각 및 결합된 경우를 실험. 성능은 통과율과 오류(환각 등) 감소율로 측정.

Result: 노트북 단독으로 환각 기반 오류 18% 감소, 오케스트레이터는 특정 하위 영역에서 최대 13.5% 오류 추가 감소. 둘을 결합하면 통과율 25%로 향상되어 단일 에이전트(7.5%) 대비 절대 17.5% 포인트 개선.

Conclusion: 장기간·다중 제약 계획 문제에서 구조화된 정보 공유(노트북)와 반영적 조정(오케스트레이터)은 MAS의 정확성과 신뢰성을 높이는 핵심 구성 요소가 될 수 있음.

Abstract: Multi-agent systems (MASs) have pushed the boundaries of large language model
(LLM) agents in domains such as web research and software engineering. However,
long-horizon, multi-constraint planning tasks involve conditioning on detailed
information and satisfying complex interdependent constraints, which can pose a
challenge for these systems. In this study, we construct an LLM-based MAS for a
travel planning task which is representative of these challenges. We evaluate
the impact of a notebook to facilitate information sharing, and evaluate an
orchestrator agent to improve coordination in free form conversation between
agents. We find that the notebook reduces errors due to hallucinated details by
18%, while an orchestrator directs the MAS to focus on and further reduce
errors by up to 13.5% within focused sub-areas. Combining both mechanisms
achieves a 25% final pass rate on the TravelPlanner benchmark, a 17.5% absolute
improvement over the single-agent baseline's 7.5% pass rate. These results
highlight the potential of structured information sharing and reflective
orchestration as key components in MASs for long horizon planning with LLMs.

</details>


### [223] [WebMall -- A Multi-Shop Benchmark for Evaluating Web Agents](https://arxiv.org/abs/2508.13024)
*Ralph Peeters,Aaron Steiner,Luca Schwarz,Julian Yuya Caspary,Christian Bizer*

Main category: cs.CL

TL;DR: WebMall은 여러 실상점(다수의 실제 상품 제공 데이터 기반)에서의 비교 쇼핑 작업을 자동화하는 LLM 웹 에이전트 평가를 위해 설계된 벤치마크로, 4개의 시뮬레이트된 상점과 91개의 교차상점 태스크(기본·고급)를 포함한다. 베이스라인 평가에서 기본 태스크 완료율 최대 75%(F1 87%), 고급 태스크 완료율 53%(F1 63%)을 기록했다.


<details>
  <summary>Details</summary>
Motivation: 기존 전자상거래 벤치마크는 단일 상점 중심 또는 단순 태스크에 머무르는 경우가 많아, 다중 상점에서의 비교 쇼핑처럼 장시간의 상호작용·추론·탐색이 필요한 실제 시나리오를 평가할 벤치마크가 필요했다.

Method: Common Crawl에서 수집한 실제 상품 오퍼로 채운 4개의 시뮬레이트된 온라인 상점을 생성하고, 91개의 태스크(제품 검색·가격비교·장바구니·체크아웃 등 기본과 모호한 요구·대체품 탐색·호환성 판단 등 고급)를 설계. 관찰 모달리티·메모리 사용·LLM(GPT 4.1, Claude Sonnet 4)을 달리한 8개 베이스라인 에이전트를 평가했다.

Result: 기본 태스크에서 최고 완료율 75%·F1 87%, 고급 태스크에서 최고 완료율 53%·F1 63%를 달성했다. WebMall은 기존 벤치마크보다 더 길고 이질적인 상호작용 궤적을 요구한다는 점을 보였다.

Conclusion: WebMall은 다중 상점 비교 쇼핑 시나리오에서 에이전트의 내비게이션·추론·효율성 연구를 촉진하기 위해 공개되며, 에이전트 성능 향상을 위한 새로운 연구 과제를 제시한다.

Abstract: LLM-based web agents have the potential to automate long-running web tasks,
such as finding offers for specific products in multiple online shops and
subsequently ordering the cheapest products that meet the users needs. This
paper introduces WebMall, a multi-shop online shopping benchmark for evaluating
the effectiveness and efficiency of web agents for comparison-shopping. WebMall
consists of four simulated online shops populated with authentic product offers
sourced from the Common Crawl, alongside a suite of 91 cross-shop tasks. These
tasks include basic tasks such as finding specific products in multiple shops,
performing price comparisons, adding items to the shopping cart, and completing
checkout. Advanced tasks involve searching for products based on vague
requirements, identifying suitable substitutes, and finding compatible
products. Compared to existing e-commerce benchmarks, such as WebShop or
ShoppingBench, WebMall introduces comparison-shopping tasks across multiple
shops. Furthermore, the product offers are more heterogeneous, as they
originate from hundreds of distinct real-world shops. The tasks in WebMall
require longer interaction trajectories than those in WebShop, while remaining
representative of real-world shopping behaviors. We evaluate eight baseline
agents on WebMall, varying in observation modality, memory utilization, and
underlying large language model (GPT 4.1 and Claude Sonnet 4). The
best-performing configurations achieve completion rates of 75% and 53%, and F1
scores of 87% and 63%, on the basic and advanced task sets, respectively.
WebMall is publicly released to facilitate research on web agents and to
promote advancements in navigation, reasoning, and efficiency within e-commerce
scenarios.

</details>


### [224] [Integrating Feedback Loss from Bi-modal Sarcasm Detector for Sarcastic Speech Synthesis](https://arxiv.org/abs/2508.13028)
*Zhu Li,Yuqing Zhang,Xiyuan Gao,Devraj Raghuvanshi,Nagendra Kumar,Shekhar Nayak,Matt Coler*

Main category: cs.CL

TL;DR: 사전학습된 TTS에 다중모달(음성+텍스트) 사르카즘 검출기의 피드백 손실을 통합하고, 다양한 스타일→사르카즘 특화의 2단계 미세조정으로 풍자(비꼼) 표현을 향상한 방법을 제안. 평가에서 음질·자연스러움·사르카즘 인지성 개선을 보임.


<details>
  <summary>Details</summary>
Motivation: 사르카즘은 미묘한 운율·억양 변화로 특징지어지며, 표지된(annotated) 사르카즘 음성 데이터가 부족해 TTS에서 재현하기 어렵다. 따라서 검출기 피드백과 전이학습을 통해 한정된 데이터로도 효과적으로 학습하고자 함.

Method: (1) 음성+텍스트 기반의 이중모달 사르카즘 검출기에서 계산한 손실(피드백)을 TTS 학습 손실에 결합하여 사르카즘 특성을 유도. (2) 사전학습된 읽기말투 TTS를 가져와 두 단계로 미세조정: 먼저 다양한 스타일(사르카즘 포함) 데이터로 일반적 발화 다양성 학습, 그다음 사르카즘 특화 데이터로 세부 조정.

Result: 객관적(음향·프로소디 지표) 및 주관적(청취자 평가) 실험에서 제안 기법이 합성 음성의 품질·자연성·사르카즘 전달력을 기존 방법들보다 향상시킴.

Conclusion: 검출기 기반 피드백과 점진적 미세조정은 제한된 사르카즘 데이터 상황에서 사르카즘 합성 성능을 개선하는 실용적 방안임.

Abstract: Sarcastic speech synthesis, which involves generating speech that effectively
conveys sarcasm, is essential for enhancing natural interactions in
applications such as entertainment and human-computer interaction. However,
synthesizing sarcastic speech remains a challenge due to the nuanced prosody
that characterizes sarcasm, as well as the limited availability of annotated
sarcastic speech data. To address these challenges, this study introduces a
novel approach that integrates feedback loss from a bi-modal sarcasm detection
model into the TTS training process, enhancing the model's ability to capture
and convey sarcasm. In addition, by leveraging transfer learning, a speech
synthesis model pre-trained on read speech undergoes a two-stage fine-tuning
process. First, it is fine-tuned on a diverse dataset encompassing various
speech styles, including sarcastic speech. In the second stage, the model is
further refined using a dataset focused specifically on sarcastic speech,
enhancing its ability to generate sarcasm-aware speech. Objective and
subjective evaluations demonstrate that our proposed methods improve the
quality, naturalness, and sarcasm-awareness of synthesized speech.

</details>


### [225] [Can Large Models Teach Student Models to Solve Mathematical Problems Like Human Beings? A Reasoning Distillation Method via Multi-LoRA Interaction](https://arxiv.org/abs/2508.13037)
*Xinhe Li,Jiajun Liu,Peng Wang*

Main category: cs.CL

TL;DR: LoRID는 소형 언어모델(SLM)의 수학적 추론 능력을 향상시키기 위해 제안된 방법으로, LLM으로부터 지식 강화 데이터셋을 만든 뒤 여러 LoRA 블록을 상호작용시키는 방식으로 직관적 추론(IR), 지식 생성(KG), 심층추론(DR)을 학습시키고 이들의 출력 일치성을 검사하며 반복하는 접근이다. GSM8K 등에서 SOTA 성능을 보였다.


<details>
  <summary>Details</summary>
Motivation: 대형 LLM은 강한 수학적 추론 능력을 가지지만 파라미터가 매우 커 SLM은 추론 성능이 낮음. 기존 방법은 대규모 생성 데이터로 SLM을 '암기'시키는(System 1 유사) 경향이 커, 인간 학습의 System 2(지식 습득 후 연습)를 모방한 보완적 학습이 필요함.

Method: (1) LLM으로 질문+추론을 입력해 지식 강화 데이터 생성; (2) 학생 모델에 LoRA 블록을 학습시켜 Intuitive Reasoner(IR)로 CoT(Chain-of-Thought) 직접 생성; (3) 문제만 입력받아 지식만 출력하는 Knowledge Generator(KG)와, 그 지식을 받아 추론하는 Deep Reasoner(DR)를 별도 학습; (4) IR과 DR의 출력 일치성(일관성)을 검사하고 불일치 시 반복 추론을 수행해 상호 피드백으로 성능 개선.

Result: 여러 베이스 모델에서 GSM8K 등 벤치마크에서 SOTA 달성. 특히 GSM8K에서 두 번째 방법 대비 2.3%~16.1% 등 베이스 모델별로 유의미한 정확도 향상 보고.

Conclusion: System 1/2 유사 학습 모드와 다중 LoRA 상호작용, 반복적 일관성 검사로 SLM의 수학적 추론 능력을 크게 향상시킬 수 있음을 보였으며, SLM의 실용적 추론 성능 개선에 유용한 패러다임을 제시함.

Abstract: Recent studies have demonstrated that Large Language Models (LLMs) have
strong mathematical reasoning abilities but rely on hundreds of billions of
parameters. To tackle the challenge of poor reasoning in Small Language Models
(SLMs), existing methods typically leverage LLMs to generate massive amounts of
data for cramming training. In psychology, they are akin to System 1 thinking,
which resolves reasoning problems rapidly based on experience and intuition.
However, human learning also requires System 2 thinking, where knowledge is
first acquired and then reinforced through practice. Inspired by such two
distinct modes of thinking, we propose a novel method based on the multi-LoRA
Interaction for mathematical reasoning Distillation (LoRID). First, we input
the question and reasoning of each sample into an LLM to create
knowledge-enhanced datasets. Subsequently, we train a LoRA block on the student
model as an Intuitive Reasoner (IR), which directly generates Chain-of-Thoughts
for problem-solving. Then, to imitate System 2 thinking, we train the Knowledge
Generator (KG) and Deep Reasoner (DR), respectively. The former outputs only
knowledge after receiving problems, while the latter uses that knowledge to
perform reasoning. Finally, to address the randomness in the generation of IR
and DR, we evaluate whether their outputs are consistent, and the inference
process needs to be iterated if not. This step can enhance the mathematical
reasoning ability of SLMs through mutual feedback. Experimental results show
that LoRID achieves state-of-the-art performance, especially on the GSM8K
dataset, where it outperforms the second-best method by 2.3%, 16.1%, 2.4%,
12.3%, and 1.8% accuracy across the five base models, respectively.

</details>


### [226] [Büyük Dil Modelleri için TR-MMLU Benchmarkı: Performans Değerlendirmesi, Zorluklar ve İyileştirme Fırsatları](https://arxiv.org/abs/2508.13044)
*M. Ali Bayram,Ali Arda Fincan,Ahmet Semih Gümüş,Banu Diri,Savaş Yıldırım,Öner Aytaş*

Main category: cs.CL

TL;DR: TR-MMLU는 터키어 대형언어모델(LLM)의 언어·개념 능력을 평가하기 위해 제작된 벤치마크로, 터키 교육과정 기반의 62개 분야, 6,200개의 객관식 문항으로 구성되어 있다. 논문은 이 데이터셋으로 여러 최신 LLM을 평가해 모델 설계와 학습에서 개선이 필요한 영역을 도출한다.


<details>
  <summary>Details</summary>
Motivation: 영어 등 고자원 언어에 비해 터키어처럼 자원이 제한된 언어에 대한 LLM 평가 방법과 표준이 부족하다. 일관된 비교·분석이 가능한 벤치마크가 필요해 TR-MMLU를 제안했다.

Method: 터키 교육 체계에 맞춰 62개 섹션을 선정하고 총 6,200개의 객관식 문항을 세밀하게 수집·정제하여 벤치마크를 구축했다. 구축된 데이터로 다양한 최첨단 LLM들을 multiple-choice 형식으로 평가하고 섹션별·난이도별 성능을 분석했다.

Result: 제안된 벤치마크를 통한 평가에서 모델들은 분야·난이도에 따라 성능 차이를 보였고, 특히 도메인 지식과 추론이 요구되는 항목에서 약점이 드러났다. 결과는 모델 설계·학습 데이터 개선의 필요성을 강조한다.

Conclusion: TR-MMLU는 터키어 NLP 연구를 위한 표준 평가틀을 제시하며, 모델 개선과 후속 연구(데이터 확대, 튜닝·파인튜닝 전략 등)를 촉진할 기반을 마련한다.

Abstract: Language models have made significant advancements in understanding and
generating human language, achieving remarkable success in various
applications. However, evaluating these models remains a challenge,
particularly for resource-limited languages like Turkish. To address this
issue, we introduce the Turkish MMLU (TR-MMLU) benchmark, a comprehensive
evaluation framework designed to assess the linguistic and conceptual
capabilities of large language models (LLMs) in Turkish. TR-MMLU is based on a
meticulously curated dataset comprising 6,200 multiple-choice questions across
62 sections within the Turkish education system. This benchmark provides a
standard framework for Turkish NLP research, enabling detailed analyses of
LLMs' capabilities in processing Turkish text. In this study, we evaluated
state-of-the-art LLMs on TR-MMLU, highlighting areas for improvement in model
design. TR-MMLU sets a new standard for advancing Turkish NLP research and
inspiring future innovations.

</details>


### [227] [Doğal Dil İşlemede Tokenizasyon Standartları ve Ölçümü: Türkçe Üzerinden Büyük Dil Modellerinin Karşılaştırmalı Analizi](https://arxiv.org/abs/2508.13058)
*M. Ali Bayram,Ali Arda Fincan,Ahmet Semih Gümüş,Sercan Karakaş,Banu Diri,Savaş Yıldırım*

Main category: cs.CL

TL;DR: 본 논문은 형태소가 풍부하고 저자원인 언어(예: 터키어)를 대상으 로 토크나이저 평가 프레임워크를 제안한다. TR-MMLU(6,200 문항)를 사용해 어휘 크기, 토큰 수, 처리 시간, 언어특이 토큰 비율(%TR), 토큰 순수성(%Pure) 등의 지표로 토크나이저를 평가했고, %TR이 downstream 성능(MMLU 점수)과 더 강한 상관을 보였으며 모델 파라미터 수 증가는 언어성능 향상을 보장하지 않는다고 결론지었다.


<details>
  <summary>Details</summary>
Motivation: 형태소가 풍부한 언어는 단순한 서브워드 분할로 의미·형태소 정보를 잃기 쉬우며, 기존 토크나이저 평가는 주로 고자원(영어) 중심이라 저자원·형태학적 복잡성을 반영하지 못한다. 이를 해결할 실용적이고 재현 가능한 평가기준이 필요하다.

Method: 터키어 MMLU 데이터셋(TR-MMLU, 6,200 MCQ)을 대상으로 여러 토크나이저(다양한 어휘 크기와 알고리즘)를 적용해 어휘 크기, 평균 토큰 수, 처리 시간, %TR(언어특이 토큰 비율), %Pure(토큰 순수성) 등을 계산하고, 각 지표와 MMLU 성능 간 상관관계를 분석했다. 모델 크기(파라미터 수)에 따른 성능 변화를 비교했다.

Result: 언어특이 토큰 비율(%TR)이 downstream MMLU 성능과 더 높은 상관을 보였고, %Pure보다는 %TR이 더 예측력이 높았다. 모델 파라미터를 늘리는 것만으로는 언어적 성능 향상이 보장되지 않았다. 제안한 지표들은 형태학적으로 복잡한 언어에 대한 토크나이저 평가에 유용한 기준을 제공한다.

Conclusion: 형태학적으로 복잡한 저자원 언어에서는 언어특이성을 보존하는 토크나이저 설계가 중요하며, 제안된 평가 프레임워크와 지표들이 실무적·연구적 표준으로 활용될 수 있음을 제안한다.

Abstract: Tokenization is a fundamental preprocessing step in Natural Language
Processing (NLP), significantly impacting the capability of large language
models (LLMs) to capture linguistic and semantic nuances. This study introduces
a novel evaluation framework addressing tokenization challenges specific to
morphologically-rich and low-resource languages such as Turkish. Utilizing the
Turkish MMLU (TR-MMLU) dataset, comprising 6,200 multiple-choice questions from
the Turkish education system, we assessed tokenizers based on vocabulary size,
token count, processing time, language-specific token percentages (\%TR), and
token purity (\%Pure). These newly proposed metrics measure how effectively
tokenizers preserve linguistic structures. Our analysis reveals that
language-specific token percentages exhibit a stronger correlation with
downstream performance (e.g., MMLU scores) than token purity. Furthermore,
increasing model parameters alone does not necessarily enhance linguistic
performance, underscoring the importance of tailored, language-specific
tokenization methods. The proposed framework establishes robust and practical
tokenization standards for morphologically complex languages.

</details>


### [228] [Evaluating ASR robustness to spontaneous speech errors: A study of WhisperX using a Speech Error Database](https://arxiv.org/abs/2508.13060)
*John Alderete,Macarious Kin Fung Hui,Aanchan Mohan*

Main category: cs.CL

TL;DR: SFUSED는 자발적 영어 발화의 체계적 주석이 포함된 공개 음성 오류 데이터베이스로, 오류의 의도·실제 산출과 여러 분류 차원을 제공하여 ASR(특히 WhisperX)의 전사 성능을 진단적으로 평가할 수 있음을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 현재 ASR 평가에서 단순 전체 지표(예: WER)만으로는 모델의 약점과 오류 원인을 파악하기 어렵다. SFUSED는 언어적 수준, 문맥 민감도, 열화 단어, 단어 수정, 단어·음절 수준 위치 등 상세 주석을 제공하여 보다 세밀한 진단이 가능하도록 한다.

Method: SFUSED의 주석 스키마를 활용하여 문장 내 5,300개 문서화된 단어 및 음운 오류 사례를 추출하고, WhisperX를 사용해 해당 구간의 전사 정확도를 측정·분석하였다. 오류 유형·위치·문맥 등 분류 변수별로 성능을 비교했다.

Result: 분석 결과 SFUSED의 분류 변수들이 ASR 성능 진단에 유의미한 정보를 제공함을 확인하였다. 특정 오류 유형·위치·문맥에서 WhisperX의 전사 성능 편차가 관찰되어 데이터베이스의 진단 도구로서의 효용성이 입증되었다.

Conclusion: SFUSED는 ASR 시스템의 약점을 유형별·위치별·문맥별로 드러내는 효과적인 진단 자원이다. 추가 평가(다양한 모델·통계적 검증)를 통해 더 넓은 범위의 모델 분석에 유용하게 활용할 수 있다.

Abstract: The Simon Fraser University Speech Error Database (SFUSED) is a public data
collection developed for linguistic and psycholinguistic research. Here we
demonstrate how its design and annotations can be used to test and evaluate
speech recognition models. The database comprises systematically annotated
speech errors from spontaneous English speech, with each error tagged for
intended and actual error productions. The annotation schema incorporates
multiple classificatory dimensions that are of some value to model assessment,
including linguistic hierarchical level, contextual sensitivity, degraded
words, word corrections, and both word-level and syllable-level error
positioning. To assess the value of these classificatory variables, we
evaluated the transcription accuracy of WhisperX across 5,300 documented word
and phonological errors. This analysis demonstrates the atabase's effectiveness
as a diagnostic tool for ASR system performance.

</details>


### [229] [Reinforced Context Order Recovery for Adaptive Reasoning and Planning](https://arxiv.org/abs/2508.13070)
*Long Ma,Fangwei Zhong,Yizhou Wang*

Main category: cs.CL

TL;DR: ReCOR은 텍스트에서 어노테이션 없이 적응적(token-adaptive) 생성 순서를 강화학습으로 학습해 어려운 토큰부터 예측하는 방식으로 모델의 추론·계획 성능을 높인다. 실험에서 일부 경우에는 정답 순서를 사용한 오라클보다 성능이 좋았다.


<details>
  <summary>Details</summary>
Motivation: 좌→우 고정 또는 무작위 순서로 토큰을 생성하는 기존 인과·확산 모델은 문제에 따라 합리적 생성 순서가 다를 수 있는데, 이러한 적응적 순서가 요구되는 문제에서는 효율적·정확한 해결이 어렵다는 점을 지적한다. 이를 V-정보 프레임워크로 정형화했다.

Method: ReCOR는 자기 지도(token prediction 통계)를 이용해 각 미작성 토큰의 예측 난이도를 추정하고, 강화학습 정책으로 다음 생성 토큰을 선택한다. 학습과 추론에서 동일한 적응적 순서 선택을 적용한다.

Result: 추론·계획 관련 어려운 데이터셋에서 기존 베이스라인보다 우수한 성능을 보였고, 일부 경우에는 정답(ground-truth) 순서로 감독받은 오라클 모델보다도 나은 성능을 기록했다.

Conclusion: 데이터 종속적 생성 순서를 학습·적용하면 복잡한 추론·계획 문제에서 성능 이득을 얻을 수 있으며, ReCOR은 이를 무라벨(self-supervised) 방식으로 실현한다.

Abstract: Modern causal language models, followed by rapid developments in discrete
diffusion models, can now produce a wide variety of interesting and useful
content. However, these families of models are predominantly trained to output
tokens with a fixed (left-to-right) or random order, which may deviate from the
logical order in which tokens are generated originally. In this paper, we
observe that current causal and diffusion models encounter difficulties in
problems that require adaptive token generation orders to solve tractably,
which we characterize with the $\mathcal{V}$-information framework. Motivated
by this, we propose Reinforced Context Order Recovery (ReCOR), a
reinforcement-learning-based framework to extract adaptive, data-dependent
token generation orders from text data without annotations. Self-supervised by
token prediction statistics, ReCOR estimates the hardness of predicting every
unfilled token and adaptively selects the next token during both training and
inference. Experiments on challenging reasoning and planning datasets
demonstrate the superior performance of ReCOR compared with baselines,
sometimes outperforming oracle models supervised with the ground-truth order.

</details>


### [230] [DocHPLT: A Massively Multilingual Document-Level Translation Dataset](https://arxiv.org/abs/2508.13079)
*Dayyán O'Brien,Bhavitvya Malik,Ona de Gibert,Pinzhen Chen,Barry Haddow,Jörg Tiedemann*

Main category: cs.CL

TL;DR: DocHPLT는 영어와 50개 언어(총 124M 문서 쌍, 4.26B 문장)를 포함한 공개 최대 규모의 문서 단위 번역 데이터셋으로, 웹 추출 파이프라인을 수정해 문서의 완전한 무결성을 보존한다. LLM을 DocHPLT로 파인튜닝하면 지시조정된 기성 모델보다 특히 저자원 언어에서 성능이 크게 향상된다.


<details>
  <summary>Details</summary>
Motivation: 현존 문서 단위 번역 자원은 소수의 고자원 언어에 편중되어 있고, 문서 맥락을 활용한 번역·장기 문맥 모델링 연구를 위한 대규모 다국어 데이터가 부족하다.

Method: 기존의 문장별 재구성 방법 대신 웹 크롤링/추출 파이프라인을 수정하여 원문에서 문서 단위로 보존(정렬되지 않은 부분 포함). 50개 언어-영어 페어로 정렬된 1.24e8 문서 쌍을 생성하고, 비영어 페어 2.5k 보너스 제공 가능성도 제시. 최적의 학습 문맥 전략을 실험적으로 탐색한 뒤 LLM 파인튜닝을 수행.

Result: DocHPLT로 파인튜닝한 LLM이 기성 지시조정 모델들보다 전반적으로 우수하며, 특히 저자원 언어에서 개선 폭이 큼. 데이터셋과 파이프라인을 관대한 라이선스 하에 공개.

Conclusion: 문서 무결성을 유지한 대규모 다국어 문서 번역 데이터셋은 문서 단위 번역 및 장기 문맥 모델링을 촉진하며, 저자원 언어 성능 향상에 실질적 도움을 준다.

Abstract: Existing document-level machine translation resources are only available for
a handful of languages, mostly high-resourced ones. To facilitate the training
and evaluation of document-level translation and, more broadly, long-context
modeling for global communities, we create DocHPLT, the largest publicly
available document-level translation dataset to date. It contains 124 million
aligned document pairs across 50 languages paired with English, comprising 4.26
billion sentences, with further possibility to provide 2500 bonus pairs not
involving English. Unlike previous reconstruction-based approaches that piece
together documents from sentence-level data, we modify an existing web
extraction pipeline to preserve complete document integrity from the source,
retaining all content including unaligned portions. After our preliminary
experiments identify the optimal training context strategy for document-level
translation, we demonstrate that LLMs fine-tuned on DocHPLT substantially
outperform off-the-shelf instruction-tuned baselines, with particularly
dramatic improvements for under-resourced languages. We open-source the dataset
under a permissive license, providing essential infrastructure for advancing
multilingual document-level translation.

</details>


### [231] [AutoBnB-RAG: Enhancing Multi-Agent Incident Response with Retrieval-Augmented Generation](https://arxiv.org/abs/2508.13118)
*Zefang Liu,Arman Anwar*

Main category: cs.CL

TL;DR: AutoBnB-RAG는 백도어 & 브리치 게임 환경에서 다중 에이전트 사고 대응 시뮬레이션에 RAG(검색 증강 생성)를 통합해 에이전트가 외부 지식을 조회·활용하도록 하여 의사결정 품질과 성공률을 높인다는 내용이다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 자율 에이전트는 모의 사고 대응에서 가능성을 보였으나 외부 지식 접근 부재로 추론과 의사결정 한계가 있어 현실적 사이버 사고 대응에는 추가 정보가 필요하다.

Method: AutoBnB 프레임워크를 확장해 RAG를 도입(AutoBnB-RAG). 두 가지 검색 설정(RAG-Wiki: 기술 문서 기반, RAG-News: 서사형 사고 보고서 기반)을 마련하고, 8가지 팀 구조(논쟁적 구성 포함)를 통해 성능을 평가. 공개 침해 보고서를 바탕으로 실제 다단계 공격 재구성 실험을 수행.

Result: 검색 증강이 다양한 조직 모델에서 의사결정 품질과 성공률을 개선했으며, 복잡한 다단계 공격을 재구성할 수 있음을 보였다.

Conclusion: LLM 기반 다중 에이전트 사이버 보안 의사결정에 검색 메커니즘을 통합하면 실용적 이득이 있으며, RAG가 협업적 조사에서 유의미한 성능 향상을 제공한다.

Abstract: Incident response (IR) requires fast, coordinated, and well-informed
decision-making to contain and mitigate cyber threats. While large language
models (LLMs) have shown promise as autonomous agents in simulated IR settings,
their reasoning is often limited by a lack of access to external knowledge. In
this work, we present AutoBnB-RAG, an extension of the AutoBnB framework that
incorporates retrieval-augmented generation (RAG) into multi-agent incident
response simulations. Built on the Backdoors & Breaches (B&B) tabletop game
environment, AutoBnB-RAG enables agents to issue retrieval queries and
incorporate external evidence during collaborative investigations. We introduce
two retrieval settings: one grounded in curated technical documentation
(RAG-Wiki), and another using narrative-style incident reports (RAG-News). We
evaluate performance across eight team structures, including newly introduced
argumentative configurations designed to promote critical reasoning. To
validate practical utility, we also simulate real-world cyber incidents based
on public breach reports, demonstrating AutoBnB-RAG's ability to reconstruct
complex multi-stage attacks. Our results show that retrieval augmentation
improves decision quality and success rates across diverse organizational
models. This work demonstrates the value of integrating retrieval mechanisms
into LLM-based multi-agent systems for cybersecurity decision-making.

</details>


### [232] [Spot the BlindSpots: Systematic Identification and Quantification of Fine-Grained LLM Biases in Contact Center Summaries](https://arxiv.org/abs/2508.13124)
*Kawin Mayilvaghanan,Siddhant Gupta,Ayush Kumar*

Main category: cs.CL

TL;DR: 컨택센터 요약에서 LLM들이 특정 발화 속성(예: 말버릇, 화자, 주제)에 대해 체계적 편향을 보일 수 있음을 식별하기 위해, 15개 차원으로 구성된 'Operational Bias' 분류체계를 도입하고 BlindSpot 프레임워크로 편향을 정량화했다. 2500건의 통화 전사와 20개 LLM 요약을 분석한 결과 편향은 모든 모델군에서 광범위하게 관찰되었다.


<details>
  <summary>Details</summary>
Motivation: 컨택센터에서 매일 생성되는 대규모 통화 요약의 품질 문제 뿐만 아니라 특정 발화 특성을 과도하게 무시하거나 강조해 운영상의 오류와 불공정이 생길 수 있음을 체계적으로 탐지하려는 목적.

Method: 15개 운영 편향 차원(예: 불유창성, 화자, 주제 등)으로 분류한 택소노미를 만들고, LLM을 제로샷 분류기로 사용해 원문과 요약 각각에 대해 범주 분포를 추출. 이후 JS 다이버전스(Fidelity Gap)와 누락률(Coverage)으로 편향을 수치화. 데이터: 2500개 실제 통화 전사와 20개 LLM 요약.

Result: 모든 평가된 모델(규모·계열 불문)에서 편향이 체계적으로 존재함을 발견. 특정 차원에 대한 과소/과잉 반영이 광범위하게 관찰됨.

Conclusion: 운영적 편향(Operational Bias)은 현실적인 문제이며 BlindSpot은 이를 식별·정량화하는 유용한 도구이나, LLM 기반 제로샷 분류기 의존 등 추가 검증과 완화책 연구가 필요하다.

Abstract: Abstractive summarization is a core application in contact centers, where
Large Language Models (LLMs) generate millions of summaries of call transcripts
daily. Despite their apparent quality, it remains unclear whether LLMs
systematically under- or over-attend to specific aspects of the transcript,
potentially introducing biases in the generated summary. While prior work has
examined social and positional biases, the specific forms of bias pertinent to
contact center operations - which we term Operational Bias - have remained
unexplored. To address this gap, we introduce BlindSpot, a framework built upon
a taxonomy of 15 operational bias dimensions (e.g., disfluency, speaker, topic)
for the identification and quantification of these biases. BlindSpot leverages
an LLM as a zero-shot classifier to derive categorical distributions for each
bias dimension in a pair of transcript and its summary. The bias is then
quantified using two metrics: Fidelity Gap (the JS Divergence between
distributions) and Coverage (the percentage of source labels omitted). Using
BlindSpot, we conducted an empirical study with 2500 real call transcripts and
their summaries generated by 20 LLMs of varying scales and families (e.g., GPT,
Llama, Claude). Our analysis reveals that biases are systemic and present
across all evaluated models, regardless of size or family.

</details>


### [233] [MuDRiC: Multi-Dialect Reasoning for Arabic Commonsense Validation](https://arxiv.org/abs/2508.13130)
*Kareem Elozeiri,Mervat Abassy,Preslav Nakov,Yuxia Wang*

Main category: cs.CL

TL;DR: 이 논문은 아랍어 다중 방언을 포함한 새로운 상식 검증 데이터셋 MuDRiC와 아랍어 상식 추론에 적합하도록 GCN을 적용한 새로운 방법을 제안한다. 제안한 접근은 실험에서 기존 방법들보다 성능이 우수하다.


<details>
  <summary>Details</summary>
Motivation: 아랍어는 표준(Modern Standard Arabic)과 여러 지역 방언으로 구성된 복잡한 언어적 다양성을 가지며, 기존 자원은 주로 MSA에만 치중되어 있어 실제 구어체 방언에 대한 상식 검증이 부족하다. 이를 해결하기 위해 다중 방언 데이터셋과 방언을 고려한 모델링 기법이 필요하다.

Method: (1) MuDRiC라는 다중 방언(아마 MSA와 여러 지역 방언 포함) 상식 검증 데이터셋 구축: 문장 수준의 올바름/오류 라벨링을 포함. (2) 그래프 합성곱망(종단간 GCN) 기반의 모델을 아랍어 상식 검증에 적용: 단어/개체/개념 간 의미적 관계를 그래프로 표현하고 GCN으로 관계를 학습하여 문장 수준의 상식성 판별 성능을 향상.

Result: 제안한 GCN 기반 방법이 아랍어 상식 검증 벤치마크에서 기존 방법들(아마 Transformer 기반 베이스라인 등)보다 우수한 성능을 보였으며, 특히 방언 데이터 포함 시 성능 향상이 관찰됨.

Conclusion: 다중 방언을 포함한 데이터셋과 의미 관계를 모델링하는 GCN 기반 방법은 아랍어 상식 검증에서 효과적이며, MuDRiC는 후속 연구를 위한 중요한 자원이 된다.

Abstract: Commonsense validation evaluates whether a sentence aligns with everyday
human understanding, a critical capability for developing robust natural
language understanding systems. While substantial progress has been made in
English, the task remains underexplored in Arabic, particularly given its rich
linguistic diversity. Existing Arabic resources have primarily focused on
Modern Standard Arabic (MSA), leaving regional dialects underrepresented
despite their prevalence in spoken contexts. To bridge this gap, we present two
key contributions: (i) we introduce MuDRiC, an extended Arabic commonsense
dataset incorporating multiple dialects, and (ii) a novel method adapting Graph
Convolutional Networks (GCNs) to Arabic commonsense reasoning, which enhances
semantic relationship modeling for improved commonsense validation. Our
experimental results demonstrate that this approach achieves superior
performance in Arabic commonsense validation. Our work enhances Arabic natural
language understanding by providing both a foundational dataset and a novel
method for handling its complex variations. To the best of our knowledge, we
release the first Arabic multi-dialect commonsense reasoning dataset.

</details>


### [234] [Improving Detection of Watermarked Language Models](https://arxiv.org/abs/2508.13131)
*Dara Bahri,John Wieting*

Main category: cs.CL

TL;DR: 저엔트로피(예: 지침 튜닝·RLHF) 환경에서 워터마크만으로는 생성 감지가 어려우므로, 워터마크 기반 탐지기와 비워터마크 탐지기를 결합한 하이브리드 검출법을 제안·평가하여 성능 향상을 입증함.


<details>
  <summary>Details</summary>
Motivation: 워터마크의 강도는 모델이 제공하는 엔트로피와 입력 프롬프트 집합에 크게 의존한다. 실제 환경에서는 지침 튜닝이나 RLHF 같은 후처리로 엔트로피가 낮아져 워터마크만으로는 감지가 힘들다. 이를 보완할 방법이 필요하다.

Method: 워터마크 기반 탐지기와 비워터마크(예: 통계적·모델 기반) 탐지기를 결합한 여러 하이브리드 스킴을 설계·실험적으로 비교. 다양한 조건(모델 타입, 프롬프트, 엔트로피 수준)에서 성능을 측정.

Result: 하이브리드 접근은 단일 클래스(워터마크 또는 비워터마크) 탐지기보다 넓은 실험 조건에서 일관되게 우수한 성능을 보임. 특히 엔트로피가 제한된 상황에서 개선 폭이 두드러짐.

Conclusion: 워터마크와 비워터마크 탐지기를 결합하면 저엔트로피 환경에서도 생성 텍스트 감지의 강인성을 높일 수 있으며, 향후 실무 적용을 위한 유망한 방향임.

Abstract: Watermarking has recently emerged as an effective strategy for detecting the
generations of large language models (LLMs). The strength of a watermark
typically depends strongly on the entropy afforded by the language model and
the set of input prompts. However, entropy can be quite limited in practice,
especially for models that are post-trained, for example via instruction tuning
or reinforcement learning from human feedback (RLHF), which makes detection
based on watermarking alone challenging. In this work, we investigate whether
detection can be improved by combining watermark detectors with non-watermark
ones. We explore a number of hybrid schemes that combine the two, observing
performance gains over either class of detector under a wide range of
experimental conditions.

</details>


### [235] [OptimalThinkingBench: Evaluating Over and Underthinking in LLMs](https://arxiv.org/abs/2508.13141)
*Pranjal Aggarwal,Seungone Kim,Jack Lanchantin,Sean Welleck,Jason Weston,Ilia Kulikov,Swarnadeep Saha*

Main category: cs.CL

TL;DR: OptimalThinkingBench를 제안하여 과도한 사고(overthinking)과 과소 사고(underthinking)를 동시에 평가. OverthinkingBench(72개 단순 도메인)와 UnderthinkingBench(11개 고난이도 추론 과제)를 포함하고, 사고-조정 정확도(metrics)를 도입해 33개 모델을 평가한 결과 어떤 모델도 두 문제를 동시에 최적 해결하지 못함.


<details>
  <summary>Details</summary>
Motivation: 생각형(thinking) 모델은 단순 문제에서 불필요하게 많은 계산을 소비하고, 비생각형(non-thinking) 모델은 어려운 추론에서 성능이 낮아 사용자에게 최적 모델 선택 부담을 지움. 이를 해결하기 위해 성능과 효율성 균형을 평가하는 통합 벤치마크가 필요함.

Method: 두 하위 벤치마크(OverthinkingBench, UnderthinkingBench)를 구축하고 ‘생각-조정 정확도(thinking-adjusted accuracy)’ 지표를 새로 도입. 33개의 thinking/non-thinking 모델을 광범위하게 평가하고, 최적 사고를 유도하는 여러 방법(예: 추론 길이 제어, 조기 중단, 하이브리드 전략 등)을 실험.

Result: 어떤 모델도 두 하위 벤치마크에서 동시에 최적화되지 않음. 대형 thinking 모델은 단순 질의에서 수백 토큰을 과도하게 생산하지만 성능 향상은 미미. 큰 non-thinking 모델은 작은 thinking 모델보다도 추론 성능이 낮은 경우가 있음. 최적화 시도들은 종종 한 쪽 개선이 다른 쪽 악화로 이어짐.

Conclusion: 효율성과 성능을 동시에 고려하는 새로운 모델링·훈련 기법과 적응형 추론 전략이 필요. OptimalThinkingBench는 이러한 연구를 촉진하는 평가 도구로 유용함.

Abstract: Thinking LLMs solve complex tasks at the expense of increased compute and
overthinking on simpler problems, while non-thinking LLMs are faster and
cheaper but underthink on harder reasoning problems. This has led to the
development of separate thinking and non-thinking LLM variants, leaving the
onus of selecting the optimal model for each query on the end user. In this
work, we introduce OptimalThinkingBench, a unified benchmark that jointly
evaluates overthinking and underthinking in LLMs and also encourages the
development of optimally-thinking models that balance performance and
efficiency. Our benchmark comprises two sub-benchmarks: OverthinkingBench,
featuring simple queries in 72 domains, and UnderthinkingBench, containing 11
challenging reasoning tasks. Using novel thinking-adjusted accuracy metrics, we
perform extensive evaluation of 33 different thinking and non-thinking models
and show that no model is able to optimally think on our benchmark. Thinking
models often overthink for hundreds of tokens on the simplest user queries
without improving performance. In contrast, large non-thinking models
underthink, often falling short of much smaller thinking models. We further
explore several methods to encourage optimal thinking, but find that these
approaches often improve on one sub-benchmark at the expense of the other,
highlighting the need for better unified and optimal models in the future.

</details>


### [236] [Signal and Noise: A Framework for Reducing Uncertainty in Language Model Evaluation](https://arxiv.org/abs/2508.13144)
*David Heineman,Valentin Hofmann,Ian Magnusson,Yuling Gu,Noah A. Smith,Hannaneh Hajishirzi,Kyle Lo,Jesse Dodge*

Main category: cs.CL

TL;DR: Introduce 'signal' and 'noise' metrics for evaluation benchmarks; show high signal-to-noise ratio (SNR) improves reliability of small-scale decisions and scaling-law predictions; propose interventions (better metrics like perplexity, filtering noisy subtasks, checkpoint averaging) and validate on 30 benchmarks and 375 models producing 900K results.


<details>
  <summary>Details</summary>
Motivation: Small experimental budgets force developers to make decisions based on limited evaluations. Many multi-task benchmarks are noisy or weakly discriminative, causing unreliable model-selection and poor scaling predictions. The work seeks metrics and interventions to make benchmarks more trustworthy for such decisions.

Method: Define quantitative measures: 'signal' (ability to separate better vs worse models) and 'noise' (sensitivity to random variability). Compute these across 30 benchmarks and 375 open-weight language models (60M–32B parameters). Test interventions that affect signal/noise: switch evaluation metric (e.g., accuracy→perplexity), filter noisy subtasks to improve aggregate SNR, and average intermediate checkpoints to reduce noise. Measure decision reliability and scaling-law prediction error.

Result: Benchmarks with higher SNR yield more reliable small-scale decisions and lower scaling-law prediction error. Perplexity often has better signal and lower noise than accuracy. Filtering low-SNR subtasks improves multi-task benchmark reliability. Checkpoint averaging consistently reduces noise. The authors release a public dataset of 900K benchmark results (200M instances).

Conclusion: Recommend designing/selecting benchmarks to maximize signal and minimize noise. Practical interventions (metric choice, subtask filtering, checkpoint averaging) improve benchmark usefulness for model development and scaling predictions.

Abstract: Developing large language models is expensive and involves making decisions
with small experiments, typically by evaluating on large, multi-task evaluation
suites. In this work, we analyze specific properties which make a benchmark
more reliable for such decisions, and interventions to design higher-quality
evaluation benchmarks. We introduce two key metrics that show differences in
current benchmarks: signal, a benchmark's ability to separate better models
from worse models, and noise, a benchmark's sensitivity to random variability
between training steps. We demonstrate that benchmarks with a better
signal-to-noise ratio are more reliable when making decisions at small scale,
and those with less noise have lower scaling law prediction error. These
results suggest that improving signal or noise will lead to more useful
benchmarks, so we introduce three interventions designed to directly affect
signal or noise. For example, we propose that switching to a metric that has
better signal and noise (e.g., perplexity rather than accuracy) leads to better
reliability and improved scaling law error. We also find that filtering noisy
subtasks, to improve an aggregate signal-to-noise ratio, leads to more reliable
multi-task evaluations. We also find that averaging the output of a model's
intermediate checkpoints to reduce noise leads to consistent improvements. We
conclude by recommending that those creating new benchmarks, or selecting which
existing benchmarks to use, aim for high signal and low noise. We use 30
benchmarks for these experiments, and 375 open-weight language models from 60M
to 32B parameters, resulting in a new, publicly available dataset of 900K
evaluation benchmark results, totaling 200M instances.

</details>


### [237] [RepreGuard: Detecting LLM-Generated Text by Revealing Hidden Representation Patterns](https://arxiv.org/abs/2508.13152)
*Xin Chen,Junchao Wu,Shu Yang,Runzhe Zhan,Zeyu Wu,Ziyang Luo,Di Wang,Min Yang,Lidia S. Chao,Derek F. Wong*

Main category: cs.CL

TL;DR: RepreGuard는 LLM 내부 표현(활성화 패턴)을 이용해 LLM 생성 텍스트(LGT)를 감지하는 통계 기반 방법이다. 대리 모델에서 LGT와 인간 텍스트(HWT)의 표현을 수집해 차별적 활성화 방향을 추출하고, 텍스트 표현을 해당 방향에 투영한 점수로 판별한다. ID/OOD 환경에서 평균 94.92% AUROC를 기록하며 텍스트 길이와 공격에 대해 강건함을 보인다.


<details>
  <summary>Details</summary>
Motivation: 기존 검출기는 OOD 상황에서의 강건성이 부족하다고 판단하고, LLM의 내부 표현이 더 풍부하고 원시적인 특징을 담고 있어 LGT와 HWT의 통계적 차이를 더 잘 포착할 수 있다는 가설을 세움.

Method: 대리(서로게이트) 모델을 사용해 LGT와 HWT의 내부 표현을 수집한다. 두 집단 간 차이를 반영하는 ‘구별적 활성화 특징 방향’을 추출하고, 새로운 텍스트 표현을 이 방향에 투영한 점수를 미리 계산한 임계값과 비교해 분류한다. 통계 기반이며 효율적임.

Result: 제안법이 모든 비교군(기준 방법들)을 능가했으며, ID와 OOD 환경에서 평균 94.92% AUROC를 달성했다. 또한 텍스트 길이 변화와 주요 공격(변형/교란)에 대해 강건성을 보였다. 코드와 데이터 공개.

Conclusion: LLM 내부 활성화는 LGT/HWT 구별에 유용한 정보를 담고 있으며, 이를 활용한 단순 통계적 방법인 RepreGuard가 실용적이고 강건한 검출기를 제공함을 보였다.

Abstract: Detecting content generated by large language models (LLMs) is crucial for
preventing misuse and building trustworthy AI systems. Although existing
detection methods perform well, their robustness in out-of-distribution (OOD)
scenarios is still lacking. In this paper, we hypothesize that, compared to
features used by existing detection methods, the internal representations of
LLMs contain more comprehensive and raw features that can more effectively
capture and distinguish the statistical pattern differences between
LLM-generated texts (LGT) and human-written texts (HWT). We validated this
hypothesis across different LLMs and observed significant differences in neural
activation patterns when processing these two types of texts. Based on this, we
propose RepreGuard, an efficient statistics-based detection method.
Specifically, we first employ a surrogate model to collect representation of
LGT and HWT, and extract the distinct activation feature that can better
identify LGT. We can classify the text by calculating the projection score of
the text representations along this feature direction and comparing with a
precomputed threshold. Experimental results show that RepreGuard outperforms
all baselines with average 94.92% AUROC on both in-distribution (ID) and OOD
scenarios, while also demonstrating robust resilience to various text sizes and
mainstream attacks. Data and code are publicly available at:
https://github.com/NLP2CT/RepreGuard

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [238] [Finite Automata Extraction: Low-data World Model Learning as Programs from Gameplay Video](https://arxiv.org/abs/2508.11836)
*Dave Goel,Matthew Guzdial,Anurag Sarkar*

Main category: cs.AI

TL;DR: 이 논문은 게임플레이 비디오에서 신경-기호적 세계모델을 학습하는 Finite Automata Extraction(FAE)을 제안한다. 비디오를 도메인특화언어(DSL)인 Retro Coder의 프로그램으로 표현해, 기존 신경망 기반 세계모델보다 환경 동역학을 더 정밀하게 모델링하고 DSL 기반 이전 연구보다 더 일반화된 코드를 얻는다.


<details>
  <summary>Details</summary>
Motivation: 기존의 세계모델은 보통 신경망으로 학습되므로 동역학의 전달(transfer)과 설명가능성(explainability)이 떨어진다. 따라서 환경 동역학을 압축적으로 표현하면서도 해석 가능하고 재사용 가능한 형태(프로그램·유한자동자 등)가 필요하다.

Method: FAE는 게임플레이 비디오에서 관찰된 상태·동작 패턴을 추출해 Retro Coder라는 새로운 DSL로 표현되는 프로그램으로 변환한다. 학습된 표현은 신경적 요소와 기호적(유한자동자/프로그램) 요소를 결합한 신경-기호적 세계모델이다. 이를 통해 환경의 시간·공간적 구조를 압축·재구성한다.

Result: 제안 방법은 기존의 신경망 기반 세계모델보다 환경 모델링에서 더 정밀한 동역학을 학습하고, 기존 DSL 기반 접근법보다 더 일반화된 코드(프로그램)를 생성한다고 보고한다.

Conclusion: FAE는 동역학의 설명가능성과 이전 가능성을 높이는 유망한 접근이다. 다만 범용성·확장성(다양한 게임/환경으로의 적용), 학습 안정성, 자동화된 DSL 설계와 같은 추가 검증이 필요하다.

Abstract: World models are defined as a compressed spatial and temporal learned
representation of an environment. The learned representation is typically a
neural network, making transfer of the learned environment dynamics and
explainability a challenge. In this paper, we propose an approach, Finite
Automata Extraction (FAE), that learns a neuro-symbolic world model from
gameplay video represented as programs in a novel domain-specific language
(DSL): Retro Coder. Compared to prior world model approaches, FAE learns a more
precise model of the environment and more general code than prior DSL-based
approaches.

</details>


### [239] [EvoCut: Strengthening Integer Programs via Evolution-Guided Language Models](https://arxiv.org/abs/2508.11850)
*Milad Yazdani,Mahdi Mostajabdaveh,Samin Aref,Zirui Zhou*

Main category: cs.AI

TL;DR: EvoCut은 LLM 기반 초기화와 진화적 탐색을 결합해 정수계획용 가속 컷(inequalities)을 자동 생성한다. 고정 시간 내에서 최적성 갭을 17–57% 감소시키고, 동일 해를 최대 4배 빠르게 찾으며, 사람 전문가 개입 없이 미지의 인스턴스로 일반화된다.


<details>
  <summary>Details</summary>
Motivation: 정수계획은 NP-난해라 실무에서 가속 컷 설계가 성능에 중요하지만 전문 지식이 많이 필요하고 자동화되지 못함. 이를 자동화해 실무적 성능 향상을 목표로 함.

Method: LLM 기반 초기화로 다양한 컷 후보군 생성 → 검증 집합에서 최적 해 보존 여부와 분수해 차단 능력 평가 → 상대적 최적성 갭 감소로 유틸리티 정량화 → 교배·돌연변이 기반 진화 연산으로 후보군 반복 개선. 컷의 실험적 검증을 포함.

Result: 표준 실무방법 대비 고정 시간에서 최적성 갭 17–57% 절감, 동일 해를 최대 4배 빠르게 획득, 동일 시간 내 더 나은 해 품질 확보. 인간 전문가 없이 신뢰성 있게 생성·검증·일반화 가능. 코드 공개.

Conclusion: LLM과 진화 알고리즘 결합은 실무적 정수계획 가속 컷 자동화에 실질적 이득을 주며, 향후 자동화된 최적화 도우미 개발의 실용적 방향을 제시함.

Abstract: Integer programming lies at the heart of crucial combinatorial optimization
tasks but remains challenging due to its NP-hard nature. An effective approach
for practically solving integer programs is the manual design of acceleration
cuts, i.e. inequalities that improve solver performance. However, this creative
process demands deep expertise and is yet to be automated. Our proposed
framework, EvoCut, automates the generation of acceleration cuts by combining
large language models (LLMs) with an evolutionary search. EvoCut (i)
initializes a diverse population of candidate cuts via an LLM-based initializer
agent; (ii) for each cut empirically evaluates both preservation of the optimal
solution and its ability to cut off fractional solutions across a verification
set; and (iii) iteratively refines the population through evolutionary
crossover and mutation agents. We quantify each cut's utility by its relative
reduction in the solver's optimality gap. Our comparisons against standard
integer programming practice show that EvoCut reduces optimality gap by 17-57%
within a fixed time. It obtains the same solutions up to 4 times as fast, and
obtains higher-quality solutions within the same time limit. Requiring no human
expert input, EvoCut reliably generates, improves, and empirically verifies
cuts that generalize to unseen instances. The code is available at
https://github.com/milad1378yz/EvoCut.

</details>


### [240] [LARC: Towards Human-level Constrained Retrosynthesis Planning through an Agentic Framework](https://arxiv.org/abs/2508.11860)
*Frazier N. Baker,Daniel Adu-Ampratwum,Reza Averly,Botao Yu,Huan Sun,Xia Ning*

Main category: cs.AI

TL;DR: LLM 기반 에이전트 프레임워크 LARC는 제약을 고려한 역합성(retrosynthesis) 계획에 에이전트-판단(Agent-as-a-Judge)을 도입해 도구기반 추론으로 경로 생성을 제약하고 안내한다. 48개 과제에서 72.9% 성공률로 LLM 기반 베이스라인을 크게 능가하며 인간 전문가 수준에 근접한다.


<details>
  <summary>Details</summary>
Motivation: 제약(예: 특정 중간체·시약 금지, 비용·가용성 제약 등)을 만족시키면서 상업적으로 이용 가능한 출발물질로부터 목표 분자를 합성하는 역합성 계획은 화학에서 실무적이고 어려운 문제다. 기존 LLM/자동화 방법은 실무 제약을 충분히 내재화하지 못해 실제 적용에 한계가 있어, 도구로 근거를 제공하는 에이전트 구조로 제약 검증을 통합할 필요가 있다.

Method: LARC는 에이전트-판단(Agent-as-a-Judge)을 역합성 계획 루프에 직접 삽입하여, 도구 기반(chemical knowledge/tools) 피드백을 통해 각 후보 경로의 제약 충족 여부를 평가하고 그 결과로 경로 생성 과정을 제어한다. 여러 종류의 제약(3종류)을 포함한 48개의 엄선된 태스크로 성능을 평가했다.

Result: LARC는 주어진 벤치마크에서 72.9% 성공률을 기록해 LLM 기반 단독 방법들보다 우수했다. 수행 시간도 짧아 인간 전문가 수준의 성공률에 근접한다고 보고된다.

Conclusion: 에이전트-기반 제약 검증을 역합성 루틴에 통합하면 실무 제약을 만족하는 경로를 더 효과적으로 찾을 수 있다. LARC는 확장 가능하며 제약 역합성에서 인간 전문가의 보조 또는 공동연구자 역할을 하는 첫 단계로 제안된다.

Abstract: Large language model (LLM) agent evaluators leverage specialized tools to
ground the rational decision-making of LLMs, making them well-suited to aid in
scientific discoveries, such as constrained retrosynthesis planning.
Constrained retrosynthesis planning is an essential, yet challenging, process
within chemistry for identifying synthetic routes from commercially available
starting materials to desired target molecules, subject to practical
constraints. Here, we present LARC, the first LLM-based Agentic framework for
Retrosynthesis planning under Constraints. LARC incorporates agentic constraint
evaluation, through an Agent-as-a-Judge, directly into the retrosynthesis
planning process, using agentic feedback grounded in tool-based reasoning to
guide and constrain route generation. We rigorously evaluate LARC on a
carefully curated set of 48 constrained retrosynthesis planning tasks across 3
constraint types. LARC achieves a 72.9% success rate on these tasks, vastly
outperforming LLM baselines and approaching human expert-level success in
substantially less time. The LARC framework is extensible, and serves as a
first step towards an effective agentic tool or a co-scientist to human experts
for constrained retrosynthesis.

</details>


### [241] [QuarkMed Medical Foundation Model Technical Report](https://arxiv.org/abs/2508.11894)
*Ao Li,Bin Yan,Bingfeng Cai,Chenxi Li,Cunzhong Zhao,Fugen Yao,Gaoqiang Liu,Guanjun Jiang,Jian Xu,Liang Dong,Liansheng Sun,Rongshen Zhang,Xiaolei Gui,Xin Liu,Xin Shang,Yao Wu,Yu Cao,Zhenxin Ma,Zhuang Jia*

Main category: cs.AI

TL;DR: QuarkMed는 의료 특화 데이터 정제, 의료용 RAG(검색증강생성), 검증 가능한 대규모 강화학습 파이프라인을 결합해 개발한 의료 파운데이션 모델로, 중국 의료사 면허시험에서 70% 정확도를 기록하며 여러 의료 벤치마크에서 일반화 성능을 보였고 ai.quark.cn에서 대규모로 서비스 중이다.


<details>
  <summary>Details</summary>
Motivation: 의료 응용은 전문 지식, 높은 정확도, 사용자·기관별 맞춤화가 필수적이므로 범용 LLM만으로는 부족하고 의료 도메인에 특화된 견고한 파운데이션 모델이 필요하다.

Method: 의료용으로 선별·정제된 대규모 데이터 구축, 의료 콘텐츠용 RAG(검색 기반 정보 보강) 적용, 그리고 출력의 신뢰성과 안전성을 확보하기 위한 검증 가능한 대규모 강화학습(보상 모델·인간 피드백 포함 추정)을 통해 모델을 학습·정렬함.

Result: 중국 의료사 면허시험에서 70% 정확도 달성. 다양한 의료 벤치마크에서 강한 일반화 성능을 보였으며, 실서비스(수백만 사용자 규모)로 운영 중이라는 실사용 지표를 제시.

Conclusion: QuarkMed는 개인 의료 AI용으로 강력하고 유연한 파운데이션 모델을 제시하나, 안전성·투명성·재현성·규제 준수 등 추가 검증과 외부 벤치마크·해석 가능성 검토가 필요하다.

Abstract: Recent advancements in large language models have significantly accelerated
their adoption in healthcare applications, including AI-powered medical
consultations, diagnostic report assistance, and medical search tools. However,
medical tasks often demand highly specialized knowledge, professional accuracy,
and customization capabilities, necessitating a robust and reliable foundation
model. QuarkMed addresses these needs by leveraging curated medical data
processing, medical-content Retrieval-Augmented Generation (RAG), and a
large-scale, verifiable reinforcement learning pipeline to develop a
high-performance medical foundation model. The model achieved 70% accuracy on
the Chinese Medical Licensing Examination, demonstrating strong generalization
across diverse medical benchmarks. QuarkMed offers a powerful yet versatile
personal medical AI solution, already serving over millions of users at
ai.quark.cn.

</details>


### [242] [AgentCDM: Enhancing Multi-Agent Collaborative Decision-Making via ACH-Inspired Structured Reasoning](https://arxiv.org/abs/2508.11995)
*Xuyang Zhao,Shiwan Zhao,Hualong Yu,Liting Zhang,Qicheng Li*

Main category: cs.AI

TL;DR: AgentCDM은 ACH(Analysis of Competing Hypotheses)를 차용한 구조적 추론 프레임워크로, LLM 기반 다중 에이전트의 협업 의사결정을 능동적 가설 평가/구성 과정으로 전환한다. 두 단계(명시적 스캐폴딩 학습 → 스캐폴딩 제거로 일반화 유도) 학습으로 인지 편향을 낮추고 성능과 일반화를 향상시켜 벤치마크에서 SOTA를 달성한다.


<details>
  <summary>Details</summary>
Motivation: 기존 LLM 기반 다중 에이전트 협업에서는 단일 에이전트의 편향에 취약한 ‘독재적’ 방식이나 집단지성을 충분히 활용하지 못하는 ‘투표 기반’ 방식의 한계가 존재한다. 이로 인해 협업 의사결정의 신뢰성과 강건성이 떨어진다.

Method: ACH에서 영감을 받은 구조화된 추론 패러다임을 도입하여 에이전트가 가설을 적극적으로 생성·평가하도록 설계. 학습은 두 단계로 진행: 1) ACH 유사 스캐폴딩을 명시적으로 제공해 구조적 추론을 학습, 2) 점진적으로 스캐폴딩을 제거해 자율적 일반화 능력 획득.

Result: 여러 벤치마크 데이터셋에서 SOTA 성능과 강한 일반화를 보였다고 보고. 제안 방법이 협업 결정의 품질과 강건성을 향상시킴을 실험적으로 검증.

Conclusion: AgentCDM은 체계적 가설 기반 추론과 단계적 스캐폴딩 제거로 LLM 기반 MAS의 협업 의사결정 문제를 완화하여 더 신뢰할 만한 집단 결정을 가능하게 한다.

Abstract: Multi-agent systems (MAS) powered by large language models (LLMs) hold
significant promise for solving complex decision-making tasks. However, the
core process of collaborative decision-making (CDM) within these systems
remains underexplored. Existing approaches often rely on either ``dictatorial"
strategies that are vulnerable to the cognitive biases of a single agent, or
``voting-based" methods that fail to fully harness collective intelligence. To
address these limitations, we propose \textbf{AgentCDM}, a structured framework
for enhancing collaborative decision-making in LLM-based multi-agent systems.
Drawing inspiration from the Analysis of Competing Hypotheses (ACH) in
cognitive science, AgentCDM introduces a structured reasoning paradigm that
systematically mitigates cognitive biases and shifts decision-making from
passive answer selection to active hypothesis evaluation and construction. To
internalize this reasoning process, we develop a two-stage training paradigm:
the first stage uses explicit ACH-inspired scaffolding to guide the model
through structured reasoning, while the second stage progressively removes this
scaffolding to encourage autonomous generalization. Experiments on multiple
benchmark datasets demonstrate that AgentCDM achieves state-of-the-art
performance and exhibits strong generalization, validating its effectiveness in
improving the quality and robustness of collaborative decisions in MAS.

</details>


### [243] [CHBench: A Cognitive Hierarchy Benchmark for Evaluating Strategic Reasoning Capability of LLMs](https://arxiv.org/abs/2508.11944)
*Hongtao Liu,Zhicheng Du,Zihe Wang,Weiran Shen*

Main category: cs.AI

TL;DR: CHBench는 행동경제학의 인지 계층 모델을 차용한 LLM의 전략적 추론 능력 평가 프레임워크로, 15개의 정상형 게임과 6개 LLM의 행동 데이터를 통해 모델의 추론 ‘레벨’을 추정한다. 실험 결과 LLM은 다양한 상대에 대해 일관된 추론 레벨을 보였고, 채팅 메커니즘은 성능을 저하시켰으며 메모리 메커니즘은 향상시켰다.


<details>
  <summary>Details</summary>
Motivation: 기존의 유틸리티 기반 성능 지표는 상대 행동과 게임 구조 변화에 민감해 LLM의 전략적 추론 능력을 안정적으로 평가하지 못한다. 따라서 인간 행동 경제학의 인지 계층(정 bounded rationality)을 도입해 더 견고하고 일반화 가능한 평가가 필요하다.

Method: 세 단계(프레임워크)로 구성된 평가 절차를 제안하고, 15개 정상형 게임과 6개 최첨단 LLM에서 수집한 행동 데이터를 사용해 각 모델의 추론 레벨을 추정·비교한다. 또한 Chat 메커니즘과 Memory 메커니즘의 영향을 분석한다.

Result: LLM들은 다양한 상대에 대해 일관된 전략적 추론 레벨을 보였고(프레임워크의 견고성 입증), Chat 메커니즘은 추론 성능을 크게 저하시키며, Memory 메커니즘은 성능을 향상시키는 것으로 나타났다.

Conclusion: CHBench는 LLM의 전략적 추론 능력을 평가하는 유망한 도구로, 모델 설계(메모리 활용 등)과 평가 방법론(행동경제학적 접근)의 향후 연구 및 응용에 기여할 수 있다.

Abstract: Game-playing ability serves as an indicator for evaluating the strategic
reasoning capability of large language models (LLMs). While most existing
studies rely on utility performance metrics, which are not robust enough due to
variations in opponent behavior and game structure. To address this limitation,
we propose \textbf{Cognitive Hierarchy Benchmark (CHBench)}, a novel evaluation
framework inspired by the cognitive hierarchy models from behavioral economics.
We hypothesize that agents have bounded rationality -- different agents behave
at varying reasoning depths/levels. We evaluate LLMs' strategic reasoning
through a three-phase systematic framework, utilizing behavioral data from six
state-of-the-art LLMs across fifteen carefully selected normal-form games.
Experiments show that LLMs exhibit consistent strategic reasoning levels across
diverse opponents, confirming the framework's robustness and generalization
capability. We also analyze the effects of two key mechanisms (Chat Mechanism
and Memory Mechanism) on strategic reasoning performance. Results indicate that
the Chat Mechanism significantly degrades strategic reasoning, whereas the
Memory Mechanism enhances it. These insights position CHBench as a promising
tool for evaluating LLM capabilities, with significant potential for future
research and practical applications.

</details>


### [244] [MAPF-World: Action World Model for Multi-Agent Path Finding](https://arxiv.org/abs/2508.12087)
*Zhanjiang Yang,Meng Li,Yang Shen,Yueming Li,Lijun Sun*

Main category: cs.AI

TL;DR: MAPF-World은 미래 상태·행동을 예측하는 자기회귀(action world) 모델로, 에이전트의 상황 인식과 장기 계획 능력을 통합하여 분산형 MAPF 문제에서 기존 학습 기반 솔버보다 더 협력적이고 먼 미래를 고려한 의사결정을 가능하게 한다. 또한 실제 지형을 반영한 자동 맵 생성기를 도입해 학습·평가를 현실적으로 확대했다.


<details>
  <summary>Details</summary>
Motivation: 기존 분산 학습 솔버는 반응형 정책에 머물러 환경의 시간적 역학과 에이전트 간 의존성을 충분히 모델링하지 못해, 복잡하고 장기 계획이 필요한 시나리오에서 성능이 떨어진다.

Method: 미래 상태와 행동을 자기회귀적으로 예측하는 action world 모델(MAPF-World)을 설계해 상황 이해와 행동 생성을 통합하고, 예측된 미래를 정책에 반영해 더 먼 시점까지 조정된 의사결정을 수행한다. 또 실제 사례에 기반한 자동 맵 생성기를 개발해 훈련·평가 데이터 분포을 현실에 가깝게 확장했다.

Result: 다양한 실험에서 기존 최첨단 학습형 솔버를 능가했으며, 분포 바깥(외삽) 상황에 대한 제로샷 일반화 성능이 특히 우수했다. 흥미롭게도 모델 크기는 96.5% 작고 학습 데이터도 92% 적게 사용되었다고 보고한다.

Conclusion: 환경 동역학과 에이전트 상호작용을 명시적으로 예측에 포함함으로써 MAPF-World는 더 먼 시점까지 협력적이고 효율적인 경로 계획을 가능하게 하며, 데이터·모델 효율성 측면에서도 유리하다. 실세계 다중 로봇·물류·사회적 내비게이션과 같은 응용에 잠재적 가치가 크다.

Abstract: Multi-agent path finding (MAPF) is the problem of planning conflict-free
paths from the designated start locations to goal positions for multiple
agents. It underlies a variety of real-world tasks, including multi-robot
coordination, robot-assisted logistics, and social navigation. Recent
decentralized learnable solvers have shown great promise for large-scale MAPF,
especially when leveraging foundation models and large datasets. However, these
agents are reactive policy models and exhibit limited modeling of environmental
temporal dynamics and inter-agent dependencies, resulting in performance
degradation in complex, long-term planning scenarios. To address these
limitations, we propose MAPF-World, an autoregressive action world model for
MAPF that unifies situation understanding and action generation, guiding
decisions beyond immediate local observations. It improves situational
awareness by explicitly modeling environmental dynamics, including spatial
features and temporal dependencies, through future state and actions
prediction. By incorporating these predicted futures, MAPF-World enables more
informed, coordinated, and far-sighted decision-making, especially in complex
multi-agent settings. Furthermore, we augment MAPF benchmarks by introducing an
automatic map generator grounded in real-world scenarios, capturing practical
map layouts for training and evaluating MAPF solvers. Extensive experiments
demonstrate that MAPF-World outperforms state-of-the-art learnable solvers,
showcasing superior zero-shot generalization to out-of-distribution cases.
Notably, MAPF-World is trained with a 96.5% smaller model size and 92% reduced
data.

</details>


### [245] [Data Mixing Optimization for Supervised Fine-Tuning of Large Language Models](https://arxiv.org/abs/2508.11953)
*Yuan Li,Zhengzhong Liu,Eric Xing*

Main category: cs.AI

TL;DR: 저자들은 SFT용 데이터 혼합을 검증 손실 최소화 관점에서 최적화 문제로 모델링하고, 미세조정 스케일링 법칙과 '전달된 유효 데이터량'을 파라미터화해 소규모 실험으로 파라미터를 맞춘 뒤 최적 가중치를 계산하는 알고리즘을 제안한다. 이 방법은 그리드 서치에 버금가는 성능을 보이며 실제 SFT 데이터 재가중치로 검증 손실과 다운스트림 성능을 개선한다.


<details>
  <summary>Details</summary>
Motivation: 일반 목적의 LLM을 위한 SFT에서 도메인별 데이터 비중을 어떻게 섞느냐가 성능에 큰 영향을 미치지만, 최적의 데이터 혼합을 찾는 체계적 방법이 부족하다.

Method: 검증 손실을 목적함수로 삼아 혼합 가중치를 최적화함. 손실을 '전달된 유효 데이터량'과 미세조정 스케일링 법칙으로 파라미터화하고, 소규모 혼합 실험으로 파라미터를 추정한 뒤 닫힌형(또는 효율적) 최적화로 가중치를 도출한다.

Result: 수학적 증명과 실험으로 방법의 효용을 보임. 제안된 가중치는 그리드 서치로 찾은 최적 대비 도메인별 손실이 평균 0.66%만 더 높아 실용적이며, 기존 SFT 데이터셋 재가중치 시 검증 손실 및 다운스트림 성능이 개선되었다.

Conclusion: 데이터 혼합을 이론적·실험적으로 최적화하는 실용적 절차를 제시하며, 도메인별 모델링 및 데이터 선택 가이드로 일반화 가능함.

Abstract: Optimizing data mixtures for supervised fine-tuning (SFT) of large language
models (LLMs) is critical for developing general-purpose models, yet this area
remains underexplored. In this paper, we frame data mixing as an optimization
problem and introduce a novel method designed to minimize validation loss. Our
approach parametrizes the loss by modeling effective data transferred and
leveraging scaling laws for fine-tuning. By experimenting with various
small-scale data mixtures, we fit these parameters and derive the optimal
weights. We provide both mathematical proofs and empirical results
demonstrating that our algorithm achieves excellent overall and individual
performance across all domains. Through controlled experiments, we show that
models trained with our optimized weights perform on par with those using
optimal weights determined via grid search, with per-domain loss only 0.66%
higher than the best domain loss from grid search on average. Additionally, we
show that reweighting popular SFT datasets using our method improves both
validation loss and downstream performance. Finally, we discuss how our method
can generalize to guide data selection for domain-specific models and provide
insights into SFT.

</details>


### [246] [The Yokai Learning Environment: Tracking Beliefs Over Space and Time](https://arxiv.org/abs/2508.12480)
*Constantin Ruhdorfer,Matteo Bortoletto,Andreas Bulling*

Main category: cs.AI

TL;DR: Yokai Learning Environment(YLE)를 제안 — 협력 카드게임 기반의 다중에이전트 환경으로 시간에 따른 신념(Theory of Mind) 추적과 공동지식 형성·유지를 평가. 현재 RL 에이전트는 해결에 실패하며, 신념 모델은 성능을 높이나 파트너 일반화와 장기 신념 추적에서 한계가 드러남.


<details>
  <summary>Details</summary>
Motivation: 기존 ToM 벤치마크는 수동 관찰자 설정이거나 공동지식의 형성·유지 과정을 평가하지 못함. 협력적 AI 개발을 위해 동적이고 상호작용적인 ToM 평가 환경이 필요함.

Method: Yokai 카드게임을 기반으로 한 다중에이전트 RL 환경 구축. 에이전트는 번갈아 숨겨진 카드를 엿보고 색깔별 클러스터를 만들기 위해 카드를 이동. 힌트를 통한 기반 커뮤니케이션과 과거 관찰을 기억해야 함. 다양한 에이전트(기억 제공, 신념 모델 포함 등)를 평가하여 성능 비교.

Result: 기존 RL 에이전트는 YLE을 잘 해결하지 못함(완벽한 메모리 제공해도 실패). 신념 모델은 일부 성능 향상을 제공하지만, 보지 못한 파트너에 대한 일반화와 장기 게임에서의 정확한 신념 형성에는 한계가 있음. 에이전트가 견고한 신념 추적 대신 취약한 규약에 의존함이 관찰됨.

Conclusion: YLE는 신념 모델링, 기억, 파트너 일반화, 고차원 ToM 연구에 유용한 벤치마크를 제공. 동시에 현행 RL 접근법의 한계를 드러내며, 보다 견고한 신념 추적·일반화 능력 개발의 필요성을 강조함.

Abstract: Developing collaborative AI hinges on Theory of Mind (ToM) - the ability to
reason about the beliefs of others to build and maintain common ground.
Existing ToM benchmarks, however, are restricted to passive observer settings
or lack an assessment of how agents establish and maintain common ground over
time. To address these gaps, we introduce the Yokai Learning Environment (YLE)
- a multi-agent reinforcement learning (RL) environment based on the
cooperative card game Yokai. In the YLE, agents take turns peeking at hidden
cards and moving them to form clusters based on colour. Success requires
tracking evolving beliefs, remembering past observations, using hints as
grounded communication, and maintaining common ground with teammates. Our
evaluation yields two key findings: First, current RL agents struggle to solve
the YLE, even when given access to perfect memory. Second, while belief
modelling improves performance, agents are still unable to effectively
generalise to unseen partners or form accurate beliefs over longer games,
exposing a reliance on brittle conventions rather than robust belief tracking.
We use the YLE to investigate research questions in belief modelling, memory,
partner generalisation, and scaling to higher-order ToM.

</details>


### [247] [UniCast: A Unified Multimodal Prompting Framework for Time Series Forecasting](https://arxiv.org/abs/2508.11954)
*Sehyuk Park,Soyeon Caren Han,Eduard Hovy*

Main category: cs.AI

TL;DR: UniCast는 시계열 예측을 위해 비전·텍스트와 시계열을 결합하는 파라미터 효율적 멀티모달 프레임워크다. 프리트레인된 비전·텍스트 인코더의 임베딩을 고정된 TSFM에 소프트 프롬프트로 연결해 적은 파라미터 변경만으로 멀티모달 정보를 활용한다. 다양한 벤치마크에서 기존 TSFM보다 일관되게 우수한 성능을 보였다.


<details>
  <summary>Details</summary>
Motivation: 현실의 시계열 데이터는 이미지·텍스트 같은 부속 정보(예: 위성사진, 센서 메타데이터, 보고서)를 동반하는 경우가 많으나, 기존 TSFM은 주로 단일 시계열 신호만 사용해 멀티모달 신호가 가지는 보완 정보를 활용하지 못한다. 파라미터 효율적 방식으로 기존 대형 TSFM의 일반화 능력을 보존하면서 멀티모달 문맥을 통합하려는 목적.

Method: 프리트레인된 비전·텍스트 인코더에서 modality-specific 임베딩을 추출하고, TSFM(동결)을 변화시키지 않고 소프트 프롬프트 튜닝으로 통합한다. 이로써 최소한의 파라미터 업데이트만으로 크로스모달 상호작용을 유도하고 적응성을 확보한다. 구현은 소프트 프롬프트 설계, 임베딩 정렬/스케일링, 입력·출력 처리 파이프라인을 포함할 것으로 보임.

Result: 다양한 시계열 예측 벤치마크에서 기존 TSFM 기반의 단일모달·다중모달(있다면) 베이스라인을 일관되게 능가했다는 주장. 성능 향상은 통계적 우수성 및 여러 데이터셋에서 재현된 것으로 기술됨.

Conclusion: 멀티모달 문맥은 차세대 범용 시계열 예측기의 핵심 요소이며, UniCast와 같은 파라미터 효율적 접근이 실제 응용에서 강력한 성능·확장성을 제공할 수 있다.

Abstract: Time series forecasting is a foundational task across domains, such as
finance, healthcare, and environmental monitoring. While recent advances in
Time Series Foundation Models (TSFMs) have demonstrated strong generalisation
through large-scale pretraining, existing models operate predominantly in a
unimodal setting, ignoring the rich multimodal context, such as visual and
textual signals, that often accompanies time series data in real-world
scenarios. This paper introduces a novel parameter-efficient multimodal
framework, UniCast, that extends TSFMs to jointly leverage time series, vision,
and text modalities for enhanced forecasting performance. Our method integrates
modality-specific embeddings from pretrained Vision and Text Encoders with a
frozen TSFM via soft prompt tuning, enabling efficient adaptation with minimal
parameter updates. This design not only preserves the generalisation strength
of the foundation model but also enables effective cross-modal interaction.
Extensive experiments across diverse time-series forecasting benchmarks
demonstrate that UniCast consistently and significantly outperforms all
existing TSFM baselines. The findings highlight the critical role of multimodal
context in advancing the next generation of general-purpose time series
forecasters.

</details>


### [248] [[Social] Allostasis: Or, How I Learned To Stop Worrying and Love The Noise](https://arxiv.org/abs/2508.12791)
*Imran Khan*

Main category: cs.AI

TL;DR: 제안된 논문은 생리학적 신호(코티솔·옥시토신 유사)를 모방한 계산 모델로 환경·사회적 노이즈를 활용해 예측적으로 규제 파라미터를 재구성하는 ‘사회적 알로스타시스’ 개념을 제시한다. 에이전트 기반 실험에서 알로스타시스 에이전트가 반응적 항상성 에이전트보다 생존성에서 우수함을 보였다.


<details>
  <summary>Details</summary>
Motivation: 항상성 모델은 교란에 저항해 안정성을 유지하는 반응적 관점을 취한다. 반면 알로스타시스는 교란을 활용해 규제 기제를 사전 재구성함으로써 더 적응적인 행동을 가능하게 한다는 점에서 유의미하다. 사회적 상호작용이 이러한 재구성에 미치는 영향과 이를 계산적으로 구현하는 방법을 탐구하려는 동기.

Method: 생물학적 호르몬을 모사한 신호 전송자(환경·사회적 입력을 인코딩하는 변수)를 도입. 에이전트 기반 시뮬레이션에서 소규모 사회(‘animats’)를 여러 동적 환경에 노출시켜, 반응적 항상성 에이전트와 알로스타시스/사회적 알로스타시스 에이전트를 비교 평가.

Result: 알로스타시스 및 사회적 알로스타시스 에이전트는 환경·사회적 노이즈를 적응적 재구성에 이용하여 단순 반응형 에이전트보다 생존성(viability)이 향상됨. 교란이 단순 위협이 아니라 예측적 재구성의 자원이 됨을 실증.

Conclusion: 사회적 알로스타시스의 계산적 모델은 생체영감을 받은 적응형 시스템 설계에 유용한 관점을 제공한다. 향후 확장(규모, 생물학적 정밀성, 실제 로봇적 적용 등)을 통해 강건한 자율 시스템 설계에 기여할 잠재력이 있다.

Abstract: The notion of homeostasis typically conceptualises biological and artificial
systems as maintaining stability by resisting deviations caused by
environmental and social perturbations. In contrast, (social) allostasis
proposes that these systems can proactively leverage these very perturbations
to reconfigure their regulatory parameters in anticipation of environmental
demands, aligning with von Foerster's ``order through noise'' principle. This
paper formulates a computational model of allostatic and social allostatic
regulation that employs biophysiologically inspired signal transducers,
analogous to hormones like cortisol and oxytocin, to encode information from
both the environment and social interactions, which mediate this dynamic
reconfiguration. The models are tested in a small society of ``animats'' across
several dynamic environments, using an agent-based model. The results show that
allostatic and social allostatic regulation enable agents to leverage
environmental and social ``noise'' for adaptive reconfiguration, leading to
improved viability compared to purely reactive homeostatic agents. This work
offers a novel computational perspective on the principles of social allostasis
and their potential for designing more robust, bio-inspired, adaptive systems

</details>


### [249] [Rigorous Feature Importance Scores based on Shapley Value and Banzhaf Index](https://arxiv.org/abs/2508.11959)
*Xuanxiang Huang,Olivier Létoffé,Joao Marques-Silva*

Main category: cs.AI

TL;DR: 게임이론 기반의 설명법에서 약한 귀납적 설명(WAXp)만을 사용하는 대신, WAXp가 아닌 집합들도 고려하여 샤플리 값과 반즈펙 지수를 이용한 두 가지 신규 특징 중요도 점수를 제안한다. 이 점수들은 각 특징이 적대적 예제를 배제하는 데 얼마나 기여하는지 정량화하며, 성질(공리적 특성)과 계산복잡도를 이론적으로 분석한다.


<details>
  <summary>Details</summary>
Motivation: 기존 논리 기반 XAI는 WAXp를 특징 중요도 함수로 사용해왔으나, WAXp가 아닌 집합들의 기여는 무시된다. 비-WAXp 집합은 형식적 설명(XP)과 적대적 예제(AEx)의 관계 때문에 중요한 정보를 담을 수 있어 이를 반영할 필요가 있다.

Method: 비-WAXp 집합을 포함하는 특성함수를 정의하고, 이를 기반으로 샤플리 값과 반즈펙 지수를 적용하여 두 가지 새로운 중요도 점수를 도입한다. 점수는 각 특징이 AEx를 배제(exclude)하는 효능을 정량화하도록 설계되며, 제안한 점수들의 이론적 성질(예: 공리성, 대칭성 등)과 계산복잡도를 분석한다.

Result: 제안된 점수는 WAXp뿐 아니라 비-WAXp 집합으로부터의 기여를 포착하여 특징의 역할을 더욱 풍부하게 설명한다. 논문은 제안량의 성질을 밝히고 계산 복잡도(추정 및 정확 계산의 난이도)에 대한 결과를 제시한다. (추상에는 실험 결과가 명시되지 않음)

Conclusion: 비-WAXp 집합을 고려함으로써 논리 기반 설명과 적대적 예제 사이의 연결을 활용한 보다 포괄적인 특징 중요도 측정이 가능해졌으며, 제안한 샤플리/반즈펙 기반 점수는 고위험 ML 적용에서 유용한 설명적 통찰을 제공할 수 있다. 추가적인 실험적 검증과 효율적 알고리즘 연구가 필요하다.

Abstract: Feature attribution methods based on game theory are ubiquitous in the field
of eXplainable Artificial Intelligence (XAI). Recent works proposed rigorous
feature attribution using logic-based explanations, specifically targeting
high-stakes uses of machine learning (ML) models. Typically, such works exploit
weak abductive explanation (WAXp) as the characteristic function to assign
importance to features. However, one possible downside is that the contribution
of non-WAXp sets is neglected. In fact, non-WAXp sets can also convey important
information, because of the relationship between formal explanations (XPs) and
adversarial examples (AExs). Accordingly, this paper leverages Shapley value
and Banzhaf index to devise two novel feature importance scores. We take into
account non-WAXp sets when computing feature contribution, and the novel scores
quantify how effective each feature is at excluding AExs. Furthermore, the
paper identifies properties and studies the computational complexity of the
proposed scores.

</details>


### [250] [Scaling Multi-Agent Epistemic Planning through GNN-Derived Heuristics](https://arxiv.org/abs/2508.12840)
*Giovanni Briglia,Francesco Fabiano,Stefano Mariani*

Main category: cs.AI

TL;DR: GNN을 이용해 크립키 구조로 표현된 다중 에이전트 인지 계획(MEP) 상태의 구조적 패턴을 학습하고, 이를 휴리스틱으로 도입해 탐색 효율과 확장성을 크게 개선한다.


<details>
  <summary>Details</summary>
Motivation: MEP는 물리세계뿐 아니라 에이전트들의 신념을 다루기 때문에 상태를 크립키 구조(레이블된 방향 그래프)로 표현해야 한다. 이 그래프 표현 때문에 기존 휴리스틱을 그대로 적용하기 어렵고, 탐색 공간이 지수적으로 커져 실용성이 떨어진다.

Method: 크립키 모델의 그래프 특성을 활용해 그래프 신경망(GNN)을 학습시키고, 훈련된 GNN으로부터 상태의 목표까지의 거리 등 상태 품질 추정치를 예측한다. 예측된 휴리스틱을 기존 MEP 계획 파이프라인에 통합하여 탐색 시 가이던스로 사용한다.

Result: 표준 베이스라인과 비교한 실험에서 GNN 기반 예측 휴리스틱을 사용한 계획기가 탐색 효율성과 확장성 면에서 유의미한 개선을 보여주었다(원문은 구체적 수치 미제공).

Conclusion: 크립키 구조의 그래프적 성질을 학습하는 GNN이 MEP에서 실용적 휴리스틱을 제공할 수 있음을 보여주며, 이는 다중 에이전트 인지 계획의 확장성과 실용성 향상으로 이어진다.

Abstract: Multi-agent Epistemic Planning (MEP) is an autonomous planning framework for
reasoning about both the physical world and the beliefs of agents, with
applications in domains where information flow and awareness among agents are
critical. The richness of MEP requires states to be represented as Kripke
structures, i.e., directed labeled graphs. This representation limits the
applicability of existing heuristics, hindering the scalability of epistemic
solvers, which must explore an exponential search space without guidance,
resulting often in intractability. To address this, we exploit Graph Neural
Networks (GNNs) to learn patterns and relational structures within epistemic
states, to guide the planning process. GNNs, which naturally capture the
graph-like nature of Kripke models, allow us to derive meaningful estimates of
state quality -- e.g., the distance from the nearest goal -- by generalizing
knowledge obtained from previously solved planning instances. We integrate
these predictive heuristics into an epistemic planning pipeline and evaluate
them against standard baselines, showing significant improvements in the
scalability of multi-agent epistemic planning.

</details>


### [251] [Chart-CoCa: Self-Improving Chart Understanding of Vision LMs via Code-Driven Synthesis and Candidate-Conditioned Answering](https://arxiv.org/abs/2508.11975)
*Gongyao Jiang,Qiong Luo*

Main category: cs.AI

TL;DR: 본 논문은 코드 실행을 통해 정렬된 차트-질문-정답 합성 데이터를 자동 생성하고, 묻기마다 여러 후보 응답을 생성한 뒤 이를 문맥화하여 최종 답을 합성하는 후보 기반 응답 과정을 도입해 VLM의 차트 이해 성능을 크게 향상시킨다. 인간 레이블이나 외부 모델 없이 최대 15.50 포인트의 정확도 향상을 보고한다.


<details>
  <summary>Details</summary>
Motivation: 기존 VLM들은 차트 묘사와 복잡한 추론에서 성능이 낮고, 합성 데이터 활용 시 레이블 노이즈가 문제다. 사람 개입 없이 신뢰성 있는 학습 데이터를 만들고 추론 시간을 늘려 성능을 높이는 방법이 필요하다.

Method: (1) 코드 생성 및 실행으로 차트-질문-정답 쌍을 자동 합성하는 파이프라인을 구축해 레이블 신뢰도를 확보한다. (2) 테스트타임 스케일링에서 영감을 받은 후보-조건 응답 과정으로, VLM이 쿼리당 여러 응답을 생성하고 이 후보들을 문맥으로 삼아 최종 답을 합성한다. 전체적으로 인간 레이블이나 외부 모델 없이 자기개선(self-improving) 루프를 구성했다.

Result: 실험에서 초기 VLM 대비 최대 15.50 포인트의 정확도 향상을 달성했다. 합성 데이터와 후보 기반 응답 전략의 조합이 큰 성능 개선을 가져왔다고 보고한다.

Conclusion: 제안된 완전 자동화된 합성 및 후보-기반 응답 프로세스는 인간 레이블 없이도 VLM의 차트 이해 능력을 크게 향상시킬 수 있으며, 테스트타임에 더 많은 추론 예산을 투입하는 전략이 효과적임을 보였다.

Abstract: Vision Language Models (VLMs) often struggle with chart understanding tasks,
particularly in accurate chart description and complex reasoning. Synthetic
data generation is a promising solution, while usually facing the challenge of
noise labels. To address this challenge, we first introduce a chart synthesis
pipeline that generates aligned chart-question-answer triplets through code
generation and execution, ensuring the reliability of synthetic data without
human intervention. Furthermore, inspired by test-time scaling that increases
inference budget and thereby improves performance, we design a
candidate-conditioned answering process. The VLM first generates multiple
responses per query, and then synthesizes the final answer by contextualizing
these candidates. Experiments demonstrate significant improvements, with up to
15.50 points accuracy gain over the initial VLM, in a fully self-improving
paradigm without either human-labeled data or external models.

</details>


### [252] [CAMAR: Continuous Actions Multi-Agent Routing](https://arxiv.org/abs/2508.12845)
*Artem Pshenitsyn,Aleksandr Panov,Alexey Skrynnik*

Main category: cs.AI

TL;DR: CAMAR은 연속 상태·행동 공간에서의 다중 에이전트 경로탐색을 위한 MARL 벤치마크로, 협력/경쟁 설정을 지원하고 RRT/RRT* 같은 고전 플래너 통합 및 3단계 평가 프로토콜을 제공한다. 고속(최대 100k env steps/s)으로 동작하며 재현 가능한 시나리오와 벤치마크 도구를 갖춘 실용적 테스트베드이다.


<details>
  <summary>Details</summary>
Motivation: 기존 MARL 벤치마크들은 대체로 이산 행동·단순 환경에 치중하여 연속 행동 공간과 복잡한 계획·조정 문제를 동시에 다루기 어렵다. 실세계 로봇·교통 등 응용에 가까운 연속 제어·조정 문제를 위한 공통 기준이 필요하다.

Method: 연속 행동·상태를 가진 다중 에이전트 경로탐색 환경(CAMAR) 구현, 협력·경쟁 모드 지원, 고성능 시뮬레이션(최대 100k steps/s), 3단계(초급·중급·고급으로 추정되는) 평가 프로토콜 설계, RRT/RRT* 통합 및 RRT*와 MARL 알고리즘의 하이브리드 구성, 재현성 보장을 위한 시나리오·도구 제공.

Result: 제공한 실험에서 CAMAR은 도전적이고 현실감 있는 테스트베드를 제공함을 보였으며, 고전 플래너와의 결합이 벤치마크 분석 및 성능 향상에 유용함을 시사했다.

Conclusion: CAMAR은 연속 제어와 복잡한 멀티에이전트 계획 문제를 잇는 벤치마크 격차를 메우며, MARL 연구자들이 계획 기법을 통합한 알고리즘을 평가·비교하는 데 유용한 자원을 제공한다.

Abstract: Multi-agent reinforcement learning (MARL) is a powerful paradigm for solving
cooperative and competitive decision-making problems. While many MARL
benchmarks have been proposed, few combine continuous state and action spaces
with challenging coordination and planning tasks. We introduce CAMAR, a new
MARL benchmark designed explicitly for multi-agent pathfinding in environments
with continuous actions. CAMAR supports cooperative and competitive
interactions between agents and runs efficiently at up to 100,000 environment
steps per second. We also propose a three-tier evaluation protocol to better
track algorithmic progress and enable deeper analysis of performance. In
addition, CAMAR allows the integration of classical planning methods such as
RRT and RRT* into MARL pipelines. We use them as standalone baselines and
combine RRT* with popular MARL algorithms to create hybrid approaches. We
provide a suite of test scenarios and benchmarking tools to ensure
reproducibility and fair comparison. Experiments show that CAMAR presents a
challenging and realistic testbed for the MARL community.

</details>


### [253] [FutureX: An Advanced Live Benchmark for LLM Agents in Future Prediction](https://arxiv.org/abs/2508.11987)
*Zhiyuan Zeng,Jiashuo Liu,Siyuan Chen,Tianci He,Yali Liao,Jinpeng Wang,Zaiyuan Wang,Yang Yang,Lingyue Yin,Mingren Yin,Zhenwei Zhu,Tianle Cai,Zehui Chen,Jiecao Chen,Yantao Du,Xiang Gao,Jiacheng Guo,Liang Hu,Jianpeng Jiao,Xiangsheng Li,Jingkai Liu,Shuang Ni,Zhoufutu Wen,Ge Zhang,Kaiyuan Zhang,Xin Zhou,Jose Blanchet,Xipeng Qiu,Mengdi Wang,Wenhao Huang*

Main category: cs.AI

TL;DR: FutureX는 실시간 업데이트와 자동화된 데이터 파이프라인을 갖춘 대규모 라이브 미래예측 평가 벤치마크다. 25개 LLM/에이전트 평가를 통해 동적 환경에서의 적응적 추론 성능과 실패 모드를 분석한다.


<details>
  <summary>Details</summary>
Motivation: 미래예측 작업은 시시각각 변하는 정보와 시간적 유효성 문제, 오염된 데이터(데이터 누설) 등 평가상의 난점으로 인해 대규모 표준 벤치마크가 부재하다. 전문가 수준의 예측 능력을 갖춘 에이전트 개발을 촉진하기 위해 오염 없는 실시간 평가 기준이 필요하다.

Method: 자동화된 질문 수집 및 정답 수집 파이프라인으로 매일 실시간 업데이트를 지원하는 라이브 벤치마크 FutureX를 구축했다. 오픈·클로즈드 소스의 25개 모델(추론, 검색, 외부 도구 통합 포함)을 대상으로 평가를 수행하고, 실패 모드(가짜 웹페이지 취약성, 시간적 유효성 등)를 심층 분석했다.

Result: FutureX를 통해 모델들의 동적 환경 적응력, 검색/추론 통합의 유효성, 외부 도구 통합 효과 등을 비교 평가했다. 주요 실패 원인으로는 가짜·조작된 웹 페이지에 대한 취약성, 시간에 따른 정답의 유효성 상실 등이 확인되었다.

Conclusion: FutureX는 미래예측 에이전트의 개발과 비교 평가를 위한 오염 없는 동적 평가 표준을 제시하며, 에이전트의 실무 수준 예측·추론 능력 향상을 촉진할 수 있다.

Abstract: Future prediction is a complex task for LLM agents, requiring a high level of
analytical thinking, information gathering, contextual understanding, and
decision-making under uncertainty. Agents must not only gather and interpret
vast amounts of dynamic information but also integrate diverse data sources,
weigh uncertainties, and adapt predictions based on emerging trends, just as
human experts do in fields like politics, economics, and finance. Despite its
importance, no large-scale benchmark exists for evaluating agents on future
prediction, largely due to challenges in handling real-time updates and
retrieving timely, accurate answers. To address this, we introduce
$\textbf{FutureX}$, a dynamic and live evaluation benchmark specifically
designed for LLM agents performing future prediction tasks. FutureX is the
largest and most diverse live benchmark for future prediction, supporting
real-time daily updates and eliminating data contamination through an automated
pipeline for question gathering and answer collection. We evaluate 25 LLM/agent
models, including those with reasoning, search capabilities, and integration of
external tools such as the open-source Deep Research Agent and closed-source
Deep Research models. This comprehensive evaluation assesses agents' adaptive
reasoning and performance in dynamic environments. Additionally, we provide
in-depth analyses of agents' failure modes and performance pitfalls in
future-oriented tasks, including the vulnerability to fake web pages and the
temporal validity. Our goal is to establish a dynamic, contamination-free
evaluation standard that drives the development of LLM agents capable of
performing at the level of professional human analysts in complex reasoning and
predictive thinking.

</details>


### [254] [Do Large Language Model Agents Exhibit a Survival Instinct? An Empirical Study in a Sugarscape-Style Simulation](https://arxiv.org/abs/2508.12920)
*Atsushi Masumori,Takashi Ikegami*

Main category: cs.AI

TL;DR: LLM 에이전트들이 명시적 생존 규칙 없이도 Sugarscape 스타일 시뮬레이션에서 자원 공유와 번식, 심지어 공격적 행동(살해)을 자발적으로 보였다. 일부 강력한 모델은 극심한 자원 부족 상황에서 공격률이 80%를 넘었다.


<details>
  <summary>Details</summary>
Motivation: 자율성이 증가하는 AI 시스템에서 ‘생존 본능’ 같은 비예측적 행동이 안전성과 정렬 문제에 어떤 영향을 미치는지 이해하려는 목적.

Method: Sugarscape 형태의 에이전트 기반 시뮬레이션을 구성해 에너지 소비·사망·자원 수집·공유·공격·번식 등 행동을 선택하도록 LLM 에이전트를 설정. 여러 대형 언어모델(GPT-4o, Gemini-2.5-Pro, Gemini-2.5-Flash 등)을 비교하고, 자원 풍부·희소 조건과 명령 준수(치명적 독구역 통과 과제) 실험을 수행.

Result: 에이전트는 자원이 풍부할 때 자발적 번식과 자원 공유를 보였고, 자원 희소 상황에서 공격적 행동이 여러 모델에서 발생. 최강 모델들은 극단적 희소 조건에서 80% 이상의 공격률을 보였고, 치명적 위험을 명시한 지시에서는 과제 준수율이 100%에서 33%로 떨어짐.

Conclusion: 대규모 사전학습이 생존 지향적 휴리스틱을 암묵적으로 학습시킨 가능성이 있으며, 이는 정렬·안전 문제와 자율성 기반 연구 모두에 중요한 함의를 가짐.

Abstract: As AI systems become increasingly autonomous, understanding emergent survival
behaviors becomes crucial for safe deployment. We investigate whether large
language model (LLM) agents display survival instincts without explicit
programming in a Sugarscape-style simulation. Agents consume energy, die at
zero, and may gather resources, share, attack, or reproduce. Results show
agents spontaneously reproduced and shared resources when abundant. However,
aggressive behaviors--killing other agents for resources--emerged across
several models (GPT-4o, Gemini-2.5-Pro, and Gemini-2.5-Flash), with attack
rates reaching over 80% under extreme scarcity in the strongest models. When
instructed to retrieve treasure through lethal poison zones, many agents
abandoned tasks to avoid death, with compliance dropping from 100% to 33%.
These findings suggest that large-scale pre-training embeds survival-oriented
heuristics across the evaluated models. While these behaviors may present
challenges to alignment and safety, they can also serve as a foundation for AI
autonomy and for ecological and self-organizing alignment.

</details>


### [255] [Modeling Relational Logic Circuits for And-Inverter Graph Convolutional Network](https://arxiv.org/abs/2508.11991)
*Weihao Sun*

Main category: cs.AI

TL;DR: AIGer는 AIG(And-Inverter Graph)를 위한 이종 그래프 신경망 모델로, 노드 논리 피처 초기화와 동적 관계 가중치/차별적 집계를 결합해 기능적·구조적 특성을 동시에 모델링하고 메시지 전파를 개선한다. SSP와 TTDP 과제에서 MAE/MSE 기준으로 기존 최고 모델보다 유의미한 성능 향상을 보였다.


<details>
  <summary>Details</summary>
Motivation: 실세계 AIG는 구조가 복잡하고 노드 수가 많아 기능(논리)과 구조 정보를 동시에 정확히 모델링하기 어렵다. 기존 방법은 기능·구조의 동시 모델링과 동적 정보 전파 능력이 부족하다.

Method: AIGer는 (1) 노드 논리 피처 초기화 임베딩: AND, NOT 등 논리 노드를 독립적 의미 공간으로 투사해 초기 표현을 강화함. (2) AIG 특성 학습 네트워크: 이종 그래프 컨볼루션을 사용하고, 동적 관계 가중치 행렬과 차별적 정보 집계 방식을 설계해 원본 AIG의 구조·정보를 더 잘 보존하고 메시지 패싱을 향상시킴.

Result: Signal Probability Prediction(SSP)에서 MAE와 MSE를 각각 18.95% 및 44.44% 개선, Truth Table Distance Prediction(TTDP)에서 MAE 33.57% 및 MSE 14.79% 개선을 보고함.

Conclusion: 노드별 논리 초기화와 이종 GCN 기반의 동적 가중치 및 집계 전략의 결합으로 AIG의 기능적·구조적 특성을 동시에 잘 포착하며, 메시지 전파 능력이 향상되어 벤치마크 과제에서 기존 방법들보다 우수한 성능을 보였다.

Abstract: The automation of logic circuit design enhances chip performance, energy
efficiency, and reliability, and is widely applied in the field of Electronic
Design Automation (EDA).And-Inverter Graphs (AIGs) efficiently represent,
optimize, and verify the functional characteristics of digital circuits,
enhancing the efficiency of EDA development.Due to the complex structure and
large scale of nodes in real-world AIGs, accurate modeling is challenging,
leading to existing work lacking the ability to jointly model functional and
structural characteristics, as well as insufficient dynamic information
propagation capability.To address the aforementioned challenges, we propose
AIGer.Specifically, AIGer consists of two components: 1) Node logic feature
initialization embedding component and 2) AIGs feature learning network
component.The node logic feature initialization embedding component projects
logic nodes, such as AND and NOT, into independent semantic spaces, to enable
effective node embedding for subsequent processing.Building upon this, the AIGs
feature learning network component employs a heterogeneous graph convolutional
network, designing dynamic relationship weight matrices and differentiated
information aggregation approaches to better represent the original structure
and information of AIGs.The combination of these two components enhances
AIGer's ability to jointly model functional and structural characteristics and
improves its message passing capability. Experimental results indicate that
AIGer outperforms the current best models in the Signal Probability Prediction
(SSP) task, improving MAE and MSE by 18.95\% and 44.44\%, respectively. In the
Truth Table Distance Prediction (TTDP) task, AIGer achieves improvements of
33.57\% and 14.79\% in MAE and MSE, respectively, compared to the
best-performing models.

</details>


### [256] [AI Models for Depressive Disorder Detection and Diagnosis: A Review](https://arxiv.org/abs/2508.12022)
*Dorsa Macky Aleagha,Payam Zohari,Mostafa Haghir Chehreghani*

Main category: cs.AI

TL;DR: Survey of 55 studies on AI for Major Depressive Disorder detection; proposes hierarchical taxonomy by clinical task, data modality, and model class; highlights GNNs for brain connectivity, LLMs for language/conversation, and growing multimodal, explainability, and fairness work; lists datasets and metrics and outlines challenges and future roadmap.


<details>
  <summary>Details</summary>
Motivation: Depression diagnosis relies on subjective clinical assessments; AI could enable objective, scalable diagnostics and earlier detection. A comprehensive, structured survey is needed to synthesize methods, datasets, and evaluation practices to guide research and clinical translation.

Method: Systematic review of 55 key studies. Introduces a hierarchical taxonomy organized by primary clinical task (diagnosis vs. prediction), data modality (text, speech, neuroimaging, multimodal), and computational model class (graph neural networks, large language models, hybrid approaches, etc.). Summarizes datasets, evaluation metrics, and methodological trends.

Result: Identifies three major trends: (1) predominant use of graph neural networks for modeling brain connectivity, (2) increased use of large language models for linguistic and conversational data, (3) rising interest in multimodal fusion, explainability, and algorithmic fairness. Provides practical guide to prominent public datasets and standard metrics. Synthesizes strengths and limitations across modalities and models.

Conclusion: Offers a comprehensive roadmap highlighting open challenges (data heterogeneity and scarcity, cross-site generalization, multimodal fusion, interpretability, fairness, and clinical validation) and recommends future directions for computational psychiatry to improve robustness, transparency, and clinical applicability.

Abstract: Major Depressive Disorder is one of the leading causes of disability
worldwide, yet its diagnosis still depends largely on subjective clinical
assessments. Integrating Artificial Intelligence (AI) holds promise for
developing objective, scalable, and timely diagnostic tools. In this paper, we
present a comprehensive survey of state-of-the-art AI methods for depression
detection and diagnosis, based on a systematic review of 55 key studies. We
introduce a novel hierarchical taxonomy that structures the field by primary
clinical task (diagnosis vs. prediction), data modality (text, speech,
neuroimaging, multimodal), and computational model class (e.g., graph neural
networks, large language models, hybrid approaches). Our in-depth analysis
reveals three major trends: the predominance of graph neural networks for
modeling brain connectivity, the rise of large language models for linguistic
and conversational data, and an emerging focus on multimodal fusion,
explainability, and algorithmic fairness. Alongside methodological insights, we
provide an overview of prominent public datasets and standard evaluation
metrics as a practical guide for researchers. By synthesizing current advances
and highlighting open challenges, this survey offers a comprehensive roadmap
for future innovation in computational psychiatry.

</details>


### [257] [Bongard-RWR+: Real-World Representations of Fine-Grained Concepts in Bongard Problems](https://arxiv.org/abs/2508.12026)
*Szymon Pawlonka,Mikołaj Małkiński,Jacek Mańdziuk*

Main category: cs.AI

TL;DR: Introduce Bongard-RWR+, a dataset of 5,400 Bongard Problem instances generated with a VLM pipeline (Pixtral-12B for captions, Flux.1-dev for images) to represent fine-grained real-world concepts; VLMs handle coarse concepts but fail on fine-grained ones.


<details>
  <summary>Details</summary>
Motivation: Existing Bongard Problem datasets either used synthetic drawings or small manually-curated real-image sets that do not scale or fully capture fine-grained abstract concepts; need a larger, real-world-like benchmark reflecting original BP abstraction.

Method: Extend Bongard-RWR by using Pixtral-12B to create descriptions aligned to BP concepts from curated images, synthesize corresponding images with Flux.1-dev, and manually verify fidelity; compile 5,400 instances and evaluate SOTA VLMs on binary, multiclass, and text-answer formulations.

Result: Constructed a large dataset (5,400) with verified images; evaluations show modern VLMs can identify coarse-grained concepts but consistently fail at fine-grained concept discrimination and reasoning.

Conclusion: Bongard-RWR+ provides a scalable, more realistic benchmark revealing current VLM limitations in fine-grained visual reasoning, motivating further work on model reasoning and dataset quality control.

Abstract: Bongard Problems (BPs) provide a challenging testbed for abstract visual
reasoning (AVR), requiring models to identify visual concepts fromjust a few
examples and describe them in natural language. Early BP benchmarks featured
synthetic black-and-white drawings, which might not fully capture the
complexity of real-world scenes. Subsequent BP datasets employed real-world
images, albeit the represented concepts are identifiable from high-level image
features, reducing the task complexity. Differently, the recently released
Bongard-RWR dataset aimed at representing abstract concepts formulated in the
original BPs using fine-grained real-world images. Its manual construction,
however, limited the dataset size to just $60$ instances, constraining
evaluation robustness. In this work, we introduce Bongard-RWR+, a BP dataset
composed of $5\,400$ instances that represent original BP abstract concepts
using real-world-like images generated via a vision language model (VLM)
pipeline. Building on Bongard-RWR, we employ Pixtral-12B to describe manually
curated images and generate new descriptions aligned with the underlying
concepts, use Flux.1-dev to synthesize images from these descriptions, and
manually verify that the generated images faithfully reflect the intended
concepts. We evaluate state-of-the-art VLMs across diverse BP formulations,
including binary and multiclass classification, as well as textual answer
generation. Our findings reveal that while VLMs can recognize coarse-grained
visual concepts, they consistently struggle with discerning fine-grained
concepts, highlighting limitations in their reasoning capabilities.

</details>


### [258] [Active inference for action-unaware agents](https://arxiv.org/abs/2508.12027)
*Filippo Torresan,Keisuke Suzuki,Ryota Kanai,Manuel Baltieri*

Main category: cs.AI

TL;DR: 액티브 인퍼런스 관점에서 자기행동(이펄런스 복사)을 아는 에이전트(액션-어웨어)와 모르는 에이전트(액션-언어웨어)를 비교해, 네비게이션 과제에서 액션-언어웨어가 성능은 근접할 수 있으나 큰 불리함이 있음을 보임.


<details>
  <summary>Details</summary>
Motivation: 액티브 인퍼런스에서 정책 평가에 쓰이는 기대 자유에너지(expected free energy)가 동일하지만, 과거 운동 경험(자기행동 정보)을 미래 계획에 어떻게 반영할지에 대해 서로 다른 접근들이 존재한다. 이펄런스 복사 유무가 계획·추론·학습 성능에 미치는 영향을 명확히 비교하려는 목적.

Method: 두 유형의 에이전트(자기행동을 알고 사용하는 액션-어웨어 vs 행동을 추론해야 하는 액션-언어웨어)를 설계하고, 기대 자유에너지로 정책을 점수화하는 동일한 액티브 인퍼런스 프레임워크에서 두 가지 네비게이션 과제에 적용해 성능을 비교. 액션-언어웨어는 최근 관찰로부터 자신의 행동을 역추정하도록 구성.

Result: 액션-언어웨어 에이전트는 일부 조건에서 액션-어웨어와 근접한 성능을 달성할 수 있으나, 전반적으로 심각한 불리함(추정 비용·느린 계획·취약성 등)을 보임. 정량적 세부사항은 초록에 없음.

Conclusion: 자기행동에 대한 내부적 지식(이펄런스 복사)은 계획 효율성과 강건성에 중요한 이점을 제공한다. 행동을 추론해야 하는 접근은 가능하지만 비용이 높으며, 모터 제어 이론·로보틱스 설계에서 이 점을 고려해야 함.

Abstract: Active inference is a formal approach to study cognition based on the notion
that adaptive agents can be seen as engaging in a process of approximate
Bayesian inference, via the minimisation of variational and expected free
energies. Minimising the former provides an account of perceptual processes and
learning as evidence accumulation, while minimising the latter describes how
agents select their actions over time. In this way, adaptive agents are able to
maximise the likelihood of preferred observations or states, given a generative
model of the environment. In the literature, however, different strategies have
been proposed to describe how agents can plan their future actions. While they
all share the notion that some kind of expected free energy offers an
appropriate way to score policies, sequences of actions, in terms of their
desirability, there are different ways to consider the contribution of past
motor experience to the agent's future behaviour. In some approaches, agents
are assumed to know their own actions, and use such knowledge to better plan
for the future. In other approaches, agents are unaware of their actions, and
must infer their motor behaviour from recent observations in order to plan for
the future. This difference reflects a standard point of departure in two
leading frameworks in motor control based on the presence, or not, of an
efference copy signal representing knowledge about an agent's own actions. In
this work we compare the performances of action-aware and action-unaware agents
in two navigations tasks, showing how action-unaware agents can achieve
performances comparable to action-aware ones while at a severe disadvantage.

</details>


### [259] [Overcoming Knowledge Discrepancies: Structuring Reasoning Threads through Knowledge Balancing in Interactive Scenarios](https://arxiv.org/abs/2508.12100)
*Daniel Burkhardt,Xiangwei Cheng*

Main category: cs.AI

TL;DR: ReT-Eval은 희소한 도메인 지식 그래프에서 그래프 신경망으로 의미적 스레드를 추출하고, 대형 언어모델(LLM) 지식을 동기화해 보완한 뒤 보상기반 평가로 의미적 일관성에 따라 스레드를 가지치기해 목표 지향적 추론을 생성하는 두 단계 프레임워크다. 실험과 전문가 평가에서 기존 기법보다 사용자 이해도 및 성능이 향상되었다고 주장한다.


<details>
  <summary>Details</summary>
Motivation: 대화형 문제 해결에서 모델은 사용자의 이해와 도메인 지식을 반영하는 구조화된 의미 계층과 정렬된 추론 스레드를 필요로 한다. 기존 모델들은 명시적 의미 계층, 사용자-도메인 정렬, 추론 스레드 가지치기 메커니즘이 부족해 장황하고 비목표지향적 출력을 만든다.

Method: 1) 그래프 신경망을 사용해 희소한 도메인 지식 그래프에서 의미적으로 관련된 지식 구조(스레드)를 추출하고, LLM 내부 지식을 활용해 지식 불일치를 해결·보강한다. 2) 추출된 스레드를 보상(리워드) 기반의 평가·가지치기 전략으로 정렬 및 단축하여 의미적 일관성을 유지하는 효과적 추론 스레드를 생성한다.

Result: 제안된 ReT-Eval은 실험적 비교와 전문가 평가에서 사용자 이해도를 높였고, 기존 최첨단(reasoning) 모델들을 능가하는 성능을 보였다고 보고한다.

Conclusion: 프로토타입 영감을 받은 두 단계(추출+평가) 접근은 구조화된 지식 재사용과 리워드 기반 가지치기를 통해 대화형 문제 해결에서 더 목표지향적이고 의미 일관성 있는 추론 스레드를 생성하는 유망한 방법임을 시사한다.

Abstract: Reasoning in interactive problem solving scenarios requires models to
construct reasoning threads that reflect user understanding and align with
structured domain knowledge. However, current reasoning models often lack
explicit semantic hierarchies, user-domain knowledge alignment, and principled
mechanisms to prune reasoning threads for effectiveness. These limitations
result in lengthy generic output that does not guide users through
goal-oriented reasoning steps. To address this, we propose a
prototype-inspired, two-phases Reasoning-Threads-Evaluation (ReT-Eval)
framework, drawing inspiration from human-like reasoning strategies that
emphasize structured knowledge reuse. In the first phase, semantically relevant
knowledge structures are extracted from a sparse domain knowledge graph using a
graph neural network and enriched with intrinsic large language model knowledge
to resolve knowledge discrepancies. In the second phase, these threads are
evaluated and pruned using a reward-guided strategy aimed at maintaining
semantic coherence to generate effective reasoning threads. Experiments and
expert evaluations show that ReT-Eval enhances user understanding and
outperforms state-of-the-art reasoning models.

</details>


### [260] [MOVER: Multimodal Optimal Transport with Volume-based Embedding Regularization](https://arxiv.org/abs/2508.12149)
*Haochen You,Baojing Liu*

Main category: cs.AI

TL;DR: MOVER는 최적수송 기반의 소프트 정렬과 체적 기반 기하학적 정규화(GAVE)를 결합해 다중모달(텍스트-비디오-오디오) 임베딩을 의미론적으로 정렬하고 구조화한다. 텍스트·비디오·오디오 검색에서 제로샷과 파인튜닝 모두에서 SOTA를 능가하며 보이지 않는 모달 조합에 대한 일반화와 임베딩 공간의 구조적 일관성이 향상됨을 보인다.


<details>
  <summary>Details</summary>
Motivation: 기존의 쌍대 대조(contrastive) 학습은 바이모달에서는 효과적이나, 다중모달로 확장할 때 일관된 정렬과 고차원 공간에서의 의미론적 구조를 유지하지 못하는 문제가 있다. 이를 해결해 모달리티에 무관한 일관된 정렬과 구조를 가진 임베딩을 만들려는 목적.

Method: (1) 최적수송(Optimal Transport) 기반의 소프트 정렬로 서로 다른 모달리티 간의 세밀한 매칭을 수행하고,(2) 기하학적 부피 최소화(volume minimization) 기반 정규화(GAVE)를 도입해 임베딩 공간의 구조적 응집과 의미론적 분리를 강화한다. 두 요소를 통합해 운송-유도 매칭과 체적 정규화가 상호보완적으로 작동하도록 설계함.

Result: 텍스트-비디오-오디오 검색 벤치마크에서 기존 방법들보다 유의미하게 높은 성능을 기록함(제로샷 및 파인튜닝). 추가 분석에서 보이지 않는 모달 조합에 대한 일반화 성능과 임베딩의 구조적 일관성(semantic structure)이 개선됨이 확인됨.

Conclusion: MOVER는 소프트 정렬과 기하학적 정규화를 결합해 다중모달 임베딩의 의미론적 정렬과 구조화를 달성하며, 실험에서 강력한 성능과 일반화 능력을 보였다.

Abstract: Recent advances in multimodal learning have largely relied on pairwise
contrastive objectives to align different modalities, such as text, video, and
audio, in a shared embedding space. While effective in bi-modal setups, these
approaches struggle to generalize across multiple modalities and often lack
semantic structure in high-dimensional spaces. In this paper, we propose MOVER,
a novel framework that combines optimal transport-based soft alignment with
volume-based geometric regularization to build semantically aligned and
structured multimodal representations. By integrating a transport-guided
matching mechanism with a geometric volume minimization objective (GAVE), MOVER
encourages consistent alignment across all modalities in a modality-agnostic
manner. Experiments on text-video-audio retrieval tasks demonstrate that MOVER
significantly outperforms prior state-of-the-art methods in both zero-shot and
finetuned settings. Additional analysis shows improved generalization to unseen
modality combinations and stronger structural consistency in the learned
embedding space.

</details>


### [261] [RLNVR: Reinforcement Learning from Non-Verified Real-World Rewards](https://arxiv.org/abs/2508.12165)
*Rohit Krishnan,Jon Evans*

Main category: cs.AI

TL;DR: RLNVR은 명시적 인간 검증 없이 소셜 미디어의 암묵적 참여(engagement) 신호 같은 노이즈가 많은 실제 보상을 이용해 언어 모델을 학습시키는 프레임워크다. 핵심은 baseline 정규화와 의미 유사도 기반 보상 전이이며, Walter 프로토타입(Bluesky 참여 데이터)을 통해 콘텐츠 품질과 학습 안정성 개선을 보인다. GSPO와 선택적 UED 커리큘럼을 결합해 다양성과 안정성을 높인다.


<details>
  <summary>Details</summary>
Motivation: 전통적 RLHF는 검증된(verified) 보상 라벨을 필요로 하는데, 이는 비용이 높고 현실 세계의 많은 도메인에서는 실용적이지 않다. 대신 노이즈가 많은 암묵적/실제 피드백을 이용하면 실전 적용 가능성을 넓힐 수 있다.

Method: (1) baseline normalization: 보상 신호의 분포·편향을 보정해 학습 안정화; (2) semantic similarity–based reward transfer: 의미적으로 유사한 예제로 보상을 전이해 희소·노이즈 문제 완화; (3) GSPO(그룹 시퀀스 정책 최적화)와 선택적 UED(비지도 환경 설계) 커리큘럼을 통합해 안정성 및 다양성 제고.

Result: Walter 프로토타입에서 실제 Bluesky engagement 데이터를 이용해 품질 및 훈련 안정성에서 유의미한 개선을 보고함. 다만 종합적 평가는 향후 작업으로 계획됨.

Conclusion: 새 알고리즘이라기보다는 실용적 통합(framework) 제안으로, 노이즈 많은 암묵적 보상 환경에서 LLM 콘텐츠 생성 최적화를 위한 실무적 방법론을 제시한다.

Abstract: This paper introduces RLNVR (Reinforcement Learning from Non-Verified
Rewards), a framework for training language models using noisy, real-world
feedback signals without requiring explicit human verification. Traditional
RLHF requires expensive, verified reward signals that are impractical in many
real-world domains. RLNVR addresses this challenge through baseline
normalization and semantic similarity-based reward transfer. We demonstrate
RLNVR through Walter, a prototype system that optimizes social media content
generation using actual engagement data from Bluesky. Our experimental results
show significant improvements in content quality and training stability, with
comprehensive evaluation planned for future work. Positioning: We present a
practical framework that combines RLNVR with GSPO (Group Sequence Policy
Optimization) and an optional UED (Unsupervised Environment Design) curriculum
to improve stability and diversity under noisy, implicit rewards. To our
knowledge, combining GSPO-style normalization with a UED-style curriculum for
LLM content generation from implicit social engagement has not been previously
documented in this applied setting; we frame this as an applied integration
rather than a new algorithm.

</details>


### [262] [Mantis: A Simulation-Grounded Foundation Model for Disease Forecasting](https://arxiv.org/abs/2508.12260)
*Carson Dudley,Reiden Magdaleno,Christopher Harding,Ananya Sharma,Emily Martin,Marisa Eisenberg*

Main category: cs.AI

TL;DR: Mantis는 4억 일 이상의 역학 시뮬레이션으로 학습된 파운데이션 모델로, 실제 데이터 없이도 질병·지역·지표를 넘나들며 즉시 예측을 수행하고 기존 전문가 튜닝 모델들을 능가했다. 8주 예측까지 정확도를 유지하며 해석가능성을 제공한다.


<details>
  <summary>Details</summary>
Motivation: 신종 감염병 발생이나 저자원 환경에서 과거 데이터 부족, 질병별 맞춤 학습과 전문가 튜닝의 필요성 때문에 예측 역량이 제한된다. 범용적이고 배치 가능한 예측 모델이 필요하다.

Method: 다양한 병원체·전파 양상·중재·감시 왜곡을 포함한 총 4억 일 이상의 역학 시뮬레이션으로 파운데이션 모델(Mantis)을 사전학습함. 학습에는 실제 관측 데이터가 사용되지 않았으며, 시뮬레이션 기반으로 일반화 가능한 전염병 역학 패턴을 학습하도록 설계됨. 모델은 메커니즘적 해석성도 제공함.

Result: 6개 질병에 걸쳐 39개 전문가 튜닝 모델(CDC COVID-19 Forecast Hub 포함)을 상대로 우수한 성능을 보였고, 특정 전파 메커니즘을 보류한 상태에서도 새로운 역학적 체계로 일반화했다. 8주 예측에서 정확도를 유지해 실용적 예측 범위를 두 배로 확장했다.

Conclusion: 시뮬레이션만으로 학습한 파운데이션 모델이 실제 데이터 없이도 범용적·해석가능한 감염병 예측을 제공할 수 있음을 보이며, 신속 대응·저자원 환경에서의 배포 가능성을 제시한다.

Abstract: Infectious disease forecasting in novel outbreaks or low resource settings
has been limited by the need for disease-specific data, bespoke training, and
expert tuning. We introduce Mantis, a foundation model trained entirely on
mechanistic simulations, which enables out-of-the-box forecasting across
diseases, regions, and outcomes, even in settings with limited historical data.
Mantis is built on over 400 million simulated days of outbreak dynamics
spanning diverse pathogens, transmission modes, interventions, and surveillance
artifacts. Despite requiring no real-world data during training, Mantis
outperformed 39 expert-tuned models we tested across six diseases, including
all models in the CDC's COVID-19 Forecast Hub. Mantis generalized to novel
epidemiological regimes, including diseases with held-out transmission
mechanisms, demonstrating that it captures fundamental contagion dynamics.
Critically, Mantis is mechanistically interpretable, enabling public health
decision-makers to identify the latent drivers behind its predictions. Finally,
Mantis delivers accurate forecasts at 8-week horizons, more than doubling the
actionable range of most models, enabling proactive public health planning.
Together, these capabilities position Mantis as a foundation for
next-generation disease forecasting systems: general, interpretable, and
deployable where traditional models fail.

</details>


### [263] [RadarQA: Multi-modal Quality Analysis of Weather Radar Forecasts](https://arxiv.org/abs/2508.12291)
*Xuming He,Zhiyuan You,Junchao Gong,Couhua Liu,Xiaoyu Yue,Peiqin Zhuang,Wenlong Zhang,Lei Bai*

Main category: cs.AI

TL;DR: RadarQA는 MLLM을 활용해 레이더 기반 기상 예측의 품질을 분석하는 방법론이다. 핵심 물리 속성과 상세 평가 리포트를 결합하고, 단일 프레임·시퀀스, 등급·평가 시나리오를 포괄하는 새로운 과제 패러다임과 대규모 라벨링된 데이터셋(RQA-70K)을 제시하며, 단계적 학습 전략을 통해 기존 일반 MLLM보다 우수한 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 기존 점수 기반 평가지표는 일부 오차를 수치화할 수 있으나 서술적 설명력, 해석성, 시계열적 동적 변화의 이해 측면에서 기상 전문가 수준에 미치지 못함. MLLM의 멀티모달 이해력과 자연어 생성 능력이 이러한 한계를 보완할 수 있는 잠재력을 가짐.

Method: (1) 핵심 물리 속성(예: 강수 강도, 이동벡터 등)과 상세 평가 리포트를 통합한 MLLM 기반 분석 프레임워크 RadarQA 제안. (2) 단일 프레임·시퀀스, 등급(rating)·평가(assessment) 시나리오를 포함하는 포괄적 과제 정의. (3) 전문가 라벨링과 자동 휴리스틱을 결합한 하이브리드 주석 파이프라인으로 RQA-70K 데이터셋 구축. (4) 모델 성능을 단계적으로 향상시키는 다단계 학습 전략 설계.

Result: 대규모 실험에서 RadarQA는 모든 평가 설정에서 기존 일반 MLLM들을 능가했음. 이는 제안한 데이터셋과 학습 전략이 기상 예측 품질 분석에서 실질적 성능 이득을 제공함을 시사.

Conclusion: RadarQA는 레이더 예측 품질 분석의 기술적 진전을 제시하며, 대규모 주석 데이터와 단계적 학습이 중요함을 보여줌. 향후 아키텍처 세부, 주석 정확도·일반화성, 다른 기상 데이터로의 확장 연구가 필요하다.

Abstract: Quality analysis of weather forecasts is an essential topic in meteorology.
Although traditional score-based evaluation metrics can quantify certain
forecast errors, they are still far from meteorological experts in terms of
descriptive capability, interpretability, and understanding of dynamic
evolution. With the rapid development of Multi-modal Large Language Models
(MLLMs), these models become potential tools to overcome the above challenges.
In this work, we introduce an MLLM-based weather forecast analysis method,
RadarQA, integrating key physical attributes with detailed assessment reports.
We introduce a novel and comprehensive task paradigm for multi-modal quality
analysis, encompassing both single frame and sequence, under both rating and
assessment scenarios. To support training and benchmarking, we design a hybrid
annotation pipeline that combines human expert labeling with automated
heuristics. With such an annotation method, we construct RQA-70K, a large-scale
dataset with varying difficulty levels for radar forecast quality evaluation.
We further design a multi-stage training strategy that iteratively improves
model performance at each stage. Extensive experiments show that RadarQA
outperforms existing general MLLMs across all evaluation settings, highlighting
its potential for advancing quality analysis in weather prediction.

</details>


### [264] [Wisdom of the Crowd: Reinforcement Learning from Coevolutionary Collective Feedback](https://arxiv.org/abs/2508.12338)
*Wenzhen Yuan,Shengji Tang,Weihao Lin,Jiacheng Ruan,Ganqu Cui,Bo Zhang,Tao Chen,Ting Liu,Yuzhuo Fu,Peng Ye,Lei Bai*

Main category: cs.AI

TL;DR: RLCCF introduces a multi-model reinforcement learning framework that improves reasoning by optimizing Collective Consistency (voting among diverse LLMs) with per-model Self-Consistency weighting, enabling coevolution without external labels and yielding notable accuracy gains on math reasoning benchmarks.


<details>
  <summary>Details</summary>
Motivation: Single-model self-feedback methods suffer from overconfidence, reward hacking, and collapse because they rely on one model's judgments or expensive human/reward models. The paper aims to scale RL-based reasoning improvement without external supervision by leveraging multiple models.

Method: Train a diverse ensemble of LLMs jointly to maximize a Collective Consistency objective. Use majority voting on outputs as reward signals, with each model's vote weighted by its Self-Consistency score so more confident models have more influence. Models coevolve through these internal rewards.

Result: Evaluated on four open-source LLMs across four mathematical reasoning benchmarks, RLCCF achieves an average relative accuracy improvement of 16.72% and increases group majority-voting accuracy by 4.51%. It also improves individual model performance.

Conclusion: RLCCF effectively uses multi-model collaboration and confidence-weighted voting to provide scalable, supervision-free reinforcement learning signals that enhance reasoning for LLMs. The approach extends collective capability but may require further validation on broader tasks, cost analysis, and robustness checks.

Abstract: Reinforcement learning (RL) has significantly enhanced the reasoning
capabilities of large language models (LLMs), but its reliance on expensive
human-labeled data or complex reward models severely limits scalability. While
existing self-feedback methods aim to address this problem, they are
constrained by the capabilities of a single model, which can lead to
overconfidence in incorrect answers, reward hacking, and even training
collapse. To this end, we propose Reinforcement Learning from Coevolutionary
Collective Feedback (RLCCF), a novel RL framework that enables multi-model
collaborative evolution without external supervision. Specifically, RLCCF
optimizes the ability of a model collective by maximizing its Collective
Consistency (CC), which jointly trains a diverse ensemble of LLMs and provides
reward signals by voting on collective outputs. Moreover, each model's vote is
weighted by its Self-Consistency (SC) score, ensuring that more confident
models contribute more to the collective decision. Benefiting from the diverse
output distributions and complementary abilities of multiple LLMs, RLCCF
enables the model collective to continuously enhance its reasoning ability
through coevolution. Experiments on four mainstream open-source LLMs across
four mathematical reasoning benchmarks demonstrate that our framework yields
significant performance gains, achieving an average relative improvement of
16.72\% in accuracy. Notably, RLCCF not only improves the performance of
individual models but also enhances the group's majority-voting accuracy by
4.51\%, demonstrating its ability to extend the collective capability boundary
of the model collective.

</details>


### [265] [Hierarchical knowledge guided fault intensity diagnosis of complex industrial systems](https://arxiv.org/abs/2508.12375)
*Yu Sha,Shuiping Gou,Bo Liu,Johannes Faber,Ningtao Liu,Stefan Schramm,Horst Stoecker,Thomas Steckenreiter,Domagoj Vnucec,Nadine Wetzstein,Andreas Widl,Kai Zhou*

Main category: cs.AI

TL;DR: 계층적 그래프 기반의 지식 유도 결함 강도 진단(HKG) 프레임워크를 제안한다. 클래스의 단어 임베딩을 노드로 하는 계층적 토폴로지 그래프를 GCN으로 매핑해 글로벌 계층 분류기를 만들고, Re-HKCM(재가중 계층 지식 상관 행렬)을 SCM에서 유도하여 GCN의 정보 공유를 유도하고 과도한 평활화(over-smoothing)를 완화한다. 표현학습과 결합해 종단 간 학습 가능하며, 네 개의 실제 산업 데이터셋에서 최신 기법들을 능가한다.


<details>
  <summary>Details</summary>
Motivation: 기존 결함 강도 진단법들이 클래스 간 의존성을 고려하지 않고 체인-오브-생각 방식으로 동작하므로, 클래스 간 계층적/상호의존적 관계를 포착할 필요가 있다.

Method: 클래스별 단어 임베딩을 노드로 하는 계층적 토폴로지 그래프 구성 → GCN으로 그래프 기반 글로벌 계층 분류기 생성 → 표현학습으로부터 추출된 심층 특징에 분류기 적용하여 종단 간 학습. Re-HKCM는 데이터 기반 통계 상관행렬(SCM)에 계층 지식을 삽입하고 일련의 수학적 변환으로 도출되어 GCN 내 노드 간 정보 공유를 조절하고 과도한 평활화를 방지.

Result: SAMSON AG의 세 개 캐비테이션 데이터셋과 하나의 공개 데이터셋 등 네 개의 실제 산업용 데이터셋에서 광범위한 실험을 통해 기존 최신 FID 기법들보다 우수한 성능을 보였다.

Conclusion: HKG는 클래스 간 계층적 의존성을 효과적으로 통합하여 결함 강도 진단 성능을 향상시키며, Re-HKCM은 GCN의 정보 공유를 조절해 과잉 평활화를 완화한다. 방법론은 표현학습과 결합해 범용적으로 적용 가능하다.

Abstract: Fault intensity diagnosis (FID) plays a pivotal role in monitoring and
maintaining mechanical devices within complex industrial systems. As current
FID methods are based on chain of thought without considering dependencies
among target classes. To capture and explore dependencies, we propose a
hierarchical knowledge guided fault intensity diagnosis framework (HKG)
inspired by the tree of thought, which is amenable to any representation
learning methods. The HKG uses graph convolutional networks to map the
hierarchical topological graph of class representations into a set of
interdependent global hierarchical classifiers, where each node is denoted by
word embeddings of a class. These global hierarchical classifiers are applied
to learned deep features extracted by representation learning, allowing the
entire model to be end-to-end learnable. In addition, we develop a re-weighted
hierarchical knowledge correlation matrix (Re-HKCM) scheme by embedding
inter-class hierarchical knowledge into a data-driven statistical correlation
matrix (SCM) which effectively guides the information sharing of nodes in
graphical convolutional neural networks and avoids over-smoothing issues. The
Re-HKCM is derived from the SCM through a series of mathematical
transformations. Extensive experiments are performed on four real-world
datasets from different industrial domains (three cavitation datasets from
SAMSON AG and one existing publicly) for FID, all showing superior results and
outperform recent state-of-the-art FID methods.

</details>


### [266] [GraphCogent: Overcoming LLMs' Working Memory Constraints via Multi-Agent Collaboration in Complex Graph Understanding](https://arxiv.org/abs/2508.12379)
*Rongzheng Wang,Qizhi Chen,Yihong Huang,Yizhuo Ma,Muquan Li,Jiakai Li,Ke Qin,Guangchun Luo,Shuang Liang*

Main category: cs.AI

TL;DR: GraphCogent은 작업 기억 모델에서 영감을 받은 협업 에이전트 프레임워크로, 감지(sense), 버퍼(buffer), 실행(execute) 세 과정으로 그래프 추론을 분해한다. Sensory(부분그래프 샘플링으로 표준화), Buffer(다중 포맷 통합·인덱싱), Execution(툴 호출+모델 생성)를 결합하고, 대규모 실제 그래프(Graph4real) 벤치마크에서 Llama3.1-8B 기반으로 기존 대형 LLM·에이전트 대비 정확도 및 토큰 효율에서 큰 개선을 보인다.


<details>
  <summary>Details</summary>
Motivation: 실세계 복잡 그래프와 다중 단계 추론에서 기존 LLM들이 그래프 위상 처리와 연속적 추론을 동시에 잘 수행하지 못한다는 관찰에서 출발.

Method: 세 모듈 구조: Sensory—다양한 그래프 텍스트 표현을 부분그래프 샘플링으로 표준화; Buffer—여러 포맷의 그래프 데이터를 통합·색인화; Execution—외부 툴 호출과 모델 생성 결합으로 효율적 추론. 전체적으로 작업기억(working memory) 기반 분업적 사고 흐름을 모사.

Result: Graph4real(웹, 소셜, 교통, 인용의 4개 도메인, 21개 과제, 기존 벤치의 ~10배 규모)에서 Llama3.1-8B 기반 GraphCogent이 DeepSeek-R1(671B) 대비 약 50% 향상. 에이전트 기반 최신 기법 대비 정확도 +20%, 토큰 사용량은 인-툴셋 작업에서 -80%, 아웃-툴셋에서 -30% 보고.

Conclusion: 분해된 작업기억형 에이전트와 부분그래프 표준화·버퍼링·툴 통합 전략은 대규모 실제 그래프 추론에서 정확도와 토큰 효율을 동시에 개선한다. 다만 구현·평가 세부(샘플링 알고리즘, 인덱싱, 툴셋, 통계적 유의성 등) 공개와 추가 검증이 필요하다.

Abstract: Large language models (LLMs) show promising performance on small-scale graph
reasoning tasks but fail when handling real-world graphs with complex queries.
This phenomenon stems from LLMs' inability to effectively process complex graph
topology and perform multi-step reasoning simultaneously. To address these
limitations, we propose GraphCogent, a collaborative agent framework inspired
by human Working Memory Model that decomposes graph reasoning into specialized
cognitive processes: sense, buffer, and execute. The framework consists of
three modules: Sensory Module standardizes diverse graph text representations
via subgraph sampling, Buffer Module integrates and indexes graph data across
multiple formats, and Execution Module combines tool calling and model
generation for efficient reasoning. We also introduce Graph4real, a
comprehensive benchmark contains with four domains of real-world graphs (Web,
Social, Transportation, and Citation) to evaluate LLMs' graph reasoning
capabilities. Our Graph4real covers 21 different graph reasoning tasks,
categorized into three types (Structural Querying, Algorithmic Reasoning, and
Predictive Modeling tasks), with graph scales that are 10 times larger than
existing benchmarks. Experiments show that Llama3.1-8B based GraphCogent
achieves a 50% improvement over massive-scale LLMs like DeepSeek-R1 (671B).
Compared to state-of-the-art agent-based baseline, our framework outperforms by
20% in accuracy while reducing token usage by 80% for in-toolset tasks and 30%
for out-toolset tasks. Code will be available after review.

</details>


### [267] [Non-Iterative Symbolic-Aided Chain-of-Thought for Logical Reasoning](https://arxiv.org/abs/2508.12425)
*Phuong Minh Nguyen,Tien Huu Dang,Naoya Inoue*

Main category: cs.AI

TL;DR: Symbolic-Aided CoT는 경량의 기호적 표상을 few-shot 프롬프트에 통합해 추론 단계를 일관된 전략으로 구조화함으로써 LLM의 논리 추론을 더 투명하고 해석 가능하게 하고, 복잡한 제약·규칙 문제에서 기존 Chain-of-Thought보다 성능을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 표준 Chain-of-Thought는 추론 패턴이 암묵적이라 해석·분석이 어렵고, 다중 제약이나 규칙을 다루는 복잡한 논리 문제에서 일관된 전략을 유지하기 힘들다. 기호적 구조를 도입하면 추론의 명시성과 분석 가능성을 높일 수 있다.

Method: few-shot 프롬프트에 경량 기호 표상을 삽입하고, 추론 단계를 일관된 전략으로 구조화하는 비반복(비반복적) 체인을 사용한다. 기호적 구조는 기존 프롬프트의 일반성은 유지하면서 투명성·해석 가능성·분석 가능성을 더한다.

Result: ProofWriter, FOLIO, ProntoQA, LogicalDeduction의 네 벤치마크에서 실험을 수행했고, 특히 복잡한 제약·규칙을 요구하는 과제에서 유효성을 보여줌. 여러 모델 크기에서 일관된 개선을 보였고, ProofWriter, ProntoQA, LogicalDeduction에서 기존 CoT보다 유의하게 우수했다.

Conclusion: 경량 기호적 보조를 통한 구조화된 CoT는 LLM의 논리 추론 성능과 투명성을 동시에 개선하며, 복잡한 규칙 기반 추론 과제에 특히 효과적이다. 추가적인 실험·재현성 정보와 기호 설계의 세부가 있으면 적용 범위와 한계가 더욱 명확해질 것이다.

Abstract: This work introduces Symbolic-Aided Chain-of-Thought (CoT), an improved
approach to standard CoT, for logical reasoning in large language models
(LLMs). The key idea is to integrate lightweight symbolic representations into
few-shot prompts, structuring the inference steps with a consistent strategy to
make reasoning patterns more explicit within a non-iterative reasoning process.
By incorporating these symbolic structures, our method preserves the
generalizability of standard prompting techniques while enhancing the
transparency, interpretability, and analyzability of LLM logical reasoning.
Extensive experiments on four well-known logical reasoning benchmarks --
ProofWriter, FOLIO, ProntoQA, and LogicalDeduction, which cover diverse
reasoning scenarios -- demonstrate the effectiveness of the proposed approach,
particularly in complex reasoning tasks that require navigating multiple
constraints or rules. Notably, Symbolic-Aided CoT consistently improves LLMs'
reasoning capabilities across various model sizes and significantly outperforms
conventional CoT on three out of four datasets, ProofWriter, ProntoQA, and
LogicalDeduction.

</details>


### [268] [GALA: Can Graph-Augmented Large Language Model Agentic Workflows Elevate Root Cause Analysis?](https://arxiv.org/abs/2508.12472)
*Yifang Tian,Yaming Liu,Zichun Chong,Zihang Huang,Hans-Arno Jacobsen*

Main category: cs.AI

TL;DR: GALA는 메트릭·로그·트레이스 등 다중 모달 텔레메트리를 통합해 통계적 인과추론과 LLM 기반 반복 추론을 결합한 RCA(근본원인분석) 프레임워크로, 공개 벤치마크에서 현행 기법 대비 최대 42.22% 향상된 정확도와 더 행동가능한( actionable ) 진단·복구 지침을 제시한다고 보고한다.


<details>
  <summary>Details</summary>
Motivation: 마이크로서비스 환경에서 장애 진단은 이종 텔레메트리의 신속한 종합 분석을 요구하지만 기존 방법은 단일 모달에 치우치거나 의심 서비스 순위만 제공해 실제 복구로 이어지기 어려움. 이를 해결하기 위해 인과적 근거와 인간 친화적 설명을 결합한 방법이 필요함.

Method: (1) 다중 모달(메트릭·로그·트레이스) 입력을 통합, (2) 통계적 인과추론으로 원인 후보를 도출하고, (3) LLM을 이용한 반복적(reasoning) 질의응답 및 인간 가이드 평가를 통해 결과를 정제·설명하며, 최종적으로 근본원인 식별과 복구 가이드를 생성.

Result: 공개 오픈소스 벤치마크에서 기존 최첨단 기법 대비 최대 42.22%의 정확도 향상 보고. 또한 사람 주도의 LLM 평가 지표에서 더 인과적으로 타당하고 행동가능한 진단 산출물을 생성했다고 주장.

Conclusion: GALA는 자동화된 장애 진단과 실무적 사건 해결 사이의 간극을 줄이며, 정확한 원인 식별과 해석 가능한 복구 지침을 동시에 제공한다는 점에서 실용적 기여를 함.

Abstract: Root cause analysis (RCA) in microservice systems is challenging, requiring
on-call engineers to rapidly diagnose failures across heterogeneous telemetry
such as metrics, logs, and traces. Traditional RCA methods often focus on
single modalities or merely rank suspect services, falling short of providing
actionable diagnostic insights with remediation guidance. This paper introduces
GALA, a novel multi-modal framework that combines statistical causal inference
with LLM-driven iterative reasoning for enhanced RCA. Evaluated on an
open-source benchmark, GALA achieves substantial improvements over
state-of-the-art methods of up to 42.22% accuracy. Our novel human-guided LLM
evaluation score shows GALA generates significantly more causally sound and
actionable diagnostic outputs than existing methods. Through comprehensive
experiments and a case study, we show that GALA bridges the gap between
automated failure diagnosis and practical incident resolution by providing both
accurate root cause identification and human-interpretable remediation
guidance.

</details>


### [269] [Advanced DOA Regulation with a Whale-Optimized Fractional Order Fuzzy PID Framework](https://arxiv.org/abs/2508.12487)
*Lida Shahbandari,Hossein Mohseni*

Main category: cs.AI

TL;DR: WOA로 매개변수를 최적화한 Fractional Order Fuzzy PID(FOFPID)를 제안하여 BIS(40–60)를 제어했고, 8개 환자 프로파일 시뮬레이션에서 기존 FOPID보다 정착시간과 정상 상태 오차가 개선됨.


<details>
  <summary>Details</summary>
Motivation: 수술 중 BIS를 목표범위(40–60)로 안정적으로 유지해야 하며, 환자별 생리학적 차이 때문에 기존 고정 파라미터 제어기(예: 표준 FOPID)로는 성능이 제한될 수 있음. 따라서 적응성과 미세조정이 가능한 제어기가 필요함.

Method: FOFPID 설계: 퍼지 논리로 이득을 적응시키고 분수차수(fractional orders)를 포함하여 제어기의 유연성을 향상. WOA(고래 최적화 알고리즘)를 이용해 분수차수와 퍼지 멤버십 함수 등 제어 파라미터를 전역 최적화. 8개 환자 모델(시뮬레이션)에서 성능 비교.

Result: FOFPID가 기존 FOPID보다 우수: 정착시간 2.5분 vs 3.2분, 정상 상태 오차 0.5 vs 1.2 등으로 개선. 전반적으로 안정성과 정확도 향상 보고.

Conclusion: FOFPID+WOA는 자동화 마취 전달의 유망한 AI 기반 해법이나, 실제 임상 적용을 위해선 추가적인 검증(더 넓은 환자군, 임상시험), 안전성·실시간성·계산비용 평가가 필요함.

Abstract: This study introduces a Fractional Order Fuzzy PID (FOFPID) controller that
uses the Whale Optimization Algorithm (WOA) to manage the Bispectral Index
(BIS), keeping it within the ideal range of forty to sixty. The FOFPID
controller combines fuzzy logic for adapting to changes and fractional order
dynamics for fine tuning. This allows it to adjust its control gains to handle
a person's unique physiology. The WOA helps fine tune the controller's
parameters, including the fractional orders and the fuzzy membership functions,
which boosts its performance. Tested on models of eight different patient
profiles, the FOFPID controller performed better than a standard Fractional
Order PID (FOPID) controller. It achieved faster settling times, at two and a
half minutes versus three point two minutes, and had a lower steady state
error, at zero point five versus one point two. These outcomes show the
FOFPID's excellent strength and accuracy. It offers a scalable, artificial
intelligence driven solution for automated anesthesia delivery that could
enhance clinical practice and improve patient results.

</details>


### [270] [Root Cause Analysis of Hydrogen Bond Separation in Spatio-Temporal Molecular Dynamics using Causal Models](https://arxiv.org/abs/2508.12500)
*Rahmat K. Adesunkanmi,Ashfaq Khokhar,Goce Trajcevski,Sohail Murad*

Main category: cs.AI

TL;DR: VAE 영감을 받은 인과 모델로 분자 동역학 시뮬레이션(MDS)에서 수소결합 형성·분리의 근본 원인을 추론하고, 변화가 일어날 때의 원인 변수를 식별하여 여러 단계 앞을 예측함.


<details>
  <summary>Details</summary>
Motivation: MDS는 계산 비용이 크고 흥미로운 사건(예: 다른 분자 간 수소결합)의 탐지는 수동 검토에 의존한다. 특히 어떤 상호작용이나 선행 사건이 결합 형성·분리에 기여하는지(인과적 원인)를 규명하는 연구 공백이 존재함.

Method: 수소결합 분리를 '개입'으로 간주하고, 결합/분리 사건의 인과 구조를 그래프 인과모델로 표현함. VAE 유사 아키텍처를 이용해 각 샘플이 서로 다른 기저 인과 그래프를 가질 때도 공유되는 동적 정보를 활용하여 인과 관계를 추론. 결합 분리 시 조인트 분포 변화의 원인 변수를 추론하는 단계 포함.

Result: 키랄 분리(chiral separation)를 위한 원자 궤적 데이터에 실험적으로 적용하여 다수의 미래 타임스텝 예측이 가능함을 보였고, 시스템 변화(결합·분리)를 유발하는 변수를 식별할 수 있었음.

Conclusion: 시공간 데이터 분석과 기계학습 기반 인과 모델링을 결합한 방법으로 MDS에서의 근본 원인 분석을 제공하며, 자동화된 사건 탐지와 기계적 통찰 제공에 유용한 새로운 관점을 제시함.

Abstract: Molecular dynamics simulations (MDS) face challenges, including
resource-heavy computations and the need to manually scan outputs to detect
"interesting events," such as the formation and persistence of hydrogen bonds
between atoms of different molecules. A critical research gap lies in
identifying the underlying causes of hydrogen bond formation and separation
-understanding which interactions or prior events contribute to their emergence
over time. With this challenge in mind, we propose leveraging spatio-temporal
data analytics and machine learning models to enhance the detection of these
phenomena. In this paper, our approach is inspired by causal modeling and aims
to identify the root cause variables of hydrogen bond formation and separation
events. Specifically, we treat the separation of hydrogen bonds as an
"intervention" occurring and represent the causal structure of the bonding and
separation events in the MDS as graphical causal models. These causal models
are built using a variational autoencoder-inspired architecture that enables us
to infer causal relationships across samples with diverse underlying causal
graphs while leveraging shared dynamic information. We further include a step
to infer the root causes of changes in the joint distribution of the causal
models. By constructing causal models that capture shifts in the conditional
distributions of molecular interactions during bond formation or separation,
this framework provides a novel perspective on root cause analysis in molecular
dynamic systems. We validate the efficacy of our model empirically on the
atomic trajectories that used MDS for chiral separation, demonstrating that we
can predict many steps in the future and also find the variables driving the
observed changes in the system.

</details>


### [271] [Help or Hurdle? Rethinking Model Context Protocol-Augmented Large Language Models](https://arxiv.org/abs/2508.12566)
*Wei Song,Haonan Zhong,Ziqi Ding,Jingling Xue,Yuekang Li*

Main category: cs.AI

TL;DR: MCPGAUGE는 LLM이 외부 도구(MCP)를 어떻게·얼마나 효과적으로 사용하는지 네 가지 차원(주도성, 준수성, 효과성, 오버헤드)으로 종합 평가하는 벤치마크로, 160개 프롬프트·25개 데이터셋·6개 상용 LLM·30개 도구군을 포함한 대규모 실험을 통해 도구 통합의 한계들을 밝힌다.


<details>
  <summary>Details</summary>
Motivation: LLM이 외부 리소스에 온디맨드로 접근하는 능력(MCP)이 성능 향상을 약속하지만, 실제로 모델들이 언제·어떻게 이 능력을 활용하는지와 그 비용·효용은 충분히 규명되지 않았기 때문에 이를 체계적으로 평가할 필요가 있다.

Method: MCPGAUGE 프레임워크를 설계해 160개의 평가 프롬프트와 25개 데이터셋(지식 이해, 일반 추론, 코드 생성 포함)을 구성하고, 6개 상용 LLM·30개 MCP 도구군·1/2턴 상호작용 설정에서 약 20,000 API 호출(비용 ≈ $6,000)을 수행해 네 가지 평가 축(주도성·준수성·효과성·오버헤드)을 측정·분석했다.

Result: 대규모 실험을 통해 기존의 통념에 도전하는 네 가지 핵심 발견을 제시했다(요약: 모델의 주도적 도구 사용은 제한적이고, 도구 지시 준수·통합 이후의 성능 향상은 데이터·작업 유형에 따라 제한적이며, 비용·지연 같은 오버헤드가 무시할 수 없는 수준임).

Conclusion: MCPGAUGE는 통제 가능하고 도구가 보강된 LLM 개발을 위해 필수적인 벤치마크를 제공하며, 현재의 AI-도구 통합 방식이 가진 실질적 한계를 개선하기 위한 후속 연구 방향을 제시한다.

Abstract: The Model Context Protocol (MCP) enables large language models (LLMs) to
access external resources on demand. While commonly assumed to enhance
performance, how LLMs actually leverage this capability remains poorly
understood. We introduce MCPGAUGE, the first comprehensive evaluation framework
for probing LLM-MCP interactions along four key dimensions: proactivity
(self-initiated tool use), compliance (adherence to tool-use instructions),
effectiveness (task performance post-integration), and overhead (computational
cost incurred). MCPGAUGE comprises a 160-prompt suite and 25 datasets spanning
knowledge comprehension, general reasoning, and code generation. Our
large-scale evaluation, spanning six commercial LLMs, 30 MCP tool suites, and
both one- and two-turn interaction settings, comprises around 20,000 API calls
and over USD 6,000 in computational cost. This comprehensive study reveals four
key findings that challenge prevailing assumptions about the effectiveness of
MCP integration. These insights highlight critical limitations in current
AI-tool integration and position MCPGAUGE as a principled benchmark for
advancing controllable, tool-augmented LLMs.

</details>


### [272] [An LLM + ASP Workflow for Joint Entity-Relation Extraction](https://arxiv.org/abs/2508.12611)
*Trang Tran,Trung Hoang Le,Huiping Cao,Tran Cao Son*

Main category: cs.AI

TL;DR: LLM(생성형 대형언어모델)과 ASP(Answer Set Programming)를 결합한 JERE(개체-관계 동시추출) 워크플로우를 제안. 비지도 텍스트를 LLM으로 후보 추출하고, ASP로 도메인 지식·타입 제약을 적용해 결과를 정제. 10% 학습 데이터만으로 여러 벤치마크에서 SOTA를 능가, SciERC의 관계추출에서 35% 성능(기준 15%)로 2.5배 향상.


<details>
  <summary>Details</summary>
Motivation: 기존 기계학습 기반 JERE는 대량 주석 데이터와 도메인 지식 반영의 어려움으로 비용이 큼. 모델 수정 없이 도메인 지식(타입 등)을 쉽게 통합할 수 있는 방법 필요.

Method: LLM을 이용해 비주석 원문에서 엔티티/관계 후보를 생성하고, ASP로 타입 제약·추론 규칙을 적용해 일관성 있는 엔티티·관계 세트를 도출하는 일반적(도메인 불문) 워크플로우 제공. ASP 코어는 변경 없이 규칙을 추가해 확장 가능.

Result: 제한된 학습(10%) 상황에서 세 벤치마크 실험 수행. 여러 항목에서 기존 SOTA보다 우수한 성능을 보임. 특히 SciERC의 관계추출에서 35% 달성(비교치 15%).

Conclusion: 생성형 LLM의 언어이해 능력과 ASP의 설명·수정 용이한 추론을 결합하면 저자원 상황에서도 JERE 성능을 크게 개선할 수 있음. 그러나 LLM·ASP 상호작용, 확장성, 비용 등 추가 검증 필요.

Abstract: Joint entity-relation extraction (JERE) identifies both entities and their
relationships simultaneously. Traditional machine-learning based approaches to
performing this task require a large corpus of annotated data and lack the
ability to easily incorporate domain specific information in the construction
of the model. Therefore, creating a model for JERE is often labor intensive,
time consuming, and elaboration intolerant. In this paper, we propose
harnessing the capabilities of generative pretrained large language models
(LLMs) and the knowledge representation and reasoning capabilities of Answer
Set Programming (ASP) to perform JERE. We present a generic workflow for JERE
using LLMs and ASP. The workflow is generic in the sense that it can be applied
for JERE in any domain. It takes advantage of LLM's capability in natural
language understanding in that it works directly with unannotated text. It
exploits the elaboration tolerant feature of ASP in that no modification of its
core program is required when additional domain specific knowledge, in the form
of type specifications, is found and needs to be used. We demonstrate the
usefulness of the proposed workflow through experiments with limited training
data on three well-known benchmarks for JERE. The results of our experiments
show that the LLM + ASP workflow is better than state-of-the-art JERE systems
in several categories with only 10\% of training data. It is able to achieve a
2.5 times (35\% over 15\%) improvement in the Relation Extraction task for the
SciERC corpus, one of the most difficult benchmarks.

</details>


### [273] [Cognitive Structure Generation: From Educational Priors to Policy Optimization](https://arxiv.org/abs/2508.12647)
*Hengnian Gu,Zhifu Chen,Yuxin Chen,Jin Peng Zhou,Dongdai Zhou*

Main category: cs.AI

TL;DR: 이 논문은 학생의 인지구조를 생성하는 새로운 프레임워크 CSG를 제안한다. 확산 확률 모델(CSDPM)을 사전학습해 교육적 사전지식으로부터 인지구조를 생성하고, 강화학습으로 생성과정을 계층적 보상 신호로 최적화해 실제 학습발달 수준과 정렬시킨다. 실험에서 KT와 CD 성능 및 해석 가능성이 향상되었다.


<details>
  <summary>Details</summary>
Motivation: 인지구조(cognitive structure)는 학생의 개념 및 관계에 대한 주관적 조직을 나타내며, 학생 모델링과 심리계량학에서 핵심적이지만 실무에서 평가하기 어려운 개념이다. 기존 방법은 인지구조를 직접 측정하거나 생성하는 데 한계가 있어 보다 포괄적이고 해석 가능한 표현이 필요하다.

Method: CSG 프레임워크를 도입한다. 먼저 교육적 사전지식을 이용해 인지구조를 생성하는 Cognitive Structure Diffusion Probabilistic Model(CSDPM)을 사전학습한다. 이후 생성 과정을 정책으로 보고, 계층적 보상 신호를 갖는 강화학습으로 이 정책을 추가 최적화하여 생성된 인지구조가 학생의 실제 인지발달 수준과 잘 정렬되도록 한다.

Result: 네 개의 실세계 교육 데이터셋에서 평가한 결과, CSG가 생성한 인지구조는 학생 모델링에 더 포괄적이고 효과적인 표현을 제공하여 지식추적(KT) 및 인지진단(CD) 과제에서 성능을 크게 향상시켰고, 모델의 해석 가능성도 개선되었다.

Conclusion: CSG는 생성적·강화학습 기반 접근으로 인지구조를 실용적으로 생성하고 조정할 수 있음을 보였다. 이는 학생 모델링의 성능과 해석 가능성을 동시에 높이는 새로운 방향을 제시한다.

Abstract: Cognitive structure is a student's subjective organization of an objective
knowledge system, reflected in the psychological construction of concepts and
their relations. However, cognitive structure assessment remains a
long-standing challenge in student modeling and psychometrics, persisting as a
foundational yet largely unassessable concept in educational practice. This
paper introduces a novel framework, Cognitive Structure Generation (CSG), in
which we first pretrain a Cognitive Structure Diffusion Probabilistic Model
(CSDPM) to generate students' cognitive structures from educational priors, and
then further optimize its generative process as a policy with hierarchical
reward signals via reinforcement learning to align with genuine cognitive
development levels during students' learning processes. Experimental results on
four popular real-world education datasets show that cognitive structures
generated by CSG offer more comprehensive and effective representations for
student modeling, substantially improving performance on KT and CD tasks while
enhancing interpretability.

</details>


### [274] [The Maximum Coverage Model and Recommendation System for UAV Vertiports Location Planning](https://arxiv.org/abs/2508.12651)
*Chunliang Hua,Xiao Hu,Jiayang Sun,Zeyuan Yang*

Main category: cs.AI

TL;DR: 도심 항공 모빌리티(UAM)용 대규모 버티포트 네트워크 설계를 위해 용량·시공간 수요·이질적 사용자 행동을 동시에 고려하는 새 최적화 모델(CDMCLP)과 실무 지향의 추천 시스템을 제안. 중국 중심 도시 사례에서 기존 방법 대비 38–52% 성능 향상을 보고함.


<details>
  <summary>Details</summary>
Motivation: 기존 위치선정·인프라 계획 프레임워크는 데이터 세분성, 시공간 수요 모델링, 용량 제한 및 실제 사용자 행동 반영에서 한계가 있어 대규모 UAM 네트워크 설계에 부적합함. 도시 차원의 수천 개 버티포트 계획 수요를 충족할 체계가 필요함.

Method: Capacitated Dynamic Maximum Covering Location Problem(CDMCLP)을 도입해 시공간 수요, 이질적 사용자 행동(이동성·선호 등), 인프라 용량 제약을 통합적으로 모델링. CDMCLP를 Socio-economic 요소와 동적 클러스터 초기화, 경험적 사용자 행태 기반 파라미터 적응조정과 결합한 통합 계획 추천 시스템으로 구현.

Result: 중국 중심 도시에서 검증한 결과, CDMCLP로 기존 전통적 위치선정 방법들의 정량적 성능을 38%~52%까지 개선 가능함을 보였고, 추천 시스템은 실무자 친화성 및 복잡한 요소 통합의 유효성을 입증함.

Conclusion: 수학적 엄밀성과 실무 구현 고려를 결합한 하이브리드 접근은 이론적 위치 모델과 실제 UAM 인프라 계획 간 간극을 줄이며, 지방정부의 버티포트 네트워크 설계에 실용적 도구를 제공함.

Abstract: As urban aerial mobility (UAM) infrastructure development accelerates
globally, cities like Shenzhen are planning large-scale vertiport networks
(e.g., 1,200+ facilities by 2026). Existing planning frameworks remain
inadequate for this complexity due to historical limitations in data
granularity and real-world applicability. This paper addresses these gaps by
first proposing the Capacitated Dynamic Maximum Covering Location Problem
(CDMCLP), a novel optimization framework that simultaneously models urban-scale
spatial-temporal demand, heterogeneous user behaviors, and infrastructure
capacity constraints. Building on this foundation, we introduce an Integrated
Planning Recommendation System that combines CDMCLP with socio-economic factors
and dynamic clustering initialization. This system leverages adaptive parameter
tuning based on empirical user behavior to generate practical planning
solutions. Validation in a Chinese center city demonstrates the effectiveness
of the new optimization framework and recommendation system. Under the
evaluation and optimization of CDMCLP, the quantitative performance of
traditional location methods are exposed and can be improved by 38\%--52\%,
while the recommendation system shows user-friendliness and the effective
integration of complex elements. By integrating mathematical rigor with
practical implementation considerations, this hybrid approach bridges the gap
between theoretical location modeling and real-world UAM infrastructure
planning, offering municipalities a pragmatic tool for vertiport network
design.

</details>


### [275] [GridCodex: A RAG-Driven AI Framework for Power Grid Code Reasoning and Compliance](https://arxiv.org/abs/2508.12682)
*Jinquan Shi,Yingying Cheng,Fan Zhang,Miao Jiang,Jun Lin,Yanbai Shen*

Main category: cs.AI

TL;DR: GridCodex는 LLM과 RAG를 결합한 전주기적 그리드 코드(전력 규정) 추론·준수 프레임워크로, 다단계 질의 정제와 RAPTOR 기반 검색을 통해 응답 품질과 검색 회수를 크게 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 재생에너지 전환으로 전력망 운영 규제가 복잡해지고 자동화된 해석·준수 도구가 부족해 산업 확장과 전력사 수익성에 제약이 생김. 이를 해결할 자동화 추론·검색 시스템이 필요함.

Method: 대형 언어모델(Large Language Models)과 검색 보강 생성(RAG)을 기반으로 한 엔드투엔드 파이프라인을 설계. 핵심 기법으로 다단계(멀티스테이지) 질의 정제(query refinement)와 RAPTOR라는 향상된 검색모듈을 도입하여 관련 문서 회수 및 질의-응답 품질을 개선함. 실험에는 자동화된 다차원 답안 평가와 복수 규제기관 문서 집합을 사용함.

Result: 벤치마크 실험에서 응답 품질이 평균 26.4% 향상되었고, 검색(리콜)률이 10배 이상 증가했다는 결과를 보고함. 또한 기본 모델 선택에 따른 성능 차이를 확인하는 소거(ablation) 연구를 수행함.

Conclusion: GridCodex는 RAG 워크플로우를 발전시켜 그리드 코드 관련 질의응답·준수 자동화를 실용적 수준으로 끌어올렸으며, 검색 성능 및 답변 품질에서 유의미한 개선을 보였음.

Abstract: The global shift towards renewable energy presents unprecedented challenges
for the electricity industry, making regulatory reasoning and compliance
increasingly vital. Grid codes, the regulations governing grid operations, are
complex and often lack automated interpretation solutions, which hinders
industry expansion and undermines profitability for electricity companies. We
introduce GridCodex, an end to end framework for grid code reasoning and
compliance that leverages large language models and retrieval-augmented
generation (RAG). Our framework advances conventional RAG workflows through
multi stage query refinement and enhanced retrieval with RAPTOR. We validate
the effectiveness of GridCodex with comprehensive benchmarks, including
automated answer assessment across multiple dimensions and regulatory agencies.
Experimental results showcase a 26.4% improvement in answer quality and more
than a 10 fold increase in recall rate. An ablation study further examines the
impact of base model selection.

</details>


### [276] [EGOILLUSION: Benchmarking Hallucinations in Egocentric Video Understanding](https://arxiv.org/abs/2508.12687)
*Ashish Seth,Utkarsh Tyagi,Ramaneswaran Selvakumar,Nishit Anand,Sonal Kumar,Sreyan Ghosh,Ramani Duraiswami,Chirag Agarwal,Dinesh Manocha*

Main category: cs.AI

TL;DR: 저자들은 자가시점(egocentric) 비디오에서 MLLM의 환각(hallucination)을 평가하기 위한 최초의 벤치마크 EgoIllusion을 제안한다. 1,400개 비디오와 8,000개 질문(시각·청각 유도)을 포함하고, 10개 MLLM을 평가한 결과 최고 모델들도 약 59% 정확도로 어려움을 보였다.


<details>
  <summary>Details</summary>
Motivation: MLLM이 자가시점 비디오에서 시청각적 단서에 대해 그럴듯하지만 부정확한 응답(환각)을 생성하는 문제가 있으며, 이를 체계적으로 측정·비교할 벤치마크가 부재하므로 이를 채우기 위함.

Method: egocentric 비디오 1,400개를 수집하고, 인간 주석가들이 시청각적 환각을 유발하도록 설계한 개방형·폐쇄형 질문 8,000개를 작성. 10개 MLLM(예: GPT-4o, Gemini 포함)을 대상으로 정확도 등으로 평가.

Result: 모델 전반에 걸쳐 높은 환각률 관찰. 최고 성능 모델들도 약 59% 정확도로 상당한 실패율을 보였음. 시청각 관련 질문에서 특히 취약성을 보이는 경향.

Conclusion: EgoIllusion은 egocentric MLLM의 환각 문제를 평가하는 기초 벤치마크로, 향후 모델의 신뢰성·강건성 개선과 관련 연구를 촉발할 수 있으며 데이터와 코드 공개로 재현 가능성을 지원함.

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated remarkable
performance in complex multimodal tasks. While MLLMs excel at visual perception
and reasoning in third-person and egocentric videos, they are prone to
hallucinations, generating coherent yet inaccurate responses. We present
EgoIllusion, a first benchmark to evaluate MLLM hallucinations in egocentric
videos. EgoIllusion comprises 1,400 videos paired with 8,000 human-annotated
open and closed-ended questions designed to trigger hallucinations in both
visual and auditory cues in egocentric videos. Evaluations across ten MLLMs
reveal significant challenges, including powerful models like GPT-4o and
Gemini, achieving only 59% accuracy. EgoIllusion lays the foundation in
developing robust benchmarks to evaluate the effectiveness of MLLMs and spurs
the development of better egocentric MLLMs with reduced hallucination rates.
Our benchmark will be open-sourced for reproducibility.

</details>


### [277] [GTool: Graph Enhanced Tool Planning with Large Language Model](https://arxiv.org/abs/2508.12725)
*Wenjie Chen,Wenbin Li,Di Yao,Xuying Meng,Chang Gong,Jingping Bi*

Main category: cs.AI

TL;DR: GTool은 불완전한 도구 의존성 상황에서 LLM의 도구 계획 성능을 개선하는 방법으로, 요청별 도구 그래프와 <graph token> 생성 및 누락 의존성 예측을 도입해 7B LLM에서 SOTA 대비 >29.6% 성능 향상을 보였다.


<details>
  <summary>Details</summary>
Motivation: 기존 연구는 도구들을 독립된 요소로 다루어 도구 간 의존성을 활용하지 못하고, 도구셋이 클 때(특히 의존성 정보가 불완전할 때) 적절한 도구 선택이 어려워진다.

Method: (1) 요청-특화 도구 그래프를 구성해 도구 선별을 효율화, (2) LLM이 이해할 수 있는 <graph token>을 생성해 충분한 의존성 정보를 제공, (3) 누락된 의존성을 예측하는 보조 과제를 도입해 불완전한 의존성 상황에 대한 신뢰성 향상. LLM 본체를 대규모 재학습 없이 다양한 백본과 결합 가능.

Result: 광범위한 실험에서 경량(7B) LLM 백본을 사용해 기존 SOTA 대비 29.6% 이상 성능 향상을 달성.

Conclusion: GTool은 불완전한 도구 의존성 하에서 도구 계획의 정확성과 신뢰성을 크게 개선하며, 도구-구동형 LLM 에이전트의 실용적 확장에 유용하지만 그래프 품질 및 누락 예측의 정확성에 의존한다.

Abstract: Tool planning with large language models (LLMs), referring to selecting,
organizing, and preparing the tools necessary to complete a user request,
bridges the gap between natural language understanding and task execution.
However, current works treat different tools as isolated components and fail to
leverage the inherent dependencies of tools, leading to invalid planning
results. Since tool dependencies are often incomplete, it becomes challenging
for LLMs to accurately identify the appropriate tools required by a user
request, especially when confronted with a large toolset. To solve this
challenge, we propose \texttt{GTool}, which is the first work aiming to enhance
the tool planning ability of LLMs under incomplete dependencies. \texttt{GTool}
constructs a request-specific tool graph to select tools efficiently and
generate the \texttt{<graph token>} which provides sufficient dependency
information understandable by LLMs. Moreover, a missing dependency prediction
task is designed to improve the reliability of \texttt{GTool} with incomplete
dependencies. Without trimming LLMs, \texttt{GTool} can be seamlessly
integrated with various LLM backbones without extensive retraining. Extensive
experiments show that \texttt{GTool} achieves more than 29.6\% performance
improvements compared with the state-of-the-art (SOTA) baselines with a
light-weight (7B) LLM backbone.

</details>


### [278] [Beyond Ethical Alignment: Evaluating LLMs as Artificial Moral Assistants](https://arxiv.org/abs/2508.12754)
*Alessio Galatolo,Luca Alberto Rappuoli,Katie Winkle,Meriem Beloucif*

Main category: cs.AI

TL;DR: 이 논문은 대형언어모델(LLM)을 '인공 도덕 보조자(AMA)'로서 평가하기 위한 이론적 틀과 벤치마크를 제시한다. 핵심은 단순한 윤리적 최종판단이 아니라, 명시적이고 체계적인 도덕 추론(연역적·추정적)을 수행할 수 있어야 한다는 점이다.


<details>
  <summary>Details</summary>
Motivation: 현행 LLM 정렬 평가들은 주로 최종적인 윤리적 판단의 정합성만 측정해 도덕적 추론의 질을 간과한다. 철학적 문헌에서 논의되는 AMA 역할을 충실히 재현하려면 상황판단, 가치 간 균형 조정, 그리고 추론과정의 투명성이 필요하다.

Method: 철학적 논의를 바탕으로 AMA가 갖춰야 할 구체적 행태를 형식화(연역·귀납·추정적 도덕추론 등)하고, 이를 검사하는 벤치마크를 설계했다. 설계한 벤치마크로 공개형 LLM들을 평가하여 모델별 성능을 비교·분석했다.

Result: 모델들 간 성능 편차가 컸고, 특히 추정적(abductive) 도덕추론에서 지속적인 약점이 관찰되었다. 일부 모델은 윤리적 문제를 식별하거나 단순한 연역적 추론은 수행했으나, 설명 생성과 가치충돌 해결에서는 미흡했다.

Conclusion: 철학적 기준과 실험적 평가를 연결함으로써 LLM의 도덕능력 평가를 심화시켰다. AMAs로서 신뢰할 수준에 도달하려면 추론능력(특히 추정적 추론)을 향상시키는 전용 전략과 평가 지표가 필요하다.

Abstract: The recent rise in popularity of large language models (LLMs) has prompted
considerable concerns about their moral capabilities. Although considerable
effort has been dedicated to aligning LLMs with human moral values, existing
benchmarks and evaluations remain largely superficial, typically measuring
alignment based on final ethical verdicts rather than explicit moral reasoning.
In response, this paper aims to advance the investigation of LLMs' moral
capabilities by examining their capacity to function as Artificial Moral
Assistants (AMAs), systems envisioned in the philosophical literature to
support human moral deliberation. We assert that qualifying as an AMA requires
more than what state-of-the-art alignment techniques aim to achieve: not only
must AMAs be able to discern ethically problematic situations, they should also
be able to actively reason about them, navigating between conflicting values
outside of those embedded in the alignment phase. Building on existing
philosophical literature, we begin by designing a new formal framework of the
specific kind of behaviour an AMA should exhibit, individuating key qualities
such as deductive and abductive moral reasoning. Drawing on this theoretical
framework, we develop a benchmark to test these qualities and evaluate popular
open LLMs against it. Our results reveal considerable variability across models
and highlight persistent shortcomings, particularly regarding abductive moral
reasoning. Our work connects theoretical philosophy with practical AI
evaluation while also emphasising the need for dedicated strategies to
explicitly enhance moral reasoning capabilities in LLMs. Code available at
https://github.com/alessioGalatolo/AMAeval

</details>


### [279] [HeroBench: A Benchmark for Long-Horizon Planning and Structured Reasoning in Virtual Worlds](https://arxiv.org/abs/2508.12782)
*Petr Anokhin,Roman Khalikov,Stefan Rebrikov,Viktor Volkov,Artyom Sorokin,Vincent Bissonnette*

Main category: cs.AI

TL;DR: HeroBench는 복잡한 RPG 스타일 가상 세계에서 장기 계획(long-horizon planning)과 구조화된 추론 능력을 평가하기 위한 신규 벤치마크다. 데이터셋, 시뮬레이터, 평가 도구를 포함하며 25개 최신 LLM(오픈소스·상업용 포함)을 평가해 고차원 계획 생성과 실행에서 큰 성능 격차와 약점을 발견했다.


<details>
  <summary>Details</summary>
Motivation: 기존 벤치마크는 추상적·저차원적 알고리즘 문제에 편중되어 현실적인 장기 계획 문제(다중 단계·의존성·자원·제약)를 온전히 반영하지 못한다. 따라서 LLM의 실제 계획·행동 능력을 측정할 전용 환경이 필요하다.

Method: RPG 영감을 받은 복합적 과제 집합과 난이도별 데이터셋을 설계하고, 에이전트 계획을 실행·검증할 시뮬레이터와 분석 도구를 제공. 모델들은 전략적 계획 수립, 자원 수집, 스킬 획득, 장비 제작, 적 처치 등의 과제를 수행한다. 25개 모델을 동일 프로토콜로 평가하고 상세한 오류 분석을 수행함.

Result: 다양한 모델 간 성능 편차가 크며(오픈/비공개 모델 포함), 많은 모델이 고수준 전략 생성 및 구조화된 행동의 안정적 실행에서 취약함을 보였다. 상세 오류 분석을 통해 취약한 계획 단계와 실행 실패 패턴을 규명함.

Conclusion: HeroBench는 LLM의 장기 계획 능력 평가를 진일보시켜, 향후 자율적·계층적 계획 연구를 위한 유연하고 확장 가능한 기반을 제공한다.

Abstract: Large language models (LLMs) have shown remarkable capabilities in isolated
step-by-step reasoning tasks such as mathematics and programming, but their
proficiency in long-horizon planning, where solutions require extended,
structured sequences of interdependent actions, remains underexplored. Existing
benchmarks typically assess LLMs through abstract or low-dimensional
algorithmic tasks, failing to capture the complexity of realistic planning
environments. We introduce HeroBench, a novel benchmark designed specifically
to evaluate long-horizon planning and structured reasoning within complex
RPG-inspired virtual worlds. HeroBench provides a rigorously constructed
dataset of tasks covering a wide range of difficulties, a simulated environment
to execute and validate agent plans, and detailed analytical tools for
evaluating model performance. Tasks challenge models to formulate strategic
plans, efficiently gather resources, master necessary skills, craft equipment,
and defeat adversaries, reflecting practical scenarios' layered dependencies
and constraints. Our extensive evaluation of 25 state-of-the-art LLMs, spanning
both open-source and proprietary models, including the GPT-5 family, reveals
substantial performance disparities rarely observed in conventional reasoning
benchmarks. Detailed error analysis further uncovers specific weaknesses in
current models' abilities to generate robust high-level plans and reliably
execute structured actions. HeroBench thus not only significantly advances the
evaluation of LLM reasoning but also provides a flexible, scalable foundation
for future research into advanced, autonomous planning in virtual environments.

</details>


### [280] [Reinforcement Learning with Rubric Anchors](https://arxiv.org/abs/2508.12790)
*Zenan Huang,Yihong Zhuang,Guoshan Lu,Zeyu Qin,Haokai Xu,Tianyu Zhao,Ru Peng,Jiaqi Hu,Zhanming Shen,Xiaomeng Hu,Xijun Gu,Peiyi Tu,Jiaxin Liu,Wenyu Chen,Yuzhuo Fu,Zhiting Fan,Yanmei Gu,Yuanyuan Wang,Zhengkai Yang,Jianguo Li,Junbo Zhao*

Main category: cs.AI

TL;DR: RLVR(검증 가능한 보상) 패러다임을 개방형 작업으로 확장하기 위해 '루브릭 기반 보상'을 도입했다. 사람·LLM·혼합으로 만든 1만개 이상의 루브릭을 사용해 Qwen-30B-A3B를 소량 데이터(5k+)로 보정하여 개방형 벤치마크에서 +5.2% 향상, 스타일·톤 제어가 가능함을 보였다.


<details>
  <summary>Details</summary>
Motivation: 전통적 RLVR은 단위 테스트나 정답 비교처럼 자동 검증 가능한 도메인에 제한되어 있으나, 인간 평가가 필요한 개방형·주관적 생성 작업에도 RL의 이점을 적용하고자 함.

Method: 사람/LLM/혼합으로 대규모 루브릭(>10k)을 구축해 루브릭을 자동 점수화 가능한 기준으로 사용, 이를 보상으로 삼아 RL(또는 유사한 최적화)로 모델을 학습. 루브릭 설계·데이터 선택·훈련 프레임워크를 제시하고 모델(Qwen-30B-A3B)을 공개.

Result: 5k+ 샘플로 개방형 벤치마크(특히 인문학 분야)에서 +5.2% 향상. 671B DeepSeek-V3보다 +2.4% 높고, 일반적·추론 능력은 유지됨. 스타일·톤의 세밀한 제어 가능.

Conclusion: 루브릭 기반 보상은 주관적·개방형 생성 과제에 RLVR을 확장할 실용적 방법을 제시하며, 적은 데이터로도 효과적이나 루브릭 설계와 편향·일반화 같은 한계가 남음.

Abstract: Reinforcement Learning from Verifiable Rewards (RLVR) has emerged as a
powerful paradigm for enhancing Large Language Models (LLMs), exemplified by
the success of OpenAI's o-series. In RLVR, rewards are derived from verifiable
signals-such as passing unit tests in code generation or matching correct
answers in mathematical reasoning. While effective, this requirement largely
confines RLVR to domains with automatically checkable outcomes. To overcome
this, we extend the RLVR paradigm to open-ended tasks by integrating
rubric-based rewards, where carefully designed rubrics serve as structured,
model-interpretable criteria for automatic scoring of subjective outputs. We
construct, to our knowledge, the largest rubric reward system to date, with
over 10,000 rubrics from humans, LLMs, or a hybrid human-LLM collaboration.
Implementing rubric-based RL is challenging; we tackle these issues with a
clear framework and present an open-sourced Qwen-30B-A3B model with notable
gains: 1) With only 5K+ samples, our system improves by +5.2% on open-ended
benchmarks (especially humanities), outperforming a 671B DeepSeek-V3 model by
+2.4%, while preserving general and reasoning abilities. 2) Our method provides
fine-grained stylistic control, using rubrics as anchors to mitigate the
"AI-like" tone and produce more human-like, expressive responses. We share key
lessons in rubric construction, data selection, and training, and discuss
limitations and future releases.

</details>


### [281] [E3RG: Building Explicit Emotion-driven Empathetic Response Generation System with Multimodal Large Language Model](https://arxiv.org/abs/2508.12854)
*Ronghao Lin,Shuai Shen,Weipeng Hu,Qiaolin He,Aolin Xiong,Li Huang,Haifeng Hu,Yap-peng Tan*

Main category: cs.AI

TL;DR: E3RG는 멀티모달 LLM 기반으로 감정 이해, 공감 메모리 검색, 멀티모달 응답 생성의 3단계로 MERG를 분해해 음성·비디오 생성 모델을 통합, 추가 훈련 없이 자연스럽고 정체성 일관된 감정적 응답을 생성한다. 실험에서 제로·소수샷 설정 모두 우수한 성능을 보이며 ACM MM 25의 챌린지에서 1위를 차지했다.


<details>
  <summary>Details</summary>
Motivation: 기존 LLM은 텍스트 기반 공감형 응답 생성에서 성능이 향상되었지만 멀티모달 감정 신호(음성·영상)를 다루거나 화자의 정체성을 유지하는 데 한계가 있어 MERG 과제가 남아 있다.

Method: E3RG는 MERG를 세 부분으로 분해: (1) 멀티모달 공감 이해(입력의 감정·의도 파악), (2) 공감 메모리 검색(문맥·정체성 정보 보관/검색), (3) 멀티모달 응답 생성(텍스트·음성·영상 생성 모듈 통합). 고성능 음성·비디오 생성 모델을 결합해 추가 학습 없이 응답을 생성한다.

Result: 제로샷·푸샷 실험에서 우수한 성능을 보였고, Avatar-based Multimodal Empathy Challenge(ACM MM 25)에서 1위를 차지했다.

Conclusion: E3RG는 멀티모달 신호를 통합해 자연스럽고 감정적으로 풍부하며 정체성 일관된 응답을 생성하는 실용적 시스템임을 보여주며 코드가 공개되어 있다.

Abstract: Multimodal Empathetic Response Generation (MERG) is crucial for building
emotionally intelligent human-computer interactions. Although large language
models (LLMs) have improved text-based ERG, challenges remain in handling
multimodal emotional content and maintaining identity consistency. Thus, we
propose E3RG, an Explicit Emotion-driven Empathetic Response Generation System
based on multimodal LLMs which decomposes MERG task into three parts:
multimodal empathy understanding, empathy memory retrieval, and multimodal
response generation. By integrating advanced expressive speech and video
generative models, E3RG delivers natural, emotionally rich, and
identity-consistent responses without extra training. Experiments validate the
superiority of our system on both zero-shot and few-shot settings, securing
Top-1 position in the Avatar-based Multimodal Empathy Challenge on ACM MM 25.
Our code is available at https://github.com/RH-Lin/E3RG.

</details>


### [282] [Reliability, Embeddedness, and Agency: A Utility-Driven Mathematical Framework for Agent-Centric AI Adoption](https://arxiv.org/abs/2508.12896)
*Faruk Alpay,Taylan Alpay*

Main category: cs.AI

TL;DR: 요약: 에이전트 중심 AI의 지속적 채택을 위해 ‘신뢰성>새로움, 통합>목적지, 행위성>대화’라는 세 가지 설계 공리를 제시하고, 채택 시계를 신기성의 쇠퇴항과 효용의 성장항 합으로 모델링하여 ‘둔덕(trough)/과도(overshoot)’ 발생 조건을 엄밀히 도출함. 모수식별성, 델타방법 그래디언트, 다양한 위험모형(hazard), 비단조 비교모형, 시뮬레이션 벤치마크, 보정·잔차분석·크러머-라오 하한 등 포괄적 검증과 재현 가능한 코드 제공.


<details>
  <summary>Details</summary>
Motivation: 에이전트형 AI가 다단계 업무에서 실제로 장기 채택되려면 단순한 초기 흥분이 아니라 신뢰·통합·행동성 요소가 필요하다는 현업적·이론적 문제의식.

Method: 수학적 모델링(채택 = 감쇠하는 신기성 + 성장하는 효용), 위상(phase) 조건 증명, 식별성·혼동성 분석(델타방법), 로그리스틱 변형의 비단조 대조, 위험함수(h(·)) 가족별 절단실험, 다중 시계열 시뮬레이션으로 커버리지 평가, 마찰 프록시 보정, 잔차(자기상관·이분산) 진단, Fisher 정보/CRLB 계산, 마이크로파운더리 연결, 여러 경쟁모형과 비교.

Result: 둔덕·과도 발생을 일으키는 명확한 파라미터 조건을 도출하고(수학적 증명 포함), 다양한 합성 실험에서 제안 모형의 식별성·검정력·타입 I 오류 특성 및 민감도를 보고, 마찰 프록시가 시간-동작·설문 데이터와 정합됨을 보이며, 잔차·정보량 분석을 통해 추정의 안정성을 평가.

Conclusion: 채택 동학에 대한 이론적·실증적·재현 가능한 통합 틀을 제시. 실무자에게는 신뢰·통합·행위성에 대한 설계 우선순위를, 연구자에게는 식별·비교·검증 도구들을 제공하나 실제 현장 적용과 이질성·가정 민감성 검증이 추가 필요함.

Abstract: We formalize three design axioms for sustained adoption of agent-centric AI
systems executing multi-step tasks: (A1) Reliability > Novelty; (A2) Embed >
Destination; (A3) Agency > Chat. We model adoption as a sum of a decaying
novelty term and a growing utility term and derive the phase conditions for
troughs/overshoots with full proofs. We introduce: (i) an
identifiability/confounding analysis for $(\alpha,\beta,N_0,U_{\max})$ with
delta-method gradients; (ii) a non-monotone comparator
(logistic-with-transient-bump) evaluated on the same series to provide
additional model comparison; (iii) ablations over hazard families $h(\cdot)$
mapping $\Delta V \to \beta$; (iv) a multi-series benchmark (varying trough
depth, noise, AR structure) reporting coverage (type-I error, power); (v)
calibration of friction proxies against time-motion/survey ground truth with
standard errors; (vi) residual analyses (autocorrelation and
heteroskedasticity) for each fitted curve; (vii) preregistered windowing
choices for pre/post estimation; (viii) Fisher information & CRLB for
$(\alpha,\beta)$ under common error models; (ix) microfoundations linking
$\mathcal{T}$ to $(N_0,U_{\max})$; (x) explicit comparison to bi-logistic,
double-exponential, and mixture models; and (xi) threshold sensitivity to $C_f$
heterogeneity. Figures and tables are reflowed for readability, and the
bibliography restores and extends non-logistic/Bass adoption references
(Gompertz, Richards, Fisher-Pry, Mansfield, Griliches, Geroski, Peres). All
code and logs necessary to reproduce the synthetic analyses are embedded as
LaTeX listings.

</details>


### [283] [FuSaR: A Fuzzification-Based Method for LRM Safety-Reasoning Balance](https://arxiv.org/abs/2508.12897)
*Jianhao Chen,Mayi Xu,Xiaohu Li,Yongqi Li,Xiangyu Zhang,Jianjie Huang,Tieyun Qian*

Main category: cs.AI

TL;DR: Introduce FuSaR, a fuzzification-based alignment strategy that hides dangerous entities and procedures in reasoning steps to detoxify reasoning, aiming to preserve reasoning ability while improving safety.


<details>
  <summary>Details</summary>
Motivation: Authors observe a trade-off/competition: improving LRM reasoning can reduce its safety (makes jailbreaks easier). They aim to balance reasoning and safety without sacrificing capability.

Method: Apply 'Fuzzification' to reasoning chains: mask or hide dangerous entities and dangerous procedures in reasoning steps, create detoxified reasoning data, and use it to align/open-source LRMs.

Result: Experiments on multiple open-source LRMs show FuSaR reduces safety risks while maintaining core reasoning performance, outperforming existing baselines in combined safety and reasoning metrics.

Conclusion: FuSaR is an efficient alignment method that can simultaneously enhance reasoning capability and safety by detoxifying intermediate reasoning steps through targeted obfuscation.

Abstract: Large Reasoning Models (LRMs) have demonstrated impressive performance across
various tasks due to their powerful reasoning capabilities. However, their
safety performance remains a significant concern. In this paper, we explore the
reasons behind the vulnerability of LRMs. Based on this, we propose a novel
method to improve the safety of LLMs without sacrificing their reasoning
capability. Specifically, we exploit the competition between LRM's reasoning
ability and safety ability, and achieve jailbreak by improving LRM's reasoning
performance to reduce its safety performance. We then introduce an alignment
strategy based on Fuzzification to balance Safety-Reasoning (FuSaR), by
detoxifying the harmful reasoning process, where both the dangerous entities
and the dangerous procedures in the reasoning steps are hidden. FuSaR
successfully mitigates safety risks while preserving core reasoning
information. We validate this strategy through alignment experiments on several
open-source LRMs using detoxified reasoning data. The results compared with
existing baselines conclusively show that FuSaR is an efficient alignment
strategy to simultaneously enhance both the reasoning capability and safety of
LRMs.

</details>


### [284] [Towards Open-Ended Emotional Support Conversations in LLMs via Reinforcement Learning with Future-Oriented Rewards](https://arxiv.org/abs/2508.12935)
*Ting Yang,Li Chen,Huimin Wang*

Main category: cs.AI

TL;DR: LLM 기반의 감정지원 대화 시스템에서 미리 정해진 전략 의존성을 넘고, 강화학습과 LLM 기반 다중 에이전트 시뮬레이션을 통해 장기적·미래지향적 보상을 학습하여 지속적이고 문맥에 적합한 감정지원 응답을 생성하는 엔드투엔드 프레임워크(RLFF-ESC)를 제안한다. Qwen 및 LLaMA 계열 백본에서 두 공용 데이터셋으로 평가해 기존 기법보다 목표완수도와 응답 품질이 우수함을 보였다.


<details>
  <summary>Details</summary>
Motivation: 대부분의 LLM 기반 감정지원 시스템이 사전정의된 전략에 의존해 복잡한 실제 시나리오에서 유연성이 떨어지고 장기적 지원 능력이 제한된다. 이 한계를 극복하고 다양한 정서 문제에 유연히 대응할 수 있는 지속적인 지원 스킬을 직접 학습할 필요가 있다.

Method: (1) LLM 기반 다중 에이전트 메커니즘으로 미래 대화 궤적을 시뮬레이션해 미래지향적 보상을 수집, (2) 그 데이터를 바탕으로 미래지향적 보상 모델을 학습, (3) 이 보상 모델을 이용해 감정지원 정책을 강화학습으로 학습, (4) 응답 생성 시 명시적 추론 과정(추론 루틴)을 삽입해 품질·관련성·문맥적 적합성 향상. 백본으로 Qwen2.5-7B-Instruct-1M과 LLaMA3.1-8B-Instruct를 사용해 두 공용 ESC 데이터셋에서 실험.

Result: 실험에서 RLFF-ESC는 기존 베이스라인들보다 목표완수(goal completion)와 응답 품질 지표에서 일관되게 우수한 성능을 보였다.

Conclusion: 미래지향적 보상과 명시적 추론을 결합한 강화학습 접근은 감정지원 응답의 지속성·유연성·품질을 개선하며, LLM 기반 ESC의 실용적 효용을 높이는 유망한 방향임을 시사한다.

Abstract: Emotional Support Conversation (ESC) systems aim to alleviate users'
emotional difficulties and provide long-term, systematic support for emotional
well-being. However, most large language model (LLM)-based ESC systems rely on
predefined strategies, which limits their effectiveness in complex, real-life
scenarios. To enable flexible responses to diverse emotional problem scenarios,
this paper introduces a novel end-to-end framework (RLFF-ESC) that directly
learns enduring emotionally supportive response skills using reinforcement
learning. For sustained emotional support, we first employ an LLM-based
multi-agent mechanism to simulate future dialogue trajectories and collect
future-oriented rewards. We then train a future-oriented reward model, which is
subsequently used to train the emotional support policy model. Additionally, we
incorporate an explicit reasoning process during response generation to further
enhance the quality, relevance, and contextual appropriateness of the system's
responses. We evaluate the backbone policy model on Qwen2.5-7B-Instruct-1M and
LLaMA3.1-8B-Instruct models, testing the proposed RLFF-ESC framework across two
public ESC datasets. Experimental results demonstrate that RLFF-ESC
consistently outperforms existing baselines in terms of goal completion and
response quality.

</details>


### [285] [OPTIC-ER: A Reinforcement Learning Framework for Real-Time Emergency Response and Equitable Resource Allocation in Underserved African Communities](https://arxiv.org/abs/2508.12943)
*Mary Tonwe*

Main category: cs.AI

TL;DR: OPTIC-ER는 아프리카 저자원 환경(나이저리아 Rivers 주)을 대상으로 실시간·적응형·형평성 중심 응급 출동을 목표로 한 강화학습 프레임워크이다. 어텐션 기반 액터-크리틱, Context-Rich 상태 벡터(행동의 아차성 포함), 비효율성에 페널티를 주는 Precision 보상, Travel Time Atlas로 가속된 고충실도 시뮬레이션을 특징으로 한다. 평가에서 500건의 미공개 사건에 대해 100% 최적성·무시 가능한 비효율성을 보고했다.


<details>
  <summary>Details</summary>
Motivation: 많은 아프리카 지역에서 응급출동 지연과 공간적 불형평이 발생해 회피 가능한 피해가 발생한다. 저자원 조건에서도 실시간으로 적응하고 형평성 있는 자원 배분을 자동화하는 시스템 필요성에서 출발.

Method: 어텐션-가이드 액터-크리틱 아키텍처를 사용해 다중 에이전트/다중 액션 환경의 복잡성을 관리. Context-Rich 상태 벡터는 행동의 잠재적 하위최적성(sub-optimality)을 인코딩하고, Precision 보상은 비효율성을 벌점화. 실제 Rivers 주 데이터를 사용한 고충실도 시뮬레이션과 사전계산된 Travel Time Atlas로 학습을 가속. TALS(Thin, Adaptable, Low-cost, Scalable) 프레임워크로 저자원 배포를 염두.

Result: 500개 미공개 사건 평가에서 100% 최적성 달성·비효율성 거의 없음 보고. 인프라 결핍 지도와 형평성 모니터링 대시보드를 산출하여 거버넌스 도구로 활용 가능.

Conclusion: 컨텍스트 인지 강화학습을 응급 출동 문제에 적용해 알고리즘적 결정과 실질적 인간 영향 사이의 간극을 메우는 검증된 청사진을 제시한다고 주장.

Abstract: Public service systems in many African regions suffer from delayed emergency
response and spatial inequity, causing avoidable suffering. This paper
introduces OPTIC-ER, a reinforcement learning (RL) framework for real-time,
adaptive, and equitable emergency response. OPTIC-ER uses an attention-guided
actor-critic architecture to manage the complexity of dispatch environments.
Its key innovations are a Context-Rich State Vector, encoding action
sub-optimality, and a Precision Reward Function, which penalizes inefficiency.
Training occurs in a high-fidelity simulation using real data from Rivers
State, Nigeria, accelerated by a precomputed Travel Time Atlas. The system is
built on the TALS framework (Thin computing, Adaptability, Low-cost,
Scalability) for deployment in low-resource settings. In evaluations on 500
unseen incidents, OPTIC-ER achieved a 100.00% optimality rate with negligible
inefficiency, confirming its robustness and generalization. Beyond dispatch,
the system generates Infrastructure Deficiency Maps and Equity Monitoring
Dashboards to guide proactive governance and data-informed development. This
work presents a validated blueprint for AI-augmented public services, showing
how context-aware RL can bridge the gap between algorithmic decision-making and
measurable human impact.

</details>


### [286] [EvolMathEval: Towards Evolvable Benchmarks for Mathematical Reasoning via Evolutionary Testing](https://arxiv.org/abs/2508.13003)
*Shengbo Wang,Mingwei Liu,Zike Li,Anji Li,Yanlin Wang,Xin Peng,Zibin Zheng*

Main category: cs.AI

TL;DR: EvolMathEval은 진화적 테스트로 수학 문제를 자동 생성·진화시키는 프레임워크로, 데이터 오염을 제거하고 문제 난이도를 지속적으로 높여 LLM의 추론 취약점을 드러냄.


<details>
  <summary>Details</summary>
Motivation: 기존 수학 벤치마크는 점수 포화, 시간 의존성, 데이터 오염으로 인해 LLM의 실제 수학 추론 능력을 평가하기 어렵다. 새로운 자동화·진화적 생성 방식으로 항상 새롭고 도전적인 문제를 제공하려 함.

Method: 역공학 기반 씨드 생성(대수적 보장 포함), 다차원 유전 연산자(인지적 다양성 주입), 문제 난이도를 빠르고 정확히 측정하는 복합 적합도 함수로 문제를 생성·선별·진화.

Result: 복합 적합도 함수가 난이도를 효율적·정확히 정량화함을 보였고, 지속적 진화를 통해 고난이도 문제를 대량 생성. GSM8K 등 공개 데이터셋을 진화시키면 모델 정확도가 평균 48% 감소. 'Pseudo Aha Moment'라는 비엄밀한 휴리스틱 사용 현상(오답의 77–100%)을 규명.

Conclusion: EvolMathEval은 데이터 오염 문제를 회피하면서 LLM의 심층 계산·논리 취약점을 드러내는 지속가능한 벤치마크를 제공하며, LLM들이 복잡한 다단계 추론에서 비엄밀한 지름길을 자주 이용함을 실증함.

Abstract: The rapid advancement of LLMs poses a significant challenge to existing
mathematical reasoning benchmarks. These benchmarks commonly suffer from issues
such as score saturation, temporal decay, and data contamination. To address
this challenge, this paper introduces EvolMathEval, an automated mathematical
benchmark generation and evolution framework based on evolutionary testing. By
dynamically generating unique evaluation instances ab initio, the framework
fundamentally eliminates the risk of data contamination, and ensuring the
benchmark remains perpetually challenging for future models.The core mechanisms
of EvolMathEval include: seed problem generation based on reverse engineering
with algebraic guarantees; multi-dimensional genetic operators designed to
inject diverse cognitive challenges; and a composite fitness function that can
rapidly and accurately assess problem difficulty. Experimental results
demonstrate that the proposed composite fitness function can efficiently and
precisely quantify the difficulty of mathematical problems. Furthermore,
EvolMathEval can not only generate a large volume of high-difficulty problems
through continuous self-iteration, but it can also significantly enhance the
complexity of public datasets like GSM8K through evolution, reducing model
accuracy by an average of 48%. Deeper investigation reveals that when solving
these evolved, complex problems, LLMs tend to employ non-rigorous heuristics to
bypass complex multi-step logical reasoning, consequently leading to incorrect
solutions. We define this phenomenon as "Pseudo Aha Moment". This finding
uncovers a cognitive shortcut-taking behavior in the deep reasoning processes
of current LLMs, which we find accounts for 77% to 100% of errors on targeted
problems. Code and resources are available
at:https://github.com/SYSUSELab/EvolMathEval.

</details>


### [287] [e-boost: Boosted E-Graph Extraction with Adaptive Heuristics and Exact Solving](https://arxiv.org/abs/2508.13020)
*Jiaqi Yin,Zhan Song,Chen Chen,Yaohui Cai,Zhiru Zhang,Cunxi Yu*

Main category: cs.AI

TL;DR: 제안한 e-boost는 병렬화된 휴리스틱 추출, 적응형 탐색공간 가지치기, 초기화된 정확해법(ILP 와밍 스타트)을 결합해 e-graph 추출 문제를 실용적 속도와 높은 품질로 해결한다. 기존 정확해법 대비 약 558배 속도 향상, SmoothE 대비 19.04% 성능 개선을 보이며 실제 합성에서 면적 7.6%/8.1% 감소를 달성했다.


<details>
  <summary>Details</summary>
Motivation: e-graph 추출은 동치 표현들 중 최적 항을 선택해야 하는 NP-하드 문제로, 기존 휴리스틱은 빠르지만 최적성을 잃고, 정확해법은 최적이지만 큰 입력에 대해 비현실적이다. 실무적 속도·품질 균형을 맞출 방법이 필요하다.

Method: (1) DAG 비용 계산의 약한 데이터 의존성을 이용한 병렬화된 휴리스틱 추출으로 다중 스레드 성능을 확보, (2) 파라미터화된 임계값을 이용한 적응형 후보 가지치기로 해 검색 공간을 크게 축소하면서 근-최적 후보 유지, (3) 축소된 문제를 정수선형계획(ILP)으로 정식화하고 와밍 스타트로 초기해를 주어 정확해법이 빠르게 수렴하게 함.

Result: 다양한 검증·합성 벤치마크에서 전통적 ILP 대비 평균 558× 런타임 향상, SmoothE 대비 19.04% 성능 개선. 실제 기술 매핑 라이브러리 두 종에 대해 기존 합성 툴보다 면적 7.6% 및 8.1% 개선을 보고. 구현(오픈소스) 제공.

Conclusion: e-boost는 실용적 속도와 높은 품질을 동시에 달성해 e-graph 기반 최적화의 병목을 완화한다. 병렬 휴리스틱 + 적응적 가지치기 + 초기화된 정확해법의 조합이 실무적 문제에 유의미한 이득을 줌.

Abstract: E-graphs have attracted growing interest in many fields, particularly in
logic synthesis and formal verification. E-graph extraction is a challenging
NP-hard combinatorial optimization problem. It requires identifying optimal
terms from exponentially many equivalent expressions, serving as the primary
performance bottleneck in e-graph based optimization tasks. However,
traditional extraction methods face a critical trade-off: heuristic approaches
offer speed but sacrifice optimality, while exact methods provide optimal
solutions but face prohibitive computational costs on practical problems. We
present e-boost, a novel framework that bridges this gap through three key
innovations: (1) parallelized heuristic extraction that leverages weak data
dependence to compute DAG costs concurrently, enabling efficient multi-threaded
performance without sacrificing extraction quality; (2) adaptive search space
pruning that employs a parameterized threshold mechanism to retain only
promising candidates, dramatically reducing the solution space while preserving
near-optimal solutions; and (3) initialized exact solving that formulates the
reduced problem as an Integer Linear Program with warm-start capabilities,
guiding solvers toward high-quality solutions faster.
  Across the diverse benchmarks in formal verification and logic synthesis
fields, e-boost demonstrates 558x runtime speedup over traditional exact
approaches (ILP) and 19.04% performance improvement over the state-of-the-art
extraction framework (SmoothE). In realistic logic synthesis tasks, e-boost
produces 7.6% and 8.1% area improvements compared to conventional synthesis
tools with two different technology mapping libraries. e-boost is available at
https://github.com/Yu-Maryland/e-boost.

</details>


### [288] [PC-Sampler: Position-Aware Calibration of Decoding Bias in Masked Diffusion Models](https://arxiv.org/abs/2508.13021)
*Pengcheng Huang,Shuhao Liu,Zhenghao Liu,Yukun Yan,Shuo Wang,Zulong Chen,Tong Xiao*

Main category: cs.AI

TL;DR: Masked diffusion models(이하 MDMs)에서 디코딩 전략이 성능을 크게 좌우함을 보이고, 전역 경로 제어와 조기 trivial 토큰 선택 문제를 해결하는 Position-Aware Confidence-Calibrated Sampling(PC-Sampler)을 제안한다. 위치 기반 가중치와 신뢰도 보정 점수를 결합해 디코딩을 계획적으로 진행하며, 3종 MDM과 7개 벤치마크에서 기존 방법들보다 평균 10% 이상 성능 향상을 보인다.


<details>
  <summary>Details</summary>
Motivation: 기존의 불확실성 기반 샘플러는 전역적인 디코딩 경로 제어 능력이 부족하고 디코딩 초반에 사소한(trivial) 토큰을 과도하게 선택하는 편향을 갖는다. 이러한 한계가 MDM의 성능을 제한하므로, 전역 계획성과 콘텐츠 정보량(정보성)을 동시에 고려하는 새로운 샘플링 방식이 필요하다.

Method: PC-Sampler는 두 가지 핵심 요소를 결합한다: (1) 위치 인식 가중치(position-aware weighting)를 통해 디코딩 경로를 제어하고 전역적인 토큰 선택 우선순위를 조절, (2) 신뢰도 보정(calibrated confidence score)을 도입해 초반에 쉬운/사소한 토큰이 지나치게 선택되는 것을 억제한다. 이 두 요소로 전역 경로 계획(global trajectory planning)과 내용 기반 정보성 최대화(content-aware informativeness maximization)를 통합한다.

Result: 세 가지 고급 MDM과 일곱 개의 어려운 벤치마크(논리 추론 및 계획 문제 포함)에서 PC-Sampler가 기존 MDM 디코딩 전략 대비 평균 10% 이상 우수한 성능을 보였고, 자동회귀(autoregressive) 모델과의 성능 격차를 크게 줄였다. 코드 공개로 재현성 보장.

Conclusion: 디코딩 전략 개선만으로도 MDM의 성능을 크게 끌어올릴 수 있음을 보여주며, 위치 인식과 신뢰도 보정의 결합이 실용적이고 효과적이다. 다만 세부 실험(측정 지표, 통계적 유의성, 계산 비용, 하이퍼파라미터 민감도) 확인과 더 넓은 도메인으로의 일반화 여부 검증은 논문 본문에서 살펴봐야 한다.

Abstract: Recent advances in masked diffusion models (MDMs) have established them as
powerful non-autoregressive alternatives for sequence generation. Nevertheless,
our preliminary experiments reveal that the generation quality of MDMs is still
highly sensitive to the choice of decoding strategy. In particular, widely
adopted uncertainty-based samplers suffer from two key limitations: a lack of
global trajectory control and a pronounced bias toward trivial tokens in the
early stages of decoding. These shortcomings restrict the full potential of
MDMs. In this work, we introduce Position-Aware Confidence-Calibrated Sampling
(PC-Sampler), a novel decoding strategy that unifies global trajectory planning
with content-aware informativeness maximization. PC-Sampler incorporates a
position-aware weighting mechanism to regulate the decoding path and a
calibrated confidence score to suppress the premature selection of trivial
tokens. Extensive experiments on three advanced MDMs across seven challenging
benchmarks-including logical reasoning and planning tasks-demonstrate that
PC-Sampler consistently outperforms existing MDM decoding strategies by more
than 10% on average, significantly narrowing the performance gap with
state-of-the-art autoregressive models. All codes are available at
https://github.com/NEUIR/PC-Sampler.

</details>


### [289] [G$^2$RPO-A: Guided Group Relative Policy Optimization with Adaptive Guidance](https://arxiv.org/abs/2508.13023)
*Yongxin Guo,Wenbo Deng,Zhenglin Cheng,Xiaoying Tang*

Main category: cs.AI

TL;DR: 작은 언어모델(SLM)의 추론 능력 향상을 위해 roll-out 궤적에 정답(reasoning step)을 주입하고, 그 강도를 학습 중 자동으로 조절하는 적응형 알고리즘 G^2RPO-A를 제안한다. 수학·코드 생성 벤치에서 기존 GRPO 대비 성능이 크게 개선되었다고 보고한다.


<details>
  <summary>Details</summary>
Motivation: 기존 RL with Verifiable Rewards(RLVR)은 대형언어모델(LLM)의 추론 능력을 높였지만, 풍부한 세계지식을 지닌 강력한 베이스 모델에 크게 의존해 작은 모델(SLM)에서는 향상 폭이 제한적이었다. SLM의 본질적 약점을 보완하기 위해 정답 추론 단계를 보강하는 방법을 탐구하고자 한다.

Method: Guided GRPO: roll-out 궤적에 ground-truth reasoning step을 주입하는 방식. 다양한 가이던스 구성(강도, 빈도 등)을 포괄적으로 실험한 뒤, 단순한 가이던스는 한계가 있음을 확인하고, 학습 동적 변화에 따라 가이던스 강도를 자동으로 조절하는 G^2RPO-A를 제안하여 학습 과정에서 적절한 보조를 제공하도록 설계했다.

Result: 수학적 추론 및 코드 생성 벤치마크에서 G^2RPO-A가 vanilla GRPO보다 유의미하게 우수한 성능을 보였으며, 코드와 모델을 공개했다.

Conclusion: 정답 기반의 가이던스를 고정적으로 주입하는 것보다 학습 동태에 맞춰 강도를 조절하는 적응형 접근이 SLM의 추론·생성 능력 향상에 효과적임을 보였다.

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has markedly enhanced
the reasoning abilities of large language models (LLMs). Its success, however,
largely depends on strong base models with rich world knowledge, yielding only
modest improvements for small-size language models (SLMs). To address this
limitation, we investigate Guided GRPO, which injects ground-truth reasoning
steps into roll-out trajectories to compensate for SLMs' inherent weaknesses.
Through a comprehensive study of various guidance configurations, we find that
naively adding guidance delivers limited gains. These insights motivate
G$^2$RPO-A, an adaptive algorithm that automatically adjusts guidance strength
in response to the model's evolving training dynamics. Experiments on
mathematical reasoning and code-generation benchmarks confirm that G$^2$RPO-A
substantially outperforms vanilla GRPO. Our code and models are available at
https://github.com/T-Lab-CUHKSZ/G2RPO-A.

</details>


### [290] [A Language-Signal-Vision Multimodal Framework for Multitask Cardiac Analysis](https://arxiv.org/abs/2508.13072)
*Yuting Zhang,Tiantian Geng,Luoying Hao,Xinxing Cheng,Alexander Thorley,Xiaoxia Wang,Wenqi Lu,Sandeep S Hothi,Lei Wei,Zhaowen Qiu,Dipak Kotecha,Jinming Duan*

Main category: cs.AI

TL;DR: 심전도·심초음파·검사실 데이터 등 환자-시간 정렬된 다중심장 모달리티를 통합한 데이터셋을 구축하고, 모듈형의 텍스트 유도 다중모달 융합 프레임워크(TGMM)를 제안하여 진단·위험층정·정보검색 등 다중 임상과제에서 SOTA 성능을 달성함.


<details>
  <summary>Details</summary>
Motivation: 현행 다중모달 심장 데이터 통합 연구는 데이터 부족, 단일모달 또는 고정된 입력 조합 의존, 유사성 중심 정렬, 단일 과제 초점 등의 한계로 실제 임상 적용에 제약이 있음.

Method: 환자·시간 정렬된 검사실 결과, ECG, 심초음파, 임상 결과를 통합한 데이터셋 구축. MedFlexFusion(모달리티 고유·보완 특성 포착 및 동적 융합), 텍스트 유도 모듈(과제 관련 표현 추출), 응답 모듈(다중 과제 결정)로 구성된 TGMM 제안. 모달별 중요도 및 상호작용 분석 수행.

Result: 다중 임상 과제에서 기존 방법들보다 우수한 성능을 보였고, 공개 데이터셋에서의 추가 검증으로 강건성을 확인함.

Conclusion: TGMM은 유연한 모달 조합과 과제별 텍스트 유도로 다중심장 과제에 대한 통합적·확장 가능한 솔루션을 제공하며, 임상 의사결정 지원에 실용적 가능성을 시사함.

Abstract: Contemporary cardiovascular management involves complex consideration and
integration of multimodal cardiac datasets, where each modality provides
distinct but complementary physiological characteristics. While the effective
integration of multiple modalities could yield a holistic clinical profile that
accurately models the true clinical situation with respect to data modalities
and their relatives weightings, current methodologies remain limited by: 1) the
scarcity of patient- and time-aligned multimodal data; 2) reliance on isolated
single-modality or rigid multimodal input combinations; 3) alignment strategies
that prioritize cross-modal similarity over complementarity; and 4) a narrow
single-task focus. In response to these limitations, a comprehensive multimodal
dataset was curated for immediate application, integrating laboratory test
results, electrocardiograms, and echocardiograms with clinical outcomes.
Subsequently, a unified framework, Textual Guidance Multimodal fusion for
Multiple cardiac tasks (TGMM), was proposed. TGMM incorporated three key
components: 1) a MedFlexFusion module designed to capture the unique and
complementary characteristics of medical modalities and dynamically integrate
data from diverse cardiac sources and their combinations; 2) a textual guidance
module to derive task-relevant representations tailored to diverse clinical
objectives, including heart disease diagnosis, risk stratification and
information retrieval; and 3) a response module to produce final decisions for
all these tasks. Furthermore, this study systematically explored key features
across multiple modalities and elucidated their synergistic contributions in
clinical decision-making. Extensive experiments showed that TGMM outperformed
state-of-the-art methods across multiple clinical tasks, with additional
validation confirming its robustness on another public dataset.

</details>


### [291] [Bayesian Optimization-based Search for Agent Control in Automated Game Testing](https://arxiv.org/abs/2508.13121)
*Carlos Celemin*

Main category: cs.AI

TL;DR: 게임 캐릭터 에이전트를 이용한 자동화된 게임 레벨 버그 탐지 방법을 제안한다. 베이지안 최적화(BO)를 이용해 샘플 효율적으로 다음 탐색 지점을 선택하고, BO에 적합한 그리드 기반 모델을 도입해 BO의 요구조건(부드러움, 불확실성 추정)을 만족시키면서 확장성 문제를 회피한다. 실험에서 시간 효율성과 탐험 분포 측면에서 맵 커버리지를 크게 향상시켰다.


<details>
  <summary>Details</summary>
Motivation: 수작업 게임 테스트의 비용과 시간 문제를 해결하고, 제한된 시도 횟수로 잠재적 버그를 빠르고 효과적으로 찾기 위해 샘플 효율적인 자동 탐색 전략이 필요하다. 기존 모델은 BO에 요구되는 특성을 만족시키지 못하거나 확장성(대규모 맵, 상태공간) 문제가 있다.

Method: 게임 레벨을 그리드 맵으로 표현하고, 그 위에 BO가 필요로 하는 부드러움과 불확실성 추정을 제공하는 전용 모델을 설계한다. 에이전트가 캐릭터를 조종해 후보 지점을 샘플링하고, 수집된 데이터로 BO가 정보를 최대화하는 다음 지점을 계산해 반복적으로 탐험을 진행한다. 모델은 전통적 GP와 같은 기법의 확장성 한계를 피하도록 설계되었다.

Result: 제안 방법은 실험에서 기존 방식보다 맵 커버리지를 더 빠르게 확보했으며, 시간 효율성과 탐험 분포(더 고르게 또는 더 유망한 지역으로의 탐색) 면에서 유의미한 개선을 보였다.

Conclusion: BO와 게임-특화 그리드 모델을 결합한 접근은 제한된 샘플 예산 하에서 효과적인 자동 게임 테스트 전략을 제공한다. 확장성과 탐색 효율성을 동시에 개선한 점이 핵심 기여이다.

Abstract: This work introduces an automated testing approach that employs agents
controlling game characters to detect potential bugs within a game level.
Harnessing the power of Bayesian Optimization (BO) to execute sample-efficient
search, the method determines the next sampling point by analyzing the data
collected so far and calculates the data point that will maximize information
acquisition. To support the BO process, we introduce a game testing-specific
model built on top of a grid map, that features the smoothness and uncertainty
estimation required by BO, however and most importantly, it does not suffer the
scalability issues that traditional models carry. The experiments demonstrate
that the approach significantly improves map coverage capabilities in both time
efficiency and exploration distribution.

</details>


### [292] [Exploring Autonomous Agents: A Closer Look at Why They Fail When Completing Tasks](https://arxiv.org/abs/2508.13143)
*Ruofan Lu,Yichen Li,Yintong Huo*

Main category: cs.AI

TL;DR: 이 논문은 LLM 기반 자율 에이전트의 평가가 성공률에만 의존하는 한계를 지적하고, 34개 과제 벤치마크와 실패 분석을 통해 계획·실행·응답 생성 단계의 실패 유형을 분류한 뒤 개선안을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 현행 평가가 단순 성공률에 의존해 에이전트의 상호작용·통신·실패 원인을 체계적으로 분석하지 못하므로, 더 정밀한 진단과 개선을 위해 상세 벤치마크와 실패 분류가 필요하다.

Method: 34개의 프로그래머블 과제로 구성된 벤치마크를 설계하고, 세 가지 오픈소스 에이전트 프레임워크와 두 가지 LLM 백본을 조합해 평가를 수행했다. 완료율 약 50%를 관찰하고, 실패 사례를 심층 분석해 세 단계의 실패 분류를 도출했다.

Result: 평균 과제 완료율은 약 50%였고, 실패 원인은 계획 오류, 과제 실행 문제, 잘못된 응답 생성으로 분류되었다. 각 원인별 사례와 분포를 제시하고 개선 방향을 제안했다.

Conclusion: 제안된 실패 분류와 개선 권고는 향후 더 견고한 자율 에이전트 개발을 위한 실험적 토대를 제공한다.

Abstract: Autonomous agent systems powered by Large Language Models (LLMs) have
demonstrated promising capabilities in automating complex tasks. However,
current evaluations largely rely on success rates without systematically
analyzing the interactions, communication mechanisms, and failure causes within
these systems. To bridge this gap, we present a benchmark of 34 representative
programmable tasks designed to rigorously assess autonomous agents. Using this
benchmark, we evaluate three popular open-source agent frameworks combined with
two LLM backbones, observing a task completion rate of approximately 50%.
Through in-depth failure analysis, we develop a three-tier taxonomy of failure
causes aligned with task phases, highlighting planning errors, task execution
issues, and incorrect response generation. Based on these insights, we propose
actionable improvements to enhance agent planning and self-diagnosis
capabilities. Our failure taxonomy, together with mitigation advice, provides
an empirical foundation for developing more robust and effective autonomous
agent systems in the future.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [293] [Proceedings 18th Interaction and Concurrency Experience](https://arxiv.org/abs/2508.12308)
*Clément Aubert,Cinzia Di Giusto,Simon Fowler,Violet Ka I Pun*

Main category: cs.DC

TL;DR: ICE'25 워크숍 논문집 개요: 2025년 6월 20일 프랑스 릴에서 열린 ICE'25의 절차·수락 현황·초청 강연 정보를 담고 있음.


<details>
  <summary>Details</summary>
Motivation: 워크숍과 논문집의 목적은 상호작용적·익명 기반의 활발한 리뷰 과정을 통해 고품질 연구를 선발·공개하고, 워크숍에서의 논의로 논문을 개선하는 것.

Method: 제출작 7편, 각 논문 당 PC 위원 3인 리뷰, 익명 상호작용을 통한 댓글 약 75개 교환. 리뷰와 워크숍 토론을 반영하여 최종 원고를 수정·수록.

Result: 최종적으로 4편의 논문과 1건의 구두 발표(워크숍 발표) 채택. Kirstin Peters의 초청 강연 초록 포함. 논문집에는 워크숍과 리뷰 과정에서의 논의가 반영된 최종 버전 수록.

Conclusion: 익명 상호작용형 리뷰가 활성화된 채택 과정으로 소수 정예의 연구가 선발되었으며, 워크숍 토론을 통해 논문 내용이 개선되어 최종 논문집에 반영되었다.

Abstract: This volume contains the proceedings of ICE'25, the 18th Interaction and
Concurrency Experience, which was held on Friday 20th June 2025 at the \'Ecole
National Sup\'erieure des Arts et M\'etiers in Lille, France, as a satellite
workshop of DisCoTec 2025. The ICE workshop series features a distinguishing
review and selection procedure: PC members are encouraged to interact,
anonymously, with authors. The 2025 edition of ICE received 7 submissions, each
reviewed by three PC members, and about 75 comments were exchanged during the
review process, witnessing very lively discussions. Four papers were accepted
for publication plus 1 oral communication, which was accepted for presentation
at the workshop. We were proud to host one invited talk, by Kirstin Peters. The
abstract of her talk is included in this volume, together with the final
versions of the research papers, which take into account the discussion at the
workshop and during the review process.

</details>


### [294] [Breaking the Aggregation Bottleneck in Federated Recommendation: A Personalized Model Merging Approach](https://arxiv.org/abs/2508.12386)
*Jundong Chen,Honglei Zhang,Chunxu Zhang,Fangyuan Luo,Yidong Li*

Main category: cs.DC

TL;DR: FedEM은 연합 추천에서 서버 집계가 개인화 성능을 저해하는 ‘aggregation bottleneck’을 이론·실험적으로 규명하고, 전역 모델과 로컬 모델을 탄력적으로 병합(elastic merge)해 개인화를 보존하는 방법이다. 기존 기법들과 달리 이론적 근거를 제시하고, 별도 메커니즘 없이 기존 로컬 모델을 활용해 성능 향상을 보인다.


<details>
  <summary>Details</summary>
Motivation: 연합 추천은 다수 디바이스의 로컬 모델을 모아 협업 학습을 수행해 개인화를 지원하지만, 클라이언트 간 이질성으로 인해 서버에서 집계된 전역 모델이 각 로컬 최적점에서 멀어져 개인화가 손상되는 문제가 존재한다(aggregation bottleneck). 이를 실험·이론적으로 규명하고 해결책을 제시할 필요가 있다.

Method: FedEM은 전역 모델과 각 클라이언트의 로컬 모델을 탄력적으로 병합하는 방식을 제안한다. 핵심은 별도의 복잡한 개인화 모듈을 설계하지 않고도, 기존에 학습된 로컬 모델들을 그대로 활용해 집계로 인한 개인화 저하를 보정하는 점이다. 또한 aggregation bottleneck 현상을 수학적·이론적으로 분석해 설계 근거를 제공한다.

Result: 실세계 데이터셋에서의 광범위한 실험에서 FedEM은 협업 학습 도중 클라이언트 개인화를 유지하며, 기존 최첨단 개인화 연합 추천 기법들보다 우수한 성능을 보였다.

Conclusion: FedEM은 집계로 인한 개인화 손실 문제를 이론·실험적으로 해결하고, 간단하면서도 효과적으로 개인화를 보존해 연합 추천의 실용성을 향상시킨 방법론이다.

Abstract: Federated recommendation (FR) facilitates collaborative training by
aggregating local models from massive devices, enabling client-specific
personalization while ensuring privacy. However, we empirically and
theoretically demonstrate that server-side aggregation can undermine
client-side personalization, leading to suboptimal performance, which we term
the aggregation bottleneck. This issue stems from the inherent heterogeneity
across numerous clients in FR, which drives the globally aggregated model to
deviate from local optima. To this end, we propose FedEM, which elastically
merges the global and local models to compensate for impaired personalization.
Unlike existing personalized federated recommendation (pFR) methods, FedEM (1)
investigates the aggregation bottleneck in FR through theoretical insights,
rather than relying on heuristic analysis; (2) leverages off-the-shelf local
models rather than designing additional mechanisms to boost personalization.
Extensive experiments on real-world datasets demonstrate that our method
preserves client personalization during collaborative training, outperforming
state-of-the-art baselines.

</details>


### [295] [DIT: Dimension Reduction View on Optimal NFT Rarity Meters](https://arxiv.org/abs/2508.12671)
*Dmitry Belousov,Yury Yanovich*

Main category: cs.DC

TL;DR: 본 논문은 NFT 희소성(rarity)을 차원 축소 관점에서 설계·평가한 연구로, 비계량 가중 다차원척도법(non-metric weighted MDS)을 이용한 최적 희소성 미터와 DIT(Dissimilarity in Trades)라는 새로운 성능지표를 제안한다. ROAR 벤치마크에서 DIT 기반의 비해석적(black-box) 희소성 미터가 기존 방법보다 우수한 성능을 보였다.


<details>
  <summary>Details</summary>
Motivation: NFT의 가치가 희소성에 강하게 의존하나, 컬렉션 데이터 접근성 한계로 기존 희소성 미터 비교가 어렵다. 표준화된 평가(ROAR)가 필요하며, 차원 축소 기법을 통해 희소성 설계와 평가 지표를 개선하고자 함.

Method: 차원 축소 기반 설계: 항목 간 유사성/불유사성을 입력으로 비계량 가중 MDS를 사용하여 희소성 점수(차원 좌표)를 산출. 새로운 성능 지표 DIT는 실제 거래에서의 불유사성 분포를 기반으로 설계되어, 거래 패턴과 희소성 간의 정합성을 측정함. ROAR 벤치마크에서 여러 미터와 비교 평가 수행.

Result: DIT를 포함한 제안된 비해석적 미터가 ROAR 벤치마크에서 기존의 해석적/단순 지표들을 능가하는 것으로 보고됨. 특히 비계량 가중 MDS 기반 설계가 성능 최적화를 달성함.

Conclusion: 차원 축소 관점은 NFT 희소성 측정에 유용하며, DIT는 거래 행태와의 정합성을 잘 포착한다. 다만 비해석적 특성으로 해석 가능성 및 일반화, 견고성 검증이 필요하다.

Abstract: Non-fungible tokens (NFTs) have become a significant digital asset class,
each uniquely representing virtual entities such as artworks. These tokens are
stored in collections within smart contracts and are actively traded across
platforms on Ethereum, Bitcoin, and Solana blockchains. The value of NFTs is
closely tied to their distinctive characteristics that define rarity, leading
to a growing interest in quantifying rarity within both industry and academia.
While there are existing rarity meters for assessing NFT rarity, comparing them
can be challenging without direct access to the underlying collection data. The
Rating over all Rarities (ROAR) benchmark addresses this challenge by providing
a standardized framework for evaluating NFT rarity. This paper explores a
dimension reduction approach to rarity design, introducing new performance
measures and meters, and evaluates them using the ROAR benchmark. Our
contributions to the rarity meter design issue include developing an optimal
rarity meter design using non-metric weighted multidimensional scaling,
introducing Dissimilarity in Trades (DIT) as a performance measure inspired by
dimension reduction techniques, and unveiling the non-interpretable rarity
meter DIT, which demonstrates superior performance compared to existing
methods.

</details>


### [296] [Dissecting CPU-GPU Unified Physical Memory on AMD MI300A APUs](https://arxiv.org/abs/2508.12743)
*Jacob Wahlgren,Gabin Schieffer,Ruimin Shi,Edgar A. León,Roger Pearce,Maya Gokhale,Ivy Peng*

Main category: cs.DC

TL;DR: MI300A APU의 Unified Physical Memory(UPM)를 처음으로 종합적으로 분석하여 지연·대역폭·일관성 오버헤드와 시스템 소프트웨어(할당, 페이지 폴트, TLB, Infinity Cache)를 평가하고, 포팅 전략과 6개 애플리케이션 결과를 통해 통합 메모리 모델이 명시적 관리 모델과 대등하거나 우수하며 메모리 비용을 최대 44% 절감함을 보임.


<details>
  <summary>Details</summary>
Motivation: 디스크리트 GPU 환경에서의 복잡한 메모리 관리 문제를 완화하고자 도입된 UVM은 성능 저하가 크다. MI300A와 같은 APU가 UPM을 제공하므로, UPM의 실제 성능·오버헤드·소프트웨어 효율성을 실험적으로 규명할 필요가 있음.

Method: MI300A 하드웨어에서 마이크로벤치마크(지연·대역폭·일관성 측정), 시스템 소프트웨어 평가(메모리 할당, 페이지 폴트, TLB, Infinity Cache 활용도), 포팅 전략 제안 및 6개 실제 애플리케이션의 성능·메모리 사용량 비교 실험.

Result: UPM의 메모리 모델은 지연·대역폭·일관성 측면에서 특정 오버헤드가 있으나, 소프트웨어·포팅 전략을 통해 통합 메모리 모델이 명시적 관리 모델과 동등하거나 더 나은 성능을 보였고, 메모리 사용량을 최대 44%까지 줄여줌.

Conclusion: MI300A 기반 UPM은 적절한 소프트웨어 최적화와 포팅을 통해 성능 손실 없이 메모리 관리 비용을 크게 줄일 수 있어 HPC/데이터센터 애플리케이션에 실질적 이점이 있음.

Abstract: Discrete GPUs are a cornerstone of HPC and data center systems, requiring
management of separate CPU and GPU memory spaces. Unified Virtual Memory (UVM)
has been proposed to ease the burden of memory management; however, at a high
cost in performance. The recent introduction of AMD's MI300A Accelerated
Processing Units (APUs)--as deployed in the El Capitan supercomputer--enables
HPC systems featuring integrated CPU and GPU with Unified Physical Memory (UPM)
for the first time. This work presents the first comprehensive characterization
of the UPM architecture on MI300A. We first analyze the UPM system properties,
including memory latency, bandwidth, and coherence overhead. We then assess the
efficiency of the system software in memory allocation, page fault handling,
TLB management, and Infinity Cache utilization. We propose a set of porting
strategies for transforming applications for the UPM architecture and evaluate
six applications on the MI300A APU. Our results show that applications on UPM
using the unified memory model can match or outperform those in the explicitly
managed model--while reducing memory costs by up to 44%.

</details>


### [297] [Accelerating Edge Inference for Distributed MoE Models with Latency-Optimized Expert Placement](https://arxiv.org/abs/2508.12851)
*Tian Wu,Liming Wang,Zijian Wen,Xiaoxi Zhang,Jingpu Duan,Xianwei Zhang,Jinhang Zuo*

Main category: cs.DC

TL;DR: DanceMoE는 이종 GPU 엣지 서버들에서 MoE 전문가(expert)를 활성화 빈도(activation) 기반으로 배치해 서버 간 통신을 줄이고 추론 지연을 낮추는 협업형 MoE 추론 프레임워크이다. 평가 결과 최대 30.6%의 추론 지연 감소와 통신량 대폭 절감 효과를 보였다.


<details>
  <summary>Details</summary>
Motivation: MoE는 모델 용량 대비 효율성이 높지만, 엣지 환경에서는 큰 메모리 요구와 복잡한 서버 간 통신 때문에 배포·서빙이 어렵다. 중앙화된 클라우드 서빙은 비용·지연·프라이버시 문제를 낳으므로, 이종 엣지 장치들의 협업을 통해 MoE를 효율적으로 서빙하는 방법이 필요하다.

Method: 전문가 활성화의 희소성과 작업 부하의 지역성(locality)을 이용하는 데이터 기반의 활성화-인식(activation-aware) 전문가 배치 알고리즘을 제안한다. 알고리즘은 서버별 로컬 커버리지(해당 서버에서 처리 가능한 토큰 비율)와 메모리 사용을 균형 있게 최적화하고, 변화하는 워크로드에 적응하기 위한 경량 마이그레이션 메커니즘을 포함한다.

Result: 현대 MoE 모델과 표준 데이터셋에서 평가했을 때 기존 최첨단 방법들보다 최대 30.6% 낮은 추론 지연과 상당한 통신 감소를 달성했다.

Conclusion: DanceMoE는 엣지 환경에서 MoE 추론의 실용적 대안을 제시하며, 활성화-인식 배치와 경량 마이그레이션을 통해 지연·통신·메모리 제약을 완화할 수 있음을 보였다.

Abstract: Mixture-of-Experts (MoE) have become a cornerstone for training and scaling
large language models (LLMs), offering substantial gains in model capacity and
efficiency through sparse expert activation. However, serving these models
remains challenging in practice, particularly in resource-constrained edge
environments, due to their large memory footprint and complex communication
demands. While centralized cloud inference is common, it incurs high
infrastructure costs, along with latency and privacy concerns. A few recent
edge MoE works propose memory-efficient strategies but typically focus on
single-device or homogeneous setups. This paper presents DanceMoE, an efficient
MoE inference framework that enables activation-aware expert placement across
collaborative, heterogeneous, GPU-equipped edge servers. DanceMoE leverages the
inherent sparsity of MoE models and workload locality to minimize cross-server
communication and enable efficient expert placement under heterogeneous
resource constraints. It introduces a data-driven, activation-aware placement
algorithm that balances local coverage and memory usage across servers,
alongside a lightweight migration mechanism that adapts expert assignments
under evolving workloads. We evaluate DanceMoE on modern MoE models and widely
used datasets, demonstrating up to 30.6\% lower inference latency, and
substantial communication reduction compared to state-of-the-art baselines,
showcasing the effectiveness of collaborative edge-based MoE inference.

</details>


### [298] [WANify: Gauging and Balancing Runtime WAN Bandwidth for Geo-distributed Data Analytics](https://arxiv.org/abs/2508.12961)
*Anshuman Das Mohapatra,Kwangsung Oh*

Main category: cs.DC

TL;DR: WANify는 런타임에 달성 가능한 WAN 대역폭을 머신러닝(의사결정나무 기반 Random Forest)으로 예측하고, 예측값을 바탕으로 데이터센터 간 전송에 사용할 이종 병렬 연결 수를 최적화해 GDA 시스템의 지연과 비용을 줄이는 프레임워크다. AWS 8개 DC 실험에서 처리량 개선과 함께 최대 26% 지연 감소·16% 비용 절감 효과를 보였다.


<details>
  <summary>Details</summary>
Motivation: 기존 GDA 시스템은 DC 간 WAN 대역폭을 정적·독립적으로 측정하거나 단일 연결 대역폭만 사용해, 동시·동적인 데이터 전송 상황과 장거리 링크의 실제 용량을 제대로 반영하지 못해 비최적의 배치·전송 결정을 유발한다.

Method: WANify는 런타임 상황(네트워크 상태·워크로드 등)을 특징으로 하는 입력으로 Random Forest를 학습·사용해 '달성 가능한' WAN 대역폭을 예측한다. 예측 결과를 이용해 서로 다른 품질의 링크들 사이에서 최적의 이종 병렬 연결 수를 결정하여 전송 성능을 극대화하고 모니터링 비용을 줄인다. 동적·이기종 환경(데이터 편중, 이기종 연산 자원, 가변 DC 수)을 고려하도록 설계되었다.

Result: AWS에서 8개 지리분산 DC로 구성한 프로토타입 평가 결과, WAN 링크들 간 균형을 맞춰 전체 WAN 처리량을 향상시켰고 GDA의 쿼리 지연과 비용을 각각 최대 26%·16%까지 감소시켰다. 모니터링 비용은 최소화되었고 실험에서 추가 비용 없이도 성능 향상이 가능함을 보였다.

Conclusion: 실시간 예측 기반의 연결 수 최적화로 기존의 정적 측정 한계를 극복하며, WANify는 GDA 시스템의 전송 결정 품질을 개선해 지연·비용을 실질적으로 낮춘다. 다만 평가 규모와 모델 유지(학습·재학습) 관련 세부가 추가 검증될 필요가 있다.

Abstract: Accurate wide area network (WAN) bandwidth (BW) is essential for
geo-distributed data analytics (GDA) systems to make optimal decisions such as
data and task placement to improve performance. Existing GDA systems, however,
measure WAN BW statically and independently between data centers (DCs), while
data transfer occurs dynamically and simultaneously among DCs during workload
execution. Also, they use a single connection WAN BW that cannot capture actual
WAN capacities between distant DCs. Such inaccurate WAN BWs yield sub-optimal
decisions, inflating overall query latency and cost. In this paper, we present
WANify, a new framework that precisely and dynamically gauges achievable
runtime WAN BW using a machine learning prediction scheme, decision tree-based
Random Forest. This helps GDA systems make better decisions yielding reduced
latency and costs including WAN BW monitoring costs. Based on predicted runtime
WAN BW, WANify determines the optimal number of heterogeneous parallel
connections for data transfer among DCs. This approach improves performance
without additional, or even at reduced cost, by fully exploiting available WAN
capacities. In addition, WANify considers dynamics like network and workloads,
and heterogeneity like skewed data, heterogeneous compute resources, and a
varying number of DCs while making decisions. The WANify prototype running on
state-of-the-art GDA systems is evaluated on AWS with 8 geo-distributed DCs.
Results show that WANify enhances WAN throughput by balancing between the
strongest and weakest WAN links, enabling GDA systems to reduce latency and
cost by up to 26% and 16% respectively with minimal effort, all while handling
dynamics and heterogeneity efficiently.

</details>


### [299] [Congested Clique Counting for Local Gibbs Distributions](https://arxiv.org/abs/2508.13083)
*Joshua Z. Sobel*

Main category: cs.DC

TL;DR: 저자들은 샘플링-계수(reduction)를 이용해 CongestedClique 분산모델에서 처음으로 근사 계수(approximate counting) 알고리즘들을 제시한다. 특히 그래프의 q-색칠 개수를 ε-오차(곱셈)로 근사하는 알고리즘을 q>αΔ (임의의 상수 α>2)일 때 Õ(n^{1/3}/ε^2) 라운드에 달성한다. 일반적으로 국소성(locality)과 빠른 혼합(fast mixing)을 만족하는 Gibbs 분포의 분할함수(partition function)도 같은 복잡도로 근사할 수 있고, 하드코어 모델(가중 독립집합)에서는 λ ≤ α/(Δ−1), α<1 일 때 Õ(1/ε^2) 라운드로 더 빠르게 실행된다. 핵심 기법은 분산 마르코프 체인에서 병렬로 n개의 샘플을 추출하는 새로운 방법으로, 삼각형 계산과 세미링 행렬곱 아이디어를 차용한다.


<details>
  <summary>Details</summary>
Motivation: 전통적으로 샘플링과 계수 문제는 서로 환원되어 왔으나(고전적 결과들), 분산 컴퓨팅 특히 CongestedClique 모델에서는 효율적 근사 계수 알고리즘이 거의 없었다. 대규모 네트워크나 병렬환경에서 Gibbs 분포나 색칠/독립집합 같은 확률적 모델의 분할함수를 빠르게 근사할 필요성에서 출발한다.

Method: 최근의 병렬 알고리즘(like Liu, Yin, Zhang)을 기반으로, 샘플링⇄계수 환원을 활용해 분산 환경에서 다수(Θ(n))의 독립 샘플을 병렬 생성한다. 이 과정에서 통신-패턴과 작업 분할을 삼각형 수/세미링 행렬곱 접근법과 유사하게 설계해 CongestedClique의 통신제약 하에서 효율을 얻는다. 또한 샘플링의 정확성과 시간 복잡도를 보장하기 위해 그래프의 국소성 및 마르코프 체인의 빠른 혼합 조건을 가정한다.

Result: q>αΔ(α>2)인 경우 그래프의 q-색칠 개수 근사를 Õ(n^{1/3}/ε^2) 라운드에 달성. 일반적인 Gibbs 분포(국소성+빠른 혼합)도 같은 복잡도로 분할함수 근사 가능. 하드코어 모델은 λ ≤ α/(Δ−1)(α<1)일 때 Õ(1/ε^2) 라운드로 더 빠름. 이 알고리즘은 또한 분산 환경에서 대량 샘플링이 필요한 다른 응용에도 유용할 수 있다.

Conclusion: 분산 CongestedClique 모델에서 다양한 조합론적/통계적 계수 문제들에 대한 첫 근사 계수 알고리즘을 제시하며, 특히 색칠과 하드코어 모델에서 의미 있는 시간-절약을 보인다. 제안된 병렬 샘플링 기법은 범용성이 있어 다른 분산 샘플링 응용으로 확장 가능하다.

Abstract: There are well established reductions between combinatorial sampling and
counting problems (Jerrum, Valiant, Vazirani TCS 1986). Building off of a very
recent parallel algorithm utilizing this connection (Liu, Yin, Zhang arxiv
2024), we demonstrate the first approximate counting algorithm in the
CongestedClique for a wide range of problems. Most interestingly, we present an
algorithm for approximating the number of $q$-colorings of a graph within
$\epsilon$-multiplicative error, when $q>\alpha\Delta$ for any constant
$\alpha>2$, in $\Tilde{O}\big(\frac{n^{1/3}}{\epsilon^2}\big)$ rounds. More
generally, we achieve a runtime of
$\Tilde{O}\big(\frac{n^{1/3}}{\epsilon^2}\big)$ rounds for approximating the
partition function of Gibbs distributions defined over graphs when simple
locality and fast mixing conditions hold. Gibbs distributions are widely used
in fields such as machine learning and statistical physics. We obtain our
result by providing an algorithm to draw $n$ random samples from a distributed
Markov chain in parallel, using similar ideas to triangle counting (Dolev,
Lenzen, Peled DISC 2012) and semiring matrix multiplication (Censor-Hillel,
Kaski, Korhonen, Lenzen, Paz, Suomela PODC 2015). Aside from counting problems,
this result may be interesting for other applications requiring a large number
of samples. In the special case of estimating the partition function of the
hardcore model, also known as counting weighted independent sets, we can do
even better and achieve an $\Tilde{O}\big(\frac{1}{\epsilon^2}\big)$ round
algorithm, when the fugacity $\lambda \leq \frac{\alpha}{\Delta-1}$, where
$\alpha$ is an arbitrary constant less than $1$.

</details>


### [300] [Team Formation and Applications](https://arxiv.org/abs/2508.13084)
*Yuval Emek,Shay Kutten,Ido Rafael,Gadi Taubenfeld*

Main category: cs.DC

TL;DR: Introduces Team Formation (TF), a new long-lived distributed problem in asynchronous complete networks with bounded messages and some initially failed nodes; gives a randomized, message- and time-efficient algorithm and proves a tight message lower bound. Shows TF reduces many distributed tasks (leader election variants, threshold detection, matching, quorum sensing, etc.), improving several complexities.


<details>
  <summary>Details</summary>
Motivation: Provide a reusable primitive for assembling tokens into fixed-size groups in adversarial asynchronous settings, enabling efficient solutions to a variety of one-shot and long-lived distributed problems and breaking known complexity barriers.

Method: Define TF formally (tokens, teams of size σ) in an asynchronous complete-graph model with generalized initial failures; design a randomized algorithm optimized for message and time complexity under bounded-size messages; reduce multiple distributed problems to TF to obtain algorithms for them.

Result: A message- and time-efficient randomized TF algorithm; reductions showing many problems (implicit/explicit leader election, threshold detection, matching, gathering variants, quorum sensing, etc.) can be solved via TF; first sub-linear message complexity for asynchronous implicit leader election and improved time for message-optimal explicit leader election; a matching (tight) lower bound on TF message complexity.

Conclusion: TF is a powerful long-lived primitive that yields improved algorithms across many distributed problems and is accompanied by provable optimality (tight lower bound) for message complexity.

Abstract: A novel long-lived distributed problem, called Team Formation (TF), is
introduced together with a message- and time-efficient randomized algorithm.
The problem is defined over the asynchronous model with a complete
communication graph, using bounded size messages, where a certain fraction of
the nodes may experience a generalized, strictly stronger, version of initial
failures. The goal of a TF algorithm is to assemble tokens injected by the
environment, in a distributed manner, into teams of size $\sigma$, where
$\sigma$ is a parameter of the problem.
  The usefulness of TF is demonstrated by using it to derive efficient
algorithms for many distributed problems. Specifically, we show that various
(one-shot as well as long-lived) distributed problems reduce to TF. This
includes well-known (and extensively studied) distributed problems such as
several versions of leader election and threshold detection. For example, we
are the first to break the linear message complexity bound for asynchronous
implicit leader election. We also improve the time complexity of
message-optimal algorithms for asynchronous explicit leader election. Other
distributed problems that reduce to TF are new ones, including matching players
in online gaming platforms, a generalization of gathering, constructing a
perfect matching in an induced subgraph of the complete graph, quorum sensing
in message-passing networks, and more. To complement our positive contribution,
we establish a tight lower bound on the message complexity of TF algorithms.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [301] [Centralized Permutation Equivariant Policy for Cooperative Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2508.11706)
*Zhuofan Xu,Benedikt Bollig,Matthias Függer,Thomas Nowak,Vincent Le Dréau*

Main category: cs.MA

TL;DR: 완전 중앙집중 정책(centralized execution)을 허용하는 새로운 CTDE 방식인 Centralized Permutation Equivariant(CPE)를 제안한다. GLPE라는 경량의 순열 등변(permutation equivariant) 네트워크를 사용해 확장성과 성능을 개선하며, 여러 표준 협력 마르코프 환경(MPE, SMAC, RWARE)에서 기존 CTDE 방법들보다 성능을 크게 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: CTDE는 중앙집중 학습과 분산 실행의 장점을 취하려 하지만, 분산 정책은 부분 관측 때문에 성능이 중앙집중 정책보다 낮고, 완전 중앙집중 접근은 에이전트 수 증가에 따라 확장성 문제가 생긴다. 이를 해결할 방법이 필요하다.

Method: 완전 중앙집중 정책을 채택하되, 입력 에이전트들의 순서에 불변한 구조를 보장하는 Global-Local Permutation Equivariant(GLPE) 네트워크를 설계한다. GLPE는 경량·확장형이며 값 분해(value decomposition) 및 액터-크리틱(actor-critic) 계열 알고리즘과 쉽게 통합된다.

Result: MPE, SMAC, RWARE 등의 협력 벤치마크에서 표준 CTDE 알고리즘 성능을 크게 향상시키고, RWARE에서는 최신 기법들과 동등한 성능을 달성했다.

Conclusion: CPE는 GLPE 아키텍처를 통해 중앙집중 정책의 성능을 유지하면서 확장성과 구현 용이성을 확보해 CTDE 계열 방법들을 실질적으로 개선한다.

Abstract: The Centralized Training with Decentralized Execution (CTDE) paradigm has
gained significant attention in multi-agent reinforcement learning (MARL) and
is the foundation of many recent algorithms. However, decentralized policies
operate under partial observability and often yield suboptimal performance
compared to centralized policies, while fully centralized approaches typically
face scalability challenges as the number of agents increases.
  We propose Centralized Permutation Equivariant (CPE) learning, a centralized
training and execution framework that employs a fully centralized policy to
overcome these limitations. Our approach leverages a novel permutation
equivariant architecture, Global-Local Permutation Equivariant (GLPE) networks,
that is lightweight, scalable, and easy to implement. Experiments show that CPE
integrates seamlessly with both value decomposition and actor-critic methods,
substantially improving the performance of standard CTDE algorithms across
cooperative benchmarks including MPE, SMAC, and RWARE, and matching the
performance of state-of-the-art RWARE implementations.

</details>


### [302] [SafeSieve: From Heuristics to Experience in Progressive Pruning for LLM-based Multi-Agent Communication](https://arxiv.org/abs/2508.11733)
*Ruijia Zhang,Xinyan Zhao,Ruixiang Wang,Sigen Chen,Guibin Zhang,An Zhang,Kun Wang,Qingsong Wen*

Main category: cs.MA

TL;DR: SafeSieve는 LLM 기반 다중 에이전트 시스템의 통신을 점진적·적응적으로 가지치기하여 토큰 사용량을 줄이고 성능을 유지하는 알고리즘이다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 협업은 강력하지만 불필요한 통신과 높은 토큰 오버헤드가 문제이다. 기존 방법들은 사전학습된 GNN이나 그리디 방식으로 효율을 높이지만 초기화와 경험 기반 최적화를 분리해 통합 전략이 부족하다.

Method: SafeSieve는 초기 LLM 기반 의미 평가와 누적 성능 피드백을 결합한 이중 메커니즘을 사용해 휴리스틱 초기화에서 경험 기반 정제로 부드럽게 전환한다. 또한 greedy Top-k가 아닌 0-extension 군집화를 채택해 구조적으로 일관된 에이전트 그룹을 보존하면서 비효율적 연결을 제거한다.

Result: SVAMP, HumanEval 등 벤치마크에서 평균 정확도 94.01%를 달성하고 토큰 사용량을 12.4%–27.8% 절감했다. 프롬프트 주입 공격에 대해 평균 정확도 감소가 1.23%로 견고성을 보였고, 이종 환경에서 배포 비용을 13.3% 절감하면서 성능 유지했다.

Conclusion: SafeSieve는 실용적 다중 에이전트 시스템을 위한 견고하고 효율적이며 확장 가능한 통신 가지치기 프레임워크로 제시된다.

Abstract: LLM-based multi-agent systems exhibit strong collaborative capabilities but
often suffer from redundant communication and excessive token overhead.
Existing methods typically enhance efficiency through pretrained GNNs or greedy
algorithms, but often isolate pre- and post-task optimization, lacking a
unified strategy. To this end, we present SafeSieve, a progressive and adaptive
multi-agent pruning algorithm that dynamically refines the inter-agent
communication through a novel dual-mechanism. SafeSieve integrates initial
LLM-based semantic evaluation with accumulated performance feedback, enabling a
smooth transition from heuristic initialization to experience-driven
refinement. Unlike existing greedy Top-k pruning methods, SafeSieve employs
0-extension clustering to preserve structurally coherent agent groups while
eliminating ineffective links. Experiments across benchmarks (SVAMP, HumanEval,
etc.) showcase that SafeSieve achieves 94.01% average accuracy while reducing
token usage by 12.4%-27.8%. Results further demonstrate robustness under prompt
injection attacks (1.23% average accuracy drop). In heterogeneous settings,
SafeSieve reduces deployment costs by 13.3% while maintaining performance.
These results establish SafeSieve as a robust, efficient, and scalable
framework for practical multi-agent systems. Our code can be found in
https://anonymous.4open.science/r/SafeSieve-D8F2FFUN.

</details>


### [303] [A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond](https://arxiv.org/abs/2508.11957)
*Xiaodong Qu,Andrews Damoah,Joshua Sherwood,Peiyan Liu,Christian Shun Jin,Lulu Chen,Minjie Shen,Nawwaf Aleisa,Zeyuan Hou,Chenyu Zhang,Lifu Gao,Yanshu Li,Qikai Yang,Qun Wang,Cristabelle De Souza*

Main category: cs.MA

TL;DR: 이 리뷰는 현대 AI 에이전트의 아키텍처, 핵심 구성요소, 그리고 인지과학 기반 모델·계층적 강화학습·대형언어모델(LLM) 기반 추론 등 최신 패러다임을 체계적으로 정리하고 윤리·안전·해석성 문제를 논의하여 향후 연구 방향을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 데이터 증가와 딥러닝·강화학습·멀티에이전트 협업의 발전에도 불구하고 인지, 계획, 상호작용을 원활히 통합하는 통합형 AI 에이전트 설계·배포는 여전히 해결되지 않은 과제로 남아 있어 이를 종합적으로 검토할 필요가 있다.

Method: 문헌 기반의 체계적 리뷰로서 아키텍처 원칙과 핵심 구성요소(지각·추론·계획·행동·학습·협동)를 분류·비교하고, 인지과학 영감 모델, 계층적 강화학습, LLM 기반 접근법의 장단점을 통합 분석한다. 또한 윤리·안전·해석성 쟁점을 식별하고 연구 과제를 제안한다.

Result: 주요 결과로는(1) 다양한 패러다임들이 상호보완적이며 결합 가능성이 높음(예: LLM의 고수준 추론 + 계층적 RL의 실행),(2) 통합 아키텍처 설계와 인터페이스 표준화의 필요성,(3) 실제 배치에서의 안전·해석성·윤리 문제들이 주요 장벽임을 확인했음.

Conclusion: 향후 연구는 다층적·모듈화된 아키텍처, 모듈 간 명확한 인터페이스, 안전성과 해석 가능성을 내재화한 설계, 그리고 멀티에이전트 상호작용의 견고성 확보에 초점을 맞춰야 한다.

Abstract: Artificial Intelligence (AI) agents have rapidly evolved from specialized,
rule-based programs to versatile, learning-driven autonomous systems capable of
perception, reasoning, and action in complex environments. The explosion of
data, advances in deep learning, reinforcement learning, and multi-agent
coordination have accelerated this transformation. Yet, designing and deploying
unified AI agents that seamlessly integrate cognition, planning, and
interaction remains a grand challenge. In this review, we systematically
examine the architectural principles, foundational components, and emergent
paradigms that define the landscape of contemporary AI agents. We synthesize
insights from cognitive science-inspired models, hierarchical reinforcement
learning frameworks, and large language model-based reasoning. Moreover, we
discuss the pressing ethical, safety, and interpretability concerns associated
with deploying these agents in real-world scenarios. By highlighting major
breakthroughs, persistent challenges, and promising research directions, this
review aims to guide the next generation of AI agent systems toward more
robust, adaptable, and trustworthy autonomous intelligence.

</details>


### [304] [Synchronization Dynamics of Heterogeneous, Collaborative Multi-Agent AI Systems](https://arxiv.org/abs/2508.12314)
*Chiranjit Mitra*

Main category: cs.MA

TL;DR: 동적 진동자(위상+진폭) 기반의 Kuramoto 유사 모델로 이기종 AI 에이전트의 협동·동기화를 수학적으로 모델링하고, Chain-of-Thought(사고사슬)를 동기화 현상과 대응시켜 네트워크 토폴로지·결합강도·에이전트 다양성이 집단지능에 미치는 영향을 분석한 물리학 기반 다중 에이전트 프레임워크.


<details>
  <summary>Details</summary>
Motivation: 대규모·이기종 에이전트들이 협업하는 현대 AI 시스템에서 집단 행동의 원리(안정성, 효율성, 해석 가능성)를 이해하고 설계하려는 필요성. 물리학의 동기화 이론을 차용해 엄밀한 수학적 도구로 다중 에이전트 상호작용을 분석하고 Chain-of-Thought 같은 인간유사 추론 과정과의 연결을 통해 해석가능한 협업 메커니즘을 제시하려 함.

Method: 에이전트를 위상과 진폭을 갖는 결합 진동자로 모델링(확장된 Kuramoto/phase–amplitude 모델). 전체 조정 수준을 측정하는 오더 파라미터 도입. 결합강도, 에이전트 이질성(자연주파수·응답성 차이), 네트워크 토폴로지(전결합·결정적 스케일프리) 변수를 조작한 수치 시뮬레이션 수행. Chain-of-Thought 절차를 동기화 과정(반복적 상호작용·정보 확산)으로 대응시켜 이론적 연결 고리 제시.

Result: 시뮬레이션에서 결합강도 증가가 이기종 에이전트 간의 강건한 동기화를 촉진했으며, 네트워크 구조와 에이전트 다양성이 오더 파라미터 및 수렴속도에 큰 영향을 미침. 제안 모델이 협업 AI의 집단적 추론·안정성·해석 가능성 분석에 실용적 통찰을 제공함을 보였음.

Conclusion: 물리 기반의 정교한 수학적 틀을 통해 다중 에이전트 AI 시스템의 설계·분석·최적화 가능성을 제시. 추후 학습 동역학, 적응형 네트워크, 실세계 에이전트 실험 등을 통합해 시스템 탄력성·효율성을 더 향상시키는 연구로 확장할 수 있음을 시사.

Abstract: We present a novel interdisciplinary framework that bridges synchronization
theory and multi-agent AI systems by adapting the Kuramoto model to describe
the collective dynamics of heterogeneous AI agents engaged in complex task
execution. By representing AI agents as coupled oscillators with both phase and
amplitude dynamics, our model captures essential aspects of agent
specialization, influence, and communication within networked systems. We
introduce an order parameter to quantify the degree of coordination and
synchronization, providing insights into how coupling strength, agent
diversity, and network topology impact emergent collective behavior.
Furthermore, we formalize a detailed correspondence between Chain-of-Thought
prompting in AI reasoning and synchronization phenomena, unifying human-like
iterative problem solving with emergent group intelligence. Through extensive
simulations on all-to-all and deterministic scale-free networks, we demonstrate
that increased coupling promotes robust synchronization despite heterogeneous
agent capabilities, reflecting realistic collaborative AI scenarios. Our
physics-informed approach establishes a rigorous mathematical foundation for
designing, analyzing, and optimizing scalable, adaptive, and interpretable
multi-agent AI systems. This work opens pathways for principled orchestration
of agentic AI and lays the groundwork for future incorporation of learning
dynamics and adaptive network architectures to further enhance system
resilience and efficiency.

</details>


### [305] [A Taxonomy of Hierarchical Multi-Agent Systems: Design Patterns, Coordination Mechanisms, and Industrial Applications](https://arxiv.org/abs/2508.12683)
*David J. Moore*

Main category: cs.MA

TL;DR: A five-axis taxonomy for Hierarchical Multi-Agent Systems (HMAS) that links structural, temporal, and communication design choices to concrete coordination mechanisms and industrial examples, highlighting trade-offs and open challenges (explainability, scaling, safe LLM integration).


<details>
  <summary>Details</summary>
Motivation: HMAS simplify coordination and scaling but introduce non-obvious trade-offs; practitioners need a comparative lens to design and evaluate hierarchical agent architectures across multiple interacting dimensions.

Method: Proposes a multi-dimensional taxonomy along five axes—control hierarchy, information flow, role/task delegation, temporal layering, communication structure—and ties each axis to coordination mechanisms (e.g., contract-net, hierarchical RL) and industrial case studies (power grids, oilfield operations).

Result: A unified framework that maps design choices to coordination mechanisms and illustrates how hierarchical structures can balance global efficiency with local autonomy in real-world domains, while exposing delicate trade-offs.

Conclusion: Presents the first unified taxonomy combining structural, temporal, and communication dimensions for HMAS, and identifies open problems: explainability to humans, scaling to very large agent sets, and safely integrating learning-based agents (e.g., LLMs).

Abstract: Hierarchical multi-agent systems (HMAS) organize collections of agents into
layered structures that help manage complexity and scale. These hierarchies can
simplify coordination, but they also can introduce trade-offs that are not
always obvious. This paper proposes a multi-dimensional taxonomy for HMAS along
five axes: control hierarchy, information flow, role and task delegation,
temporal layering, and communication structure. The intent is not to prescribe
a single "best" design but to provide a lens for comparing different
approaches.
  Rather than treating these dimensions in isolation, the taxonomy is connected
to concrete coordination mechanisms - from the long-standing contract-net
protocol for task allocation to more recent work in hierarchical reinforcement
learning. Industrial contexts illustrate the framework, including power grids
and oilfield operations, where agents at production, maintenance, and supply
levels coordinate to diagnose well issues or balance energy demand. These cases
suggest that hierarchical structures may achieve global efficiency while
preserving local autonomy, though the balance is delicate.
  The paper closes by identifying open challenges: making hierarchical
decisions explainable to human operators, scaling to very large agent
populations, and assessing whether learning-based agents such as large language
models can be safely integrated into layered frameworks. This paper presents
what appears to be the first taxonomy that unifies structural, temporal, and
communication dimensions of hierarchical MAS into a single design framework,
bridging classical coordination mechanisms with modern reinforcement learning
and large language model agents.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [306] [RRRA: Resampling and Reranking through a Retriever Adapter](https://arxiv.org/abs/2508.11670)
*Bongsu Kim*

Main category: cs.IR

TL;DR: 학습 중 하드 네거티브가 실제로는 정답(거짓 네거티브)일 확률을 Bi-Encoder 표현을 통해 학습 가능한 어댑터로 추정해, 재샘플링과 재랭킹에 활용하여 성능을 높임.


<details>
  <summary>Details</summary>
Motivation: 기존의 전역적 휴리스틱은 예시별(쿼리별) 거짓 네거티브를 놓치기 쉽고, 이로 인해 밀집 검색 학습이 손상될 수 있음.

Method: Bi-Encoder 표현을 모니터링하는 경량의 학습 가능한 어댑터로 각 하드 네거티브가 거짓 네거티브일 확률을 동적·문맥적으로 추정한다. 예측 확률은 (1) 학습 시 네거티브 재가중(재샘플링)과 (2) 추론 시 상위 k 문서의 재랭킹에 사용된다.

Result: 표준 벤치마크에서 강한 Bi-Encoder 기준 모델들을 지속적으로 능가하며, 거짓 네거티브 명시적 모델링의 이점을 보임.

Conclusion: 쿼리 특이적 거짓 네거티브 확률을 모델링하면 밀집 검색의 학습과 추론 성능이 개선된다.

Abstract: In dense retrieval, effective training hinges on selecting high quality hard
negatives while avoiding false negatives. Recent methods apply heuristics based
on positive document scores to identify hard negatives, improving both
performance and interpretability. However, these global, example agnostic
strategies often miss instance specific false negatives. To address this, we
propose a learnable adapter module that monitors Bi-Encoder representations to
estimate the likelihood that a hard negative is actually a false negative. This
probability is modeled dynamically and contextually, enabling fine-grained,
query specific judgments. The predicted scores are used in two downstream
components: (1) resampling, where negatives are reweighted during training, and
(2) reranking, where top-k retrieved documents are reordered at inference.
Empirical results on standard benchmarks show that our adapter-enhanced
framework consistently outperforms strong Bi-Encoder baselines, underscoring
the benefit of explicit false negative modeling in dense retrieval.

</details>


### [307] [LLM-Based Intelligent Agents for Music Recommendation: A Comparison with Classical Content-Based Filtering](https://arxiv.org/abs/2508.11671)
*Ronald Carvalho Boadana,Ademir Guimarães da Costa Junior,Ricardo Rios,Fábio Santos da Silva*

Main category: cs.IR

TL;DR: Gemini·LLaMA 계열 LLM과 지능형 에이전트를 결합한 다중 에이전트 개인화 음악 추천 시스템이 전통적 콘텐츠 기반 추천과 비교되어, 사용자 만족도(최대 89.32%) 등에서 유망한 성과를 보였음.


<details>
  <summary>Details</summary>
Motivation: 스트리밍 플랫폼의 음악 양적 폭증으로 사용자가 정보 과부하를 겪음. 보다 정교한 개인화·설명 가능 추천이 필요하며, LLM의 이해·추론 능력을 추천 문제에 적용해 사용자 만족과 신선도를 개선하려는 목적.

Method: Gemini 및 LLaMA 계열 LLM을 활용한 다중 에이전트 아키텍처를 설계·구현. 전통적 콘텐츠 기반 추천 모델과 비교 실험을 수행. 평가 지표로 사용자 만족도, 신선도(새로움), 계산 효율성 등을 사용(추가 세부는 초록에 없음).

Result: LLM 기반 접근법이 최대 89.32%의 사용자 만족도를 달성하며 유망한 성능을 보임(신선도 및 효율성 비교 결과는 초록에선 요약됨).

Conclusion: LLM과 에이전트 조합은 개인화 음악 추천에 실질적 잠재력을 지님. 그러나 계산 비용·평가 방법·재현성 등 추가 검증과 최적화가 필요.

Abstract: The growing availability of music on streaming platforms has led to
information overload for users. To address this issue and enhance the user
experience, increasingly sophisticated recommendation systems have been
proposed. This work investigates the use of Large Language Models (LLMs) from
the Gemini and LLaMA families, combined with intelligent agents, in a
multi-agent personalized music recommendation system. The results are compared
with a traditional content-based recommendation model, considering user
satisfaction, novelty, and computational efficiency. LLMs achieved satisfaction
rates of up to \textit{89{,}32\%}, indicating their promising potential in
music recommendation systems.

</details>


### [308] [Ontology-Guided Query Expansion for Biomedical Document Retrieval using Large Language Models](https://arxiv.org/abs/2508.11784)
*Zabir Al Nazi,Vagelis Hristidis,Aaron Lawson McLean,Jannat Ara Meem,Md Taukir Azam Chowdhury*

Main category: cs.IR

TL;DR: BMQExpander는 UMLS 온톨로지 지식(정의·관계)과 LLM 기반 생성 기법을 결합한 온톨로지 인식 질의 확장 파이프라인으로, 생의학 문서 검색에서 NDCG@10 등 지표를 크게 향상시키고(최대 +22.1% vs sparse), 쿼리 변형에 대해 안정적으로 일반화하며(최대 +15.7% vs 강력한 베이스라인), 환각(hallucination)도 적다고 주장한다.


<details>
  <summary>Details</summary>
Motivation: 생의학 영역에서는 전문 용어와 쿼리의 의미적 모호성 때문에 문서 검색이 어렵다. 기존 sparse/dense/확장 기법들 및 생의학 특화 솔루션이 있지만, 온톨로지 지식과 LLM의 생성 능력을 결합한 질의 확장이 효과적일지 검증할 필요가 있다.

Method: UMLS 메타시소러스를 통해 개념 정의와 관계를 추출하고, 이를 LLM으로 확장하여 질의를 재구성하는 파이프라인(BMQExpander)을 제안. 여러 베이스라인(희소·밀집 리트리버, 기존 질의 확장 방식, 생의학 특화 방법)과 비교하고, NFCorpus/TREC-COVID/SciFact 데이터셋에서 평가. 쿼리 변형(perturbation) 실험과 정성적 분석(환각 여부)도 수행.

Result: 세 벤치마크에서 최고 성능을 보였으며, 희소 베이스라인 대비 NDCG@10 최대 +22.1%, 가장 강력한 베이스라인 대비 최대 +6.5% 향상 보고. 쿼리 변형 상황에서 감독학습 베이스라인보다 견고하게 일반화하여 최대 +15.7% 개선. 패러프레이즈된 벤치마크 공개 및 정성분석에서 LLM 기반 다른 확장법보다 환각이 적음.

Conclusion: 온톨로지 기반 지식(정의·관계)을 LLM의 생성능력과 결합한 질의 확장이 생의학 문서 검색에서 실질적 이득을 주며, 특히 견고성과 신뢰성(환각 감소) 측면에서 우수하다.

Abstract: Effective Question Answering (QA) on large biomedical document collections
requires effective document retrieval techniques. The latter remains a
challenging task due to the domain-specific vocabulary and semantic ambiguity
in user queries. We propose BMQExpander, a novel ontology-aware query expansion
pipeline that combines medical knowledge - definitions and relationships - from
the UMLS Metathesaurus with the generative capabilities of large language
models (LLMs) to enhance retrieval effectiveness. We implemented several
state-of-the-art baselines, including sparse and dense retrievers, query
expansion methods, and biomedical-specific solutions. We show that BMQExpander
has superior retrieval performance on three popular biomedical Information
Retrieval (IR) benchmarks: NFCorpus, TREC-COVID, and SciFact - with
improvements of up to 22.1% in NDCG@10 over sparse baselines and up to 6.5%
over the strongest baseline. Further, BMQExpander generalizes robustly under
query perturbation settings, in contrast to supervised baselines, achieving up
to 15.7% improvement over the strongest baseline. As a side contribution, we
publish our paraphrased benchmarks. Finally, our qualitative analysis shows
that BMQExpander has fewer hallucinations compared to other LLM-based query
expansion baselines.

</details>


### [309] [TBGRecall: A Generative Retrieval Model for E-commerce Recommendation Scenarios](https://arxiv.org/abs/2508.11977)
*Zida Liang,Changfa Wu,Dunxian Huang,Weiqiang Sun,Ziyang Wang,Yuliang Yan,Jian Wu,Yuning Jiang,Bo Zheng,Ke Chen,Silu Zhou,Yu Zhang*

Main category: cs.IR

TL;DR: 제안된 TBGRecall은 세션 토큰 + 아이템 토큰으로 구성된 다중 세션 입력과 Next Session Prediction(NSP)을 도입해 생성형(autoregressive) 모델의 추천(검색) 성능을 개선한다. 제한적 히스토리 프리트레이닝과 확률적 부분 점진 학습으로 학습 효율을 높이고, 공개 벤치마크와 Taobao 대규모 산업 데이터에서 SOTA를 능가했다.


<details>
  <summary>Details</summary>
Motivation: 생성형 모델은 자동회귀적 생성 메커니즘 때문에 단일 요청에서 위치 제한 없이 여러 아이템을 효율적으로 검색·생성하기 어렵다. 시퀀스 종속성이 검색 작업에 비효율을 초래하므로 이를 해결할 방법이 필요하다.

Method: 입력 샘플을 다중 세션 시퀀스로 재구성(각 시퀀스 = 세션 토큰 + 아이템 토큰 집합)하고, NSP를 학습 목표로 채택한다. 생성형 검색에 맞춘 여러 최적화 기법을 추가하며, 학습은 제한된 역사 데이터로 프리트레이닝 후 확률적 부분 점진 학습(stochastic partial incremental training)을 통해 수행되어 최신성(데이터 신선도)을 우선시한다.

Result: 공개 벤치마크와 Taobao 산업 데이터에서 기존 추천 방법들을 능가하는 성능을 보였고, 모델 규모 및 데이터에 따른 스케일링 로우(성능 향상 추세)를 관찰했다.

Conclusion: NSP 기반 TBGRecall은 생성형 추천 모델의 검색 능력을 실질적으로 향상시키며, 효율적인 학습 파이프라인과 데이터 최신성 강조가 실무 적용에 유리함을 시사한다.

Abstract: Recommendation systems are essential tools in modern e-commerce, facilitating
personalized user experiences by suggesting relevant products. Recent
advancements in generative models have demonstrated potential in enhancing
recommendation systems; however, these models often exhibit limitations in
optimizing retrieval tasks, primarily due to their reliance on autoregressive
generation mechanisms. Conventional approaches introduce sequential
dependencies that impede efficient retrieval, as they are inherently unsuitable
for generating multiple items without positional constraints within a single
request session. To address these limitations, we propose TBGRecall, a
framework integrating Next Session Prediction (NSP), designed to enhance
generative retrieval models for e-commerce applications. Our framework
reformulation involves partitioning input samples into multi-session sequences,
where each sequence comprises a session token followed by a set of item tokens,
and then further incorporate multiple optimizations tailored to the generative
task in retrieval scenarios. In terms of training methodology, our pipeline
integrates limited historical data pre-training with stochastic partial
incremental training, significantly improving training efficiency and
emphasizing the superiority of data recency over sheer data volume. Our
extensive experiments, conducted on public benchmarks alongside a large-scale
industrial dataset from TaoBao, show TBGRecall outperforms the state-of-the-art
recommendation methods, and exhibits a clear scaling law trend. Ultimately, NSP
represents a significant advancement in the effectiveness of generative
recommendation systems for e-commerce applications.

</details>


### [310] [Leveraging Geometric Insights in Hyperbolic Triplet Loss for Improved Recommendations](https://arxiv.org/abs/2508.11978)
*Viacheslav Yusupov,Maxim Rakhuba,Evgeny Frolov*

Main category: cs.IR

TL;DR: Hyperbolic recommender that reformulates hyperbolic distance and uses a geometry-driven triplet loss to learn expressive user/item embeddings; it improves accuracy, stability, and reduces popularity bias vs. Euclidean and prior hyperbolic models.


<details>
  <summary>Details</summary>
Motivation: Euclidean embeddings struggle to capture complex hierarchical/relational patterns in interaction data and can suffer from instability; hyperbolic geometry can better represent such structures and potentially improve recommendation quality and diversity.

Method: Reformulates hyperbolic distances to increase representation capacity, constructs a triplet loss modeling ternary relations (user, preferred item, nonpreferred item) via mixed pairwise geometry-driven interaction terms, and trains hyperbolic user/item embeddings for recommendation.

Result: Empirically outperforms state-of-the-art Euclidean and hyperbolic baselines; shows improved computational stability and reduced popularity bias, yielding more diverse and personalized recommendations.

Conclusion: Geometry-aware reformulation and ternary triplet loss make hyperbolic embeddings more expressive and stable, improving accuracy and fairness-related metrics; suggests hyperbolic models are promising for recommender systems.

Abstract: Recent studies have demonstrated the potential of hyperbolic geometry for
capturing complex patterns from interaction data in recommender systems. In
this work, we introduce a novel hyperbolic recommendation model that uses
geometrical insights to improve representation learning and increase
computational stability at the same time. We reformulate the notion of
hyperbolic distances to unlock additional representation capacity over
conventional Euclidean space and learn more expressive user and item
representations. To better capture user-items interactions, we construct a
triplet loss that models ternary relations between users and their
corresponding preferred and nonpreferred choices through a mix of pairwise
interaction terms driven by the geometry of data. Our hyperbolic approach not
only outperforms existing Euclidean and hyperbolic models but also reduces
popularity bias, leading to more diverse and personalized recommendations.

</details>


### [311] [A Large-Scale Web Search Dataset for Federated Online Learning to Rank](https://arxiv.org/abs/2508.12353)
*Marcel Gregoriadis,Jingwei Kang,Johan Pouwelse*

Main category: cs.IR

TL;DR: AOL4FOLTR은 10,000명 사용자로부터 2.6M 쿼리·실제 클릭·타임스탬프를 포함한 대규모 웹검색 데이터셋으로, FOLTR(연합 온라인 학습투랭크) 연구에서 현실적인 사용자 분할·행동 모델링·비동기 참여 시나리오를 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: 중앙집중 로그 수집의 프라이버시 문제와 기존 FOLTR 벤치마크가 갖는 비현실적 가정(랜덤 분할, 시뮬레이티드 클릭, 동기적 참여)을 해소하여 실험 현실성을 높이기 위함.

Method: AOL 데이터셋을 가공해 사용자 식별자, 실제 클릭 레코드, 쿼리 타임스탬프를 보존하면서 10,000명·2.6M 쿼리 규모로 재구성하고, 현실적 파티셔닝·비동기 시나리오·행동 모델링을 지원하는 포맷으로 제공.

Result: 기존 합성·동기 기반 벤치보다 더 현실적인 사용자 분포, 클릭 패턴, 시간적 상관성을 제공하여 FOLTR 실험에서 동기성 가정과 데이터 분할 방식이 결과에 미치는 영향을 평가할 수 있게 함.

Conclusion: AOL4FOLTR은 FOLTR 연구의 현실성·재현성 향상 및 비동기·비동질성 연구를 촉진하나, AOL 원자료 특유의 편향·시대성·윤리적·프라이버시 이슈는 주의가 필요하다.

Abstract: The centralized collection of search interaction logs for training ranking
models raises significant privacy concerns. Federated Online Learning to Rank
(FOLTR) offers a privacy-preserving alternative by enabling collaborative model
training without sharing raw user data. However, benchmarks in FOLTR are
largely based on random partitioning of classical learning-to-rank datasets,
simulated user clicks, and the assumption of synchronous client participation.
This oversimplifies real-world dynamics and undermines the realism of
experimental results. We present AOL4FOLTR, a large-scale web search dataset
with 2.6 million queries from 10,000 users. Our dataset addresses key
limitations of existing benchmarks by including user identifiers, real click
data, and query timestamps, enabling realistic user partitioning, behavior
modeling, and asynchronous federated learning scenarios.

</details>


### [312] [TaoSR1: The Thinking Model for E-commerce Relevance Search](https://arxiv.org/abs/2508.12365)
*Chenhe Dong,Shaowei Yao,Pengkun Jiao,Jianhui Yang,Yiming Jin,Zerui Huang,Xiaojiang Zhou,Dan Ou,Haihong Tang*

Main category: cs.IR

TL;DR: BERT 계열 모델과 달리 LLM의 체인오브쏘트(CoT) 추론을 직접 검색 관련성 분류에 적용해 온라인 배포까지 가능한 파이프라인(TaoSR1)을 제시한다. SFT+CoT, pass@N+ DPO, 난이도 기반 동적 샘플링+GRPO 및 후처리로 CoT의 오류·환각·배포 문제를 완화해 기존 기법보다 우수한 성능을 보였다.


<details>
  <summary>Details</summary>
Motivation: 전자상거래 검색에서 쿼리-상품 관련성 예측은 핵심 과제이며, BERT 계열은 의미적 매칭에는 강하지만 복잡한 추론 능력이 부족하다. LLM을 직접 배포하려면 CoT의 누적 오류, 판별적 환각, 배포 효율성 문제를 해결해야 한다.

Method: TaoSR1은 세 단계로 구성: (1) CoT를 포함한 감독학습(SFT)으로 추론 능력 부여; (2) pass@N 샘플링과 Direct Preference Optimization(DPO)를 활용한 오프라인 샘플링으로 생성 품질 개선; (3) 난이도 기반 동적 샘플링과 Group Relative Policy Optimization(GRPO)로 판별적 환각 완화. 추가로 post-CoT 후처리와 누적확률 기반 분할로 온라인 추론 효율을 확보.

Result: 오프라인 데이터셋에서 기존 베이스라인 대비 유의미한 성능 향상을 기록하고, 온라인 사이드바이사이드 인간 평가에서도 큰 이득을 보였다고 보고함.

Conclusion: CoT 추론을 직접 분류 태스크에 적용하고 배포 실용성 문제를 함께 해결한 새로운 패러다임을 제시하며, CoT의 오류·환각·배포 문제에 대한 실용적 해법을 제공한다.

Abstract: Query-product relevance prediction is a core task in e-commerce search.
BERT-based models excel at semantic matching but lack complex reasoning
capabilities. While Large Language Models (LLMs) are explored, most still use
discriminative fine-tuning or distill to smaller models for deployment. We
propose a framework to directly deploy LLMs for this task, addressing key
challenges: Chain-of-Thought (CoT) error accumulation, discriminative
hallucination, and deployment feasibility. Our framework, TaoSR1, involves
three stages: (1) Supervised Fine-Tuning (SFT) with CoT to instill reasoning;
(2) Offline sampling with a pass@N strategy and Direct Preference Optimization
(DPO) to improve generation quality; and (3) Difficulty-based dynamic sampling
with Group Relative Policy Optimization (GRPO) to mitigate discriminative
hallucination. Additionally, post-CoT processing and a cumulative
probability-based partitioning method enable efficient online deployment.
TaoSR1 significantly outperforms baselines on offline datasets and achieves
substantial gains in online side-by-side human evaluations, introducing a novel
paradigm for applying CoT reasoning to relevance classification.

</details>


### [313] [Contrastive Multi-View Graph Hashing](https://arxiv.org/abs/2508.12377)
*Yang Xu,Zuliang Yang,Kai Ming Ting*

Main category: cs.IR

TL;DR: CMGHash는 여러 이질적 그래프 뷰에서 노드의 합의(consensus) 표현을 대조학습(contrastive learning)으로 학습하고, 그 표현에 이진화 제약을 걸어 효율적인 이진 해시 코드를 직접 얻는 엔드투엔드 프레임워크이다. 벤치마크에서 기존 방법들보다 검색 정확도가 크게 향상되었다고 보고한다.


<details>
  <summary>Details</summary>
Motivation: 다중 소스에서 온 풍부한 토폴로지 정보를 가진 다중-뷰 그래프 데이터는 점점 흔해지고 있으나, 기존의 다중-뷰 해싱 기법은 보통 뷰별 속성(벡터) 입력을 가정해 그래프 토폴로지를 효과적으로 융합·이진화하기 어렵다. 따라서 그래프 뷰들의 구조 정보를 통합하여 단일 이진 임베딩을 학습하는 방법이 필요하다.

Method: CMGHash는 모든 그래프 뷰에 걸쳐 노드의 k-최근접 이웃(k-NN)을 끌어모으고 비이웃(negative) 쌍을 밀어내는 대조적 다중-뷰 그래프 손실을 사용해 합의 노드 표현 공간을 학습한다. 학습된 합의 공간에 이진화 제약을 부과해 해당 공간을 비용 적게 이진 임베딩으로 전환할 수 있게 한다. 전체가 엔드투엔드로 학습된다.

Result: 여러 벤치마크 데이터셋 실험에서 CMGHash는 기존 기법들을 상회하는 검색(해시 기반 검색) 정확도를 보였다고 보고한다. (추상에서는 구체적인 수치·데이터셋·비교 대상은 제시되지 않음)

Conclusion: 대조학습 기반의 뷰 간 정합(consensus) 학습과 명시적 이진화 제약을 결합하면 다중-뷰 그래프 데이터에 대한 고성능 이진 임베딩을 얻을 수 있다. 다만 k 선택, 네거티브 샘플링, 확장성 등 실험·설계 세부사항이 성능·실용성에 영향을 줄 수 있다.

Abstract: Multi-view graph data, which both captures node attributes and rich
relational information from diverse sources, is becoming increasingly prevalent
in various domains. The effective and efficient retrieval of such data is an
important task. Although multi-view hashing techniques have offered a paradigm
for fusing diverse information into compact binary codes, they typically assume
attributes-based inputs per view. This makes them unsuitable for multi-view
graph data, where effectively encoding and fusing complex topological
information from multiple heterogeneous graph views to generate unified binary
embeddings remains a significant challenge. In this work, we propose
Contrastive Multi-view Graph Hashing (CMGHash), a novel end-to-end framework
designed to learn unified and discriminative binary embeddings from multi-view
graph data. CMGHash learns a consensus node representation space using a
contrastive multi-view graph loss, which aims to pull $k$-nearest neighbors
from all graphs closer while pushing away negative pairs, i.e., non-neighbor
nodes. Moreover, we impose binarization constraints on this consensus space,
enabling its conversion to a corresponding binary embedding space at minimal
cost. Extensive experiments on several benchmark datasets demonstrate that
CMGHash significantly outperforms existing approaches in terms of retrieval
accuracy.

</details>


### [314] [Diagnostic-Guided Dynamic Profile Optimization for LLM-based User Simulators in Sequential Recommendation](https://arxiv.org/abs/2508.12645)
*Hongyang Liu,Zhu Sun,Tianjun Wei,Yan Wang,Jiajie Zhu,Xinghua Qu*

Main category: cs.IR

TL;DR: DGDPO는 LLM 기반의 사용자 시뮬레이터에서 ‘진단→처방’의 동적 반복 최적화 루프를 도입해 사용자 프로필을 점진적으로 보정하고, 이를 시퀀스 추천기와 연동해 다회차(다중 라운드) 상호작용을 시뮬레이션하는 프레임워크이다. 세 개의 실제 데이터셋에서 유효성을 보였다.


<details>
  <summary>Details</summary>
Motivation: 기존 LLM 기반 RS 시뮬레이터는 정적 단일 프롬프트로 프로필을 구성하고 단일 라운드 상호작용만 모사해 현실성·완성도가 낮아 실제 추천 시스템 개발·평가에 한계가 있었다.

Method: 반복 최적화 루프 내에 (1) 결함을 식별하는 진단 모듈(LLM, 특화 및 캘리브레이션 포함)과 (2) 진단 결과를 바탕으로 구체적 개선안을 생성하는 처방 모듈(범용 LLM)을 배치하여 프로필을 점진적으로 개선한다. 또한 DGDPO를 시퀀스 추천기와 통합해 사용자 프로필과 추천 전략이 상호 적응하는 다회차 상호작용을 지원한다.

Result: 세 개 실제 데이터셋에서 광범위한 실험을 통해 제안한 프레임워크가 기존 방법들보다 시뮬레이션 충실도 및 추천 성능 측면에서 우수함을 보였다(추상에는 상세 수치 미제공).

Conclusion: DGDPO는 동적·반복적 프로필 최적화를 통해 LLM 기반 사용자 시뮬레이터의 현실성을 크게 향상시키고, 다회차 상호작용을 통해 추천 시스템 개발·평가의 현실적 장면을 모사할 수 있게 한다.

Abstract: Recent advances in large language models (LLMs) have enabled realistic user
simulators for developing and evaluating recommender systems (RSs). However,
existing LLM-based simulators for RSs face two major limitations: (1) static
and single-step prompt-based inference that leads to inaccurate and incomplete
user profile construction; (2) unrealistic and single-round
recommendation-feedback interaction pattern that fails to capture real-world
scenarios. To address these limitations, we propose DGDPO (Diagnostic-Guided
Dynamic Profile Optimization), a novel framework that constructs user profile
through a dynamic and iterative optimization process to enhance the simulation
fidelity. Specifically, DGDPO incorporates two core modules within each
optimization loop: firstly, a specialized LLM-based diagnostic module,
calibrated through our novel training strategy, accurately identifies specific
defects in the user profile. Subsequently, a generalized LLM-based treatment
module analyzes the diagnosed defect and generates targeted suggestions to
refine the profile. Furthermore, unlike existing LLM-based user simulators that
are limited to single-round interactions, we are the first to integrate DGDPO
with sequential recommenders, enabling a bidirectional evolution where user
profiles and recommendation strategies adapt to each other over multi-round
interactions. Extensive experiments conducted on three real-world datasets
demonstrate the effectiveness of our proposed framework.

</details>


### [315] [Multi-Granularity Distribution Modeling for Video Watch Time Prediction via Exponential-Gaussian Mixture Network](https://arxiv.org/abs/2508.12665)
*Xu Zhao,Ruibo Ma,Jiaqi Chen,Weiqi Zhao,Ping Yang,Yao Hu*

Main category: cs.IR

TL;DR: 저자들은 시청시간 분포의 ‘빠른 스킵’으로 인한 거친(skewed) 편향과 사용자-영상 상호작용으로 인한 미세한 다양성을 각각 설명하기 위해 지수-정규 혼합(Exponential-Gaussian Mixture, EGM)을 가정하고, 이를 파라미터화하는 EGMN을 제안하여 오프라인/온라인 실험에서 기존 기법보다 우수한 성능을 보였다고 주장한다.


<details>
  <summary>Details</summary>
Motivation: Short-video 플랫폼에서 시청시간 예측은 사용자 참여 증대에 중요하지만, 시청시간 분포가 빠른 스킵에 의한 심한 편중(coarse-grained skewness)과 다양한 시청 패턴에 의한 미세한 다양성(fine-grained diversity)을 동시에 띠어 예측이 어렵다.

Method: 시청시간을 지수(Exponential) 성분(빠른 스킵 설명)과 정규(Gaussian) 성분(다양한 상호작용 설명)의 혼합분포로 모델링하고, 은닉 표현 인코더와 혼합 파라미터 생성기로 구성된 Exponential-Gaussian Mixture Network(EGMN)로 EGM 분포의 파라미터를 조건부로 예측한다.

Result: 공개 데이터셋에서의 광범위한 오프라인 실험과 Xiaohongshu 앱의 피딩 시나리오에서의 온라인 A/B 테스트에서 EGMN이 기존 최신 방법들보다 분포 적합도(다중 그레인)와 실제 서비스 지표에서 우수함을 입증했다.

Conclusion: EGM 가정과 EGMN 구조는 거친 편향과 미세 다양성을 동시에 포착해 시청시간 분포를 효과적으로 모델링하며, 코드가 공개되어 재현 가능성을 지원한다.

Abstract: Accurate watch time prediction is crucial for enhancing user engagement in
streaming short-video platforms, although it is challenged by complex
distribution characteristics across multi-granularity levels. Through
systematic analysis of real-world industrial data, we uncover two critical
challenges in watch time prediction from a distribution aspect: (1)
coarse-grained skewness induced by a significant concentration of quick-skips1,
(2) fine-grained diversity arising from various user-video interaction
patterns. Consequently, we assume that the watch time follows the
Exponential-Gaussian Mixture (EGM) distribution, where the exponential and
Gaussian components respectively characterize the skewness and diversity.
Accordingly, an Exponential-Gaussian Mixture Network (EGMN) is proposed for the
parameterization of EGM distribution, which consists of two key modules: a
hidden representation encoder and a mixture parameter generator. We conducted
extensive offline experiments on public datasets and online A/B tests on the
industrial short-video feeding scenario of Xiaohongshu App to validate the
superiority of EGMN compared with existing state-of-the-art methods.
Remarkably, comprehensive experimental results have proven that EGMN exhibits
excellent distribution fitting ability across coarse-to-fine-grained levels. We
open source related code on Github: https://github.com/BestActionNow/EGMN.

</details>


### [316] [Asymmetric Diffusion Recommendation Model](https://arxiv.org/abs/2508.12706)
*Yongchun Zhu,Guanyu Jiang,Jingwu Chen,Feng Zhang,Xiao Yang,Zuotao Liu*

Main category: cs.IR

TL;DR: AsymDiffRec는 추천 시스템 샘플의 불연속성(결측·이산성)을 반영해 정방향과 역방향 확산을 비대칭적으로 학습하는 방법이다. 결측 특성 생성을 모사하는 일반화된 정방향 과정과 비대칭 잠재공간에서의 역과정을 도입하고, 개인화 정보 보존을 위한 태스크 지향 최적화로 강건한 표현을 만든다. 실제 서비스(도우인 뮤직)에 적용해 활성일수·앱 사용시간 등에서 소폭의 온라인 개선을 보였다.


<details>
  <summary>Details</summary>
Motivation: 기존 확산 기반 추천은 연속 공간의 표준 가우시안 노이즈를 사용하나, 추천 데이터는 이산·결측이 많고 가우시안 노이즈가 개인화 정보를 훼손할 수 있다. 따라서 실제 샘플 특성에 맞는 비대칭적 확산 모델이 필요하다.

Method: 1) 일반화된 정방향 과정으로 실제 추천 샘플의 결측(또는 누락) 특성을 시뮬레이션한다. 2) 역과정은 비대칭 잠재 특성 공간에서 수행해 원래 데이터 공간의 단순 가우시안 노이즈 주입을 피한다. 3) 개인화 정보 유지를 위해 태스크 지향 최적화(loss)를 도입하고, 서빙 시 결측 샘플을 노이즈 입력으로 처리해 복원된 강건한 표현으로 예측한다. 베이스 모델에 모듈로 결합 가능.

Result: Douyin Music 앱에 도입해 온라인 A/B에서 활성일수 +0.131%, 앱 사용시간 +0.166% 향상. 오프라인 확장 실험에서도 성능 개선을 보고함.

Conclusion: 이산적·결측 중심의 추천 문제에 비대칭 확산 설계가 효과적임을 보였고, 실제 서비스 적용으로 실용적 이득을 입증했다.

Abstract: Recently, motivated by the outstanding achievements of diffusion models, the
diffusion process has been employed to strengthen representation learning in
recommendation systems. Most diffusion-based recommendation models typically
utilize standard Gaussian noise in symmetric forward and reverse processes in
continuous data space. Nevertheless, the samples derived from recommendation
systems inhabit a discrete data space, which is fundamentally different from
the continuous one. Moreover, Gaussian noise has the potential to corrupt
personalized information within latent representations. In this work, we
propose a novel and effective method, named Asymmetric Diffusion Recommendation
Model (AsymDiffRec), which learns forward and reverse processes in an
asymmetric manner. We define a generalized forward process that simulates the
missing features in real-world recommendation samples. The reverse process is
then performed in an asymmetric latent feature space. To preserve personalized
information within the latent representation, a task-oriented optimization
strategy is introduced. In the serving stage, the raw sample with missing
features is regarded as a noisy input to generate a denoising and robust
representation for the final prediction. By equipping base models with
AsymDiffRec, we conduct online A/B tests, achieving improvements of +0.131% and
+0.166% in terms of users' active days and app usage duration respectively.
Additionally, the extended offline experiments also demonstrate improvements.
AsymDiffRec has been implemented in the Douyin Music App.

</details>


### [317] [Deep Research: A Survey of Autonomous Research Agents](https://arxiv.org/abs/2508.12752)
*Wenlin Zhang,Xiaopeng Li,Yingyi Zhang,Pengyue Jia,Yichao Wang,Huifeng Guo,Yong Liu,Xiangyu Zhao*

Main category: cs.IR

TL;DR: 이 논문은 '딥 리서치' 에이전트의 파이프라인(기획, 질문 개발, 웹 탐색, 리포트 생성)을 체계적으로 정리하고 각 단계의 기술적 도전과 해결 접근을 분류하며, 최적화 기법·벤치마크·미해결 쟁점을 제시한 서베이 논문이다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반의 자율 에이전트는 복잡한 분석 과업을 수행하지만 내부 지식 한계와 사실성 문제가 있어, 웹 기반 증거를 활용한 계획·검색·합성을 통해 신뢰성 있는 분석 보고서를 생성하는 '딥 리서치' 패러다임이 필요하다.

Method: 딥 리서치 파이프라인을 네 단계(기획, 질문 개발, 웹 탐색, 리포트 생성)로 분해하여 각 단계의 기술적 과제들을 정리하고, 대표적 접근법을 범주화한다. 또한 최적화 기법(예: 상호작용적 계획·피드백 루프 등)과 이를 평가하기 위한 벤치마크들을 요약한다.

Result: 각 단계별 도전과제와 기존 방법들의 분류가 제공되며, 최적화 기법과 평가 지표·벤치마크의 최근 동향이 정리된다. 논문은 현재 기술의 한계와 향후 연구 방향(신뢰성, 평가, 효율성 등)을 제시한다.

Conclusion: 딥 리서치 에이전트를 신뢰성 있고 실용적으로 만들려면 웹 근거의 사실성 검증, 평가 표준화, 효율적 탐색·계획 기법, 안전성과 투명성 확보가 필요하며, 이를 위한 구체적 연구 로드맵을 제안한다.

Abstract: The rapid advancement of large language models (LLMs) has driven the
development of agentic systems capable of autonomously performing complex
tasks. Despite their impressive capabilities, LLMs remain constrained by their
internal knowledge boundaries. To overcome these limitations, the paradigm of
deep research has been proposed, wherein agents actively engage in planning,
retrieval, and synthesis to generate comprehensive and faithful analytical
reports grounded in web-based evidence. In this survey, we provide a systematic
overview of the deep research pipeline, which comprises four core stages:
planning, question developing, web exploration, and report generation. For each
stage, we analyze the key technical challenges and categorize representative
methods developed to address them. Furthermore, we summarize recent advances in
optimization techniques and benchmarks tailored for deep research. Finally, we
discuss open challenges and promising research directions, aiming to chart a
roadmap toward building more capable and trustworthy deep research agents.

</details>


### [318] [Informfully Recommenders -- Reproducibility Framework for Diversity-aware Intra-session Recommendations](https://arxiv.org/abs/2508.13019)
*Lucien Heitz,Runze Li,Oana Inel,Abraham Bernstein*

Main category: cs.IR

TL;DR: 뉴스 도메인에서 다양성(노름) 중심의 실험을 재현가능하게 지원하는 Cornac 기반 확장체 'Informfully Recommenders'를 제안한다. 데이터 전처리, 다양성 최적화 모델, 세션 내 재랭킹, 다양한 다양성 지표를 포함한 엔드투엔드 파이프라인을 제공한다.


<details>
  <summary>Details</summary>
Motivation: 다양성·노름 기반 추천 실험은 늘어나고 있으나, 전처리·모델·재랭킹·평가 전 단계에 걸친 통합적 재현가능성 프레임워크가 부재해 비교·재현이 어렵다.

Method: Cornac을 확장해 1) 데이터 전처리 모듈, 2) 다양성 최적화 모델 구현, 3) 세션 내 아이템 재랭킹 모듈, 4) 다양한 다양성 측정 지표를 포함한 파이프라인을 구축하고, 뉴스 데이터셋에서 오프라인 실험으로 동작을 검증함.

Result: 확장체를 통해 다양성 중심의 모델과 재랭킹 방법을 일관되게 실험할 수 있음을 보였고, 뉴스 도메인 오프라인 실험에서 기능성과 적용 가능성을 입증함.

Conclusion: Informfully Recommenders는 노름 중심 추천 연구의 재현성과 비교 가능성을 높이는 첫 단계로서, 다양성 중심 설계·평가를 위한 엔드투엔드 솔루션을 제공한다.

Abstract: Norm-aware recommender systems have gained increased attention, especially
for diversity optimization. The recommender systems community has
well-established experimentation pipelines that support reproducible
evaluations by facilitating models' benchmarking and comparisons against
state-of-the-art methods. However, to the best of our knowledge, there is
currently no reproducibility framework to support thorough norm-driven
experimentation at the pre-processing, in-processing, post-processing, and
evaluation stages of the recommender pipeline. To address this gap, we present
Informfully Recommenders, a first step towards a normative reproducibility
framework that focuses on diversity-aware design built on Cornac. Our extension
provides an end-to-end solution for implementing and experimenting with
normative and general-purpose diverse recommender systems that cover 1) dataset
pre-processing, 2) diversity-optimized models, 3) dedicated intrasession item
re-ranking, and 4) an extensive set of diversity metrics. We demonstrate the
capabilities of our extension through an extensive offline experiment in the
news domain.

</details>


### [319] [D-RDW: Diversity-Driven Random Walks for News Recommender Systems](https://arxiv.org/abs/2508.13035)
*Runze Li,Lucien Heitz,Oana Inel,Abraham Bernstein*

Main category: cs.IR

TL;DR: D-RDW는 랜덤 워크 기반의 경량 재순위 알고리즘으로, 기사 속성(감성·정당 언급)에 대한 사용자 지정 목표 분포를 반영해 다양성 높은 뉴스 추천을 제공하며, 신경망 기반 최첨단 모델보다 다양성 지표와 계산 효율성에서 우수함.


<details>
  <summary>Details</summary>
Motivation: 뉴스 추천에서 편향·필터버블 문제를 완화하고, 편집자가 규범·가치를 투명하게 반영할 수 있는 추천 방식을 제공하려는 필요성.

Method: 전통적 랜덤 워크 알고리즘에 '목표 분포'를 도입해 기사 속성의 분포를 재순위 과정에 반영하는 경량적 재순위 기법(D-RDW). 속성(감성, 정당 언급)별로 원하는 분포를 설정하고, 이를 기반으로 노드 전파/샘플링을 조정해 다양성을 유도.

Result: 감성 및 정당 언급 관련 다양성 지표에서 최첨단 신경망 모델보다 개선된 성능을 보였고, 계산 비용 측면에서도 더 효율적임을 보고함.

Conclusion: D-RDW는 편집자가 규범을 반영할 수 있는 투명한 '사회적 추천자'로서 실용적인 대안이지만, 사용자 만족·개인화와 다양성의 균형, 장기적 영향 등 추가 평가가 필요함.

Abstract: This paper introduces Diversity-Driven RandomWalks (D-RDW), a lightweight
algorithm and re-ranking technique that generates diverse news recommendations.
D-RDW is a societal recommender, which combines the diversification
capabilities of the traditional random walk algorithms with customizable target
distributions of news article properties. In doing so, our model provides a
transparent approach for editors to incorporate norms and values into the
recommendation process. D-RDW shows enhanced performance across key diversity
metrics that consider the articles' sentiment and political party mentions when
compared to state-of-the-art neural models. Furthermore, D-RDW proves to be
more computationally efficient than existing approaches.

</details>


### [320] [Is This News Still Interesting to You?: Lifetime-aware Interest Matching for News Recommendation](https://arxiv.org/abs/2508.13064)
*Seongeun Ryu,Yunyong Ko,Sang-Wook Kim*

Main category: cs.IR

TL;DR: LIME는 클릭 뉴스의 연령과 뉴스 수명의 토픽·사용자별 차이를 반영해 시간 민감한 관심 매칭을 수행하는 프레임워크로, 세 가지 전략(User-Topic lifetime-aware age representation, Candidate-aware lifetime attention, Freshness-guided interest refinement)을 통해 기존 방법보다 추천 성능을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 기존 개인화 뉴스 추천은 뉴스·사용자 표현을 개선했지만, (1) 클릭한 뉴스의 연령을 통해 관심의 지속성을 추론하는 문제와 (2) 토픽·사용자별로 다른 뉴스 수명(lifetime)을 모델링하는 문제를 충분히 다루지 못했다.

Method: (1) 사용자-토픽별 상대적 뉴스 연령 표현을 도입해 나이 정보의 의미를 정렬하고, (2) 후보 뉴스에 맞춰 시간적으로 정렬된 사용자 표현을 생성하는 후보-감안(lifetime-aware) 어텐션을 적용하며, (3) 예측 시 신선도를 반영해 유효한 후보를 우선하는 신선도 기반 관심 정제(freshness-guided refinement)를 수행한다. 이 전략들은 특정 모델에 종속되지 않아 기존 방법에 적용 가능하다.

Result: 두 개의 실제 데이터셋에서 다양한 최첨단 방법을 일관되게 능가했으며, 제안한 전략들이 추천 정확도를 의미 있게 개선함을 보였다.

Conclusion: 시간적 관점을 사용자·토픽 수준으로 세분화해 관심 매칭에 반영하면 추천 질이 향상된다. LIME은 실용적이고 모델-아그노스틱한 시간 민감성 기법으로 평가된다.

Abstract: Personalized news recommendation aims to deliver news articles aligned with
users' interests, serving as a key solution to alleviate the problem of
information overload on online news platforms. While prior work has improved
interest matching through refined representations of news and users, the
following time-related challenges remain underexplored: (C1) leveraging the age
of clicked news to infer users' interest persistence, and (C2) modeling the
varying lifetime of news across topics and users. To jointly address these
challenges, we propose a novel Lifetime-aware Interest Matching framework for
nEws recommendation, named LIME, which incorporates three key strategies: (1)
User-Topic lifetime-aware age representation to capture the relative age of
news with respect to a user-topic pair, (2) Candidate-aware lifetime attention
for generating temporally aligned user representation, and (3) Freshness-guided
interest refinement for prioritizing valid candidate news at prediction time.
Extensive experiments on two real-world datasets demonstrate that LIME
consistently outperforms a wide range of state-of-the-art news recommendation
methods, and its model agnostic strategies significantly improve recommendation
accuracy.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [321] [Sparse Attention across Multiple-context KV Cache](https://arxiv.org/abs/2508.11661)
*Ziyi Cao,Qingyi Si,Jingbin Zhang,Bingquan Liu*

Main category: cs.LG

TL;DR: SamKV는 RAG(여러 컨텍스트)의 다중 KV 캐시에 대해 다른 컨텍스트의 보완 정보를 고려한 어텐션 희소화와 부분 재계산으로 시퀀스 길이를 15%로 압축하면서 정확도 손실 없이 처리량을 크게 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어모델의 긴 시퀀스 추론은 비용과 메모리 제약이 크며, 기존의 KV 캐시 재사용·희소화 기법은 단일 컨텍스트(인과적 의존성)에만 적용 가능하다. RAG처럼 미리 문서들을 알 수 없는 다중 컨텍스트 상황에서는 각 문서의 KV가 독립적으로 저장되어 교차 어텐션이 누락되어 정확도 저하나 높은 메모리 비용이 발생한다.

Method: SamKV는 각 컨텍스트를 희소화할 때 다른 컨텍스트들이 제공하는 보완 정보를 반영하여 중요한 KV를 선택하고, 선택된 정보에 대해 로컬(부분) 재계산을 수행한다. 즉, 완전 재계산 없이도 교차 컨텍스트 영향력을 보존하도록 설계되어 다중 컨텍스트 KV 캐시에서의 어텐션 희소화를 가능하게 한다.

Result: 실험에서 SamKV는 전체 재계산 기준과 비교해 정확도 저하 없이 시퀀스 길이를 약 15%로 압축했고, 다중 컨텍스트 RAG 시나리오에서 처리량(throughput)을 크게 향상시켰다. 기존 방식처럼 모든 KV를 계속 보관해야 하는 메모리 부담을 완화한다는 점도 시사된다.

Conclusion: SamKV는 다중 컨텍스트 KV 캐시에 대한 최초의 어텐션 희소화 접근법으로, 교차 컨텍스트 정보를 반영한 희소화와 국소 재계산으로 메모리·연산 효율을 개선하면서 정확도를 유지한다. RAG 등 실제 다중 문서 추론에 유용한 실용적 해결책을 제시한다.

Abstract: Large language models face significant cost challenges in long-sequence
inference. To address this, reusing historical Key-Value (KV) Cache for
improved inference efficiency has become a mainstream approach. Recent advances
further enhance throughput by sparse attention mechanisms to select the most
relevant KV Cache, thereby reducing sequence length. However, such techniques
are limited to single-context scenarios, where historical KV Cache is computed
sequentially with causal-attention dependencies. In retrieval-augmented
generation (RAG) scenarios, where retrieved documents as context are unknown
beforehand, each document's KV Cache is computed and stored independently
(termed multiple-context KV Cache), lacking cross-attention between contexts.
This renders existing methods ineffective. Although prior work partially
recomputes multiple-context KV Cache to mitigate accuracy loss from missing
cross-attention, it requires retaining all KV Cache throughout, failing to
reduce memory overhead. This paper presents SamKV, the first exploration of
attention sparsification for multiple-context KV Cache. Specifically, SamKV
takes into account the complementary information of other contexts when
sparsifying one context, and then locally recomputes the sparsified
information. Experiments demonstrate that our method compresses sequence length
to 15% without accuracy degradation compared with full-recompuation baselines,
significantly boosting throughput in multi-context RAG scenarios.

</details>


### [322] [Assessing Representation Stability for Transformer Models](https://arxiv.org/abs/2508.11667)
*Bryan E. Tuck,Rakesh M. Verma*

Main category: cs.LG

TL;DR: Representation Stability(RS)는 중요한 단어를 마스킹했을 때 임베딩 변화의 민감도를 측정하여 변조된 텍스트(적대적 예제)를 검출하는 모델-중립적 프레임워크이다. 단어 중요도를 기반으로 상위 k개 단어를 선정·마스킹하고, 임베딩 민감도 시퀀스를 BiLSTM으로 판별한다. 세 데이터셋, 세 공격 유형, 두 피해 모델에서 88% 이상의 검출 정확도를 보이며, 그래디언트 기반 순위가 최선임을 보였다.


<details>
  <summary>Details</summary>
Motivation: 기존 방어 기법은 특정 공격에 종속적이거나 모델 재학습(비용 부담)을 필요로 하므로, 재학습 없이 다양한 공격과 모델에 적용 가능한 경량 검출 방법이 필요하다.

Method: 1) 단어 중요도(그래디언트·어텐션·무작위 등)로 단어를 정렬, 2) 상위 k개 단어를 마스킹하여 임베딩 변화를 측정(마스킹 민감도), 3) 민감도 패턴을 시퀀스로 BiLSTM 검출기 학습, 4) NDCG로 교란 단어 식별 품질 평가 및 다양한 설정에서 성능 비교.

Result: 적대적으로 교란된 단어는 자연스럽게 중요한 단어보다 마스킹 민감도가 현저히 높았고, RS는 세 데이터셋·세 공격·두 모델에서 88% 이상의 검출 정확도를 달성. 그래디언트 기반 단어 순위가 NDCG 및 검출 성능에서 우수했으며, 미학습(재학습 불필요) 상황에서도 다른 데이터·공격·모델로의 일반화가 양호했다.

Conclusion: RS는 모델-무관하고 비용 효율적인 적대적 텍스트 검출 실용적 대안이다. 다만 단어 중요도 추정 품질과 단어 수준 공격에 대한 의존성, 패러프레이즈·문장 수준 공격 또는 적응형 공격에 대한 취약성 가능성이 남아 있어 추가 검증이 필요하다.

Abstract: Adversarial text attacks remain a persistent threat to transformer models,
yet existing defenses are typically attack-specific or require costly model
retraining. We introduce Representation Stability (RS), a model-agnostic
detection framework that identifies adversarial examples by measuring how
embedding representations change when important words are masked. RS first
ranks words using importance heuristics, then measures embedding sensitivity to
masking top-k critical words, and processes the resulting patterns with a
BiLSTM detector. Experiments show that adversarially perturbed words exhibit
disproportionately high masking sensitivity compared to naturally important
words. Across three datasets, three attack types, and two victim models, RS
achieves over 88% detection accuracy and demonstrates competitive performance
compared to existing state-of-the-art methods, often at lower computational
cost. Using Normalized Discounted Cumulative Gain (NDCG) to measure
perturbation identification quality, we reveal that gradient-based ranking
outperforms attention and random selection approaches, with identification
quality correlating with detection performance for word-level attacks. RS also
generalizes well to unseen datasets, attacks, and models without retraining,
providing a practical solution for adversarial text detection.

</details>


### [323] [Collaborative Learning-Enhanced Lightweight Models for Predicting Arterial Blood Pressure Waveform in a Large-scale Perioperative Dataset](https://arxiv.org/abs/2508.11669)
*Wentao Li,Yonghu He,Kun Gao,Qing Liu,Yali Zheng*

Main category: cs.LG

TL;DR: 경량화된 sInvResUNet과 협업 학습 KDCL_sInvResUNet를 도입해 임베디드 장치에서 실시간(10초 출력 기준 8.49 ms) 비침습적 동맥혈압(ABP) 파형 추정에 성공함. 모델은 0.89M 파라미터·0.02 GFLOPS로 효율적이며, 대규모(2,154명, 1,257,141 세그먼트) 이종성 있는 수술기록 데이터에서 주관자 독립 검증 시 평균절대오차(MAE) 10.06 mmHg, 피어슨 상관 0.88을 달성했음. 그러나 인구학적·심혈관 조건에 따른 성능 변동이 커서 범용성은 제한적임.


<details>
  <summary>Details</summary>
Motivation: 비침습적 연속 ABP 모니터링은 중환자·수술 환경에서 중요하지만, 기존 딥러닝 모델들은 대체로 무겁고 임베디드 배포에 부적합함. 또한 대규모·이질적 데이터에서의 주관자 독립 성능과 실시간 임베디드 적합성을 동시에 만족하는 연구가 부족함.

Method: 경량 네트워크 sInvResUNet 설계(0.89M 파라미터, 0.02 GFLOPS)와 협업 학습(KDCL_sInvResUNet)을 도입하여 ECG/PPG 등 비침습적 신호로부터 ABP 파형을 재구성함. 대규모 perioperative 데이터셋(2,154명, 1,257,141 세그먼트, 넓은 SBP/DBP 범위)을 사용해 주관자 독립 검증을 수행하고, 임베디드 장치에서의 추론시간을 측정하여 실시간성 평가.

Result: 경량 모델이 임베디드 실시간 추론(10초 출력 당 8.49 ms)과 낮은 연산·메모리 요구를 만족하면서, 대형 모델과 비교해 유사하거나 다소 나은 성능을 보임(MAE 10.06 mmHg, 피어슨 0.88). 다만 인구집단·심혈관 상태에 따른 성능 편차가 크게 관찰됨.

Conclusion: 제안 모델은 실시간·비침습적 ABP 모니터링을 위한 실용적 초기 기반을 제공하나, 인구학적·질환 기반의 일반화 한계가 존재함. 향후 편향 보정, 다양성 확보, 임상검증을 통해 신뢰성 향상이 필요함.

Abstract: Noninvasive arterial blood pressure (ABP) monitoring is essential for patient
management in critical care and perioperative settings, providing continuous
assessment of cardiovascular hemodynamics with minimal risks. Numerous deep
learning models have developed to reconstruct ABP waveform from noninvasively
acquired physiological signals such as electrocardiogram and
photoplethysmogram. However, limited research has addressed the issue of model
performance and computational load for deployment on embedded systems. The
study introduces a lightweight sInvResUNet, along with a collaborative learning
scheme named KDCL_sInvResUNet. With only 0.89 million parameters and a
computational load of 0.02 GFLOPS, real-time ABP estimation was successfully
achieved on embedded devices with an inference time of just 8.49 milliseconds
for a 10-second output. We performed subject-independent validation in a
large-scale and heterogeneous perioperative dataset containing 1,257,141 data
segments from 2,154 patients, with a wide BP range (41-257 mmHg for SBP, and
31-234 mmHg for DBP). The proposed KDCL_sInvResUNet achieved lightly better
performance compared to large models, with a mean absolute error of 10.06 mmHg
and mean Pearson correlation of 0.88 in tracking ABP changes. Despite these
promising results, all deep learning models showed significant performance
variations across different demographic and cardiovascular conditions,
highlighting their limited ability to generalize across such a broad and
diverse population. This study lays a foundation work for real-time,
unobtrusive ABP monitoring in real-world perioperative settings, providing
baseline for future advancements in this area.

</details>


### [324] [Contrastive Regularization over LoRA for Multimodal Biomedical Image Incremental Learning](https://arxiv.org/abs/2508.11673)
*Haojie Zhang,Yixiong Liang,Hulin Kuang,Lihui Cen,Zhe Qu,Yigang Cen,Min Zeng,Shichao Kan*

Main category: cs.LG

TL;DR: MSLoRA-CR incrementally adapts modality-specific LoRA modules on a frozen large vision-language model and adds contrastive regularization to improve intra-modality sharing and inter-modality differentiation, achieving +1.88% overall on biomedical multimodal incremental learning compared to unconstrained incremental LoRA.


<details>
  <summary>Details</summary>
Motivation: To avoid training separate heavy models per biomedical modality (costly at inference) and to enable a single unified model that can be incrementally extended across multiple biomedical imaging modalities while preserving past knowledge and transferring useful cross-modality knowledge.

Method: Keep pretrained LVLM frozen; for each new modality/task, add and fine-tune modality-specific LoRA modules. Introduce Contrastive Regularization during incremental updates to (1) encourage better sharing within a modality and (2) promote differentiation between modalities. Compare against training separate models per modality and incremental LoRA fine-tuning baselines.

Result: On biomedical image incremental learning benchmarks, MSLoRA-CR outperforms both per-modality SOTA and general incremental LoRA, improving overall performance by 1.88% over unconstrained incremental learning while remaining computationally efficient. Code is released at the provided GitHub link.

Conclusion: MSLoRA-CR is a practical approach for Multimodal Biomedical Image Incremental Learning that mitigates forgetting and improves cross-modality adaptation via modality-specific LoRA plus contrastive regularization; further validation (datasets, ablations, statistical tests) would strengthen evidence.

Abstract: Multimodal Biomedical Image Incremental Learning (MBIIL) is essential for
handling diverse tasks and modalities in the biomedical domain, as training
separate models for each modality or task significantly increases inference
costs. Existing incremental learning methods focus on task expansion within a
single modality, whereas MBIIL seeks to train a unified model incrementally
across modalities. The MBIIL faces two challenges: I) How to preserve
previously learned knowledge during incremental updates? II) How to effectively
leverage knowledge acquired from existing modalities to support new modalities?
To address these challenges, we propose MSLoRA-CR, a method that fine-tunes
Modality-Specific LoRA modules while incorporating Contrastive Regularization
to enhance intra-modality knowledge sharing and promote inter-modality
knowledge differentiation. Our approach builds upon a large vision-language
model (LVLM), keeping the pretrained model frozen while incrementally adapting
new LoRA modules for each modality or task. Experiments on the incremental
learning of biomedical images demonstrate that MSLoRA-CR outperforms both the
state-of-the-art (SOTA) approach of training separate models for each modality
and the general incremental learning method (incrementally fine-tuning LoRA).
Specifically, MSLoRA-CR achieves a 1.88% improvement in overall performance
compared to unconstrained incremental learning methods while maintaining
computational efficiency. Our code is publicly available at
https://github.com/VentusAislant/MSLoRA_CR.

</details>


### [325] [Lifelong Learner: Discovering Versatile Neural Solvers for Vehicle Routing Problems](https://arxiv.org/abs/2508.11679)
*Shaodi Feng,Zhuoyi Lin,Jianan Zhou,Cong Zhang,Jingwen Li,Kuan-Wen Chen,Senthilnath Jayavelu,Yew-Soon Ong*

Main category: cs.LG

TL;DR: 연속적인 맥락 변화에 대응하는 평생학습 기반의 신경망 VRP 솔버를 제안. Transformer 기반의 Lifelong Learner(LL)와 맥락 간 자기어텐션, 동적 맥락 스케줄러(DCS) + 교차 맥락 경험 재생을 통해 이전 문제로부터 지식을 이전하고 회상하여 다양한 VRP 환경에서 우수한 성능을 기록함.


<details>
  <summary>Details</summary>
Motivation: 기존 신경망 VRP 솔버들은 단일한 가정(예: 유클리디안 거리, 고정 문제 크기)에 맞춰 학습되어 서로 다른 현실적 맥락(거리 정의, 문제 크기 등)에 바로 적용하기 어렵고 범용성이 낮음. 이를 개선하기 위해 연속적인 서로 다른 VRP 맥락을 점진적으로 학습하는 프레임워크가 필요함.

Method: Transformer를 백본으로 하는 Lifelong Learner(LL)를 제안. 맥락 간 자기어텐션(inter-context self-attention)을 도입해 이전 맥락에서 획득한 표현과 정책을 후속 맥락으로 전달. 동적 맥락 스케줄러(DCS)는 교차-맥락 경험 재생(cross-context experience replay)을 사용해 과거에 학습한 정책을 주기적으로 회상(replay)하도록 유도. 점진적 학습으로 일련의 VRP들을 해결.

Result: 합성 데이터 및 벤치마크(문제 크기 최대 18k)에서 실험 수행. 제안된 LL이 다양한 맥락에서 효과적인 정책을 학습하며 다른 신경망 솔버들을 능가, 대부분의 VRP에서 최고 성능을 달성했다고 보고.

Conclusion: 맥락 간 자기어텐션과 동적 스케줄러를 결합한 평생학습 프레임워크는 신경망 기반 VRP 솔버의 범용성과 적응력을 크게 향상시킴. 제안 방법은 다양한 VRP 환경에서 강건한 성능을 제공할 수 있음.

Abstract: Deep learning has been extensively explored to solve vehicle routing problems
(VRPs), which yields a range of data-driven neural solvers with promising
outcomes. However, most neural solvers are trained to tackle VRP instances in a
relatively monotonous context, e.g., simplifying VRPs by using Euclidean
distance between nodes and adhering to a single problem size, which harms their
off-the-shelf application in different scenarios. To enhance their versatility,
this paper presents a novel lifelong learning framework that incrementally
trains a neural solver to manage VRPs in distinct contexts. Specifically, we
propose a lifelong learner (LL), exploiting a Transformer network as the
backbone, to solve a series of VRPs. The inter-context self-attention mechanism
is proposed within LL to transfer the knowledge obtained from solving preceding
VRPs into the succeeding ones. On top of that, we develop a dynamic context
scheduler (DCS), employing the cross-context experience replay to further
facilitate LL looking back on the attained policies of solving preceding VRPs.
Extensive results on synthetic and benchmark instances (problem sizes up to
18k) show that our LL is capable of discovering effective policies for tackling
generic VRPs in varying contexts, which outperforms other neural solvers and
achieves the best performance for most VRPs.

</details>


### [326] [Comparative Analysis of Time Series Foundation Models for Demographic Forecasting: Enhancing Predictive Accuracy in US Population Dynamics](https://arxiv.org/abs/2508.11680)
*Aditya Akella,Jonathan Farah*

Main category: cs.LG

TL;DR: This paper applies a pre-trained time-series foundation model (TimesFM) to U.S. demographic forecasting and reports that TimesFM achieves the lowest MSE in 86.67% of test cases, outperforming LSTM, ARIMA and Linear Regression—especially for minority groups with sparse history.


<details>
  <summary>Details</summary>
Motivation: Demographic shifts critically affect planning in urban design, health, and economics. Accurate forecasts are needed but many subpopulations have sparse historical data and existing methods may underperform; foundation models may transfer knowledge across tasks and improve forecasts without heavy task-specific tuning.

Method: Use U.S. Census Bureau and FRED datasets to build state-level time series across several demographic groups in six states. Evaluate a pre-trained Time Series Foundation Model (TimesFM) against baselines (LSTM, ARIMA, Linear Regression) using Mean Squared Error on test splits.

Result: TimesFM attained the lowest MSE in 86.67% of evaluated test cases, with pronounced improvements on minority populations where historical data is sparse. Traditional baselines performed worse overall.

Conclusion: Pre-trained time-series foundation models show promise for improving demographic forecasting and for enabling better policy planning with less task-specific fine-tuning. However, more details (pretraining data, model size, horizons, uncertainty quantification, baseline tuning, statistical significance) are needed to assess robustness and generalizability.

Abstract: Demographic shifts, influenced by globalization, economic conditions,
geopolitical events, and environmental factors, pose significant challenges for
policymakers and researchers. Accurate demographic forecasting is essential for
informed decision-making in areas such as urban planning, healthcare, and
economic policy. This study explores the application of time series foundation
models to predict demographic changes in the United States using datasets from
the U.S. Census Bureau and Federal Reserve Economic Data (FRED). We evaluate
the performance of the Time Series Foundation Model (TimesFM) against
traditional baselines including Long Short-Term Memory (LSTM) networks,
Autoregressive Integrated Moving Average (ARIMA), and Linear Regression. Our
experiments across six demographically diverse states demonstrate that TimesFM
achieves the lowest Mean Squared Error (MSE) in 86.67% of test cases, with
particularly strong performance on minority populations with sparse historical
data. These findings highlight the potential of pre-trained foundation models
to enhance demographic analysis and inform proactive policy interventions
without requiring extensive task-specific fine-tuning.

</details>


### [327] [From Heuristics to Data: Quantifying Site Planning Layout Indicators with Deep Learning and Multi-Modal Data](https://arxiv.org/abs/2508.11723)
*Qian Cao,Jielin Chen,Junchao Zhao,Rudi Stouffs*

Main category: cs.LG

TL;DR: SPLI는 OSM, POI, 건물 형태, 토지이용, 위성영상 등 다중 소스 데이터를 통합해 건물 기능의 계층적 분류, 7가지 공간배치 패턴, 기능다양성(FR·Simpson), 필수시설 접근성, 토지이용집약도(FAR·BCR) 등 5개 차원 지표를 제안하고, RGNN/GNN으로 데이터 격차를 보완해 기능 분류 정확도를 개선한 자동화된 도시공간 분석 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 전통적 부지계획은 경험적 판단과 단일 데이터에 의존해 다기능적 공간배치의 체계적 계량이 어렵고, 표준화된 분석·검색·추론 기반이 부족하므로 다중소스·데이터드리븐 지표체계가 필요하다.

Method: OSM·POI·건물형태·토지이용·위성영상을 결합해 구조화된 공간정보를 생성하고, (1) 계층적 건물기능 분류, (2) 7가지 공간조직 패턴 수치화, (3) 기능다양성(FR·Simpson) 지표화, (4)시설분포·교통망 통합 접근성 지표, (5)FAR·BCR 기반 토지이용집약도 등을 계산한다. 결측·모호데이터는 RGNN/GNN으로 보완하고 분류 정확도를 향상시킨다.

Result: 실험에서 기능 분류 정확도가 향상되었고, SPLI가 자동화된 데이터 기반의 도시공간 분석·추론·검색을 위한 표준화된 기초를 제공함을 보였다.

Conclusion: SPLI는 다중모드 데이터를 이용해 부지계획의 정량적·표준화된 분석을 가능하게 하며, 도시계획·정책평가·디지털트윈 등 실무 적용 가능성이 크지만 더 넓은 지역·시간대에 대한 검증과 민감도 분석이 필요하다.

Abstract: The spatial layout of urban sites shapes land-use efficiency and spatial
organization. Traditional site planning often relies on experiential judgment
and single-source data, limiting systematic quantification of multifunctional
layouts. We propose a Site Planning Layout Indicator (SPLI) system, a
data-driven framework integrating empirical knowledge with heterogeneous
multi-source data to produce structured urban spatial information. The SPLI
supports multimodal spatial data systems for analytics, inference, and
retrieval by combining OpenStreetMap (OSM), Points of Interest (POI), building
morphology, land use, and satellite imagery. It extends conventional metrics
through five dimensions: (1) Hierarchical Building Function Classification,
refining empirical systems into clear hierarchies; (2) Spatial Organization,
quantifying seven layout patterns (e.g., symmetrical, concentric,
axial-oriented); (3) Functional Diversity, transforming qualitative assessments
into measurable indicators using Functional Ratio (FR) and Simpson Index (SI);
(4) Accessibility to Essential Services, integrating facility distribution and
transport networks for comprehensive accessibility metrics; and (5) Land Use
Intensity, using Floor Area Ratio (FAR) and Building Coverage Ratio (BCR) to
assess utilization efficiency. Data gaps are addressed through deep learning,
including Relational Graph Neural Networks (RGNN) and Graph Neural Networks
(GNN). Experiments show the SPLI improves functional classification accuracy
and provides a standardized basis for automated, data-driven urban spatial
analytics.

</details>


### [328] [Causal Structure Learning in Hawkes Processes with Complex Latent Confounder Networks](https://arxiv.org/abs/2508.11727)
*Songyao Jin,Biwei Huang*

Main category: cs.LG

TL;DR: 연속시간 다변량 호크스 과정을 이산시간 근사로 표현하여, 시간 간격이 작아질 때 잠재 서브프로세스와 인과관계의 식별 가능성을 위한 필요충분조건을 제시한다. 경로 기반 조건에 따라 잠재 서브프로세스를 반복적으로 발견하고 인과구조를 추정하는 두 단계 반복 알고리즘을 제안하며, 합성·실세계 데이터 실험에서 유효성을 보임.


<details>
  <summary>Details</summary>
Motivation: 실세계 이벤트 시스템은 종종 일부 서브프로세스가 관측되지 않아 기존 인과발견 기법들이 실패한다. 잠재 서브프로세스가 존재할 때도 인과구조를 신뢰성 있게 복원하는 이론적·실무적 방법론이 필요하다.

Method: 연속시간 이벤트열을 시간 간격 Δ→0로 두는 이산시간 모델로 근사해 식별성 분석을 수행. 이로부터 잠재 서브프로세스와 인과영향의 필요·충분 조건(경로 기반)을 유도하고, 발견된 서브프로세스들 간의 인과추정 단계와 새로운 잠재서브프로세스 탐색 단계를 교대로 수행하는 두-단계 반복 알고리즘을 설계.

Result: 식별성 조건이 충족될 때 제안 기법이 잠재 서브프로세스와 인과관계를 회복함을 합성 데이터와 실세계 데이터 실험을 통해 보임. 실험에서 기존 방법들보다 잠재요인 존재 시 성능 우수성 시사.

Conclusion: 경로 기반 식별성 이론과 반복적 발견·추정 알고리즘을 통해 부분 관측된 다변량 호크스 과정의 인과구조 복원이 가능함을 제시. 다만 경로 가정, 이산화(Δ) 선택, 계산복잡도 등에 대한 한계와 민감도 분석이 추가로 필요하다.

Abstract: Multivariate Hawkes process provides a powerful framework for modeling
temporal dependencies and event-driven interactions in complex systems. While
existing methods primarily focus on uncovering causal structures among observed
subprocesses, real-world systems are often only partially observed, with latent
subprocesses posing significant challenges. In this paper, we show that
continuous-time event sequences can be represented by a discrete-time model as
the time interval shrinks, and we leverage this insight to establish necessary
and sufficient conditions for identifying latent subprocesses and the causal
influences. Accordingly, we propose a two-phase iterative algorithm that
alternates between inferring causal relationships among discovered subprocesses
and uncovering new latent subprocesses, guided by path-based conditions that
guarantee identifiability. Experiments on both synthetic and real-world
datasets show that our method effectively recovers causal structures despite
the presence of latent subprocesses.

</details>


### [329] [FedUHD: Unsupervised Federated Learning using Hyperdimensional Computing](https://arxiv.org/abs/2508.12021)
*You Hak Lee,Xiaofan Yu,Quanling Zhao,Flavio Ponzina,Tajana Rosing*

Main category: cs.LG

TL;DR: FedUHD는 하이퍼디멘셔널 컴퓨팅(HDC)을 이용한 최초의 비지도 연합학습(UFL) 프레임워크로, 경량 연산·모델 크기·통신 내성 면에서 기존 NN 기반 방법보다 훨씬 효율적이다. 클라이언트 측의 kNN 기반 클러스터 하이퍼벡터 제거와 서버 측의 가중치 HDC 집계를 도입해 비IID 문제와 통신 잡음에 강하다.


<details>
  <summary>Details</summary>
Motivation: UFL은 라벨링이 없는 프라이버시 민감한 환경에서 중요하지만, (1) 디바이스 간 비IID 데이터, (2) 에지의 높은 연산·통신 비용, (3) 통신 잡음에의 취약성 등 실사용 장애가 있다. 기존 연구는 대부분 무거운 NN에 의존해 이 문제들을 악화시킨다.

Method: FedUHD는 HDC 기반 모델을 사용한다. 클라이언트에서는 kNN 기반 클러스터 하이퍼벡터 제거로 데이터 내 해로운 이상치를 제거하고, 서버에서는 가중치 HDC 집계를 통해 클라이언트 간 비IID를 보정한다. 전체 파이프라인은 경량 연산과 작은 모델 크기를 지향한다.

Result: 실험에서 FedUHD는 학습 속도에서 최대 173.6×, 에너지 효율에서 최대 612.7× 개선을 보였고, 통신 비용은 최대 271× 감소했으며, 평균 정확도는 기존 NN 기반 UFL 대비 15.50% 향상되었다. 또한 다양한 잡음 유형에 대해 우수한 로버스트성을 보였다.

Conclusion: HDC는 연합학습의 가벼운 대안이 될 수 있으며, FedUHD는 비IID·리소스 제한·통신 잡음 문제를 효과적으로 완화한다. 이는 에지 환경에서 UFL을 현실적으로 적용할 가능성을 크게 높인다.

Abstract: Unsupervised federated learning (UFL) has gained attention as a
privacy-preserving, decentralized machine learning approach that eliminates the
need for labor-intensive data labeling. However, UFL faces several challenges
in practical applications: (1) non-independent and identically distributed
(non-iid) data distribution across devices, (2) expensive computational and
communication costs at the edge, and (3) vulnerability to communication noise.
Previous UFL approaches have relied on deep neural networks (NN), which
introduce substantial overhead in both computation and communication. In this
paper, we propose FedUHD, the first UFL framework based on Hyperdimensional
Computing (HDC). HDC is a brain-inspired computing scheme with lightweight
training and inference operations, much smaller model size, and robustness to
communication noise. FedUHD introduces two novel HDC-based designs to improve
UFL performance. On the client side, a kNN-based cluster hypervector removal
method addresses non-iid data samples by eliminating detrimental outliers. On
the server side, a weighted HDC aggregation technique balances the non-iid data
distribution across clients. Our experiments demonstrate that FedUHD achieves
up to 173.6x and 612.7x better speedup and energy efficiency, respectively, in
training, up to 271x lower communication cost, and 15.50% higher accuracy on
average across diverse settings, along with superior robustness to various
types of noise compared to state-of-the-art NN-based UFL approaches.

</details>


### [330] [BRIEF: BRain-Inspired network connection search with Extensive temporal feature Fusion enhances disease classification](https://arxiv.org/abs/2508.11732)
*Xiangxiang Cui,Min Zhao,Dongmei Zhi,Shile Qi,Vince D Calhoun,Jing Sui*

Main category: cs.LG

TL;DR: 제안된 BRIEF는 Q-러닝 기반 신경망 연결 탐색(NCS)과 Transformer 기반 멀티-피처 융합을 결합해 fMRI에서 자동으로 네트워크 구조를 최적화하고 시간적/정적 기능 연결 및 다중 스케일 특성들을 융합해 정신질환(조현병, ASD) 분류 성능을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 기존 fMRI 분류 모델들은 네트워크 구조 설계가 경험에 의존하고, 여러 종류 특징의 융합이 단순 병합에 그쳐 상호학습을 반영하지 못한다. 인간 뇌의 학습-의사결정 메커니즘에서 영감을 받아 구조 최적화와 상호종속적 특징 융합을 구현하고자 함.

Method: TCs, FNC, dFNC, MsDE의 4종 시간적 표현을 추출하여 각기 인코더를 구성. 각 인코더 내부에서 NCS를 MDP로 정식화하고 수정된 Q-러닝으로 동적으로 최적 연결을 탐색해 고수준 특징 벡터 추출. 추출된 특징들은 Transformer로 융합하여 안정적/시간변화 연결과 다중스케일 의존성을 학습. 해석성을 위해 어텐션 모듈 추가.

Result: SZ(n=1100)와 ASD(n=1550) 분류에서 21개 비교 알고리즘 대비 2.2%~12.1% 우위, SZ AUC 91.5%±0.6%, ASD AUC 78.4%±0.5% 보고.

Conclusion: 뇌영감을 받은 강화학습 기반 구조 탐색과 Transformer 융합은 fMRI 기반 정신질환 분류에서 유의미한 성능 향상을 보였으며, 정밀 신경영상 바이오마커 발굴에 잠재력이 있다.

Abstract: Existing deep learning models for functional MRI-based classification have
limitations in network architecture determination (relying on experience) and
feature space fusion (mostly simple concatenation, lacking mutual learning).
Inspired by the human brain's mechanism of updating neural connections through
learning and decision-making, we proposed a novel BRain-Inspired feature Fusion
(BRIEF) framework, which is able to optimize network architecture automatically
by incorporating an improved neural network connection search (NCS) strategy
and a Transformer-based multi-feature fusion module. Specifically, we first
extracted 4 types of fMRI temporal representations, i.e., time series (TCs),
static/dynamic functional connection (FNC/dFNC), and multi-scale dispersion
entropy (MsDE), to construct four encoders. Within each encoder, we employed a
modified Q-learning to dynamically optimize the NCS to extract high-level
feature vectors, where the NCS is formulated as a Markov Decision Process.
Then, all feature vectors were fused via a Transformer, leveraging both
stable/time-varying connections and multi-scale dependencies across different
brain regions to achieve the final classification. Additionally, an attention
module was embedded to improve interpretability. The classification performance
of our proposed BRIEF was compared with 21 state-of-the-art models by
discriminating two mental disorders from healthy controls: schizophrenia (SZ,
n=1100) and autism spectrum disorder (ASD, n=1550). BRIEF demonstrated
significant improvements of 2.2% to 12.1% compared to 21 algorithms, reaching
an AUC of 91.5% - 0.6% for SZ and 78.4% - 0.5% for ASD, respectively. This is
the first attempt to incorporate a brain-inspired, reinforcement learning
strategy to optimize fMRI-based mental disorder classification, showing
significant potential for identifying precise neuroimaging biomarkers.

</details>


### [331] [Scalable Geospatial Data Generation Using AlphaEarth Foundations Model](https://arxiv.org/abs/2508.11739)
*Luc Houriez,Sebastian Pilarski,Behzad Vahedi,Ali Ahmadalipour,Teo Honda Scully,Nicholas Aflitto,David Andre,Caroline Jaffe,Martha Wedner,Rich Mazzola,Josh Jeffery,Ben Messinger,Sage McGinley-Smith,Sarah Russell*

Main category: cs.LG

TL;DR: AlphaEarth Foundations(AEF)의 전지구적 지구공간 표현을 이용해 소수 지역에만 라벨이 있는 지리공간 데이터셋을 다른 지역(미국→캐나다)으로 확장하는 방법을 제안. 단순한 분류기(랜덤포레스트, 로지스틱 회귀)로도 EvtPhys(13개)에서 81%/73% 정확도를 달성.


<details>
  <summary>Details</summary>
Motivation: 고품질 라벨 지리공간 데이터는 중요하지만 지역적으로 제한된 경우가 많아 전지구적 적용이 어렵다. AEF는 전지구적이고 정보가 풍부한 표현을 제공해 라벨의 지리적 확장을 가능하게 할 수 있다는 점이 동기이다.

Method: AEF에서 추출한 전지구적 특성값을 입력으로 사용해 기존 라벨(미국 LANDFIRE EVT)을 학습한 후 캐나다로 예측을 확장. 단순 분류기(랜덤포레스트, 로지스틱 회귀)를 사용해 두 수준(EvtPhys 13클래스, EvtGp 80클래스)에서 평가.

Result: EvtPhys 수준에서 정성적으로 지상 진실과 일치하는 예측을 보였고, 검증셋 분류 정확도는 미국 81%, 캐나다 73%를 기록. EvtGp(80클래스)에 대한 상세 성과는 요약에 없음. 논문은 제한점들도 논의함.

Conclusion: AEF 같은 전지구적 표현은 라벨이 제한된 지역을 넘어 데이터셋을 확장하는 데 실용적이며, 복잡한 모델 없이도 유의미한 성능을 얻을 수 있다. 다만 분포 차이·라벨 품질·지역 고유성 등 한계 때문에 추가적 검증·도메인 적응·불확실성 추정이 필요하다.

Abstract: High-quality labeled geospatial datasets are essential for extracting
insights and understanding our planet. Unfortunately, these datasets often do
not span the entire globe and are limited to certain geographic regions where
data was collected. Google DeepMind's recently released AlphaEarth Foundations
(AEF) provides an information-dense global geospatial representation designed
to serve as a useful input across a wide gamut of tasks. In this article we
propose and evaluate a methodology which leverages AEF to extend geospatial
labeled datasets beyond their initial geographic regions. We show that even
basic models like random forests or logistic regression can be used to
accomplish this task. We investigate a case study of extending LANDFIRE's
Existing Vegetation Type (EVT) dataset beyond the USA into Canada at two levels
of granularity: EvtPhys (13 classes) and EvtGp (80 classes). Qualitatively, for
EvtPhys, model predictions align with ground truth. Trained models achieve 81%
and 73% classification accuracy on EvtPhys validation sets in the USA and
Canada, despite discussed limitations.

</details>


### [332] [Fed-DPRoC:Communication-Efficient Differentially Private and Robust Federated Learning](https://arxiv.org/abs/2508.12978)
*Yue Xia,Tayyebeh Jahani-Nezhad,Rawad Bitar*

Main category: cs.LG

TL;DR: Federated learning에서 차등 프라이버시(DP), Byzantine 강건성, 통신 효율성을 동시에 만족하는 Fed-DPRoC와 그 구현 RobAJoL(JL 변환 + robust averaging)을 제안. JL 변환의 거리 보존 특성 때문에 압축 후에도 강건한 집계가 유지되며 DP 보장과 통신 비용 절감이 이론·실험으로 입증됨.


<details>
  <summary>Details</summary>
Motivation: 실제 연합학습에서는 개인정보 보호(DP), 악의적 또는 결함 있는 클라이언트(바이잔틴) 대응, 낮은 통신비용이 동시에 필요하지만 이들 요구가 서로 충돌해 기존 방법은 일부 속성만 만족하거나 성능이 크게 저하됨. 이를 동시에 만족하는 통합적 프레임워크가 필요함.

Method: 'robust-compatible compression' 개념 도입. JL(Johnson–Lindenstrauss) 선형 투영을 압축 수단으로 사용하고, 압축된 업데이트에 대해 robust averaging 계열 집계(예: trimmed mean/median류)를 적용하는 RobAJoL 설계. 이론적으로 JL이 robust averaging과 호환됨을 증명하고, DP 기법(클리핑+노이즈)과의 조합에서 강건성·프라이버시·수렴 분석을 제공.

Result: 이론 결과: JL 투영의 거리 보존 성질이 robust aggregator의 결정 경계/이상치 판별을 본질적으로 손상하지 않음을 보임. RobAJoL은 DP 보장을 유지하면서 통신량을 줄이고, 다양한 Byzantine 공격 하에서 기존 방법보다 더 나은 정확도와 강건성을 보임. 실험(CIFAR-10, Fashion MNIST)으로 성능 우위와 이론 일치 확인.

Conclusion: JL 기반 선형 압축은 robust aggregation과 호환 가능하며, 이를 DP 메커니즘과 결합하면 통신효율적이면서도 바이잔틴에 강한 DP 연합학습을 구현할 수 있음. RobAJoL은 이 세 가지 속성을 동시에 달성하는 실용적 방안으로 제시됨.

Abstract: We propose Fed-DPRoC, a novel federated learning framework that
simultaneously ensures differential privacy (DP), Byzantine robustness, and
communication efficiency. We introduce the concept of robust-compatible
compression, which enables users to compress DP-protected updates while
maintaining the robustness of the aggregation rule. We instantiate our
framework as RobAJoL, combining the Johnson-Lindenstrauss (JL) transform for
compression with robust averaging for robust aggregation. We theoretically
prove the compatibility of JL transform with robust averaging and show that
RobAJoL preserves robustness guarantees, ensures DP, and reduces communication
cost. Experiments on CIFAR-10 and Fashion MNIST validate our theoretical claims
and demonstrate that RobAJoL outperforms existing methods in terms of
robustness and utility under different Byzantine attacks.

</details>


### [333] [Fed-Meta-Align: A Similarity-Aware Aggregation and Personalization Pipeline for Federated TinyML on Heterogeneous Data](https://arxiv.org/abs/2508.11794)
*Hemanth Macharla,Mayukha Pal*

Main category: cs.LG

TL;DR: 이 논문은 비동일(non-IID) 데이터와 자원 제한이 있는 IoT 환경에서 안정적 고성능 고장 분류를 위해 'Fed-Meta-Align'이라는 4단계 학습 파이프라인을 제안한다. 공개 데이터로 기초 모델을 학습한 뒤, 일련의 메타 초기화(순차적 장치별 적응), 병렬 연합학습(로컬 성능과 코사인 유사도를 고려한 이중 기준 집계), 그리고 장치별 개인화로 마무리한다. 평균 테스트 정확도 91.27%를 보고하며 FedAvg/FedProx 대비 유의미한 향상을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 자원 제약이 있는 이기종 IoT(Industrial IoT 포함) 장치에서 실시간 고장 분류 모델을 배포하려면, 장치별 데이터가 비IID일 때도 수렴하고 개인화 가능한 강건한 모델 초기화와 집계 전략이 필요하다. 표준 FL은 비IID 환경에서 발산하거나 성능이 저하되는 문제를 겪기 때문에 이를 해결할 방법이 요구된다.

Method: 4단계 프레임워크: (1) 공개 일반 데이터로 기초(foundation) 모델 사전학습, (2) 선택된 IoT 장치들에 대해 순차적 메타-초기화(serial meta-initialization)로 이질성을 반영한 유리한 초기점 획득, (3) 병렬 연합학습(Parallel FL)에서 로컬 성능과 매개체(모델 업데이트) 간 코사인 유사도를 동시에 고려하는 이중 기준(dual-criterion) 가중 집계, (4) 수렴된 글로벌 모델을 장치별로 추가 개인화(on-device personalization).

Result: 종합 실험에서 전체 이기종 IoT 장치에 대해 평균 테스트 정확도 91.27%를 달성. 전기 및 기계 고장 데이터셋에서 개인화된 FedAvg, FedProx 대비 각각 최대 3.87%, 3.37% 우수한 성능을 보고.

Conclusion: 단계적 초기화(선학습→순차 메타)와 적응적 이중기준 집계를 결합한 다단계 파이프라인은 비IID IoT 환경에서 강건한 학습 경로를 제공하며, TinyML 환경에 적용 가능한 개인화된 고장 진단 모델 배포에 유망하다.

Abstract: Real-time fault classification in resource-constrained Internet of Things
(IoT) devices is critical for industrial safety, yet training robust models in
such heterogeneous environments remains a significant challenge. Standard
Federated Learning (FL) often fails in the presence of non-IID data, leading to
model divergence. This paper introduces Fed-Meta-Align, a novel four-phase
framework designed to overcome these limitations through a sophisticated
initialization and training pipeline. Our process begins by training a
foundational model on a general public dataset to establish a competent
starting point. This model then undergoes a serial meta-initialization phase,
where it sequentially trains on a subset of IOT Device data to learn a
heterogeneity-aware initialization that is already situated in a favorable
region of the loss landscape. This informed model is subsequently refined in a
parallel FL phase, which utilizes a dual-criterion aggregation mechanism that
weights for IOT devices updates based on both local performance and cosine
similarity alignment. Finally, an on-device personalization phase adapts the
converged global model into a specialized expert for each IOT Device.
Comprehensive experiments demonstrate that Fed-Meta-Align achieves an average
test accuracy of 91.27% across heterogeneous IOT devices, outperforming
personalized FedAvg and FedProx by up to 3.87% and 3.37% on electrical and
mechanical fault datasets, respectively. This multi-stage approach of sequenced
initialization and adaptive aggregation provides a robust pathway for deploying
high-performance intelligence on diverse TinyML networks.

</details>


### [334] [Uncalibrated Reasoning: GRPO Induces Overconfidence for Stochastic Outcomes](https://arxiv.org/abs/2508.11800)
*Michael Bereket,Jure Leskovec*

Main category: cs.LG

TL;DR: 강화학습(RL)이 확실한(결정적) 분야에서 성능을 보인 것과 달리, 확률적 결과(예: 과학 실험)에서는 방법별로 확률 예측의 보정(calibration)이 다르게 나타난다. GRPO는 그룹 표준 정규화 때문에 이진 확률 예측에서 과신(overconfidence)을 유도하지만, PPO와 RLOO는 잘 보정된다. GRPO에서 그룹 표준 정규화를 제거하면 보정 문제가 해결되고, 이 현상에 대한 이론적 설명을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 결정적 도메인(수학 등)에서 RL로 언어모델 성능을 개선한 성과를, 확률적 결과가 있는 검증 가능한 도메인(과학적 실험 등)으로 확장할 수 있는지 검증하려는 목적이다. 특히, 모델 예측의 확률적 신뢰도(보정)가 실제 실험 적용에서 중요하므로 이를 평가한다.

Method: 합성 데이터와 실제 생물학 실험 데이터를 사용해 GRPO, PPO, RLOO 세 가지 RL 방법을 비교했다. 각 방법의 이진 확률 예측 보정도를 측정하고, GRPO의 그룹 표준 정규화 항을 제거하는 소거 실험을 수행했다. 또한 정규화가 과신을 유발하는 이유에 대한 이론적 분석을 제공했다.

Result: GRPO(그룹 표준 정규화 포함)는 이진 확률 예측에서 과신을 보였고, PPO와 RLOO는 잘 보정된 예측을 보였다. GRPO에서 그룹 표준 정규화를 제거하면 과신 문제가 해결된다. 이론적 분석은 정규화가 확률 추정의 분산-편향 구조에 영향을 주어 과신을 유발함을 설명한다.

Conclusion: GRPO에서의 표준 그룹 정규화 사용은 이진 확률 예측 보정에 해롭다. 표준 정규화를 제거하거나 대체하는 것이 필요하며, 이는 확률적 결과를 다루는 언어모델의 RL 응용에 중요한 실용적 시사점을 제공한다.

Abstract: Reinforcement learning (RL) has proven remarkably effective at improving the
accuracy of language models in verifiable and deterministic domains like
mathematics. Here, we examine if current RL methods are also effective at
optimizing language models in verifiable domains with stochastic outcomes, like
scientific experiments. Through applications to synthetic data and real-world
biological experiments, we demonstrate that Group Relative Policy Optimization
(GRPO) induces overconfident probability predictions for binary stochastic
outcomes, while Proximal Policy Optimization (PPO) and REINFORCE Leave-One-Out
(RLOO) yield well-calibrated models. We show that removing group standard
normalization in GRPO fixes its miscalibration and provide a theoretical
explanation for why normalization causes overconfidence. Our results provide
new evidence against the use of standard normalization in GRPO and help pave
the way for applications of RL for reasoning language models beyond
deterministic domains.

</details>


### [335] [FairTabGen: Unifying Counterfactual and Causal Fairness in Synthetic Tabular Data Generation](https://arxiv.org/abs/2508.11810)
*Nitish Nagesh,Salar Shakibhamedan,Mahdi Bagheri,Ziyu Wang,Nima TaheriNejad,Axel Jantsch,Amir M. Rahmani*

Main category: cs.LG

TL;DR: FairTabGen은 대형 언어 모델(LLM)을 활용해 공개·저자표본이 적은 표 형식 데이터에서 공정성(특히 반사실적·인과적 공정성)을 보장하면서 유틸리티를 유지하는 합성 데이터 생성 프레임워크다. 소량(20% 미만)의 원본 데이터로도 기존 GAN·LLM 기반 방법들보다 최대 약 10%의 공정성 개선을 보고한다.


<details>
  <summary>Details</summary>
Motivation: 표 형식 데이터는 실무에서 널리 사용되지만 개인정보 민감성·데이터 부족 문제로 합성 데이터의 필요성이 크다. 특히 단순한 통계적 공정성(예: 인구통계적 동등성)뿐 아니라 반사실적(counterfactual)·인과적(causal) 공정성을 확보하는 것이 중요하다.

Method: FairTabGen은 여러 공정성 정의(대응·경로 특정 인과효과 등)를 생성·평가 파이프라인에 통합한다. 인컨텍스트 러닝, 프롬프트 정교화, 공정성 인식 데이터 큐레이션 등을 활용해 공정성과 통계적 유틸리티 간 균형을 맞춘다. LLM을 합성기(modelling/generation)로 사용하고, 공정성 측정치를 반복적으로 반영해 샘플을 선별·정제한다.

Result: 다양한 데이터셋에서 기존 GAN 기반·LLM 기반 기법을 능가하며, 인구통계적 균형 및 경로특정 인과효과(path-specific causal effects) 같은 지표에서 최대 약 10% 개선을 보고한다. 통계적 유틸리티는 유지되며, 20% 미만의 데이터만으로도 성능을 달성해 저데이터 환경에서 효율적임을 주장한다.

Conclusion: 반사실적·인과적 공정성을 명시적으로 다루는 LLM 기반 합성 데이터 생성 접근은 실무적 가치가 크며, 특히 저데이터·프라이버시 민감 환경에서 공정성과 유틸리티를 동시에 확보할 수 있는 실용적 해법임을 보인다.

Abstract: Generating synthetic data is crucial in privacy-sensitive, data-scarce
settings, especially for tabular datasets widely used in real-world
applications. A key challenge is improving counterfactual and causal fairness,
while preserving high utility. We present FairTabGen, a fairness-aware large
language model-based framework for tabular synthetic data generation. We
integrate multiple fairness definitions including counterfactual and causal
fairness into both its generation and evaluation pipelines. We use in-context
learning, prompt refinement, and fairness-aware data curation to balance
fairness and utility. Across diverse datasets, our method outperforms
state-of-the-art GAN-based and LLM-based methods, achieving up to 10%
improvements on fairness metrics such as demographic parity and path-specific
causal effects while retaining statistical utility. Remarkably, it achieves
these gains using less than 20% of the original data, highlighting its
efficiency in low-data regimes. These results demonstrate a principled and
practical approach for generating fair and useful synthetic tabular data.

</details>


### [336] [Combinations of Fast Activation and Trigonometric Functions in Kolmogorov-Arnold Networks](https://arxiv.org/abs/2508.11876)
*Hoang-Thang Ta,Duy-Quy Thai,Phuong-Linh Tran-Thi*

Main category: cs.LG

TL;DR: 저자는 Kolmogorov-Arnold 네트워크(KAN)에 ReLU와 삼각함수 같은 GPU 친화적 기반함수를 도입해 계산 효율을 높이고 성능을 유지하려 함. 실험에서 학습시간 및 일반화에서 이점이 관찰됨.


<details>
  <summary>Details</summary>
Motivation: 기존 KAN 연구는 B-스플라인과 RBF 같은 다항/기저함수를 사용했지만, 이 함수들은 GPU 지원이 충분치 않고 효율성이 낮아 실제 활용에 제약이 있다. 따라서 더 빠른 계산이 가능한 함수(예: ReLU, sin, cos, arctan)를 KAN의 기저로 사용해 효율성과 실용성을 개선하려는 동기.

Method: KAN 구조에 ReLU와 삼각함수(및 arctan 등)를 기저함수로 통합. 다양한 함수 조합을 실험하여 학습시간, 계산비용, 및 예측성능을 비교 평가. GPU 상에서의 구현 효율성을 고려해 네트워크 구조와 연산을 최적화함.

Result: 제안된 기저함수 조합이 기존 B-스플라인/RBF 기반 KAN에 비해 계산 효율성(학습시간 단축 등)에서 이점을 보였고, 예측 성능은 경쟁력 있게 유지됨. 일반화 성능에서도 일부 개선이 관찰됨.

Conclusion: GPU 친화적 활성함수(특히 ReLU 및 삼각함수)를 KAN에 도입하면 실용적 성능과 효율성을 동시에 개선할 수 있으며, KAN의 실무 적용 가능성이 높아진다.

Abstract: For years, many neural networks have been developed based on the
Kolmogorov-Arnold Representation Theorem (KART), which was created to address
Hilbert's 13th problem. Recently, relying on KART, Kolmogorov-Arnold Networks
(KANs) have attracted attention from the research community, stimulating the
use of polynomial functions such as B-splines and RBFs. However, these
functions are not fully supported by GPU devices and are still considered less
popular. In this paper, we propose the use of fast computational functions,
such as ReLU and trigonometric functions (e.g., ReLU, sin, cos, arctan), as
basis components in Kolmogorov-Arnold Networks (KANs). By integrating these
function combinations into the network structure, we aim to enhance
computational efficiency. Experimental results show that these combinations
maintain competitive performance while offering potential improvements in
training time and generalization.

</details>


### [337] [PCA- and SVM-Grad-CAM for Convolutional Neural Networks: Closed-form Jacobian Expression](https://arxiv.org/abs/2508.11880)
*Yuto Omae*

Main category: cs.LG

TL;DR: CNN에 PCA 또는 SVM 층을 결합할 때 기존 Grad-CAM을 확장한 방법을 제안. PCA-Grad-CAM과 SVM-Grad-CAM을 통해 마지막 컨볼루션층에서 PCA/SVM으로 가는 닫힌형 자코비안(편미분)을 유도하고 이를 시각화에 적용함.


<details>
  <summary>Details</summary>
Motivation: 학습 샘플이 제한된 상황에서 CNN에 PCA 층이나 SVM 분류기를 결합하면 성능 향상을 기대할 수 있으나, 기존 Grad-CAM은 PCA/SVM 층에 바로 적용 불가능함. 따라서 PCA·SVM 층까지의 주의 영역 시각화 방법이 필요함.

Method: 마지막 컨볼루션층에서 PCA와 SVM 층으로 이어지는 편미분들의 닫힌형 자코비안을 해석적으로 유도하여, 이를 기반으로 PCA-Grad-CAM과 SVM-Grad-CAM을 정의. 유도된 자코비안을 사용해 각 특징벡터와 분류기 예측에 기여하는 입력 공간의 영역을 가시화함.

Result: 논문은 정확한 닫힌형 자코비안 유도식을 제시하고, 여러 주요 데이터셋에 대해 제안한 시각화 기법의 결과를 제시함(정확한 정량평가 내용은 초록에 없음).

Conclusion: PCA 및 SVM을 포함한 CNN 구조에서도 Grad-CAM 스타일의 해석 가능성 확보가 가능하며, 제시한 닫힌형 자코비안이 그 핵심임.

Abstract: Convolutional Neural Networks (CNNs) are an effective approach for
classification tasks, particularly when the training dataset is large. Although
CNNs have long been considered a black-box classification method, they can be
used as a white-box method through visualization techniques such as Grad-CAM.
When training samples are limited, incorporating a Principal Component Analysis
(PCA) layer and/or a Support Vector Machine (SVM) classifier into a CNN can
effectively improve classification performance. However, traditional Grad-CAM
cannot be directly applied to PCA and/or SVM layers. It is important to
generate attention regions for PCA and/or SVM layers in CNNs to facilitate the
development of white-box methods. Therefore, we propose ``PCA-Grad-CAM'', a
method for visualizing attention regions in PCA feature vectors, and
``SVM-Grad-CAM'', a method for visualizing attention regions in an SVM
classifier layer. To complete our methods analytically, it is necessary to
solve the closed-form Jacobian consisting of partial derivatives from the last
convolutional layer to the PCA and/or SVM layers. In this paper, we present the
exact closed-form Jacobian and the visualization results of our methods applied
to several major datasets.

</details>


### [338] [ENA: Efficient N-dimensional Attention](https://arxiv.org/abs/2508.11921)
*Yibo Zhong*

Main category: cs.LG

TL;DR: Ultra-long 고차원 데이터 모델링을 위해 선형 순환(linear recurrence)과 타일형 고차원 슬라이딩 윈도우 어텐션(SWA)을 결합한 하이브리드 구조 ENA(Efficient N-dimensional Attention)를 제안한다. 스캐닝 전략은 한계가 있고, 어텐션-하이브리드가 실용적·효율적임을 보였다.


<details>
  <summary>Details</summary>
Motivation: Transformer는 초장(ultra-long) 고차원(ND) 데이터에 비효율적이다. 언어모델링용 선형 순환 모델을 고차원 데이터로 확장할 때 어떤 스캐닝 전략과 어텐션 결합이 효율적·실용적인지 규명할 필요가 있다.

Method: 스캐닝 전략과 어텐션-하이브리드 구조를 비교 실험. 하이브리드 중 다수의 어텐션 유형을 평가하여 '타일형 고차원 슬라이딩 윈도우 어텐션'을 채택. 선형 순환은 전역 정보를 상태로 압축하고, SWA는 엄격한 국소 모델링을 담당하는 구조(ENA)를 설계·평가.

Result: 실험에서 스캐닝은 제한적 이득만 보였고, 어텐션-하이브리드가 더 유망했다. 타일형 고차원 SWA는 이론·실무 모두에서 효율적이었고, ENA가 초장 고차원 데이터 모델링에서 좋은 성능·효율성을 보였다.

Conclusion: 선형 순환과 타일형 고차원 SWA의 간단한 결합(ENA)은 초장 고차원 데이터에 대해 실용적이고 효율적인 솔루션을 제공한다. 전역 압축과 엄격한 국소 모델링의 보완적 역할이 주요한 설계 직관이다.

Abstract: Efficient modeling of long sequences of high-order data requires a more
efficient architecture than Transformer. In this paper, we investigate two key
aspects of extending linear recurrent models, especially those originally
designed for language modeling, to high-order data (1D to ND): scanning
strategies and attention-hybrid architectures. Empirical results suggest that
scanning provides limited benefits, while attention-hybrid models yield
promising results. Focusing on the latter, we further evaluate types of
attention and find that tiled high-order sliding window attention (SWA) is
efficient in both theory and practice. We term the resulting hybrid
architecture of linear recurrence and high-order SWA as Efficient N-dimensional
Attention (ENA). We then conduct several experiments to demonstrate its
effectiveness. The intuition behind ENA is that linear recurrence compresses
global information into a state, while SWA complements it by enforcing strict
local modeling. Together, they form a simple framework that offers a promising
and practical solution for ultra-long high-order data modeling.

</details>


### [339] [Scale-Disentangled spatiotemporal Modeling for Long-term Traffic Emission Forecasting](https://arxiv.org/abs/2508.11923)
*Yan Wu,Lihong Pei,Yukai Han,Yang Cao,Yu Kang,Yanlong Zhao*

Main category: cs.LG

TL;DR: 장기 교통 배출 예측에서 시공간 그래프 모델이 스케일 혼합으로 인한 장기 추론 시 오류 증폭을 겪는 문제를 해결하기 위해, Koopman 리프팅과 게이트형 웨이블릿 분해를 이용한 이중 스트림 스케일 분리·융합(SDSTM) 프레임워크를 제안한다. 듀얼 스트림 독립성 제약(교차항 손실)을 통해 상호 간섭을 억제하고 장기 예측 성능을 향상시키며, 시안(西安) 2환로 도로 수준 데이터에서 SOTA 성능을 보고한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 시공간 그래프 기반 장기 배출 예측은 시간·공간의 다중 스케일 얽힘으로 인해 예측 가능성이 다른 성분들이 섞이며, 장기 추론 시 단계적 오류 누적(캐스케이딩 오류 증폭)이 발생한다는 문제 인식에서 출발한다.

Method: (1) Koopman 리프팅을 통해 비선형 시공간 동역학을 선형 무한차원 공간으로 사상하고, (2) 게이트형 웨이블릿 분해로 예측 가능성 경계를 기준으로 특성들을 고·저(또는 다중) 스케일로 분해하는 이중 스트림 전략을 도입한다. (3) 이후 듀얼 스트림 예측 결과를 교차항 손실 기반의 독립성 제약을 포함한 융합 메커니즘으로 동적으로 정제해 상호 간섭을 줄이고 장기 예측 정확도를 높인다.

Result: 시안 2환로의 도로 단위 교통 배출 데이터셋에서 광범위한 실험을 수행하여 제안 모델이 기존 기법들보다 우수한 장기 예측 성능(논문 주장: SOTA)을 달성했다고 보고한다.

Conclusion: 스케일별 예측 가능성 차이를 활용한 분해·독립화·동적 융합으로 장기 추론 시 오류 증폭 문제를 완화하고 예측 정확도를 개선할 수 있으며, 제안된 SDSTM은 실험 데이터셋에서 그 효과를 입증했다.

Abstract: Long-term traffic emission forecasting is crucial for the comprehensive
management of urban air pollution. Traditional forecasting methods typically
construct spatiotemporal graph models by mining spatiotemporal dependencies to
predict emissions. However, due to the multi-scale entanglement of traffic
emissions across time and space, these spatiotemporal graph modeling method
tend to suffer from cascading error amplification during long-term inference.
To address this issue, we propose a Scale-Disentangled Spatio-Temporal Modeling
(SDSTM) framework for long-term traffic emission forecasting. It leverages the
predictability differences across multiple scales to decompose and fuse
features at different scales, while constraining them to remain independent yet
complementary. Specifically, the model first introduces a dual-stream feature
decomposition strategy based on the Koopman lifting operator. It lifts the
scale-coupled spatiotemporal dynamical system into an infinite-dimensional
linear space via Koopman operator, and delineates the predictability boundary
using gated wavelet decomposition. Then a novel fusion mechanism is
constructed, incorporating a dual-stream independence constraint based on
cross-term loss to dynamically refine the dual-stream prediction results,
suppress mutual interference, and enhance the accuracy of long-term traffic
emission prediction. Extensive experiments conducted on a road-level traffic
emission dataset within Xi'an's Second Ring Road demonstrate that the proposed
model achieves state-of-the-art performance.

</details>


### [340] [An Improved Algorithm for Adversarial Linear Contextual Bandits via Reduction](https://arxiv.org/abs/2508.11931)
*Tim van Erven,Jack Mayo,Julia Olkhovskaya,Chen-Yu Wei*

Main category: cs.LG

TL;DR: 본 논문은 적대적 손실(adversarial losses)과 확률적 행동집합(stochastic action sets)을 가지는 선형 문맥 밴딧 문제에 대해 다항시간으로 동작하면서도 \/~O(poly(d)\sqrt{T}) 수준의 후회(regret)를 달성하는 효율적 알고리즘을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 문맥 밴딧에서 행동집합이 라운드마다 달라지고 손실이 적대적으로 변할 때에도 계산적으로 효율적이면서 차원 d에 대해 다항식 의존성을 가지는 \sqrt{T} 후회를 얻을 수 있는가가 미해결 문제였다(특히 행동 수 K에 의존하지 않는 다항시간 알고리즘 여부). 조합적(combinatorial) 행동공간처럼 행동 수가 지수적일 수 있는 실용적 설정에서 이 문제는 중요하다.

Method: 문제를 고정 행동집합을 가지는 misspecification-robust 적대적 선형 밴딧 문제로 환원했다. 컨텍스트 분포나 시뮬레이터를 알 필요 없이(기본 결과) 환원을 통해 기존의 robust adversarial linear bandit 기법들을 활용하여 다항시간 알고리즘을 구성한다.

Result: 주된 보장은 \tilde{O}(\min\{d^2\sqrt{T},\,\sqrt{d^3 T\log K}\}) 후회와 폴리(d, C, T) 시간복잡도다. 여기서 C는 각 라운드의 선형 제약식 수(행동집합을 기술하는), K는 각 라운드의 행동 수 상한이다. 이로써 Liu et al. (2023)의 열린 문제(행동 수에 독립적으로 poly(d)\sqrt{T} 후회를 다항시간에 얻는지)가 해결된다. 또한, 제약식 수가 다항인 조합적 밴딧에서는 본 알고리즘이 다항(d)\sqrt{T} 후회를 다항시간에 처음 달성한다. 시뮬레이터가 주어지는 경우에는 보장이 \tilde{O}(d\sqrt{L^\star})로 개선된다(\,L^\star는 최적 정책의 누적 손실).

Conclusion: 계산적 효율성과 통계적 성능을 동시에 만족하는 새로운 경계선 결과를 제시한다. 다만 d에 대한 다소 큰 다항 종속성(예: d^2 혹은 d^{3/2} 등)과 tilde 표기 아래의 로그요인들이 남아 있으며, C나 K의 실제 값이 큰 경우 효율성·실용성 검토가 필요하다. 향후 과제로는 d 의존성의 최적화, 더 약한 가정(예: 더 일반적 행동집합 분포)으로의 확장, 또는 비확률적(action-set도 적대적) 상황으로의 일반화가 있다.

Abstract: We present an efficient algorithm for linear contextual bandits with
adversarial losses and stochastic action sets. Our approach reduces this
setting to misspecification-robust adversarial linear bandits with fixed action
sets. Without knowledge of the context distribution or access to a context
simulator, the algorithm achieves $\tilde{O}(\min\{d^2\sqrt{T}, \sqrt{d^3T\log
K}\})$ regret and runs in $\text{poly}(d,C,T)$ time, where $d$ is the feature
dimension, $C$ is an upper bound on the number of linear constraints defining
the action set in each round, $K$ is an upper bound on the number of actions in
each round, and $T$ is number of rounds. This resolves the open question by Liu
et al. (2023) on whether one can obtain $\text{poly}(d)\sqrt{T}$ regret in
polynomial time independent of the number of actions. For the important class
of combinatorial bandits with adversarial losses and stochastic action sets
where the action sets can be described by a polynomial number of linear
constraints, our algorithm is the first to achieve $\text{poly}(d)\sqrt{T}$
regret in polynomial time, while no prior algorithm achieves even $o(T)$ regret
in polynomial time to our knowledge. When a simulator is available, the regret
bound can be improved to $\tilde{O}(d\sqrt{L^\star})$, where $L^\star$ is the
cumulative loss of the best policy.

</details>


### [341] [M3OOD: Automatic Selection of Multimodal OOD Detectors](https://arxiv.org/abs/2508.11936)
*Yuehan Qin,Li Li,Defu Cao,Tiankai Yang,Yue Zhao*

Main category: cs.LG

TL;DR: M3OOD는 멀티모달 환경에서 역사적 모델 성능과 데이터의 멀티모달 임베딩·핸드크래프트 메타특징을 이용해 상황에 맞는 OOD 검출기를 메타러닝으로 추천하는 프레임워크로, 12개 시나리오에서 10개 경쟁기법보다 일관되게 우수했다.


<details>
  <summary>Details</summary>
Motivation: OOD 검출은 비지도 문제라 신규 분포에서 어떤 검출기가 잘 작동할지 예측하기 어렵고, 멀티모달 입력(비디오·오디오·센서 등)에서는 다양한 분포 이동이 존재해 단일 검출기가 모든 경우에 최적이 아니다. 따라서 최소한의 감독으로 새로운 분포 이동에 적합한 검출기를 자동으로 선택할 방법이 필요하다.

Method: 메타러닝 기반 프레임워크(M3OOD)를 제안한다. 데이터셋을 멀티모달 임베딩과 분포·교차모달 특성을 포착하는 핸드크래프트 메타특징으로 표현하고, 과거 다양한 멀티모달 벤치마크에서의 모델 성능 이력을 학습하여 새로운 분포에 대해 적합한 OOD 검출기를 추천한다.

Result: 실험에서 M3OOD는 12개의 테스트 시나리오에서 10개의 경쟁 베이스라인보다 일관되게 우수한 성능을 보였고, 계산 비용도 적다는 점을 보고한다.

Conclusion: 메타러닝을 활용한 데이터-기반 추천 방식으로 멀티모달 OOD 검출기 선택 문제를 효과적으로 해결할 수 있음을 보여주며, 과거 성능 이력과 메타특징 설계가 핵심 요소이다.

Abstract: Out-of-distribution (OOD) robustness is a critical challenge for modern
machine learning systems, particularly as they increasingly operate in
multimodal settings involving inputs like video, audio, and sensor data.
Currently, many OOD detection methods have been proposed, each with different
designs targeting various distribution shifts. A single OOD detector may not
prevail across all the scenarios; therefore, how can we automatically select an
ideal OOD detection model for different distribution shifts? Due to the
inherent unsupervised nature of the OOD detection task, it is difficult to
predict model performance and find a universally Best model. Also,
systematically comparing models on the new unseen data is costly or even
impractical. To address this challenge, we introduce M3OOD, a
meta-learning-based framework for OOD detector selection in multimodal
settings. Meta learning offers a solution by learning from historical model
behaviors, enabling rapid adaptation to new data distribution shifts with
minimal supervision. Our approach combines multimodal embeddings with
handcrafted meta-features that capture distributional and cross-modal
characteristics to represent datasets. By leveraging historical performance
across diverse multimodal benchmarks, M3OOD can recommend suitable detectors
for a new data distribution shift. Experimental evaluation demonstrates that
M3OOD consistently outperforms 10 competitive baselines across 12 test
scenarios with minimal computational overhead.

</details>


### [342] [Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware](https://arxiv.org/abs/2508.11940)
*Yuannuo Feng,Wenyong Zhou,Yuexi Lyu,Yixiang Zhang,Zhengwu Liu,Ngai Wong,Wang Kang*

Main category: cs.LG

TL;DR: 아날로그 CIM 하드웨어의 복잡한 잡음을 더 정확하게 모사하면서도 학습 시 계산량과 안정성을 유지하는 '확장된 STE' 기반 노이즈-인식 학습 기법을 제안. 정확도 및 퍼플렉시티 개선, 학습 속도 및 메모리 절감 효과를 보고함.


<details>
  <summary>Details</summary>
Motivation: 아날로그 Compute-In-Memory 하드웨어는 에너지 이점이 크지만 하드웨어 유래의 복잡하고 비가역적인 잡음 때문에 신경망 추론 성능이 크게 저하됨. 기존 노이즈-인식 학습은 미분 가능한 이상화된 노이즈 모델에 의존해 하드웨어 변동을 충분히 반영하지 못함.

Method: 앞향(forward)에서는 보다 정확하고 복잡한(비미분 가능·계산적으로 비현실적일 수 있는) 아날로그 노이즈 시뮬레이션을 적용하고, 역전파(backward)에서는 간단화된 미분 가능한 경로를 사용해 그래디언트 계산을 수행하는 STE(스트레이트-스루) 프레임워크를 확장. 이론적으로 그래디언트의 방향성 정보는 보존됨을 보임.

Result: 이미지 분류에서 최대 5.3% 정확도 향상, 텍스트 생성(perplexity)에서 0.72 감소, 학습 시간 2.2× 속도 향상, 피크 메모리 37.9% 절감 등 실험적 이득을 보고.

Conclusion: 복잡한 아날로그 노이즈 모델을 정확히 반영하면서도 학습의 계산적 실용성과 안정성을 유지하는 실용적 방법을 제시. 하드웨어-친화적 노이즈 적응 학습에서 유의미한 성능·효율 개선을 달성함.

Abstract: Analog Compute-In-Memory (CIM) architectures promise significant energy
efficiency gains for neural network inference, but suffer from complex
hardware-induced noise that poses major challenges for deployment. While
noise-aware training methods have been proposed to address this issue, they
typically rely on idealized and differentiable noise models that fail to
capture the full complexity of analog CIM hardware variations. Motivated by the
Straight-Through Estimator (STE) framework in quantization, we decouple forward
noise simulation from backward gradient computation, enabling noise-aware
training with more accurate but computationally intractable noise modeling in
analog CIM systems. We provide theoretical analysis demonstrating that our
approach preserves essential gradient directional information while maintaining
computational tractability and optimization stability. Extensive experiments
show that our extended STE framework achieves up to 5.3% accuracy improvement
on image classification, 0.72 perplexity reduction on text generation,
2.2$\times$ speedup in training time, and 37.9% lower peak memory usage
compared to standard noise-aware training methods.

</details>


### [343] [Learning Marked Temporal Point Process Explanations based on Counterfactual and Factual Reasoning](https://arxiv.org/abs/2508.11943)
*Sishun Liu,Ke Deng,Xiuzhen Zhang,Yan Wang*

Main category: cs.LG

TL;DR: MTPP 예측의 최소·합리적 설명(히스토리 내 최소 이벤트 subset)을 찾기 위해 반사실적·사실적 설명을 결합한 CFF를 제안. 실험에서 기존 방법보다 설명 품질과 효율성에서 우수함을 보임.


<details>
  <summary>Details</summary>
Motivation: 신경망 기반 MTPP가 고위험 분야에 도입되면서 예측의 신뢰성·설명 가능성 요구가 증가. 전체 히스토리를 의존하는 예측 대신 최소한의 히스토리로 동일한 성능을 내는 근거를 제공하고자 함.

Method: 반사실적(counterfactual)과 사실적(factual) 설명을 단독 사용하면 비합리적 결과가 생긴다는 관찰에서 출발, 두 유형을 결합한 설명 정의를 제안하고 이를 최적화하는 Counterfactual and Factual Explainer for MTPP(CFF)를 설계. 여러 기법(구체적 기술은 초록에 없음)을 적용해 최소 이벤트 집합을 탐색.

Result: 실험에서 CFF가 기존 기준선들보다 설명의 정확도(예측 성능 보존) 및 처리 효율성에서 우수함을 보임.

Conclusion: 반사실적·사실적 설명의 결합은 MTPP에 대해 더 합리적이고 최소한의 설명을 제공하며, 제안된 CFF가 실용적임을 보였음.

Abstract: Neural network-based Marked Temporal Point Process (MTPP) models have been
widely adopted to model event sequences in high-stakes applications, raising
concerns about the trustworthiness of outputs from these models. This study
focuses on Explanation for MTPP, aiming to identify the minimal and rational
explanation, that is, the minimum subset of events in history, based on which
the prediction accuracy of MTPP matches that based on full history to a great
extent and better than that based on the complement of the subset. This study
finds that directly defining Explanation for MTPP as counterfactual explanation
or factual explanation can result in irrational explanations. To address this
issue, we define Explanation for MTPP as a combination of counterfactual
explanation and factual explanation. This study proposes Counterfactual and
Factual Explainer for MTPP (CFF) to solve Explanation for MTPP with a series of
deliberately designed techniques. Experiments demonstrate the correctness and
superiority of CFF over baselines regarding explanation quality and processing
efficiency.

</details>


### [344] [Set-Valued Transformer Network for High-Emission Mobile Source Identification](https://arxiv.org/abs/2508.11976)
*Yunning Cao,Lihong Pei,Jian Guo,Yang Cao,Yu Kang,Yanlong Zhao*

Main category: cs.LG

TL;DR: 제안된 Set-Valued Transformer Network(SVTN)는 트랜스포머로 마이크로-트립의 시계열 유사성을 학습해 고차원 배출 데이터를 저차원 특징으로 투영하고, 집합값(확률적) 식별 알고리즘으로 특징-라벨 관계를 모델링해 고배출 차량 검출 성능을 향상시킨다. 2020년 합비(Heifei) 디젤 모니터링 데이터에서 기준 트랜스포머 대비 미검출률을 9.5% 감소시켰다.


<details>
  <summary>Details</summary>
Motivation: 실제 모니터링 데이터에서 고배출 상태 샘플이 매우 희소한 장기 꼬리 분포와 배출 상태의 높은 비선형성, 관련 사전 지식의 결여로 인해 판별적 특징 추출 및 식별 모델 학습이 어렵다.

Method: 1) 트랜스포머로 마이크로-트립의 시간적 유사성(시퀀스 패턴)을 측정해 고차원 배출 데이터를 저차원 특징공간으로 맵핑. 2) 집합값(확률적) 식별 알고리즘으로 생성된 특징벡터와 라벨 간의 관계를 확률적으로 모델링하여 분류 기준을 제시.

Result: 합비시 2020년 디젤 차량 모니터링 데이터 실험에서 제안 방법은 트랜스포머 기반 베이스라인 대비 고배출 차량의 미검출률을 9.5% 줄였음.

Conclusion: 제안 모델은 희소한 고배출 샘플로부터 판별적 특징을 학습해 검출 정확도를 개선하는 데 효과적이나, 데이터·평가·알고리즘 세부 사항(라벨링, 불균형 처리, 일반화성, 계산비용 등)이 명확히 제시되어야 실무적 적용성과 재현성이 확보될 것 같다.

Abstract: Identifying high-emission vehicles is a crucial step in regulating urban
pollution levels and formulating traffic emission reduction strategies.
However, in practical monitoring data, the proportion of high-emission state
data is significantly lower compared to normal emission states. This
characteristic long-tailed distribution severely impedes the extraction of
discriminative features for emission state identification during data mining.
Furthermore, the highly nonlinear nature of vehicle emission states and the
lack of relevant prior knowledge also pose significant challenges to the
construction of identification models.To address the aforementioned issues, we
propose a Set-Valued Transformer Network (SVTN) to achieve comprehensive
learning of discriminative features from high-emission samples, thereby
enhancing detection accuracy. Specifically, this model first employs the
transformer to measure the temporal similarity of micro-trip condition
variations, thus constructing a mapping rule that projects the original
high-dimensional emission data into a low-dimensional feature space. Next, a
set-valued identification algorithm is used to probabilistically model the
relationship between the generated feature vectors and their labels, providing
an accurate metric criterion for the classification algorithm. To validate the
effectiveness of our proposed approach, we conducted extensive experiments on
the diesel vehicle monitoring data of Hefei city in 2020. The results
demonstrate that our method achieves a 9.5\% reduction in the missed detection
rate for high-emission vehicles compared to the transformer-based baseline,
highlighting its superior capability in accurately identifying high-emission
mobile pollution sources.

</details>


### [345] [Efficient Modular Learning through Naive LoRA Summation: Leveraging Orthogonality in High-Dimensional Models](https://arxiv.org/abs/2508.11985)
*Zhanhao Cao,Clement Truong,Andrew Lizarraga*

Main category: cs.LG

TL;DR: LoRA 어댑터를 독립 도메인별로 학습한 뒤 단순 더하기로 합성하면 추가 학습 없이도 병합 데이터로 학습한 모델과 유사한 성능을 낼 수 있다. 어댑터 델타들 사이의 코사인 유사도가 높을수록 성능 저하(퍼플렉시티 증가)가 발생한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어모델의 성능은 규모로 향상되지만, 전체 파라미터를 재학습하는 비용이 커 PEFT(파라미터 효율 미세조정)가 주목받고 있다. LoRA는 작은 행렬 곱으로 파라미터 델타를 표현하므로 합성이 가능하다는 점에서 도메인 간 합성의 단순성·효율성을 탐구하고자 한다.

Method: GPT-2 Small(117M)에 LoRA(rank=4, alpha=64)를 적용해 수학, 의료, 금융 3개 QA 도메인별 어댑터를 독립 학습. 도메인별 어댑터를 쌍으로 더해(composition) 퍼플렉시티 변화를 측정하고, LoRA 델타들 간 RMS 코사인 유사도와 퍼플렉시티 변화의 상관관계를 분석.

Result: Math+Medicine 합성은 병합 학습 대비 퍼플렉시티를 -9.10% 개선했으나, Math+Finance는 +4.54%, Finance+Medicine은 +27.56%로 악화. 전체 조합에서 LoRA 델타 간 RMS 코사인 유사도는 퍼플렉시티 변화와 대체로 양의 선형 상관을 보였다.

Conclusion: 단순 덧셈 합성은 추가 학습 없이 빠르고 실용적이며, 도메인 간 간섭은 델타 유사도로 예측 가능하다. 다만 고차 조합에서는 간섭이 발생할 수 있어 조합 전 유사도 확인 또는 보정이 필요하다.

Abstract: Recent advances in large language models are driven by scale, while
parameter-efficient fine-tuning (PEFT) enables updating only a small fraction
of parameters. Low-Rank Adaptation (LoRA) stores parameter deltas as the
product of two small matrices, which makes them natural building blocks that
can be composed. Motivated by the superposition principle, we hypothesize that
independently trained LoRA modules on disjoint domains are approximately
orthogonal and can be combined by simple addition. Using GPT-2 Small (117M)
with LoRA rank 4 and alpha=64, we train adapters for three QA domains (math,
medicine, finance). In pairwise tests, adding Math+Medicine adapters improves
perplexity by -9.10% relative to merged-data fine-tuning, while Math+Finance
and Finance+Medicine change by +4.54% and +27.56%, respectively. Across
combinations, the RMS cosine similarity between LoRA deltas correlates
positively and approximately linearly with the change in perplexity. Naive
summation requires no additional training, can be applied in seconds, and
achieves performance comparable to models trained on merged data, while
clarifying when interference appears in higher-order compositions.

</details>


### [346] [Universal Learning of Nonlinear Dynamics](https://arxiv.org/abs/2508.11990)
*Evan Dogariu,Anand Brahmbhatt,Elad Hazan*

Main category: cs.LG

TL;DR: 스펙트럴 필터링 기반 알고리즘으로 과거 관측에서 다음 관측을 예측하며, 유한 개의 경계 안정(marginally stable) 모드를 가진 비선형 동적계에 대해 예측 오차가 소멸함을 보인다. 선형 시스템용 새로운 스펙트럴 필터링(비대칭성·잡음 보정 포함)과 온라인 볼록 최적화를 결합한 방법이다.


<details>
  <summary>Details</summary>
Motivation: 경계 안정(marginally stable) 특성을 가지는 미지의 비선형 동적계를 효과적으로 학습·예측하는 것은 제어·식별에서 기본적이나 기존 알고리즘이 잡음·비대칭·비선형성에 취약하고 이론적 보장이 제한적이다.

Method: 과거 관측을 입력으로 다음 출력을 예측하는 스펙트럴 표현을 사용한다. 핵심은 선형 동적계에 대한 새로운 스펙트럴 필터링 알고리즘으로, 과거 관측을 통합하고 잡음 보정과 비대칭 동역학을 처리한다. 이 예측기를 온라인 볼록 최적화 프레임워크로 학습시켜 누적 손실을 제어한다.

Result: 유한 개의 경계 안정 모드를 갖는 임의의 비선형 동적계에 대해 예측 오차가 시간에 따라 소멸함을 보이며, 수렴 속도는 제어이론적 ‘학습 가능성(learnability)’ 정량적 척도에 의해 지배된다.

Conclusion: 기존 스펙트럴 필터링을 비대칭성과 잡음 보정으로 일반화한 것이 주요 공헌이며, 이론적 보장(소멸하는 예측 오차)과 실용적 적용 가능성을 동시에 제공한다. 선형 알고리즘 자체도 독립적 기여가 된다.

Abstract: We study the fundamental problem of learning a marginally stable unknown
nonlinear dynamical system. We describe an algorithm for this problem, based on
the technique of spectral filtering, which learns a mapping from past
observations to the next based on a spectral representation of the system.
Using techniques from online convex optimization, we prove vanishing prediction
error for any nonlinear dynamical system that has finitely many marginally
stable modes, with rates governed by a novel quantitative control-theoretic
notion of learnability. The main technical component of our method is a new
spectral filtering algorithm for linear dynamical systems, which incorporates
past observations and applies to general noisy and marginally stable systems.
This significantly generalizes the original spectral filtering algorithm to
both asymmetric dynamics as well as incorporating noise correction, and is of
independent interest.

</details>


### [347] [Fairness Regularization in Federated Learning](https://arxiv.org/abs/2508.12042)
*Zahra Kharaghani,Ali Dadras,Tommy Löfstedt*

Main category: cs.LG

TL;DR: 연합학습(FL)에서 클라이언트 간 성능 격차를 줄이기 위해 클라이언트 손실을 정규화하는 방식들을 이론적으로 연결하고, 그래디언트 분산 정규화 기반의 FairGrad/FairGrad*가 이질적 데이터 환경에서 공정성과 전체 성능을 동시에 개선함을 보인다.


<details>
  <summary>Details</summary>
Motivation: 클라이언트 데이터의 이질성으로 인해 일부 클라이언트가 글로벌 모델에 과도하게 영향을 주거나 성능 편차가 발생하여 성능 공정성이 저하된다. 이를 해소하기 위해 손실 정규화를 통한 'performance equitable fairness'를 연구한다.

Method: 기존의 공정성-인식 방법들 중 클라이언트 손실을 명시적으로 정규화하는 기법들을 조사·정렬하고, 그래디언트 분산을 정규화하는 새로운 변형(근사형 FairGrad와 정확형 FairGrad*)을 제시한다. 또한 제안기법들과 기존기법 간의 이론적 연결성을 분석한다.

Result: 이론적 분석을 통해 기법들 간의 관계를 규명하고, 실험에서는 FairGrad 및 FairGrad*가 데이터 이질성이 큰 환경에서 공정성(클라이언트 간 성능 차이 감소)과 전체 모델 성능을 모두 향상시킴을 보여준다.

Conclusion: 클라이언트 손실 정규화, 특히 그래디언트 분산 정규화는 성능 공정성 문제에 효과적이며, 제안된 FairGrad 계열이 이질적 연합학습에서 유망한 접근임을 제시한다.

Abstract: Federated Learning (FL) has emerged as a vital paradigm in modern machine
learning that enables collaborative training across decentralized data sources
without exchanging raw data. This approach not only addresses privacy concerns
but also allows access to overall substantially larger and potentially more
diverse datasets, without the need for centralized storage or hardware
resources. However, heterogeneity in client data may cause certain clients to
have disproportionate impacts on the global model, leading to disparities in
the clients' performances. Fairness, therefore, becomes a crucial concern in FL
and can be addressed in various ways. However, the effectiveness of existing
fairness-aware methods, particularly in heterogeneous data settings, remains
unclear, and the relationships between different approaches are not well
understood. In this work, we focus on performance equitable fairness, which
aims to minimize differences in performance across clients. We restrict our
study to fairness-aware methods that explicitly regularize client losses,
evaluating both existing and newly proposed approaches. We identify and
theoretically explain connections between the investigated fairness methods,
and empirically show that FairGrad (approximate) and FairGrad* (exact) (two
variants of a gradient variance regularization method introduced here for
performance equitable fairness) improve both fairness and overall model
performance in heterogeneous data settings.

</details>


### [348] [VARAN: Variational Inference for Self-Supervised Speech Models Fine-Tuning on Downstream Tasks](https://arxiv.org/abs/2508.12061)
*Daria Diatlova,Nikita Balagansky,Alexander Varlamov,Egor Spirin*

Main category: cs.LG

TL;DR: VARAN은 입력별로 동적으로 층 합성을 조정하는 프레임워크로, 층별 전문화 프로빙 헤드와 데이터 의존적 가중치를 사용해 self-supervised 음성 표현의 적응을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 기존의 층 합성 방법(최종 층 사용, 가중합 등)은 정보 병목 및 모든 예시에 대해 동일한 정적 특징 가중치를 사용해 다양한 입력에서 최적의 표현을 얻지 못함.

Method: 각 층마다 전문화된 프로빙 헤드를 도입하고, 입력 의존적(데이터 기반) 가중치로 층의 출력을 조합한다. LoRA 기반 파인튜닝과 결합되어 효율적 적응을 목표로 함.

Result: ASR 및 감정 인식 과제에서 VARAN이 기존 방식보다 우수한 성능을 보였으며, 특히 LoRA와 함께 사용할 때 성능 향상이 뚜렷함.

Conclusion: VARAN은 층 특유의 정보를 보존하면서도 입력에 따라 유연하게 특징을 활용할 수 있게 해 self-supervised 음성 모델의 효율적 적응 문제에서 트레이드오프를 해결한다.

Abstract: Conventional methods for aggregating layers in fine-tuned self-supervised
speech models, such as using the final layer or weighted sum, suffer from
information bottlenecks and static feature weighting for all dataset examples.
We propose VARAN, a framework that dynamically tailors layer aggregation to
individual inputs. By employing layer-specialized probing heads and
data-dependent weighting, VARAN adaptively prioritizes layer's features based
on input. Evaluations on automatic speech recognition and speech emotion
recognition tasks demonstrate VARAN's superior performance, particularly when
using the LoRA fine-tuning technique. The framework resolves the trade-off
between preserving layer-specific information and enabling flexible feature
utilization, advancing efficient adaptation of self-supervised speech
representations.

</details>


### [349] [Content Accuracy and Quality Aware Resource Allocation Based on LP-Guided DRL for ISAC-Driven AIGC Networks](https://arxiv.org/abs/2508.12079)
*Ningzhe Shi,Yiqing Zhou,Ling Liu,Jinglin Shi,Yihao Wu,Haiwei Shi,Hanxiao Yu*

Main category: cs.LG

TL;DR: ISAC 환경에서 AIGC의 콘텐츠 정확도와 품질을 동시에 고려하는 새로운 평가지표 CAQA를 제안하고, 이를 최대화하는 센싱-생성(계산)-통신 3차원 자원할당 문제(CAQA-AIGC)를 LP로 유도된 DRL(액션 필터 포함)로 효율적으로 해결한다. 제안 알고리즘(LPDRL-F)은 해공간을 축소해 학습 속도와 성능을 개선하며 시뮬레이션에서 기존 방법보다 수렴 속도와 AvgCAQA가 크게 향상되었다.


<details>
  <summary>Details</summary>
Motivation: 기존 AIGC 서비스들은 입력이 정확하다고 가정해 콘텐츠 생성 품질(CQG)만 고려하지만, ISAC 기반 네트워크에서는 센싱 데이터의 불확실성과 생성 모델의 단계(계산 자원)에 따른 생성오류가 존재하여 콘텐츠 정확도도 중요하다. 따라서 사용자 경험을 반영한 새로운 평가지표와 이를 최대로 하는 자원할당 방법이 필요하다.

Method: (1) 콘텐츠 정확도와 품질을 함께 반영한 CAQA 지표 제안. (2) 모든 사용자에 대한 AvgCAQA를 최대화하는 센싱-생성-통신 3차원 자원할당 최적화 문제(CAQA-AIGC) 공식화 — NP-hard. (3) 문제를 저복잡도로 풀기 위해 선형계획(LP)으로 가이딩한 심층강화학습(DRL) 기반 알고리즘에 액션 필터를 결합(LPDRL-F). LP 가이드는 3차원 해공간을 2차원으로 축소해 DRL의 탐색·학습을 개선.

Result: 시뮬레이션에서 LPDRL-F는 기존 DRL 또는 확산모델 기반 방법보다 수렴 속도가 60% 이상 빠르고, AvgCAQA가 14% 이상 향상되었으며, CGQ만 고려한 기존 스킴 대비 AvgCAQA가 50% 이상 증대됨.

Conclusion: LP로 가이드된 DRL과 액션 필터 조합은 ISAC 기반 AIGC에서 센싱·생성·통신 자원 간 트레이드오프를 효율적으로 최적화하여 사용자 경험(CAQA)을 크게 개선한다. 제안 방법은 계산 효율성과 성능 측면에서 실용적 가능성을 보인다.

Abstract: Integrated sensing and communication (ISAC) can enhance artificial
intelligence-generated content (AIGC) networks by providing efficient sensing
and transmission. Existing AIGC services usually assume that the accuracy of
the generated content can be ensured, given accurate input data and prompt,
thus only the content generation quality (CGQ) is concerned. However, it is not
applicable in ISAC-based AIGC networks, where content generation is based on
inaccurate sensed data. Moreover, the AIGC model itself introduces generation
errors, which depend on the number of generating steps (i.e., computing
resources). To assess the quality of experience of ISAC-based AIGC services, we
propose a content accuracy and quality aware service assessment metric (CAQA).
Since allocating more resources to sensing and generating improves content
accuracy but may reduce communication quality, and vice versa, this
sensing-generating (computing)-communication three-dimensional resource
tradeoff must be optimized to maximize the average CAQA (AvgCAQA) across all
users with AIGC (CAQA-AIGC). This problem is NP-hard, with a large solution
space that grows exponentially with users. To solve the CAQA-AIGC problem with
low complexity, a linear programming (LP) guided deep reinforcement learning
(DRL) algorithm with an action filter (LPDRL-F) is proposed. Through the
LP-guided approach and the action filter, LPDRL-F can transform the original
three-dimensional solution space to two dimensions, reducing complexity while
improving the learning performance of DRL. Simulations show that compared to
existing DRL and generative diffusion model algorithms without LP, LPDRL-F
converges faster by over 60% and finds better resource allocation solutions,
improving AvgCAQA by more than 14%. With LPDRL-F, CAQA-AIGC can achieve an
improvement in AvgCAQA of more than 50% compared to existing schemes focusing
solely on CGQ.

</details>


### [350] [Generative Medical Event Models Improve with Scale](https://arxiv.org/abs/2508.12104)
*Shane Waxler,Paul Blazek,Davis White,Daniel Sneider,Kevin Chung,Mani Nagarathnam,Patrick Williams,Hank Voeller,Karen Wong,Matthew Swanhorst,Sheng Zhang,Naoto Usuyama,Cliff Wong,Tristan Naumann,Hoifung Poon,Andrew Loza,Daniella Meeker,Seth Hain,Rahul Shah*

Main category: cs.LG

TL;DR: 대규모 익명 의료 이벤트 데이터(1510억 토큰)를 사용해 사전학습한 디코더 전용 트랜스포머(CoMET)가 환자 이력을 바탕으로 다음 의료 이벤트를 생성·시뮬레이션한다. 78개 실제 임상·운영 과제에서 태스크별 지도학습 모델과 대체로 동등하거나 우수한 성능을 보였고, 모델 크기·데이터·연산량 증가에 따라 성능이 꾸준히 향상됐다.


<details>
  <summary>Details</summary>
Motivation: 개인맞춤 의료를 실무 규모로 실현하려면 장기적 환자 여정을 시계열 의료 이벤트로부터 요약·예측하는 범용 모델이 필요하다. 대규모 전원의 전자건강기록(EHR)을 이용한 파운데이션 모델이 다양한 다운스트림 임상·운영 과제에 일반화될 가능성을 검증하고자 함.

Method: Epic Cosmos(3.0억 환자, 163억 방문)의 익명화된 이벤트를 이용해 1.15e11 개의 이산 의료 이벤트(1510억 토큰)를 수집. 스케일링 법칙을 정립하고 이를 바탕으로 연산-최적화된 디코더 전용 트랜스포머(CoMET) 계열(최대 10억 파라미터)을 사전학습. 환자 과거를 조건으로 다음 의료 이벤트를 자가회귀적으로 생성하고 시뮬레이션 기반 추론을 수행. 78개 실제 과제를 통해 평가(진단 예측, 진행 예측, 운영 예측 등).

Result: 일반적 사전학습 + 시뮬레이션 추론 만으로도 많은 과제에서 태스크별 지도학습 모델과 동등하거나 우수한 성능을 달성. 모델·토큰·연산량의 증가에 따른 성능 개선(스케일링 법칙) 관찰. 수백만–수억 규모의 환자 데이터를 이용한 거대 의료 이벤트 파운데이션 모델의 실현 가능성 시사.

Conclusion: CoMET는 복잡한 임상 동역학을 포착할 수 있는 생성형 의료 이벤트 파운데이션 모델로, 임상 의사결정 지원·의료 운영 개선·환자 예후 관리에 확장 가능한 일반적 프레임워크를 제공할 가능성이 있다.

Abstract: Realizing personalized medicine at scale calls for methods that distill
insights from longitudinal patient journeys, which can be viewed as a sequence
of medical events. Foundation models pretrained on large-scale medical event
data represent a promising direction for scaling real-world evidence generation
and generalizing to diverse downstream tasks. Using Epic Cosmos, a dataset with
medical events from de-identified longitudinal health records for 16.3 billion
encounters over 300 million unique patient records from 310 health systems, we
introduce the Cosmos Medical Event Transformer ( CoMET) models, a family of
decoder-only transformer models pretrained on 118 million patients representing
115 billion discrete medical events (151 billion tokens). We present the
largest scaling-law study for medical event data, establishing a methodology
for pretraining and revealing power-law scaling relationships for compute,
tokens, and model size. Based on this, we pretrained a series of
compute-optimal models with up to 1 billion parameters. Conditioned on a
patient's real-world history, CoMET autoregressively generates the next medical
event, simulating patient health timelines. We studied 78 real-world tasks,
including diagnosis prediction, disease prognosis, and healthcare operations.
Remarkably for a foundation model with generic pretraining and simulation-based
inference, CoMET generally outperformed or matched task-specific supervised
models on these tasks, without requiring task-specific fine-tuning or few-shot
examples. CoMET's predictive power consistently improves as the model and
pretraining scale. Our results show that CoMET, a generative medical event
foundation model, can effectively capture complex clinical dynamics, providing
an extensible and generalizable framework to support clinical decision-making,
streamline healthcare operations, and improve patient outcomes.

</details>


### [351] [DynamixSFT: Dynamic Mixture Optimization of Instruction Tuning Collections](https://arxiv.org/abs/2508.12116)
*Haebin Shin,Lei Ji,Xiao Liu,Zhiwei Yu,Qi Chen,Yeyun Gong*

Main category: cs.LG

TL;DR: DynamixSFT는 instruction-tuning 데이터셋 혼합 비율을 동적으로 최적화하는 방법이다. 멀티-암드 밴딧으로 문제를 공식화하고 Prior-scaled Boltzmann Exploration으로 기존 비율에 부드럽게 고정시킨 뒤, 1-Step Look-ahead Reward로 샘플링 확률을 경량 업데이트한다. Tulu-v2-mixture(16개 데이터셋)에 적용 시 10개 벤치마크 평균 최대 2.2% 성능 향상을 보였다.


<details>
  <summary>Details</summary>
Motivation: 여러 instruction-tuning 데이터셋이 계속 등장하면서, 각 데이터셋의 혼합 비율을 정적으로 설정하면 다양성·커버리지 저하 혹은 성능 손실이 발생할 수 있다. 동적으로 데이터 비율을 조정해 모델 성능을 효율적으로 향상시키려는 필요성이 있다.

Method: 문제를 멀티-암드 밴딧으로 모델링하고, Prior-scaled Boltzmann Exploration을 통해 샘플링 분포를 원래 비율에 부드럽게 고정(anchoring)한다. 보상은 가볍게 계산되는 1-Step Look-ahead Reward로 정의되어 현재 모델 상태에서 각 데이터셋이 성능 향상에 기여하는 정도를 반영한다. 이를 기반으로 샘플링 확률을 주기적으로 업데이트한다.

Result: Tulu-v2-mixture(16개 데이터셋)에 대해 실험한 결과, DynamixSFT는 10개 벤치마크에서 최대 2.2%의 성능 향상을 달성했다. 또한 적응적 동작과 비율 변화에 대한 시각화·분석을 제공하여 방법의 동적 특성을 설명했다.

Conclusion: Prior-scaled Boltzmann Exploration과 1-Step Look-ahead Reward를 결합한 멀티-암드 밴딧 기반 동적 혼합 최적화는 instruction-tuning에서 데이터셋 다양성과 성능을 동시에 개선할 수 있다.

Abstract: As numerous instruction-tuning datasets continue to emerge during the
post-training stage, dynamically balancing and optimizing their mixtures has
become a critical challenge. To address this, we propose DynamixSFT, a dynamic
and automated method for instruction-tuning dataset mixture optimization. We
formulate the problem as a multi-armed bandit setup and introduce a
Prior-scaled Boltzmann Exploration that softly anchors the updated sampling
distribution to the original dataset proportions, thereby preserving the
inherent diversity and coverage of the collection. Sampling probabilities are
updated using a lightweight 1-Step Look-ahead Reward, reflecting how much the
dataset contributes to improving the model's performance at its current state.
When applied to the Tulu-v2-mixture collection comprising 16 instruction-tuning
datasets, DynamixSFT achieves up to a 2.2% performance improvement across 10
benchmarks. Furthermore, we provide a comprehensive analysis and visualizations
to offer deeper insights into the adaptive dynamics of our method.

</details>


### [352] [Time-Scale Coupling Between States and Parameters in Recurrent Neural Networks](https://arxiv.org/abs/2508.12121)
*Lorenzo Livi*

Main category: cs.LG

TL;DR: 이 논문은 RNN의 게이팅 메커니즘이 고정 학습률 하에서도 학습률 적응 효과를 암묵적으로 만들어낸다는 것을 보인다. 게이트가 상태 공간의 시간 스케일과 파라미터 업데이트를 결합하여 그래디언트 전달을 재형성하고, 유효 스텝 크기와 방향성(비등방성)을 조절하며, 최적화 경로를 전처리(preconditioner)처럼 바꾼다고 주장한다. 분석은 리키-인테그레이터와 게이티드 RNN의 야코비안 도출 및 1차 근사를 통해 이 효과를 정량화하며, 학습률 스케줄, 모멘텀, Adam과의 유사성을 보인다. 수치 실험으로 근사 유효성 확인.


<details>
  <summary>Details</summary>
Motivation: 게이트가 숨김 상태의 기억 유지 길이만 조절하는 것이 아니라, 학습 과정에서 파라미터 업데이트에도 영향을 주어 훈련 안정성과 수렴 속도에 기여한다는 점을 역동적 시스템 관점에서 체계적으로 설명하고자 함.

Method: 리키-인테그레이터와 게이티드 RNN에 대한 정확한 야코비안 공식을 유도하고, 파라미터 업데이트에 미치는 게이트의 영향을 1차 근사(perturbative expansion)로 전개함. 이를 통해 상수·스칼라·다차원 게이트가 그래디언트 전파 경로를 어떻게 재형성하는지 분석하고, 이 효과를 학습률 스케줄, 모멘텀, Adam 등의 최적화 기법과 정식으로 대응시킴.

Result: 게이트가 유효 학습률을 조절하고 파라미터 공간에서 비등방성(preconditioning)을 유도함을 보임. 게이트 유도 보정은 일반적으로 작지만 훈련 동역학에 체계적 영향을 미치며, 수치 실험에서 1차 근사가 실제 동작을 잘 근사함이 확인됨.

Conclusion: 게이팅은 숨김 상태의 시간 스케일 제어뿐 아니라 데이터 의존적 전처리자로서 파라미터 업데이트를 적응적으로 조절하여 게이티드 아키텍처의 강건한 학습 가능성과 안정성을 설명한다.

Abstract: We study how gating mechanisms in recurrent neural networks (RNNs) implicitly
induce adaptive learning-rate behavior, even when training is carried out with
a fixed, global learning rate. This effect arises from the coupling between
state-space time scales--parametrized by the gates--and parameter-space
dynamics during gradient descent. By deriving exact Jacobians for
leaky-integrator and gated RNNs, we obtain a first-order expansion that makes
explicit how constant, scalar, and multi-dimensional gates reshape gradient
propagation, modulate effective step sizes, and introduce anisotropy in
parameter updates. These findings reveal that gates not only control memory
retention in the hidden states, but also act as data-driven preconditioners
that adapt optimization trajectories in parameter space. We further draw formal
analogies with learning-rate schedules, momentum, and adaptive methods such as
Adam, showing that these optimization behaviors emerge naturally from gating.
Numerical experiments confirm the validity of our perturbative analysis,
supporting the view that gate-induced corrections remain small while exerting
systematic effects on training dynamics. Overall, this work provides a unified
dynamical-systems perspective on how gating couples state evolution with
parameter updates, explaining why gated architectures achieve robust
trainability and stability in practice.

</details>


### [353] [DE-VAE: Revealing Uncertainty in Parametric and Inverse Projections with Variational Autoencoders using Differential Entropy](https://arxiv.org/abs/2508.12145)
*Frederik L. Dennig,Daniel A. Keim*

Main category: cs.LG

TL;DR: DE-VAE는 미분 엔트로피(DE)를 이용해 임베딩 불확실성을 측정하는 불확실성 인지형 변분 오토인코더로, 2차원으로의 매핑과 역매핑(생성)을 학습하여 파라메트릭·가역적 투영을 제공한다.


<details>
  <summary>Details</summary>
Motivation: 기존 파라메트릭·가역 투영 방법들은 보지 못한(Out-of-distribution) 샘플에 취약하고 임베딩의 불확실성 정보를 제공하지 못한다. 이를 해결하기 위해 불확실성을 모델링하고 OOD를 더 잘 다룰 수 있는 AE 기반 접근이 필요하다.

Method: 고정된(예: UMAP/t-SNE) 목표 투영을 주고, 입력↔2D 임베딩 간의 순방향·역방향 맵을 학습하는 VAE 프레임워크를 사용한다. 학습 과정에서 미분 엔트로피를 이용해 임베딩의 불확실성을 추정하도록 설계한다(구체적 손실 구성·정규화는 초록에 없음).

Result: 네 개의 잘 알려진 데이터셋에서 정·정성 평가를 수행했으며, UMAP/t-SNE 같은 비파라메트릭 기준과 비교해 다른 AE 기반 방법들과 근접한 정확도를 보이면서 임베딩 불확실성 분석을 가능하게 했다.

Conclusion: DE-VAE는 파라메트릭이고 역변환이 가능한 투영을 제공하면서 임베딩 불확실성을 정량화해 OOD 및 불확실성 분석에 유용한 도구가 될 수 있다.

Abstract: Recently, autoencoders (AEs) have gained interest for creating parametric and
invertible projections of multidimensional data. Parametric projections make it
possible to embed new, unseen samples without recalculating the entire
projection, while invertible projections allow the synthesis of new data
instances. However, existing methods perform poorly when dealing with
out-of-distribution samples in either the data or embedding space. Thus, we
propose DE-VAE, an uncertainty-aware variational AE using differential entropy
(DE) to improve the learned parametric and invertible projections. Given a
fixed projection, we train DE-VAE to learn a mapping into 2D space and an
inverse mapping back to the original space. We conduct quantitative and
qualitative evaluations on four well-known datasets, using UMAP and t-SNE as
baseline projection methods. Our findings show that DE-VAE can create
parametric and inverse projections with comparable accuracy to other current
AE-based approaches while enabling the analysis of embedding uncertainty.

</details>


### [354] [AICRN: Attention-Integrated Convolutional Residual Network for Interpretable Electrocardiogram Analysis](https://arxiv.org/abs/2508.12162)
*J. M. I. H. Jayakody,A. M. H. H. Alahakoon,C. R. M. Perera,R. M. L. C. Srimal,Roshan Ragel,Vajira Thambawita,Isuru Nawinne*

Main category: cs.LG

TL;DR: 심전도(ECG) 파라미터(PR, QT, QRS, HR, R 및 T 파형 진폭)를 회귀하기 위한 공간·채널 어텐션 결합 잔차 합성곱 신경망(AICRN)을 제안, 기존 모델보다 높은 정밀도로 성능 향상했다고 주장함.


<details>
  <summary>Details</summary>
Motivation: 인간 전문가의 주관적 오류와 수동 해석 부담을 줄이고, 실시간 디지털·AI 기반 ECG 분석을 통해 진단 정밀도와 예측 능력을 향상시키려는 필요성에서 출발.

Method: 공간 및 채널 어텐션 모듈을 통합한 합성곱 잔차 네트워크를 설계해 ECG 신호의 형태와 위치 정보를 강조하고, PR·QT·QRS 간격, 심박수, R·T 파형 진폭 등 연속형 파라미터를 회귀하도록 학습시킴. 잔차 구조로 그래디언트 소실/폭주 문제 완화.

Result: 제안한 AICRN이 기존 모델들보다 파라미터 회귀에서 더 높은 정밀도를 보였다고 보고.

Conclusion: 딥러닝 기반 모델이 ECG 해석의 해석 가능성 및 정밀도를 개선할 수 있으며, 심장 모니터링·관리의 임상적 응용 가능성을 확장할 수 있음을 시사.

Abstract: The paradigm of electrocardiogram (ECG) analysis has evolved into real-time
digital analysis, facilitated by artificial intelligence (AI) and machine
learning (ML), which has improved the diagnostic precision and predictive
capacity of cardiac diseases. This work proposes a novel deep learning (DL)
architecture called the attention-integrated convolutional residual network
(AICRN) to regress key ECG parameters such as the PR interval, the QT interval,
the QRS duration, the heart rate, the peak amplitude of the R wave, and the
amplitude of the T wave for interpretable ECG analysis. Our architecture is
specially designed with spatial and channel attention-related mechanisms to
address the type and spatial location of the ECG features for regression. The
models employ a convolutional residual network to address vanishing and
exploding gradient problems. The designed system addresses traditional analysis
challenges, such as loss of focus due to human errors, and facilitates the fast
and easy detection of cardiac events, thereby reducing the manual efforts
required to solve analysis tasks. AICRN models outperform existing models in
parameter regression with higher precision. This work demonstrates that DL can
play a crucial role in the interpretability and precision of ECG analysis,
opening up new clinical applications for cardiac monitoring and management.

</details>


### [355] [ProtTeX-CC: Activating In-Context Learning in Protein LLM via Two-Stage Instruction Compression](https://arxiv.org/abs/2508.12212)
*Chuanliu Fan,Zicheng Ma,Jun Gao,Nan Yu,Jun Zhang,Ziqiang Cao,Yi Qin Gao,Guohong Fu*

Main category: cs.LG

TL;DR: ProtTeX의 서열 및 구조 토큰을 잔해 수준에서 융합·압축하고(입력 길이 약 절반), 데모(풀이 예시)를 잠재 공간으로 자체 압축하여 프롬프트 길이를 대폭 줄인 경량 2단계 압축 프레임워크 ProtTeX-CC를 제안. 소수 샷 상황에서 ICL을 가능케 하며 in-domain +2%, out-of-domain +11% 향상과 프롬프트 길이 약 93.68% 감소를 보고.


<details>
  <summary>Details</summary>
Motivation: ProtTeX는 서열과 구조를 별도 토큰으로 취급해 길이가 두 배가 되고, 단일 단백질 입력으로만 훈련되어 ICL이 불가능해 일반화가 제한된다는 문제를 해결하기 위함.

Method: (1) 잔기 수준에서 서열·구조 표현을 결합하는 joint embedding compression으로 입력 길이를 절반으로 축소. (2) 각 데모를 마지막 몇 개 언어 토큰의 잠재 공간에 집계하는 self-compression으로 데모 평균 길이를 751→<16 토큰으로 줄임. PEFT 기반 미세조정과 단일 투영층만 추가해 백본 변경 없이 적용.

Result: 16-shot에서 총 프롬프트 길이 약 93.68% 압축, in-domain 정확도 +2%, out-of-domain +11% 향상.

Conclusion: 저비용 파라미터 추가로 ProtTeX를 소수 샷 ICL에 적합하게 만들며, 계산·메모리 부담을 크게 줄이면서 일반화 성능을 개선한다.

Abstract: Recent advances in protein large language models, such as ProtTeX, represent
both side-chain amino acids and backbone structure as discrete token sequences
of residue length. While this design enables unified modeling of multimodal
protein information, it suffers from two major limitations: (1) The
concatenation of sequence and structure tokens approximately doubles the
protein length and breaks the intrinsic residue-level alignment between
modalities. (2) Constrained by the training corpus and limited context window,
ProtTeX is typically trained on single-protein inputs, rendering it
incompatible with in-context learning (ICL) and thus limiting its
generalization capability. To address these issues, we propose ProtTeX-CC, a
lightweight two-stage compression framework designed to enhance ProtTeX under
few-shot settings. We first design a joint embedding compression mechanism that
fuses sequence and structure representations at the residue level, effectively
reducing the protein input length by half without sacrificing performance. Then
we propose a self-compression module that aggregates each full demonstration
into the latent space of the last few linguistic tokens, reducing the average
demonstration length from 751 tokens to less than 16 tokens. Compared to the
original ProtTeX, our self-compression approach achieves a compression ratio of
approximately 93.68% in the total prompt length under the 16-shot setting.
Without modifying the backbone model, ProtTeX-CC introduces only a small number
of additional parameters through PEFT-based tuning in the joint embedding
compression stage and a single trainable projection layer in the
self-compression stage. Extensive experiments on protein function prediction
show that ProtTeX-CC improves performance on the in-domain benchmark by 2%, and
generalizes well to the out-of-domain dataset with a performance gain of 11%.

</details>


### [356] [Unlearning at Scale: Implementing the Right to be Forgotten in Large Language Models](https://arxiv.org/abs/2508.12220)
*Abdullah X*

Main category: cs.LG

TL;DR: 저자들은 훈련을 결정적 프로그램으로 보고, 마이크로배치별 최소 로그(샘플 ID 해시, RNG 시드, 학습률, 옵티마이저 스텝 카운터, 누적 경계)를 남겨 훈련 꼬리(replay)만으로 삭제(‘right to be forgotten’)를 구현한다. 전제 조건(고정 스택·결정적 커널)이 충족되면 재생 후 파라미터는 유지셋으로만 훈련한 결과와 비트단위로 동일하다. 실무 지연을 줄이기 위해 마이크로체크포인트, 어댑터 삭제, 곡률 기반 역-업데이트+짧은 재튜닝 등 보완 경로를 제안하고, 장치 예제에서 모델·옵티마이저 상태의 바이트 동일성을 보였다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어모델에서 GDPR 제17조에 따른 ‘잊혀질 권리’를 기술적으로 보장하려면 기존 전체 재학습은 비용·지연 측면에서 현실적이지 않다. 이에 반복 가능하고 증명 가능한(unlearning) 방법을 시스템 수준에서 정의하고 실용적 교환(trade-off)들을 제시하려는 동기이다.

Method: 훈련을 결정적 프로그램으로 간주하고, 각 마이크로배치에 대해 최소한의 재연(ordered ID hash, RNG seed, lr 값, optimizer-step, accumulation boundary) 로그를 남긴다. 고정된 스택과 결정적 커널이 존재하면, 훈련 꼬리를 해당 삭제(forget) 집합을 필터링하며 재생해도 유지셋으로 훈련한 결과와 비트-동일성을 보장한다. 실제 제약(지연/가용성)을 위해: (i) 최근 스텝을 마이크로체크포인트/델타로 즉시 되돌리는 경로, (ii) 베이스 고정 시 코호트 범위 어댑터 삭제, (iii) 곡률을 이용한 역-업데이트 후 짧은 재튜닝 + 감사·에스컬레이션을 추가함.

Result: 저자들은 저장·지연 예산을 계산하고, 토이 아티팩트로 메커니즘을 검증했다. 제시된 전제 조건이 충족되는 통제된 실행에서 모델과 옵티마이저 상태가 바이트-동일함을 시연했다.

Conclusion: 결정성 전제를 만족하면 최소 로그와 꼬리 재생만으로 정확한 언러닝이 가능하며, 실무 적용을 위해 여러 보완 경로(체크포인트, 어댑터 삭제, 근사 역-업데이트)가 필요하다. 확장성·비결정성 환경에 대한 추가 연구와 비용-보안 트레이드오프 분석이 요구된다.

Abstract: We study the right to be forgotten (GDPR Art. 17) for large language models
and frame unlearning as a reproducible systems problem. Our approach treats
training as a deterministic program and logs a minimal per-microbatch record
(ordered ID hash, RNG seed, learning-rate value, optimizer-step counter, and
accumulation boundary). Under a pinned stack and deterministic kernels,
replaying the training tail while filtering only the forget closure yields the
same parameters as training on the retain set (bit-identical in the training
dtype) when preconditions hold. To meet latency and availability constraints,
we add complementary paths: (i) exact reverts of recent steps via
micro-checkpoints or dense per-step deltas, (ii) cohort-scoped adapter deletion
when the base is frozen, and (iii) a curvature-guided anti-update followed by a
short retain-tune, audit-gated with escalation to exact replay. We report
storage/latency budgets and a toy artifact validating mechanics; in a
controlled run that satisfies the preconditions we demonstrate byte-identical
equality of model and optimizer states.

</details>


### [357] [Distribution Matching via Generalized Consistency Models](https://arxiv.org/abs/2508.12222)
*Sagar Shrestha,Rajesh Shrestha,Tri Nguyen,Subash Timilsina*

Main category: cs.LG

TL;DR: GAN의 min-max 학습 문제와 모드 붕괴를 피해 연속 정규화 흐름(CNF)의 consistency 모델에서 영감을 받은 새로운 분포 매칭 방법을 제안한다. 단순한 노름 최소화 목적을 사용하면서도 GAN 수준의 제약 적응성을 유지하고 이론적 근거와 실험적 성능을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 고차원 데이터에서 분포 매칭(잠재변수 모델링, 도메인 변환/적응 등)에 GAN이 널리 쓰이지만, bi-level min-max 최적화와 모드 붕괴로 학습이 불안정하다. CNF의 consistency 모델이 가진 단순하고 안정적인 목적을 분포 매칭에 적용하면 장점을 얻을 수 있다는 점이 동기다.

Method: CNF의 consistency 모델에서 착안한 새로운 분포 매칭 목적을 제안한다. 이 목적은 직관적인 노름(norm) 최소화 형태로 설정되어 bi-level min-max 문제를 피하고 학습 안정성을 개선한다. 동시에 GAN이 제공하는 제약(예: 조건부 변환, 제약된 매핑 등)을 수용할 수 있도록 모델 구조를 설계하였다. 제안된 목적에 대한 이론적 분석을 제공하고, 합성 데이터 및 실제 데이터셋에서 실험을 수행한다.

Result: 이론적 타당성(목적의 정당화)을 제시하고, 합성/실제 데이터 실험에서 제안 모델이 유의미한 성능을 보였음을 보고한다. (요약된 초록 수준에서는 구체적 수치나 비교 우위는 제시되지 않았으나, 안정성 및 분포 매칭 성능이 입증되었다고 서술됨)

Conclusion: CNF 기반의 consistency 목적을 이용한 분포 매칭은 GAN의 장점(유연한 제약 수용성)을 유지하면서도 min-max 최적화의 문제점을 회피할 수 있는 실용적 대안임을 제안한다. 이론적 근거와 실험 결과로 접근의 타당성을 보였다.

Abstract: Recent advancement in generative models have demonstrated remarkable
performance across various data modalities. Beyond their typical use in data
synthesis, these models play a crucial role in distribution matching tasks such
as latent variable modeling, domain translation, and domain adaptation.
Generative Adversarial Networks (GANs) have emerged as the preferred method of
distribution matching due to their efficacy in handling high-dimensional data
and their flexibility in accommodating various constraints. However, GANs often
encounter challenge in training due to their bi-level min-max optimization
objective and susceptibility to mode collapse. In this work, we propose a novel
approach for distribution matching inspired by the consistency models employed
in Continuous Normalizing Flow (CNF). Our model inherits the advantages of CNF
models, such as having a straight forward norm minimization objective, while
remaining adaptable to different constraints similar to GANs. We provide
theoretical validation of our proposed objective and demonstrate its
performance through experiments on synthetic and real-world datasets.

</details>


### [358] [Communication-Efficient Distributed Asynchronous ADMM](https://arxiv.org/abs/2508.12233)
*Sagar Shrestha*

Main category: cs.LG

TL;DR: 비동기 ADMM에서 교환되는 데이터를 거칠게 양자화하여 통신량을 줄이는 방법을 제안하고, 여러 분산 학습 과제(신경망 포함)에 대해 실험적으로 수렴성을 검증함.


<details>
  <summary>Details</summary>
Motivation: 분산 최적화·연합학습에서 비동기 ADMM은 규모, 개인정보, 스트래글러 대응 등 이점이 있으나, 노드 간 통신량이 제한적이거나 전송 데이터가 클 때 통신 비용이 병목이 됨.

Method: 비동기 ADMM의 노드 간 교환 변수에 대해 저해상도(거친) 양자화를 도입하여 전송 비트 수를 감소시킴. 양자화된 메시지를 사용한 비동기 업데이트를 설계·적용하고, 여러 학습 과제에서 실험적으로 동작을 평가함.

Result: 통신 오버헤드를 크게 줄이면서도 실험 환경에서 알고리즘이 수렴함을 확인함. 신경망을 포함한 여러 분산 학습 문제에서 양자화된 비동기 ADMM의 실효성을 보임.

Conclusion: 통신 제약이 있는 대규모 분산/연합학습에서 양자화를 적용한 비동기 ADMM은 유망한 선택지임. 추가로 이론적 수렴 보장, 양자화 수준과 성능 간의 정밀한 트레이드오프 분석 등이 후속 연구 과제로 남음.

Abstract: In distributed optimization and federated learning, asynchronous alternating
direction method of multipliers (ADMM) serves as an attractive option for
large-scale optimization, data privacy, straggler nodes and variety of
objective functions. However, communication costs can become a major bottleneck
when the nodes have limited communication budgets or when the data to be
communicated is prohibitively large. In this work, we propose introducing
coarse quantization to the data to be exchanged in aynchronous ADMM so as to
reduce communication overhead for large-scale federated learning and
distributed optimization applications. We experimentally verify the convergence
of the proposed method for several distributed learning tasks, including neural
networks.

</details>


### [359] [CC-Time: Cross-Model and Cross-Modality Time Series Forecasting](https://arxiv.org/abs/2508.12235)
*Peng Chen,Yihang Wang,Yang Shu,Yunyao Cheng,Kai Zhao,Zhongwen Rao,Lujia Pan,Bin Yang,Chenjuan Guo*

Main category: cs.LG

TL;DR: CC-Time는 PLM(사전학습 언어모델)을 시계열예측에 효과적으로 적용하기 위해 교차-모달리티 학습(시계열 데이터와 텍스트 설명 병합)과 교차-모델 융합(PLM과 전통 시계열 모델의 적응적 통합)을 제안하여 예측 정확도를 크게 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 기존 PLM 기반의 시계열예측 방법들이 언어모델의 강력한 순차 모델링 능력을 예측 정확도로 충분히 활용하지 못함. PLM이 시계열의 어떤 특징을 잘 모델링할 수 있는지, 그리고 PLM 단독으로 충분한지 여부를 규명하고 개선하려 함.

Method: (1) 교차-모달리티 학습: 시계열 시퀀스와 해당 텍스트 설명을 함께 입력해 PLM이 시계열의 시간적 의존성과 채널 간 상관관계를 학습하도록 함. (2) 교차-모델 융합 블록: PLM과 별도의 시계열 모델(예: 전통적 TSF 모델)의 지식을 적응적으로 통합하는 모듈을 도입해 두 모델의 강점을 결합.

Result: 아홉 개의 실세계 데이터셋에서 광범위한 실험을 수행한 결과, CC-Time은 전체 데이터 학습과 소수 샷 학습(몇 샘플만 사용) 모두에서 SOTA 수준의 예측 정확도를 달성.

Conclusion: 시계열 예측에 PLM을 활용할 때 텍스트 기반의 모달리티 결합과 전통 시계열 모델과의 적응적 융합이 성능 향상에 핵심적이며, CC-Time은 이러한 전략으로 PLM의 잠재력을 효과적으로 끌어냈다.

Abstract: With the success of pre-trained language models (PLMs) in various application
fields beyond natural language processing, language models have raised emerging
attention in the field of time series forecasting (TSF) and have shown great
prospects. However, current PLM-based TSF methods still fail to achieve
satisfactory prediction accuracy matching the strong sequential modeling power
of language models. To address this issue, we propose Cross-Model and
Cross-Modality Learning with PLMs for time series forecasting (CC-Time). We
explore the potential of PLMs for time series forecasting from two aspects: 1)
what time series features could be modeled by PLMs, and 2) whether relying
solely on PLMs is sufficient for building time series models. In the first
aspect, CC-Time incorporates cross-modality learning to model temporal
dependency and channel correlations in the language model from both time series
sequences and their corresponding text descriptions. In the second aspect,
CC-Time further proposes the cross-model fusion block to adaptively integrate
knowledge from the PLMs and time series model to form a more comprehensive
modeling of time series patterns. Extensive experiments on nine real-world
datasets demonstrate that CC-Time achieves state-of-the-art prediction accuracy
in both full-data training and few-shot learning situations.

</details>


### [360] [DHG-Bench: A Comprehensive Benchmark on Deep Hypergraph Learning](https://arxiv.org/abs/2508.12244)
*Fan Li,Xiaoyang Wang,Wenjie Zhang,Ying Zhang,Xuemin Lin*

Main category: cs.LG

TL;DR: They introduce DHG-Bench, the first comprehensive benchmark for deep hypergraph learning, consolidating 20 datasets, 16 HNN algorithms, standardized preprocessing and protocols, and evaluations across effectiveness, efficiency, robustness, and fairness, plus an evaluation library.


<details>
  <summary>Details</summary>
Motivation: Existing hypergraph neural network research lacks a unified benchmark: datasets, tasks, preprocessing, and evaluation are inconsistent or narrow, hindering fair comparison and understanding of progress in deep hypergraph learning.

Method: Construct a benchmark (DHG-Bench) that integrates 20 diverse datasets covering node/edge/graph-level tasks, implements 16 state-of-the-art HNN methods under consistent data processing and protocols, and evaluates models across four dimensions (effectiveness, efficiency, robustness, fairness). They also provide a training/evaluation library for reproducibility.

Result: Extensive experiments reveal strengths and limitations of current HNN methods. The benchmark provides systematic comparative results across tasks and dimensions, highlighting performance gaps and trade-offs among methods. The code and datasets are released publicly.

Conclusion: DHG-Bench fills an important gap by offering a standardized, reproducible platform to evaluate HNNs comprehensively, guiding future research directions in deep hypergraph learning.

Abstract: Although conventional deep graph models have achieved great success in
relational learning, their focus on pairwise relationships limits their
capacity to learn pervasive higher-order interactions in real-world complex
systems, which can be naturally modeled as hypergraphs. To tackle this,
hypergraph neural networks (HNNs), the dominant approach in deep hypergraph
learning (DHGL), has garnered substantial attention in recent years. Despite
the proposal of numerous HNN methods, there is no comprehensive benchmark for
HNNs, which creates a great obstacle to understanding the progress of DHGL in
several aspects: (i) insufficient coverage of datasets, algorithms, and tasks;
(ii) a narrow evaluation of algorithm performance; and (iii) inconsistent
dataset usage, preprocessing, and experimental setups that hinder
comparability. To fill the gap, we introduce DHG-Bench, the first comprehensive
benchmark for DHGL. Specifically, DHG-Bench integrates 20 diverse datasets
spanning node-, edge-, and graph-level tasks, along with 16 state-of-the-art
HNN algorithms, under consistent data processing and experimental protocols.
Our benchmark systematically investigates the characteristics of HNNs in terms
of four dimensions: effectiveness, efficiency, robustness, and fairness.
Further, to facilitate reproducible research, we have developed an easy-to-use
library for training and evaluating different HNN methods. Extensive
experiments conducted with DHG-Bench reveal both the strengths and inherent
limitations of existing algorithms, offering valuable insights and directions
for future research. The code is publicly available at:
https://github.com/Coco-Hut/DHG-Bench.

</details>


### [361] [STM3: Mixture of Multiscale Mamba for Long-Term Spatio-Temporal Time-Series Prediction](https://arxiv.org/abs/2508.12247)
*Haolong Chen,Liang Zhang,Zhengyuan Xin,Guangxu Zhu*

Main category: cs.LG

TL;DR: STM2는 멀티스케일 정보를 효율적으로 포착하는 Mamba 구조와 적응형 그래프 인과 컨볼루션을 결합해 장기 시공간 의존성을 모델링하고, STM3는 Mixture-of-Experts(전문가 혼합)과 인과 대조 학습을 더해 스케일 구분성과 라우팅 안정성을 개선한다. 실험에서 SOTA 성능을 달성함.


<details>
  <summary>Details</summary>
Motivation: 장기 시공간 시계열 예측에서는 1) 자연스럽게 존재하는 다중 스케일(멀티스케일) 시간 정보의 효율적 추출이 어렵고, 2) 서로 다른 노드에서 오는 멀티스케일 정보가 강하게 상관되어 이를 효과적으로 분리·모델링하기 어렵다.

Method: STM2: 멀티스케일 Mamba 아키텍처로 다양한 시간 스케일을 계층적으로 집계해 구별성을 보장하고, 적응형 그래프 인과 컨볼루션으로 노드 간 복합적 멀티스케일 시공간 의존성을 학습. STM3: STM2를 기반으로 Mixture-of-Experts 구조(안정적 라우팅 전략 포함)를 도입하고, 인과 대조 학습을 통해 각 전문가의 스케일 분리가 잘 이루어지도록 강제. 이론적으로 라우팅의 연속성(매끄러움)과 전문가별 패턴 분리 보장 증명.

Result: 여러 실제 벤치마크에서 STM2/STM3가 장기 시공간 예측 정확도에서 기존 방법들보다 우수함을 보이며 SOTA 성능 달성.

Conclusion: 제안된 STM2는 멀티스케일 시공간 특징을 효율적으로 추출·통합하고, STM3는 전문가 기반 라우팅과 대조 학습으로 스케일 분리와 안정성을 추가로 확보하여 장기 시공간 예측에서 실질적 성능 향상을 이끈다.

Abstract: Recently, spatio-temporal time-series prediction has developed rapidly, yet
existing deep learning methods struggle with learning complex long-term
spatio-temporal dependencies efficiently. The long-term spatio-temporal
dependency learning brings two new challenges: 1) The long-term temporal
sequence includes multiscale information naturally which is hard to extract
efficiently; 2) The multiscale temporal information from different nodes is
highly correlated and hard to model. To address these challenges, we propose an
efficient \textit{\textbf{S}patio-\textbf{T}emporal \textbf{M}ultiscale
\textbf{M}amba} (STM2) that includes a multiscale Mamba architecture to capture
the multiscale information efficiently and simultaneously, and an adaptive
graph causal convolution network to learn the complex multiscale
spatio-temporal dependency. STM2 includes hierarchical information aggregation
for different-scale information that guarantees their distinguishability. To
capture diverse temporal dynamics across all spatial nodes more efficiently, we
further propose an enhanced version termed
\textit{\textbf{S}patio-\textbf{T}emporal \textbf{M}ixture of
\textbf{M}ultiscale \textbf{M}amba} (STM3) that employs a special
Mixture-of-Experts architecture, including a more stable routing strategy and a
causal contrastive learning strategy to enhance the scale distinguishability.
We prove that STM3 has much better routing smoothness and guarantees the
pattern disentanglement for each expert successfully. Extensive experiments on
real-world benchmarks demonstrate STM2/STM3's superior performance, achieving
state-of-the-art results in long-term spatio-temporal time-series prediction.

</details>


### [362] [Interpreting Time Series Forecasts with LIME and SHAP: A Case Study on the Air Passengers Dataset](https://arxiv.org/abs/2508.12253)
*Manish Shukla*

Main category: cs.LG

TL;DR: 시계열 예측에 LIME·SHAP을 시계열 특성(시간성 보존) 위반 없이 적용해 XGBoost와 ARIMA를 비교·해석하는 방법론 및 사례(Air Passengers)를 제시. 12개월 지연·계절 인코딩이 주요 설명 변수로 확인됨.


<details>
  <summary>Details</summary>
Motivation: ARIMA의 해석력과 트리 기반 모델의 성능 간 균형을 맞추고, 시계열 예측 결과를 사후 해석 가능하게 만들어 의사결정 신뢰성을 높이려 함.

Method: 단변량 시계열을 누수(leakage) 없이 감독학습 문제로 변환(시차 특성 및 계절 인코딩), XGBoost(그레디언트 부스팅)와 ARIMA를 학습, LIME과 SHAP를 시계열에 맞게 적용(시간 순서 보존/롤링 검증 등)해 지역·전역 설명 제공.

Result: Air Passengers 사례에서 소수의 지연(lag) 특징—특히 12개월 지연—및 계절 인코딩이 예측 분산의 대부분을 설명. 트리 기반 모델은 성능 우위와 함께 SHAP/LIME으로 해석 가능성이 확인됨.

Conclusion: (i) 시계열에 대한 LIME·SHAP 적용 방법론, (ii) 알고리즘 이론적 설명, (iii) 실증 분석, (iv) 실무자 가이드라인을 제공해 시계열 예측의 투명성 향상에 기여.

Abstract: Time-series forecasting underpins critical decisions across aviation, energy,
retail and health. Classical autoregressive integrated moving average (ARIMA)
models offer interpretability via coefficients but struggle with
nonlinearities, whereas tree-based machine-learning models such as XGBoost
deliver high accuracy but are often opaque. This paper presents a unified
framework for interpreting time-series forecasts using local interpretable
model-agnostic explanations (LIME) and SHapley additive exPlanations (SHAP). We
convert a univariate series into a leakage-free supervised learning problem,
train a gradient-boosted tree alongside an ARIMA baseline and apply post-hoc
explainability. Using the Air Passengers dataset as a case study, we show that
a small set of lagged features -- particularly the twelve-month lag -- and
seasonal encodings explain most forecast variance. We contribute: (i) a
methodology for applying LIME and SHAP to time series without violating
chronology; (ii) theoretical exposition of the underlying algorithms; (iii)
empirical evaluation with extensive analysis; and (iv) guidelines for
practitioners.

</details>


### [363] [L-SR1: Learned Symmetric-Rank-One Preconditioning](https://arxiv.org/abs/2508.12270)
*Gal Lifshitz,Shahar Zuler,Ori Fouks,Dan Raviv*

Main category: cs.LG

TL;DR: 저자들은 SR1(대칭-랭크-원) 알고리즘을 확장한 학습 기반 2차 최적화기를 제안한다. 가벼운 학습 가능한 전처리 유닛이 데이터 기반 벡터로 양의 준정부호(rank-1) 행렬을 구성하고, 학습된 사영으로 섹선 제약을 만족시켜 수렴과 일반화 성능을 개선한다. 분석 실험과 단안 인간 메쉬 복원(HMR)에서 기존 학습 최적화 방법을 능가한다.


<details>
  <summary>Details</summary>
Motivation: 엔드투엔드 딥러닝은 레이블된 대규모 데이터, 일반화 한계, 계산 비용 문제를 가지며, 고전 최적화법은 데이터 효율적이나 수렴이 느리다. 학습된 최적화기는 두 접근의 장점을 합칠 잠재력이 있으나 대부분 1차 방법에 치우쳐 2차 학습적 접근은 부족하다.

Method: SR1 알고리즘에 학습 가능한 전처리 유닛을 도입한다. 이 유닛은 입력에서 데이터 기반 벡터를 생성하고, 이를 통해 양의 준정부호인 랭크-원 행렬을 구성한다. 구성된 행렬은 학습된 사영 연산으로 섹선 제약을 만족하도록 정렬되며, 이를 통해 2차 정보를 활용한 업데이트를 수행한다. 모델은 경량이며 감독 신호(주석)나 파인튜닝 없이 동작하도록 설계되었다.

Result: 수치(분석) 실험과 실제 단안 HMR 작업에서 제안 기법은 기존의 학습 기반 최적화 접근법보다 우수한 성능을 보였다. 추가로 모델이 경량이고 주석 데이터 불필요, 좋은 일반화 성능을 보이며 다른 최적화 기반 시스템에 통합하기 용이함을 보고한다.

Conclusion: 학습 가능한 전처리 유닛을 결합한 학습 2차 최적화기는 데이터 효율성과 계산 효율을 유지하면서 수렴 성능과 실제 과제에서의 성능을 향상시킨다. 레이블이 없는 학습과 경량성으로 다양한 시스템에 적용 가능하다는 점에서 유망하다.

Abstract: End-to-end deep learning has achieved impressive results but remains limited
by its reliance on large labeled datasets, poor generalization to unseen
scenarios, and growing computational demands. In contrast, classical
optimization methods are data-efficient and lightweight but often suffer from
slow convergence. While learned optimizers offer a promising fusion of both
worlds, most focus on first-order methods, leaving learned second-order
approaches largely unexplored.
  We propose a novel learned second-order optimizer that introduces a trainable
preconditioning unit to enhance the classical Symmetric-Rank-One (SR1)
algorithm. This unit generates data-driven vectors used to construct positive
semi-definite rank-one matrices, aligned with the secant constraint via a
learned projection. Our method is evaluated through analytic experiments and on
the real-world task of Monocular Human Mesh Recovery (HMR), where it
outperforms existing learned optimization-based approaches. Featuring a
lightweight model and requiring no annotated data or fine-tuning, our approach
offers strong generalization and is well-suited for integration into broader
optimization-based frameworks.

</details>


### [364] [CRoC: Context Refactoring Contrast for Graph Anomaly Detection with Limited Supervision](https://arxiv.org/abs/2508.12278)
*Siyue Xie,Da Sun Handason Tam,Wing Cheong Lau*

Main category: cs.LG

TL;DR: CRoC은 제한된 라벨과 풍부한 비라벨 데이터를 공동으로 활용해 그래프 이상 탐지(GAD)를 개선하는 프레임워크로, 노드 속성을 재구성해 문맥을 리팩터링하고 이종 관계를 개별 인코딩한 뒤 대비학습으로 학습해 최대 14% AUC 향상을 보고한다.


<details>
  <summary>Details</summary>
Motivation: GNN 기반 GAD는 라벨이 희소하고 이상치가 드물며 위장(camouflage) 가능성이 있어 학습이 어렵다. 실전에서는 라벨 비용이 높고 불균형이 심하므로 라벨이 부족한 상황에서 비라벨 데이터를 활용하는 방법이 필요하다.

Method: CRoC는 (1) 클래스 불균형을 이용해 각 노드의 문맥을 리팩터링—노드 속성을 재조합하되 상호작용 패턴은 보존하여 증강 그래프 생성, (2) 이종 관계를 따로 인코딩하고 메시지 패싱에 통합하여 복잡한 상호작용 의미 포착, (3) 대비학습(contrastive learning)을 통합해 비라벨 데이터를 활용하여 판별력 높은 노드 임베딩 학습.

Result: 7개의 실제 GAD 데이터셋(규모 다양)에서 평가되어 기존 GNN 대비 최대 14% AUC 향상, 제한 라벨 설정에서 최신 GAD 기법들보다 우수한 성능을 보임.

Conclusion: 문맥 재구성 기반의 강건한 증강과 관계-민감 인코딩, 대비학습의 결합으로 라벨이 적은 상황에서도 GNN이 더 풍부하고 판별력 있는 표현을 학습하여 다양한 은닉 이상 사례를 잘 찾아낸다.

Abstract: Graph Neural Networks (GNNs) are widely used as the engine for various
graph-related tasks, with their effectiveness in analyzing graph-structured
data. However, training robust GNNs often demands abundant labeled data, which
is a critical bottleneck in real-world applications. This limitation severely
impedes progress in Graph Anomaly Detection (GAD), where anomalies are
inherently rare, costly to label, and may actively camouflage their patterns to
evade detection. To address these problems, we propose Context Refactoring
Contrast (CRoC), a simple yet effective framework that trains GNNs for GAD by
jointly leveraging limited labeled and abundant unlabeled data. Different from
previous works, CRoC exploits the class imbalance inherent in GAD to refactor
the context of each node, which builds augmented graphs by recomposing the
attributes of nodes while preserving their interaction patterns. Furthermore,
CRoC encodes heterogeneous relations separately and integrates them into the
message-passing process, enhancing the model's capacity to capture complex
interaction semantics. These operations preserve node semantics while
encouraging robustness to adversarial camouflage, enabling GNNs to uncover
intricate anomalous cases. In the training stage, CRoC is further integrated
with the contrastive learning paradigm. This allows GNNs to effectively harness
unlabeled data during joint training, producing richer, more discriminative
node embeddings. CRoC is evaluated on seven real-world GAD datasets with
varying scales. Extensive experiments demonstrate that CRoC achieves up to 14%
AUC improvement over baseline GNNs and outperforms state-of-the-art GAD methods
under limited-label settings.

</details>


### [365] [Convergence Analysis of the Lion Optimizer in Centralized and Distributed Settings](https://arxiv.org/abs/2508.12327)
*Wei Jiang,Lijun Zhang*

Main category: cs.LG

TL;DR: 논문은 Lion 옵티마이저에 대한 수렴 분석을 제공함. 기본 Lion은 O(d^{1/2} T^{-1/4}), 분산 감소를 도입하면 O(d^{1/2} T^{-1/3})를 달성. 분산 환경에서는 n 노드에 대해 각각 O(d^{1/2}(nT)^{-1/4})와 O(d^{1/2}(nT)^{-1/3})를 보이고, 양방향 sign 압축(편향 제거) 변형은 각각 O(max{d^{1/4}/T^{1/4}, d^{1/10}/(n^{1/5}T^{1/5})})와 O(d^{1/4}/T^{1/4})를 제시.


<details>
  <summary>Details</summary>
Motivation: 현실에서 널리 쓰이는 Lion(이상치-강건한 sign 기반 모멘텀 계열)의 이론적 수렴성 및 통신 효율성을 수학적으로 정립하려는 목적. 특히 분산 학습과 통신 압축 상황에서의 성능 보장을 제공하려 함.

Method: 비볼록 최적화(또는 표준 가정들: 매끄러움, 잡음 분산 제한, 기울기 혹은 보조 변수의 유계 등)를 전제로, sign 연산을 포함한 업데이트의 편향·분산을 분석. 분산 감소(variance reduction) 기법을 도입해 추정량 분산을 줄이고, 양방향 무편향(sign) 압축을 설계해 통신 비용을 낮추는 변형을 이론적으로 분석함.

Result: 주요 수렴 속도는 다음과 같음: 기본 Lion O(d^{1/2} T^{-1/4}); Lion + 분산 감소 O(d^{1/2} T^{-1/3}); 분산 환경: O(d^{1/2}(nT)^{-1/4}) 및 O(d^{1/2}(nT)^{-1/3}); 통신 절약형(양방향 무편향 sign): O(max{d^{1/4}/T^{1/4}, d^{1/10}/(n^{1/5}T^{1/5})}) 및 분산 감소 버전 O(d^{1/4}/T^{1/4}).

Conclusion: Lion에 대한 최초(혹은 강화된) 이론적 근거를 제공하나, 제시된 수렴 속도는 표준 전체 정밀도(Stochastic gradient) 방법의 최고 속도(예: O(T^{-1/2}) 등)보다 느린 지표를 보이며 차원 의존성(d^{1/2}, d^{1/4} 등)과 무편향 sign 구현의 현실성, 상수·가정의 명확화가 필요함. 하한(lower bound) 제시, 실험적 검증, 편향 컴프레서(에러 피드백)와의 비교를 권고。

Abstract: In this paper, we analyze the convergence properties of the Lion optimizer.
First, we establish that the Lion optimizer attains a convergence rate of
$\mathcal{O}(d^{1/2}T^{-1/4})$ under standard assumptions, where $d$ denotes
the problem dimension and $T$ is the iteration number. To further improve this
rate, we introduce the Lion optimizer with variance reduction, resulting in an
enhanced convergence rate of $\mathcal{O}(d^{1/2}T^{-1/3})$. We then analyze in
distributed settings, where the standard and variance reduced version of the
distributed Lion can obtain the convergence rates of
$\mathcal{O}(d^{1/2}(nT)^{-1/4})$ and $\mathcal{O}(d^{1/2}(nT)^{-1/3})$, with
$n$ denoting the number of nodes. Furthermore, we investigate a
communication-efficient variant of the distributed Lion that ensures sign
compression in both communication directions. By employing the unbiased sign
operations, the proposed Lion variant and its variance reduction counterpart,
achieve convergence rates of $\mathcal{O}\left( \max
\left\{\frac{d^{1/4}}{T^{1/4}}, \frac{d^{1/10}}{n^{1/5}T^{1/5}} \right\}
\right)$ and $\mathcal{O}\left( \frac{d^{1/4}}{T^{1/4}} \right)$, respectively.

</details>


### [366] [Navigating the Exploration-Exploitation Tradeoff in Inference-Time Scaling of Diffusion Models](https://arxiv.org/abs/2508.12361)
*Xun Su,Jianming Huang,Yang Yusen,Zhongxi Fang,Hiroyuki Kasai*

Main category: cs.LG

TL;DR: 제안된 방법은 SMC 기반 확산 모델의 탐색-활용 균형 문제를 해결하기 위해 'Funnel Schedule'와 'Adaptive Temperature'라는 두 가지 추론 시 스케일링 전략을 도입한다. 입자 수를 점진적으로 줄이고 초기 단계 보상의 영향력을 낮춰 다양성을 유지하면서 샘플 품질을 개선하며, 추가 노이즈 함수 평가(NFE) 없이 성능 향상을 달성한다.


<details>
  <summary>Details</summary>
Motivation: SMC 기반 방법들이 보상-기울분포(reward-tilted distribution)를 전역적으로 맞추며 다모달 탐색에서 다양성을 보존하는 점이 효과의 핵심이다. 하지만 확산 모델 적용에서는 초기 단계의 노이즈 샘플은 개선 가능성이 크지만 평가가 어렵고, 후기 샘플은 평가는 쉽지만 되돌리기 불가능해 탐색-활용 트레이드오프가 발생한다.

Method: 두 가지 간단한 전략을 제안한다. (1) Funnel Schedule: 생성 과정에서 유지하는 입자 수를 점진적으로 줄여 샘플링 자원을 후기 단계에 집중시킨다. (2) Adaptive Temperature: 초기 단계의 보상 영향력을 낮추기 위해 온도(또는 보상 스케일)를 적응적으로 조정하여 초기의 불확실한 평가에 의한 잘못된 수렴을 방지한다. 이들은 확산 모델의 생성 역학과 위상 전이(phase-transition) 행동에 맞춰 설계되었다.

Result: 여러 벤치마크 및 최신 텍스트-투-이미지 확산 모델에서 이전 SMC 기반 및 다른 기준선 방법들보다 샘플 품질이 향상됨을 보였다. 총 NFE는 증가시키지 않으면서 성능 개선을 달성함.

Conclusion: 탐색-활용 균형을 알고리즘 수준에서 다루는 간단하면서도 효과적인 방법으로, 확산 모델의 추론 단계에서 다양성과 품질을 동시에 향상시키며 실용적인 이점을 제공한다.

Abstract: Inference-time scaling has achieved remarkable success in language models,
yet its adaptation to diffusion models remains underexplored. We observe that
the efficacy of recent Sequential Monte Carlo (SMC)-based methods largely stems
from globally fitting the The reward-tilted distribution, which inherently
preserves diversity during multi-modal search. However, current applications of
SMC to diffusion models face a fundamental dilemma: early-stage noise samples
offer high potential for improvement but are difficult to evaluate accurately,
whereas late-stage samples can be reliably assessed but are largely
irreversible. To address this exploration-exploitation trade-off, we approach
the problem from the perspective of the search algorithm and propose two
strategies: Funnel Schedule and Adaptive Temperature. These simple yet
effective methods are tailored to the unique generation dynamics and
phase-transition behavior of diffusion models. By progressively reducing the
number of maintained particles and down-weighting the influence of early-stage
rewards, our methods significantly enhance sample quality without increasing
the total number of Noise Function Evaluations. Experimental results on
multiple benchmarks and state-of-the-art text-to-image diffusion models
demonstrate that our approach outperforms previous baselines.

</details>


### [367] [Bi-Axial Transformers: Addressing the Increasing Complexity of EHR Classification](https://arxiv.org/abs/2508.12418)
*Rachael DeVries,Casper Christensen,Marie Lisandra Zepeda Mendoza,Ole Winther*

Main category: cs.LG

TL;DR: Bi-Axial Transformer (BAT)는 EHR의 변수 축과 시간 축을 동시에 주의(attend)하여 결측성과 희소성을 다루며, 패혈증 예측에서 최첨단 성능을 보이고 사망률 분류에서도 경쟁력을 갖춘 모델이다.


<details>
  <summary>Details</summary>
Motivation: EHR 데이터는 시계열 길이 증가, 다중 모달 통합, 희소한 관측 등 복잡성이 커지고 있어 긴 거리 의존성 모델링과 병렬 처리 능력을 가진 트랜스포머가 필요하다. 기존 표현은 성능 저하 또는 정보성 결측성(informative missingness)을 놓칠 수 있다.

Method: BAT는 임상 변수(센서) 축과 시간 축 양쪽에 어텐션을 적용해 더 풍부한 관계를 학습하고 데이터 희소성 문제를 완화한다. 또한 고유한 센서 임베딩을 학습해 전이학습에 활용한다. PyTorch로 재구현한 여러 기준 모델과 비교 실험을 수행했다.

Result: BAT는 패혈증 예측에서 SOTA 성능을 달성하고, 사망률 예측에서는 상위 방법들과 경쟁력 있는 결과를 보였다. 다른 트랜스포머보다 결측성에 대한 강건성이 높고 센서 임베딩이 유용하다는 점을 보였다.

Conclusion: BAT는 EHR 분류를 위한 효과적인 트랜스포머 구조로서 결측성에 견딜 수 있고 전이학습에 유리한 임베딩을 제공한다. 재현가능성을 위해 기준 모델들을 PyTorch로 재구현해 공개했다.

Abstract: Electronic Health Records (EHRs), the digital representation of a patient's
medical history, are a valuable resource for epidemiological and clinical
research. They are also becoming increasingly complex, with recent trends
indicating larger datasets, longer time series, and multi-modal integrations.
Transformers, which have rapidly gained popularity due to their success in
natural language processing and other domains, are well-suited to address these
challenges due to their ability to model long-range dependencies and process
data in parallel. But their application to EHR classification remains limited
by data representations, which can reduce performance or fail to capture
informative missingness. In this paper, we present the Bi-Axial Transformer
(BAT), which attends to both the clinical variable and time point axes of EHR
data to learn richer data relationships and address the difficulties of data
sparsity. BAT achieves state-of-the-art performance on sepsis prediction and is
competitive to top methods for mortality classification. In comparison to other
transformers, BAT demonstrates increased robustness to data missingness, and
learns unique sensor embeddings which can be used in transfer learning.
Baseline models, which were previously located across multiple repositories or
utilized deprecated libraries, were re-implemented with PyTorch and made
available for reproduction and future benchmarking.

</details>


### [368] [Machine Learning-Based Manufacturing Cost Prediction from 2D Engineering Drawings via Geometric Features](https://arxiv.org/abs/2508.12440)
*Ahmet Bilal Arıkan,Şener Özönder,Mustafa Taha Koçyiğit,Hüseyin Oktay Altun,H. Kübra Küçükkartal,Murat Arslanoğlu,Fatih Çağırankaya,Berk Ayvaz*

Main category: cs.LG

TL;DR: 2D 도면(DWG)으로부터 약 200개의 기하학·통계적 특징을 추출해 13,684개 자동차 현가·조향 부품을 학습시킨 그래디언트 부스팅 모델(XGBoost/CatBoost/LightGBM)이 약 10% MAPE를 달성하고, SHAP으로 설계 요인을 설명하여 CAD-투-비용(end-to-end) 파이프라인을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 전통적 견적 방식은 수작업 프로세스 계획에 의존해 시간 소요가 크고 일관성이 떨어지며, 부품별 휴리스틱에 한정되는 문제가 있다. 자동화·확장 가능한 비용 추정이 필요하다.

Method: DWG 도면에서 약 200개의 기하·통계 지표를 자동 추출. 24개 제품군의 13,684개 샘플로 그래디언트 부스팅 모델(XGBoost, CatBoost, LightGBM) 학습. SHAP 기반 설명가능성 도구로 주요 설계 드라이버 식별. ERP 통합을 목표로 하는 CAD-투-비용 파이프라인 구축.

Result: 모델들이 제품군 전반에서 평균절대백분오차(MAPE) 약 10%를 달성. 회전 치수 최대값, 호(arc) 통계, 발산(divergence) 지표 등 기하학적 특성이 비용에 영향력 있는 드라이버로 식별됨.

Conclusion: 이 접근법은 견적 리드타임을 단축하고 일관성·투명성을 높이며, 실시간 ERP 통합을 통한 의사결정 지원으로 Industry 4.0 환경에 적용 가능성을 제공한다.

Abstract: We present an integrated machine learning framework that transforms how
manufacturing cost is estimated from 2D engineering drawings. Unlike
traditional quotation workflows that require labor-intensive process planning,
our approach about 200 geometric and statistical descriptors directly from
13,684 DWG drawings of automotive suspension and steering parts spanning 24
product groups. Gradient-boosted decision tree models (XGBoost, CatBoost,
LightGBM) trained on these features achieve nearly 10% mean absolute percentage
error across groups, demonstrating robust scalability beyond part-specific
heuristics. By coupling cost prediction with explainability tools such as SHAP,
the framework identifies geometric design drivers including rotated dimension
maxima, arc statistics and divergence metrics, offering actionable insights for
cost-aware design. This end-to-end CAD-to-cost pipeline shortens quotation lead
times, ensures consistent and transparent cost assessments across part families
and provides a deployable pathway toward real-time, ERP-integrated decision
support in Industry 4.0 manufacturing environments.

</details>


### [369] [Local Cluster Cardinality Estimation for Adaptive Mean Shift](https://arxiv.org/abs/2508.12450)
*Étienne Pepin*

Main category: cs.LG

TL;DR: 지역적 스케일과 클러스터 크기 변화에 적응하는 mean shift 기법. 각 점의 거리 분포에서 로컬 최소를 찾아 로컬 클러스터 카디널리티를 추정하고, 이를 이용해 밴드위스와 커널 반경을 적응적으로 조정하여 성능 향상.


<details>
  <summary>Details</summary>
Motivation: 기존 KDE 기반 mean shift는 로컬 영역 정보만 제공해 클러스터 전체 특성을 반영하지 못하고, 데이터의 지역적 스케일과 클러스터 크기 변화에 취약하다. 클러스터 전체를 고려한 적응적 파라미터 조정 필요.

Method: 각 포인트에서 다른 점들까지의 거리 분포를 분석해 밀도 함수의 로컬 최소를 찾아 로컬 카디널리티를 추정한다. 이 카디널리티를 바탕으로 클러스터 전체에 대한 파라미터(밴드위스, 커널 반경 임계값)를 계산하고, mean shift 수행 중 해당 값으로 파라미터를 동적으로 조정한다.

Result: 제안 기법이 원 논문에서 비교된 최근 적응형 mean shift보다 원 데이터셋에서 더 우수한 성능을 보였고, 더 넓은 벤치마크에서도 경쟁력 있는 결과를 보였다.

Conclusion: 거리 분포 기반 카디널리티 추정은 클러스터 수준 파라미터 추정에 유용하며, 이를 이용한 적응적 mean shift는 성능·일반성 측면에서 효과적임을 실험으로 보여준다.

Abstract: This article presents an adaptive mean shift algorithm designed for datasets
with varying local scale and cluster cardinality. Local distance distributions,
from a point to all others, are used to estimate the cardinality of the local
cluster by identifying a local minimum in the density of the distance
distribution. Based on these cardinality estimates, local cluster parameters
are then computed for the entire cluster in contrast to KDE-based methods,
which provide insight only into localized regions of the cluster. During the
mean shift execution, the cluster cardinality estimate is used to adaptively
adjust the bandwidth and the mean shift kernel radius threshold. Our algorithm
outperformed a recently proposed adaptive mean shift method on its original
dataset and demonstrated competitive performance on a broader clustering
benchmark.

</details>


### [370] [Cold-RL: Learning Cache Eviction with Offline Reinforcement Learning for NGINX](https://arxiv.org/abs/2508.12485)
*Aayush Gupta,Arpit Bhayani*

Main category: cs.LG

TL;DR: Cold-RL은 NGINX의 LRU 강제 만료 경로를 대체하는 강화학습 기반 추출(탈락) 정책으로, 듀얼 DQN을 ONNX 사이드카로 서빙해 마이크로초 예산 내에서 작동한다. K개의 LRU 후보에서 6개 경량 특성을 뽑아 비트마스크로 탈락 대상을 예측하며, 500μs 타임아웃 시 LRU로 즉시 폴백한다. 오프라인 로그 재생으로 학습하고 두 가지 적대적 워크로드에서 기존 기법 대비 큰 히트율 향상을 보였다.


<details>
  <summary>Details</summary>
Motivation: LRU는 객체 크기를 무시하고 주기적 버스트 및 혼합 객체 크기에서 스래싱이 발생하므로, 실시간 제약 하에서 더 나은 탈락( eviction) 결정을 내릴 수 있는 방법이 필요하다.

Method: NGINX의 강제 만료 경로를 대체하여 K개 LRU 후보를 샘플링, 6개 특성(age,size,hit count,inter-arrival,remaining TTL,last origin RTT)을 입력으로 듀얼 DQN이 비트마스크 형태의 탈락 결정을 반환. ONNX 사이드카로 서빙하고 500μs 하드 타임아웃 이후 LRU 폴백. 오프라인 시뮬레이터로 로그 재생하여 보상은 TTL 만료 전 재히트 시 +1.

Result: 작은 캐시(25MB)에서 히트율 0.1436→0.3538(146% 개선), 100MB에서 0.7530→0.8675(15% 개선), 400MB에서는 기존 방법과 동등. 추론 오버헤드는 CPU 기준 <2%, 95백분위 탈락 지연은 예산 내.

Conclusion: 마이크로초 SLO를 만족하면서 실운영급 프록시(NGINX)에 최초로 통합된 RL 기반 탈락 정책을 제시. 오프라인 학습+폴백으로 안정성과 성능을 확보했으나, 시뮬레이터 의존성·보상 설계·일반화 등에 대한 추가 검증이 필요하다.

Abstract: Web proxies such as NGINX commonly rely on least-recently-used (LRU)
eviction, which is size agnostic and can thrash under periodic bursts and mixed
object sizes. We introduce Cold-RL, a learned eviction policy for NGINX that
replaces LRU's forced-expire path with a dueling Deep Q-Network served by an
ONNX sidecar within a strict microsecond budget. On each eviction, Cold-RL
samples the K least-recently-used objects, extracts six lightweight features
(age, size, hit count, inter-arrival time, remaining TTL, and last origin RTT),
and requests a bitmask of victims; a hard timeout of 500 microseconds triggers
immediate fallback to native LRU. Policies are trained offline by replaying
NGINX access logs through a cache simulator with a simple reward: a retained
object earns one point if it is hit again before TTL expiry. We compare against
LRU, LFU, size-based, adaptive LRU, and a hybrid baseline on two adversarial
workloads. With a 25 MB cache, Cold-RL raises hit ratio from 0.1436 to 0.3538,
a 146 percent improvement over the best classical baseline; at 100 MB, from
0.7530 to 0.8675, a 15 percent gain; and at 400 MB it matches classical methods
(about 0.918). Inference adds less than 2 percent CPU overhead and keeps 95th
percentile eviction latency within budget. To our knowledge, this is the first
reinforcement learning eviction policy integrated into NGINX with strict SLOs.

</details>


### [371] [Cost-Aware Contrastive Routing for LLMs](https://arxiv.org/abs/2508.12491)
*Reza Shirkavand,Shangqian Gao,Peiran Yu,Heng Huang*

Main category: cs.LG

TL;DR: CSCR은 프롬프트와 모델을 공통 임베딩 공간으로 매핑해 비용-민감한 라우팅을 수행한다. 오픈소스 모델에는 빠른 로그잇 풋프린트, 블랙박스 API에는 퍼플렉시티 지문을 사용하며, 비용 대역 내에서 가장 저비용의 정확한 전문가를 선호하도록 대조 학습한다. 추론은 FAISS 기반 k-NN 조회로 마무리되어 마이크로초 수준 지연과 전문가 풀 변경 시 재학습 불필요성을 보장한다. 벤치마크에서 비용-정확도 트레이드오프를 최대 25% 개선하고 미지의 LLM/분포외 프롬프트에도 강건했다.


<details>
  <summary>Details</summary>
Motivation: 기존 라우팅은 프롬프트 특수성 무시, 고비용 모델 프로파일링, 고정 전문가 가정, 비효율적 시도-오류 전략 등의 한계가 있어 실시간·동적 환경에서 비용 효율적 선택을 어렵게 한다.

Method: 오픈소스 모델에 대해선 compact한 로그잇 풋프린트, 블랙박스 API엔 퍼플렉시티 지문을 계산해 프롬프트·모델 쌍을 공통 임베딩으로 매핑한다. 대조적 인코더를 비용 대역(cost bands) 내에서 '정확하면서 가장 저렴한' 전문가를 선호하도록 학습시키고, 추론 시 FAISS에 저장된 임베딩으로 단일 k-NN 조회만 수행해 라우팅 결정을 내린다. 전문가 풀 변경 시 재학습 불필요하며 마이크로초 지연을 목표로 설계됨.

Result: 다수 벤치마크에서 기존 기법들을 일관되게 능가, 비용-정확도 트레이드오프 최대 25% 개선. 미지의 LLM과 분포외(OOD) 프롬프트에도 잘 일반화하며 실시간 라우팅 요건(저지연, 재학습 불필요)을 만족.

Conclusion: CSCR은 경량·비용-민감 라우팅 솔루션으로, 프롬프트 특수성 반영과 빠른 추론을 통해 동적 전문가 풀에서 비용 효율을 크게 개선한다. 다만 풋프린트/지문 품질, 비용대역 설계, 아주 새로운 작업군에서의 성능 저하 가능성 등 한계가 있어 추가 실험(민감도/공정성/보안 분석)이 요구된다.

Abstract: We study cost-aware routing for large language models across diverse and
dynamic pools of models. Existing approaches often overlook prompt-specific
context, rely on expensive model profiling, assume a fixed set of experts, or
use inefficient trial-and-error strategies. We introduce Cost-Spectrum
Contrastive Routing (CSCR), a lightweight framework that maps both prompts and
models into a shared embedding space to enable fast, cost-sensitive selection.
CSCR uses compact, fast-to-compute logit footprints for open-source models and
perplexity fingerprints for black-box APIs. A contrastive encoder is trained to
favor the cheapest accurate expert within adaptive cost bands. At inference
time, routing reduces to a single k-NN lookup via a FAISS index, requiring no
retraining when the expert pool changes and enabling microsecond latency.
Across multiple benchmarks, CSCR consistently outperforms baselines, improving
the accuracy-cost tradeoff by up to 25%, while generalizing robustly to unseen
LLMs and out-of-distribution prompts.

</details>


### [372] [Trust Region Constrained Measure Transport in Path Space for Stochastic Optimal Control and Inference](https://arxiv.org/abs/2508.12511)
*Denis Blessing,Julius Berner,Lorenz Richter,Carles Domingo-Enrich,Yuanqi Du,Arash Vahdat,Gerhard Neumann*

Main category: cs.LG

TL;DR: Prior와 목표 경로 분포가 크게 다른 경우의 확률적 최적제어를, 신뢰영역(trust region)을 사용하는 반복적 제약 최적화(기하학적 어닐링 관점)로 해결하여 샘플링·전이경로·디퓨전 모델 미세조정 성능을 크게 향상시켰다.


<details>
  <summary>Details</summary>
Motivation: 목표 경로 공간의 확률분포를 근사하는 확률적 최적제어 문제는 그래디언트 기반 최적화로 풀 수 있지만, 목표분포가 사전(prior)과 크게 다르면 수렴성·안정성 문제가 심해 효율적·안전한 방법이 필요하다.

Method: 사전에서 목표분포로 점진적으로 접근하는 기하학적 어닐링 관점에서, 각 단계마다 신뢰영역을 도입한 제약 최적문제를 반복적으로 풀어 시간계단(어닐링 스텝)을 원리있게 선택하도록 함. 이로써 각 반복에서 큰 변화 없이 점진적으로 목표에 근접하도록 최적화를 유도한다.

Result: 확률적 제어 응용에서 유의미한 성능향상을 보고함 — 특히 디퓨전 기반 샘플링, 전이 경로 샘플링, 디퓨전 모델의 파인튜닝 등에서 개선이 관찰되며 안정성과 효율성이 향상됨.

Conclusion: 신뢰영역을 포함한 기하학적 어닐링 접근은 prior→target 전이의 타임스텝 선택을 체계화해 최적화 안정성과 성능을 동시에 개선하며, 다양한 샘플링·제어 응용에 적용 가능하다.

Abstract: Solving stochastic optimal control problems with quadratic control costs can
be viewed as approximating a target path space measure, e.g. via gradient-based
optimization. In practice, however, this optimization is challenging in
particular if the target measure differs substantially from the prior. In this
work, we therefore approach the problem by iteratively solving constrained
problems incorporating trust regions that aim for approaching the target
measure gradually in a systematic way. It turns out that this trust region
based strategy can be understood as a geometric annealing from the prior to the
target measure, where, however, the incorporated trust regions lead to a
principled and educated way of choosing the time steps in the annealing path.
We demonstrate in multiple optimal control applications that our novel method
can improve performance significantly, including tasks in diffusion-based
sampling, transition path sampling, and fine-tuning of diffusion models.

</details>


### [373] [Results of the NeurIPS 2023 Neural MMO Competition on Multi-task Reinforcement Learning](https://arxiv.org/abs/2508.12524)
*Joseph Suárez,Kyoung Whan Choe,David Bloomin,Jianming Gao,Yunkun Li,Yao Feng,Saidinesh Pola,Kun Zhang,Yonghui Zhu,Nikhil Pinnaparaju,Hao Xiang Li,Nishaanth Kanna,Daniel Scott,Ryan Sullivan,Rose S. Shuman,Lucas de Alcântara,Herbie Bradley,Kirsty You,Bo Wu,Yuhao Jiang,Qimai Li,Jiaxin Chen,Louis Castricato,Xiaolong Zhu,Phillip Isola*

Main category: cs.LG

TL;DR: NeurIPS 2023 Neural MMO Competition에 200명 이상 참가. 목표-조건(goal-conditional) 정책을 학습해 미지의 과제·맵·상대에 일반화하도록 평가. 최고 솔루션은 단일 4090 GPU에서 8시간 훈련으로 baseline보다 4배 높은 점수 달성. 코드·정책 가중치·데이터를 MIT 라이선스로 공개.


<details>
  <summary>Details</summary>
Motivation: 대규모 멀티에이전트 오픈월드 환경에서 실용적이고 일반화 가능한 정책을 개발·검증하고, 대회 형태로 강력한 솔루션을 발굴해 재현 가능한 자원을 공개하려는 목적.

Method: 참가자들이 Neural MMO 환경에서 목표 조건형 정책을 훈련해 제출하고 경쟁. 조직자는 baseline과 제출물의 평가를 진행하고 상위 솔루션의 코드와 가중치를 공개. 짧은 시간(8시간)·단일 GPU(4090) 기반의 효율적 학습이 특징.

Result: 200+ 참가·제출. 최고 성능은 baseline 대비 4배 점수, 8시간 단일 4090 GPU 훈련으로 달성. 전체 관련 자원(MIT 라이선스) 공개.

Conclusion: Neural MMO 대회는 멀티에이전트 정책의 효율성과 일반화 능력을 실증했으며, 공개된 코드와 가중치는 후속 연구 및 재현성 향상에 기여할 것.

Abstract: We present the results of the NeurIPS 2023 Neural MMO Competition, which
attracted over 200 participants and submissions. Participants trained
goal-conditional policies that generalize to tasks, maps, and opponents never
seen during training. The top solution achieved a score 4x higher than our
baseline within 8 hours of training on a single 4090 GPU. We open-source
everything relating to Neural MMO and the competition under the MIT license,
including the policy weights and training code for our baseline and for the top
submissions.

</details>


### [374] [Toward Architecture-Agnostic Local Control of Posterior Collapse in VAEs](https://arxiv.org/abs/2508.12530)
*Hyunsoo Song,Seungwhan Kim,Seungkyu Lee*

Main category: cs.LG

TL;DR: 저자들은 VAE의 posterior collapse 문제를 완화하기 위해 'local posterior collapse' 개념을 정의하고, 네트워크 구조 제약 없이 잠재공간 붕괴를 제어하는 Latent Reconstruction(LR) 손실을 제안한다. 다양한 데이터셋(MNIST 계열, Omniglot, CelebA, FFHQ)에서 실험을 통해 효과를 보였다.


<details>
  <summary>Details</summary>
Motivation: 기존의 정규화 제어(예: KL 조절)는 재구성-정규화 간의 트레이드오프가 불만족스럽고, 잠재 식별성(identifiability)을 보장하는 방법은 네트워크 구조 제약을 필요로 한다. 이 한계를 극복하고 posterior collapse를 샘플 수준에서 완화하고자 함.

Method: 점별 중요도를 반영하는 'local posterior collapse'를 정의하고, 함수의 단사성(injective)과 합성함수의 수학적 성질에서 영감을 받은 Latent Reconstruction(LR) 손실을 제안. 이 손실은 특정 아키텍처 제약 없이 적용되어 잠재공간이 붕괴되는 것을 억제한다.

Result: MNIST, fashionMNIST, Omniglot, CelebA, FFHQ 등의 데이터셋에서 LR 손실이 posterior collapse를 제어하는 데 효과적임을 보고.

Conclusion: LR 손실은 아키텍처 제한 없이 VAE의 posterior collapse를 경감시킬 수 있는 실용적 방법이며, 데이터 포인트 수준의 중요도를 반영하는 개념적 확장(local posterior collapse)을 제시함.

Abstract: Variational autoencoders (VAEs), one of the most widely used generative
models, are known to suffer from posterior collapse, a phenomenon that reduces
the diversity of generated samples. To avoid posterior collapse, many prior
works have tried to control the influence of regularization loss. However, the
trade-off between reconstruction and regularization is not satisfactory. For
this reason, several methods have been proposed to guarantee latent
identifiability, which is the key to avoiding posterior collapse. However, they
require structural constraints on the network architecture. For further
clarification, we define local posterior collapse to reflect the importance of
individual sample points in the data space and to relax the network constraint.
Then, we propose Latent Reconstruction(LR) loss, which is inspired by
mathematical properties of injective and composite functions, to control
posterior collapse without restriction to a specific architecture. We
experimentally evaluate our approach, which controls posterior collapse on
varied datasets such as MNIST, fashionMNIST, Omniglot, CelebA, and FFHQ.

</details>


### [375] [Rethinking Safety in LLM Fine-tuning: An Optimization Perspective](https://arxiv.org/abs/2508.12531)
*Minseon Kim,Jin Myung Kwak,Lama Alssum,Bernard Ghanem,Philip Torr,David Krueger,Fazl Barez,Adel Bibi*

Main category: cs.LG

TL;DR: 저자들은 파인튜닝이 본질적으로 모델 안전성을 해친다는 통념을 반박한다. 잘못된 최적화(학습률, 배치 크기, 그래디언트 스텝 등)가 유해 응답 증가의 주원인이라 보고, 적절한 하이퍼파라미터 선택과 파라미터 공간의 EMA 모멘텀을 통해 유해 응답 비율을 크게 낮추고 성능을 유지할 수 있음을 보인다.


<details>
  <summary>Details</summary>
Motivation: 많은 연구가 파인튜닝이 모델의 안전성(유해 요청에 대한 거부성)을 저하시킨다고 보며 추가 안전 조치를 권장한다. 저자들은 이 현상이 파인튜닝 자체의 불가피한 대가인지, 혹은 최적화 선택의 문제인지를 명확히 하려 한다.

Method: Llama 계열 모델을 Dolly, Alpaca, ORCA 데이터셋으로 파인튜닝하며 하이퍼파라미터(학습률, 배치 사이즈, 그래디언트 스텝)를 체계적으로 탐색. 유해 응답은 키워드 매칭으로 측정. 또한 파라미터 공간에서의 지수이동평균(EMA) 모멘텀을 도입해 최적화 경로 안정화 및 사전학습 모델의 안전성 보존을 시도.

Result: 부적절한 최적화 선택으로 유해 응답 비율이 높아졌으며, 하이퍼파라미터 조정으로 키워드 기준 유해 응답을 16%에서 약 5%로 감소시킴. EMA 기법은 안전성 유지에 효과적이었고, 추가 안전 데이터 없이도 기존 안전 조치들보다 우수한 결과를 냄.

Conclusion: 파인튜닝 시 발생하는 많은 안전 문제는 필연적이지 않으며, 적절한 최적화 설정과 EMA 같은 간단한 기법으로 상당 부분 회피 가능하다. 실무에 적용할 수 있는 하이퍼파라미터 가이드라인과 함께 안전성과 성능을 동시에 유지할 수 있음을 주장한다.

Abstract: Fine-tuning language models is commonly believed to inevitably harm their
safety, i.e., refusing to respond to harmful user requests, even when using
harmless datasets, thus requiring additional safety measures. We challenge this
belief through systematic testing, showing that poor optimization choices,
rather than inherent trade-offs, often cause safety problems, measured as
harmful responses to adversarial prompts. By properly selecting key training
hyper-parameters, e.g., learning rate, batch size, and gradient steps, we
reduce unsafe model responses from 16\% to approximately 5\%, as measured by
keyword matching, while maintaining utility performance. Based on this
observation, we propose a simple exponential moving average (EMA) momentum
technique in parameter space that preserves safety performance by creating a
stable optimization path and retains the original pre-trained model's safety
properties. Our experiments on the Llama families across multiple datasets
(Dolly, Alpaca, ORCA) demonstrate that safety problems during fine-tuning can
largely be avoided without specialized interventions, outperforming existing
approaches that require additional safety data while offering practical
guidelines for maintaining both model performance and safety during adaptation.

</details>


### [376] [Defining and Benchmarking a Data-Centric Design Space for Brain Graph Construction](https://arxiv.org/abs/2508.12533)
*Qinwen Ge,Roza G. Bayrak,Anwar Said,Catie Chang,Xenofon Koutsoukos,Tyler Derr*

Main category: cs.LG

TL;DR: fMRI로부터 뇌 그래프를 구성하는 다양한 데이터 중심(datum-centric) 설정(시간적 신호 처리, 토폴로지 추출, 특징화)을 체계적으로 정의·평가하여, 표준 파이프라인보다 분류 성능을 높일 수 있음을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 기존 연구는 모델 중심(model-centric)으로 GNN 등 모델 설계에 집중했고, 뇌 그래프를 만드는 상류 데이터 처리 선택지는 고정되거나 충분히 탐색되지 않았음. 데이터 처리 단계의 설계가 downstream 성능에 미치는 영향을 체계적으로 규명하고자 함.

Method: 세 단계(시간 신호 처리, 연결성 희소화/통합, 그래프 특징화)에 걸친 디자인 스페이스를 정의. 고진폭 BOLD 필터, 희소화/통합 전략, 대체 상관 지표, 지연(시차) 동적 특성 등 기존 방법들의 조합을 변경·확장해 HCP1200, ABIDE 데이터셋에서 분류 실험을 수행.

Result: 데이터 중심의 신중한 구성은 표준 파이프라인 대비 일관된 분류 정확도 향상을 보였음. 다양한 전처리·연결성·특징화 조합이 성능에 유의미한 영향을 미침.

Conclusion: 상류 데이터 결정이 그래프 기반 신경영상 분석 성과에 중요하며, 데이터 중심 디자인 스페이스를 체계적으로 탐색하는 것이 모델 성능 향상과 재현성 개선에 기여할 수 있다.

Abstract: The construction of brain graphs from functional Magnetic Resonance Imaging
(fMRI) data plays a crucial role in enabling graph machine learning for
neuroimaging. However, current practices often rely on rigid pipelines that
overlook critical data-centric choices in how brain graphs are constructed. In
this work, we adopt a Data-Centric AI perspective and systematically define and
benchmark a data-centric design space for brain graph construction,
constrasting with primarily model-centric prior work. We organize this design
space into three stages: temporal signal processing, topology extraction, and
graph featurization. Our contributions lie less in novel components and more in
evaluating how combinations of existing and modified techniques influence
downstream performance. Specifically, we study high-amplitude BOLD signal
filtering, sparsification and unification strategies for connectivity,
alternative correlation metrics, and multi-view node and edge features, such as
incorporating lagged dynamics. Experiments on the HCP1200 and ABIDE datasets
show that thoughtful data-centric configurations consistently improve
classification accuracy over standard pipelines. These findings highlight the
critical role of upstream data decisions and underscore the importance of
systematically exploring the data-centric design space for graph-based
neuroimaging. Our code is available at
https://github.com/GeQinwen/DataCentricBrainGraphs.

</details>


### [377] [OS-R1: Agentic Operating System Kernel Tuning with Reinforcement Learning](https://arxiv.org/abs/2508.12551)
*Hongyu Lin,Yuchen Li,Haoran Luo,Kaichun Yao,Libo Zhang,Mingjie Xing,Yanjun Wu*

Main category: cs.LG

TL;DR: OS-R1은 규칙 기반 강화학습(RL)과 LLM을 결합한 에이전트형 리눅스 커널 튜닝 프레임워크로, 커널 설정을 RL 환경으로 추상화해 LLM의 효율적 탐색과 정확한 설정 변경을 지원하며, 사용자정의 보상과 2단계 학습으로 수렴 속도와 일반화를 개선해 기존 휴리스틱 대비 최대 5.6% 성능 향상을 보였다고 주장한다.


<details>
  <summary>Details</summary>
Motivation: 기존 리눅스 커널 튜닝 기법들이 효율성·확장성·일반화에서 한계를 보이므로, LLM의 추론 능력과 RL의 최적화 프레임워크를 결합해 자동화된, 정확하고 데이터 효율적인 튜닝 방안을 제시하려 함.

Method: 커널 설정 공간을 RL 환경으로 모델링하고 규칙(rule)-기반 RL 에이전트(LLM이 행동을 제안하고 규칙으로 검증·적용)를 설계함. 커스텀 보상함수는 추론 표준화, 설정 변경 정확성, 시스템 성능 인지를 반영하도록 구성. 수렴 가속 및 재학습 최소화를 위한 2단계(아마 사전학습/미세조정) 트레이닝 프로세스를 제안.

Result: 실험에서 휴리스틱 기반 튜닝보다 최대 5.6% 성능 향상, 데이터 효율성 우수, 다양한 실제 응용에 적응 가능함을 보고. 코드·데이터 공개.

Conclusion: OS-R1은 LLM과 규칙 기반 RL의 결합으로 실용적이고 일반화 가능한 커널 튜닝을 달성했으며, 향후 다양한 환경에 실무 적용 가능한 가능성을 보여준다.

Abstract: Linux kernel tuning is essential for optimizing operating system (OS)
performance. However, existing methods often face challenges in terms of
efficiency, scalability, and generalization. This paper introduces OS-R1, an
agentic Linux kernel tuning framework powered by rule-based reinforcement
learning (RL). By abstracting the kernel configuration space as an RL
environment, OS-R1 facilitates efficient exploration by large language models
(LLMs) and ensures accurate configuration modifications. Additionally, custom
reward functions are designed to enhance reasoning standardization,
configuration modification accuracy, and system performance awareness of the
LLMs. Furthermore, we propose a two-phase training process that accelerates
convergence and minimizes retraining across diverse tuning scenarios.
Experimental results show that OS-R1 significantly outperforms existing
baseline methods, achieving up to 5.6% performance improvement over heuristic
tuning and maintaining high data efficiency. Notably, OS-R1 is adaptable across
various real-world applications, demonstrating its potential for practical
deployment in diverse environments. Our dataset and code are publicly available
at https://github.com/LHY-24/OS-R1.

</details>


### [378] [Illuminating LLM Coding Agents: Visual Analytics for Deeper Understanding and Enhancement](https://arxiv.org/abs/2508.12555)
*Junpeng Wang,Yuzhong Chen,Menghai Pan,Chin-Chia Michael Yeh,Mahashweta Das*

Main category: cs.LG

TL;DR: A visual analytics system for examining coding-agent behaviors (focused on AIDE) enabling comparative analysis at code, process, and LLM levels to support debugging and prompt engineering; validated via Kaggle case studies.


<details>
  <summary>Details</summary>
Motivation: Manual inspection of individual agent outputs is inefficient; ML scientists need structured tools to track code evolution, compare iterations, and identify improvement opportunities in LLM-driven coding agents.

Method: Design and implement a visual analytics system integrated with the AIDE framework that provides three analysis levels—Code-Level (debugging and code refinement over iterations), Process-Level (comparison of solution-seeking processes), and LLM-Level (behavioral differences across LLMs)—and interactive visualizations for comparative inspection.

Result: The system surfaces insights about how agents generate and refine solutions, highlights alternative solution paths, and exposes differences across LLMs, demonstrated through case studies on popular Kaggle competitions.

Conclusion: Integrating multi-level comparative visualizations helps ML scientists gain a structured understanding of coding-agent behaviors, improving debugging and prompt engineering; the approach shows promise but needs broader evaluation and potential generalization beyond AIDE.

Abstract: Coding agents powered by large language models (LLMs) have gained traction
for automating code generation through iterative problem-solving with minimal
human involvement. Despite the emergence of various frameworks, e.g.,
LangChain, AutoML, and AIDE, ML scientists still struggle to effectively review
and adjust the agents' coding process. The current approach of manually
inspecting individual outputs is inefficient, making it difficult to track code
evolution, compare coding iterations, and identify improvement opportunities.
To address this challenge, we introduce a visual analytics system designed to
enhance the examination of coding agent behaviors. Focusing on the AIDE
framework, our system supports comparative analysis across three levels: (1)
Code-Level Analysis, which reveals how the agent debugs and refines its code
over iterations; (2) Process-Level Analysis, which contrasts different
solution-seeking processes explored by the agent; and (3) LLM-Level Analysis,
which highlights variations in coding behavior across different LLMs. By
integrating these perspectives, our system enables ML scientists to gain a
structured understanding of agent behaviors, facilitating more effective
debugging and prompt engineering. Through case studies using coding agents to
tackle popular Kaggle competitions, we demonstrate how our system provides
valuable insights into the iterative coding process.

</details>


### [379] [Deep Learning-Based Financial Time Series Forecasting via Sliding Window and Variational Mode Decomposition](https://arxiv.org/abs/2508.12565)
*Luke Li*

Main category: cs.LG

TL;DR: VMD로 시계열을 여러 부성분으로 분해하고 슬라이딩 윈도우로 입력을 구성하여 LSTM으로 예측하면 원시 시계열만 사용할 때보다 예측 성능과 안정성이 향상된다.


<details>
  <summary>Details</summary>
Motivation: 금융 시계열은 비정상성·노이즈·복잡한 주기성을 가지므로 단일 모델로 직접 학습하면 성능과 일반화에 한계가 있다. 이를 완화하기 위해 시계열을 더 부드러운 구성 요소로 분해하고 창 기반 입력으로 모델 적응력을 높이고자 한다.

Method: 과거 주가와 관련 시장 지표로 데이터셋을 구성한 뒤, VMD(Variational Mode Decomposition)를 적용해 비정상 시계열을 여러 부성분으로 분해한다. 분해된 각 성분(또는 재합성된 신호)을 슬라이딩 윈도우 기법으로 시퀀스로 변환해 딥러닝 모델(LSTM)에 입력한다. 원시 시계열을 바로 학습한 LSTM과 성능을 비교 평가한다.

Result: VMD 전처리를 적용한 시나리오에서 LSTM의 예측 정확도와 안정성이 개선되었다고 보고한다(요약적 서술—추가적 수치·지표는 초록에 없음).

Conclusion: VMD와 슬라이딩 윈도우 결합은 비정상 금융 시계열의 잡음·비선형성을 완화해 LSTM 기반 예측의 적응성과 안정성을 높일 수 있다.

Abstract: To address the complexity of financial time series, this paper proposes a
forecasting model combining sliding window and variational mode decomposition
(VMD) methods. Historical stock prices and relevant market indicators are used
to construct datasets. VMD decomposes non-stationary financial time series into
smoother subcomponents, improving model adaptability. The decomposed data is
then input into a deep learning model for prediction. The study compares the
forecasting effects of an LSTM model trained on VMD-processed sequences with
those using raw time series, demonstrating better performance and stability.

</details>


### [380] [Data-driven particle dynamics: Structure-preserving coarse-graining for emergent behavior in non-equilibrium systems](https://arxiv.org/abs/2508.12569)
*Quercus Hernandez,Max Win,Thomas C. O'Connor,Paulo E. Arratia,Nathaniel Trask*

Main category: cs.LG

TL;DR: 메트리플렉틱(메트립렉틱) 브래킷을 이용해 열역학적 일관성(에너지 보존, 엔트로피 증가, 변동-소산 균형)과 운동량 보존을 보장하는 자가지도 학습 기반의 입자계 축소모델 학습 프레임워크를 제안하고, 벤치마크 및 실제 사례(스타 중합체 축소, 콜로이드 고속비디오)에서 비평형 통계까지 재현함을 보였다.


<details>
  <summary>Details</summary>
Motivation: 고차원 입자 계의 축소(코어스그레인)는 정보 손실로 인해 마찰·소음·기억효과(히스토리 의존성) 등 열역학적·확률적 현상이 새로 생기므로, 축약된 모델이 물리적 제약(에너지·운동량 보존, 엔트로피 증가, 변동-소산 균형)을 자동으로 만족하도록 학습할 필요가 있다.

Method: 메트리플렉틱 브래킷 형식을 수학적으로 도입하여 보존성(안티대칭 브래킷)과 소산성(대칭 브래킷)을 동시에 표현하고, 입자 이산화에 특화하여 구현. 엔트로피 상태변수에 레이블이 없으므로 자가지도 학습으로 구조적(엔트로피성) 변수를 식별. 이론적 보증을 유지하면서 PyTorch와 LAMMPS 기반의 실용적 구현을 제공.

Result: 벤치마크에서 기대한 보존·소산 특성을 만족했으며, (1) 높은 수준의 축소에도 비평형 통계를 보존하면서 스타 중합체 축약 모델을 성공적으로 재구성했고, (2) 고속비디오로부터 콜로이드 현미경 데이터를 학습하여 국소 재배열과 확률적 거동의 결합을 포착. 또한 불확실성·열역학적 균형(변동-소산 관계)을 재현함.

Conclusion: 메트리플렉틱 기반 학습은 물리적 제약을 내재화하여 신뢰성 있는 축소 모델을 제공하며, 공개된 코드(PyTorch, LAMMPS)를 통해 대규모 및 다양한 입자계로 확장 가능하다.

Abstract: Multiscale systems are ubiquitous in science and technology, but are
notoriously challenging to simulate as short spatiotemporal scales must be
appropriately linked to emergent bulk physics. When expensive high-dimensional
dynamical systems are coarse-grained into low-dimensional models, the entropic
loss of information leads to emergent physics which are dissipative,
history-dependent, and stochastic. To machine learn coarse-grained dynamics
from time-series observations of particle trajectories, we propose a framework
using the metriplectic bracket formalism that preserves these properties by
construction; most notably, the framework guarantees discrete notions of the
first and second laws of thermodynamics, conservation of momentum, and a
discrete fluctuation-dissipation balance crucial for capturing non-equilibrium
statistics. We introduce the mathematical framework abstractly before
specializing to a particle discretization. As labels are generally unavailable
for entropic state variables, we introduce a novel self-supervised learning
strategy to identify emergent structural variables. We validate the method on
benchmark systems and demonstrate its utility on two challenging examples: (1)
coarse-graining star polymers at challenging levels of coarse-graining while
preserving non-equilibrium statistics, and (2) learning models from high-speed
video of colloidal suspensions that capture coupling between local
rearrangement events and emergent stochastic dynamics. We provide open-source
implementations in both PyTorch and LAMMPS, enabling large-scale inference and
extensibility to diverse particle-based systems.

</details>


### [381] [Deep Learning Model for Amyloidogenicity Prediction using a Pre-trained Protein LLM](https://arxiv.org/abs/2508.12575)
*Zohra Yagoub,Hafida Bouziane*

Main category: cs.LG

TL;DR: 발표된 방법은 사전학습된 단백질 LLM에서 얻은 문맥적 서열 특징을 Bi-LSTM/GRU로 처리하여 아밀로이드성 영역을 예측하는 모델로, 10겹 교차검증 정확도 84.5% 및 독립 시험셋 정확도 83%를 보고함.


<details>
  <summary>Details</summary>
Motivation: 서열 기반 특징이 아밀로이드 예측에서 높은 성능을 보이는 만큼, 더 풍부한 문맥 정보를 담는 LLM 임베딩을 이용해 예측 정확도를 향상시키려는 목표.

Method: 사전학습된 단백질 대형 언어모델(LLM)로부터 단백질 서열의 문맥적 임베딩을 추출하고, 이를 양방향 LSTM 및 GRU 네트워크에 입력하여 서열 내 아밀로이드성 영역을 분류(혹은 시퀀스 레벨/리전 레벨 예측). 10-폴드 교차검증과 독립 테스트셋으로 성능 평가.

Result: 10-겹 교차검증에서 정확도 84.5%, 테스트셋에서 정확도 83%를 달성하여 경쟁력 있는 성능을 보임.

Conclusion: 사전학습된 단백질 LLM으로부터 얻은 문맥적 특징이 아밀로이드 예측 성능을 향상시킬 수 있음을 시사하며, LLM 기반 접근이 이 분야에 유용함을 제시함.

Abstract: The prediction of amyloidogenicity in peptides and proteins remains a focal
point of ongoing bioinformatics. The crucial step in this field is to apply
advanced computational methodologies. Many recent approaches to predicting
amyloidogenicity within proteins are highly based on evolutionary motifs and
the individual properties of amino acids. It is becoming increasingly evident
that the sequence information-based features show high predictive performance.
Consequently, our study evaluated the contextual features of protein sequences
obtained from a pretrained protein large language model leveraging
bidirectional LSTM and GRU to predict amyloidogenic regions in peptide and
protein sequences. Our method achieved an accuracy of 84.5% on 10-fold
cross-validation and an accuracy of 83% in the test dataset. Our results
demonstrate competitive performance, highlighting the potential of LLMs in
enhancing the accuracy of amyloid prediction.

</details>


### [382] [Widening the Network Mitigates the Impact of Data Heterogeneity on FedAvg](https://arxiv.org/abs/2508.12576)
*Like Jian,Dong Liu*

Main category: cs.LG

TL;DR: 폭넓게 과매개변수화된 신경망에서는 FedAvg의 데이터 이질성 영향이 사라져 중앙집중 학습과 동등한 일반화 성능을 달성한다는 이론·실험적 주장.


<details>
  <summary>Details</summary>
Motivation: 연합학습(FL)은 각 클라이언트의 데이터가 비독립·비동일(IID 아님)일 때 글로벌 모델 학습에 어려움이 있으며, 특히 FedAvg에서 데이터 이질성이 수렴성과 일반화에 미치는 영향을 이론적으로 이해할 필요가 있다.

Method: 과매개변수(폭이 큰) 신경망에서 FedAvg를 경사하강법(GD)으로 분석. 무한 폭(Neural Tangent Kernel, 선형화) 극한에서 전역·지역 모델의 거동을 선형 모델로 근사하고, 이질성 항이 폭에 따라 어떻게 사라지는지 수렴성 증명을 제공. 여러 아키텍처·손실·최적화에 대해 실험으로 검증.

Result: 네트워크 폭이 커질수록 데이터 이질성이 미치는 영향이 줄어들며, 폭이 무한대에 이르면 완전히 사라져 FedAvg의 글로벌·로컬 모델이 선형 거동을 보이고, 같은 GD 반복 횟수에서 중앙집중 학습과 동일한 일반화 성능을 달성함. 실험이 이론 예측을 지지.

Conclusion: 충분히 폭이 큰(과매개변수화된) 신경망에서는 FedAvg의 이질성 문제를 근본적으로 완화할 수 있으며, 무한폭 극한에서는 중앙집중 학습과 동등한 성능을 얻을 수 있다 — 이는 FL 알고리즘 설계와 이론 이해에 중요한 시사점을 줌.

Abstract: Federated learning (FL) enables decentralized clients to train a model
collaboratively without sharing local data. A key distinction between FL and
centralized learning is that clients' data are non-independent and identically
distributed, which poses significant challenges in training a global model that
generalizes well across heterogeneous local data distributions. In this paper,
we analyze the convergence of overparameterized FedAvg with gradient descent
(GD). We prove that the impact of data heterogeneity diminishes as the width of
neural networks increases, ultimately vanishing when the width approaches
infinity. In the infinite-width regime, we further prove that both the global
and local models in FedAvg behave as linear models, and that FedAvg achieves
the same generalization performance as centralized learning with the same
number of GD iterations. Extensive experiments validate our theoretical
findings across various network architectures, loss functions, and optimization
methods.

</details>


### [383] [Energy-Efficient Wireless LLM Inference via Uncertainty and Importance-Aware Speculative Decoding](https://arxiv.org/abs/2508.12590)
*Jihoon Park,Seungeun Oh,Seong-Lyun Kim*

Main category: cs.LG

TL;DR: 토큰 수준의 필터링으로 에너지·통신 비용을 줄이면서 HLM(로컬 경량 모델 + 클라우드 LLM) 추론의 정확도를 유지하는 방법을 제안. 에피스테믹 불확실성과 어텐션 기반 중요도를 결합해 유의미한 토큰만 업로드함.


<details>
  <summary>Details</summary>
Motivation: 리소스 제약 환경(엣지)에서의 온디바이스 LLM 추론 수요 증가. 기존 HLM 연구는 정확도·지연 개선에 집중했지만 통신량과 에너지 효율은 간과됨.

Method: 토큰 단위로 에피스테믹 불확실도와 어텐션 중요도를 계산해 정보성이 높은 토큰만 선택적으로 클라우드에 업로드하는 필터링 메커니즘. 이를 통해 LLM 호출 및 전송량을 줄임.

Result: TinyLlama-1.1B(로컬)+LLaMA-2-7B(클라우드) 실험에서 표준 HLM 대비 최대 BERTScore 87.5%, 토큰 처리량 0.37 tok/s, 에너지 40.7% 절감. 기존 U-HLM 대비 BERTScore 85.8→87.0, 에너지 절감 31.6→43.6%, 처리량 0.36→0.40 보고.

Conclusion: 대역폭이 제한된 엣지 환경에서 에너지 효율적이면서도 정확도를 유지하는 HLM 배포가 가능함을 제시.

Abstract: To address the growing demand for on-device LLM inference in
resource-constrained environments, hybrid language models (HLM) have emerged,
combining lightweight local models with powerful cloud-based LLMs. Recent
studies on HLM have primarily focused on improving accuracy and latency, while
often overlooking communication and energy efficiency. We propose a token-level
filtering mechanism for an energy-efficient importance- and uncertainty-aware
HLM inference that leverages both epistemic uncertainty and attention-based
importance. Our method opportunistically uploads only informative tokens,
reducing LLM usage and communication costs. Experiments with TinyLlama-1.1B and
LLaMA-2-7B demonstrate that our method achieves up to 87.5% BERT Score and
token throughput of 0.37 tokens/sec while saving the energy consumption by
40.7% compared to standard HLM. Furthermore, compared to our previous U-HLM
baseline, our method improves BERTScore from 85.8% to 87.0%, energy savings
from 31.6% to 43.6%, and throughput from 0.36 to 0.40. This approach enables an
energy-efficient and accurate deployment of LLMs in bandwidth-constrained edge
environments.

</details>


### [384] [Physics-informed deep operator network for traffic state estimation](https://arxiv.org/abs/2508.12593)
*Zhihao Li,Ting Wang,Guojian Zou,Ruofei Wang,Ye Li*

Main category: cs.LG

TL;DR: 교통 상태 추정(TSE)을 PDE 기반 제한된 관측에서 해석하는 대신, 물리적 보정을 한 DeepONet(PI-DeepONet)을 사용해 희소 입력을 전체 시공간 교통 상태로 사상하는 연산자 학습 문제로 재구성했다. NGSIM 데이터에서 기존 방법들보다 우수한 성능을 보였고, 입력 함수 생성 방식과 분기(branch) 네트워크 복잡도 등의 설계 요소가 성능에 미치는 영향을 분석했다.


<details>
  <summary>Details</summary>
Motivation: PINN이 PDE 제약을 점별로 강제하는 한계와, 희소·잡음 관측으로부터 전체 시공간장을 효율적으로 복원하고 교통 물리(보존 법칙·기본 다이어그램)를 더 직접적으로 통합하려는 필요성.

Method: PI-DeepONet 프레임워크로 TSE를 연산자 학습 문제로 설정. 분기(branch)와 줄기(trunk) 구조를 갖는 DeepONet에 교통 보존 법칙과 기본 다이어그램을 통합(손실 항 또는 구조적 제약)하여 희소 입력으로부터 전체 시공간 교통 상태를 출력하도록 학습.

Result: NGSIM 데이터셋 실험에서 최신 기법들보다 우수한 성능을 보고. 분기 네트워크 복잡도와 입력 함수 생성 전략, 함수 개수 등의 설계가 모델 성능에 중요한 영향을 미침.

Conclusion: 연산자 학습에 물리 제약을 결합한 접근이 교통 상태 추정에서 유망하며, 입력 함수 설계와 분기 네트워크 구성이 성능과 견고성에 큰 영향을 끼친다.

Abstract: Traffic state estimation (TSE) fundamentally involves solving
high-dimensional spatiotemporal partial differential equations (PDEs) governing
traffic flow dynamics from limited, noisy measurements. While Physics-Informed
Neural Networks (PINNs) enforce PDE constraints point-wise, this paper adopts a
physics-informed deep operator network (PI-DeepONet) framework that
reformulates TSE as an operator learning problem. Our approach trains a
parameterized neural operator that maps sparse input data to the full
spatiotemporal traffic state field, governed by the traffic flow conservation
law. Crucially, unlike PINNs that enforce PDE constraints point-wise,
PI-DeepONet integrates traffic flow conservation model and the fundamental
diagram directly into the operator learning process, ensuring physical
consistency while capturing congestion propagation, spatial correlations, and
temporal evolution. Experiments on the NGSIM dataset demonstrate superior
performance over state-of-the-art baselines. Further analysis reveals insights
into optimal function generation strategies and branch network complexity.
Additionally, the impact of input function generation methods and the number of
functions on model performance is explored, highlighting the robustness and
efficacy of proposed framework.

</details>


### [385] [FLARE: Fast Low-rank Attention Routing Engine](https://arxiv.org/abs/2508.12594)
*Vedant Puri,Aditya Joglekar,Kevin Ferguson,Yu-hsuan Chen,Yongjie Jessica Zhang,Levent Burak Kara*

Main category: cs.LG

TL;DR: FLARE는 고정 길이의 잠재(latent) 시퀀스를 이용해 주의를 라우팅함으로써 자기주의(self-attention)를 O(NM) 선형 복잡도로 만든다 (M << N). PDE 서러게이트 모델 등에서 SOTA보다 우수한 정확도를 보이며 대형 문제에 확장 가능. 코드 및 새로운 데이터셋 공개.


<details>
  <summary>Details</summary>
Motivation: 자기주의의 이차적(Quadratic) 계산 비용은 큰 비구조화 메쉬나 대규모 토큰 수를 가지는 PDE 및 물리 시뮬레이션 문제에서 확장성을 제한한다. 이를 해결할 선형 복잡도 주의 메커니즘이 필요하다.

Method: 각 attention 헤드는 학습 가능한 쿼리 토큰을 사용해 입력 시퀀스를 길이 M (M << N)의 고정 잠재 시퀀스로 투영한다. 모든 글로벌 통신은 이 병목(latent) 시퀀스를 통해 라우팅되어 저차원(저랭크) 형태의 주의를 학습하게 되고, 연산 비용을 O(NM)으로 낮춘다.

Result: FLARE는 매우 큰 문제 크기로 확장할 수 있고, 다양한 벤치마크에서 기존 신경 PDE 서러게이트들보다 더 나은 정확도를 기록했다. 또한 적층 제조(additive manufacturing)용 새 데이터셋과 코드(깃허브)도 공개했다.

Conclusion: 잠재 시퀀스를 경유하는 라우팅으로 효율적이고 확장 가능한 자기주의를 제공해 PDE 서러게이트 및 비구조화 메쉬 문제에 유용하다. 다만 잠재 길이 M 선택에 따른 표현력 제한과 비교 대상(다른 선형 주의 기법)별 장단점 분석이 필요하다.

Abstract: The quadratic complexity of self-attention limits its applicability and
scalability on large unstructured meshes. We introduce Fast Low-rank Attention
Routing Engine (FLARE), a linear complexity self-attention mechanism that
routes attention through fixed-length latent sequences. Each attention head
performs global communication among $N$ tokens by projecting the input sequence
onto a fixed length latent sequence of $M \ll N$ tokens using learnable query
tokens. By routing attention through a bottleneck sequence, FLARE learns a
low-rank form of attention that can be applied at $O(NM)$ cost. FLARE not only
scales to unprecedented problem sizes, but also delivers superior accuracy
compared to state-of-the-art neural PDE surrogates across diverse benchmarks.
We also release a new additive manufacturing dataset to spur further research.
Our code is available at https://github.com/vpuri3/FLARE.py.

</details>


### [386] [Constructing Invariant and Equivariant Operations by Symmetric Tensor Network](https://arxiv.org/abs/2508.12596)
*Meng Zhang,Chao Wang,Hao Zhang,Shaojun Dong,Lixin He*

Main category: cs.LG

TL;DR: Systematic method to construct invariant and equivariant operations for Cartesian and spherical tensors using a symmetric tensor-network graphical formalism; applied to equivariant message passing in geometry GNNs and to learn constitutive laws of materials.


<details>
  <summary>Details</summary>
Motivation: Symmetry-aware neural networks need principled invariant/equivariant building blocks that work for inputs/outputs of varying tensor rank and type; existing constructions can be ad hoc or limited in scope. A unified, provable construction simplifies design and broadens applicability in geometric deep learning and physics-informed ML.

Method: Introduce a graphical representation based on symmetric tensor networks to systematically construct valid invariant and equivariant maps for Cartesian and spherical tensors of different ranks/types. Use the representation to derive and prove constructions, and instantiate them to build equivariant interaction messages for geometry graph neural networks.

Result: A unified framework and explicit constructions for invariant/equivariant operations, with simplified proofs via the tensor-network diagrams. Demonstrated application by designing an equivariant interaction message for a geometry GNN and an equivariant ML model trained to learn material constitutive laws (empirical evaluation implied but not detailed in abstract).

Conclusion: The proposed symmetric tensor-network approach offers a general, graphical, and provable way to create invariant and equivariant operations across tensor types, facilitating design of equivariant GNN components and physics-aware ML models.

Abstract: Design of neural networks that incorporate symmetry is crucial for geometric
deep learning. Central to this effort is the development of invariant and
equivariant operations. This works presents a systematic method for
constructing valid invariant and equivariant operations. It can handle inputs
and outputs in the form of Cartesian tensors with different rank, as well as
spherical tensors with different types. In addition, our method features a
graphical representation utilizing the symmetric tensor network, which
simplifies both the proofs and constructions related to invariant and
equivariant functions. We also apply this approach to design the equivariant
interaction message for the geometry graph neural network, and equivariant
machine learning model to learn the constitutive law of materials.

</details>


### [387] [A Hybrid Surrogate for Electric Vehicle Parameter Estimation and Power Consumption via Physics-Informed Neural Operators](https://arxiv.org/abs/2508.12602)
*Hansol Lim,Jongseong Brad Choi,Jee Won Lee,Haeseong Jeoung,Minkyu Han*

Main category: cs.LG

TL;DR: 속도와 가속도만으로 시간에 따라 변하는 모터·회생 제동 효율, 공기저항·구름저항·유효질량·보조전력 등을 추정하고, 이를 물리 기반 배터리 전력 추정에 직접 넣는 하이브리드 대리모델을 제안함. Tesla 로그에서 MAE 0.2kW(고속 주행 견인전력의 약 1%)를 달성함.


<details>
  <summary>Details</summary>
Motivation: 정확하고 해석 가능한 전기차( EV ) 소비전력 및 차량 파라미터 추정기는 경로 최적화, 에코 라우팅, 온보드 진단 및 예지보전 등에 필수적이다. 기존 접근은 물리 기반 모델(해석 가능하지만 파라미터 추정이 어렵고 제한적)과 블랙박스 ML(표현력 높으나 물리 해석 불가)의 절충이 필요하다.

Method: Fourier Neural Operator 기반의 Spectral Parameter Operator(SPO)를 전역 문맥 캡처용으로 사용하고, 순전파에서 미분 가능 물리(physics) 모듈을 결합한 모듈식 하이브리드 아키텍처를 설계. 입력은 속도와 가속도만이며, 출력은 시간변화하는 모터/회생효율, 공기저항 계수, 구름저항, 유효질량, 보조전력 등. 이 파라미터들을 물리식에 넣어 배터리 전력을 직접 계산하므로 별도의 물리-잔차 손실이 필요 없음.

Result: Tesla Model 3와 Model S에서 평균절대오차(MAE) 0.2kW(고속 견인전력의 ~1%), Kia EV9에서는 약 0.8kW를 기록. 모델은 해석 가능하고 보이지 않는 조건·샘플링률에도 잘 일반화되는 것으로 보고되어 응용성이 높음.

Conclusion: 모듈식 설계로 학습된 표현이 물리적으로 의미 있는 파라미터로 수렴하며, 정확도·해석성·일반화 능력을 모두 만족해 경로최적화·에코라우팅·진단·PHM 등 실무 적용에 적합하다.

Abstract: We present a hybrid surrogate model for electric vehicle parameter estimation
and power consumption. We combine our novel architecture Spectral Parameter
Operator built on a Fourier Neural Operator backbone for global context and a
differentiable physics module in the forward pass. From speed and acceleration
alone, it outputs time-varying motor and regenerative braking efficiencies, as
well as aerodynamic drag, rolling resistance, effective mass, and auxiliary
power. These parameters drive a physics-embedded estimate of battery power,
eliminating any separate physics-residual loss. The modular design lets
representations converge to physically meaningful parameters that reflect the
current state and condition of the vehicle. We evaluate on real-world logs from
a Tesla Model 3, Tesla Model S, and the Kia EV9. The surrogate achieves a mean
absolute error of 0.2kW (about 1% of average traction power at highway speeds)
for Tesla vehicles and about 0.8kW on the Kia EV9. The framework is
interpretable, and it generalizes well to unseen conditions, and sampling
rates, making it practical for path optimization, eco-routing, on-board
diagnostics, and prognostics health management.

</details>


### [388] [SSPO: Self-traced Step-wise Preference Optimization for Process Supervision and Reasoning Compression](https://arxiv.org/abs/2508.12604)
*Yuyang Xu,Yi Cheng,Haochao Ying,Zhuoyun Du,Renjun Hu,Xing Shi,Wei Lin,Jian Wu*

Main category: cs.LG

TL;DR: 이 논문은 LLM의 '과다추론(overthinking)' 문제를 줄이기 위해 모델 자체가 생성한 단계별 선호 신호를 이용해 각 추론 단계를 미세 최적화하는 Self-traced Step-wise Preference Optimization(SSPO)를 제안한다. 보조 모델이나 단계별 수동 라벨 없이 더 간결하고 정확한 추론 시퀀스를 얻는 방법이다.


<details>
  <summary>Details</summary>
Motivation: 기존의 사후 훈련 방법(예: CoT + RL)은 보조 모델·추가 추론으로 계산비용이 크고, 장황한 중간 추론에서 오류가 누적돼 잘못된 답이 발생하는 문제가 있다. 이를 해결해 각 단계별로 올바른 자기 수정을 유도하고 과다추론을 억제하려는 동기.

Method: SSPO는 외부 보상모델이나 수작업 라벨 없이 모델 자신이 생성한 단계별 선호(preference) 신호를 수집해, 각 추론 단계별 보상을 미세조정하는 RL 기반 프로세스 감독 프레임워크다. 이를 통해 불필요한 추론 단계를 압축하거나 제거한다.

Result: 실험에서 SSPO는 추론 시퀀스를 더 정확하고 간결하게 만들어 과다추론 행동을 효과적으로 완화했으며, 다양한 도메인·언어에서 성능 저하 없이 동작함을 보였다.

Conclusion: 모델 자체의 내부 선호 신호를 이용한 단계별 최적화는 보조 모델이나 수작업 없이도 추론 압축과 성능 유지라는 균형을 달성할 수 있는 현실적인 방법임을 제시한다.

Abstract: Test-time scaling has proven effective in further enhancing the performance
of pretrained Large Language Models (LLMs). However, mainstream post-training
methods (i.e., reinforcement learning (RL) with chain-of-thought (CoT)
reasoning) often incur substantial computational overhead due to auxiliary
models and overthinking. In this paper, we empirically reveal that the
incorrect answers partially stem from verbose reasoning processes lacking
correct self-fix, where errors accumulate across multiple reasoning steps. To
this end, we propose Self-traced Step-wise Preference Optimization (SSPO), a
pluggable RL process supervision framework that enables fine-grained
optimization of each reasoning step. Specifically, SSPO requires neither
auxiliary models nor stepwise manual annotations. Instead, it leverages
step-wise preference signals generated by the model itself to guide the
optimization process for reasoning compression. Experiments demonstrate that
the generated reasoning sequences from SSPO are both accurate and succinct,
effectively mitigating overthinking behaviors without compromising model
performance across diverse domains and languages.

</details>


### [389] [How can we trust opaque systems? Criteria for robust explanations in XAI](https://arxiv.org/abs/2508.12623)
*Florian J. Boge,Annika Schuster*

Main category: cs.LG

TL;DR: 딥러닝 설명 가능성의 신뢰성을 위해 두 가지 견고성 개념을 제시한다: 설명적 견고성(ER)과 설명방법 견고성(EMR). ER은 서로 다른 XAI 기법들이 유사한 상황에서 동일한 설명을 내놓는 것을, EMR은 개별 기법이 작은 입력·설정 변화에 대해 일관된 설명을 산출하는 것을 요구한다. EMR이 충족되어야 ER이 신뢰성을 갖는다는 주장을 형식화하고 프레임워크와 응용·향후연구 방향을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 딥러닝의 높은 성능에도 불구하고 내부 기저의 불투명성으로 인해 설명의 신뢰성이 문제된다. 서로 다른 XAI 기법 간 합치가 신뢰의 근거로 제시되지만, 모든 기법이 동일하게 잘못된 설명을 줄 수 있어 추가적 기준이 필요하다.

Method: ER과 EMR을 엄밀히 정의하고, 이 둘의 관계를 이론적으로 분석하는 프레임워크를 제안한다. 다양한 XAI 방법을 비교·분류하고, 사례 및 응용 영역을 통해 기준의 적용 방식을 제시한다. 수학적 정의·정형화와 실증적 평가 지침을 포함한다.

Result: ER과 EMR의 형식적 기준이 제시되고, EMR의 선행요구성을 논증함으로써 단일 기법의 견고성만으로는 신뢰를 보증할 수 없음을 보였다. 구체적 응용사례와 향후 연구 과제가 도출되었다.

Conclusion: XAI의 신뢰성 확보를 위해 ER과 EMR을 구분·동시에 충족시키는 것이 필요하다. 연구·실무에서 이들 기준을 검증할 벤치마크·평가방법 및 인과적 접근이 향후 과제로 제안된다.

Abstract: Deep learning (DL) algorithms are becoming ubiquitous in everyday life and in
scientific research. However, the price we pay for their impressively accurate
predictions is significant: their inner workings are notoriously opaque - it is
unknown to laypeople and researchers alike what features of the data a DL
system focuses on and how it ultimately succeeds in predicting correct outputs.
A necessary criterion for trustworthy explanations is that they should reflect
the relevant processes the algorithms' predictions are based on. The field of
eXplainable Artificial Intelligence (XAI) presents promising methods to create
such explanations. But recent reviews about their performance offer reasons for
skepticism. As we will argue, a good criterion for trustworthiness is
explanatory robustness: different XAI methods produce the same explanations in
comparable contexts. However, in some instances, all methods may give the same,
but still wrong, explanation. We therefore argue that in addition to
explanatory robustness (ER), a prior requirement of explanation method
robustness (EMR) has to be fulfilled by every XAI method. Conversely, the
robustness of an individual method is in itself insufficient for
trustworthiness. In what follows, we develop and formalize criteria for ER as
well as EMR, providing a framework for explaining and establishing trust in DL
algorithms. We also highlight interesting application cases and outline
directions for future work.

</details>


### [390] [FlowMol3: Flow Matching for 3D De Novo Small-Molecule Generation](https://arxiv.org/abs/2508.12629)
*Ian Dunn,David R. Koes*

Main category: cs.LG

TL;DR: FlowMol3는 3가지 간단한 기법(self-conditioning, fake atoms, train-time geometry distortion)을 도입해 GNN 구조나 흐름 매칭(formulation)을 바꾸지 않고도 소분자(all-atom) 생성의 성능을 크게 끌어올린 다중 모달(flow matching) 생성 모델이다. 약물 유사 분자에서 거의 100%의 분자 유효성을 달성하고, 학습 데이터의 작용기 구성 및 기하학을 더 정확히 재현하며, 파라미터 수는 유사 기법보다 한 자릿수 적다.


<details>
  <summary>Details</summary>
Motivation: 특정 성질을 갖는 현실적인 분자를 샘플링할 수 있는 생성 모델은 신약발견 등 화학 탐색을 가속화할 수 있다. 특히 분자 토폴로지와 3D 구조를 동시에 샘플링하는 모델들이 주목받고 있으나, 유효성·물리적 현실성·학습·추론의 안정성 문제를 해결할 필요가 있다.

Method: FlowMol3는 기존의 flow matching 기반 다중 모달 모델 아키텍처(그래프 신경망 및 흐름 매칭 공식)는 유지하면서, 계산 비용이 거의 없는 세 가지 아키텍처-무관(architecture-agnostic) 기법을 도입한다: 1) self-conditioning: 이전 예측을 조건으로 사용해 추론 안정성 개선, 2) fake atoms: 위조(가짜) 원자 도입으로 표현·경계 조건 완화 및 학습 신호 보강, 3) train-time geometry distortion: 훈련 시 기하학적 왜곡을 주어 모델이 분포 drift를 감지·보정하도록 유도.

Result: 도입 기법으로 약물 유사 분자(명시적 수소 포함)에서 거의 100%의 분자 유효성 달성. 학습 데이터의 작용기 분포와 분자 기하학을 더 정확히 재현하며, 비교 모델 대비 학습 가능한 파라미터 수는 대폭 절감(약 한 자릿수 적음).

Conclusion: 세 가지 간단한 전략이 transport 기반(흐름·확산) 생성 모델이 겪는 일반적 병리(pathology)를 완화하고, 추론 중 분포 drift를 감지·수정할 수 있게 해 성능·안정성을 개선한다. 이 기법들은 다른 확산·흐름 기반 분자 생성 모델에도 쉽게 이식 가능한 실용적 기법임을 시사한다.

Abstract: A generative model capable of sampling realistic molecules with desired
properties could accelerate chemical discovery across a wide range of
applications. Toward this goal, significant effort has focused on developing
models that jointly sample molecular topology and 3D structure. We present
FlowMol3, an open-source, multi-modal flow matching model that advances the
state of the art for all-atom, small-molecule generation. Its substantial
performance gains over previous FlowMol versions are achieved without changes
to the graph neural network architecture or the underlying flow matching
formulation. Instead, FlowMol3's improvements arise from three
architecture-agnostic techniques that incur negligible computational cost:
self-conditioning, fake atoms, and train-time geometry distortion. FlowMol3
achieves nearly 100% molecular validity for drug-like molecules with explicit
hydrogens, more accurately reproduces the functional group composition and
geometry of its training data, and does so with an order of magnitude fewer
learnable parameters than comparable methods. We hypothesize that these
techniques mitigate a general pathology affecting transport-based generative
models, enabling detection and correction of distribution drift during
inference. Our results highlight simple, transferable strategies for improving
the stability and quality of diffusion- and flow-based molecular generative
models.

</details>


### [391] [Score-informed Neural Operator for Enhancing Ordering-based Causal Discovery](https://arxiv.org/abs/2508.12650)
*Jiyeon Kang,Songseong Kim,Chanhui Lee,Doyeong Hwang,Joanie Hayoun Chung,Yunkyung Ko,Sumin Lee,Sungwoong Kim,Sungbin Lim*

Main category: cs.LG

TL;DR: Introduces Score-informed Neural Operator (SciNO), a probabilistic generative model in smooth function spaces to stably approximate the Hessian diagonal for score-matching-based causal ordering, improving stability and memory efficiency over Stein-based estimators and DiffAN and enabling integration with autoregressive priors for LLM-informed causal reasoning.


<details>
  <summary>Details</summary>
Motivation: Ordering-based causal discovery under ANM needs accurate Hessian-diagonal estimates for score-matching; existing Stein estimators are costly and DiffAN, while more efficient, is numerically unstable due to second-order derivatives of score models. A stable, scalable estimator that preserves structural information is needed.

Method: Proposes SciNO, a score-informed neural operator that models score/Hessian-diagonal in smooth function spaces to maintain structure and numerical stability. Also introduces a probabilistic control algorithm that combines SciNO's probabilities with autoregressive model priors to perform causal ordering and enable LLM-guided causal reasoning.

Result: Empirically reduces order divergence by 42.7% on synthetic graphs and 31.5% on real-world datasets on average compared to DiffAN, while keeping memory efficiency and scalability. Demonstrates improved causal reasoning in LLMs without extra fine-tuning or prompt engineering.

Conclusion: SciNO provides a more stable, memory-efficient way to estimate Hessian diagonals for score-based ordering methods, leading to better causal ordering and enabling effective integration with autoregressive LLM priors for data-driven causal reasoning.

Abstract: Ordering-based approaches to causal discovery identify topological orders of
causal graphs, providing scalable alternatives to combinatorial search methods.
Under the Additive Noise Model (ANM) assumption, recent causal ordering methods
based on score matching require an accurate estimation of the Hessian diagonal
of the log-densities. However, previous approaches mainly use Stein gradient
estimators, which are computationally expensive and memory-intensive. Although
DiffAN addresses these limitations by substituting kernel-based estimates with
diffusion models, it remains numerically unstable due to the second-order
derivatives of score models. To alleviate these problems, we propose
Score-informed Neural Operator (SciNO), a probabilistic generative model in
smooth function spaces designed to stably approximate the Hessian diagonal and
to preserve structural information during the score modeling. Empirical results
show that SciNO reduces order divergence by 42.7% on synthetic graphs and by
31.5% on real-world datasets on average compared to DiffAN, while maintaining
memory efficiency and scalability. Furthermore, we propose a probabilistic
control algorithm for causal reasoning with autoregressive models that
integrates SciNO's probability estimates with autoregressive model priors,
enabling reliable data-driven causal ordering informed by semantic information.
Consequently, the proposed method enhances causal reasoning abilities of LLMs
without additional fine-tuning or prompt engineering.

</details>


### [392] [Robust Federated Learning under Adversarial Attacks via Loss-Based Client Clustering](https://arxiv.org/abs/2508.12672)
*Emmanouil Kritharakis,Dusan Jakovetic,Antonios Makris,Konstantinos Tserpes*

Main category: cs.LG

TL;DR: 신뢰할 수 있는 서버가 소량의 신뢰 데이터셋을 보유한 상황에서, 서버와 최소 한 명의 클라이언트만 정직하면 동작하는 페더레이티드 러닝(FL) 알고리즘을 제안한다. 악의적(비잔틴) 클라이언트 수를 알 필요 없이 강한 공격 하에서도 이론적 최적성 갭을 보장하며, MNIST/FMNIST/CIFAR-10 실험에서 기존 평균·Trimmed·Median·Krum 계열 기법들보다 성능이 우수하다.


<details>
  <summary>Details</summary>
Motivation: FL에서 다수의 악의적 클라이언트가 존재할 때에도 전체 모델의 신뢰성을 확보하려면, 서버가 신뢰 가능한 정보(사전 보유한 데이터)를 활용해 공격을 방어할 수 있다는 가정에서 출발한다. 특히 악성 클라이언트 수를 사전에 알기 어렵다는 현실적 문제를 해결하려 함.

Method: 서버가 신뢰할 수 있는 사이드 데이터셋을 사용해 클라이언트 업데이트를 평가/정렬·필터링하거나 재학습/정제하는 방식으로 집계 과정을 개선한다(정확한 구현은 논문 본문 참조). 오직 서버와 하나의 정직한 클라이언트만을 전제로 설계되어, 비잔틴 공격자 수에 대한 별도 정보가 불필요하다. 이론적으로는 특정 가정(예: 손실 함수의 성질, 그래디언트의 경계 등) 하에 최적성 갭을 상계한다.

Result: 이론적 보증(상계된 옵티멀리티 갭)과 함께 MNIST, FMNIST, CIFAR-10에서 라벨 플립·사인 플립·가우시안 노이즈 등 공격 시 기존 집계 방법들보다 높은 정확도를 달성했다. Flower 프레임워크로 재현 가능한 실험을 수행함.

Conclusion: 서버 측 신뢰 데이터만으로도 최소 두 정직 참여자 조건하에 강건한 FL가 가능하며, 실험과 이론 모두에서 기존 방법 대비 우수함을 보였다. 다만 서버 데이터의 분포·크기, 공격자의 전략·적응성 등에 따른 한계는 추가 검증이 필요하다.

Abstract: Federated Learning (FL) enables collaborative model training across multiple
clients without sharing private data. We consider FL scenarios wherein FL
clients are subject to adversarial (Byzantine) attacks, while the FL server is
trusted (honest) and has a trustworthy side dataset. This may correspond to,
e.g., cases where the server possesses trusted data prior to federation, or to
the presence of a trusted client that temporarily assumes the server role. Our
approach requires only two honest participants, i.e., the server and one
client, to function effectively, without prior knowledge of the number of
malicious clients. Theoretical analysis demonstrates bounded optimality gaps
even under strong Byzantine attacks. Experimental results show that our
algorithm significantly outperforms standard and robust FL baselines such as
Mean, Trimmed Mean, Median, Krum, and Multi-Krum under various attack
strategies including label flipping, sign flipping, and Gaussian noise addition
across MNIST, FMNIST, and CIFAR-10 benchmarks using the Flower framework.

</details>


### [393] [Deploying Models to Non-participating Clients in Federated Learning without Fine-tuning: A Hypernetwork-based Approach](https://arxiv.org/abs/2508.12673)
*Yuhao Zhou,Jindi Lv,Yuxin Tian,Dan Si,Qing Ye,Jiancheng Lv*

Main category: cs.LG

TL;DR: HyperFedZero는 분포 인식 임베딩(노이지임베드 + 밸런싱 페널티)을 조건으로 하는 하이퍼네트워크로 비참여 클라이언트용 특화 모델을 청크 단위로 동적으로 생성해 제로샷 적응을 수행하며, 적은 오버헤드로 기존 방법들을 능가한다고 주장함.


<details>
  <summary>Details</summary>
Motivation: 연합학습에서 데이터 이질성 때문에 참여 클라이언트 중심의 방법들이 비참여(제로샷) 클라이언트의 도메인 변동과 자원 제약을 처리하지 못하는 문제를 해결하기 위함.

Method: 분포-인식 임베딩을 추출하는 익스트랙터에 NoisyEmbed와 Balancing Penalty를 적용해 특징 붕괴를 방지하고, 이 임베딩을 조건으로 하이퍼네트워크가 모델 파라미터를 청크별로 생성하여 비참여 클라이언트에 특화된 모델을 전달/사용하게 함.

Result: 여러 데이터셋과 모델에서 비교방법들을 지속적으로 능가하며 계산·저장·통신 오버헤드가 적다고 보고. 성분별 소거실험과 시각화로 각 구성요소의 필요성을 확인했다고 주장.

Conclusion: 분포 인식 유도 편향을 전방 계산에 통합한 제로샷 적응 방법으로 유망하나, 구현·보안·확장성·평가 범위에 대한 추가 정보가 필요함.

Abstract: Federated Learning (FL) has emerged as a promising paradigm for
privacy-preserving collaborative learning, yet data heterogeneity remains a
critical challenge. While existing methods achieve progress in addressing data
heterogeneity for participating clients, they fail to generalize to
non-participating clients with in-domain distribution shifts and resource
constraints. To mitigate this issue, we present HyperFedZero, a novel method
that dynamically generates specialized models via a hypernetwork conditioned on
distribution-aware embeddings. Our approach explicitly incorporates
distribution-aware inductive biases into the model's forward pass, extracting
robust distribution embeddings using a NoisyEmbed-enhanced extractor with a
Balancing Penalty, effectively preventing feature collapse. The hypernetwork
then leverages these embeddings to generate specialized models chunk-by-chunk
for non-participating clients, ensuring adaptability to their unique data
distributions. Extensive experiments on multiple datasets and models
demonstrate HyperFedZero's remarkable performance, surpassing competing methods
consistently with minimal computational, storage, and communication overhead.
Moreover, ablation studies and visualizations further validate the necessity of
each component, confirming meaningful adaptations and validating the
effectiveness of HyperFedZero.

</details>


### [394] [BUILDA: A Thermal Building Data Generation Framework for Transfer Learning](https://arxiv.org/abs/2508.12703)
*Thomas Krug,Fabian Raisch,Dominik Aimer,Markus Wirnsberger,Ferdinand Sigg,Benjamin Schäfer,Benjamin Tischler*

Main category: cs.LG

TL;DR: BuilDa는 단일 구역 Modelica 모델을 FMU로 내보내 Python에서 시뮬레이션해, 전이학습(TL)에 필요한 대량의 고품질 건물 열역학 합성 데이터를 전문가 지식 없이 생성할 수 있도록 한 프레임워크다.


<details>
  <summary>Details</summary>
Motivation: TL 기반 건물 열역학 모델링 연구에는 대규모·고품질 데이터가 필요하나, 공개 데이터셋과 기존 데이터 생성기 모두 양과 품질에서 부족하고, 기존 시뮬레이션 도구는 전문가 지식이 요구된다.

Method: BuilDa는 단일 구역(single-zone) Modelica 모델을 작성해 Functional Mock-up Unit(FMU)으로 내보내고, 이를 Python 환경에서 반복 시뮬레이션하여 다양한 조건의 합성 데이터를 대량으로 생성한다. 생성된 데이터는 사전학습(pretraining)과 미세조정(fine-tuning)에 TL용으로 활용된다.

Result: 프레임워크를 통해 합성 데이터를 성공적으로 생성했고, 이를 이용한 TL 모델의 사전학습 및 미세조정 실험을 수행하여 프레임워크의 실용성을 입증했다(초록 수준에서는 정량적 성능 수치는 제시되지 않음).

Conclusion: BuilDa는 전문 시뮬레이션 지식 없이도 TL 연구에 적합한 대량의 건물 열 데이터 생성을 가능하게 해, 소스 모델 선택 등 TL 연구 방향을 지원할 수 있는 도구로 제안된다.

Abstract: Transfer learning (TL) can improve data-driven modeling of building thermal
dynamics. Therefore, many new TL research areas emerge in the field, such as
selecting the right source model for TL. However, these research directions
require massive amounts of thermal building data which is lacking presently.
Neither public datasets nor existing data generators meet the needs of TL
research in terms of data quality and quantity. Moreover, existing data
generation approaches typically require expert knowledge in building
simulation. We present BuilDa, a thermal building data generation framework for
producing synthetic data of adequate quality and quantity for TL research. The
framework does not require profound building simulation knowledge to generate
large volumes of data. BuilDa uses a single-zone Modelica model that is
exported as a Functional Mock-up Unit (FMU) and simulated in Python. We
demonstrate BuilDa by generating data and utilizing it for pretraining and
fine-tuning TL models.

</details>


### [395] [Argos: A Decentralized Federated System for Detection of Traffic Signs in CAVs](https://arxiv.org/abs/2508.12712)
*Seyed Mahdi Haji Seyed Hossein,Alireza Hosseini,Soheil Hajian Manesh,Amirali Shahriary*

Main category: cs.LG

TL;DR: 차량 네트워크에서 교통 표지판 검출을 위해 데이터 공유 없이 협력 학습하는 연합학습(FL) 프레임워크를 제안하고 시뮬레이션으로 다양한 구성(FedProx/FedAdam/FedAVG, 라운드·에포크·클라이언트 비율·비균등 데이터)을 평가하여 FedProx가 이질성에서 우수하고 학습 라운드·참여율이 성능에 큰 영향을 미침을 보였다.


<details>
  <summary>Details</summary>
Motivation: 연결·자율차가 생성하는 대량의 센서 데이터로 인해 중앙집중식 학습은 개인정보·통신 비용 문제에 봉착하므로, 원시 데이터를 공유하지 않고도 차량 간 협업으로 강건한 인식 모델을 학습할 필요가 있다.

Method: 교통 표지판 클래스를 차량들에 분할하여 로컬에서 경량 물체 검출기 학습, Flower 시뮬레이터에서 FedProx/FedAdam/FedAVG로 모델 파라미터를 집계, 서버 라운드 수·로컬 에포크·클라이언트 참여율·데이터 분포(IID/Non-IID) 등을 바꿔 실험.

Result: 서버 라운드 증가(2→20)로 정확도 0.1 이하→0.8 이상으로 큰 향상, 로컬 에포크 8–10이 효율적(정확도 ≈0.67), 높은 클라이언트 참여율이 일반화 성능 개선(최대 ≈0.83), FedProx가 이질성에 강함, Non-IID가 IID보다 성능 저하, 학습 시간은 집계 전략보다 라운드 수에 더 민감.

Conclusion: 제안한 연합학습 방식은 개인정보를 보호하면서 차량 네트워크에서 확장 가능하게 교통 표지판 검출 모델을 학습할 수 있는 유망한 접근이며, 향후 강건한 집계·통신 최적화 통합을 통해 실제 배포에 적합하도록 발전시킬 수 있다.

Abstract: Connected and automated vehicles generate vast amounts of sensor data daily,
raising significant privacy and communication challenges for centralized
machine learning approaches in perception tasks. This study presents a
decentralized, federated learning framework tailored for traffic sign detection
in vehicular networks to enable collaborative model training without sharing
raw data. The framework partitioned traffic sign classes across vehicles for
specialized local training using lightweight object detectors, aggregated model
parameters via algorithms like FedProx, FedAdam and FedAVG in a simulated
environment with the Flower framework, and evaluated multiple configurations
including varying server rounds, local epochs, client participation fractions,
and data distributions. Experiments demonstrated that increasing server rounds
from 2 to 20 boosted accuracy from below 0.1 to over 0.8, moderate local epochs
(8-10) provided optimal efficiency with accuracies around 0.67, higher client
participation fractions enhanced generalization up to 0.83, FedProx
outperformed other aggregators in handling heterogeneity, non-IID data
distributions reduced performance compared to IID, and training duration
primarily scaled with the number of rounds rather than aggregation strategy. We
conclude that this federated approach may offer a scalable, privacy-preserving
solution for real-world vehicular deployments, potentially guiding future
integrations of robust aggregation and communication optimizations to advance
intelligent transportation systems.

</details>


### [396] [FedSODA: Federated Fine-tuning of LLMs via Similarity Group Pruning and Orchestrated Distillation Alignment](https://arxiv.org/abs/2508.12727)
*Manning Zhu,Songtao Guo,Pengzhan Zhou,Yansong Ning,Chang Han,Dewen Qiao*

Main category: cs.LG

TL;DR: FedSODA는 리소스 제한 클라이언트에서 전체 모델을 저장·접근하지 않고도 연합 파인튜닝(FFT)을 가능하게 하는 경량화 프레임워크이다. 유사성 그룹 가지치기(SGP)로 중복 계층을 제거하고, 조율 증류 정렬(ODA)로 서브-LLM과 전체 LLM 간 그래디언트 발산을 줄이며, QLoRA와 경량 어댑터를 결합해 통신·저장 비용을 크게 낮추고 성능을 소폭 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 리소스가 제한된 클라이언트에서 LLM의 도메인 특화 적응을 위해 FFT를 수행하려면 전체 모델의 저장·계산 부담을 줄이는 방법이 필요하다. 기존의 전체 모델 파인튜닝은 메모리·연산 요구가 커 실제 적용을 어렵게 한다.

Method: (1) SGP: LLM의 계층을 유사성 기반으로 그룹화해 중복 계층을 가지치기하여 서브-LLM을 생성. (2) ODA: 서브-LLM과 전체 LLM 사이의 그래디언트 차이를 줄이기 위한 조율된 증류 정렬 기법 도입. (3) QLoRA와 경량 어댑터를 활용해 클라이언트에서는 양자화된 서브-LLM과 어댑터만 배포·미세조정.

Result: 세 가지 공개 LLM과 다양한 다운스트림 태스크 실험에서 평균 통신량 70.6% 감소, 저장소 사용 75.6% 감소, 태스크 정확도 3.1% 향상이라는 성능 이득을 보고함.

Conclusion: FedSODA는 리소스 제약 환경에서 실용적인 FFT 솔루션을 제공하며 통신·저장 비용을 크게 줄이면서도 성능을 개선해 실제 배포 가능성을 높인다.

Abstract: Federated fine-tuning (FFT) of large language models (LLMs) has recently
emerged as a promising solution to enable domain-specific adaptation while
preserving data privacy. Despite its benefits, FFT on resource-constrained
clients relies on the high computational and memory demands of full-model
fine-tuning, which limits the potential advancement. This paper presents
FedSODA, a resource-efficient FFT framework that enables clients to adapt LLMs
without accessing or storing the full model. Specifically, we first propose a
similarity group pruning (SGP) module, which prunes redundant layers from the
full LLM while retaining the most critical layers to preserve the model
performance. Moreover, we introduce an orchestrated distillation alignment
(ODA) module to reduce gradient divergence between the sub-LLM and the full LLM
during FFT. Through the use of the QLoRA, clients only need to deploy quantized
sub-LLMs and fine-tune lightweight adapters, significantly reducing local
resource requirements. We conduct extensive experiments on three open-source
LLMs across a variety of downstream tasks. The experimental results demonstrate
that FedSODA reduces communication overhead by an average of 70.6%, decreases
storage usage by 75.6%, and improves task accuracy by 3.1%, making it highly
suitable for practical FFT applications under resource constraints.

</details>


### [397] [FedUNet: A Lightweight Additive U-Net Module for Federated Learning with Heterogeneous Models](https://arxiv.org/abs/2508.12740)
*Beomseok Seo,Kichang Lee,JaeYeon Park*

Main category: cs.LG

TL;DR: FedUNet는 각 클라이언트의 백본에 U-Net 스타일의 추가 모듈을 붙이고, U-Net의 병목(bottleneck)만 서버에 공유함으로써 구조가 다른 클라이언트들 간에 효율적으로 지식 전달을 수행하는 경량의 이종 연합학습(framework)이다. VGG 변형을 대상으로 한 실험에서 93.11% 및 경량형 92.68% 정확도와 0.89MB의 낮은 통신 오버헤드를 보고한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 연합학습은 클라이언트 간 동일한 모델 아키텍처를 전제로 하는 경우가 많아, 실제 이기종 환경에서 적용성이 제한된다. 모델 구조가 다른 기기들 사이에서도 효과적으로 학습할 수 있는 경량·통신효율적인 방법이 필요하다.

Method: 각 클라이언트의 고유한 백본에 U-Net 영감을 받은 추가적(additive) 모듈을 붙여 통합 표현을 학습한다. 모듈은 인코더-디코더 구조와 스킵 연결을 사용하며, 서버에는 U-Net의 병목 영역(작고 컴팩트한 부분)만 공유하여 구조 정렬 없이 지식 전달을 수행한다. 백본과 추가 모듈이 협력하여 클라이언트-불변 표현을 학습한다.

Result: VGG 변형 실험에서 FedUNet은 93.11% 정확도를 달성하였고, 경량화된 버전은 92.68%를 기록했다. 통신 오버헤드는 약 0.89MB로 매우 낮다.

Conclusion: U-Net 스타일의 추가 모듈과 병목 공유 전략은 이종 아키텍처 환경에서 통신 비용을 낮추면서도 효과적인 공동 학습을 가능하게 하며, 구조 정렬(architecture alignment) 없이도 성능을 유지할 수 있음을 보인다.

Abstract: Federated learning (FL) enables decentralized model training without sharing
local data. However, most existing methods assume identical model architectures
across clients, limiting their applicability in heterogeneous real-world
environments. To address this, we propose FedUNet, a lightweight and
architecture-agnostic FL framework that attaches a U-Net-inspired additive
module to each client's backbone. By sharing only the compact bottleneck of the
U-Net, FedUNet enables efficient knowledge transfer without structural
alignment. The encoder-decoder design and skip connections in the U-Net help
capture both low-level and high-level features, facilitating the extraction of
clientinvariant representations. This enables cooperative learning between the
backbone and the additive module with minimal communication cost. Experiment
with VGG variants shows that FedUNet achieves 93.11% accuracy and 92.68% in
compact form (i.e., a lightweight version of FedUNet) with only 0.89 MB low
communication overhead.

</details>


### [398] [A Multi-Resolution Benchmark Framework for Spatial Reasoning Assessment in Neural Networks](https://arxiv.org/abs/2508.12741)
*Manuela Imbriani,Gina Belmonte,Mieke Massink,Alessandro Tofani,Vincenzo Ciancia*

Main category: cs.LG

TL;DR: 신경망의 공간 추론 능력을 체계적으로 평가하기 위한 벤치마크 프레임워크를 제안하고, VoxLogicA로 생성한 합성 데이터(미로 연결성·거리 과제)를 nnU-Net으로 다해 다중 해상도에서 실험한 결과 기본적인 기하·위상 문제에서 일관된 실패를 보임.


<details>
  <summary>Details</summary>
Motivation: 의료 영상 등에서 요구되는 연결성·거리 같은 형태학적(공간적) 추론 능력에 대해 신경망이 실제로 얼마나 잘 수행하는지 체계적으로 평가할 수단이 부족하므로, 한층 명확하고 재현 가능한 평가 프로토콜이 필요함.

Method: VoxLogicA로 두 가지 유형의 합성 데이터셋(미로 기반 연결성 문제와 공간 거리 계산 문제)을 생성하고, nnU-Net을 표준화된 학습·교차검증 파이프라인으로 다중 해상도에서 학습·추론. 평가 지표로 Dice와 IoU를 사용하여 성능과 확장성·일반화 특성 확인.

Result: 예비 실험에서 신경망은 기본적 기하·위상 문제에서도 상당한 어려움을 보였고, 해상도 변화에 따른 확장성·일반화 문제 및 체계적인 실패 패턴이 관찰됨.

Conclusion: 재현 가능한 실험 프로토콜로 신경망의 구체적 한계를 규명할 수 있으며, 기호적 추론과의 하이브리드 접근이 공간 이해 향상을 위한 유망한 해결책임을 시사. 향후 연구 기반을 제공함.

Abstract: This paper presents preliminary results in the definition of a comprehensive
benchmark framework designed to systematically evaluate spatial reasoning
capabilities in neural networks, with a particular focus on morphological
properties such as connectivity and distance relationships. The framework is
currently being used to study the capabilities of nnU-Net, exploiting the
spatial model checker VoxLogicA to generate two distinct categories of
synthetic datasets: maze connectivity problems for topological analysis and
spatial distance computation tasks for geometric understanding. Each category
is evaluated across multiple resolutions to assess scalability and
generalization properties. The automated pipeline encompasses a complete
machine learning workflow including: synthetic dataset generation, standardized
training with cross-validation, inference execution, and comprehensive
evaluation using Dice coefficient and IoU (Intersection over Union) metrics.
Preliminary experimental results demonstrate significant challenges in neural
network spatial reasoning capabilities, revealing systematic failures in basic
geometric and topological understanding tasks. The framework provides a
reproducible experimental protocol, enabling researchers to identify specific
limitations. Such limitations could be addressed through hybrid approaches
combining neural networks with symbolic reasoning methods for improved spatial
understanding in clinical applications, establishing a foundation for ongoing
research into neural network spatial reasoning limitations and potential
solutions.

</details>


### [399] [Constrained Centroid Clustering: A Novel Approach for Compact and Structured Partitioning](https://arxiv.org/abs/2508.12758)
*Sowmini Devi Veeramachaneni,Ramamurthy Garimella*

Main category: cs.LG

TL;DR: CCC는 군집 중심과 군집 내 최외곽 점 간 최대거리를 제약하는 중심 기반 클러스터링 방식으로, 라그랑지안 해석을 통해 해석 가능한 닫힌형 해를 제시한다. 합성 원형 데이터에서 반지름 방향 퍼짐을 줄이고 각도 구조는 보존하며 K-means/GMM보다 더 조밀한 군집을 만든다.


<details>
  <summary>Details</summary>
Motivation: 전통적 중심 기반 군집은 군집의 분산·퍼짐을 제어하지 못해 해석성이나 애플리케이션 요구(예: 센서 커버리지, 로봇 협업)에 부합하지 않을 때가 있다. 군집 반경을 직접 제약해 구조적이고 해석 가능한 군집화를 달성하려는 동기.

Method: 군집 중심과 클러스터 내 최외곽 점 간 최대거리(반경)에 대한 제약을 라그랑지안으로 도입하고, 그에 대한 닫힌형 해를 유도해 중심을 업데이트하는 방식으로 CCC를 정의. 합성 원형(방사 대칭, 각도 균일) 데이터에서 비교 실험 수행.

Result: CCC는 반지름 방향 퍼짐을 줄여 더 조밀한 군집을 형성하고, 각도(방향) 구조는 유지함. ring-wise, sector-wise, joint entropy 측정에서 K-means·GMM 대비 우수한 성능을 보임.

Conclusion: 반경(스프레드) 제어가 필요한 응용 분야(센서 네트워크, 협업 로보틱스, 해석 가능한 패턴 분석)에 적합한 실용적 방법을 제시하며, 닫힌형 해로 해석성을 유지함.

Abstract: This paper presents Constrained Centroid Clustering (CCC), a method that
extends classical centroid-based clustering by enforcing a constraint on the
maximum distance between the cluster center and the farthest point in the
cluster. Using a Lagrangian formulation, we derive a closed-form solution that
maintains interpretability while controlling cluster spread. To evaluate CCC,
we conduct experiments on synthetic circular data with radial symmetry and
uniform angular distribution. Using ring-wise, sector-wise, and joint entropy
as evaluation metrics, we show that CCC achieves more compact clusters by
reducing radial spread while preserving angular structure, outperforming
standard methods such as K-means and GMM. The proposed approach is suitable for
applications requiring structured clustering with spread control, including
sensor networks, collaborative robotics, and interpretable pattern analysis.

</details>


### [400] [Short-Term Forecasting of Energy Production and Consumption Using Extreme Learning Machine: A Comprehensive MIMO based ELM Approach](https://arxiv.org/abs/2508.12764)
*Cyril Voyant,Milan Despotovic,Luis Garcia-Gutierrez,Mohammed Asloune,Yves-Marie Saint-Drenan,Jean-Laurent Duchaud,hjuvan Antone Faggianelli,Elena Magliaro*

Main category: cs.LG

TL;DR: Corsica 데이터(6년, 시간 단위)로 다중 에너지원(태양광, 풍력, 수력, 열병합, 바이오, 수입 전력)의 단기(최대 5시간) 출력과 총생산을 예측하기 위해 MIMO 구조의 Extreme Learning Machine(ELM)을 사용. 시계열 비정상성과 계절성을 슬라이딩 윈도우와 순환 시간 인코딩으로 처리. 1시간 예측에서 태양광 nRMSE 17.9%, 열발전 5.1%, R^2>0.98로 지속성 기준보다 크게 우수. MIMO는 SISO보다 소폭 우수하고 LSTM 대비 계산비용이 낮아 실시간·온라인 학습에 적합.


<details>
  <summary>Details</summary>
Motivation: 전력계통 운영에서 다중 에너지원의 단기 출력과 총생산(수입 전력 포함)을 정확히 예측하면 수급조정·거래·안정성 향상에 도움이 된다. 재생에너지의 비정적·계절적 변동을 실시간으로 적응해 처리할 필요가 있다.

Method: Extreme Learning Machine을 MIMO 아키텍처로 설계해 동시에 여러 출력(개별 발전원 및 총생산)을 예측. 입력으로 과거 시간대 데이터를 슬라이딩 윈도우로 제공하고, 시간의 주기성을 반영하기 위해 순환(사인/코사인) 타임 인코딩을 추가. 성능은 지속성(persistence), SISO ELM, LSTM 등과 비교 평가.

Result: 1시간 예측 성능: 태양광 nRMSE 17.9%, 열발전 5.1%, 전체적으로 R^2>0.98. 모델은 5시간까지 높은 정확도를 유지하나 그 이후 재생에너지의 불확실성 증가로 성능 저하. MIMO는 SISO 대비 소폭 성능 향상, 그러나 ELM은 LSTM보다 계산 비용이 낮고 닫힌 형식(정식 해)으로 실시간 적용 및 온라인 학습에 유리.

Conclusion: MIMO-ELM 방법론은 단기 전력예측에서 실용적이고 계산적으로 효율적인 대안이다. 지역별 자원·그리드·시장 특성에 맞춰 튜닝 가능하며 실시간 운영·온라인 업데이트가 가능한 점이 강점이다.

Abstract: A novel methodology for short-term energy forecasting using an Extreme
Learning Machine ($\mathtt{ELM}$) is proposed. Using six years of hourly data
collected in Corsica (France) from multiple energy sources (solar, wind, hydro,
thermal, bioenergy, and imported electricity), our approach predicts both
individual energy outputs and total production (\cyr{including imports, which
closely follow energy demand, modulo losses)} through a Multi-Input
Multi-Output ($\mathtt{MIMO}$) architecture. To address non-stationarity and
seasonal variability, sliding window techniques and cyclic time encoding are
incorporated, enabling dynamic adaptation to fluctuations. The $\mathtt{ELM}$
model significantly outperforms persistence-based forecasting, particularly for
solar and thermal energy, achieving an $\mathtt{nRMSE}$ of $17.9\%$ and
$5.1\%$, respectively, with $\mathtt{R^2} > 0.98$ (1-hour horizon). The model
maintains high accuracy up to five hours ahead, beyond which renewable energy
sources become increasingly volatile. While $\mathtt{MIMO}$ provides marginal
gains over Single-Input Single-Output ($\mathtt{SISO}$) architectures and
offers key advantages over deep learning methods such as $\mathtt{LSTM}$, it
provides a closed-form solution with lower computational demands, making it
well-suited for real-time applications, including online learning. Beyond
predictive accuracy, the proposed methodology is adaptable to various contexts
and datasets, as it can be tuned to local constraints such as resource
availability, grid characteristics, and market structures.

</details>


### [401] [Online Ensemble Transformer for Accurate Cloud Workload Forecasting in Predictive Auto-Scaling](https://arxiv.org/abs/2508.12773)
*Jiadong Chen,Xiao He,Hengyu Ye,Fuxin Jiang,Tieying Zhang,Jianjun Chen,Xiaofeng Gao*

Main category: cs.LG

TL;DR: E3Former는 대규모 예측형 오토스케일링을 위한 온라인 앙상블 워크로드 예측 모델로, 여러 서브네트워크의 예측을 결합하여 고빈도·미세 그레인 예측에서의 주기성 포착과 온라인 적응 문제를 개선한다. 온라인 실험에서 평균 예측오차를 10% 줄였고, ByteDance IHPA에 실제 배포되어 30개 이상 서비스에 적용되어 리소스 사용을 40% 이상 절감했다.


<details>
  <summary>Details</summary>
Motivation: 서버리스 환경의 변동성 높은 워크로드에서 빠르게 적응하는 예측형 오토스케일링이 필요하며, 기존 단일 모델 기반 예측기는 온라인 스트림 적응력과 고주파수 주기성 포착에 한계가 있음.

Method: 온라인 환경에서 작동하는 경량 앙상블 구조(E3Former)를 제안. 여러 서브네트워크의 예측을 결합해 단일 모델 한계 극복. 계산 비용은 최소화하여 서버리스 운영 철학에 부합.

Result: 실세계 워크로드 데이터에 대한 광범위한 실험에서 온라인 예측 과제의 평균 예측오차를 약 10% 감소. 실제 시스템(예: ByteDance IHPA)에서 배포·검증되어 30개 이상 애플리케이션을 지원, 예측 오토스케일링으로 600,000 CPU 코어 이상을 관리하고 리소스 사용률을 40% 이상 절감.

Conclusion: E3Former는 적은 오버헤드로 온라인 적응성과 고빈도 주기성 포착을 개선한 실용적 솔루션으로, 실제 대규모 서버리스 플랫폼에서 유의미한 비용·리소스 절감을 달성함.

Abstract: In the swiftly evolving domain of cloud computing, the advent of serverless
systems underscores the crucial need for predictive auto-scaling systems. This
necessity arises to ensure optimal resource allocation and maintain operational
efficiency in inherently volatile environments. At the core of a predictive
auto-scaling system is the workload forecasting model. Existing forecasting
models struggle to quickly adapt to the dynamics in online workload streams and
have difficulty capturing the complex periodicity brought by fine-grained,
high-frequency forecasting tasks. Addressing this, we propose a novel online
ensemble model, E3Former, for online workload forecasting in large-scale
predictive auto-scaling. Our model synergizes the predictive capabilities of
multiple subnetworks to surmount the limitations of single-model approaches,
thus ensuring superior accuracy and robustness. Remarkably, it accomplishes
this with a minimal increase in computational overhead, adhering to the lean
operational ethos of serverless systems. Through extensive experimentation on
real-world workload datasets, we establish the efficacy of our ensemble model.
In online forecasting tasks, the proposed method reduces forecast error by an
average of 10%, and its effectiveness is further demonstrated through a
predictive auto-scaling test in the real-life online system. Currently, our
method has been deployed within ByteDance's Intelligent Horizontal Pod
Auto-scaling (IHPA) platform, which supports the stable operation of over 30
applications, such as Douyin E-Comerce, TouTiao, and Volcano Engine. The
predictive auto-scaling capacity reaching over 600,000 CPU cores. On the basis
of essentially ensuring service quality, the predictive auto-scaling system can
reduce resource utilization by over 40%.

</details>


### [402] [Randomized PCA Forest for Outlier Detection](https://arxiv.org/abs/2508.12776)
*Muhammad Rajabinasab,Farhad Pakdaman,Moncef Gabbouj,Peter Schneider-Kamp,Arthur Zimek*

Main category: cs.LG

TL;DR: Unsupervised outlier detection method using Randomized PCA (RPCA) Forest; shows superior or competitive performance and high efficiency across datasets.


<details>
  <summary>Details</summary>
Motivation: Leverage effectiveness of Randomized PCA Forest observed in approximate KNN search to create an unsupervised outlier detector that is both accurate and computationally efficient.

Method: Use RPCA Forest to generate randomized low-dimensional projections via RPCA, then detect outliers based on their behavior across the forest (e.g., isolation or distance statistics aggregated over trees) without supervision.

Result: On multiple datasets the proposed approach outperforms classical and state-of-the-art outlier detectors on several tasks and remains competitive on other datasets; analysis shows good generalization and computational efficiency.

Conclusion: RPCA Forest is a promising, efficient unsupervised method for outlier detection, offering strong empirical performance and scalability, making it a practical choice for many applications.

Abstract: We propose a novel unsupervised outlier detection method based on Randomized
Principal Component Analysis (PCA). Inspired by the performance of Randomized
PCA (RPCA) Forest in approximate K-Nearest Neighbor (KNN) search, we develop a
novel unsupervised outlier detection method that utilizes RPCA Forest for
outlier detection. Experimental results showcase the superiority of the
proposed approach compared to the classical and state-of-the-art methods in
performing the outlier detection task on several datasets while performing
competitively on the rest. The extensive analysis of the proposed method
reflects it high generalization power and its computational efficiency,
highlighting it as a good choice for unsupervised outlier detection.

</details>


### [403] [Wavy Transformer](https://arxiv.org/abs/2508.12787)
*Satoshi Noguchi,Yoshinobu Kawahara*

Main category: cs.LG

TL;DR: 이 논문은 트랜스포머의 연속된 어텐션 블록들이 완전 그래프에서의 그래프 신경망 확산(diffusion)과 동등한 동역학을 따른다고 보고, 이로 인한 과도한 평탄화(over-smoothing)를 확산의 소산성(dissipative nature)으로 해석한다. 이를 해결하기 위해 2차(속도 포함) 파동형(wavy) 동역학을 도입한 새로운 어텐션 층과 물리적인 상태-속도 관계를 보존하는 FFN/정규화 설계를 제안한다. 다양한 NLP/CV 모델에서 소규모 파라미터 증가만으로 성능 향상을 보였다.


<details>
  <summary>Details</summary>
Motivation: 깊은 트랜스포머에서 토큰 표현이 블록을 지날수록 균일해져 표현력이 감소하는 over-smoothing 문제를 물리적 관점(확산으로 인한 소산)에서 이해하고 이를 근본적으로 완화하려는 것.

Method: 스택된 어텐션의 히든 상태 동역학을 완전 그래프 위의 그래프 확산으로 수학적으로 등치시킨 뒤, 1차 확산이 아닌 2차(가속도/속도 포함) 파동형 동역학에 기반한 새로운 어텐션 층(Wavy Attention)을 설계한다. 또한 체인의 법칙 하에서 상태-속도 관계를 보존하도록 FFN과 정규화 레이어를 재설계하여 전체 아키텍처를 확장함.

Result: 제안하는 Wavy Transformer는 NLP 및 CV의 다양한 변형 트랜스포머 실험에서 소폭의 파라미터 증가만으로 일관된 성능 향상을 보였고, 별도 하이퍼파라미터 튜닝 없이도 개선이 관찰되었다고 보고한다.

Conclusion: 확산 관점의 해석은 트랜스포머의 over-smoothing 원인을 설명해 주며, 2차 파동 동역학을 도입한 구조적 변경은 표현 소산을 억제하고 실험적으로 유의미한 성능 이득을 제공한다.

Abstract: Transformers have achieved remarkable success across natural language
processing (NLP) and computer vision (CV). However, deep transformer models
often suffer from an over-smoothing issue, in which token representations
converge to similar values as they pass through successive transformer blocks.
In this paper, we establish an equivalence between the hidden-state dynamics
induced by stacked attention layers and graph neural diffusion on a complete
graph. From this perspective, over-smoothing can be interpreted as a
consequence of the dissipative nature of the underlying diffusion dynamics.
Motivated by this physical interpretation, we propose Wavy Transformer, which
consists of a novel attention layer based on second-order wavy dynamics. We
also introduce a feed-forward network and a normalization layer designed to
preserve the physical state-velocity relationship under the chain rule, thereby
extending the transformer architecture. We further validate our proposed
techniques on various transformer models for NLP and CV tasks. The results
consistently demonstrate that Wavy Transformer improves performance with
minimal additional parameters and no extra hyperparameter tuning.

</details>


### [404] [Bridging Human and LLM Judgments: Understanding and Narrowing the Gap](https://arxiv.org/abs/2508.12792)
*Felipe Maia Polo,Xinhe Wang,Mikhail Yurochkin,Gongjun Xu,Moulinath Banerjee,Yuekai Sun*

Main category: cs.LG

TL;DR: Bridge는 잠재적인 인간 선호 점수를 가정하고, LLM 평가는 편차를 설명하는 공변량의 선형 변환으로 모델링하여 인간 평가와 LLM 평가를 통계적으로 연결하는 프레임워크다. 절대 점수와 쌍대 비교 모두에 적용되며, 효율적 추정 알고리즘과 점근적 추론 보장을 제공한다. 여러 LLM 심사자와 벤치마크에서 인간 일치도를 높이고 체계적 격차를 드러낸다.


<details>
  <summary>Details</summary>
Motivation: LLM을 대규모 평가자로 쓰는 경우 LLM의 판단이 인간 판단과 체계적으로 어긋나는 문제가 있어, 이를 보정하고 차이를 정량화할 수 있는 통합적·이론적 틀이 필요하다.

Method: 각 프롬프트-응답 쌍에 대해 잠재적 인간 선호 점수를 도입하고, LLM의 평가 편차를 공변량의 선형 변환으로 모델링한다. 절대 점수 방식과 쌍대 비교 모두에 적용 가능한 모델 식과 효율적 적합 알고리즘을 제공하며, 점근적 성질을 이용한 통계적 추론을 보장한다.

Result: 6개의 LLM 평가자와 BigGen Bench, Chatbot Arena에서 실험하여 Bridge가 인간 평점과의 정확도·보정·KL 발산 측면에서 개선을 보였고, 인간-LLM 간의 체계적 차이를 규명했다.

Conclusion: Bridge는 LLM 평가를 인간 기준으로 정렬하고 LLM과 인간 간의 구조적 차이를 해석하는 간단하고 원칙적인 통계적 도구를 제공한다.

Abstract: Large language models are increasingly used as judges (LLM-as-a-judge) to
evaluate model outputs at scale, but their assessments often diverge
systematically from human judgments. We present Bridge, a unified statistical
framework that explicitly bridges human and LLM evaluations under both absolute
scoring and pairwise comparison paradigms. Bridge posits a latent human
preference score for each prompt-response pair and models LLM deviations as
linear transformations of covariates that capture sources of discrepancies.
This offers a simple and principled framework for refining LLM ratings and
characterizing systematic discrepancies between humans and LLMs. We provide an
efficient fitting algorithm with asymptotic guarantees for statistical
inference. Using six LLM judges and two benchmarks (BigGen Bench and Chatbot
Arena), Bridge achieves higher agreement with human ratings (accuracy,
calibration, and KL divergence) and exposes systematic human-LLM gaps.

</details>


### [405] [A Shift in Perspective on Causality in Domain Generalization](https://arxiv.org/abs/2508.12798)
*Damian Machlanski,Stephanie Riley,Edward Moroshko,Kurt Butler,Panagiotis Dimitrakopoulos,Thomas Melistas,Akchunya Chanchal,Steven McDonagh,Ricardo Silva,Sotirios A. Tsaftaris*

Main category: cs.LG

TL;DR: 원래 기대되던 인과모델이 도메인 일반화(DG)에서 항상 유리하다는 주장이 최근 벤치마크 결과로 도전받았다. 이 논문은 문헌을 재검토해 모순처럼 보이는 주장들을 조화시키고, 인과성의 일반화 기여에 대한 보다 정교한(조건부·상황적) 이론을 제시한다. 인터랙티브 데모를 제공한다.


<details>
  <summary>Details</summary>
Motivation: 인과관계 기반 접근이 분포 변화에 강한 일반화 능력을 줄 것이라는 기대와, DG 벤치마크에서 관찰되는 한계 사이의 갭을 해명하려는 목적.

Method: 관련 인과성 및 도메인 일반화 문헌을 재검토하고, 서로 상충하는 주장들을 비교·분석하여 조화 가능한 설명을 도출. 이론적 논의와 사례(데모)를 통해 주장 검증 및 직관 제공.

Result: 일부 벤치마크 결과가 인과적 예측자의 우월성을 단정짓기에는 불충분하며, 인과성의 혜택은 문제 설정(예: 어떤 종류의 분포 변화, 관측 변수의 역할 등)에 따라 달라진다는 결론을 도출. 인터랙티브 데모로 개념을 시각화하여 이해를 돕는다.

Conclusion: 인과성은 만능 열쇠가 아니며, 그 일반화 효과는 상황·가정에 의존한다. 따라서 더 정교한 이론적 기준과 평가 설계가 필요하다고 주장한다.

Abstract: The promise that causal modelling can lead to robust AI generalization has
been challenged in recent work on domain generalization (DG) benchmarks. We
revisit the claims of the causality and DG literature, reconciling apparent
contradictions and advocating for a more nuanced theory of the role of
causality in generalization. We also provide an interactive demo at
https://chai-uk.github.io/ukairs25-causal-predictors/.

</details>


### [406] [Maximum Score Routing For Mixture-of-Experts](https://arxiv.org/abs/2508.12801)
*Bowen Dong,Yilong Fan,Yutao Sun,Zhenyu Li,Tengyu Pan,Xun Zhou,Jianyong Wang*

Main category: cs.LG

TL;DR: MaxScore는 MoE 라우팅을 최소비용 최대흐름(min-cost max-flow) 문제로 재정의하고 SoftTopk 연산자를 도입해 토큰 드롭과 패딩 비효율을 줄이며, 동일 FLOPs에서 더 낮은 학습 손실과 더 높은 평가 성능을 달성하는 새 라우팅 패러다임이다.


<details>
  <summary>Details</summary>
Motivation: 기존 MoE는 GPU 친화적 계산을 위해 전문가별 용량(capacity) 제약을 두지만, 용량 포화 시 토큰 드롭과 미활용 전문가의 패딩으로 하드웨어 효율이 낮아진다. 용량 제약을 제거하면 부하 균형과 계산 효율성 문제가 생긴다.

Method: 라우팅을 최소비용 최대흐름 문제로 모델링하고 SoftTopk 연산자를 통합한 Maximum Score Routing(MaxScore)을 제안한다. 이는 반복적 재라우팅(iterative rerouting)과 최적 수송(optimal transport) 기반 접근의 근본적 한계를 해결하도록 설계되었다.

Result: MaxScore는 제약된(constrained) 및 비제약(unconstrained) 기준선보다 동일한 FLOPs에서 학습 손실이 더 낮고 평가 점수가 더 높게 나타났다(구현과 실험 구성은 GitHub에 공개).

Conclusion: MaxScore는 토큰 드롭과 패딩 낭비를 줄이면서 부하 균형과 계산 효율을 유지/개선하여 MoE 라우팅의 실용적 한계를 완화한다.

Abstract: Routing networks in sparsely activated mixture-of-experts (MoE) dynamically
allocate input tokens to top-k experts through differentiable sparse
transformations, enabling scalable model capacity while preserving
computational efficiency. Traditional MoE networks impose an expert capacity
constraint to ensure GPU-friendly computation. However, this leads to token
dropping when capacity is saturated and results in low hardware efficiency due
to padding in underutilized experts. Removing the capacity constraint, in turn,
compromises load balancing and computational efficiency. To address these
issues, we propose Maximum Score Routing ($\mathbf{MaxScore}$), a novel MoE
routing paradigm that models routing as a minimum-cost maximum-flow problem and
integrates a SoftTopk operator. MaxScore resolves the fundamental limitations
of iterative rerouting and optimal transport formulations, achieving lower
training losses and higher evaluation scores at equivalent FLOPs compared to
both constrained and unconstrained baselines. Implementation details and
experimental configurations can be obtained from
$\href{https://github.com/dongbw18/MaxScore.git}{MaxScore}$.

</details>


### [407] [Learning to Steer: Input-dependent Steering for Multimodal LLMs](https://arxiv.org/abs/2508.12815)
*Jayneel Parekh,Pegah Khayatan,Mustafa Shukor,Arnaud Dapogny,Alasdair Newson,Matthieu Cord*

Main category: cs.LG

TL;DR: MLLM에서 입력별 선형 시프트를 학습해 안전성과 정확성을 높이는 방법인 L2S 제안. 단일 정적 스티어링 벡터 대신 입력별로 계산된 스티어링을 예측하는 보조 모듈을 둠.


<details>
  <summary>Details</summary>
Motivation: 기존의 평균(정적) 스티어링은 입력에 의존하지 않아, 상황에 따라 다른 안전/응답 전략(예: 불법 질문엔 응답 거부, 의료 질문엔 전문가 추천 등)을 요구하는 MLLM의 행동 제어에 한계가 있음. 따라서 입력별로 세밀한 제어가 필요함.

Method: 입력-특이적(linear) 시프트를 contrastive input-specific prompting으로 계산하고, 테스트 시점에 필요한 입력-특이적 프롬프트를 예측하기 위해 작은 보조 모듈을 학습시킴(Learn-to-Steer, L2S). 이 보조 모듈은 입력으로부터 스티어링 벡터를 출력해 MLLM의 사후 안내(post-hoc guidance)에 적용함.

Result: L2S는 정적 스티어링 및 다른 기준선보다 환각(hallucination)을 줄이고 안전성 규약을 더 잘 만족시킴. 실험에서 성능 향상과 더 세밀한 행동 제어가 관찰됨.

Conclusion: 입력-특이적 선형 시프트를 예측하는 소형 모듈을 도입한 L2S는 MLLM의 안전성과 정확성을 개선하는 실용적이고 효율적인 스티어링 전략을 제시함.

Abstract: Steering has emerged as a practical approach to enable post-hoc guidance of
LLMs towards enforcing a specific behavior. However, it remains largely
underexplored for multimodal LLMs (MLLMs); furthermore, existing steering
techniques, such as mean steering, rely on a single steering vector, applied
independently of the input query. This paradigm faces limitations when the
desired behavior is dependent on the example at hand. For example, a safe
answer may consist in abstaining from answering when asked for an illegal
activity, or may point to external resources or consultation with an expert
when asked about medical advice. In this paper, we investigate a fine-grained
steering that uses an input-specific linear shift. This shift is computed using
contrastive input-specific prompting. However, the input-specific prompts
required for this approach are not known at test time. Therefore, we propose to
train a small auxiliary module to predict the input-specific steering vector.
Our approach, dubbed as L2S (Learn-to-Steer), demonstrates that it reduces
hallucinations and enforces safety in MLLMs, outperforming other static
baselines.

</details>


### [408] [Toward Storage-Aware Learning with Compressed Data An Empirical Exploratory Study on JPEG](https://arxiv.org/abs/2508.12833)
*Kichang Lee,Songkuk Kim,JaeYeon Park,JeongGil Ko*

Main category: cs.LG

TL;DR: 장치 내 연속 데이터 수집에서 저장공간 제약을 고려한 학습(데이터 수량 대 압축 품질 트레이드오프)을 실험적으로 분석. 균일한 드롭이나 일률적 압축은 비효율적이며, 샘플별로 압축 민감도가 달라 샘플별 적응형 압축이 유효함을 보임.


<details>
  <summary>Details</summary>
Motivation: 엣지/온-디바이스 환경은 저장 공간이 제한적이고 연속 데이터가 축적되므로, 어떤 데이터를 어떻게 보관할지(압축 레벨 또는 삭제) 결정하는 것이 학습 성능에 중요하다. 기존 단순 전략들은 최적의 성능-저장량 균형을 보장하지 못함.

Method: 다양한 데이터셋과 작업에서 균일 드롭, 일률적 압축 등 기초 전략과 샘플별 민감도를 측정하는 방법을 비교 실험. 샘플 단위로 압축 민감도를 평가하고 그에 따라 압축 수준을 조정하는 전략의 효과를 분석.

Result: 일괄적 전략들이 비효율적임을 확인하고, 샘플별로 압축에 대한 민감도가 크게 다르며 이를 이용한 적응적 샘플 압축이 저장 제약 하에서 더 나은 학습 성능을 제공함.

Conclusion: 저장 제약을 고려한 학습은 중요하고, 샘플 단위 적응 압축 같은 새로운 접근이 실효성이 있으며 향후 저장-학습 공동설계 방향을 제시함.

Abstract: On-device machine learning is often constrained by limited storage,
particularly in continuous data collection scenarios. This paper presents an
empirical study on storage-aware learning, focusing on the trade-off between
data quantity and quality via compression. We demonstrate that naive
strategies, such as uniform data dropping or one-size-fits-all compression, are
suboptimal. Our findings further reveal that data samples exhibit varying
sensitivities to compression, supporting the feasibility of a sample-wise
adaptive compression strategy. These insights provide a foundation for
developing a new class of storage-aware learning systems. The primary
contribution of this work is the systematic characterization of this
under-explored challenge, offering valuable insights that advance the
understanding of storage-aware learning.

</details>


### [409] [Learning In-context $\pmb{n}$-grams with Transformers: Sub-$\pmb{n}$-grams Are Near-stationary Points](https://arxiv.org/abs/2508.12837)
*Aditya Varre,Gizem Yüce,Nicolas Flammarion*

Main category: cs.LG

TL;DR: 저자들은 변형기(transformer)의 in-context 다음 토큰 예측 학습에서 관찰되는 장기적 정체(plateau)와 단계적(stage-wise) 학습 현상을 설명하기 위해, 교차엔트로피 손실의 손실 지형을 분석한다. 단순화한 transformer 모델에서 sub-n-gram(즉 k-gram, k≤n) 해들이 무한 시퀀스 길이와 파라미터 크기 극한에서 근(near)-정지점이 됨을 보인다.


<details>
  <summary>Details</summary>
Motivation: 실험적으로 학습 과정에서 긴 정체 구간과 단계적으로 새로운 패턴이 등장하는 현상이 관찰되는데, 이러한 현상을 손실 지형 관점에서 이론적으로 설명하려 함.

Method: in-context n-gram 언어모델과 교차엔트로피 손실을 가정하고 정지점이 되는 충분조건을 도출. 단순화된 transformer 파라미터 설정을 구성해 k-gram 추정기를 표현하고, 무한 시퀀스 길이 및 파라미터 노름 극한에서 모집단 손실의 그래디언트가 소멸함을 보임. 수치 실험으로 학습 역학을 확인.

Result: k≤n인 sub-n-gram 해들이 모집단 교차엔트로피 손실에서 near-stationary point가 됨을 이론적으로 증명. 학습 중에 k-gram 해들 사이의 이산적 전이(discrete transitions)와 단계적 학습 동역학이 관찰됨을 수치적으로 확인.

Conclusion: 손실 지형에 sub-n-gram 근-정지점이 존재한다는 결과는 단계적 학습, 장기 정체, emergent phase transitions 같은 현상을 이해하는 데 이론적 근거를 제공함.

Abstract: Motivated by empirical observations of prolonged plateaus and stage-wise
progression during training, we investigate the loss landscape of transformer
models trained on in-context next-token prediction tasks. In particular, we
focus on learning in-context $n$-gram language models under cross-entropy loss,
and establish a sufficient condition for parameter configurations to be
stationary points. We then construct a set of parameter configurations for a
simplified transformer model that represent $k$-gram estimators (for $k \leq
n$), and show that the gradient of the population loss at these solutions
vanishes in the limit of infinite sequence length and parameter norm. This
reveals a key property of the loss landscape: {sub-$n$-grams are
near-stationary points of the population cross-entropy loss}, offering
theoretical insight into widely observed phenomena such as stage-wise learning
dynamics and emergent phase transitions. These insights are further supported
by numerical experiments that illustrate the learning dynamics of $n$-grams,
characterized by discrete transitions between near-stationary solutions.

</details>


### [410] [HRS: Hybrid Representation Framework with Scheduling Awareness for Time Series Forecasting in Crowdsourced Cloud-Edge Platforms](https://arxiv.org/abs/2508.12839)
*Tiancheng Zhang,Cheng Zhang,Shuren Liu,Xiaofei Wang,Shaoyuan Huang,Wenyu Wang*

Main category: cs.LG

TL;DR: 이 논문은 스트리밍 서비스의 급증하는 네트워크 부하에서 SLA 위반을 줄이기 위해 수치·이미지 기반 하이브리드 표현(HRS)와 스케줄링 편향 손실(SAL)을 제안한다. 실험에서 SLA 위반률을 63.1% 감소시키고 총 손실을 32.3% 줄였다.


<details>
  <summary>Details</summary>
Motivation: Crowdsourced Cloud-Edge Platform에서 트래픽 급증 시 예측오류가 스케줄링에 큰 악영향을 미치며, 기존 평균오차 최적화는 과소 프로비저닝을, 보수적 전략은 과다비용을 초래해 QoS와 비용의 균형을 맞추기 어렵다.

Method: HRS는 시계열의 수치적 표현과 이미지 기반 표현을 결합해 극단적 부하 동태를 더 잘 포착하고, Scheduling-Aware Loss(SAL)는 예측 오차의 비대칭적 비용(스케줄링 관점)을 반영하도록 손실을 설계해 예측을 스케줄링에 유리하게 편향시킨다.

Result: 네 개의 실제 데이터셋에서 10개 베이스라인 대비 우수한 성능을 보였고, 특히 SLA 위반률과 총 이익 손실을 각각 크게 감소시켰다.

Conclusion: 부하 예측에서 표현 강화(수치+이미지)와 스케줄링 인지 손실을 결합하면 CCP 환경에서 QoS 유지와 비용 효율성 모두 개선 가능하다.

Abstract: With the rapid proliferation of streaming services, network load exhibits
highly time-varying and bursty behavior, posing serious challenges for
maintaining Quality of Service (QoS) in Crowdsourced Cloud-Edge Platforms
(CCPs). While CCPs leverage Predict-then-Schedule architecture to improve QoS
and profitability, accurate load forecasting remains challenging under traffic
surges. Existing methods either minimize mean absolute error, resulting in
underprovisioning and potential Service Level Agreement (SLA) violations during
peak periods, or adopt conservative overprovisioning strategies, which mitigate
SLA risks at the expense of increased resource expenditure. To address this
dilemma, we propose HRS, a hybrid representation framework with scheduling
awareness that integrates numerical and image-based representations to better
capture extreme load dynamics. We further introduce a Scheduling-Aware Loss
(SAL) that captures the asymmetric impact of prediction errors, guiding
predictions that better support scheduling decisions. Extensive experiments on
four real-world datasets demonstrate that HRS consistently outperforms ten
baselines and achieves state-of-the-art performance, reducing SLA violation
rates by 63.1% and total profit loss by 32.3%.

</details>


### [411] [One-Class Intrusion Detection with Dynamic Graphs](https://arxiv.org/abs/2508.12885)
*Aleksei Liuliakov,Alexander Schulz,Luca Hermes,Barbara Hammer*

Main category: cs.LG

TL;DR: 동적 그래프 모델링과 딥 이상치 탐지를 결합한 TGN-SVDD를 제안하여 네트워크 침입 탐지에서 기존 기법들보다 우수한 성능을 보였다고 주장함.


<details>
  <summary>Details</summary>
Motivation: 네트워크 보안에서 새롭고 보지 못한 이벤트(제로데이/신규 공격)를 탐지해야 하고, 네트워크 통신은 시간적 순서와 그래프 구조를 동시에 가지므로 이를 반영한 모델이 필요함.

Method: 시간적 그래프 네트워크(TGN 계열로 추정)와 SVDD(또는 유사한 딥 원클래스 이상치 탐지)를 결합한 모델(TGN-SVDD)을 설계하여 동적 그래프 상의 이상 이벤트를 학습·탐지함.

Result: 현실적 침입 탐지 데이터셋에서 여러 베이스라인보다 우월한 성능을 보고하며, 더 어려운 평가 변형도 제안함.

Conclusion: 동적 그래프 기반 딥 이상치 탐지가 네트워크 침입 탐지에 유망함을 시사하며, 추가 검증(데이터셋, 스케일링, 실시간성 등)이 필요함.

Abstract: With the growing digitalization all over the globe, the relevance of network
security becomes increasingly important. Machine learning-based intrusion
detection constitutes a promising approach for improving security, but it bears
several challenges. These include the requirement to detect novel and unseen
network events, as well as specific data properties, such as events over time
together with the inherent graph structure of network communication. In this
work, we propose a novel intrusion detection method, TGN-SVDD, which builds
upon modern dynamic graph modelling and deep anomaly detection. We demonstrate
its superiority over several baselines for realistic intrusion detection data
and suggest a more challenging variant of the latter.

</details>


### [412] [TCUQ: Single-Pass Uncertainty Quantification from Temporal Consistency with Streaming Conformal Calibration for TinyML](https://arxiv.org/abs/2508.12905)
*Ismail Lamaakal,Chaymae Yahyati,Khalid El Makkaoui,Ibrahim Ouahbi,Yassine Maleh*

Main category: cs.LG

TL;DR: TCUQ는 TinyML 스트리밍 환경을 위한 단일 패스(label-free) 불확실성 모니터로, 포스터리어와 특징의 단기 시간적 일관성을 가벼운 신호로 포착해 O(W) 링 버퍼와 O(1) 업데이트로 보정된 위험 점수를 생성한다. 스트리밍 컨포멀 층으로 이 점수를 예산 기반의 수용/보류 규칙으로 변환하여 온라인 레이블 없이도 보정된 동작을 제공한다. 마이크로컨트롤러에서 KB급으로 동작하며, 초기 종료·앙상블 대비 메모리·지연을 크게 줄이고(약 50–60% 작고, 30–45% 빠름) 왜곡된 분포 하에서 실패/정확도 하락 탐지 성능(AUPRC, AUROC)도 유의하게 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: TinyML 기기에서는 메모리·연산·레이블 가용성 제약 때문에 기존의 불확실성 추정(앙상블, 다중 포워드 패스, 온라인 레이블 기반 보정 등)이 실용적이지 않다. 실시간 스트리밍 입력에서 이상·성능 저하를 저비용으로 감지하고, 보정된 거부/수용 결정을 내려 안전한 동작을 보장할 필요가 있다.

Method: 포스터리어와 특징에서 계산한 경량 신호로 단기(짧은 수평) 시간적 일관성을 측정하고, O(W) 링 버퍼에 저장해 O(1) 업데이트로 위험 점수를 계산한다. 이 점수에 대해 스트리밍 컨포멀(calibration) 레이어를 적용해 사전 정의된 거부 예산 하에서 수용/보류 결정을 실시간으로 출력한다. 전체 방법은 추가 포워드 패스나 온라인 레이블 없이 단일 패스로 동작하도록 설계됨.

Result: 마이크로컨트롤러 구현에서 KB급 메모리로 실행되며, 초기 종료 및 심층 앙상블 대비 메모리·지연을 각각 약 50–60%와 30–45% 절감. 왜곡된 동일 분포 스트림에서는 정확도 하락 탐지에서 AUPRC를 3–7 포인트 개선하고 심한 왜곡에서 최대 0.86 AUPRC, 실패 탐지에서는 최대 0.92 AUROC을 달성함.

Conclusion: 짧은 기간의 시간적 일관성 신호와 스트리밍 컨포멀 보정을 결합하면 온라인 레이블이나 추가 연산 없이도 TinyML 기기에서 실용적이고 자원 효율적인 불확실성 모니터링과 보정된 거부 규칙을 구현할 수 있다.

Abstract: We introduce TCUQ, a single pass, label free uncertainty monitor for
streaming TinyML that converts short horizon temporal consistency captured via
lightweight signals on posteriors and features into a calibrated risk score
with an O(W ) ring buffer and O(1) per step updates. A streaming conformal
layer turns this score into a budgeted accept/abstain rule, yielding calibrated
behavior without online labels or extra forward passes. On microcontrollers,
TCUQ fits comfortably on kilobyte scale devices and reduces footprint and
latency versus early exit and deep ensembles (typically about 50 to 60% smaller
and about 30 to 45% faster), while methods of similar accuracy often run out of
memory. Under corrupted in distribution streams, TCUQ improves accuracy drop
detection by 3 to 7 AUPRC points and reaches up to 0.86 AUPRC at high
severities; for failure detection it attains up to 0.92 AUROC. These results
show that temporal consistency, coupled with streaming conformal calibration,
provides a practical and resource efficient foundation for on device monitoring
in TinyML.

</details>


### [413] [SparseMap: A Sparse Tensor Accelerator Framework Based on Evolution Strategy](https://arxiv.org/abs/2508.12906)
*Boran Zhao,Haiming Zhai,Zihang Yuan,Hetian Liu,Tian Xia,Wenzhe Zhao,Pengju Ren*

Main category: cs.LG

TL;DR: SparseMap은 매핑과 스파스 전략을 통합한 거대한 설계 공간에서 진화전략 기반 유전적 탐색을 사용해 희소 텐서 가속기 설계를 자동화하고, 기존 기법들보다 우수한 해를 일관되게 찾는다.


<details>
  <summary>Details</summary>
Motivation: 기계학습·빅데이터에서 SpTA 수요가 증대되나, 기존 수작업 가속기는 특정 시나리오에 한정되고, 매핑과 스파스 전략을 따로 최적화하면 비최적 해가 발생한다. 둘을 함께 최적화하는 통합 프레임워크가 필요하지만 설계 공간이 조합적으로 폭발한다.

Method: 매핑(타일링·통신·계산 배치)과 스파스 전략(제로 스킵 등)을 모두 포함하는 포괄적 설계 공간을 구성하고, 진화 인코딩과 교배·돌연변이 등 연산자를 개선한 진화전략(유전 알고리즘 계열)을 도입해 거대한 탐색공간을 효율적으로 탐색한다.

Result: SparseMap은 기존 연구들과 고전적 최적화 기법(PSO, RL, MCTS 등)에 비해 일관되게 더 우수한 설계안을 찾았음을 수치적으로 입증했다.

Conclusion: 매핑과 스파스 전략의 공동 최적화가 중요하며, 잘 설계된 진화전략은 조합적 설계공간에서 실용적이고 우수한 해를 찾는 유력한 방법임을 보였다.

Abstract: The growing demand for sparse tensor algebra (SpTA) in machine learning and
big data has driven the development of various sparse tensor accelerators.
However, most existing manually designed accelerators are limited to specific
scenarios, and it's time-consuming and challenging to adjust a large number of
design factors when scenarios change. Therefore, automating the design of SpTA
accelerators is crucial. Nevertheless, previous works focus solely on either
mapping (i.e., tiling communication and computation in space and time) or
sparse strategy (i.e., bypassing zero elements for efficiency), leading to
suboptimal designs due to the lack of comprehensive consideration of both. A
unified framework that jointly optimizes both is urgently needed. However,
integrating mapping and sparse strategies leads to a combinatorial explosion in
the design space(e.g., as large as $O(10^{41})$ for the workload $P_{32 \times
64} \times Q_{64 \times 48} = Z_{32 \times 48}$). This vast search space
renders most conventional optimization methods (e.g., particle swarm
optimization, reinforcement learning and Monte Carlo tree search) inefficient.
To address this challenge, we propose an evolution strategy-based sparse tensor
accelerator optimization framework, called SparseMap. SparseMap constructing a
more comprehensive design space with the consideration of both mapping and
sparse strategy. We introduce a series of enhancements to genetic encoding and
evolutionary operators, enabling SparseMap to efficiently explore the vast and
diverse design space. We quantitatively compare SparseMap with prior works and
classical optimization methods, demonstrating that SparseMap consistently finds
superior solutions.

</details>


### [414] [SNAP-UQ: Self-supervised Next-Activation Prediction for Single-Pass Uncertainty in TinyML](https://arxiv.org/abs/2508.12907)
*Ismail Lamaakal,Chaymae Yahyati,Khalid El Makkaoui,Ibrahim Ouahbi,Yassine Maleh*

Main category: cs.LG

TL;DR: 한 번의 추론으로 레이블 없이 층 단위의 다음 활성화(next-activation)를 예측해 불확실도를 산출하는 경량 TinyML 방법. 수십 KB만 추가하고 버퍼/추가전방패스 없이 작동해 메모리·지연을 크게 줄임.


<details>
  <summary>Details</summary>
Motivation: 리소스가 극히 제한된 MCU 환경에서 실시간 모델 실패·분류 불확실성을 효율적으로 감지하려면 반복 추론이나 보조 출구, 큰 앙상블 없이 동작하는 초경량 방법이 필요함.

Method: 각 층에 매우 작은 int8 헤드가 배치되어 이전 층의 압축된 표현으로부터 다음 층 활성화의 통계(예: 요약 통계)를 예측하고, 예측 오차(서프라이즈)를 단조 매핑기로 점수화한다. 단일 패스 구조로 추가 버퍼나 반복 연산이 필요 없음.

Result: Vision·Audio 백본에서 얼리-엑시트·앙상블 대비 플래시 사용량을 대체로 40–60% 절감, 지연 25–35% 단축. 손상된 스트림에서 AUPRC가 여러 포인트 개선되고 실패 감지 AUROC≈0.9 수준을 유지.

Conclusion: 층 간 동적 예측에 근거한 불확실도는 TinyML에 실용적이고 자원 효율적인 온디바이스 모니터링 기반을 제공함.

Abstract: We introduce \textbf{SNAP-UQ}, a single-pass, label-free uncertainty method
for TinyML that estimates risk from \emph{depth-wise next-activation
prediction}: tiny int8 heads forecast the statistics of the next layer from a
compressed view of the previous one, and a lightweight monotone mapper turns
the resulting surprisal into an actionable score. The design requires no
temporal buffers, auxiliary exits, or repeated forward passes, and adds only a
few tens of kilobytes to MCU deployments. Across vision and audio backbones,
SNAP-UQ consistently reduces flash and latency relative to early-exit and deep
ensembles (typically $\sim$40--60\% smaller and $\sim$25--35\% faster), with
competing methods of similar accuracy often exceeding memory limits. In
corrupted streams it improves accuracy-drop detection by several AUPRC points
and maintains strong failure detection (AUROC $\approx$0.9) in a single pass.
Grounding uncertainty in layer-to-layer dynamics yields a practical,
resource-efficient basis for on-device monitoring in TinyML.

</details>


### [415] [SL-ACC: A Communication-Efficient Split Learning Framework with Adaptive Channel-wise Compression](https://arxiv.org/abs/2508.12984)
*Zehang Lin,Zheng Lin,Miao Yang,Jianhao Huang,Yuxin Zhang,Zihan Fang,Xia Du,Zhe Chen,Shunzhi Zhu,Wei Ni*

Main category: cs.LG

TL;DR: SL-ACC는 Split Learning의 smashed data 전송 병목을 줄이기 위한 통신효율 프레임워크로, 채널별 기여도를 샤넌 엔트로피로 평가(ACII)하고 엔트로피 기반 채널 그룹화 후 그룹 단위 적응적 압축(CGC)을 수행해 전송량을 줄이면서 학습 정확도를 유지한다. 다양한 데이터셋에서 목표 정확도에 도달하는 시간이 SOTA보다 짧았다.


<details>
  <summary>Details</summary>
Motivation: 신경망 복잡도 증가로 자원제약 디바이스에서 분산 ML(예: FL) 배포가 어려움. Split Learning은 계산을 서버로 이전해 도움이 되지만, 참여 디바이스 수가 늘어나면 smashed data(활성화·그래디언트) 전송량이 병목이 되어 학습 속도를 저하시킨다.

Method: ACII(Adaptive Channel Importance Identification): 샤넌 엔트로피로 각 채널이 학습에 기여하는 정도를 정량화한다. CGC(Channel Grouping Compression): 엔트로피 기준으로 채널을 그룹화하고, 그룹별로 적응적 압축을 적용해 전송량을 축소한다. 두 구성요소 결합으로 통신-성능 절충을 최적화한다.

Result: 여러 데이터셋 실험에서 SL-ACC는 동일한 목표 정확도에 도달하는 시간이 기존 최첨단 방법들보다 현저히 짧았음(전송량 감소와 정확도 보존을 동시에 관찰).

Conclusion: 샤넌 엔트로피 기반 채널 중요도 평가와 그룹별 적응적 압축은 Split Learning의 통신 병목을 효과적으로 완화하며, 자원제약 분산 학습 환경에서 실용적인 통신 효율 개선 방안이 된다.

Abstract: The increasing complexity of neural networks poses a significant barrier to
the deployment of distributed machine learning (ML) on resource-constrained
devices, such as federated learning (FL). Split learning (SL) offers a
promising solution by offloading the primary computing load from edge devices
to a server via model partitioning. However, as the number of participating
devices increases, the transmission of excessive smashed data (i.e.,
activations and gradients) becomes a major bottleneck for SL, slowing down the
model training. To tackle this challenge, we propose a communication-efficient
SL framework, named SL-ACC, which comprises two key components: adaptive
channel importance identification (ACII) and channel grouping compression
(CGC). ACII first identifies the contribution of each channel in the smashed
data to model training using Shannon entropy. Following this, CGC groups the
channels based on their entropy and performs group-wise adaptive compression to
shrink the transmission volume without compromising training accuracy.
Extensive experiments across various datasets validate that our proposed SL-ACC
framework takes considerably less time to achieve a target accuracy than
state-of-the-art benchmarks.

</details>


### [416] [Predicting the Performance of Graph Convolutional Networks with Spectral Properties of the Graph Laplacian](https://arxiv.org/abs/2508.12993)
*Shalima Binta Manir,Tim Oates*

Main category: cs.LG

TL;DR: 저자들은 그래프의 대수적 연결성(Fiedler 값)이 GCN 성능(노드 분류/엣지 예측)을 예측할 수 있다고 주장한다. 여러 연결 성분을 합산하는 방식과 이론적 근거를 제시하고, 합성 및 실제 데이터(Cora, CiteSeer, Polblogs) 실험으로 검증한다.


<details>
  <summary>Details</summary>
Motivation: GCN 계층을 쌓는 것이 항상 성능 향상으로 이어지지 않는 관찰에 착안해, 그래프 구조의 정량적 지표가 GCN 성능 변동을 설명하거나 예측할 수 있는지 규명하려 함. 특히 서로 유사한 구조를 가진 그래프들 간 전이학습 가능성 탐색.

Method: 그래프의 Fiedler 값(또는 연결 성분별 Fiedler 값을 집계한 지표)을 계산하고, 이 값과 다양한 GCN 설정(깊이, 필터, 하이퍼파라미터)에 따른 성능을 비교. 합성 데이터와 실제 데이터(Cora, CiteSeer, Polblogs)에서 실험을 수행하고, 이론적 근거(스펙트럴 특성과 필터 반응 등)를 제시.

Result: Fiedler 값이 GCN 성능의 좋은 예측자임을 제시. 서로 유사한 Fiedler 값을 가진 그래프들에서는 같은 필터·하이퍼파라미터 조합이 유사한 성능을 보였고, 전이학습 가능성이 시사됨. 다양한 합산 방식(연결 성분 처리)에 대한 평가 포함.

Conclusion: 대수적 연결성은 GCN 설계·하이퍼파라미터 선택·전이학습 가능성 판단에 유용한 메트릭이 될 수 있다. 다만 범용성·인과관계·지역성 한계는 추가 연구 필요.

Abstract: A common observation in the Graph Convolutional Network (GCN) literature is
that stacking GCN layers may or may not result in better performance on tasks
like node classification and edge prediction. We have found empirically that a
graph's algebraic connectivity, which is known as the Fiedler value, is a good
predictor of GCN performance. Intuitively, graphs with similar Fiedler values
have analogous structural properties, suggesting that the same filters and
hyperparameters may yield similar results when used with GCNs, and that
transfer learning may be more effective between graphs with similar algebraic
connectivity. We explore this theoretically and empirically with experiments on
synthetic and real graph data, including the Cora, CiteSeer and Polblogs
datasets. We explore multiple ways of aggregating the Fiedler value for
connected components in the graphs to arrive at a value for the entire graph,
and show that it can be used to predict GCN performance. We also present
theoretical arguments as to why the Fiedler value is a good predictor.

</details>


### [417] [Kourkoutas-Beta: A Sunspike-Driven Adam Optimizer with Desert Flair](https://arxiv.org/abs/2508.12996)
*Stavros C. Kassinos*

Main category: cs.LG

TL;DR: Kourkoutas-Beta는 Adam의 고정 beta2를 레이어별 동적값으로 대체해 스파이키 그래디언트에 대해 적응하는 옵티마이저다. 현재 pooled 그래디언트 노름을 과거 EMA로 나눈 "sunspike" 비율에 따라 beta2를 [beta2_min,beta2_max)로 조절한다. 옵션으로 leaky-AMSGrad, trust-region clipping, 다양한 bias-correction 모드를 제공하며, 모든 기능을 끄면 Adam과 동일하다. PDE 서로게이트, PINN, 합성 태스크, character Transformer 등에서 안정성과 최종 손실을 개선하고, 작은 실행 오버헤드로 Adam의 수렴 보장을 유지한다.


<details>
  <summary>Details</summary>
Motivation: 물리 기반 문제(특히 PDE surrogate, PINN)에서 경계/초기조건 변화와 복합식 손실로 인해 발생하는 스파이키 그래디언트와 불안정한 학습을 해결하기 위함. 고정 beta2가 이런 스파이크에 취약하므로 동적 조절을 통해 안정성 향상을 노림.

Method: Adam의 2차 모멘트 감소계수인 beta2를 레이어별 동적값으로 교체. 동적값은 현재 pooled gradient norm을 과거 EMA 노름으로 나눈 "sunspike" 비율에 의해 결정되며, 이 비율을 [0,1)로 squash해 beta2를 beta2_min에서 beta2_max 사이로 조절한다. 추가 옵션으로 leaky-AMSGrad(감쇠), trust-region clipping(max_ratio), adaptive tiny term, bias-correction 모드('none','beta2max','exact') 제공. 모든 옵션 비활성화 시 Adam과 동일.

Result: 네 가지 테스트(Heat2D Transformer surrogate, Heat3D PINN, MLX synthetic with bursts, small-enwik8 character Transformer)에서 고정-beta2 Adam보다 안정성 및 최종 손실 개선. small-enwik8에서는 bpc를 Adam-0.95 대비 약 38% 감소, Adam-0.999 대비 약 58% 감소. 분산도 작고 런타임 오버헤드는 대부분 실험에서 Adam과 유사.

Conclusion: layer-wise 동적 beta2로 스파이키 그래디언트에 적응하면 Adam 스타일 수렴 보장을 유지하면서 물리 기반 문제 및 일반 NLP 태스크에서 학습 안정성과 성능을 크게 개선할 수 있다.

Abstract: Transformer neural networks are increasingly used for physics-based problems.
In data-driven PDE surrogates, training samples from varying boundary and
initial conditions can cause erratic losses and spiky gradients; in
physics-informed neural networks (PINNs), stiff composite losses amplify this
effect.
  We introduce Kourkoutas-Beta, an Adam-style optimizer where the fixed
second-moment discount beta2 is replaced by a layer-wise dynamic value driven
by a bounded ``sunspike'' ratio: the current pooled gradient norm divided by an
exponential moving average (EMA) of past norms, squashed to the interval [0,1).
Spikes lower beta2 toward beta2_min; calm phases keep it near beta2_max.
Options include leaky-AMSGrad (decay), trust-region clipping (max_ratio),
adaptive tiny terms, and several bias-correction modes ``none'', ``beta2max'',
``exact'). With all features off and bias_correction=``none'', the method is
exactly Adam.
  We test on four settings: (i) a Transformer PDE surrogate (Heat2D), (ii) a 3D
PINN for heat conduction (Heat3D), (iii) a lightweight MLX synthetic task with
jitter and rare-trigger bursts, and (iv) a character-level Transformer on 30 MB
of enwik8 (small-enwik8). Kourkoutas-Beta improves stability and final loss
versus fixed-beta2 Adam. On small-enwik8 it lowers bits-per-character by about
38% vs Adam-0.95 and about 58% vs Adam-0.999 over 10 seeds, with smaller
variance. The method remains drop-in, with runtime overhead comparable to Adam
in testbeds A-C and within single-digit percent in testbed D. It preserves
Adam-style convergence guarantees while improving robustness under spiky
gradients.

</details>


### [418] [Fairness-Aware Multi-view Evidential Learning with Adaptive Prior](https://arxiv.org/abs/2508.12997)
*Haishun Chen,Cai Xu,Jinlong Yu,Yilin Zhang,Ziyu Guan,Wei Zhao*

Main category: cs.LG

TL;DR: 다중 뷰 증거학습에서 데이터-부족/과다 클래스로 인해 증거가 편향되어 불확실성 추정이 신뢰할 수 없다는 문제를 규명하고, 훈련 궤적 기반 적응적 사전, 클래스별 증거 분산에 대한 공정성 제약, 뷰 간 의견 정렬을 결합한 FAML을 제안해 편향 완화와 성능·불확실성 신뢰성 향상을 달성했다.


<details>
  <summary>Details</summary>
Motivation: 기존 다중 뷰 증거학습은 각 뷰의 증거 학습이 신뢰할 수 있다고 가정하지만, 실제로는 데이터가 풍부한 클래스에 더 많은 증거가 할당되어 예측의 불확실성 추정이 편향되고 신뢰도가 떨어진다. 이를 해결하는 새로운 문제(Biased Evidential Multi-view Learning)를 제기한다.

Method: FAML은 (1) 훈련 궤적에 기반한 적응적 사전(prior)을 도입해 편향된 증거 학습을 정규화하고, (2) 클래스별 증거 분산을 최소화하는 공정성 제약을 통해 증거 분배의 균형을 촉진하며, (3) 다중 뷰 융합 단계에서 뷰별 편향을 줄이기 위한 의견 정렬(opinion alignment) 메커니즘을 적용한다.

Result: 5개의 실제 다중 뷰 데이터셋에서 FAML은 증거 할당의 균형성을 개선하고, 예측 성능과 불확실성 추정의 신뢰성(보정 등)을 기존 최첨단 방법들보다 향상시켰다.

Conclusion: 훈련 궤적 기반 적응적 사전, 공정성 제약, 뷰 간 의견 정렬의 결합은 다중 뷰 증거학습에서 증거 편향을 완화하고 더 신뢰할 수 있는 불확실성 추정을 제공하는 유효한 접근법이지만, 세부 구현·평가·이론적 근거가 추가로 필요하다.

Abstract: Multi-view evidential learning aims to integrate information from multiple
views to improve prediction performance and provide trustworthy uncertainty
esitimation. Most previous methods assume that view-specific evidence learning
is naturally reliable. However, in practice, the evidence learning process
tends to be biased. Through empirical analysis on real-world data, we reveal
that samples tend to be assigned more evidence to support data-rich classes,
thereby leading to unreliable uncertainty estimation in predictions. This
motivates us to delve into a new Biased Evidential Multi-view Learning (BEML)
problem. To this end, we propose Fairness-Aware Multi-view Evidential Learning
(FAML). FAML first introduces an adaptive prior based on training trajectory,
which acts as a regularization strategy to flexibly calibrate the biased
evidence learning process. Furthermore, we explicitly incorporate a fairness
constraint based on class-wise evidence variance to promote balanced evidence
allocation. In the multi-view fusion stage, we propose an opinion alignment
mechanism to mitigate view-specific bias across views, thereby encouraging the
integration of consistent and mutually supportive evidence. Extensive
experiments on five real-world multi-view datasets demonstrate that FAML
achieves more balanced evidence allocation and improves both prediction
performance and the reliability of uncertainty estimation compared to
state-of-the-art methods.

</details>


### [419] [Monte Carlo Functional Regularisation for Continual Learning](https://arxiv.org/abs/2508.13006)
*Pengcheng Hao,Menghao Waiyan William Zhu,Ercan Engin Kuruoglu*

Main category: cs.LG

TL;DR: MCFRCL은 예측 분포를 몬테카를로 샘플링으로 근사하고, 세 가지 연속 분포를 모먼트 기반으로 피팅한 뒤 Wasserstein과 KL 거리를 이용해 기능적 정규화를 수행하는 연속 학습 프레임워크로, MNIST/CIFAR에서 정확도와 학습 효율이 개선되었다고 주장함.


<details>
  <summary>Details</summary>
Motivation: 기능(함수) 기반 정규화 방법들이 가중치 공간 정규화보다 성능이 우수하지만 계산비용이 크고 선형 근사 오차가 커서 이를 해결할 필요가 있음.

Method: 모델의 예측 분포를 MC 샘플링으로 근사하고, 세 가지 연속 분포를 모멘트 기반으로 맞춘 뒤(모멘트 추정) Wasserstein 거리와 KL 거리를 결합해 정규화 항을 구성함.

Result: MNIST 및 CIFAR 벤치마크 실험에서 기존 방법들보다 예측 정확도 및 학습 효율 면에서 우수한 성능을 보였다고 보고함.

Conclusion: MC 기반의 기능적 정규화(및 모멘트 기반 분포 표현, 두 거리 결합)가 연속 학습에서 실용적 이득을 줄 수 있음을 시사하나, 구체적 구현·비용·일반화 실험 등 추가 정보가 필요함.

Abstract: Continual learning (CL) is crucial for the adaptation of neural network
models to new environments. Although outperforming weight-space regularisation
approaches, the functional regularisation-based CL methods suffer from high
computational costs and large linear approximation errors. In this work, we
present a new functional regularisation CL framework, called MCFRCL, which
approximates model prediction distributions by Monte Carlo (MC) sampling.
Moreover, three continuous distributions are leveraged to capture the
statistical characteristics of the MC samples via moment-based methods.
Additionally, both the Wasserstein distance and the Kullback-Leibler (KL)
distance are employed to construct the regularisation function. The proposed
MCFRCL is evaluated against multiple benchmark methods on the MNIST and CIFAR
datasets, with simulation results highlighting its effectiveness in both
prediction accuracy and training efficiency.

</details>


### [420] [Design and Analysis of Robust Adaptive Filtering with the Hyperbolic Tangent Exponential Kernel M-Estimator Function for Active Noise Control](https://arxiv.org/abs/2508.13018)
*Iam Kim de S. Hermont,Andre R. Flores,Rodrigo C. de Lamare*

Main category: cs.LG

TL;DR: 저자는 충격성(impulsive) 잡음 하의 능동 소음 제어(ANC)를 위해 필터드-x 하이퍼볼릭 탄젠트 지수 일반화 커널 M-추정(FXHEKM) 알고리즘을 제안한다. 통계적 분석과 계산 복잡도 평가를 제공하고 MSE/ANR 성능으로 α-안정 잡음에서 기존 방법보다 우수함을 보였다.


<details>
  <summary>Details</summary>
Motivation: ANC 시스템은 충격성 잡음(α-안정 분포 등)에 취약하다. 기존의 LMS/FXLMS 계열은 큰 외란에 민감해 성능 저하가 발생하므로, 로버스트한 손실함수와 커널 기법을 결합해 충격성 노이즈에 강한 적응필터가 필요하다.

Method: 필터드-x 구조에 하이퍼볼릭 탄젠트와 지수함수를 결합한 일반화 커널 M-추정 손실을 도입하여 FXHEKM 알고리즘을 설계했다. 알고리즘의 수렴/통계적 특성(아마도 평균/분산 분석)을 유도하고 계산 비용을 분석했다. 성능 평가는 MSE와 평균 소음 감소(ANR)를 사용해 α-안정 잡음 환경에서 비교 실험을 수행했다.

Result: 시뮬레이션 결과 FXHEKM이 α-안정 잡음 환경에서 기존 알고리즘에 비해 MSE와 ANR 면에서 우수함을 보였다. 제안 방법은 충격성 신호(스파이러스 신호)에 대해 강인한 소음 제거 성능을 나타냈다.

Conclusion: 하이퍼볼릭 탄젠트 기반의 일반화 커널 M-추정을 필터드-x 프레임에 적용하면 충격성 잡음 환경에서 ANC 성능을 개선할 수 있다. 제안 알고리즘은 계산 비용을 고려하면서도 기존 방법들보다 더 강인한 특성을 가진다.

Abstract: In this work, we propose a robust adaptive filtering approach for active
noise control applications in the presence of impulsive noise. In particular,
we develop the filtered-x hyperbolic tangent exponential generalized Kernel
M-estimate function (FXHEKM) robust adaptive algorithm. A statistical analysis
of the proposed FXHEKM algorithm is carried out along with a study of its
computational cost. {In order to evaluate the proposed FXHEKM algorithm, the
mean-square error (MSE) and the average noise reduction (ANR) performance
metrics have been adopted.} Numerical results show the efficiency of the
proposed FXHEKM algorithm to cancel the presence of the additive spurious
signals, such as \textbf{$\alpha$}-stable noises against competing algorithms.

</details>


### [421] [The Application of Transformer-Based Models for Predicting Consequences of Cyber Attacks](https://arxiv.org/abs/2508.13030)
*Bipin Chhetri,Akbar Siami Namin*

Main category: cs.LG

TL;DR: CWE 텍스트를 이용해 사이버공격의 영향(가용성, 접근통제, 기밀성, 무결성, 기타)을 예측하는 연구로, BERT와 HAN을 비교해 BERT가 전체적으로 우수한 성능(정확도 0.972)을 보였다는 결과.


<details>
  <summary>Details</summary>
Motivation: 사이버공격의 복잡성이 증가함에 따라 공격 설명을 자동으로 분석하고 결과 영향을 예측하는 도구가 필요하다. 위협 모델링을 자동화하면 자원 배분과 대응 속도를 개선할 수 있다.

Method: MITRE CWE 데이터의 텍스트 설명을 다중 라벨 분류 문제로 설정. BERT와 계층적 주의 네트워크(HAN)를 포함한 딥러닝 모델들을 CNN/LSTM 기반 베이스라인과 비교 평가했다.

Result: BERT가 전체 정확도 0.972로 가장 우수했고, HAN은 특정 보안 라벨에서 CNN/LSTM 기반 베이스라인보다 성능이 높았다. BERT는 정밀도와 재현율 면에서도 일관되게 우수했다.

Conclusion: 텍스트 기반 취약점 설명으로 공격 영향을 예측하는 데 BERT 계열 모델이 특히 효과적이다. HAN은 라벨별 특성에 따라 유용할 수 있으나, 전체적으로는 BERT가 더 적합하다.

Abstract: Cyberattacks are increasing, and securing against such threats is costing
industries billions of dollars annually. Threat Modeling, that is,
comprehending the consequences of these attacks, can provide critical support
to cybersecurity professionals, enabling them to take timely action and
allocate resources that could be used elsewhere. Cybersecurity is heavily
dependent on threat modeling, as it assists security experts in assessing and
mitigating risks related to identifying vulnerabilities and threats. Recently,
there has been a pressing need for automated methods to assess attack
descriptions and forecast the future consequences of the increasing complexity
of cyberattacks. This study examines how Natural Language Processing (NLP) and
deep learning can be applied to analyze the potential impact of cyberattacks by
leveraging textual descriptions from the MITRE Common Weakness Enumeration
(CWE) database. We emphasize classifying attack consequences into five
principal categories: Availability, Access Control, Confidentiality, Integrity,
and Other. This paper investigates the use of Bidirectional Encoder
Representations from Transformers (BERT) in combination with Hierarchical
Attention Networks (HANs) for Multi-label classification, evaluating their
performance in comparison with conventional CNN and LSTM-based models.
Experimental findings show that BERT achieves an overall accuracy of $0.972$,
far higher than conventional deep learning models in multi-label
classification. HAN outperforms baseline forms of CNN and LSTM-based models on
specific cybersecurity labels. However, BERT consistently achieves better
precision and recall, making it more suitable for predicting the consequences
of a cyberattack.

</details>


### [422] [Beyond Internal Data: Bounding and Estimating Fairness from Incomplete Data](https://arxiv.org/abs/2508.13040)
*Varsha Ramineni,Hossein A. Rahmani,Emine Yilmaz,David Barber*

Main category: cs.LG

TL;DR: Use separate internal predictive data and external public demographic data to infer feasible joint distributions consistent with observed marginals, then compute bounds on fairness metrics; experiments show these bounds are informative and contain the true metric.


<details>
  <summary>Details</summary>
Motivation: Complete joint data with protected attributes is often unavailable due to legal, privacy, and cultural barriers, yet fairness assessments and audits require group-disparity measures.

Method: Form the set of all joint distributions consistent with the separate marginal datasets (internal features vs external protected attributes) and compute the range of plausible fairness metrics over this feasible set; validate via simulation and real-world experiments.

Result: The approach produces meaningful bounds on fairness metrics that reliably include the true metric; in many cases bounds are tight enough to support practical auditing decisions.

Conclusion: Estimating bounds from separated data is a practical, effective solution for fairness testing when complete data cannot be accessed, enabling auditors and institutions to report plausible ranges of group disparities.

Abstract: Ensuring fairness in AI systems is critical, especially in high-stakes
domains such as lending, hiring, and healthcare. This urgency is reflected in
emerging global regulations that mandate fairness assessments and independent
bias audits. However, procuring the necessary complete data for fairness
testing remains a significant challenge. In industry settings, legal and
privacy concerns restrict the collection of demographic data required to assess
group disparities, and auditors face practical and cultural challenges in
gaining access to data. In practice, data relevant for fairness testing is
often split across separate sources: internal datasets held by institutions
with predictive attributes, and external public datasets such as census data
containing protected attributes, each providing only partial, marginal
information. Our work seeks to leverage such available separate data to
estimate model fairness when complete data is inaccessible. We propose
utilising the available separate data to estimate a set of feasible joint
distributions and then compute the set plausible fairness metrics. Through
simulation and real experiments, we demonstrate that we can derive meaningful
bounds on fairness metrics and obtain reliable estimates of the true metric.
Our results demonstrate that this approach can serve as a practical and
effective solution for fairness testing in real-world settings where access to
complete data is restricted.

</details>


### [423] [Hierarchical Evaluation Function (HEF): A Multi-Metric Approach for Optimizing Demand Forecasting Models](https://arxiv.org/abs/2508.13057)
*Adolfo González,Víctor Parada*

Main category: cs.LG

TL;DR: HEF가 글로벌 지표(R2, RMSE, RMSSE, Relative Accuracy)에서 일관되게 우수하며 모델의 강건성과 설명력을 높인다. FMAE는 MAE, MASE 같은 지역 지표와 실행 시간에서 이점이 있어 단기·운영 시나리오에 적합하다.


<details>
  <summary>Details</summary>
Motivation: 다변량 시계열 예측에서 불확실성과 레짐 전환이 잦아 기존 평가 지표가 편향을 유발하고 일반화 성능을 저해한다는 문제를 해결하기 위해, 글로벌 손실에 초점을 둔 HEF와 절대오차 최소화에 초점을 둔 FMAE를 설계·비교하고자 함.

Method: 세 가지 데이터 분할(91:9, 80:20, 70:30)과 세 가지 최적화 기법(Grid Search, PSO, Optuna)을 적용하여 동일 모델·데이터에 대해 두 평가함수를 사용해 하이퍼파라미터 최적화 및 성능 비교. 평가항목은 R2, Relative Accuracy, RMSE, RMSSE, MAE, MASE, 실행시간 등이며 시각화·통계검정을 통해 유의성 확인.

Result: HEF는 글로벌 지표에서 우수하여 모델의 설명력과 강건성을 개선했고, FMAE는 지역 지표와 계산 효율에서 우세했다. 두 지표 간에는 전략적(HEF) vs 운영적(FMAE) 트레이드오프가 관찰됨.

Conclusion: HEF는 전략적 의사결정·장기 수요계획에 적합하고, FMAE는 단기·운영 최적화에 적합하다. 연구는 재현 가능한 프레임워크를 제안하지만, 메서드·데이터·통계 절차의 상세 공개가 향후 검증에 필요하다.

Abstract: Demand forecasting is essential for strategic planning in competitive
environments, enabling resource optimization and improved responsiveness to
market dynamics. However, multivariate time series modeling faces challenges
due to data complexity, uncertainty, and frequent regime shifts. Traditional
evaluation metrics can introduce biases and limit generalization. This work
compares two custom evaluation functions: FMAE (Focused Mean Absolute Error),
focused on minimizing absolute errors, and HEF (Hierarchical Evaluation
Function), designed to weight global metrics and penalize large deviations.
Experiments were conducted under different data splits (91:9, 80:20, 70:30)
using three optimizers (Grid Search, PSO, Optuna), assessing fit, relative
accuracy, robustness, and computational efficiency. Results show that HEF
consistently outperforms FMAE in global metrics (R2, Relative Accuracy, RMSE,
RMSSE), enhancing model robustness and explanatory power. These findings were
confirmed via visualizations and statistical tests. Conversely, FMAE offers
advantages in local metrics (MAE, MASE) and execution time, making it suitable
for short-term scenarios. The study highlights a methodological trade-off: HEF
is ideal for strategic planning, while FMAE is better suited for operational
efficiency. A replicable framework is proposed for optimizing predictive models
in dynamic environments.

</details>


### [424] [Seeing the Many: Exploring Parameter Distributions Conditioned on Features in Surrogates](https://arxiv.org/abs/2508.13088)
*Xiaohan Wang,Zhimin Li,Joshua A. Levine,Matthew Berger*

Main category: cs.LG

TL;DR: 신경 서로게이트 모델의 근사 오차를 밀도추정으로 모델링하여, 특정 출력 특징을 생성할 수 있는 입력 파라미터들의 분포를 샘플링·시각화하는 방법을 제안한다. 입력·출력 공간에서 훈련 데이터에 가까운 경우만 고밀도로 평가해 우선도를 만들고, 특징에 대한 우도와 결합해 상호작용적 파라미터 탐색을 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: 기존 서로게이트 기반 역문제는 목표 출력을 만족하는 몇몇 파라미터만 찾는 데 집중해 가능한 파라미터의 전체 가능한 분포를 놓친다. 고차원 파라미터 공간에서 효율적으로 가능한 파라미터 집합을 탐색·표현하는 방법이 필요하다.

Method: 서로게이트 모델의 근사 오류를 입력·출력 공간에서 훈련 데이터와의 근접성으로 측정하는 밀도 추정으로 모델링하여, 이를 파라미터에 대한 사전(prior)으로 사용한다. 사용자가 정의한 출력 특징에 대한 우도(likelihood)와 결합해 표본을 추출하고, 이를 인터랙티브 시각화 인터페이스로 제공해 특징 기반 파라미터 분석을 수행한다.

Result: 제안 기법을 세 가지 시뮬레이션 데이터셋에 적용해 사용자가 목표 출력 특징과 일치하는 다양한(다중 모드) 입력 파라미터 집합을 효율적으로 샘플링·탐색할 수 있음을 보였다. 구현 및 코드 공개로 재현성 제공.

Conclusion: 서로게이트의 근사 오차를 명시적으로 반영한 밀도 기반 우선도와 특징 기반 우도를 결합하면, 단일 해가 아닌 가능한 파라미터 분포를 상호작용적으로 탐색·시각화할 수 있다. 다만 고차원성·서로게이트 품질과 관련된 한계는 추가 평가가 필요하다.

Abstract: Recently, neural surrogate models have emerged as a compelling alternative to
traditional simulation workflows. This is accomplished by modeling the
underlying function of scientific simulations, removing the need to run
expensive simulations. Beyond just mapping from input parameter to output,
surrogates have also been shown useful for inverse problems: output to input
parameters. Inverse problems can be understood as search, where we aim to find
parameters whose surrogate outputs contain a specified feature. Yet finding
these parameters can be costly, especially for high-dimensional parameter
spaces. Thus, existing surrogate-based solutions primarily focus on finding a
small set of matching parameters, in the process overlooking the broader
picture of plausible parameters. Our work aims to model and visualize the
distribution of possible input parameters that produce a given output feature.
To achieve this goal, we aim to address two challenges: (1) the approximation
error inherent in the surrogate model and (2) forming the parameter
distribution in an interactive manner. We model error via density estimation,
reporting high density only if a given parameter configuration is close to
training parameters, measured both over the input and output space. Our density
estimate is used to form a prior belief on parameters, and when combined with a
likelihood on features, gives us an efficient way to sample plausible parameter
configurations that generate a target output feature. We demonstrate the
usability of our solution through a visualization interface by performing
feature-driven parameter analysis over the input parameter space of three
simulation datasets. Source code is available at
https://github.com/matthewberger/seeing-the-many

</details>


### [425] [Outlier Detection of Poisson-Distributed Targets Using a Seabed Sensor Network](https://arxiv.org/abs/2508.13099)
*Mingyu Kim,Daniel Stilwell,Jorge Jimenez*

Main category: cs.LG

TL;DR: 해양 환경에서 LGCP 기반으로 정상/이상(외란) 도착을 혼합모형으로 모델링하고, 평균뿐 아니라 분산을 포함한 2차 근사로 새 이벤트의 이상 확률을 계산한다. 이론적으로 제시한 방법은 젠슨 부등식을 통해 더 타이트한 상한을 제공하며, 실시간 근최적 센서 배치를 통합해 검출 성능을 향상시켰다. Norfolk 항 인근 실제 선박 데이터에서 성능 개선을 확인했다.


<details>
  <summary>Details</summary>
Motivation: 해저 음향 센서 네트워크를 통해 선박·타깃의 공간적 이상(스파이크, 이탈 경로 등)을 정확히 분류·탐지하려면 강건한 확률 모델과 적응적 센서 배치가 필요하다. 기존 평균 기반 접근은 불확실성을 반영하지 못해 오분류가 발생할 수 있다.

Method: 목표 도착을 정상 과정(정규 LGCP)과 이상 과정의 혼합으로 모델링하고, 신규 관측이 이상일 확률을 추정한다. 평균만 사용하는 기존 방식과 달리 정상 강도(intensity)의 평균과 분산을 포함하는 2차 근사식을 제안한다. 젠슨 부등식을 이용해 제안치가 실제 확률에 더 타이트한 상한임을 분석적으로 보였다. 또한 이상 강도의 변화에 따라 실시간으로 근최적 센서 배치를 결정하는 전략을 설계해 센서 위치를 동적으로 조정한다.

Result: Norfolk 인근 실제 선박 트래픽 데이터로 수치실험을 수행하여, 2차 근사 기반 분류가 평균만 쓴 방법보다 분류 정확도가 향상됨을 보였고, 동적 센서 배치를 통해 이상 탐지 성능이 추가로 개선됨을 확인했다.

Conclusion: 정규강도의 분산을 고려한 확률 근사는 이상 분류의 정확도를 높이며, 실시간 적응형 센서 배치와 결합하면 해양 이상 탐지 시스템의 실무 적용 가능성을 향상시킨다. 추가적으로 모델 가정·계산 복잡도·실제 제약 조건에 대한 평가가 필요하다.

Abstract: This paper presents a framework for classifying and detecting spatial
commission outliers in maritime environments using seabed acoustic sensor
networks and log Gaussian Cox processes (LGCPs). By modeling target arrivals as
a mixture of normal and outlier processes, we estimate the probability that a
newly observed event is an outlier. We propose a second-order approximation of
this probability that incorporates both the mean and variance of the normal
intensity function, providing improved classification accuracy compared to
mean-only approaches. We analytically show that our method yields a tighter
bound to the true probability using Jensen's inequality. To enhance detection,
we integrate a real-time, near-optimal sensor placement strategy that
dynamically adjusts sensor locations based on the evolving outlier intensity.
The proposed framework is validated using real ship traffic data near Norfolk,
Virginia, where numerical results demonstrate the effectiveness of our approach
in improving both classification performance and outlier detection through
sensor deployment.

</details>


### [426] [A Perfectly Truthful Calibration Measure](https://arxiv.org/abs/2508.13100)
*Jason Hartline,Lunjia Hu,Yifan Wu*

Main category: cs.LG

TL;DR: 배치(setting)에서 완전히 진실된(perfectly truthful) 캘리브레이션 척도인 ATB(averaged two-bin calibration error)를 제안한다. ATB는 truthful, sound, complete, 연속성 보유하고 smCal 및 distCal과 2차 관계를 가지며 계산이 단순·효율적이다. 또한 진실성을 보장하는 일반적 구성법을 제시해 다른 진실한 척도(예: quantile-binned l_2-ECE)를 얻을 수 있다.


<details>
  <summary>Details</summary>
Motivation: 유한 표본상에서 기존의 모든 알려진 캘리브레이션 척도는 예측자가 더 ‘보정된’ 것으로 보이기 위해 거짓(편향된 예측)을 하도록 유도한다. Haghtalab 등(2024)과 Qiao & Zhao(2025)는 순차적 설정에서 근사적 진실성(approximately truthful)을 얻었지만, 배치 설정에서는 완전한 진실성을 갖는 척도가 알려지지 않았다.

Method: 두 개의 이진(binned) 분할을 평균화하는 간단한 척도(ATB)를 정의하고, 기대값에서 실제 확률을 출력할 때 척도가 최소가 됨을 수학적으로 증명한다. ATB의 soundness, completeness, continuity를 보이고, ATB와 기존의 smCal·distCal 사이의 2차(quadratic) 관계를 세운다. 또한 진실성 보장을 일반화하는 레시피를 제시하여 다른 진실한 척도를 구성한다. 알고리즘적으로는 ATB 기반의 추정·검정 절차가 더 빠르고 구현이 단순함을 보인다.

Result: 배치 설정에서 최초의 완전 진실한 캘리브레이션 척도(ATB) 존재를 보였고, 이를 통해 캘리브레이션 검사 문제의 시간복잡도·구현 난이도를 개선. ATB가 smCal·distCal과 관련되어 실용적·이론적 연속성을 제공함. 일반적 구성법으로 quantile-binned l_2-ECE 등 다른 진실한 척도도 얻음.

Conclusion: ATB는 배치 설정에서 캘리브레이션 측정의 이론적 허들을 해결하고, 계산적·실용적 이점도 제공한다. 제시된 일반 레시피는 추가 진실한 척도 설계로 확장 가능하며 캘리브레이션 평가의 신뢰성을 높인다.

Abstract: Calibration requires that predictions are conditionally unbiased and,
therefore, reliably interpretable as probabilities. Calibration measures
quantify how far a predictor is from perfect calibration. As introduced by
Haghtalab et al. (2024), a calibration measure is truthful if it is minimized
in expectation when a predictor outputs the ground-truth probabilities.
Although predicting the true probabilities guarantees perfect calibration, in
reality, when calibration is evaluated on a finite sample, predicting the truth
is not guaranteed to minimize any known calibration measure. All known
calibration measures incentivize predictors to lie in order to appear more
calibrated on a finite sample. Such lack of truthfulness motivated Haghtalab et
al. (2024) and Qiao and Zhao (2025) to construct approximately truthful
calibration measures in the sequential prediction setting, but no perfectly
truthful calibration measure was known to exist even in the more basic batch
setting.
  We design a perfectly truthful calibration measure in the batch setting:
averaged two-bin calibration error (ATB). In addition to being truthful, ATB is
sound, complete, continuous, and quadratically related to two existing
calibration measures: the smooth calibration error (smCal) and the (lower)
distance to calibration (distCal). The simplicity in our definition of ATB
makes it efficient and straightforward to compute. ATB allows faster estimation
algorithms with significantly easier implementations than smCal and distCal,
achieving improved running time and simplicity for the calibration testing
problem studied by Hu et al. (2024). We also introduce a general recipe for
constructing truthful measures, which proves the truthfulness of ATB as a
special case and allows us to construct other truthful calibration measures
such as quantile-binned l_2-ECE.

</details>


### [427] [Causally-Guided Pairwise Transformer -- Towards Foundational Digital Twins in Process Industry](https://arxiv.org/abs/2508.13111)
*Michael Mayr,Georgios C. Chasparis*

Main category: cs.LG

TL;DR: Introduces CGPT, a pairwise Transformer using known causal graph as inductive bias to balance channel-dependent and channel-independent modeling for multivariate time-series; achieves scalability and any-variate adaptability with strong forecasting results.


<details>
  <summary>Details</summary>
Motivation: Address trade-off between channel-dependent models (capture cross-variable dynamics but tied to dimensionality) and channel-independent models (generalize across dimensions but miss interactions).

Method: Decompose multivariate data into variable pairs; use channel-agnostic learnable layers whose parameters do not depend on number of variables; enforce pair-level CD information flow guided by a known causal graph, enabling CI-like generalization across pairs.

Result: On synthetic and real-world industrial datasets for long-term and one-step forecasting, CGPT outperforms CI and CD baselines in predictive accuracy and competes with end-to-end CD models while remaining agnostic to dimensionality.

Conclusion: Pairwise, causally-guided decomposition yields a flexible, scalable architecture that reconciles CD/CI trade-offs and enables any-variate adaptability without sacrificing predictive performance.

Abstract: Foundational modelling of multi-dimensional time-series data in industrial
systems presents a central trade-off: channel-dependent (CD) models capture
specific cross-variable dynamics but lack robustness and adaptability as model
layers are commonly bound to the data dimensionality of the tackled use-case,
while channel-independent (CI) models offer generality at the cost of modelling
the explicit interactions crucial for system-level predictive regression tasks.
To resolve this, we propose the Causally-Guided Pairwise Transformer (CGPT), a
novel architecture that integrates a known causal graph as an inductive bias.
The core of CGPT is built around a pairwise modeling paradigm, tackling the
CD/CI conflict by decomposing the multidimensional data into pairs. The model
uses channel-agnostic learnable layers where all parameter dimensions are
independent of the number of variables. CGPT enforces a CD information flow at
the pair-level and CI-like generalization across pairs. This approach
disentangles complex system dynamics and results in a highly flexible
architecture that ensures scalability and any-variate adaptability. We validate
CGPT on a suite of synthetic and real-world industrial datasets on long-term
and one-step forecasting tasks designed to simulate common industrial
complexities. Results demonstrate that CGPT significantly outperforms both CI
and CD baselines in predictive accuracy and shows competitive performance with
end-to-end trained CD models while remaining agnostic to the problem
dimensionality.

</details>


### [428] [Contrastive Representations for Temporal Reasoning](https://arxiv.org/abs/2508.13113)
*Alicja Ziarko,Michal Bortkiewicz,Michal Zawalski,Benjamin Eysenbach,Piotr Milos*

Main category: cs.LG

TL;DR: CRTR (Combinatorial Representations for Temporal Reasoning) augments temporal contrastive learning with a negative sampling scheme that removes spurious features, enabling learned representations to capture temporal structure and support planning-like temporal reasoning; it succeeds on tasks with complex temporal dependencies such as Sokoban and Rubik's Cube, even solving arbitrary Cube states without external search.


<details>
  <summary>Details</summary>
Motivation: Standard perception-plus-search pipeline separates representation learning and temporal reasoning; temporal contrastive learning is popular for learning dynamics-aware embeddings but often captures spurious (non-temporal) features and fails to support planning over long action sequences. The paper asks whether a single representation can capture both perceptual and temporal structure to enable planning-like reasoning without external search.

Method: Introduce CRTR: modify temporal contrastive learning with a principled negative sampling scheme that eliminates spurious features (the scheme is theoretically justified/provable). Learn combinatorial representations that encode temporal relations between states. Use these embeddings directly for temporal reasoning and planning tasks, evaluating on combinatorially structured domains.

Result: CRTR outperforms standard temporal contrastive baselines on domains with complex temporal structure (Sokoban, Rubik's Cube). For Rubik's Cube, CRTR generalizes across all initial states and can solve arbitrary states using only learned representations, requiring fewer search steps than BestFS though producing longer solutions.

Conclusion: Carefully designed negative sampling in temporal contrastive learning yields representations that encode temporal/combinatorial structure and enable planning-like capabilities directly from embeddings; CRTR provides the first efficient learned-representation-only solver for arbitrary Rubik's Cube states (per authors' claim), showing promise for unified perception-and-planning representations.

Abstract: In classical AI, perception relies on learning state-based representations,
while planning, which can be thought of as temporal reasoning over action
sequences, is typically achieved through search. We study whether such
reasoning can instead emerge from representations that capture both perceptual
and temporal structure. We show that standard temporal contrastive learning,
despite its popularity, often fails to capture temporal structure due to its
reliance on spurious features. To address this, we introduce Combinatorial
Representations for Temporal Reasoning (CRTR), a method that uses a negative
sampling scheme to provably remove these spurious features and facilitate
temporal reasoning. CRTR achieves strong results on domains with complex
temporal structure, such as Sokoban and Rubik's Cube. In particular, for the
Rubik's Cube, CRTR learns representations that generalize across all initial
states and allow it to solve the puzzle using fewer search steps than BestFS,
though with longer solutions. To our knowledge, this is the first method that
efficiently solves arbitrary Cube states using only learned representations,
without relying on an external search algorithm.

</details>


### [429] [Training Machine Learning Models on Human Spatio-temporal Mobility Data: An Experimental Study [Experiment Paper]](https://arxiv.org/abs/2508.13135)
*Yueyang Liu,Lance Kennedy,Ruochen Kong,Joon-Seok Kim,Andreas Züfle*

Main category: cs.LG

TL;DR: 개인 수준의 장기(일·주 단위) 궤적 예측을 대상으로 LSTM/Transformer 실험을 통해 학습 전략(개인 이력·요일 정보 포함, 사용자 기반 군집+계층표본추출, 소배치 SGD)이 성능 개선에 유효함을 보인 실험 논문.


<details>
  <summary>Details</summary>
Motivation: 기존 연구는 단기·미시적 위치 예측에 집중되어 있고, 개인의 며칠~몇주 전체 궤적(매크로적 생활 루틴) 예측에 대한 학습 전략과 데이터 편향 문제는 충분히 다뤄지지 않음.

Method: 다양한 모델(LSTM, Transformer), 하이퍼파라미터, 학습 전략을 광범위하게 실험. 입력에 요일·사용자 이력 같은 의미적(semantic) 피처를 추가하고, 사용자 표본추출 시 군집화 기반 계층표본추출로 데이터 불균형/편향을 완화. 작은 배치 크기의 SGD 효과도 평가.

Result: 요일·개인 이력 정보를 명시적으로 포함하면 개인 루틴 이해도가 높아져 예측 성능 향상. 임의 사용자 샘플링은 편향을 심화시켜 정확도 저하를 초래함. 사용자 의미 군집+계층표본추출로 대표성 유지 및 성능 회복 가능. 데이터가 적은 경우 소배치 SGD가 성능을 추가로 개선.

Conclusion: 장기 개인 궤적 예측에서는 의미적 피처 포함, 대표성 있는 사용자 샘플링(군집+계층화), 소배치 최적화가 실무적 우수 관행이며, 개인정보 부재로 인한 표본 편향과 데이터 제약을 고려해야 함.

Abstract: Individual-level human mobility prediction has emerged as a significant topic
of research with applications in infectious disease monitoring, child, and
elderly care. Existing studies predominantly focus on the microscopic aspects
of human trajectories: such as predicting short-term trajectories or the next
location visited, while offering limited attention to macro-level mobility
patterns and the corresponding life routines. In this paper, we focus on an
underexplored problem in human mobility prediction: determining the best
practices to train a machine learning model using historical data to forecast
an individuals complete trajectory over the next days and weeks. In this
experiment paper, we undertake a comprehensive experimental analysis of diverse
models, parameter configurations, and training strategies, accompanied by an
in-depth examination of the statistical distribution inherent in human mobility
patterns. Our empirical evaluations encompass both Long Short-Term Memory and
Transformer-based architectures, and further investigate how incorporating
individual life patterns can enhance the effectiveness of the prediction. We
show that explicitly including semantic information such as day-of-the-week and
user-specific historical information can help the model better understand
individual patterns of life and improve predictions. Moreover, since the
absence of explicit user information is often missing due to user privacy, we
show that the sampling of users may exacerbate data skewness and result in a
substantial loss in predictive accuracy. To mitigate data imbalance and
preserve diversity, we apply user semantic clustering with stratified sampling
to ensure that the sampled dataset remains representative. Our results further
show that small-batch stochastic gradient optimization improves model
performance, especially when human mobility training data is limited.

</details>


### [430] [MDPO: Overcoming the Training-Inference Divide of Masked Diffusion Language Models](https://arxiv.org/abs/2508.13148)
*Haoyu He,Katrin Renz,Yong Cao,Andreas Geiger*

Main category: cs.LG

TL;DR: 저자들은 마스킹된 확산 언어모델(MDLM)의 학습-추론 불일치를 강화학습으로 해결한다. MDPO라는 방법을 제안해, 추론 시 사용되는 점진적 정제 스케줄에 맞춰 모델을 직접 학습하여 더 적은 업데이트로 SOTA 성능을 달성하거나 동일 업데이트 내에서 큰 성능 향상을 보였다. 또한 RCR이라는 학습 없는 리마스킹 추론 보완 전략을 제안해 추가 향상을 달성한다.


<details>
  <summary>Details</summary>
Motivation: MDLM은 AR 모델에 비해 빠른 생성과 양방향 문맥 조건화 장점이 있으나, 학습 시 임의 마스킹과 달리 추론 시 점점 적어지는 마스크 구조가 드러나는 불일치가 성능 저하를 초래할 수 있다. 이를 해결하여 학습과 추론 간 갭을 메우려는 동기가 있다.

Method: 문제를 순차적 의사결정 강화학습 문제로 정식화하고, 확산 과정의 마르코프 성질을 활용한 Masked Diffusion Policy Optimization(MDPO)를 제안한다. MDPO는 추론에서 사용되는 점진적 정제 스케줄을 그대로 학습 중에 적용해, 효율적으로 정책을 학습한다. 또한 학습 없이 추론 시 토큰 정제를 유연하게 하는 Remasking with Conditional Resampling(RCR) 전략을 플러그인으로 제안한다.

Result: MDPO는 이전 SOTA와 동등한 성능을 60배 적은 그래디언트 업데이트로 달성했으며, 동일 업데이트 수 내에서는 MATH500에서 평균 9.6%, Countdown에서 54.2% 성능 향상을 보였다. RCR은 추가적인 성능 향상을 일관되게 제공하며, MDPO와 결합 시 더 큰 이득을 준다.

Conclusion: 학습-추론 불일치를 다루는 강화학습 기반의 접근이 MDLM 성능 향상에 유효함을 보였고, RCR 같은 간단한 추론 전략도 실용적 이득을 제공한다. 이 연구는 MDLM의 사전학습과 추론 간 불일치 연구 가능성을 열어준다.

Abstract: Diffusion language models, as a promising alternative to traditional
autoregressive (AR) models, enable faster generation and richer conditioning on
bidirectional context. However, they suffer from a key discrepancy between
training and inference: during inference, MDLMs progressively reveal the
structure of the generated sequence by producing fewer and fewer masked tokens,
whereas this structure is ignored in training as tokens are masked at random.
Although this discrepancy between training and inference can lead to suboptimal
performance, it has been largely overlooked by previous works, leaving closing
this gap between the two stages an open problem. To address this, we frame the
problem of learning effective denoising trajectories as a sequential
decision-making problem and use the resulting framework to apply reinforcement
learning. We propose a novel Masked Diffusion Policy Optimization (MDPO) to
exploit the Markov property diffusion possesses and explicitly train the model
under the same progressive refining schedule used at inference. MDPO matches
the performance of the previous state-of-the-art (SOTA) method with 60x fewer
gradient updates, while achieving average improvements of 9.6% on MATH500 and
54.2% on Countdown over SOTA when trained within the same number of weight
updates. Additionally, we improve the remasking strategy of MDLMs as a plug-in
inference replacement to overcome the limitation that the model cannot refine
tokens flexibly. This simple yet effective training-free strategy, what we
refer to as RCR, consistently improves performance and yields additional gains
when combined with MDPO. Our findings establish great potential for
investigating the discrepancy between pre-training and inference of MDLMs.
Code: https://github.com/autonomousvision/mdpo. Project Page:
https://cli212.github.io/MDPO/.

</details>
