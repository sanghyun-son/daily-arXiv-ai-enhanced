<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 156]
- [cs.CL](#cs.CL) [Total: 81]
- [cs.AI](#cs.AI) [Total: 55]
- [cs.DC](#cs.DC) [Total: 8]
- [cs.IR](#cs.IR) [Total: 15]
- [cs.LG](#cs.LG) [Total: 110]
- [cs.MA](#cs.MA) [Total: 5]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [A Deep Learning-Based CCTV System for Automatic Smoking Detection in Fire Exit Zones](https://arxiv.org/abs/2508.11696)
*Sami Sadat,Mohammad Irtiza Hossain,Junaid Ahmed Sifat,Suhail Haque Rafi,Md. Waseq Alauddin Alvi,Md. Khalilur Rhaman*

Main category: cs.CV

TL;DR: CCTV 비상구 주변의 흡연을 실시간 탐지하는 시스템을 제안. 데이터셋 8,124장(20 시나리오)과 2,708 저조도 샘플 포함. YOLOv8/YOLOv11/YOLOv12를 평가한 뒤 YOLOv8 기반 커스텀 모델을 개발. 제안 모델이 최상 성능(Recall 78.90%, mAP@0.5 83.70%)을 보였고 Jetson Xavier NX에서 52–97ms/inference로 실시간 처리가 가능함.


<details>
  <summary>Details</summary>
Motivation: 비상구·화재 취약 구역에서의 흡연은 심각한 안전 문제이므로 CCTV를 통한 자동 감지로 공공 안전과 규정 준수를 보장하려는 목적.

Method: 20개 시나리오에서 이미지 수집(저조도 포함), 세 가지 최신 YOLO 계열(8/11/12) 비교 평가, YOLOv8 기반으로 감지 성능 향상을 위한 구조적 추가 및 엣지 장치(멀티스레드)에서의 추론 속도 측정.

Result: 커스텀 모델이 다른 모델들보다 우수: Recall 78.90%, mAP@50 83.70%. Jetson Xavier NX에서 추론 지연 52–97ms로 시간 민감 작업에 적합.

Conclusion: 엣지 환경에서 실시간 흡연 감지에 실용적인 성능을 보이나, 데이터·평가·일반화 관련 세부 정보(데이터 분할, 클래스 불균형, 추가 메트릭 등) 제공이 필요함.

Abstract: A deep learning real-time smoking detection system for CCTV surveillance of
fire exit areas is proposed due to critical safety requirements. The dataset
contains 8,124 images from 20 different scenarios along with 2,708 raw samples
demonstrating low-light areas. We evaluated three advanced object detection
models: YOLOv8, YOLOv11, and YOLOv12, followed by development of a custom model
derived from YOLOv8 with added structures for challenging surveillance
contexts. The proposed model outperformed the others, achieving a recall of
78.90 percent and mAP at 50 of 83.70 percent, delivering optimal object
detection across varied environments. Performance evaluation on multiple edge
devices using multithreaded operations showed the Jetson Xavier NX processed
data at 52 to 97 milliseconds per inference, establishing its suitability for
time-sensitive operations. This system offers a robust and adaptable platform
for monitoring public safety and enabling automatic regulatory compliance.

</details>


### [2] [Separating Knowledge and Perception with Procedural Data](https://arxiv.org/abs/2508.11697)
*Adrián Rodríguez-Muñoz,Manel Baradad,Phillip Isola,Antonio Torralba*

Main category: cs.CV

TL;DR: 절차적 데이터만으로 학습한 표현 모델을 추가 학습 없이 ‘비주얼 메모리’(참조 이미지 임베딩 DB)를 통해 유사도, 분류, 제로샷 세분화 등에 적용하여 실데이터 기반 모델과 경쟁력 있는 성능을 달성한다. 성능 차이는 주로 같은 객체의 부분들이 절차적 모델에서 불일치한 임베딩을 갖는 현상에서 기인한다.


<details>
  <summary>Details</summary>
Motivation: 실세계 이미지에 대한 의존도를 없애 프라이버시·데이터 수집 비용 문제를 완화하고, 실데이터와 완전 분리된(컴파트멘탈화된) 모델로도 실용적 성능을 얻는 것을 목표로 함.

Method: 절차적(프로시저럴) 데이터만으로 임베딩 모델을 학습하고, 참조 이미지들의 임베딩을 저장한 비주얼 메모리를 구축한다. 다운스트림(유사도 검색, 분류, 세분화)에서는 추가 파인튜닝 없이 메모리 검색으로 예측을 수행하고, Places 등 실데이터 모델과 비교 실험을 수행함.

Result: NIGHTS 유사도에서 Places 대비 성능차 1% 내외, CUB200 및 Flowers102 미세분류에서는 각각 +8%·+15% 우수, ImageNet-1K 분류는 약 10% 이내, COCO 제로샷 세그먼테이션(R^2)은 실데이터 모델 대비 10% 내외 차이. 그러나 일부 성능 갭 존재.

Conclusion: 절차적 데이터 + 비주얼 메모리 조합으로 실데이터 없이도 강력한 일반화 성능을 보일 수 있으며, 남은 격차는 객체 부분 간 임베딩 일관성 문제를 개선하면 줄일 수 있다.

Abstract: We train representation models with procedural data only, and apply them on
visual similarity, classification, and semantic segmentation tasks without
further training by using visual memory -- an explicit database of reference
image embeddings. Unlike prior work on visual memory, our approach achieves
full compartmentalization with respect to all real-world images while retaining
strong performance. Compared to a model trained on Places, our procedural model
performs within $1\%$ on NIGHTS visual similarity, outperforms by $8\%$ and
$15\%$ on CUB200 and Flowers102 fine-grained classification, and is within
$10\%$ on ImageNet-1K classification. It also demonstrates strong zero-shot
segmentation, achieving an $R^2$ on COCO within $10\%$ of the models trained on
real data. Finally, we analyze procedural versus real data models, showing that
parts of the same object have dissimilar representations in procedural models,
resulting in incorrect searches in memory and explaining the remaining
performance gap.

</details>


### [3] [FusionFM: Fusing Eye-specific Foundational Models for Optimized Ophthalmic Diagnosis](https://arxiv.org/abs/2508.11721)
*Ke Zou,Jocelyn Hui Lin Goh,Yukun Zhou,Tian Lin,Samantha Min Er Yew,Sahana Srinivasan,Meng Wang,Rui Santos,Gabor M. Somfai,Huazhu Fu,Haoyu Chen,Pearse A. Keane,Ching-Yu Cheng,Yih Chung Tham*

Main category: cs.CV

TL;DR: 이 논문은 안과 분야의 파운데이션 모델(FM)들을 체계적으로 비교하고, 두 가지 모델 융합 방법을 제안해 성능을 평가한 최초의 연구다. DINORET과 RetiZero가 전반적으로 우수했으며, 게이팅 기반 융합은 일부 질환(녹내장, AMD, 고혈압) 예측에서 성능을 개선했다. 다만 외부 코호트에서의 전신 질환(특히 고혈압) 예측은 여전히 어렵다.


<details>
  <summary>Details</summary>
Motivation: 안과용 파운데이션 모델들이 다양하게 등장했지만, 어떤 모델이 우수한지, 과제별로 성능 차이가 있는지, 모델들을 융합하면 성능이 향상되는지에 대한 체계적 비교와 실험적 근거가 부족했다.

Method: FusionFM 평가 프레임워크를 제시하고, RETFound, VisionFM, RetiZero, DINORET 네 모델을 표준화된 다국가 데이터셋에서 녹내장, 당뇨망막병증, 나이관련 황반변성(안과 질환)과 당뇨, 고혈압(전신 질환) 예측 과제로 벤치마킹했다. 두 가지 융합 방법(논문에선 게이팅 기반 등으로 보임)을 도입해 단일 모델 대비 성능 변화를 평가했으며 AUC와 F1을 주요 지표로 사용했다.

Result: DINORET과 RetiZero가 전반적으로 우수했고, RetiZero가 외부 데이터에서 더 좋은 일반화 성능을 보였다. 게이팅 기반 융합은 녹내장, AMD, 고혈압 예측에서 일부 성능 향상을 가져왔으나 전신 질환(특히 외부 코호트에서의 고혈압) 예측은 여전히 낮은 성능을 보였다.

Conclusion: 안과용 파운데이션 모델의 성능 비교와 융합의 잠재적 혜택을 제시했으며, 외부 일반화와 전신 질환 예측 향상을 위한 추가 연구(데이터 다양성 확대, 모델 개선, 융합 전략 고도화)가 필요하다고 제안한다.

Abstract: Foundation models (FMs) have shown great promise in medical image analysis by
improving generalization across diverse downstream tasks. In ophthalmology,
several FMs have recently emerged, but there is still no clear answer to
fundamental questions: Which FM performs the best? Are they equally good across
different tasks? What if we combine all FMs together? To our knowledge, this is
the first study to systematically evaluate both single and fused ophthalmic
FMs. To address these questions, we propose FusionFM, a comprehensive
evaluation suite, along with two fusion approaches to integrate different
ophthalmic FMs. Our framework covers both ophthalmic disease detection
(glaucoma, diabetic retinopathy, and age-related macular degeneration) and
systemic disease prediction (diabetes and hypertension) based on retinal
imaging. We benchmarked four state-of-the-art FMs (RETFound, VisionFM,
RetiZero, and DINORET) using standardized datasets from multiple countries and
evaluated their performance using AUC and F1 metrics. Our results show that
DINORET and RetiZero achieve superior performance in both ophthalmic and
systemic disease tasks, with RetiZero exhibiting stronger generalization on
external datasets. Regarding fusion strategies, the Gating-based approach
provides modest improvements in predicting glaucoma, AMD, and hypertension.
Despite these advances, predicting systemic diseases, especially hypertension
in external cohort remains challenging. These findings provide an
evidence-based evaluation of ophthalmic FMs, highlight the benefits of model
fusion, and point to strategies for enhancing their clinical applicability.

</details>


### [4] [UniDCF: A Foundation Model for Comprehensive Dentocraniofacial Hard Tissue Reconstruction](https://arxiv.org/abs/2508.11728)
*Chunxia Ren,Ning Zhu,Yue Lai,Gui Chen,Ruijie Wang,Yangyi Hu,Suyao Liu,Shuwen Mao,Hong Su,Yu Zhang,Li Xiao*

Main category: cs.CV

TL;DR: UniDCF는 포인트클라우드와 다각도 이미지의 멀티모달 융합과 점수 기반 노이즈 제거를 결합해 치아·두개안면 경조직을 통합 재구성하는 프레임워크로, 대규모 멀티모달 데이터셋(6,609명, 54,555 인스턴스)을 통해 기존 기법보다 기하학적 정밀도·완성도·공간 정확도에서 우수하다고 주장함.


<details>
  <summary>Details</summary>
Motivation: 기존 딥러닝 기반 재구성 모델들이 단일 조직·단일 모달리티에만 최적화되어 일반화가 어렵고, 해부학적 충실도·계산 효율성·다중조직 적응성 사이에 트레이드오프가 존재함.

Method: 포인트클라우드와 다중 뷰 이미지를 융합하는 멀티모달 인코더를 설계하고, 표면 부드러움을 개선하기 위해 점수 기반 denoising 모듈을 도입하는 통합 프레임워크 UniDCF를 제시.

Result: 대규모 멀티모달 데이터셋에서 실험하여 기존 SOTA를 능가하는 기하학적 정밀도·구조적 완성도·공간 정확도를 달성했으며, 임상 시뮬레이션에서 설계 시간을 99% 단축하고 의사 수용도 94% 이상을 보고함.

Conclusion: UniDCF는 빠르고 자동화된 고충실도 치과·두개안면 경조직 재구성을 가능하게 하여 개인화된 복원치료와 임상 워크플로우 개선에 기여할 수 있다.

Abstract: Dentocraniofacial hard tissue defects profoundly affect patients'
physiological functions, facial aesthetics, and psychological well-being,
posing significant challenges for precise reconstruction. Current deep learning
models are limited to single-tissue scenarios and modality-specific imaging
inputs, resulting in poor generalizability and trade-offs between anatomical
fidelity, computational efficiency, and cross-tissue adaptability. Here we
introduce UniDCF, a unified framework capable of reconstructing multiple
dentocraniofacial hard tissues through multimodal fusion encoding of point
clouds and multi-view images. By leveraging the complementary strengths of each
modality and incorporating a score-based denoising module to refine surface
smoothness, UniDCF overcomes the limitations of prior single-modality
approaches. We curated the largest multimodal dataset, comprising intraoral
scans, CBCT, and CT from 6,609 patients, resulting in 54,555 annotated
instances. Evaluations demonstrate that UniDCF outperforms existing
state-of-the-art methods in terms of geometric precision, structural
completeness, and spatial accuracy. Clinical simulations indicate UniDCF
reduces reconstruction design time by 99% and achieves clinician-rated
acceptability exceeding 94%. Overall, UniDCF enables rapid, automated, and
high-fidelity reconstruction, supporting personalized and precise restorative
treatments, streamlining clinical workflows, and enhancing patient outcomes.

</details>


### [5] [Ovis2.5 Technical Report](https://arxiv.org/abs/2508.11737)
*Shiyin Lu,Yang Li,Yu Xia,Yuwei Hu,Shanshan Zhao,Yanqing Ma,Zhichao Wei,Yinglun Li,Lunhao Duan,Jianshan Zhao,Yuxuan Han,Haijun Li,Wanying Chen,Junke Tang,Chengkun Hou,Zhixing Du,Tianli Zhou,Wenjie Zhang,Huping Ding,Jiahe Li,Wen Li,Gui Hu,Yiliang Gu,Siran Yang,Jiamang Wang,Hailong Sun,Yibo Wang,Hui Sun,Jinlong Huang,Yuping He,Shengze Shi,Weihong Zhang,Guodong Zheng,Junpeng Jiang,Sensen Gao,Yi-Feng Wu,Sijia Chen,Yuhui Chen,Qing-Guo Chen,Zhao Xu,Weihua Luo,Kaifu Zhang*

Main category: cs.CV

TL;DR: Ovis2.5는 고해상도 원본 이미지를 변수 해상도로 그대로 처리하는 네이티브-해상도 비전 트랜스포머와 '반성(reflection)' 기반의 고급 추론 모드를 도입한 Ovis2의 후속 모델이다. 5단계 커리큘럼(시각·멀티모달 프리트레인 → 대규모 지시 튜닝 → 정렬·추론 강화(DPO·GRPO) 등)으로 학습되며, 멀티모달 데이터 패킹과 하이브리드 병렬화로 효율을 높였다. 공개된 두 버전(Ovis2.5-9B, Ovis2.5-2B)은 OpenCompass에서 각각 78.3 / 73.9를 기록하며 동일 규모 오픈 소스 MLLM에서 SOTA를 달성했다.


<details>
  <summary>Details</summary>
Motivation: 복잡한 차트나 시각적으로 밀집된 콘텐츠에서 고해상도 세부와 전역 레이아웃을 보존해야 하고, 단순한 연쇄적 체인오브소트(chain-of-thought)를 넘는 자기검사·수정 능력으로 추론 정확도를 높일 필요가 있어서 개발됨.

Method: (1) 네이티브-해상도 비전 트랜스포머로 입력 이미지를 고정 타일링 없이 변수 해상도로 처리하여 세부·전역 정보를 보존. (2) 반성(reflection) 기반의 '생각 모드'—자기검사와 수정이 가능한 선택적 추론 단계—도입. (3) 5단계 커리큘럼: 시각·멀티모달 프리트레인 → 대규모 지시 튜닝 → 정렬 및 추론 강화(DPO, GRPO 포함). (4) 멀티모달 데이터 패킹 + 하이브리드 병렬로 학습 효율 극대화. (5) 두 가지 모델 크기(9B, 2B) 공개.

Result: Ovis2.5-9B가 OpenCompass 평균 78.3으로 이전 Ovis2-8B 대비 큰 향상 및 40B 미만 오픈소스 MLLM 중 SOTA 달성. Ovis2.5-2B는 73.9로 동일 규모에서 SOTA. 특히 STEM 벤치마크, 그라운딩·비디오 과제, 복잡한 차트 분석에서 뛰어난 성능을 보임.

Conclusion: 네이티브 해상도 처리를 통한 시각적 세부 보존과 반성형 추론 모드로 멀티모달 이해·추론 역량을 크게 개선했다. 효율적 학습 파이프라인으로 확장성 확보, 2B 모델은 리소스 제약 환경(온-디바이스)에 적합한 '작지만 강한' 대안 제공.

Abstract: We present Ovis2.5, a successor to Ovis2 designed for native-resolution
visual perception and strong multimodal reasoning. Ovis2.5 integrates a
native-resolution vision transformer that processes images at their native,
variable resolutions, avoiding the degradation from fixed-resolution tiling and
preserving both fine detail and global layout -- crucial for visually dense
content like complex charts. To strengthen reasoning, we train the model to
move beyond linear chain-of-thought and perform reflection -- including
self-checking and revision. This advanced capability is exposed as an optional
"thinking mode" at inference time, allowing users to trade latency for enhanced
accuracy on difficult inputs. The model is trained via a comprehensive
five-phase curriculum that progressively builds its skills. The process begins
with foundational visual and multimodal pretraining, advances through
large-scale instruction tuning, and culminates in alignment and reasoning
enhancement using DPO and GRPO. To scale these upgrades efficiently, we employ
multimodal data packing and hybrid parallelism, yielding a significant
end-to-end speedup. We release two open-source models: Ovis2.5-9B and
Ovis2.5-2B. The latter continues the "small model, big performance" philosophy
of Ovis2, making it ideal for resource-constrained, on-device scenarios. On the
OpenCompass multimodal leaderboard, Ovis2.5-9B averages 78.3, marking a
substantial improvement over its predecessor, Ovis2-8B, and achieving
state-of-the-art results among open-source MLLMs in the sub-40B parameter
range; Ovis2.5-2B scores 73.9, establishing SOTA for its size. Beyond aggregate
scores, Ovis2.5 achieves leading results on STEM benchmarks, exhibits strong
capabilities on grounding and video tasks, and achieves open-source SOTA at its
scale for complex chart analysis.

</details>


### [6] [VideoAVE: A Multi-Attribute Video-to-Text Attribute Value Extraction Dataset and Benchmark Models](https://arxiv.org/abs/2508.11801)
*Ming Cheng,Tong Wu,Jiazhen Hu,Jiaying Gong,Hoda Eldardiry*

Main category: cs.CV

TL;DR: VideoAVE는 비디오-텍스트 전자상거래 속성-값 추출(AVE)을 위한 최초의 공개 데이터셋으로, 14개 도메인과 172개 속성, 22.4만 학습·2.5만 평가 샘플(정제 후)을 포함한다. CLIP 기반 Mixture-of-Experts 필터(CLiP-MoE)로 비디오-상품 불일치 샘플을 제거하고, 여러 최신 비디오 VLM을 벤치마크하여 문제의 난이도와 향후 연구 방향을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 기존 AVE 데이터셋은 텍스트-텍스트·이미지-텍스트 중심으로 비디오를 다루지 못하고, 속성 다양성과 공개 가용성이 부족하다. 비디오에서 시간적 정보를 이용한 속성값 추출을 위해 공개적이고 확장성 있는 데이터셋과 벤치마크가 필요하다.

Method: 웹에서 비디오-상품 쌍을 수집한 뒤, CLIP 기반 Mixture-of-Experts(클립-MoE) 후처리 필터링으로 불일치 쌍을 제거해 데이터 품질을 높임. 데이터셋(224k/25k)을 구성하고, 속성-조건(value prediction)과 오픈 속성-값 추출 두 과제로 여러 최첨단 비디오 VLM을 평가함.

Result: 정제된 대규모 VideoAVE 데이터셋 공개 및 다양한 VLM 실험 결과, 비디오-텍스트 AVE는 특히 오픈 설정에서 여전히 어려운 문제임이 확인됨. 시간 정보를 잘 활용하는 모델 개발 여지가 큼.

Conclusion: VideoAVE는 비디오 기반 AVE 연구를 촉진할 공개 리소스와 기준을 제공하며, 향후 시간적·다중모달 정보를 효과적으로 활용하는 VLM 설계가 필요함.

Abstract: Attribute Value Extraction (AVE) is important for structuring product
information in e-commerce. However, existing AVE datasets are primarily limited
to text-to-text or image-to-text settings, lacking support for product videos,
diverse attribute coverage, and public availability. To address these gaps, we
introduce VideoAVE, the first publicly available video-to-text e-commerce AVE
dataset across 14 different domains and covering 172 unique attributes. To
ensure data quality, we propose a post-hoc CLIP-based Mixture of Experts
filtering system (CLIP-MoE) to remove the mismatched video-product pairs,
resulting in a refined dataset of 224k training data and 25k evaluation data.
In order to evaluate the usability of the dataset, we further establish a
comprehensive benchmark by evaluating several state-of-the-art video vision
language models (VLMs) under both attribute-conditioned value prediction and
open attribute-value pair extraction tasks. Our results analysis reveals that
video-to-text AVE remains a challenging problem, particularly in open settings,
and there is still room for developing more advanced VLMs capable of leveraging
effective temporal information. The dataset and benchmark code for VideoAVE are
available at: https://github.com/gjiaying/VideoAVE

</details>


### [7] [An MLP Baseline for Handwriting Recognition Using Planar Curvature and Gradient Orientation](https://arxiv.org/abs/2508.11803)
*Azam Nouri*

Main category: cs.CV

TL;DR: 곡률(크기·부호)과 그래디언트 방향 한정의 3개 2차 기하학적 맵을 입력으로 한 MLP가 MNIST에서 97%, EMNIST 문자에서 89%의 성능을 보였다는 주장. CNN 대신 해석 가능한 수공 특징으로도 높은 인식률을 얻을 수 있음을 제시.


<details>
  <summary>Details</summary>
Motivation: CNN에 의존하지 않고, 해석 가능하고 계산적으로 단순한 2차 기하학적(곡률·방향) 수공 특징만으로도 필기문자 인식 성능을 달성할 수 있는지 검증하려는 목적.

Method: 입력으로 planar curvature magnitude, curvature sign, gradient orientation의 3개 특징 맵을 사용. 이 맵들을 다층퍼셉트론(MLP)에 공급하여 MNIST와 EMNIST에서 학습·평가. 구체적 아키텍처·하이퍼파라미터는 초록에 명시되지 않음.

Result: 제시한 모델이 MNIST 숫자에서 약 97% 정확도, EMNIST 문자에서 약 89% 정확도 달성. 곡률 기반 표현이 판별력이 높음을 주장.

Conclusion: 해석 가능한 수공 피처만으로도 딥러닝의 장점을 일부 재현할 수 있으며, 곡률·방향 기반 표현이 HCR에 유용하다는 결론을 제시.

Abstract: This study investigates whether second-order geometric cues - planar
curvature magnitude, curvature sign, and gradient orientation - are sufficient
on their own to drive a multilayer perceptron (MLP) classifier for handwritten
character recognition (HCR), offering an alternative to convolutional neural
networks (CNNs). Using these three handcrafted feature maps as inputs, our
curvature-orientation MLP achieves 97 percent accuracy on MNIST digits and 89
percent on EMNIST letters. These results underscore the discriminative power of
curvature-based representations for handwritten character images and
demonstrate that the advantages of deep learning can be realized even with
interpretable, hand-engineered features.

</details>


### [8] [Labels or Input? Rethinking Augmentation in Multimodal Hate Detection](https://arxiv.org/abs/2508.11808)
*Sahajpreet Singh,Rongxin Ouyang,Subhayan Mukerjee,Kokil Jaidka*

Main category: cs.CV

TL;DR: 시각·언어 모델의 프롬프트 설계와 표적적인 멀티모달 증강이 혐오 밈 검출 성능과 일반화에 큰 영향을 미친다. 구조화된 프롬프트와 레이블 스케일링은 소형 모델에서도 견고성을 높이고, InternVL2가 최상 성능을 냈다. 또한 2,479개의 반사실적(비혐오) 밈을 생성하는 LLM–VLM 멀티에이전트 증강 파이프라인은 스퓨리어스 상관관계를 줄이고 분류기 일반화를 개선한다.


<details>
  <summary>Details</summary>
Motivation: 웹상 멀티모달 콘텐츠 증가로 텍스트·이미지 상호작용을 통해 은밀하게 전달되는 혐오 표현을 효과적으로 탐지하는 것이 어려워짐. 기존 VLM들은 세밀한 지도학습을 지원하지 못하고 암묵적 혐오에 취약하다.

Method: (1) 프롬프트 최적화 프레임워크: 프롬프트 구조, 지도 레이블의 세분화(스케일링), 학습 모달리티를 체계적으로 변형해 성능 비교. (2) 멀티모달 데이터 증강: 멀티에이전트 LLM–VLM 시스템으로 혐오성을 유발하는 모달리티를 분리·재작성해 2,479개의 반사실적(중립) 밈 생성, 증강 데이터를 통해 학습시켜 스퓨리어스 상관 제거.

Result: 구조화된 프롬프트와 레이블 스케일링이 성능과 견고성에 유의미한 영향. InternVL2가 이진 및 스케일드 설정에서 최고 F1 점수 달성. 생성된 2,479개 반사실적 밈은 스퓨리어스 상관을 줄이고 분류기 일반화를 향상시킴.

Conclusion: 프롬프트 설계와 데이터 구성은 모델 크기만큼 중요하며, 표적적 멀티모달 증강은 보다 공정하고 문맥 민감한 혐오 검출을 지원할 수 있다. 합성 데이터 설계는 강건하고 신뢰할 수 있는 VLM 학습의 새로운 방향을 제시한다.

Abstract: The modern web is saturated with multimodal content, intensifying the
challenge of detecting hateful memes, where harmful intent is often conveyed
through subtle interactions between text and image under the guise of humor or
satire. While recent advances in Vision-Language Models (VLMs) show promise,
these models lack support for fine-grained supervision and remain susceptible
to implicit hate speech. In this paper, we present a dual-pronged approach to
improve multimodal hate detection. First, we propose a prompt optimization
framework that systematically varies prompt structure, supervision granularity,
and training modality. We show that prompt design and label scaling both
influence performance, with structured prompts improving robustness even in
small models, and InternVL2 achieving the best F1-scores across binary and
scaled settings. Second, we introduce a multimodal data augmentation pipeline
that generates 2,479 counterfactually neutral memes by isolating and rewriting
the hateful modality. This pipeline, powered by a multi-agent LLM-VLM setup,
successfully reduces spurious correlations and improves classifier
generalization. Our approaches inspire new directions for building synthetic
data to train robust and fair vision-language models. Our findings demonstrate
that prompt structure and data composition are as critical as model size, and
that targeted augmentation can support more trustworthy and context-sensitive
hate detection.

</details>


### [9] [Towards Understanding 3D Vision: the Role of Gaussian Curvature](https://arxiv.org/abs/2508.11825)
*Sherlon Almeida da Silva,Davi Geiger,Luiz Velho,Moacir Antonelli Ponti*

Main category: cs.CV

TL;DR: 이 논문은 3D 표면 모델링에서 가우시안 곡률(Gaussian curvature, GC)이 갖는 장점(관측자 불변성, 희소·압축적 표현)을 실증하고, Middlebury 스테레오 데이터셋을 이용해 GC가 기존 단안·스테레오 방법들에서 암묵적으로 반영되는지, 재구성 개선을 위한 기하학적 프라이어로서의 활용 가능성, 그리고 비지도적 평가 지표로의 잠재성을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 딥러닝 기반의 데이터 중심 3D 재구성 기법들은 성능이 빠르게 개선되었으나 명시적 기하학 모델을 제공하지 못해 해석·전이·제어가 어렵다. 관찰자 불변인 가우시안 곡률을 통해 명시적이고 해석 가능한 3D 표현을 얻고자 한다.

Method: Middlebury 스테레오 데이터셋에서 곡률을 계산·분석하여 GC의 분포와 희소성 검증, 기존 단안·스테레오 기법들이 GC와의 상관성을 암묵적으로 학습하는지 비교 실험, GC를 프라이어로 결합한 재구성 실험, GC 기반 비지도 평가 지표의 성능 평가를 수행한다.

Result: GC가 3D 표면을 희소하고 압축적으로 설명함을 보였고(주요 특징만 포착), 최첨단 단안·스테레오 방법들이 GC를 암묵적으로 고려하는 경향이 관찰되었으며, GC 기반 프라이어를 도입하면 재구성 품질이 향상되고 GC를 이용한 비지도 평가가 실용적임을 제시했다.

Conclusion: 가우시안 곡률은 관측자 불변의 유용한 기하학적 표현으로 3D 재구성의 프라이어, 분석 도구, 비지도 평가 지표로 활용될 잠재력이 크며, 향후 차별화된 곡률 추정 방법·연산적 효율화·다양한 데이터셋 검증이 필요하다.

Abstract: Recent advances in computer vision have predominantly relied on data-driven
approaches that leverage deep learning and large-scale datasets. Deep neural
networks have achieved remarkable success in tasks such as stereo matching and
monocular depth reconstruction. However, these methods lack explicit models of
3D geometry that can be directly analyzed, transferred across modalities, or
systematically modified for controlled experimentation. We investigate the role
of Gaussian curvature in 3D surface modeling. Besides Gaussian curvature being
an invariant quantity under change of observers or coordinate systems, we
demonstrate using the Middlebury stereo dataset that it offers: (i) a sparse
and compact description of 3D surfaces, (ii) state-of-the-art monocular and
stereo methods seem to implicitly consider it, but no explicit module of such
use can be extracted, (iii) a form of geometric prior that can inform and
improve 3D surface reconstruction, and (iv) a possible use as an unsupervised
metric for stereo methods.

</details>


### [10] [From Pixels to Graphs: Deep Graph-Level Anomaly Detection on Dermoscopic Images](https://arxiv.org/abs/2508.11826)
*Dehn Xu,Tim Katzke,Emmanuel Müller*

Main category: cs.CV

TL;DR: 피부 영상(dermoscopy)을 이미지→그래프 변환(분할·특징·간선) 방식별로 체계적으로 비교해 GNN 기반 그래프 수준 이상탐지(GLAD)에 적합한 변환 설계안을 제시함. 색상 단독으로 좋은 성능을 내고, 형태·텍스처를 추가하면 향상되며 비사전학습(Unsupervised)으로 AUC 0.805, 스파스 라벨로 0.872, 완전 감독으로 0.914를 기록함.


<details>
  <summary>Details</summary>
Motivation: 이미지 기반 이상탐지에 GNN을 적용할 때 다양한 이미지→그래프 변환 설계(분할 기법·간선 구성·노드 특징)가 존재하지만, 어떤 조합이 GLAD에 가장 적합한지 체계적 비교가 부족함.

Method: 여러 분할 스킴, 간선 구성 전략, 색상·텍스처·형태 기반 노드 특징 집합을 조합하여 이미지 유래 그래프 표현을 생성하고, SOTA GLAD 모델(예: OCGTL 등)으로 순수 비지도·약지도·완전지도 환경에서 성능 및 효율을 평가함.

Result: 색상 특징이 단독으로 가장 우수하며, 형태·텍스처 추가 시 일관된 성능 향상. 비지도 최고 AUC-ROC 0.805, 약지도(희소 라벨) 0.872, 완전지도 0.914 달성. 사전학습 백본 없이도 경쟁력 있는 결과.

Conclusion: 이미지→그래프 변환 설계가 GLAD 성능에 큰 영향을 미치며, 적절한 노드 특징 조합과 라벨 이용 수준에 따라 GNN 기반 접근이 실용적 대안이 될 수 있음.

Abstract: Graph Neural Networks (GNNs) have emerged as a powerful approach for
graph-based machine learning tasks. Previous work applied GNNs to image-derived
graph representations for various downstream tasks such as classification or
anomaly detection. These transformations include segmenting images, extracting
features from segments, mapping them to nodes, and connecting them. However, to
the best of our knowledge, no study has rigorously compared the effectiveness
of the numerous potential image-to-graph transformation approaches for
GNN-based graph-level anomaly detection (GLAD). In this study, we
systematically evaluate the efficacy of multiple segmentation schemes, edge
construction strategies, and node feature sets based on color, texture, and
shape descriptors to produce suitable image-derived graph representations to
perform graph-level anomaly detection. We conduct extensive experiments on
dermoscopic images using state-of-the-art GLAD models, examining performance
and efficiency in purely unsupervised, weakly supervised, and fully supervised
regimes. Our findings reveal, for example, that color descriptors contribute
the best standalone performance, while incorporating shape and texture features
consistently enhances detection efficacy. In particular, our best unsupervised
configuration using OCGTL achieves a competitive AUC-ROC score of up to 0.805
without relying on pretrained backbones like comparable image-based approaches.
With the inclusion of sparse labels, the performance increases substantially to
0.872 and with full supervision to 0.914 AUC-ROC.

</details>


### [11] [Recent Advances in Transformer and Large Language Models for UAV Applications](https://arxiv.org/abs/2508.11834)
*Hamza Kheddar,Yassine Habchi,Mohamed Chahine Ghanem,Mustapha Hemis,Dusit Niyato*

Main category: cs.CV

TL;DR: Transformer 기반 모델들이 UAV의 인식·결정·자율화 역량을 크게 향상시키며, 본 리뷰는 Transformer 아키텍처(어텐션, CNN-Transformer 하이브리드, RL-Transformer, LLM)를 통합 분류하고 응용 분야·데이터셋·시뮬레이터·성능 벤치마크·개선 과제를 정리한다. 계산 효율성과 실시간 배치가 주요 과제로 남아 있다.


<details>
  <summary>Details</summary>
Motivation: Transformer 기술의 빠른 발전이 UAV 시스템의 핵심 기능(센싱·계획·제어)에 미치는 영향이 커지고 있어, 분야별 분류·비교·공통 이슈를 체계적으로 정리해 연구자와 실무자를 안내할 필요가 있음.

Method: 문헌 조사와 체계적 분류를 통해 Transformer 기반 UAV 모델의 통합 분류 체계 수립, 어텐션 변형·하이브리드 모델·강화학습·LLM 적용 사례 정리, 데이터셋·시뮬레이터·평가 지표와 비교 표·성능 벤치마크 제공.

Result: 아키텍처별 분류와 적용 사례(정밀농업, 자율항법 등), 주요 데이터셋·시뮬레이터 목록, 성능 비교 테이블, 계산 비용·실시간성·데이터 편향 등 문헌상 공통 한계와 갭 도출.

Conclusion: Transformer 기반 UAV 연구의 전체 지도를 제공하여 향후 연구 방향(경량화·하드웨어 친화적 설계·시뮬레이션-실세계 전이·안전성·표준화된 벤치마크)을 제시하며, 실시간·에너지 제한 환경에서의 적용을 위한 추가 연구 필요성을 강조함.

Abstract: The rapid advancement of Transformer-based models has reshaped the landscape
of uncrewed aerial vehicle (UAV) systems by enhancing perception,
decision-making, and autonomy. This review paper systematically categorizes and
evaluates recent developments in Transformer architectures applied to UAVs,
including attention mechanisms, CNN-Transformer hybrids, reinforcement learning
Transformers, and large language models (LLMs). Unlike previous surveys, this
work presents a unified taxonomy of Transformer-based UAV models, highlights
emerging applications such as precision agriculture and autonomous navigation,
and provides comparative analyses through structured tables and performance
benchmarks. The paper also reviews key datasets, simulators, and evaluation
metrics used in the field. Furthermore, it identifies existing gaps in the
literature, outlines critical challenges in computational efficiency and
real-time deployment, and offers future research directions. This comprehensive
synthesis aims to guide researchers and practitioners in understanding and
advancing Transformer-driven UAV technologies.

</details>


### [12] [ComplicitSplat: Downstream Models are Vulnerable to Blackbox Attacks by 3D Gaussian Splat Camouflages](https://arxiv.org/abs/2508.11854)
*Matthew Hull,Haoyang Yang,Pratham Mehta,Mansi Phute,Aeree Cho,Haorang Wang,Matthew Lau,Wenke Lee,Wilian Lunardi,Martin Andreoni,Polo Chau*

Main category: cs.CV

TL;DR: ComplicitSplat은 3D Gaussian Splatting(3DGS)의 표준 음영(shading) 기법을 악용해 특정 시점에서만 보이는 시점-특이적 위장(색·질감)을 만들어 객체 탐지기를 속이는 최초의 블랙박스 공격이다. 모델 구조·가중치 접근 없이 다양한 탐지기와 실제/합성 환경에서 성공적으로 동작하며, 자율주행 등 안전중요 시스템에 새로운 위험을 제기한다.


<details>
  <summary>Details</summary>
Motivation: 3DGS가 정적 이미지로부터 효율적인 신시점 합성을 위해 빠르게 채택되는 가운데, 안전중요(task-critical) 응용에서 입력 이미지가 조작될 경우 발생하는 잠재적 피해를 규명하고자 함. 특히 3DGS의 시점 종속적 표현이 악용될 수 있다는 점에 주목.

Method: 3DGS의 표준 쉐이딩을 이용해 시점별로 색상·텍스처가 변하는 위장 패턴을 객체에 삽입하도록 최적화함. 공격은 블랙박스 설정으로, 대상 탐지기의 내부 구조나 가중치에 접근하지 않고도 특정 시점에서만 탐지 실패(또는 오탐지)를 유도하도록 설계됨. 실세계 물체 촬영과 합성 장면에서 다양한 단일-스테이지, 다중-스테이지, 트랜스포머 기반 탐지기를 대상으로 평가.

Result: 광범위한 실험에서 ComplicitSplat은 여러 인기 탐지기들에 대해 성공적으로 일반화된 공격 성능을 보였음(실제 촬영·합성 장면 모두). 시점 특이적 위장이 탐지 성공률을 크게 떨어뜨리고, 블랙박스 환경에서도 작동함을 입증함.

Conclusion: 3DGS를 이용한 신시점 합성 파이프라인이 새로운 공격 표면을 제공함을 보여주며, 자율주행·로보틱스 등 임무 중요 시스템에서의 안전성·강건성 확보를 위한 방어·검출 연구가 시급함을 제시함.

Abstract: As 3D Gaussian Splatting (3DGS) gains rapid adoption in safety-critical tasks
for efficient novel-view synthesis from static images, how might an adversary
tamper images to cause harm? We introduce ComplicitSplat, the first attack that
exploits standard 3DGS shading methods to create viewpoint-specific camouflage
- colors and textures that change with viewing angle - to embed adversarial
content in scene objects that are visible only from specific viewpoints and
without requiring access to model architecture or weights. Our extensive
experiments show that ComplicitSplat generalizes to successfully attack a
variety of popular detector - both single-stage, multi-stage, and
transformer-based models on both real-world capture of physical objects and
synthetic scenes. To our knowledge, this is the first black-box attack on
downstream object detectors using 3DGS, exposing a novel safety risk for
applications like autonomous navigation and other mission-critical robotic
systems.

</details>


### [13] [Impact of Clinical Image Quality on Efficient Foundation Model Finetuning](https://arxiv.org/abs/2508.11864)
*Yucheng Tang,Pawel Rajwa,Alexander Ng,Yipei Wang,Wen Yan,Natasha Thorley,Aqua Asif,Clare Allen,Louise Dickinson,Francesco Giganti,Shonit Punwani,Daniel C. Alexander,Veeru Kasivisvanathan,Yipeng Hu*

Main category: cs.CV

TL;DR: 프로스타트 MRI용 도메인 특화 파운데이션 모델(ProFound)에서 이미지 품질 분포가 파인튜닝의 라벨 효율성과 일반화에 큰 영향을 미친다. 고품질 이미지 비율이 충분하지 않으면 사전학습의 이점이 사라지고, 파인튜닝·배포 간 품질 불일치는 성능 저하를 초래한다.


<details>
  <summary>Details</summary>
Motivation: 라벨이 제한된 의료영상 환경에서 파운데이션 모델이 제공하는 데이터·계산 효율을 실제 임상 데이터(다양한 화질)를 대상으로 검증하고, 화질 변동이 파인튜닝 성능과 일반화에 미치는 영향을 규명하려는 목적.

Method: ProFound(전립선 MRI에 특화된 대규모 사전학습 모델)을 사용해 실험을 설계. 파인튜닝·평가 세트에서 고/저화질 이미지 비율을 체계적으로 변화시키며 자동 판독 보고서 생성·전립선암 검출 등 여러 다운스트림 작업에 대해 라벨 효율성과 일반화 성능을 측정. 사전학습 없이 학습한 모델과 비교해 이득을 평가.

Result: 파인튜닝과 테스트의 화질 분포 차이는 성능에 유의미한 영향을 미침. 파인튜닝 세트에 충분한 고품질 이미지가 포함되어야 사전학습의 이점이 유지되며, 화질비가 일치할 때는 적은 라벨만으로도 우수한 성능 달성. 그러나 고품질 데이터가 부족하면 사전학습 모델이 비사전학습 모델보다 우수하지 못함. 다운스트림 작업별로 품질 일치의 중요도는 상이함.

Conclusion: 파운데이션 모델의 라벨·계산 효율을 실제로 실현하려면 파인튜닝 데이터의 영상 품질을 계량하고 배포 환경과 품질 분포를 정렬해야 한다. 특정 다운스트림 작업에 맞춘 품질 기준과 데이터 선택·평가 전략 수립이 필요하다.

Abstract: Foundation models in medical imaging have shown promising label efficiency,
achieving high downstream performance with only a fraction of annotated data.
Here, we evaluate this in prostate multiparametric MRI using ProFound, a
domain-specific vision foundation model pretrained on large-scale prostate MRI
datasets. We investigate how variable image quality affects label-efficient
finetuning by measuring the generalisability of finetuned models. Experiments
systematically vary high-/low-quality image ratios in finetuning and evaluation
sets. Our findings indicate that image quality distribution and its
finetune-and-test mismatch significantly affect model performance. In
particular: a) Varying the ratio of high- to low-quality images between
finetuning and test sets leads to notable differences in downstream
performance; and b) The presence of sufficient high-quality images in the
finetuning set is critical for maintaining strong performance, whilst the
importance of matched finetuning and testing distribution varies between
different downstream tasks, such as automated radiology reporting and prostate
cancer detection.When quality ratios are consistent, finetuning needs far less
labeled data than training from scratch, but label efficiency depends on image
quality distribution. Without enough high-quality finetuning data, pretrained
models may fail to outperform those trained without pretraining. This
highlights the importance of assessing and aligning quality distributions
between finetuning and deployment, and the need for quality standards in
finetuning data for specific downstream tasks. Using ProFound, we show the
value of quantifying image quality in both finetuning and deployment to fully
realise the data and compute efficiency benefits of foundation models.

</details>


### [14] [AdaRing: Towards Ultra-Light Vision-Language Adaptation via Cross-Layer Tensor Ring Decomposition](https://arxiv.org/abs/2508.11870)
*Ying Huang,Yuanbin Man,Wenqi Jia,Zhengzhong Tu,Junzhou Huang,Miao Yin*

Main category: cs.CV

TL;DR: AdaRing은 텐서 링 분해(TRD)를 이용해 레이어 간 어댑터 중복을 제거하고 레이어-공유 텐서 코어와 레이어-특이 슬라이스로 어댑터를 표현한다. 다양한 랭크의 어댑터들이 협업하도록 일반화 인식 파인튜닝을 적용해 VLM을 평균 학습 파라미터 90% 절감으로 효율적·고성능으로 적응시킨다.


<details>
  <summary>Details</summary>
Motivation: 기존 어댑터 기반 파인튜닝은 각 레이어에 동종 어댑터를 삽입해 레이어 간 중복을 무시하므로 압축률과 표현력에 한계가 있다. 레이어 간 중복을 구조적으로 제거하고 표현 다양성을 확보해 VLM 적응을 더 경량화·효율화하려는 목적.

Method: 어댑터들을 텐서 수준의 저랭크성 가정하에 텐서 링 분해로 형식화하여 공통(레이어-공유) 텐서 코어와 레이어별 슬라이스로 분해한다. 여러 랭크를 가진 어댑터들을 도입하고 일반화 인식(Generalization-aware) 파인튜닝으로 이들 간 협업을 유도한다.

Result: 초록에 따르면 다양한 태스크에서 SOTA 성능을 달성하면서 평균 학습 파라미터를 90% 줄였음. 다만 초록만으로는 사용한 VLM 백본, 데이터셋, 비교 실험의 상세 수치·추가 비용(추론·학습 속도 등)은 불명.

Conclusion: AdaRing은 레이어 간 중복 제거와 랭크 기반 다양성 도입으로 어댑터의 압축-표현력 균형을 개선한 실용적 접근이다. 구현·평가 세부정보 확인과 실제 오버헤드(메모리·계산) 검증이 필요하다.

Abstract: Adapter-based fine-tuning has gained remarkable attention in adapting large
pre-trained vision language models (VLMs) for a wide range of downstream tasks
efficiently. In this paradigm, only the inserted adapters are fine-tuned,
without the need for training the original VLM backbone. Existing works scale
adapters by integrating them into every layer of VLMs to increase the capacity
of adapters. However, these methods face two primary limitations: 1) limited
compression rate due to ignoring cross-layer redundancy, and 2) limited
representational capacity across homogeneous adapters. In this paper, we
propose a novel vision-language fine-tuning framework based on cross-layer
tensor ring decomposition (TRD) with the integration and collaboration of
diverse adapters, called AdaRing, achieving ultra-light parameter-efficient
adaptation of VLMs on various tasks. To remove the high redundancy that exists
among adapters across layers, we exploit the tensor-level low-rankness to
formulate adapters as layer-shared tensor cores and layer-specific slices.
Moreover, guided by generalization-aware fine-tuning, diverse rank-driven
adapters cooperate to handle tasks that require different representations. Our
experiments show that the proposed AdaRing achieves the state-of-the-art
performance while reducing average training parameters by 90%.

</details>


### [15] [EVTP-IVS: Effective Visual Token Pruning For Unifying Instruction Visual Segmentation In Multi-Modal Large Language Models](https://arxiv.org/abs/2508.11886)
*Wenhui Zhu,Xiwen Chen,Zhipeng Wang,Shao Tang,Sayan Ghosh,Xuanzhao Dong,Rajat Koner,Yalin Wang*

Main category: cs.CV

TL;DR: IVS(지시 기반 시각 분할)에서 시각 토큰 샘플링과 분할 성능의 상관관계를 보여주고, 공간 정보를 통합한 k-center 기반의 토큰 프루닝 기법 EVTP-IV를 제안해 20% 토큰으로도 이미지에서 3.5배, 비디오에서 5배까지 추론 속도를 높이면서 정확도를 유지함.


<details>
  <summary>Details</summary>
Motivation: 멀티모달 LLM이 IVS 성능은 우수하지만, 특히 비디오에서 추론 비용이 매우 높아 실제 적용이 어렵다. 일부 토큰만 사용해도 성능을 유지할 수 있다는 관찰에서 출발.

Method: 토큰 커버리지와 성능의 상관관계를 실험적으로 분석한 뒤, k-center 알고리즘을 확장하여 공간 정보를 통합한 토큰 선택(프루닝) 방법 EVTP-IV를 설계. 정보이론적 분석으로 설계 근거를 제시.

Result: 표준 IVS 벤치마크에서 토큰의 20%만 사용해도 이미지에서 최대 3.5×, 비디오에서 최대 5×의 속도 향상을 달성. 다양한 프루닝 비율에서 기존 프루닝 방법들보다 일관되게 우수한 성능을 보임.

Conclusion: 공간적으로 대표성 있는 소수의 비주얼 토큰만으로도 MLLM 기반 IVS의 효율을 크게 개선할 수 있으며, EVTP-IV는 실용적인 속도-정확도 균형을 제공한다.

Abstract: Instructed Visual Segmentation (IVS) tasks require segmenting objects in
images or videos based on natural language instructions. While recent
multimodal large language models (MLLMs) have achieved strong performance on
IVS, their inference cost remains a major bottleneck, particularly in video. We
empirically analyze visual token sampling in MLLMs and observe a strong
correlation between subset token coverage and segmentation performance. This
motivates our design of a simple and effective token pruning method that
selects a compact yet spatially representative subset of tokens to accelerate
inference. In this paper, we introduce a novel visual token pruning method for
IVS, called EVTP-IV, which builds upon the k-center by integrating spatial
information to ensure better coverage. We further provide an
information-theoretic analysis to support our design. Experiments on standard
IVS benchmarks show that our method achieves up to 5X speed-up on video tasks
and 3.5X on image tasks, while maintaining comparable accuracy using only 20%
of the tokens. Our method also consistently outperforms state-of-the-art
pruning baselines under varying pruning ratios.

</details>


### [16] [MOON: Generative MLLM-based Multimodal Representation Learning for E-commerce Product Understanding](https://arxiv.org/abs/2508.11999)
*Daoze Zhang,Zhanheng Nie,Jianyu Liu,Chenghan Fu,Wanxian Guan,Yuan Gao,Jun Song,Pengjie Wang,Jian Xu,Bo Zheng*

Main category: cs.CV

TL;DR: 생성형 MLLM 기반의 제품 표현 학습 모델 MOON을 제안. guided MoE로 멀티모달·측면(aspect) 특화 모델링, 핵심 영역 검출로 배경노이즈 제거, 어려운 음성 샘플링으로 대조학습 강화. 대규모 제품 벤치마크 MBE 공개, 다양한 다운스트림에서 제로샷으로 경쟁력 보임.


<details>
  <summary>Details</summary>
Motivation: 기존의 판별형(dual-flow) 아키텍처는 여러 이미지와 텍스트가 many-to-one 정렬되는 제품 데이터 특성을 잘 모델링하지 못함. 생성형 MLLM이 더 일반적 표현 학습에 유리하다고 보고 이를 제품 이해에 적용하려는 동기.

Method: (1) guided Mixture-of-Experts(MoE) 모듈로 멀티모달·측면별 콘텐츠를 표적 모델링, (2) 이미지 내 핵심 의미 영역을 검출해 배경 노이즈 제거, (3) 특수 음성(negative) 샘플링 전략으로 음성의 난이도·다양성 증대. 생성형 MLLM 프레임에 이들 모듈을 결합.

Result: 자체 공개한 대규모 MBE 벤치마크와 공개 데이터셋에서 제로샷으로 경쟁력 있는 성능을 보임. 교차모달 검색, 제품 분류, 속성 예측 등 다양한 태스크에서 일반화 능력 확인. 케이스 스터디와 시각화로 효과성 보조.

Conclusion: 생성형 MLLM에 guided MoE, 핵심 영역 검출, 어려운 음성 샘플링을 더해 제품 표현 학습을 개선했으며, 벤치마크 공개로 다양한 태스크에서 강한 제로샷 일반화 성능을 입증했다.

Abstract: With the rapid advancement of e-commerce, exploring general representations
rather than task-specific ones has attracted increasing research attention. For
product understanding, although existing discriminative dual-flow architectures
drive progress in this field, they inherently struggle to model the many-to-one
alignment between multiple images and texts of products. Therefore, we argue
that generative Multimodal Large Language Models (MLLMs) hold significant
potential for improving product representation learning. Nevertheless,
achieving this goal still remains non-trivial due to several key challenges:
the lack of multimodal and aspect-aware modeling modules in typical LLMs; the
common presence of background noise in product images; and the absence of a
standard benchmark for evaluation. To address these issues, we propose the
first generative MLLM-based model named MOON for product representation
learning. Our method (1) employs a guided Mixture-of-Experts (MoE) module for
targeted modeling of multimodal and aspect-specific product content; (2)
effectively detects core semantic regions in product images to mitigate the
distraction and interference caused by background noise; and (3) introduces the
specialized negative sampling strategy to increase the difficulty and diversity
of negative samples. In addition, we release a large-scale multimodal benchmark
MBE for various product understanding tasks. Experimentally, our model
demonstrates competitive zero-shot performance on both our benchmark and the
public dataset, showcasing strong generalization across various downstream
tasks, including cross-modal retrieval, product classification, and attribute
prediction. Furthermore, the case study and visualization illustrate the
effectiveness of MOON for product understanding.

</details>


### [17] [Large Kernel Modulation Network for Efficient Image Super-Resolution](https://arxiv.org/abs/2508.11893)
*Quanwei Hu,Yinggan Tang,Xuguang Zhang*

Main category: cs.CV

TL;DR: LKMN은 순수 CNN 기반의 경량 이미지 초해상화 모델로, 부분 대형 커널 스트립 합성곱과 크로스-게이트 FFN을 통해 비지역 특성 캡처와 낮은 지연시간을 동시에 달성한다.


<details>
  <summary>Details</summary>
Motivation: 제한된 자원 환경에서 초해상화 모델은 성능(화질)과 추론 지연시간 사이에서 균형을 맞춰야 한다. 기존 CNN은 지연시간은 낮지만 비지역 정보 모델링이 부족하고, Transformer는 비지역 모델링에 강하지만 추론이 느리다. 이러한 트레이드오프를 해결하려는 동기가 있다.

Method: 제안한 LKMN은 두 가지 핵심 모듈로 구성된다. (1) Enhanced Partial Large Kernel Block(EPLKB): 채널 셔플로 채널 간 상호작용을 증대하고 채널 어텐션으로 중요한 정보를 강조하며, 일부 채널에만 대형 커널 스트립 합성곱을 적용해 비지역 특성을 복잡도 낮게 추출한다. (2) Cross-Gate Feed-Forward Network(CGFN): 입력, 로컬, 비지역 특성 간 불일치를 학습 가능한 스케일링으로 보정한 뒤 크로스-게이트 방식으로 특성을 조절·융합하여 상호 보완성을 향상시킨다.

Result: 광범위한 실험에서 기존 경량 SR SOTA를 능가한다고 보고된다. 예: LKMN-L은 Manga109 데이터셋의 4× 업스케일에서 DAT-light 대비 PSNR 0.23 dB 향상, 추론 속도는 약 4.8배 빠름. 코드와 추가 자료는 공개됨.

Conclusion: LKMN은 순수 CNN 구조로 대형 커널 기반의 비지역 모델링과 낮은 추론 지연시간을 양립시켜 경량 SR에서 좋은 품질·효율 균형을 달성한다. 코드가 공개되어 재현성과 확장성이 확보되었다.

Abstract: Image super-resolution (SR) in resource-constrained scenarios demands
lightweight models balancing performance and latency. Convolutional neural
networks (CNNs) offer low latency but lack non-local feature capture, while
Transformers excel at non-local modeling yet suffer slow inference. To address
this trade-off, we propose the Large Kernel Modulation Network (LKMN), a pure
CNN-based model. LKMN has two core components: Enhanced Partial Large Kernel
Block (EPLKB) and Cross-Gate Feed-Forward Network (CGFN). The EPLKB utilizes
channel shuffle to boost inter-channel interaction, incorporates channel
attention to focus on key information, and applies large kernel strip
convolutions on partial channels for non-local feature extraction with reduced
complexity. The CGFN dynamically adjusts discrepancies between input, local,
and non-local features via a learnable scaling factor, then employs a
cross-gate strategy to modulate and fuse these features, enhancing their
complementarity. Extensive experiments demonstrate that our method outperforms
existing state-of-the-art (SOTA) lightweight SR models while balancing quality
and efficiency. Specifically, LKMN-L achieves 0.23 dB PSNR improvement over
DAT-light on the Manga109 dataset at $\times$4 upscale, with nearly $\times$4.8
times faster. Codes are in the supplementary materials. The code is available
at https://github.com/Supereeeee/LKMN.

</details>


### [18] [A Sobel-Gradient MLP Baseline for Handwritten Character Recognition](https://arxiv.org/abs/2508.11902)
*Azam Nouri*

Main category: cs.CV

TL;DR: Sobel 엣지(수평·수직 기울기)만을 입력으로 한 완전연결 MLP가 MNIST 98%, EMNIST Letters 92%를 달성해, 1차 기울기 정보만으로도 손글씨 인식의 핵심 정보를 많이 포착함을 보였다.


<details>
  <summary>Details</summary>
Motivation: CNN의 복잡성·메모리 비용에 비해 더 단순하고 해석 가능한 대안을 찾기 위해, 1차 엣지(소벨)만으로도 MLP가 경쟁력 있는 성능을 낼 수 있는지 확인하려는 의도.

Method: 원본 이미지 대신 수평·수직 소벨 도함수를 입력 채널로 사용해 모든 층이 전결합인 MLP를 학습. 데이터셋은 MNIST와 EMNIST Letters를 사용해 성능을 평가.

Result: 매우 간단한 입력과 모델 구조에도 MNIST에서 98% 정확도, EMNIST Letters에서 92% 정확도 달성. CNN에 근접하는 성능과 더 작은 메모리 풋프린트, 투명한(해석 가능한) 특징을 확보.

Conclusion: 손글씨 이미지의 클래스 판별 정보 중 많은 부분이 1차 기울기(엣지)에 이미 포함되어 있으며, 엣지 기반 MLP는 HCR(손글씨 인식)에 실용적이고 매력적인 대안이 될 수 있다.

Abstract: We revisit the classical Sobel operator to ask a simple question: Are
first-order edge maps sufficient to drive an all-dense multilayer perceptron
(MLP) for handwritten character recognition (HCR), as an alternative to
convolutional neural networks (CNNs)? Using only horizontal and vertical Sobel
derivatives as input, we train an MLP on MNIST and EMNIST Letters. Despite its
extreme simplicity, the resulting network reaches 98% accuracy on MNIST digits
and 92% on EMNIST letters -- approaching CNNs while offering a smaller memory
footprint and transparent features. Our findings highlight that much of the
class-discriminative information in handwritten character images is already
captured by first-order gradients, making edge-aware MLPs a compelling option
for HCR.

</details>


### [19] [OVG-HQ: Online Video Grounding with Hybrid-modal Queries](https://arxiv.org/abs/2508.11903)
*Runhao Zeng,Jiaqi Mao,Minghao Lai,Minh Hieu Phan,Yanjie Dong,Wei Wang,Qi Chen,Xiping Hu*

Main category: cs.CV

TL;DR: OVG-HQ는 스트리밍 환경과 시각적 쿼리를 지원하는 새로운 온라인 비디오 그라운딩 과제다. PMB(Parametric Memory Block)와 교차-모달 지식 증류로 제한된 컨텍스트와 모달리티 불균형을 해결하고, QVHighlights-Unify 데이터셋과 온라인 평가 지표(oR@n, IoU=m, omAP)를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기존 VG는 오프라인 전제(전체 비디오 접근)와 텍스트 쿼리 중심이라 스트리밍(온라인) 처리와 이미지/비디오 기반 쿼리 같은 하이브리드 모달리티를 다루지 못한다. 실시간성·다중모달 쿼리 대응이 필요한 응용(예: 실시간 탐색, 인터랙티브 검색)에 대응하기 위해.

Method: OVG-HQ-Unify라는 단일 모델 프레임워크를 제시. (1) Parametric Memory Block(PMB): 이전에 본 정보를 파라메트릭 메모리로 유지해 현재의 온라인 예측을 보조. (2) 교차-모달 지식 증류: 우세한(지배적) 모달리티에서 비우세 모달리티로 지식을 전달해 학습 불균형을 완화. 단일 모델로 텍스트·이미지·비디오 세 가지 쿼리 및 조합 처리.

Result: QVHighlights-Unify라는 멀티모달 쿼리 데이터셋 구축. 온라인 평가 지표(oR@n, IoU=m, omAP) 제안. 실험에서 OVG-HQ-Unify가 기존 모델들을 능가해 온라인·하이브리드 모달리티 상황에서 견고한 성능을 보임.

Conclusion: 제안된 프레임워크와 지표, 데이터셋은 온라인·하이브리드 쿼리 비디오 그라운딩 문제를 효과적으로 해결하며, 단일 모델로 다양한 쿼리 모달리티를 처리할 수 있음을 입증한다.

Abstract: Video grounding (VG) task focuses on locating specific moments in a video
based on a query, usually in text form. However, traditional VG struggles with
some scenarios like streaming video or queries using visual cues. To fill this
gap, we present a new task named Online Video Grounding with Hybrid-modal
Queries (OVG-HQ), which enables online segment localization using text, images,
video segments, and their combinations. This task poses two new challenges:
limited context in online settings and modality imbalance during training,
where dominant modalities overshadow weaker ones. To address these, we propose
OVG-HQ-Unify, a unified framework featuring a Parametric Memory Block (PMB)
that retain previously learned knowledge to enhance current decision and a
cross-modal distillation strategy that guides the learning of non-dominant
modalities. This design enables a single model to effectively handle
hybrid-modal queries. Due to the lack of suitable datasets, we construct
QVHighlights-Unify, an expanded dataset with multi-modal queries. Besides,
since offline metrics overlook prediction timeliness, we adapt them to the
online setting, introducing oR@n, IoU=m, and online mean Average Precision
(omAP) to evaluate both accuracy and efficiency. Experiments show that our
OVG-HQ-Unify outperforms existing models, offering a robust solution for
online, hybrid-modal video grounding. Source code and datasets are available at
https://github.com/maojiaqi2324/OVG-HQ.

</details>


### [20] [SafeCtrl: Region-Based Safety Control for Text-to-Image Diffusion via Detect-Then-Suppress](https://arxiv.org/abs/2508.11904)
*Lingyun Zhang,Yu Xie,Yanwei Fu,Ping Chen*

Main category: cs.CV

TL;DR: SafeCtrl는 텍스트→이미지 모델의 유해 콘텐츠를 먼저 정확히 지역화하고(hard replace 대신) 해당 의미를 ‘억제’하여 생성 과정이 자연스럽고 문맥적으로 일관된 안전한 대안으로 수렴하게 만드는 경량 플러그인이다. Direct Preference Optimization(DPO)를 이용해 이미지 수준의 선호 데이터로 학습하므로 픽셀 레벨 주석이 필요 없다. 실험에서 안전성과 충실도 모두에서 기존 방법들을 능가함.


<details>
  <summary>Details</summary>
Motivation: 텍스트-투-이미지 모델은 유해한 이미지를 생성할 위험이 크다. 기존 안전화 기법(프롬프트 재작성, 모델 파인튜닝 등)은 종종 안전성과 충실도 간의 트레이드오프를 만들며, 지역화 기반의 개념 치환 방식은 의미적 불일치(semantic incongruity)를 초래할 수 있다. 따라서 더 유연하고 문맥에 맞는 제어 방식이 필요하다.

Method: SafeCtrl은 두 단계 접근: (1) 유해 콘텐츠의 정확한 지역화(localization). (2) 하드 A→B 치환 대신 ‘억제(suppression)’를 적용하여 유해 의미를 약화하고 생성기가 자연스럽게 대체 표현을 생성하도록 유도. 학습은 DPO를 통해 이미지 수준 선호 데이터로 수행되어, 세밀한 억제 행동을 학습하고 지역 가이드 개입을 통해 추론 시 적용한다. 플러그인은 경량·비침습적 설계.

Result: 대규모 실험에서 SafeCtrl은 안전성(유해 이미지 생성 차단)과 충실도(원래 프롬프트의 의도 유지) 측면에서 최신 기법들을 유의하게 능가했다는 보고. 픽셀 수준 주석이 불필요하므로 비용·확장성 측면에서도 유리함.

Conclusion: 지역화 후 억제(suppress) 기반의 분리된 제어 전략은 텍스트-투-이미지 모델을 보다 책임감 있게 만드는 데 효과적이며, DPO와 이미지 수준 선호 데이터의 결합은 실용적이고 확장 가능한 접근임을 시사한다.

Abstract: The widespread deployment of text-to-image models is challenged by their
potential to generate harmful content. While existing safety methods, such as
prompt rewriting or model fine-tuning, provide valuable interventions, they
often introduce a trade-off between safety and fidelity. Recent
localization-based approaches have shown promise, yet their reliance on
explicit ``concept replacement" can sometimes lead to semantic incongruity. To
address these limitations, we explore a more flexible detect-then-suppress
paradigm. We introduce SafeCtrl, a lightweight, non-intrusive plugin that first
precisely localizes unsafe content. Instead of performing a hard A-to-B
substitution, SafeCtrl then suppresses the harmful semantics, allowing the
generative process to naturally and coherently resolve into a safe,
context-aware alternative. A key aspect of our work is a novel training
strategy using Direct Preference Optimization (DPO). We leverage readily
available, image-level preference data to train our module, enabling it to
learn nuanced suppression behaviors and perform region-guided interventions at
inference without requiring costly, pixel-level annotations. Extensive
experiments show that SafeCtrl significantly outperforms state-of-the-art
methods in both safety efficacy and fidelity preservation. Our findings suggest
that decoupled, suppression-based control is a highly effective and scalable
direction for building more responsible generative models.

</details>


### [21] [TimeSenCLIP: A Vision-Language Model for Remote Sensing Using Single-Pixel Time Series](https://arxiv.org/abs/2508.11919)
*Pallavi Jain,Diego Marcos,Dino Ienco,Roberto Interdonato,Tristan Berchoux*

Main category: cs.CV

TL;DR: TimeSenCLIP은 대형 공간 패치 대신 단일 픽셀의 시계열·스펙트럴 정보를 활용하고 지상 사진과의 크로스뷰 학습으로 캡션 없이도 위성·지상 시멘틱 정렬을 달성해 LULC 분류를 경량화한 모델이다.


<details>
  <summary>Details</summary>
Motivation: 기존 비전-언어 기반 원격탐사 방법들은 큰 공간 타일과 텍스트 레이블(캡션)에 의존해 계산 비용이 크고 텍스트 감독이 부족한 환경에서 실용성이 떨어진다. 저자들은 공간 컨텍스트의 중요성을 재평가하고 동일 픽셀의 시간·스펙트럼 정보를 통해 의미 있는 분류가 가능한지 검증하려 한다.

Method: Sentinel-2의 스펙트럴 밴드와 시계열을 단일 픽셀 입력으로 사용하고, 지오태그된 지상 사진과의 크로스뷰 학습(텍스트 캡션 의존 최소화)을 통해 오버헤드-지상 표현의 시맨틱 정렬을 학습한다. LUCAS·Sen4Map 데이터셋을 학습·평가에 사용해 LULC, 작물 유형, 생태계 유형 분류 성능을 측정한다.

Result: 단일 픽셀＋시계열·스펙트럴 정보만으로도 LULC·작물·생태계 분류에서 경쟁력 있는 성능을 보이며, 계산 효율성과 확장성 측면에서 이점이 있음을 보고한다. 코드 공개.

Conclusion: 시공간적 맥락(특히 시계열·스펙트럼)을 활용하면 공간 패치 의존도를 낮추고 텍스트 감독 없이도 실용적인 대규모 주제 지도(mapping)가 가능하다.

Abstract: Vision-language models have shown significant promise in remote sensing
applications, particularly for land-use and land-cover (LULC) via zero-shot
classification and retrieval. However, current approaches face two key
challenges: reliance on large spatial tiles that increase computational cost,
and dependence on text-based supervision, which is often not readily available.
In this work, we present TimeSenCLIP, a lightweight framework that reevaluate
the role of spatial context by evaluating the effectiveness of a single pixel
by leveraging its temporal and spectral dimensions, for classifying LULC and
ecosystem types. By leveraging spectral and temporal information from
Sentinel-2 imagery and cross-view learning with geo-tagged ground-level photos,
we minimises the need for caption-based training while preserving semantic
alignment between overhead (satellite) and ground perspectives. Our approach is
grounded in the LUCAS and Sen4Map datasets, and evaluated on classification
tasks including LULC, crop type, and ecosystem type. We demonstrate that single
pixel inputs, when combined with temporal and spectral cues, are sufficient for
thematic mapping, offering a scalable and efficient alternative for large-scale
remote sensing applications. Code is available at
https://github.com/pallavijain-pj/TimeSenCLIP

</details>


### [22] [Assessment of Using Synthetic Data in Brain Tumor Segmentation](https://arxiv.org/abs/2508.11922)
*Aditi Jahagirdar,Sameer Joshi*

Main category: cs.CV

TL;DR: GAN으로 생성한 합성 MRI를 U-Net 학습에 혼합한 탐색 연구. 정량적 지표는 실데이터 단독과 대체로 유사했지만, 40% 실 + 60% 합성 혼합에서 전체 종양 경계(WT) 표현이 질적으로 개선됨. 핵심(CT) 및 강화종양(ET) 영역 성능은 여전히 낮아 클래스 불균형 문제는 잔존.


<details>
  <summary>Details</summary>
Motivation: 뇌종양 MRI 분할은 종양 이질성, 주석 데이터 부족, 클래스 불균형 때문에 어렵다. 합성 데이터를 통해 데이터 다양성을 늘리고 분할 성능을 향상시킬 가능성을 타진하려 함.

Method: BraTS 2020 실데이터와 medigan으로 생성한 GAN 합성 MRI를 사용. U-Net을 실데이터만, 합성만, 다양한 비율(실:합성) 혼합 데이터로 학습. 평가 지표로 Dice, IoU, precision, recall, accuracy를 사용하고 정성적 시각검사 수행.

Result: 정량적 성능은 실데이터 단독과 혼합 학습 모델이 대체로 비슷함. 정성적 관찰에서는 40% 실 + 60% 합성이 전체 종양 경계 표현을 개선했으나 종양 핵심 및 강화영역의 영역별 정확도는 낮게 유지됨.

Conclusion: 합성 데이터는 뇌종양 분할에서 데이터 보강 전략으로 가능성이 있으나, 대규모 실험, 볼륨 일관성(3D), 클래스 불균형 해소 등 추가 연구가 필요하다.

Abstract: Manual brain tumor segmentation from MRI scans is challenging due to tumor
heterogeneity, scarcity of annotated data, and class imbalance in medical
imaging datasets. Synthetic data generated by generative models has the
potential to mitigate these issues by improving dataset diversity. This study
investigates, as a proof of concept, the impact of incorporating synthetic MRI
data, generated using a pre-trained GAN model, into training a U-Net
segmentation network. Experiments were conducted using real data from the BraTS
2020 dataset, synthetic data generated with the medigan library, and hybrid
datasets combining real and synthetic samples in varying proportions. While
overall quantitative performance (Dice coefficient, IoU, precision, recall,
accuracy) was comparable between real-only and hybrid-trained models,
qualitative inspection suggested that hybrid datasets, particularly with 40%
real and 60% synthetic data, improved whole tumor boundary delineation.
However, region-wise accuracy for the tumor core and the enhancing tumor
remained lower, indicating a persistent class imbalance. The findings support
the feasibility of synthetic data as an augmentation strategy for brain tumor
segmentation, while highlighting the need for larger-scale experiments,
volumetric data consistency, and mitigating class imbalance in future work.

</details>


### [23] [Deep Learning For Point Cloud Denoising: A Survey](https://arxiv.org/abs/2508.11932)
*Chengwei Zhang,Xueyi Zhang,Mingrui Lao,Tao Jiang,Xinhao Xu,Wenjie Li,Fubo Zhang,Longyong Chen*

Main category: cs.CV

TL;DR: 저 논문은 딥러닝 기반 점군 잡음 제거(PCD)를 체계적으로 정리한 서베이로, PCD를 이상치 제거(outlier removal)와 표면 잡음 복원(surface noise restoration)의 두 단계로 정식화하고 기존 연구들을 분류·비교하며 한계와 향후 연구방향을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 실세계 점군은 다양한 형태와 강도의 잡음을 가지며, DL 기반 모델이 전통 기법을 능가했음에도 DL-기반 PCD의 발전을 총괄한 종합적 서베이가 부족해 이를 보완하려는 목적.

Method: 문헌 분석을 통해 DL-기반 PCD를 두 단계(이상치 제거·표면 복원)로 재정의하고, 이에 맞춘 분류법(taxonomy)을 제안해 각 접근법의 기여·유사점·차이점·장단점을 정리·비교함.

Result: PCD에 적용되는 주요 모델군(네트워크 구조, 손실함수, 데이터·증강·평가 지표 등)을 체계적으로 분류·요약하고, 각 방법이 해결하는 문제와 한계, 성능 차이를 정리한 통찰을 제공함.

Conclusion: 제안된 분류체계와 비교 분석을 통해 연구의 공백(예: 실세계 잡음 시나리오, 표준화된 평가, 계산 효율성 등)을 도출하고, 향후 데이터·모델·평가 측면의 연구 방향을 제시한다.

Abstract: Real-world environment-derived point clouds invariably exhibit noise across
varying modalities and intensities. Hence, point cloud denoising (PCD) is
essential as a preprocessing step to improve downstream task performance. Deep
learning (DL)-based PCD models, known for their strong representation
capabilities and flexible architectures, have surpassed traditional methods in
denoising performance. To our best knowledge, despite recent advances in
performance, no comprehensive survey systematically summarizes the developments
of DL-based PCD. To fill the gap, this paper seeks to identify key challenges
in DL-based PCD, summarizes the main contributions of existing methods, and
proposes a taxonomy tailored to denoising tasks. To achieve this goal, we
formulate PCD as a two-step process: outlier removal and surface noise
restoration, encompassing most scenarios and requirements of PCD. Additionally,
we compare methods in terms of similarities, differences, and respective
advantages. Finally, we discuss research limitations and future directions,
offering insights for further advancements in PCD.

</details>


### [24] [DynamicPose: Real-time and Robust 6D Object Pose Tracking for Fast-Moving Cameras and Objects](https://arxiv.org/abs/2508.11950)
*Tingbang Liang,Yixin Zeng,Jiatong Xie,Boyu Zhou*

Main category: cs.CV

TL;DR: DynamicPose는 재학습 없이 빠르게 움직이는 카메라와 물체 환경에서도 실시간으로 안정적인 6D 포즈 추적을 제공하는 프레임워크이다. VIO로 ROI 보정, 깊이 기반 2D 트래커로 물체 병진 보정, VIO-유도 칼만 필터로 회전 예측·후보 포즈 생성·계층적 정제를 결합한 폐쇄루프 구조가 핵심이다.


<details>
  <summary>Details</summary>
Motivation: 기존 6D 포즈 추적 기법들은 정적·준정적 장면에서 성능을 내도록 설계되어 빠른 카메라 및 물체 움직임이 동시에 발생하면 성능이 급격히 떨어진다. 이를 해결해 빠른 운동 상황에서도 안정적이고 실시간인 추적을 달성하려는 것이 동기다.

Method: 세 가지 시너지 구성요소: (1) VIO 기반으로 카메라 움직임에 의해 발생한 ROI 이동 보정; (2) 깊이 정보를 활용한 2D 트래커로 큰 물체 병진으로 인한 ROI 편차 보정; (3) VIO-유도 칼만 필터로 물체 회전 예측, 여러 후보 포즈 생성 및 계층적 정제로 최종 포즈 선정. 6D 포즈 결과를 2D 트래커와 칼만 필터에 피드백해 폐쇄루프를 형성한다. 재학습 불필요(retraining-free) 설계로 별도 학습 과정 없이 바로 적용 가능하다.

Result: 시뮬레이션 및 실제 환경 실험에서 고속 카메라/물체 상황에서도 실시간으로 안정적인 6D 추적 성능을 보였다고 보고한다. 특히 ROI 보정과 후보-정제 파이프라인이 큰 이동과 회전에 강인함을 제공한다.

Conclusion: DynamicPose는 VIO와 깊이 정보를 결합한 폐쇄루프 구조로 빠르게 움직이는 장면에서도 재학습 없이 실시간 6D 포즈 추적을 향상시킨다. 다만 VIO·깊이의 품질 의존성, 부분 가려짐·대칭성 처리 등 한계와 비교 실험·정량적 지표 제시 여부가 중요하다.

Abstract: We present DynamicPose, a retraining-free 6D pose tracking framework that
improves tracking robustness in fast-moving camera and object scenarios.
Previous work is mainly applicable to static or quasi-static scenes, and its
performance significantly deteriorates when both the object and the camera move
rapidly. To overcome these challenges, we propose three synergistic components:
(1) A visual-inertial odometry compensates for the shift in the Region of
Interest (ROI) caused by camera motion; (2) A depth-informed 2D tracker
corrects ROI deviations caused by large object translation; (3) A VIO-guided
Kalman filter predicts object rotation, generates multiple candidate poses, and
then obtains the final pose by hierarchical refinement. The 6D pose tracking
results guide subsequent 2D tracking and Kalman filter updates, forming a
closed-loop system that ensures accurate pose initialization and precise pose
tracking. Simulation and real-world experiments demonstrate the effectiveness
of our method, achieving real-time and robust 6D pose tracking for fast-moving
cameras and objects.

</details>


### [25] [Transferable Class Statistics and Multi-scale Feature Approximation for 3D Object Detection](https://arxiv.org/abs/2508.11951)
*Hao Peng,Hong Sang,Yajing Ma,Ping Qiu,Chao Ji*

Main category: cs.CV

TL;DR: 단일 이웃 기반 지식 증류로 다중 스케일 특성을 근사하고, 클래스-인식 통계 기반의 전달 가능한 특징 임베딩과 중심 가중치 IoU로 경계 상자 정렬을 개선하여 연산 비용을 크게 줄인 3D 포인트클라우드 물체 검출 경량화 방법.


<details>
  <summary>Details</summary>
Motivation: 포인트클라우드 물체 검출에서 다중 스케일 특성은 필수이나, 이를 위해 여러 이웃 탐색과 스케일 인지 계층을 사용하는 기존 방법은 계산·메모리 비용이 크고 경량 모델 설계나 자원 제약 연구에 제약을 준다.

Method: 하나의 이웃(neighborhood)만으로 다중 스케일 특성을 근사하기 위해 지식 증류(knowledge distillation)를 적용하고, 단일 이웃에서 손실되는 표현 다양성을 보완하기 위해 클래스-인식 통계(class-aware statistics)를 전달 가능한 특징으로 설계해 임베딩에 활용한다. 추가로 중심 위치 오프셋으로 인한 최적화 불일치를 완화하기 위해 중심 가중치 교차점 IoU(central weighted IoU)를 국지화 손실에 도입한다.

Result: 제안 방법은 계산 비용을 절감하면서도 공개 데이터셋에서 경쟁력 있는 검출 성능을 보였다고 보고한다(구체적 수치·데이터셋은 초록에 없음).

Conclusion: 지식 증류와 경량의 전달 가능한 특징 설계로 다중 스케일 학습의 비용을 줄이며 실용적인 경량 3D 검출기를 제시. 다만 상세 구현·정량 비교·한계는 본문 확인 필요.

Abstract: This paper investigates multi-scale feature approximation and transferable
features for object detection from point clouds. Multi-scale features are
critical for object detection from point clouds. However, multi-scale feature
learning usually involves multiple neighborhood searches and scale-aware
layers, which can hinder efforts to achieve lightweight models and may not be
conducive to research constrained by limited computational resources. This
paper approximates point-based multi-scale features from a single neighborhood
based on knowledge distillation. To compensate for the loss of constructive
diversity in a single neighborhood, this paper designs a transferable feature
embedding mechanism. Specifically, class-aware statistics are employed as
transferable features given the small computational cost. In addition, this
paper introduces the central weighted intersection over union for localization
to alleviate the misalignment brought by the center offset in optimization.
Note that the method presented in this paper saves computational costs.
Extensive experiments on public datasets demonstrate the effectiveness of the
proposed method.

</details>


### [26] [UniUGG: Unified 3D Understanding and Generation via Geometric-Semantic Encoding](https://arxiv.org/abs/2508.11952)
*Yueming Xu,Jiahui Zhang,Ze Huang,Yurui Chen,Yanpeng Zhou,Zhenyu Chen,Yu-Jie Yuan,Pengxiang Xia,Guowei Huang,Xinyue Cai,Zhongang Qi,Xingyue Quan,Jianye Hao,Hang Xu,Li Zhang*

Main category: cs.CV

TL;DR: 본 논문은 3D 모달리티에 대한 통합적 이해·생성 프레임워크 UniUGG를 제안한다. LLM을 통한 문장·3D 표현 해석과 latent diffusion 기반 공간 디코더로 고품질 3D 표현 생성 및 시점 변환을 지원하며, 기하·의미 병렬 학습으로 인코더를 사전학습한다.


<details>
  <summary>Details</summary>
Motivation: 최근 통합 비전-언어 아키텍처들이 이미지 수준에서 큰 성과를 내지만, 3D 작업을 통합하는 연구는 제한적이다. 3D 생성·이해를 단일 프레임워크로 처리하려는 필요성에서 출발한다.

Method: LLM으로 텍스트와 3D 표현을 해석하고, latent diffusion 기반의 spatial decoder로 입력 이미지와 임의 시점 변환을 받아 3D 장면을 생성한다. 또한 기하-의미(geometric-semantic) 학습 전략으로 비전 인코더를 사전학습해 공간 이해와 생성 성능을 향상시킨다.

Result: 실험에서 시각 표현, 공간 이해(VQA 포함), 3D 생성 성능에서 우수함을 보였다고 주장한다. 코드 공개 예정.

Conclusion: UniUGG는 3D 모달리티를 포함하는 통합 이해·생성 파이프라인의 가능성을 제시하지만, 구현·평가의 세부사항(데이터, 메트릭, 계산비용 등)이 명확해야 실제 성과와 재현성이 검증될 것 같다.

Abstract: Despite the impressive progress on understanding and generating images shown
by the recent unified architectures, the integration of 3D tasks remains
challenging and largely unexplored. In this paper, we introduce UniUGG, the
first unified understanding and generation framework for 3D modalities. Our
unified framework employs an LLM to comprehend and decode sentences and 3D
representations. At its core, we propose a spatial decoder leveraging a latent
diffusion model to generate high-quality 3D representations. This allows for
the generation and imagination of 3D scenes based on a reference image and an
arbitrary view transformation, while remaining supports for spatial visual
question answering (VQA) tasks. Additionally, we propose a geometric-semantic
learning strategy to pretrain the vision encoder. This design jointly captures
the input's semantic and geometric cues, enhancing both spatial understanding
and generation. Extensive experimental results demonstrate the superiority of
our method in visual representation, spatial understanding, and 3D generation.
The source code will be released upon paper acceptance.

</details>


### [27] [SAMDWICH: Moment-aware Video-text Alignment for Referring Video Object Segmentation](https://arxiv.org/abs/2508.11955)
*Seunghun Lee,Jiwan Seo,Jeonghoon Kim,Siwon Kim,Haeun Yun,Hyogyeong Jeon,Wonhyeok Choi,Jaehoon Jeong,Zane Durante,Sang Hyun Park,Sunghoon Im*

Main category: cs.CV

TL;DR: 비디오-텍스트 정렬을 위해 참조 시점을 수동 주석화하고, 시점 인지 전파 및 객체 선택적 감독을 도입한 SAMDWICH 프레임워크(및 MeViS-M 데이터셋)는 MeViS에서 SOTA 성능을 달성함.


<details>
  <summary>Details</summary>
Motivation: 기존 RVOS는 무차별적 프레임 샘플링과 모든 보이는 객체에 대한 일괄적 감독 때문에 텍스트와 비주얼의 의미적 불일치(semantic misalignment)를 겪음. 표현이 참조하는 정확한 시점과 객체를 반영한 감독이 필요함.

Method: (1) MeViS 데이터에 각 객체가 표현으로 참조되는 시간적 모멘트를 수동 주석화한 MeViS-M 데이터셋을 구축. (2) 텍스트-클립 정렬을 활용하는 SAMDWICH 프레임워크 제안. (3) Moment-guided Dual-path Propagation(MDP): 시점 중심 메모리 메커니즘으로 관련/비관련 프레임을 모두 학습하여 그라운딩과 트래킹을 향상. (4) Object-level Selective Supervision(OSS): 각 훈련 클립에서 표현과 시간적으로 정렬된 객체만 감독하여 의미적 노이즈 감소.

Result: 제안한 방법은 MeViS 벤치마크에서 SOTA 성능을 기록하며, 특히 다양한 복잡한 표현을 포함한 시나리오에서 참조 이해와 추적 성능이 크게 향상됨.

Conclusion: 시점 인지(모멘트 기반) 지도와 객체 수준의 선택적 감독은 언어-비주얼 정렬을 강화하고 불필요한 감독 노이즈를 줄임. 제안된 구성요소들은 RVOS의 정확한 그라운딩과 트래킹에 효과적이며, 향후 자동화된 모멘트 주석화나 더 넓은 도메인 일반화 연구로 확장 가능함.

Abstract: Referring Video Object Segmentation (RVOS) aims to segment and track objects
in videos based on natural language expressions, requiring precise alignment
between visual content and textual queries. However, existing methods often
suffer from semantic misalignment, largely due to indiscriminate frame sampling
and supervision of all visible objects during training -- regardless of their
actual relevance to the expression. To address this, we introduce a
moment-aware RVOS framework named SAMDWICH, along with a newly annotated
dataset, MeViS-M, built upon the challenging MeViS benchmark. We manually
annotate temporal moments indicating when each object is referred to by the
expression, enabling semantically grounded supervision that strengthens
video-text alignment. SAMDWICH leverages these aligned text-to-clip pairs to
guide training, significantly enhancing referential understanding. Building
upon this framework, we propose Moment-guided Dual-path Propagation (MDP), a
moment-aware propagation strategy that improves both object grounding and
tracking by training on both relevant and irrelevant frames through a
moment-centric memory mechanism. In addition, we introduce Object-level
Selective Supervision (OSS), an object-level filtering strategy that supervises
only the objects temporally aligned with the expression in each training clip.
This selective supervision reduces semantic noise and reinforces
language-conditioned learning. Extensive experiments show that SAMDWICH
achieves state-of-the-art performance on challenging MeViS benchmark,
particularly excelling in complex scenarios involving diverse expressions.

</details>


### [28] [PEdger++: Practical Edge Detection via Assembling Cross Information](https://arxiv.org/abs/2508.11961)
*Yuanbin Fu,Liang Li,Xiaojie Guo*

Main category: cs.CV

TL;DR: Proposes PEdger++, a collaborative learning framework that leverages cross-information from heterogeneous architectures, diverse training moments, and multiple parameter samplings to produce lightweight, accurate edge detectors for resource-constrained devices.


<details>
  <summary>Details</summary>
Motivation: Edge detection is essential for many vision tasks but modern deep models are often too large/compute-heavy for deployment on low-resource devices. The paper aims to maintain or improve accuracy while reducing computation and model size.

Method: Introduce PEdger++, which aggregates 'cross-information' coming from heterogeneous architectures, checkpoints from different training moments, and multiple parameter samplings. This ensemble-style collaboration is used to train compact detectors. Multiple model variants are provided to match different resource budgets.

Result: Reports quantitative and qualitative improvements over existing methods on BSDS500, NYUD, and Multicue datasets. Claims reduced computational cost and smaller model sizes while improving accuracy. Provides code and several model-size options.

Conclusion: PEdger++ is an adaptive, ensemble-inspired framework that trades architectural complexity for collaborative learning among diverse models/checkpoints to achieve efficient and effective edge detection suitable for various device constraints.

Abstract: Edge detection serves as a critical foundation for numerous computer vision
applications, including object detection, semantic segmentation, and image
editing, by extracting essential structural cues that define object boundaries
and salient edges. To be viable for broad deployment across devices with
varying computational capacities, edge detectors shall balance high accuracy
with low computational complexity. While deep learning has evidently improved
accuracy, they often suffer from high computational costs, limiting their
applicability on resource-constrained devices. This paper addresses the
challenge of achieving that balance: \textit{i.e.}, {how to efficiently capture
discriminative features without relying on large-size and sophisticated
models}. We propose PEdger++, a collaborative learning framework designed to
reduce computational costs and model sizes while improving edge detection
accuracy. The core principle of our PEdger++ is that cross-information derived
from heterogeneous architectures, diverse training moments, and multiple
parameter samplings, is beneficial to enhance learning from an ensemble
perspective. Extensive experimental results on the BSDS500, NYUD and Multicue
datasets demonstrate the effectiveness of our approach, both quantitatively and
qualitatively, showing clear improvements over existing methods. We also
provide multiple versions of the model with varying computational requirements,
highlighting PEdger++'s adaptability with respect to different resource
constraints. Codes are accessible at
https://github.com/ForawardStar/EdgeDetectionviaPEdgerPlus/.

</details>


### [29] [Exploring Spatial-Temporal Dynamics in Event-based Facial Micro-Expression Analysis](https://arxiv.org/abs/2508.11988)
*Nicolas Mastropasqua,Ignacio Bugueno-Cordova,Rodrigo Verschae,Daniel Acevedo,Pablo Negri,Maria E. Buemi*

Main category: cs.CV

TL;DR: 저자들은 RGB와 이벤트 카메라로 동기화된 다중 해상도·다중 모달 마이크로표정 데이터셋을 제안하고, 이벤트 데이터로 AU 분류(스파이킹 신경망)와 프레임 복원(CVAE)을 평가하여 이벤트 센서의 유용성을 보였다.


<details>
  <summary>Details</summary>
Motivation: RGB 카메라는 시간 분해능과 모션 블러에 한계가 있어 미세·빠른 표정(마이크로표정)의 포착이 어렵다. 이벤트 카메라는 마이크로초 수준의 시간 해상도와 낮은 지연, 넓은 다이내믹 레인지를 제공하므로 미세 움직임 분석에 적합하지만, 이벤트 기반 AU 데이터셋이 부족하다.

Method: 동기화된 RGB 및 이벤트 카메라로 다양한 조명 조건에서 다중 해상도의 마이크로표정 데이터를 수집. 두 가지 기본 과제에 대해 평가: (1) 이벤트 입력을 사용한 AU 분류에 스파이킹 신경망 적용, (2) 고해상도 이벤트 입력을 조건부 변분 오토인코더(CVAE)로 프레임 복원.

Result: AU 분류에서 이벤트 입력은 51.23% 정확도, RGB는 23.12%로 이벤트가 우수함. 프레임 복원에서 고해상도 이벤트 입력으로 SSIM=0.8513, PSNR=26.89 dB 달성.

Conclusion: 이벤트 기반 데이터는 마이크로표정 인식 및 프레임 복원에 유망하며, 제안 데이터셋은 연구를 촉진할 수 있다. 다만 예비 연구로서 샘플 수·레이블링·범용성에 대한 추가 확장과 다양한 모델·평가가 필요하다.

Abstract: Micro-expression analysis has applications in domains such as Human-Robot
Interaction and Driver Monitoring Systems. Accurately capturing subtle and fast
facial movements remains difficult when relying solely on RGB cameras, due to
limitations in temporal resolution and sensitivity to motion blur. Event
cameras offer an alternative, with microsecond-level precision, high dynamic
range, and low latency. However, public datasets featuring event-based
recordings of Action Units are still scarce. In this work, we introduce a
novel, preliminary multi-resolution and multi-modal micro-expression dataset
recorded with synchronized RGB and event cameras under variable lighting
conditions. Two baseline tasks are evaluated to explore the spatial-temporal
dynamics of micro-expressions: Action Unit classification using Spiking Neural
Networks (51.23\% accuracy with events vs. 23.12\% with RGB), and frame
reconstruction using Conditional Variational Autoencoders, achieving SSIM =
0.8513 and PSNR = 26.89 dB with high-resolution event input. These promising
results show that event-based data can be used for micro-expression recognition
and frame reconstruction.

</details>


### [30] [InstDrive: Instance-Aware 3D Gaussian Splatting for Driving Scenes](https://arxiv.org/abs/2508.12015)
*Hongyuan Liu,Haochen Yu,Jianfei Jiang,Qiankun Liu,Jiansheng Chen,Huimin Ma*

Main category: cs.CV

TL;DR: InstDrive: 대시캠 동적 주행 장면을 위한 인스턴스 인식 3D Gaussian Splatting. SAM 마스크로 2D 특징 학습을 지도하고, 3D 정규화와 voxel 손실로 인스턴스 일관성 강제, 경량 정적 코드북으로 연속 특징→불연속 ID 연결. 별도 사전처리 없이 동적 야외 장면에서 3D 인스턴스 분할 달성.


<details>
  <summary>Details</summary>
Motivation: 기존 방법은 배경을 단일 표현으로 통합해 인스턴스별 이해와 편집이 어려움. 2D 세그먼트를 3D로 올리는 기존 접근은 사전처리된 ID 또는 복잡한 파이프라인에 의존하고, 실내 풍부한 시점에 최적화되어 야외 주행 장면에 부적합.

Method: SAM에서 생성한 마스크를 의사 정답으로 사용해 대조 손실과 의사-감독 목표로 2D 특징을 학습. 3D 수준에서는 정규화를 도입해 인스턴스 정체성을 암묵적으로 인코딩하고 voxel 기반 손실로 일관성 강제. 경량 정적 코드북으로 연속 특징과 불연속 ID를 연결하여 복잡한 사전처리 없이 인스턴스 분할 구현.

Result: 정량·정성 실험에서 InstDrive의 효과를 입증. 동적 오픈월드 주행 장면에서 최초로 3D 인스턴스 분할을 달성했다고 주장.

Conclusion: InstDrive는 복잡한 사전처리나 ID 추적 없이 대시캠 기반 동적 주행 장면에서 인스턴스 인식 3D 재구성을 가능하게 해, 자율주행 및 장면 편집에서 실용성을 높임.

Abstract: Reconstructing dynamic driving scenes from dashcam videos has attracted
increasing attention due to its significance in autonomous driving and scene
understanding. While recent advances have made impressive progress, most
methods still unify all background elements into a single representation,
hindering both instance-level understanding and flexible scene editing. Some
approaches attempt to lift 2D segmentation into 3D space, but often rely on
pre-processed instance IDs or complex pipelines to map continuous features to
discrete identities. Moreover, these methods are typically designed for indoor
scenes with rich viewpoints, making them less applicable to outdoor driving
scenarios. In this paper, we present InstDrive, an instance-aware 3D Gaussian
Splatting framework tailored for the interactive reconstruction of dynamic
driving scene. We use masks generated by SAM as pseudo ground-truth to guide 2D
feature learning via contrastive loss and pseudo-supervised objectives. At the
3D level, we introduce regularization to implicitly encode instance identities
and enforce consistency through a voxel-based loss. A lightweight static
codebook further bridges continuous features and discrete identities without
requiring data pre-processing or complex optimization. Quantitative and
qualitative experiments demonstrate the effectiveness of InstDrive, and to the
best of our knowledge, it is the first framework to achieve 3D instance
segmentation in dynamic, open-world driving scenes.More visualizations are
available at our project page.

</details>


### [31] [WiseLVAM: A Novel Framework For Left Ventricle Automatic Measurements](https://arxiv.org/abs/2508.12023)
*Durgesh Kumar Singh,Qing Cao,Sarina Thomas,Ahcène Boubekki,Robert Jenssen,Michael Kampffmeyer*

Main category: cs.CV

TL;DR: 심장 초음파 B-모드에서 LV 선형 측정은 임상 지침상 기저부를 가로지르는 가상 스캔라인(SL)에 수직으로 수행되어야 한다. 기존 자동화는 B-모드에서 직접 랜드마크를 예측해 작은 위치 오차가 큰 측정 오류로 이어졌으나, EnLVAM은 임상의가 정한 SL에 제약을 두어 AMM(Anatomical Motion Mode) 이미지에서 랜드마크를 예측함으로써 이를 완화했다. 본 논문은 약지도학습 기반의 윤곽 인식기를 통해 SL을 자동으로 배치하고, 그 위에서 AMM 모드로 측정하는 완전 자동·수동 조정 가능한 WiseLVAM을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 임상 지침을 따르는 정확한 SL 배치가 없으면 B-모드 기반 랜드마크 예측에서 작은 위치 변화도 LV 직선 치수 측정에 큰 오류를 유발하여 임상 신뢰도가 떨어진다. EnLVAM은 임상의가 지정한 SL로 제한해 문제를 일부 해결했으나, 완전 자동화와 실무 적용을 위해 SL을 자동으로 배치하는 방법이 필요하다.

Method: 1) 약지도학습된 B-모드 랜드마크/윤곽 검출기로 LV 윤곽을 추정한다. 2) 추정된 윤곽으로부터 LV 장축과 기저부(판막 팁 수준)를 규정해 임상 지침을 모방한 SL을 자동 배치한다. 3) 해당 SL을 따라 AMM 이미지를 생성하고, AMM 모드의 동적 정보와 B-모드의 구조 정보를 결합해 랜드마크를 예측하여 선형 치수를 산출한다. 프레임워크는 자동 동작하되 사용자가 수동으로 조정할 수 있게 설계되었다.

Result: 초록에서는 구조 인식(B-mode)과 운동 인식(AMM)을 결합해 강건성과 정확도를 향상시킨다고 주장하며 임상 적용 가능성을 제시한다. 다만 초록만으로는 정량적 성능(오차, 민감도/특이도, 비교 대상 대비 이득), 데이터셋 규모·다양성, 계산 비용 등 구체적 결과는 제시되지 않았다.

Conclusion: WiseLVAM은 임상 지침을 모사한 자동 SL 배치와 AMM 기반 측정을 결합해 기존 B-모드 직접 예측 방식의 취약성을 보완하려는 실용적 접근이다. 하지만 임상 적용을 위해서는 정량적 검증, 다양한 장비·횡단면 데이터에서의 일반화 실험, 사용자 수동보정 인터페이스 및 실사용 처리시간 검증이 필요하다.

Abstract: Clinical guidelines recommend performing left ventricular (LV) linear
measurements in B-mode echocardiographic images at the basal level -- typically
at the mitral valve leaflet tips -- and aligned perpendicular to the LV long
axis along a virtual scanline (SL). However, most automated methods estimate
landmarks directly from B-mode images for the measurement task, where even
small shifts in predicted points along the LV walls can lead to significant
measurement errors, reducing their clinical reliability. A recent
semi-automatic method, EnLVAM, addresses this limitation by constraining
landmark prediction to a clinician-defined SL and training on generated
Anatomical Motion Mode (AMM) images to predict LV landmarks along the same. To
enable full automation, a contour-aware SL placement approach is proposed in
this work, in which the LV contour is estimated using a weakly supervised
B-mode landmark detector. SL placement is then performed by inferring the LV
long axis and the basal level-mimicking clinical guidelines. Building on this
foundation, we introduce \textit{WiseLVAM} -- a novel, fully automated yet
manually adaptable framework for automatically placing the SL and then
automatically performing the LV linear measurements in the AMM mode.
\textit{WiseLVAM} utilizes the structure-awareness from B-mode images and the
motion-awareness from AMM mode to enhance robustness and accuracy with the
potential to provide a practical solution for the routine clinical application.

</details>


### [32] [Q-FSRU: Quantum-Augmented Frequency-Spectral Fusion for Medical Visual Question Answering](https://arxiv.org/abs/2508.12036)
*Rakesh Thakur,Yusra Tariq*

Main category: cs.CV

TL;DR: Q-FSRU는 이미지·텍스트 특징을 FFT로 주파수 영역으로 변환해 노이즈를 감소시키고, ‘Quantum RAG’로 외부 의료 지식을 검색해 주파수 기반 특징과 융합해 의료 VQA 성능과 설명력을 개선한 모델이다. VQA-RAD에서 기존 모델을 능가했다고 보고한다.


<details>
  <summary>Details</summary>
Motivation: 의료에서 이미지와 텍스트를 동시에 이해해야 하는 난제(노이즈, 근거 기반 답변 필요)를 해결하고, 더 정확하고 근거 있는 VQA 시스템을 만들기 위함.

Method: 의료 이미지·텍스트 특징을 FFT로 주파수 영역으로 변환(FSRU)해 유의미한 성분을 강조/노이즈 제거. 외부 의료 지식을 Quantum RAG(양자 영감 유사도 기반 검색)으로 조회해 관련 사실을 확보하고, 해당 사실을 주파수 특징과 융합해 추론 및 응답 생성.

Result: VQA-RAD 데이터셋에서 기존 방법들보다 우수한 성능을 보였으며, 특히 복합적 이미지-텍스트 추론 문제에서 개선이 두드러졌다고 보고. 설명력(근거 제시)도 향상되었다고 주장.

Conclusion: 주파수 표현과 양자 영감 기반 검색의 결합은 의료 VQA에서 성능 및 설명력을 동시에 개선할 가능성이 있으며, 임상의용으로 유망한 접근법을 제안함.

Abstract: Solving tough clinical questions that require both image and text
understanding is still a major challenge in healthcare AI. In this work, we
propose Q-FSRU, a new model that combines Frequency Spectrum Representation and
Fusion (FSRU) with a method called Quantum Retrieval-Augmented Generation
(Quantum RAG) for medical Visual Question Answering (VQA). The model takes in
features from medical images and related text, then shifts them into the
frequency domain using Fast Fourier Transform (FFT). This helps it focus on
more meaningful data and filter out noise or less useful information. To
improve accuracy and ensure that answers are based on real knowledge, we add a
quantum-inspired retrieval system. It fetches useful medical facts from
external sources using quantum-based similarity techniques. These details are
then merged with the frequency-based features for stronger reasoning. We
evaluated our model using the VQA-RAD dataset, which includes real radiology
images and questions. The results showed that Q-FSRU outperforms earlier
models, especially on complex cases needing image-text reasoning. The mix of
frequency and quantum information improves both performance and explainability.
Overall, this approach offers a promising way to build smart, clear, and
helpful AI tools for doctors.

</details>


### [33] [VimoRAG: Video-based Retrieval-augmented 3D Motion Generation for Motion Language Models](https://arxiv.org/abs/2508.12081)
*Haidong Xu,Guangwei Xu,Zhedong Zheng,Xiatian Zhu,Wei Ji,Xiangtai Li,Ruijie Guo,Meishan Zhang,Min zhang,Hao Fei*

Main category: cs.CV

TL;DR: VimoRAG는 대규모 인-더-와일드 비디오에서 2D 인간 모션 신호를 검색해 텍스트만 입력 가능한 모션 LLM의 3D 모션 생성 성능을 크게 향상시키는 비디오 기반 RAG(framework)이다.


<details>
  <summary>Details</summary>
Motivation: 모션 LLM은 주석된 3D 동작 데이터가 제한적이어서 도메인 외/어휘 외 문제를 겪는다. 비디오 데이터의 풍부한 2D 모션 정보를 활용해 이 한계를 보완하고자 한다.

Method: (1) 인간 포즈·동작을 구분하는 모션 중심의 영상 검색기: Gemini Motion Video Retriever 설계로 관련 2D 모션 신호를 찾음. (2) 검색 오류가 생성에 전파되는 문제 완화: Motion-centric Dual-alignment DPO Trainer를 통해 검색-생성 간 정렬과 오류 완화 기법 도입.

Result: 제안된 VimoRAG는 텍스트 전용 입력에 제한된 모션 LLM들에서 실험적으로 성능을 유의미하게 향상시킴.

Conclusion: 비디오 기반 RAG는 모션 생성에서 실용적 이점을 제공하며, 검색 품질 개선과 검색-생성 정렬이 핵심이다. 향후 검색 정확도, 도메인 적응성, 시공간적 정합성 향상 연구가 필요하다.

Abstract: This paper introduces VimoRAG, a novel video-based retrieval-augmented motion
generation framework for motion large language models (LLMs). As motion LLMs
face severe out-of-domain/out-of-vocabulary issues due to limited annotated
data, VimoRAG leverages large-scale in-the-wild video databases to enhance 3D
motion generation by retrieving relevant 2D human motion signals. While
video-based motion RAG is nontrivial, we address two key bottlenecks: (1)
developing an effective motion-centered video retrieval model that
distinguishes human poses and actions, and (2) mitigating the issue of error
propagation caused by suboptimal retrieval results. We design the Gemini Motion
Video Retriever mechanism and the Motion-centric Dual-alignment DPO Trainer,
enabling effective retrieval and generation processes. Experimental results
show that VimoRAG significantly boosts the performance of motion LLMs
constrained to text-only input.

</details>


### [34] [Automated Model Evaluation for Object Detection via Prediction Consistency and Reliablity](https://arxiv.org/abs/2508.12082)
*Seungju Yoo,Hyuk Kwon,Joong-Won Hwang,Kibok Lee*

Main category: cs.CV

TL;DR: 지도 레이블 없이 객체 검출기의 성능을 추정하는 자동평가(AutoEval) 프레임워크를 제안. NMS 이전의 후보 박스 정보를 활용해 공간적 일관성과 신뢰도를 측정하는 PCR 지표로 성능을 예측하며, 이미지 손상 정도를 바꾼 메타-데이터셋으로 평가함.


<details>
  <summary>Details</summary>
Motivation: 실제 응용에서 객체 검출기 성능을 평가하려면 수작업 레이블링이 필요해 비용이 크고 확장성이 떨어짐. 자동화된, 라벨 없는 성능 평가 방법이 필요함.

Method: NMS 전에 생성되는 다중 후보 바운딩 박스들을 이용. 1) NMS 전후 박스들의 공간적 일관성(겹침·위치 변화)을 측정하고, 2) 유지된 박스의 신뢰도를 겹치는 후보들의 confidence 점수로 평가. 이 둘을 결합해 라벨 없이 성능을 추정하는 PCR 지표를 만듦. 또한 다양한 심각도의 이미지 손상을 적용한 메타-데이터셋을 구축해 더 현실적 평가를 수행.

Result: 제안한 PCR이 기존 자동평가 기법들보다 성능 추정 정확도가 높음. 제안한 메타-데이터셋이 검출 성능 범위를 더 넓게 커버함. 코드 공개(깃허브 링크 제공).

Conclusion: NMS 이전 후보 박스의 정보만으로도 지상참조 없이 검출기 성능을 신뢰성 있게 추정할 수 있으며, 현실성 높은 손상 기반 메타-데이터셋과 결합해 실무 적용 가능성이 높음.

Abstract: Recent advances in computer vision have made training object detectors more
efficient and effective; however, assessing their performance in real-world
applications still relies on costly manual annotation. To address this
limitation, we develop an automated model evaluation (AutoEval) framework for
object detection. We propose Prediction Consistency and Reliability (PCR),
which leverages the multiple candidate bounding boxes that conventional
detectors generate before non-maximum suppression (NMS). PCR estimates
detection performance without ground-truth labels by jointly measuring 1) the
spatial consistency between boxes before and after NMS, and 2) the reliability
of the retained boxes via the confidence scores of overlapping boxes. For a
more realistic and scalable evaluation, we construct a meta-dataset by applying
image corruptions of varying severity. Experimental results demonstrate that
PCR yields more accurate performance estimates than existing AutoEval methods,
and the proposed meta-dataset covers a wider range of detection performance.
The code is available at https://github.com/YonseiML/autoeval-det.

</details>


### [35] [Generic Event Boundary Detection via Denoising Diffusion](https://arxiv.org/abs/2508.12084)
*Jaejun Hwang,Dayoung Gong,Manjin Kim,Minsu Cho*

Main category: cs.CV

TL;DR: DiffGEBD는 동영상의 이벤트 경계 검출을 확산(denoising diffusion) 기반 생성 모델로 접근해, 프레임 간 변화(temporal self-similarity)를 인코딩하고 노이즈를 반복적으로 디코딩하여 다양한 그럴듯한 경계 후보를 생성한다. 분류기-프리 가이던스로 다양성 조절이 가능하며, 다양성과 충실도를 함께 평가하는 새로운 지표를 제안한다. Kinetics-GEBD와 TAPOS에서 우수한 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 이벤트 경계는 본질적으로 주관적이고 다중 해답이 존재할 수 있음에도 기존 연구는 단일 결정론적 예측에 치중했고, 다양한 타당한 경계 후보를 생성하는 문제는 미해결 상태였다.

Method: 입력 영상에서 temporal self-similarity로 프레임 간 변화 특성을 인코딩한 뒤, 조건부 확산 모델을 사용해 무작위 노이즈를 반복적으로 경계 예측으로 역변환한다. classifier-free guidance를 도입해 디노이징 과정에서 다양성-충실도 균형을 제어한다. 또한 다양성 및 충실도를 동시에 반영하는 새로운 평가 지표를 설계했다.

Result: 제안 방식은 Kinetics-GEBD와 TAPOS 두 벤치마크에서 강한 성능을 기록했으며, 다양한(다중) 경계 후보를 생성해 인간의 주관적 분할 가능성을 더 잘 포착했다.

Conclusion: GEBD에 생성적 확산모델을 적용하는 것은 실용적이고 유망한 접근이며, 다양성 제어와 새로운 평가척도는 주관적 문제를 더 잘 다루게 해 준다. 향후 실시간성, 주석 불확실성 모델링, 사용자 연구 등이 필요하다.

Abstract: Generic event boundary detection (GEBD) aims to identify natural boundaries
in a video, segmenting it into distinct and meaningful chunks. Despite the
inherent subjectivity of event boundaries, previous methods have focused on
deterministic predictions, overlooking the diversity of plausible solutions. In
this paper, we introduce a novel diffusion-based boundary detection model,
dubbed DiffGEBD, that tackles the problem of GEBD from a generative
perspective. The proposed model encodes relevant changes across adjacent frames
via temporal self-similarity and then iteratively decodes random noise into
plausible event boundaries being conditioned on the encoded features.
Classifier-free guidance allows the degree of diversity to be controlled in
denoising diffusion. In addition, we introduce a new evaluation metric to
assess the quality of predictions considering both diversity and fidelity.
Experiments show that our method achieves strong performance on two standard
benchmarks, Kinetics-GEBD and TAPOS, generating diverse and plausible event
boundaries.

</details>


### [36] [Enhancing 3D point accuracy of laser scanner through multi-stage convolutional neural network for applications in construction](https://arxiv.org/abs/2508.12089)
*Qinyuan Fan,Clemens Gühmann*

Main category: cs.CV

TL;DR: 이 논문은 다단계 합성곱 신경망(MSCNN)과 전통 기하처리를 결합해 저가 레이저 스캐너(LAS)의 3D 포인트 정확도를 고가 장비(HAS) 수준으로 보정하는 방법을 제안한다. HAS와 LAS의 동일 환경 측정을 비교해 오차 패턴을 학습·보정하여 MSE를 70% 이상 감소시키고 PSNR을 약 6dB 향상시켰다.


<details>
  <summary>Details</summary>
Motivation: 저가 레이저 스캐너는 장비 및 환경적 요인으로 위치 오차가 커 고정밀 실내 측량·모델링에 적합하지 않다. 하드웨어 교체 없이 비용 효율적으로 측정 불확도(포인트 정확도)를 낮추려는 것이 동기이다.

Method: 동일 환경에서 HAS(참조)와 LAS(대상)의 측정쌍을 수집해 오차와 공간분포의 통계적 관계를 모델링한다. 전통 기하처리로 기초 정합·보정 후, 다단계 CNN(MSCNN)을 통해 잔차적 오차를 정밀하게 보정하는 통합 프레임워크로 지도학습 문제로 변환한다. 기하학적 특성을 보존하도록 설계했다.

Result: 실험에서 자체 수집한 '거칠은 실내' 데이터셋에 대해 MSE가 70% 이상 감소하고 PSNR이 약 6dB 향상되었다. 저가 장비의 측정 불확도가 고가 장비 수준에 근접함을 보였다.

Conclusion: 제안한 MSCNN 통합 보정법은 하드웨어 수정 없이 저가 LS의 측정 정확도를 크게 개선하여 고정밀 모델링·리노베이션에 활용될 수 있다.

Abstract: We propose a multi-stage convolutional neural network (MSCNN) based
integrated method for reducing uncertainty of 3D point accuracy of lasar
scanner (LS) in rough indoor rooms, providing more accurate spatial
measurements for high-precision geometric model creation and renovation. Due to
different equipment limitations and environmental factors, high-end and low-end
LS have positional errors. Our approach pairs high-accuracy scanners (HAS) as
references with corresponding low-accuracy scanners (LAS) of measurements in
identical environments to quantify specific error patterns. By establishing a
statistical relationship between measurement discrepancies and their spatial
distribution, we develop a correction framework that combines traditional
geometric processing with targeted neural network refinement. This method
transforms the quantification of systematic errors into a supervised learning
problem, allowing precise correction while preserving critical geometric
features. Experimental results in our rough indoor rooms dataset show
significant improvements in measurement accuracy, with mean square error (MSE)
reductions exceeding 70% and peak signal-to-noise ratio (PSNR) improvements of
approximately 6 decibels. This approach enables low-end devices to achieve
measurement uncertainty levels approaching those of high-end devices without
hardware modifications.

</details>


### [37] [Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion](https://arxiv.org/abs/2508.12094)
*Songwei Liu,Hong Liu,Fangmin Chen,Xurui Peng,Chenqian Yan,Lean Fu,Xing Mei*

Main category: cs.CV

TL;DR: DM의 반복적 샘플링에서 PTQ로 인한 단계별 양자화 오차가 누적되는 현상을 수학적으로 모델링하고, 단계별 누적오차의 닫힌형 해를 유도한 뒤, 타임스텝 인지 누적오차 보정(timestep-aware compensation)을 제안하여 저정밀(diffusion) 모델의 샘플 품질을 획기적으로 개선함.


<details>
  <summary>Details</summary>
Motivation: 확률적 반복 복원 과정이 필요한 Diffusion Models는 샘플링 비용이 크고, PTQ는 가속에 유리하나 각 샘플링 스텝에서 양자화 오차가 누적되어 결과 화질이 급격히 저하되는 문제가 있음. 이를 이론적으로 해석하고 보정하는 기법이 필요함.

Method: 각 샘플링 스텝의 양자화 오차 전파를 수식화하여 per-step 전파 방정식을 도출하고, 전체 누적오차에 대한 닫힌형 해를 제시함. 이 해를 바탕으로 타임스텝에 따라 보정량을 달리 적용하는 누적오차 보정 기법을 설계하고, 기존 PTQ 파이프라인에 통합하여 저정밀 환경에서 보정을 수행함.

Result: 여러 이미지 데이터셋에서 실험하여 제안한 보정 기법이 기존 PTQ 방법들의 성능을 크게 향상시켰으며, 저비트(low-precision) 확산 모델에서 SOTA 수준의 샘플 품질을 달성함.

Conclusion: 이론적 오차 모델링과 타임스텝 인지 보정은 반복적 샘플링에서의 양자화 누적오차를 효과적으로 완화하여 실용적 저정밀 확산 모델 배포에 기여함.

Abstract: Diffusion models have transformed image synthesis by establishing
unprecedented quality and creativity benchmarks. Nevertheless, their
large-scale deployment faces challenges due to computationally intensive
iterative denoising processes. Although post-training quantization(PTQ)
provides an effective pathway for accelerating sampling, the iterative nature
of diffusion models causes stepwise quantization errors to accumulate
progressively during generation, inevitably compromising output fidelity. To
address this challenge, we develop a theoretical framework that mathematically
formulates error propagation in Diffusion Models (DMs), deriving per-step
quantization error propagation equations and establishing the first closed-form
solution for cumulative error. Building on this theoretical foundation, we
propose a timestep-aware cumulative error compensation scheme. Extensive
experiments across multiple image datasets demonstrate that our compensation
strategy effectively mitigates error propagation, significantly enhancing
existing PTQ methods to achieve state-of-the-art(SOTA) performance on
low-precision diffusion models.

</details>


### [38] [VELVET-Med: Vision and Efficient Language Pre-training for Volumetric Imaging Tasks in Medicine](https://arxiv.org/abs/2508.12108)
*Ziyang Zhang,Yang Yu,Xulei Yang,Si Yong Yeo*

Main category: cs.CV

TL;DR: VELVET-Med는 제한된 3D 볼륨(예: CT)과 소견문 쌍(38,875건)만으로 효과적인 비전-언어 사전학습을 수행하는 프레임워크다. 유니모달 자기지도학습을 VLP에 통합하고, 다층적 텍스트 표현을 위한 TriBERT와 다층 계층적 콘트라스티브 학습을 도입해 공간·의미적 대응을 학습한다. 결과적으로 3D 분할, 크로스모달 검색, VQA, 소견문 생성 등에서 SOTA 성능을 달성한다.


<details>
  <summary>Details</summary>
Motivation: 의료 영상(특히 3D 볼륨 CT)과 텍스트 쌍을 대규모로 수집하기 어렵고 비용이 크기 때문에, 제한된 페어드 데이터로도 강건한 비전-언어 표현을 학습할 방법이 필요하다. 기존 VLM 문헌은 2D 일반도메인 중심이고, 유니모달 자기지도학습을 VLP에 결합한 연구는 드물다.

Method: 1) 유니모달 자기지도학습을 VLP 파이프라인에 통합해 각 모달의 표현력을 강화한다. 2) TriBERT라는 언어 인코더를 도입해 다층(예: 토큰·문장·문서 수준) 텍스트 의미를 학습한다. 3) 계층적(단계적·다수 수준) 콘트라스티브 학습을 설계해 다층 시각-언어 대응을 포착한다. 전체 학습은 38,875개의 CT-레포트 페어로 수행된다.

Result: 제안된 인코더는 제한된 데이터로 학습했음에도 불구하고 여러 다운스트림 의료 과제(3D 분할, 크로스모달 검색, VQA, 레포트 생성)에서 기존 방법을 능가하는 최첨단 성능을 보였다.

Conclusion: 유니모달 자기지도학습과 다층적 언어 인코더, 계층적 콘트라스티브 학습을 결합하면 소규모 볼륨 의료 데이터로도 강력한 VLP가 가능하다. VELVET-Med는 제한된 데이터 환경에서의 일반화성과 전이능력을 크게 향상시키며, 향후 의료 VLM 연구에서 유용한 설계 원칙을 제시한다.

Abstract: Vision-and-language models (VLMs) have been increasingly explored in the
medical domain, particularly following the success of CLIP in general domain.
However, unlike the relatively straightforward pairing of 2D images and text,
curating large-scale paired data in the medical field for volumetric modalities
such as CT scans remains a challenging and time-intensive process. This
difficulty often limits the performance on downstream tasks. To address these
challenges, we propose a novel vision-language pre-training (VLP) framework,
termed as \textbf{VELVET-Med}, specifically designed for limited volumetric
data such as 3D CT and associated radiology reports. Instead of relying on
large-scale data collection, our method focuses on the development of effective
pre-training objectives and model architectures. The key contributions are: 1)
We incorporate uni-modal self-supervised learning into VLP framework, which are
often underexplored in the existing literature. 2) We propose a novel language
encoder, termed as \textbf{TriBERT}, for learning multi-level textual
semantics. 3) We devise the hierarchical contrastive learning to capture
multi-level vision-language correspondence. Using only 38,875 scan-report
pairs, our approach seeks to uncover rich spatial and semantic relationships
embedded in volumetric medical images and corresponding clinical narratives,
thereby enhancing the generalization ability of the learned encoders. The
resulting encoders exhibit strong transferability, achieving state-of-the-art
performance across a wide range of downstream tasks, including 3D segmentation,
cross-modal retrieval, visual question answering, and report generation.

</details>


### [39] [Simple o3: Towards Interleaved Vision-Language Reasoning](https://arxiv.org/abs/2508.12109)
*Ye Wang,Qianglong Chen,Zejun Li,Siyuan Wang,Shijie Guo,Zhirui Zhang,Zhongyu Wei*

Main category: cs.CV

TL;DR: MLLM에 인터리브된 도구 기반 시각-언어 추론(크롭·확대·재사용)을 도입한 Simple o3는 SFT 기반의 데이터 합성(observe-reason-act)과 TWI-Tools-146K 데이터셋으로 학습되어 다양한 벤치마크에서 기존 방법을 앞서며 세부 시각 추론 능력을 크게 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 기존 MLLM은 시각-언어 문제에서 성능이 좋지만, 긴 체인 오브 생각(Chain-of-Thought, CoT)을 요구하는 멀티모달 추론—특히 반복적 이미지 조작(크롭/확대/재사용 등)과 언어적 추론을 섞어 쓰는—능력은 충분히 연구되지 않았다. OpenAI의 o3가 제시한 ‘이미지로 생각하기’(thinking with image) 개념을 확장하고 실용적·경량화된 방법을 제안하려는 동기다.

Method: Simple o3는 다음을 포함한다: (1) 인터리브된 시각-언어 추론을 위해 동적 도구(크롭, 줌, 재사용)를 모델 입력/출력 흐름에 통합; (2) 감독적 파인튜닝(SFT)을 위한 대규모 합성 파이프라인—observe-reason-act 사이클로 시각 조작 명령과 검증을 포함한 추론 체인 생성; (3) TWI-Tools-146K 공개 데이터셋 제공; (4) 추가 시각 토큰 도입으로 원본 이미지의 재사용·확대 및 정밀한 시각적 그라운딩 기반 크롭 전략을 학습시켜 세부 인지 능력 향상.

Result: 여러 벤치마크에서 기존 방법들보다 우수한 성능을 보고한다. 재사용·확대는 시각적 추론과 미세 인지 능력을 크게 향상시키고, 그라운딩 기반의 정확한 크롭은 핵심 객체·영역에 집중하는 데 유효함을 실험적으로 입증했다. 또한 다양한 인터리브 전략에 대한 첫 심층 분석을 제공한다.

Conclusion: Simple o3는 계산적으로 부담이 크지 않은 방식으로 멀티모달 장기 추론 능력을 향상시키는 실용적 패러다임을 제시하며, 인터리브 전략(재사용·확대·크롭)의 상호보완적 이점을 규명해 향후 MLLM 설계에 실질적 가이드를 제공한다.

Abstract: Multimodal Large Language Models (MLLMs) have shown impressive performance on
vision-language tasks, but their long Chain-of-Thought (CoT) capabilities in
multimodal scenarios remain underexplored. Inspired by OpenAI's o3 model, which
emulates human-like ''thinking with image'' through iterative visual
transformations and linguistic reasoning, we propose Simple o3, an end-to-end
framework that integrates dynamic tool interactions (e.g., cropping, zooming,
and reusing) into interleaved vision-language reasoning via supervised
fine-tuning (SFT). Our approach features a scalable data synthesis pipeline
that generates high-quality interleaved vision-language reasoning chains via an
''observe-reason-act'' cycle, complete with executable visual operations and
rigorous verification, yielding the open-source TWI-Tools-146K dataset.
Experimental results demonstrate Simple o3's superior performance on diverse
benchmarks, outperforming existing approaches. By combining enhanced reasoning
capabilities, Simple o3 establishes a powerful yet computationally affordable
paradigm for advancing multimodal reasoning. Remarkably, we provide the first
in-depth analysis of different interleaved reasoning strategies, offering
insights into their impact on model performance. We found that by introducing
additional visual tokens for interleaved vision-language reasoning, reusing and
magnifying the original image significantly improves the model's visual
reasoning and fine-grained perception, while image cropping based on precise
visual grounding allows the model to effectively focus on key entities or
regions, further enhancing its capabilities.

</details>


### [40] [DualFit: A Two-Stage Virtual Try-On via Warping and Synthesis](https://arxiv.org/abs/2508.12131)
*Minh Tran,Johnmark Clements,Annie Prasanna,Tri Nguyen,Ngan Le*

Main category: cs.CV

TL;DR: DualFit는 두 단계의 하이브리드 VTON 파이프라인으로, 첫 단계에서 학습된 플로우 필드로 옷을 왜곡(warp)하여 정밀한 세부(로고·문자)를 보존하고, 두 번째 단계에서 보존 영역 입력과 인페인팅 마스크를 이용해 필요한 부분만 재생성하며 최종 이미지를 합성한다. 결과적으로 고주파 디테일과 시각적 자연스러움 사이의 균형을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 확산 기반(warp-free) 방법들이 지각 품질은 개선했지만 로고·프린트 같은 고주파 의류 디테일을 잘 보존하지 못해 브랜드 무결성과 신뢰성에 문제가 생긴다. 이를 해결해 온라인 패션에서 정확한 착용 시각화를 제공하려는 필요성이 있다.

Method: 두 단계 접근법: (1) 학습된 플로우 필드로 목표 의류를 인물에 정렬(워핑) — 고충실도 보존을 목표로 함. (2) 보존-충실도 기반의 트라이온 모듈이 워핑된 의류와 보존된 인물 영역을 블렌딩하여 최종 합성. 프로세스를 안내하기 위해 보존-영역 입력과 인페인팅 마스크를 도입해 의류 심선 주변 등 필요한 부분만 재생성하도록 제한한다.

Result: 질적 평가에서 DualFit은 시각적으로 이음새 없이 자연스러운 트라이온 이미지를 생성하면서 로고·문자 등 고주파 디테일을 충실히 유지한다고 주장한다. 재구성 정확도와 지각적 현실감 사이에서 균형을 달성했다.

Conclusion: 워핑 기반 보존과 선택적 재생성을 결합한 하이브리드 설계는 고주파 디테일 유지에 효과적이며, 기존 확산 기반 워프-프리 방법들의 약점을 보완할 수 있다.

Abstract: Virtual Try-On technology has garnered significant attention for its
potential to transform the online fashion retail experience by allowing users
to visualize how garments would look on them without physical trials. While
recent advances in diffusion-based warping-free methods have improved
perceptual quality, they often fail to preserve fine-grained garment details
such as logos and printed text elements that are critical for brand integrity
and customer trust. In this work, we propose DualFit, a hybrid VTON pipeline
that addresses this limitation by two-stage approach. In the first stage,
DualFit warps the target garment to align with the person image using a learned
flow field, ensuring high-fidelity preservation. In the second stage, a
fidelity-preserving try-on module synthesizes the final output by blending the
warped garment with preserved human regions. Particularly, to guide this
process, we introduce a preserved-region input and an inpainting mask, enabling
the model to retain key areas and regenerate only where necessary, particularly
around garment seams. Extensive qualitative results show that DualFit achieves
visually seamless try-on results while faithfully maintaining high-frequency
garment details, striking an effective balance between reconstruction accuracy
and perceptual realism.

</details>


### [41] [TriQDef: Disrupting Semantic and Gradient Alignment to Prevent Adversarial Patch Transferability in Quantized Neural Networks](https://arxiv.org/abs/2508.12132)
*Amira Guesmi,Bassem Ouni,Muhammad Shafique*

Main category: cs.CV

TL;DR: TriQDef는 QNN의 패치 기반 적대적 공격이 서로 다른 비트 폭으로 전이되는 것을 저지하기 위해 설계된 삼중(특징·그래디언트·학습 프로토콜) 정량화 인식 방어 기법이다. 중간 표현의 지각 유사성 및 입력 그래디언트의 구조·방향 정합을 불일치시켜 전이 성공률을 크게 낮춘다.


<details>
  <summary>Details</summary>
Motivation: QNN은 엣지 환경에서 효율적이지만, 국소적·고기여도 패치 공격은 비트 폭이 달라져도 놀랍도록 전이성이 높아 기존 방어들이 교차 비트 일반화에 실패한다. 이를 해결할 정량화-인식 방어가 필요하다.

Method: (1) Feature Disalignment Penalty(FDP): 중간 표현의 지각적 유사도를 벌점화해 의미적 일치를 깨트림. (2) Gradient Perceptual Dissonance Penalty(GPDP): Edge IoU와 HOG 코사인 지표로 비트 폭 간 입력 그래디언트의 구조·방향 합의를 최소화. (3) Joint Quantization-Aware Training: 공유 가중치로 여러 양자화 수준을 동시 학습시켜 위 벌점들을 적용.

Result: CIFAR-10 및 ImageNet 실험에서, TriQDef는 보지 않은 패치·양자화 조합에 대해 공격 성공률(ASR)을 40% 이상 감소시키면서 깨끗한 정확도는 높은 수준으로 유지함.

Conclusion: 의미적 정렬과 그래디언트의 지각적 정합을 동시에 교란하는 것이 QNN에서 패치 기반 공격의 비트 간 전이성을 완화하는 데 효과적이며, TriQDef는 이를 실무적으로 달성한다.

Abstract: Quantized Neural Networks (QNNs) are increasingly deployed in edge and
resource-constrained environments due to their efficiency in computation and
memory usage. While shown to distort the gradient landscape and weaken
conventional pixel-level attacks, it provides limited robustness against
patch-based adversarial attacks-localized, high-saliency perturbations that
remain surprisingly transferable across bit-widths. Existing defenses either
overfit to fixed quantization settings or fail to address this cross-bit
generalization vulnerability. We introduce \textbf{TriQDef}, a tri-level
quantization-aware defense framework designed to disrupt the transferability of
patch-based adversarial attacks across QNNs. TriQDef consists of: (1) a Feature
Disalignment Penalty (FDP) that enforces semantic inconsistency by penalizing
perceptual similarity in intermediate representations; (2) a Gradient
Perceptual Dissonance Penalty (GPDP) that explicitly misaligns input gradients
across bit-widths by minimizing structural and directional agreement via Edge
IoU and HOG Cosine metrics; and (3) a Joint Quantization-Aware Training
Protocol that unifies these penalties within a shared-weight training scheme
across multiple quantization levels. Extensive experiments on CIFAR-10 and
ImageNet demonstrate that TriQDef reduces Attack Success Rates (ASR) by over
40\% on unseen patch and quantization combinations, while preserving high clean
accuracy. Our findings underscore the importance of disrupting both semantic
and perceptual gradient alignment to mitigate patch transferability in QNNs.

</details>


### [42] [Infusing fine-grained visual knowledge to Vision-Language Models](https://arxiv.org/abs/2508.12137)
*Nikolaos-Antonios Ypsilantis,Kaifeng Chen,André Araujo,Ondřej Chum*

Main category: cs.CV

TL;DR: 대규모 대비학습 VLM을 도메인 특화 세밀 검색에 맞춰 미세조정하면서도 범용 멀티모달 성능 저하(망각)를 막는 규제 기반 미세조정 방법을 제안한다. 텍스트 데이터나 원본 텍스트 인코더 없이도 시각-텍스트 정렬을 유지하며 다양한 검색 벤치마크에서 우수한 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 사전학습된 VLM 임베딩은 강력하지만 세밀한(open-set) 시각 검색에서는 도메인별 주석을 이용한 미세조정이 필요하다. 단순 미세조정은 치명적 망각을 유발해 원래의 범용 및 교차모달 능력을 손상시킨다. 이를 해결할 방법이 필요하다.

Method: 연속학습(continual learning) 문헌에서 영감을 받아, 지식 보존을 위한 표준 규제기법들을 체계적으로 분석하고 효율적이며 실용적인 규제 조합 전략을 제안한다. 또한 재현성과 일반화를 위해 검증집합 설계와 하이퍼파라미터 튜닝 관행을 상세히 다루며, 텍스트 데이터나 원본 텍스트 인코더 없이 비전 인코더만으로 미세조정한다.

Result: 세밀/거칠기준의 이미지-이미지 및 이미지-텍스트 검색 벤치마크 전반에서 일관되게 강한 성능을 달성하고, 시각-텍스트 정렬을 유지한다. 코드와 체크포인트를 공개하여 재현 가능하다.

Conclusion: 제안된 미세조정 프로토콜은 도메인 특화 세밀 검색 성능을 높이는 동시에 사전학습된 VLM의 범용 멀티모달 능력을 보존한다. 구현은 실용적이며 여러 데이터셋과 사전학습 모델에서 견고하게 동작한다.

Abstract: Large-scale contrastive pre-training produces powerful Vision-and-Language
Models (VLMs) capable of generating representations (embeddings) effective for
a wide variety of visual and multimodal tasks. However, these pretrained
embeddings remain suboptimal for fine-grained open-set visual retrieval, where
state-of-the-art results require fine-tuning the vision encoder using annotated
domain-specific samples. Naively performing such fine-tuning typically leads to
catastrophic forgetting, severely diminishing the model's general-purpose
visual and cross-modal capabilities.
  In this work, we propose a fine-tuning method explicitly designed to achieve
optimal balance between fine-grained domain adaptation and retention of the
pretrained VLM's broad multimodal knowledge. Drawing inspiration from continual
learning literature, we systematically analyze standard regularization
techniques aimed at knowledge retention and propose an efficient and effective
combination strategy. Additionally, we address the commonly overlooked yet
critical aspects of validation set design and hyperparameter tuning to ensure
reproducibility and robust generalization across datasets and pretrained
models. We extensively evaluate our method on both fine-grained and
coarse-grained image-image and image-text retrieval benchmarks. Our approach
consistently achieves strong results, notably retaining the visual-text
alignment without utilizing any text data or the original text encoder during
fine-tuning. Code and model checkpoints: https://github.com/nikosips/infusing .

</details>


### [43] [KP-INR: A Dual-Branch Implicit Neural Representation Model for Cardiac Cine MRI Reconstruction](https://arxiv.org/abs/2508.12147)
*Donghang Lyu,Marius Staring,Mariya Doneva,Hildo J. Lamb,Nicola Pezzotti*

Main category: cs.CV

TL;DR: KP-INR은 k-공간에서 동작하는 이중 분기 INR로, 한 분기는 k-공간 좌표의 위치 임베딩을, 다른 분기는 해당 좌표의 지역 다중스케일 k-공간 특징을 학습해 상호작용을 통해 목표 k-공간 값을 복원한다. CMRxRecon2024 데이터셋에서 베이스라인보다 우수한 성능을 보였다.


<details>
  <summary>Details</summary>
Motivation: 심장 cine MRI의 촬영 시간을 줄이기 위해 빠른 획득(언더샘플링)이 널리 쓰이지만 이미지 품질 저하 문제가 발생한다. 최근 INR 기반 무감독 재구성은 유망하지만 기존 접근법은 좌표 기반 임베딩만 사용해 타겟 지점과 인접 문맥의 특징 표현을 간과한다는 한계가 있다.

Method: KP-INR은 k-공간에서 두 갈래의 신경망을 병렬로 운용한다. 첫 번째 분기는 k-공간 좌표의 positional embedding을 처리하고, 두 번째 분기는 해당 좌표에서 추출한 지역적 다중스케일 k-공간 특징을 학습한다. 두 분기 간의 교차 상호작용을 통해 각 좌표의 k-공간 값을 근사하여 복원 성능을 향상시킨다. 주로 Cartesian k-공간 데이터에 초점을 맞춘다.

Result: CMRxRecon2024 데이터셋 실험에서 KP-INR은 베이스라인 모델들보다 전반적으로 향상된 재구성 성능을 보였고, 특히 도전적인 Cartesian k-공간 조건에서 강한 성능을 나타냈다(구체적 수치 미기재).

Conclusion: k-공간 좌표 임베딩과 지역 다중스케일 특징의 결합은 언더샘플링된 cardiac cine MRI 복원에 유효하며, KP-INR은 해당 접근의 실용적 가능성을 보여준다. 향후에는 시간적 일관성, 계산 효율성, 다양한 스캐너·획득 패턴에서의 일반화 검증이 필요하다.

Abstract: Cardiac Magnetic Resonance (CMR) imaging is a non-invasive method for
assessing cardiac structure, function, and blood flow. Cine MRI extends this by
capturing heart motion, providing detailed insights into cardiac mechanics. To
reduce scan time and breath-hold discomfort, fast acquisition techniques have
been utilized at the cost of lowering image quality. Recently, Implicit Neural
Representation (INR) methods have shown promise in unsupervised reconstruction
by learning coordinate-to-value mappings from undersampled data, enabling
high-quality image recovery. However, current existing INR methods primarily
focus on using coordinate-based positional embeddings to learn the mapping,
while overlooking the feature representations of the target point and its
neighboring context. In this work, we propose KP-INR, a dual-branch INR method
operating in k-space for cardiac cine MRI reconstruction: one branch processes
the positional embedding of k-space coordinates, while the other learns from
local multi-scale k-space feature representations at those coordinates. By
enabling cross-branch interaction and approximating the target k-space values
from both branches, KP-INR can achieve strong performance on challenging
Cartesian k-space data. Experiments on the CMRxRecon2024 dataset confirms its
improved performance over baseline models and highlights its potential in this
field.

</details>


### [44] [Demystifying Foreground-Background Memorization in Diffusion Models](https://arxiv.org/abs/2508.12148)
*Jimmy Z. Di,Yiwei Lu,Yaoliang Yu,Gautam Kamath,Adam Dziedzic,Franziska Boenisch*

Main category: cs.CV

TL;DR: FB-Mem이라는 분할 기반 지표를 제안해 확률적 생성 모델(확산모델)의 부분적·지역적 암기 현상을 정량화한다. 결과: 암기는 기존 생각보다 광범위하며, 단일 생성물이 여러 훈련 이미지 클러스터와 연결되는 패턴을 보이고, 신경 유닛 비활성화·가지치기 같은 기존 완화법은 특히 전경 영역의 지역적 암기를 제거하지 못한다. 군집 기반 완화법을 제안해 성능을 개선한다.


<details>
  <summary>Details</summary>
Motivation: 기존 검출 방법은 훈련 이미지의 완전 복제(verbatim)를 찾아내지만, 소규모 이미지 영역에서 발생하는 부분적 암기(지역적 암기)와 단일 프롬프트-이미지 쌍을 넘는 암기 패턴(클러스터링 형태)을 포착하지 못한다는 문제의식에서 출발한다.

Method: 생성 이미지의 전경/배경 분할을 활용해 암기 영역을 분류·정량화하는 'Foreground Background Memorization (FB‑Mem)' 지표를 도입한다. 생성물과 훈련 집합 사이의 유사도 분석 및 클러스터링을 통해 한 생성물이 여러 유사 훈련 이미지 군집과 연결되는지 탐지한다. 또한 기존 완화법(뉴런 비활성화, 가지치기 등)의 효과를 실험적으로 평가하고, 클러스터 기반 완화 방법을 제안한다.

Result: (1) 암기는 보다 광범위하고 미시적이며, 특히 전경에서 강하게 나타난다. (2) 단일 생성물이 다수의 유사 훈련 이미지 클러스터와 연결되는 복잡한 암기 패턴이 관찰된다. (3) 뉴런 비활성화·프루닝은 지역적 암기를 완전히 제거하지 못했으나, 제안한 클러스터 기반 완화법은 암기 감소에 더 효과적이었다.

Conclusion: FB‑Mem은 확산모델의 지역적·부분적 암기를 측정하는 실용적 프레임워크를 제공하며, 기존의 모델 수준 완화책이 불충분하다는 점을 보여준다. 향후엔 전경 중심의 방어 설계와 클러스터 기반 완화 전략의 추가 연구가 필요하다.

Abstract: Diffusion models (DMs) memorize training images and can reproduce
near-duplicates during generation. Current detection methods identify verbatim
memorization but fail to capture two critical aspects: quantifying partial
memorization occurring in small image regions, and memorization patterns beyond
specific prompt-image pairs. To address these limitations, we propose
Foreground Background Memorization (FB-Mem), a novel segmentation-based metric
that classifies and quantifies memorized regions within generated images. Our
method reveals that memorization is more pervasive than previously understood:
(1) individual generations from single prompts may be linked to clusters of
similar training images, revealing complex memorization patterns that extend
beyond one-to-one correspondences; and (2) existing model-level mitigation
methods, such as neuron deactivation and pruning, fail to eliminate local
memorization, which persists particularly in foreground regions. Our work
establishes an effective framework for measuring memorization in diffusion
models, demonstrates the inadequacy of current mitigation approaches, and
proposes a stronger mitigation method using a clustering approach.

</details>


### [45] [RealTalk: Realistic Emotion-Aware Lifelike Talking-Head Synthesis](https://arxiv.org/abs/2508.12163)
*Wenqing Wang,Yun Fu*

Main category: cs.CV

TL;DR: RealTalk는 오디오로부터 VAE로 3D 얼굴 랜드마크를 생성하고 감정 임베딩과 ResNet 기반 랜드마크 변형 모델로 감정 랜드마크를 만들며, 랜드마크와 블렌드쉐이프 계수를 tri‑plane attention NeRF에 함께 조건화하여 감정 정확도·제어성·정체성 보존이 우수한 감정 말하는 얼굴을 합성한다.


<details>
  <summary>Details</summary>
Motivation: 기존 기법은 입술 동기화와 화질은 좋지만, 감정 표현의 정확성·제어성 확보와 원본 인물 정체성 보존을 동시에 달성하지 못함. 사회적 인공지능에 필요한 신뢰할 수 있는 감정 합성 기법 요구.

Method: 1) VAE를 사용해 드라이빙 오디오로부터 3D 얼굴 랜드마크 생성. 2) 감정 라벨 임베딩을 랜드마크에 연결하고 ResNet 기반의 랜드마크 변형 모델(LDM)로 감정 랜드마크 생성. 3) 생성된 감정 랜드마크와 얼굴 블렌드쉐이프 계수를 공동 조건으로 하는 tri‑plane attention NeRF를 통해 고해상도 감정 말하는 얼굴 합성.

Result: 광범위한 실험에서 기존 방법 대비 감정 정확도, 감정 제어성, 인물 정체성 보존 면에서 우수한 성능을 보였음(논문 본문에서 정량·정성 비교 제시).

Conclusion: RealTalk는 감정 표현의 정확성과 제어성, 정체성 보존을 동시에 개선하여 사회적 AI의 감정 합성 능력을 발전시킴. 추가로 실시간성, 다양한 감정·인물 일반화, 시간적 일관성 검증 등이 후속 연구로 필요함.

Abstract: Emotion is a critical component of artificial social intelligence. However,
while current methods excel in lip synchronization and image quality, they
often fail to generate accurate and controllable emotional expressions while
preserving the subject's identity. To address this challenge, we introduce
RealTalk, a novel framework for synthesizing emotional talking heads with high
emotion accuracy, enhanced emotion controllability, and robust identity
preservation. RealTalk employs a variational autoencoder (VAE) to generate 3D
facial landmarks from driving audio, which are concatenated with emotion-label
embeddings using a ResNet-based landmark deformation model (LDM) to produce
emotional landmarks. These landmarks and facial blendshape coefficients jointly
condition a novel tri-plane attention Neural Radiance Field (NeRF) to
synthesize highly realistic emotional talking heads. Extensive experiments
demonstrate that RealTalk outperforms existing methods in emotion accuracy,
controllability, and identity preservation, advancing the development of
socially intelligent AI systems.

</details>


### [46] [Scalable RF Simulation in Generative 4D Worlds](https://arxiv.org/abs/2508.12176)
*Zhiwei Zheng,Dongyin Hu,Mingmin Zhao*

Main category: cs.CV

TL;DR: WaveVerse는 텍스트/공간 제약으로 조건화된 4D 장면과 인간 동작을 생성하고, 위상 일관성(phase coherence)을 유지하는 레이 트레이싱 기반 RF 시뮬레이터로 현실적 RF 신호 데이터를 대규모로 합성하여 RF 이미징과 활동 인식 성능을 향상시키는 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 실내 환경에서 프라이버시를 지키면서도 다양한 동적 상황의 고품질 RF 데이터를 확보하기 어렵고, 특히 위상 일관성을 갖춘 RF 신호의 시뮬레이션이 부족해 ML 모델 학습과 응용에 한계가 있다.

Method: 언어 유도 4D 월드 제너레이터(공간 제약·텍스트로 조건화된 상태-인식 인과적 트랜스포머 기반 인간 동작 생성)와 위상 일관성을 보장하는 레이 트레이싱 RF 시뮬레이터를 결합한 prompt 기반 스케일러블 데이터 합성 파이프라인을 제안한다.

Result: 조건화된 인간 동작 생성이 효과적이며, 위상 일관성은 빔포밍 및 호흡 모니터링 같은 응용에서 실질적인 이득을 보였고, 고해상도 RF 이미징과 인간 활동 인식의 두 사례 연구에서 데이터가 제한적이거나 충분한 상황 모두에서 성능 향상을 입증했다.

Conclusion: WaveVerse는 RF 이미징을 위한 데이터 생성(처음으로 시도한 영역 포함)을 가능하게 하고, 실제 ML 태스크에서 일관된 성능 향상을 제공해 RF 센싱 연구와 응용을 가속화할 수 있는 유용한 합성 데이터 솔루션이다.

Abstract: Radio Frequency (RF) sensing has emerged as a powerful, privacy-preserving
alternative to vision-based methods for indoor perception tasks. However,
collecting high-quality RF data in dynamic and diverse indoor environments
remains a major challenge. To address this, we introduce WaveVerse, a
prompt-based, scalable framework that simulates realistic RF signals from
generated indoor scenes with human motions. WaveVerse introduces a
language-guided 4D world generator, which includes a state-aware causal
transformer for human motion generation conditioned on spatial constraints and
texts, and a phase-coherent ray tracing simulator that enables the simulation
of accurate and coherent RF signals. Experiments demonstrate the effectiveness
of our approach in conditioned human motion generation and highlight how phase
coherence is applied to beamforming and respiration monitoring. We further
present two case studies in ML-based high-resolution imaging and human activity
recognition, demonstrating that WaveVerse not only enables data generation for
RF imaging for the first time, but also consistently achieves performance gain
in both data-limited and data-adequate scenarios.

</details>


### [47] [Splat Feature Solver](https://arxiv.org/abs/2508.12216)
*Butian Xiong,Rong Liu,Kenneth Xu,Meida Chen,Andrew Feng*

Main category: cs.CV

TL;DR: 본 논문은 이미지 기반 풍부한 특징(예: DINO, CLIP)을 스플랫(splat) 기반 3D 표현에 부착하는 'feature lifting' 문제를 희소 선형 역문제로 통일하여 닫힌 해로 효율적으로 풀이한다. 볼록 손실에 대해 전역 최적 오차의 상한을 제공하고, 불일치와 노이즈를 처리하기 위해 Tikhonov Guidance(수치적 안정성)와 Post-Lifting Aggregation(특징 클러스터링)을 도입한다. 실험에서 오픈보캐뷸러리 3D 분할 데이터셋에서 SOTA 성능을 보이며 수분 내로 특징을 생성한다.


<details>
  <summary>Details</summary>
Motivation: 멀티뷰 이미지에서 얻은 풍부한 일반화된 이미지 특징을 스플랫 같은 3D 프리미티브에 안정적으로 부착하려면, 뷰 간 불일치와 노이즈를 처리하면서 일반성·효율성·정확성을 동시에 달성하는 방법이 필요하다.

Method: 모든 커널 및 피처 타입에 대해 적용 가능한 통일된 희소 선형 역문제로 문제를 정식화하고, 닫힌 해를 이용해 효율적 해를 계산한다. 볼록 손실 하에서 전역 최적 오차 상한을 증명한다. 불안정성/노이즈 관리를 위해 두 가지 정규화 기법을 도입: (1) Tikhonov Guidance로 소프트 대각우세성을 강제해 수치적 안정성 확보, (2) Post-Lifting Aggregation으로 특징 클러스터링을 통해 노이즈 필터링.

Result: 여러 오픈보캐뷸러리 3D 분할 벤치마크에서 기존의 학습 기반·그룹핑 기반·휴리스틱 기반 방법들을 능가하는 성능을 달성했고, 특징 생성 속도가 수분 내로 매우 빠르다.

Conclusion: 희소 선형 역문제 정식화와 두 가지 보강 전략의 결합으로 feature lifting의 정확성과 안정성을 크게 향상시켰으며, 실용적이고 확장 가능한 3D 분할 응용에 유의미한 기여를 제공한다.

Abstract: Feature lifting has emerged as a crucial component in 3D scene understanding,
enabling the attachment of rich image feature descriptors (e.g., DINO, CLIP)
onto splat-based 3D representations. The core challenge lies in optimally
assigning rich general attributes to 3D primitives while addressing the
inconsistency issues from multi-view images. We present a unified, kernel- and
feature-agnostic formulation of the feature lifting problem as a sparse linear
inverse problem, which can be solved efficiently in closed form. Our approach
admits a provable upper bound on the global optimal error under convex losses
for delivering high quality lifted features. To address inconsistencies and
noise in multi-view observations, we introduce two complementary regularization
strategies to stabilize the solution and enhance semantic fidelity. Tikhonov
Guidance enforces numerical stability through soft diagonal dominance, while
Post-Lifting Aggregation filters noisy inputs via feature clustering. Extensive
experiments demonstrate that our approach achieves state-of-the-art performance
on open-vocabulary 3D segmentation benchmarks, outperforming training-based,
grouping-based, and heuristic-forward baselines while producing the lifted
features in minutes. Code is available at
\href{https://github.com/saliteta/splat-distiller.git}{\textbf{github}}. We
also have a \href{https://splat-distiller.pages.dev/}

</details>


### [48] [C2PSA-Enhanced YOLOv11 Architecture: A Novel Approach for Small Target Detection in Cotton Disease Diagnosis](https://arxiv.org/abs/2508.12219)
*Kaiyuan Wang,Jixing Liu,Xiaobo Cai*

Main category: cs.CV

TL;DR: 본 논문은 YOLOv11을 기반으로 한 목화 질병 검출기 개선을 제안한다. C2PSA로 소대상 특징을 강화하고, 동적 카테고리 가중치로 샘플 불균형을 처리하며, Mosaic-MixUp 스케일링으로 데이터 증강을 개선하여 mAP 및 현장 성능을 크게 향상시켰다.


<details>
  <summary>Details</summary>
Motivation: (1) 5mm^2 이하의 초기 병반에서 높은 누락률(35%)을 줄이고, (2) 야외 필드 환경에서의 성능 저하(정확도 25% 감소)를 보완하며, (3) 다병해 상황에서의 높은 오탐률(34.7%)을 낮추어 실시간 모니터링 및 정밀 처치가 가능한 시스템을 만드는 것.

Method: YOLOv11 구조를 개선: 소대상 특성 추출을 위한 C2PSA 모듈 도입, 클래스 불균형 대응을 위한 Dynamic category weighting, 데이터 다양성 확보를 위한 Mosaic-MixUp 스케일링 적용. 모바일 배포를 위해 경량화 및 추론 최적화 수행.

Result: 4,078장 데이터셋에서 mAP50=0.820 (+8.0%), mAP50-95=0.705 (+10.5%), 추론 속도 158 FPS 달성. 현장 실시간 질병 모니터링 및 정밀 처치 가능성을 보고.

Conclusion: 제안된 개선은 소형 병반 검출, 필드 강건성, 다병해 상황 처리 능력을 유의미하게 향상시켜 모바일 기반 실시간 농업 적용에 적합함을 시사한다.

Abstract: This study presents a deep learning-based optimization of YOLOv11 for cotton
disease detection, developing an intelligent monitoring system. Three key
challenges are addressed: (1) low precision in early spot detection (35%
leakage rate for sub-5mm2 spots), (2) performance degradation in field
conditions (25% accuracy drop), and (3) high error rates (34.7%) in
multi-disease scenarios. The proposed solutions include: C2PSA module for
enhanced small-target feature extraction; Dynamic category weighting to handle
sample imbalance; Improved data augmentation via Mosaic-MixUp scaling.
Experimental results on a 4,078-image dataset show: mAP50: 0.820 (+8.0%
improvement); mAP50-95: 0.705 (+10.5% improvement); Inference speed: 158 FPS.
The mobile-deployed system enables real-time disease monitoring and precision
treatment in agricultural applications.

</details>


### [49] [In vivo 3D ultrasound computed tomography of musculoskeletal tissues with generative neural physics](https://arxiv.org/abs/2508.12226)
*Zhijun Zeng,Youjia Zheng,Chang Su,Qianhang Wu,Hao Hu,Zeyuan Dong,Shan Gao,Yang Lv,Rui Tang,Ligang Cui,Zhiyong Hou,Weijun Lin,Zuoqiang Shi,Yubing Li,He Sun*

Main category: cs.CV

TL;DR: 강한 산란을 무시하는 기존 레이 기반 재구성의 한계를 넘기 위해, 생성 신경망과 물리 기반 신경 시뮬레이션을 결합한 ‘생성적 신경 물리(Generative neural physics)’ 프레임워크를 제안한다. 수십 장의 교차 모달리티 이미지만으로 초음파 파동 전파의 컴팩트한 대리모델을 학습해 고충실도 3D USCT를 10분 이내에 재구성하고, 근골격계 조직의 음향 물성 맵을 MRI 수준의 해상도로 얻는다.


<details>
  <summary>Details</summary>
Motivation: USCT는 방사선 위험이 없고 고해상도지만, 근골격계처럼 강한 산란이 있는 영역에서는 전통적 레이 기반 재구성이 부정확하여 정량 영상화가 제한된다. 계산량과 안정성 문제를 해결할 필요가 있다.

Method: 생성 네트워크와 물리 기반 신경 시뮬레이터를 결합. 수십 장의 교차 모달리티(예: MRI/초음파) 이미지만으로 파동전파의 컴팩트 서로게이트 모델을 학습해, 물리적 정확성(파동 모델링)과 딥러닝의 효율/안정성을 결합해 3D 파라미터 맵을 역문제 방식으로 재구성.

Result: 합성 데이터 및 in vivo(유방, 팔, 다리)에서 10분 미만의 연산으로 3D 조직 파라미터 지도(음속·임피던스 등 추정)를 얻었고, 근육·뼈의 생체역학적 특성에 민감하며 MRI와 유사한 해상도를 보임.

Conclusion: 강한 산란 영역에서의 계산 병목을 해소하여 USCT를 근골격계 질환의 임상적 정량 평가에 적용할 가능성을 크게 진전시킨다.

Abstract: Ultrasound computed tomography (USCT) is a radiation-free, high-resolution
modality but remains limited for musculoskeletal imaging due to conventional
ray-based reconstructions that neglect strong scattering. We propose a
generative neural physics framework that couples generative networks with
physics-informed neural simulation for fast, high-fidelity 3D USCT. By learning
a compact surrogate of ultrasonic wave propagation from only dozens of
cross-modality images, our method merges the accuracy of wave modeling with the
efficiency and stability of deep learning. This enables accurate quantitative
imaging of in vivo musculoskeletal tissues, producing spatial maps of acoustic
properties beyond reflection-mode images. On synthetic and in vivo data
(breast, arm, leg), we reconstruct 3D maps of tissue parameters in under ten
minutes, with sensitivity to biomechanical properties in muscle and bone and
resolution comparable to MRI. By overcoming computational bottlenecks in
strongly scattering regimes, this approach advances USCT toward routine
clinical assessment of musculoskeletal disease.

</details>


### [50] [WXSOD: A Benchmark for Robust Salient Object Detection in Adverse Weather Conditions](https://arxiv.org/abs/2508.12250)
*Quan Chen,Xiong Yang,Rongfeng Lu,Qianyu Zhang,Yu Liu,Xiaofei Zhou,Bolun Zheng*

Main category: cs.CV

TL;DR: 이 논문은 기상 잡음이 있는 환경에서의 주목 객체 검출(SOD)을 다루기 위해 기상 확장 SOD 데이터셋(WXSOD)을 제안하고, 날씨 인식 분기와 SOD 분기를 결합한 두-분기 네트워크 WFANet을 제시해 여러 기존 방법 대비 우수한 성능을 보였다고 보고한다.


<details>
  <summary>Details</summary>
Motivation: 기존 SOD 연구는 주로 잡음이 거의 없는 자연 장면에 초점을 맞추고 있으며, 비나 눈, 안개 등 기상 잡음이 성능에 미치는 영향과 이에 대한 데이터셋이 부족하다. 실제 환경에서의 일반화 문제를 해결하기 위해 기상 잡음이 포함된 픽셀 단위 주석 데이터셋이 필요하다.

Method: WXSOD 데이터셋(14,945 RGB 이미지, 픽셀 단위 GT, 기상 라벨 포함)을 구축하고, 합성 테스트셋(클린 이미지에 기상 잡음 추가)과 실제 기상 잡음으로 구성된 실측 테스트셋을 마련했다. 제안 네트워크 WFANet은 완전 지도(two-branch) 구조로, 기상 예측 분기에서 기상 관련 특징을 추출하고, SOD 분기에서 백본으로부터 추출된 의미 특징과 기상 특징을 융합하여 주목 객체를 검출한다.

Result: WXSOD 상에서 17개 기존 SOD 방법과 비교하여 WFANet이 우수한 성능을 기록했으며, 코드와 벤치마크 결과를 공개할 예정이라고 보고한다.

Conclusion: 기상 잡음에 강건한 SOD 연구를 촉진할 수 있는 대규모 데이터셋과효율적인 두-분기 기반의 강건한 기법을 제공하여 실환경 일반화 문제에 기여한다.

Abstract: Salient object detection (SOD) in complex environments remains a challenging
research topic. Most existing methods perform well in natural scenes with
negligible noise, and tend to leverage multi-modal information (e.g., depth and
infrared) to enhance accuracy. However, few studies are concerned with the
damage of weather noise on SOD performance due to the lack of dataset with
pixel-wise annotations. To bridge this gap, this paper introduces a novel
Weather-eXtended Salient Object Detection (WXSOD) dataset. It consists of
14,945 RGB images with diverse weather noise, along with the corresponding
ground truth annotations and weather labels. To verify algorithm
generalization, WXSOD contains two test sets, i.e., a synthesized test set and
a real test set. The former is generated by adding weather noise to clean
images, while the latter contains real-world weather noise. Based on WXSOD, we
propose an efficient baseline, termed Weather-aware Feature Aggregation Network
(WFANet), which adopts a fully supervised two-branch architecture.
Specifically, the weather prediction branch mines weather-related deep
features, while the saliency detection branch fuses semantic features extracted
from the backbone with weather features for SOD. Comprehensive comparisons
against 17 SOD methods shows that our WFANet achieves superior performance on
WXSOD. The code and benchmark results will be made publicly available at
https://github.com/C-water/WXSOD

</details>


### [51] [Superpixel-informed Continuous Low-Rank Tensor Representation for Multi-Dimensional Data Recovery](https://arxiv.org/abs/2508.12261)
*Zhizhou Wang,Ruijing Zheng,Zhenyu Wu,Jianli Wang*

Main category: cs.CV

TL;DR: SCTR proposes a superpixel-informed continuous low-rank tensor representation using asymmetric low-rank tensor factorization (ALTF) with a shared neural network and specialized heads, enabling non-grid continuous modeling and better local adaptation; reports 3–5 dB PSNR gains over prior LRTR methods on multispectral images, videos, and color images.


<details>
  <summary>Details</summary>
Motivation: Classical low-rank tensor methods assume global low-rankness and grid-based data; these assumptions fail in real-world data with strong spatial variations and non-meshgrid formats.

Method: Use superpixels as modeling units to exploit local semantic coherence; introduce ALTF where per-superpixel factor matrices are generated by a shared neural network with specialized heads, separating global pattern learning from local adaptation to produce a compact continuous representation.

Result: Extensive benchmarks across multispectral images, videos, and color images show consistent improvements of about 3–5 dB PSNR over existing LRTR-based approaches.

Conclusion: SCTR yields a more expressive and flexible LRTR framework that handles spatially varying and non-grid data, balancing efficiency and adaptability through superpixel modeling and asymmetric factorization.

Abstract: Low-rank tensor representation (LRTR) has emerged as a powerful tool for
multi-dimensional data processing. However, classical LRTR-based methods face
two critical limitations: (1) they typically assume that the holistic data is
low-rank, this assumption is often violated in real-world scenarios with
significant spatial variations; and (2) they are constrained to discrete
meshgrid data, limiting their flexibility and applicability. To overcome these
limitations, we propose a Superpixel-informed Continuous low-rank Tensor
Representation (SCTR) framework, which enables continuous and flexible modeling
of multi-dimensional data beyond traditional grid-based constraints. Our
approach introduces two main innovations: First, motivated by the observation
that semantically coherent regions exhibit stronger low-rank characteristics
than holistic data, we employ superpixels as the basic modeling units. This
design not only encodes rich semantic information, but also enhances
adaptability to diverse forms of data streams. Second, we propose a novel
asymmetric low-rank tensor factorization (ALTF) where superpixel-specific
factor matrices are parameterized by a shared neural network with specialized
heads. By strategically separating global pattern learning from local
adaptation, this framework efficiently captures both cross-superpixel
commonalities and within-superpixel variations. This yields a representation
that is both highly expressive and compact, balancing model efficiency with
adaptability. Extensive experiments on several benchmark datasets demonstrate
that SCTR achieves 3-5 dB PSNR improvements over existing LRTR-based methods
across multispectral images, videos, and color images.

</details>


### [52] [Region-Level Context-Aware Multimodal Understanding](https://arxiv.org/abs/2508.12263)
*Hongliang Wei,Xianqi Zhang,Xingtao Wang,Xiaopeng Fan,Debin Zhao*

Main category: cs.CV

TL;DR: MLLM에 객체 텍스트와 바운딩 박스를 통합해 영역 수준 문맥 인식(RCMU)을 수행하도록 학습하는 RCVIT 방법을 제안하고, 이를 위한 대규모 데이터셋(RCMU dataset), 벤치마크(RC&P-Bench), 참조-없는 평가 지표 및 Qwen2-VL 기반 RC-Qwen2-VL 모델을 공개하여 RCMU 성능과 응용성을 입증함.


<details>
  <summary>Details</summary>
Motivation: 기존 멀티모달 LLM 연구는 주로 일반적인 시각 이해에 초점을 맞추어, 객체에 연관된 텍스트 컨텍스트를 통합해 더 문맥 인식적인 응답을 생성하는 능력(영역 수준 문맥 인식, RCMU)을 간과함.

Method: 입력에 객체별 텍스트 정보와 바운딩 박스 좌표를 포함시키고, 바운딩 박스로 시각 콘텐츠와 텍스트 정보를 효과적으로 연결하도록 시각-언어 지시학습(Region-level Context-aware Visual Instruction Tuning, RCVIT)을 수행. RCMU 과제들을 포함한 대규모 튜닝 데이터셋과 평가 벤치마크를 함께 제시.

Result: RC-Qwen2-VL 모델들이 여러 RCMU 과제에서 우수한 성능을 보였고, 멀티모달 RAG 및 개인화 대화 같은 실용적 응용에서도 성공적으로 동작함. 추가로 참조-없는 세부 평가 지표로 영역 수준 설명의 질을 정밀 평가함.

Conclusion: RCVIT과 RCMU 데이터/벤치마크는 MLLM의 영역-수준 문맥 인식 능력을 크게 향상시키며, 제시된 데이터·모델·도구의 공개가 해당 연구 영역의 확장과 재현성을 촉진할 것임.

Abstract: Despite significant progress, existing research on Multimodal Large Language
Models (MLLMs) mainly focuses on general visual understanding, overlooking the
ability to integrate textual context associated with objects for a more
context-aware multimodal understanding -- an ability we refer to as
Region-level Context-aware Multimodal Understanding (RCMU). To address this
limitation, we first formulate the RCMU task, which requires models to respond
to user instructions by integrating both image content and textual information
of regions or objects. To equip MLLMs with RCMU capabilities, we propose
Region-level Context-aware Visual Instruction Tuning (RCVIT), which
incorporates object information into the model input and enables the model to
utilize bounding box coordinates to effectively associate objects' visual
content with their textual information. To address the lack of datasets, we
introduce the RCMU dataset, a large-scale visual instruction tuning dataset
that covers multiple RCMU tasks. We also propose RC\&P-Bench, a comprehensive
benchmark that can evaluate the performance of MLLMs in RCMU and multimodal
personalized understanding tasks. Additionally, we propose a reference-free
evaluation metric to perform a comprehensive and fine-grained evaluation of the
region-level context-aware image descriptions. By performing RCVIT on Qwen2-VL
models with the RCMU dataset, we developed RC-Qwen2-VL models. Experimental
results indicate that RC-Qwen2-VL models not only achieve outstanding
performance on multiple RCMU tasks but also demonstrate successful applications
in multimodal RAG and personalized conversation. Our data, model and benchmark
are available at https://github.com/hongliang-wei/RC-MLLM

</details>


### [53] [SNNSIR: A Simple Spiking Neural Network for Stereo Image Restoration](https://arxiv.org/abs/2508.12271)
*Ronghua Xu,Jin Xie,Jing Nie,Jiale Cao,Yanwei Pang*

Main category: cs.CV

TL;DR: 본 논문은 완전 스파이크 구동(spike-driven) 방식의 스테레오 이미지 복원용 SNN(SNNSIR)을 제안한다. 스파이크 호환 잔차 블록(SRBB), 스파이크 스테레오 컨볼루션 모듈(SSCM), 스파이크 스테레오 교차-어텐션(SSCA)를 도입해 이진 스파이크만으로 스테레오 복원(비, 물방울 제거, 저조도 향상, 초해상도)에서 경쟁력 있는 성능과 저전력 계산을 달성한다.


<details>
  <summary>Details</summary>
Motivation: SNN은 이진 이벤트 기반 스파이킹으로 저전력·고효율 연산이 가능한 반면, 기존 연구는 혼합 SNN-ANN 구조로 부동소수점 연산(나눗셈, 지수 등)에 의존해 스파이크 기반 하드웨어와의 정합성이 떨어진다. 따라서 완전한 스파이크-드리븐 아키텍처로 실시간·저전력 스테레오 복원을 구현할 필요가 있다.

Method: 이진 스파이크 뉴런의 표현력 한계를 보완하기 위해: (1) 정보 흐름을 개선하는 경량 Spike Residual Basic Block(SRBB)을 도입, (2) 요소별 곱셈 기반의 단순 비선형성을 사용하는 Spike Stereo Convolutional Modulation(SSCM)으로 교차-뷰 민감 영역을 강조, (3) 스파이크 호환 방식으로 양방향 특징 상호작용을 가능하게 하는 Spike Stereo Cross-Attention(SSCA)를 설계. 전체 모델은 완전 스파이크-드리븐으로 설계되어 부동소수점의 고비용 연산을 회피한다.

Result: 비·물방울 제거, 저조도 향상, 초해상도 등 다양한 스테레오 복원 과제에서 경쟁력 있는 복원 성능을 보이면서 계산 비용을 크게 절감했다(실험적 수치 미제시된 초록 기준). 이는 실시간 저전력 스테레오 비전 적용 가능성을 시사한다.

Conclusion: SNNSIR은 스파이크 기반 연산만으로 실용적 수준의 스테레오 이미지 복원을 달성할 수 있음을 보여준다. 하드웨어 친화적이고 저전력인 점이 장점이나, 스파이크 뉴런의 표현력 한계·정밀도/품질 격차·하드웨어 실험 부재 등은 후속 검증이 필요하다.

Abstract: Spiking Neural Networks (SNNs), characterized by discrete binary activations,
offer high computational efficiency and low energy consumption, making them
well-suited for computation-intensive tasks such as stereo image restoration.
In this work, we propose SNNSIR, a simple yet effective Spiking Neural Network
for Stereo Image Restoration, specifically designed under the spike-driven
paradigm where neurons transmit information through sparse, event-based binary
spikes. In contrast to existing hybrid SNN-ANN models that still rely on
operations such as floating-point matrix division or exponentiation, which are
incompatible with the binary and event-driven nature of SNNs, our proposed
SNNSIR adopts a fully spike-driven architecture to achieve low-power and
hardware-friendly computation. To address the expressiveness limitations of
binary spiking neurons, we first introduce a lightweight Spike Residual Basic
Block (SRBB) to enhance information flow via spike-compatible residual
learning. Building on this, the Spike Stereo Convolutional Modulation (SSCM)
module introduces simplified nonlinearity through element-wise multiplication
and highlights noise-sensitive regions via cross-view-aware modulation.
Complementing this, the Spike Stereo Cross-Attention (SSCA) module further
improves stereo correspondence by enabling efficient bidirectional feature
interaction across views within a spike-compatible framework. Extensive
experiments on diverse stereo image restoration tasks, including rain streak
removal, raindrop removal, low-light enhancement, and super-resolution
demonstrate that our model achieves competitive restoration performance while
significantly reducing computational overhead. These results highlight the
potential for real-time, low-power stereo vision applications. The code will be
available after the article is accepted.

</details>


### [54] [TSLA: A Task-Specific Learning Adaptation for Semantic Segmentation on Autonomous Vehicles Platform](https://arxiv.org/abs/2508.12279)
*Jun Liu,Zhenglun Kong,Pu Zhao,Weihao Zeng,Hao Tang,Xuan Shen,Changdi Yang,Wenbin Zhang,Geng Yuan,Wei Niu,Xue Lin,Yanzhi Wang*

Main category: cs.CV

TL;DR: 자율주행용 시맨틱 세그멘테이션 모델을 하드웨어 제약(예: DRIVE PX2)에 맞춰 세분화된 제어(폭 배수, 분류기 깊이, 분류기 커널)로 조정하고, 베이지안 최적화를 통해 계산 예산 내에서 하이퍼파라미터를 탐색해 다양한 작업·시나리오에 맞는 MACs 스케일의 Task-Specific Learning Adaptation(TSLA)를 생성한다.


<details>
  <summary>Details</summary>
Motivation: 임베디드 자율주행 플랫폼은 제한된 연산 자원과 다양한 정확도 요구를 가지므로, 타깃 하드웨어와 주행 시나리오에 맞춰 모델을 맞춤화해 계산 비용을 고려한 배포가 필요하다.

Method: 세 가지 제어 축(폭 배수, 분류기 깊이, 분류기 커널)을 도입해 모델 구성 요소를 세밀하게 조정하고, 베이지안 최적화(대리모델)를 사용해 제한된 계산 예산 하에서 하이퍼파라미터 공간을 효율적으로 탐색한다. 이를 통해 MACs을 스케일링하고 최종 레이어와 커널 크기를 시나리오 특화로 튜닝한다.

Result: 하드웨어 제약과 작업 요구사항에 맞춘 여러 대안 구성(TSLA)을 얻어 하드웨어 활용도를 높이고 정확도-연산량 트레이드오프를 개선한다. 제한된 예산 내에서 효율적 탐색으로 실용적 구성 획득이 가능하다.

Conclusion: 제안 방법은 자율주행용 세그멘테이션 모델을 플랫폼·시나리오별로 자동 최적화해 계산 자원을 최대한 활용하면서 성능을 향상시키며, 임베디드 타깃(예: DRIVE PX2)에 실전 배포하기에 적합하다.

Abstract: Autonomous driving platforms encounter diverse driving scenarios, each with
varying hardware resources and precision requirements. Given the computational
limitations of embedded devices, it is crucial to consider computing costs when
deploying on target platforms like the NVIDIA\textsuperscript{\textregistered}
DRIVE PX 2. Our objective is to customize the semantic segmentation network
according to the computing power and specific scenarios of autonomous driving
hardware. We implement dynamic adaptability through a three-tier control
mechanism -- width multiplier, classifier depth, and classifier kernel --
allowing fine-grained control over model components based on hardware
constraints and task requirements. This adaptability facilitates broad model
scaling, targeted refinement of the final layers, and scenario-specific
optimization of kernel sizes, leading to improved resource allocation and
performance.
  Additionally, we leverage Bayesian Optimization with surrogate modeling to
efficiently explore hyperparameter spaces under tight computational budgets.
Our approach addresses scenario-specific and task-specific requirements through
automatic parameter search, accommodating the unique computational complexity
and accuracy needs of autonomous driving. It scales its Multiply-Accumulate
Operations (MACs) for Task-Specific Learning Adaptation (TSLA), resulting in
alternative configurations tailored to diverse self-driving tasks. These TSLA
customizations maximize computational capacity and model accuracy, optimizing
hardware utilization.

</details>


### [55] [CLAIR: CLIP-Aided Weakly Supervised Zero-Shot Cross-Domain Image Retrieval](https://arxiv.org/abs/2508.12290)
*Chor Boon Tan,Conghui Hu,Gim Hee Lee*

Main category: cs.CV

TL;DR: CLAI R은 CLIP로 생성된 노이즈한 유사-라벨을 신뢰도 기반으로 정제하고, 인스턴스·클러스터·도메인 간 대조 손실과 CLIP 텍스트 임베딩을 이용한 폐쇄형(closed-form) 교차도메인 사상(mapping) 및 학습가능 프롬프트를 결합해 약지도(weakly supervised) 제로샷 교차도메인 이미지 검색 성능을 높이는 방법이다.


<details>
  <summary>Details</summary>
Motivation: 대규모 파운데이션 모델이 대량의 비라벨 데이터에 대해 의사(유사) 라벨을 쉽게 생성하면서, 완전한 비지도(UZS)보다 노이즈한 의사라벨을 다루는 약지도(WSZS-CDIR)가 현실적이고 중요해짐.

Method: (1) CLIP 텍스트·이미지 유사도로 각 의사라벨에 신뢰도(confidence) 부여 및 라벨 정제, (2) 인스턴스·클러스터 대조 손실로 클래스 인지(latent) 특징 학습, (3) 도메인 차이를 줄이는 도메인 간 대조 손실, (4) CLIP 텍스트 임베딩만으로 이미지 특징을 한 도메인에서 다른 도메인으로 투영하는 폐쇄형 교차도메인 매핑 학습, (5) 제로샷 일반화를 위한 추가 학습가능 프롬프트 도입.

Result: TUBerlin, Sketchy, QuickDraw, DomainNet 등의 제로샷 데이터셋에서 기존 SOTA를 일관되게 능가하는 성능을 보고.

Conclusion: CLAI R은 CLIP 기반 의사라벨의 노이즈를 신뢰도로 보완하고, 구조화된 대조학습 및 텍스트 기반 폐쇄형 매핑으로 도메인 간 정렬을 효과적으로 수행해 WSZS-CDIR에서 우수한 결과를 보인다.

Abstract: The recent growth of large foundation models that can easily generate
pseudo-labels for huge quantity of unlabeled data makes unsupervised Zero-Shot
Cross-Domain Image Retrieval (UZS-CDIR) less relevant. In this paper, we
therefore turn our attention to weakly supervised ZS-CDIR (WSZS-CDIR) with
noisy pseudo labels generated by large foundation models such as CLIP. To this
end, we propose CLAIR to refine the noisy pseudo-labels with a confidence score
from the similarity between the CLIP text and image features. Furthermore, we
design inter-instance and inter-cluster contrastive losses to encode images
into a class-aware latent space, and an inter-domain contrastive loss to
alleviate domain discrepancies. We also learn a novel cross-domain mapping
function in closed-form, using only CLIP text embeddings to project image
features from one domain to another, thereby further aligning the image
features for retrieval. Finally, we enhance the zero-shot generalization
ability of our CLAIR to handle novel categories by introducing an extra set of
learnable prompts. Extensive experiments are carried out using TUBerlin,
Sketchy, Quickdraw, and DomainNet zero-shot datasets, where our CLAIR
consistently shows superior performance compared to existing state-of-the-art
methods.

</details>


### [56] [Improving Densification in 3D Gaussian Splatting for High-Fidelity Rendering](https://arxiv.org/abs/2508.12313)
*Xiaobin Deng,Changyu Diao,Min Li,Ruohan Yu,Duanqing Xu*

Main category: cs.CV

TL;DR: Proposes an improved densification pipeline for 3D Gaussian Splatting using Edge-Aware Score for candidate selection, Long-Axis Split to reduce geometric distortion, and three overfitting-mitigation techniques (Recovery-Aware Pruning, Multi-step Update, Growth Control); achieves higher-fidelity rendering with fewer Gaussians and no extra training/inference cost.


<details>
  <summary>Details</summary>
Motivation: Current densification in 3D Gaussian Splatting leads to suboptimal reconstructions and geometric artifacts; need better criteria for splitting, splitting strategy to avoid distortions, and methods to prevent overfitting during growth.

Method: (1) Edge-Aware Score to select Gaussians near important edges for splitting. (2) Long-Axis Split that divides Gaussians along their principal axis to minimize distortion from clone/split. (3) Overfitting controls: Recovery-Aware Pruning to remove harmful Gaussians, Multi-step Update to stabilize parameter changes after splits, and Growth Control to regulate densification.

Result: Improves rendering fidelity and achieves state-of-the-art performance with fewer Gaussians; no additional training or inference overhead reported.

Conclusion: A focused redesign of the densification pipeline (selection, splitting, and overfitting mitigation) yields more accurate, efficient 3DGS reconstructions and better visual quality without extra runtime cost.

Abstract: Although 3D Gaussian Splatting (3DGS) has achieved impressive performance in
real-time rendering, its densification strategy often results in suboptimal
reconstruction quality. In this work, we present a comprehensive improvement to
the densification pipeline of 3DGS from three perspectives: when to densify,
how to densify, and how to mitigate overfitting. Specifically, we propose an
Edge-Aware Score to effectively select candidate Gaussians for splitting. We
further introduce a Long-Axis Split strategy that reduces geometric distortions
introduced by clone and split operations. To address overfitting, we design a
set of techniques, including Recovery-Aware Pruning, Multi-step Update, and
Growth Control. Our method enhances rendering fidelity without introducing
additional training or inference overhead, achieving state-of-the-art
performance with fewer Gaussians.

</details>


### [57] [Neural Cellular Automata for Weakly Supervised Segmentation of White Blood Cells](https://arxiv.org/abs/2508.12322)
*Michael Deutges,Chen Yang,Raheleh Salehi,Nassir Navab,Carsten Marr,Ario Sadafi*

Main category: cs.CV

TL;DR: NCA 분류기의 내부 feature map을 이용해 추가 학습 없이 약지도(weakly supervised)로 백혈구 분할 마스크를 추출하는 기법으로, 세 개의 현미경 데이터셋에서 기존 약지도 기법보다 우수한 성능을 보임.


<details>
  <summary>Details</summary>
Motivation: 의료 영상 분할에 필요한 픽셀 단위 레이블 획득은 비용과 시간이 많이 드므로, 분할 레이블 없이도 신뢰할 수 있는 마스크를 얻을 수 있는 약지도 기법이 필요함.

Method: Neural Cellular Automata(NCA)를 분류기로 학습한 뒤, NCA가 생성하는 feature map/activation을 분석하여 활성 영역을 추출하고 후처리(임계값, 형태학적 연산 등)로 분할 마스크를 생성함. 별도의 분할 레이블로 재학습하지 않음.

Result: 세 개의 백혈구 현미경 데이터셋에서 기존 약지도 분할 방법들보다 정량적(예: IoU/Dice 등)으로 우수한 성능을 기록함. 정성적 결과도 경계와 세포 형태를 잘 포착함을 제시함.

Conclusion: NCA는 분류와 분할 정보를 동시에 내포할 수 있어 약지도 분할에 유망한 방법임. 라벨 비용을 낮추면서 실용적인 의료 영상 분석 파이프라인에 적용 가능하지만, 일반화성·안정성·후처리 민감도 등에 대한 추가 분석이 필요함.

Abstract: The detection and segmentation of white blood cells in blood smear images is
a key step in medical diagnostics, supporting various downstream tasks such as
automated blood cell counting, morphological analysis, cell classification, and
disease diagnosis and monitoring. Training robust and accurate models requires
large amounts of labeled data, which is both time-consuming and expensive to
acquire. In this work, we propose a novel approach for weakly supervised
segmentation using neural cellular automata (NCA-WSS). By leveraging the
feature maps generated by NCA during classification, we can extract
segmentation masks without the need for retraining with segmentation labels. We
evaluate our method on three white blood cell microscopy datasets and
demonstrate that NCA-WSS significantly outperforms existing weakly supervised
approaches. Our work illustrates the potential of NCA for both classification
and segmentation in a weakly supervised framework, providing a scalable and
efficient solution for medical image analysis.

</details>


### [58] [Attention Pooling Enhances NCA-based Classification of Microscopy Images](https://arxiv.org/abs/2508.12324)
*Chen Yang,Michael Deutges,Jingsong Liu,Han Li,Nassir Navab,Carsten Marr,Ario Sadafi*

Main category: cs.CV

TL;DR: NCA에 어텐션 풀링을 결합해 현저히 성능을 끌어올리고, 파라미터 효율성과 설명가능성을 유지한 채 현장형 현미경 이미지 분류에서 기존 NCA와 경량 CNN/ViT 계열보다 우수한 성능을 보였다는 주장.


<details>
  <summary>Details</summary>
Motivation: Neural Cellular Automata는 해석성·로버스트함 측면에서 현미경 이미지 분석에 유망하지만, 복잡한 대형 모델들과 비교할 때 분류 성능에서 차이가 존재한다. 이 성능 격차를 줄이면서 NCA의 장점을 유지하려는 요구가 있음.

Method: NCA 모델에 attention pooling을 도입하여 이미지의 정보량이 큰 영역에 집중하도록 특징 추출을 정제함. 파라미터 수를 적게 유지하는 구조적 설계와 함께 8개의 다양한 현미경 이미지 데이터셋에서 실험을 수행하고, 기존 NCA 방법들과 경량 CNN·ViT 계열 모델들을 비교 평가.

Result: 제안한 NCA+attention pooling이 기존 NCA들보다 유의미하게 높은 분류 정확도를 기록했으며, 비교 대상으로 둔 경량 CNN·ViT보다도 우수한 성능을 보이되 파라미터 수는 현저히 낮음. 설명가능성도 유지된다고 보고.

Conclusion: 어텐션 풀링을 결합한 NCA는 파라미터 효율적이면서 설명 가능한 현미경 이미지 분류 대안으로 실용성이 높으며, 단순 NCA의 성능 한계를 효과적으로 완화함.

Abstract: Neural Cellular Automata (NCA) offer a robust and interpretable approach to
image classification, making them a promising choice for microscopy image
analysis. However, a performance gap remains between NCA and larger, more
complex architectures. We address this challenge by integrating attention
pooling with NCA to enhance feature extraction and improve classification
accuracy. The attention pooling mechanism refines the focus on the most
informative regions, leading to more accurate predictions. We evaluate our
method on eight diverse microscopy image datasets and demonstrate that our
approach significantly outperforms existing NCA methods while remaining
parameter-efficient and explainable. Furthermore, we compare our method with
traditional lightweight convolutional neural network and vision transformer
architectures, showing improved performance while maintaining a significantly
lower parameter count. Our results highlight the potential of NCA-based models
an alternative for explainable image classification.

</details>


### [59] [DoppDrive: Doppler-Driven Temporal Aggregation for Improved Radar Object Detection](https://arxiv.org/abs/2508.12330)
*Yuval Haitman,Oded Bialer*

Main category: cs.CV

TL;DR: DoppDrive는 도플러 정보를 이용해 레이더 과거 프레임 포인트를 방사 방향으로 보정하고 포인트별 집계 지속시간을 조정해 산란을 최소화하며 포인트 밀도를 높이는 사전 처리 기법이다.


<details>
  <summary>Details</summary>
Motivation: 레이더는 장거리 검출에 유리하지만 포인트 클라우드가 희박해 정확한 물체 검출이 어렵다. 기존의 시간적 집계는 자차 보정 후 동적 객체로부터 발생하는 산란을 유발해 성능을 저하시킨다.

Method: 과거 프레임 포인트의 동적 도플러 성분에 따라 방사 방향으로 이동시켜 방사 산란을 제거하고, 각 포인트에 대해 도플러 값과 각도를 이용해 고유한 집계 지속시간을 할당해 접선(방향) 산란을 최소화한다. 검출기 앞단의 밀도 향상 단계로 모든 검출기와 호환된다.

Result: 여러 검출기와 데이터셋에서 적용 시 포인트 밀도가 증가하고 물체 검출 성능이 유의미하게 향상됨을 보였다.

Conclusion: DoppDrive는 도플러 기반 보정으로 시간적 집계의 산란 문제를 완화하면서 범용적으로 적용 가능한 포인트 클라우드 밀도 향상 방법을 제시한다.

Abstract: Radar-based object detection is essential for autonomous driving due to
radar's long detection range. However, the sparsity of radar point clouds,
especially at long range, poses challenges for accurate detection. Existing
methods increase point density through temporal aggregation with ego-motion
compensation, but this approach introduces scatter from dynamic objects,
degrading detection performance. We propose DoppDrive, a novel Doppler-Driven
temporal aggregation method that enhances radar point cloud density while
minimizing scatter. Points from previous frames are shifted radially according
to their dynamic Doppler component to eliminate radial scatter, with each point
assigned a unique aggregation duration based on its Doppler and angle to
minimize tangential scatter. DoppDrive is a point cloud density enhancement
step applied before detection, compatible with any detector, and we demonstrate
that it significantly improves object detection performance across various
detectors and datasets.

</details>


### [60] [Geometry-Aware Video Inpainting for Joint Headset Occlusion Removal and Face Reconstruction in Social XR](https://arxiv.org/abs/2508.12336)
*Fatemeh Ghorbani Lohesara,Karen Eguiazarian,Sebastian Knorr*

Main category: cs.CV

TL;DR: 단일 RGB 뷰와 한 장의 비가림(occlusion)-프리 참조 프레임, 밀집 랜드마크 유도를 통해 HMD를 제거하고 3DMM 기반 완전한 3D 얼굴을 재구성하는, 기하 인지형 학습 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: HMD 착용으로 얼굴 상단이 가려지면 영상기반 원격회의 등 사회적 XR 애플리케이션에서 표정·시선 정보가 손실되어 상호작용과 몰입감이 크게 저하된다. 이를 RGB 단일 뷰에서 보정·복원하고 3D 얼굴을 재구성하고자 함.

Method: GAN 기반 비디오 인페인팅 네트워크를 사용하여 밀집 랜드마크와 단일 오클루전-프리 참조 프레임으로 결손 영역을 복원하고, 이어서 SynergyNet 계열 모듈로 인페인팅 프레임에서 3DMM 파라미터를 회귀해 3D 얼굴을 재구성한다. 파이프라인 전반에 걸쳐 밀집 랜드마크 최적화를 도입해 인페인팅 품질과 기하학적 충실도를 향상시켰다.

Result: 제안 프레임워크가 RGB 얼굴 영상에서 HMD를 제거하면서도 정체성(identity)과 현실감을 유지하며 포토리얼한 3D 얼굴 기하를 생성한다. 어블레이션 실험에서 랜드마크 밀도 변화에 대해 강건함을 보였음.

Conclusion: 밀집 랜드마크와 참조 프레임을 활용한 기하 인지형 인페인팅과 3DMM 회귀의 결합으로, HMD로 가려진 얼굴의 사실적 복원 및 3D 재구성이 가능하며 실사용 가능한 수준의 정체성 보존 성능을 보인다.

Abstract: Head-mounted displays (HMDs) are essential for experiencing extended reality
(XR) environments and observing virtual content. However, they obscure the
upper part of the user's face, complicating external video recording and
significantly impacting social XR applications such as teleconferencing, where
facial expressions and eye gaze details are crucial for creating an immersive
experience. This study introduces a geometry-aware learning-based framework to
jointly remove HMD occlusions and reconstruct complete 3D facial geometry from
RGB frames captured from a single viewpoint. The method integrates a GAN-based
video inpainting network, guided by dense facial landmarks and a single
occlusion-free reference frame, to restore missing facial regions while
preserving identity. Subsequently, a SynergyNet-based module regresses 3D
Morphable Model (3DMM) parameters from the inpainted frames, enabling accurate
3D face reconstruction. Dense landmark optimization is incorporated throughout
the pipeline to improve both the inpainting quality and the fidelity of the
recovered geometry. Experimental results demonstrate that the proposed
framework can successfully remove HMDs from RGB facial videos while maintaining
facial identity and realism, producing photorealistic 3D face geometry outputs.
Ablation studies further show that the framework remains robust across
different landmark densities, with only minor quality degradation under sparse
landmark configurations.

</details>


### [61] [Semantic Discrepancy-aware Detector for Image Forgery Identification](https://arxiv.org/abs/2508.12341)
*Ziye Wang,Minghang Yu,Chunyan Xu,Zhen Cui*

Main category: cs.CV

TL;DR: 이 논문은 사전학습된 비전-언어 모델의 개념 지식을 이용해 위조(포저리)와 의미적 개념 공간의 불일치를 정렬하는 새로운 탐지기 SDD를 제안한다. 시맨틱 토큰 샘플링으로 관련 없는 특징을 제거하고, 개념 수준 재구성 기반의 위조 불일치 학습과 저수준 특성 강화 모듈로 위조 흔적을 효과적으로 포착한다. 표준 데이터셋에서 기존 방법을 능가한다.


<details>
  <summary>Details</summary>
Motivation: 사전학습된 모델이 가진 의미적 개념은 위조 이미지 탐지에 중요하지만, 위조 특징 공간과 의미 개념 공간의 불일치로 인해 탐지 성능이 저해된다. 이를 해결해 더 정교한 위조 탐지를 가능하게 하려는 목적이다.

Method: (1) 시맨틱 토큰 샘플링 모듈로 비관련된 특징을 제거해 개념-위조 공간 간의 shift 완화, (2) 비쥬얼 재구성 패러다임 위에 구축된 개념 수준 위조 불일치 학습 모듈로 개념 기반의 위조-시맨틱 상호작용 강화, (3) 저수준 위조 특징 강화기로 학습된 개념 수준 불일치를 통합해 불필요한 위조 정보를 최소화.

Result: 두 개의 표준 이미지 위조 데이터셋에서 실험을 수행했으며, 제안한 SDD는 기존 방법들보다 우수한 성능을 보였다.

Conclusion: 개념 수준의 재구성 기반 불일치 학습과 시맨틱 토큰 샘플링을 결합하면 사전학습된 비전-언어 모델의 개념 지식을 위조 탐지에 효과적으로 활용할 수 있으며, 이는 위조 탐지 정확도를 향상시킨다.

Abstract: With the rapid advancement of image generation techniques, robust forgery
detection has become increasingly imperative to ensure the trustworthiness of
digital media. Recent research indicates that the learned semantic concepts of
pre-trained models are critical for identifying fake images. However, the
misalignment between the forgery and semantic concept spaces hinders the
model's forgery detection performance. To address this problem, we propose a
novel Semantic Discrepancy-aware Detector (SDD) that leverages reconstruction
learning to align the two spaces at a fine-grained visual level. By exploiting
the conceptual knowledge embedded in the pre-trained vision language model, we
specifically design a semantic token sampling module to mitigate the space
shifts caused by features irrelevant to both forgery traces and semantic
concepts. A concept-level forgery discrepancy learning module, built upon a
visual reconstruction paradigm, is proposed to strengthen the interaction
between visual semantic concepts and forgery traces, effectively capturing
discrepancies under the concepts' guidance. Finally, the low-level forgery
feature enhancemer integrates the learned concept level forgery discrepancies
to minimize redundant forgery information. Experiments conducted on two
standard image forgery datasets demonstrate the efficacy of the proposed SDD,
which achieves superior results compared to existing methods. The code is
available at https://github.com/wzy1111111/SSD.

</details>


### [62] [AquaFeat: A Features-Based Image Enhancement Model for Underwater Object Detection](https://arxiv.org/abs/2508.12343)
*Emanuel C. Silva,Tatiana T. Schein,Stephanie L. Brião,Guilherme L. M. Costa,Felipe G. Oliveira,Gustavo P. Almeida,Eduardo L. Silva,Sam S. Devincenzi,Karina S. Machado,Paulo L. J. Drews-Jr*

Main category: cs.CV

TL;DR: AquaFeat는 탐지기 손실로 직접 지도되는 다중 스케일의 플러그인 특성 향상 모듈로, YOLOv8m에 통합해 수중 객체 검출 성능(Precision 0.877, Recall 0.624, mAP@0.5 0.677, mAP@[0.5:0.95] 0.421)을 향상시키며 46.5 FPS의 실무적 속도를 유지한다.


<details>
  <summary>Details</summary>
Motivation: 수중 환경의 심한 영상 열화는 객체 검출 성능을 저하시키고, 기존의 영상 향상 기법은 일반적으로 시각 품질을 중심으로 최적화되어 검출 같은 다운스트림 작업에 최적화되어 있지 않다. 따라서 검출 성능을 직접 개선하도록 설계된 특성 수준의 향상 방법이 필요하다.

Method: 다중 스케일 특성 향상 네트워크를 플러그인 모듈로 제안하고, 이를 검출기(예: YOLOv8m)와 end-to-end로 결합해 검출기의 손실로 학습한다. 이렇게 하면 향상 과정이 검출에 직접적으로 관련된 피처를 정제하도록 유도된다. 아키텍처 상세(구성 블록, 삽입 위치, 손실 가중치 등)는 초록에 구체적이지 않다.

Result: 도전적인 수중 데이터셋에서 YOLOv8m과 통합 시 SOTA 수준의 Precision(0.877)과 Recall(0.624)을 달성했고, mAP@0.5=0.677, mAP@[0.5:0.95]=0.421을 보고했다. 처리 속도는 46.5 FPS로 실시간(또는 근실시간) 적용이 가능하다.

Conclusion: 검출 손실로 직접 감독되는 특성 레벨 향상은 수중 객체 검출에서 유의미한 이득을 주며, 정확도와 속도 간의 실용적 균형을 제공한다. 다만 재현성·일반화 가능성·비교 실험 등 추가 정보가 필요하다.

Abstract: The severe image degradation in underwater environments impairs object
detection models, as traditional image enhancement methods are often not
optimized for such downstream tasks. To address this, we propose AquaFeat, a
novel, plug-and-play module that performs task-driven feature enhancement. Our
approach integrates a multi-scale feature enhancement network trained
end-to-end with the detector's loss function, ensuring the enhancement process
is explicitly guided to refine features most relevant to the detection task.
When integrated with YOLOv8m on challenging underwater datasets, AquaFeat
achieves state-of-the-art Precision (0.877) and Recall (0.624), along with
competitive mAP scores (mAP@0.5 of 0.677 and mAP@[0.5:0.95] of 0.421). By
delivering these accuracy gains while maintaining a practical processing speed
of 46.5 FPS, our model provides an effective and computationally efficient
solution for real-world applications, such as marine ecosystem monitoring and
infrastructure inspection.

</details>


### [63] [MBMamba: When Memory Buffer Meets Mamba for Structure-Aware Image Deblurring](https://arxiv.org/abs/2508.12346)
*Hu Gao,Depeng Dang*

Main category: cs.CV

TL;DR: Mamba 기반 디블러에서 flatten-and-scan으로 인한 지역 픽셀 망각과 채널 중복 문제를 메모리 버퍼와 이징( Ising ) 영감 정규화 손실로 해결한 MBMamba를 제안. 원래 아키텍처를 바꾸지 않고 구조 보존성과 공간적 연관성 학습을 개선해 벤치마크에서 SOTA 성능을 보고함.


<details>
  <summary>Details</summary>
Motivation: Mamba의 flatten-and-scan 전략은 2D 공간 정보의 집계를 약화시키고 국소 픽셀 정보가 소실되며 채널 중복이 발생. 기존 해결책은 스캔 전략 수정이나 지역 특성 모듈 추가로 계산 비용이 증가해 실시간 성능을 저해함.

Method: 원본 Mamba 아키텍처를 변경하지 않고(1) 과거 특징을 저장해 이후에 융합하는 메모리 버퍼 메커니즘을 도입해 인접 특징 간의 연관성을 안정적으로 모델링하고, (2) 픽 간의 '상호 끌림'을 물리계의 에너지 최소화 관점으로 모사하는 이징 영감 정규화 손실을 추가하여 구조와 응집력을 유지. 이를 통합한 모델을 MBMamba라 명명.

Result: 제안한 MBMamba는 널리 쓰이는 디블러 벤치마크에서 기존 최첨단 방법들을 능가하는 성능을 보고함(논문 초록 기준). 구조 보존성과 디블러 성능이 개선되었고 아키텍처 변경 없이 적용 가능함.

Conclusion: 간단한 구조적 보조(메모리 버퍼)와 물리 인스파이어드 손실을 통해 Mamba의 공간 정보 집계 한계를 보완하고, 실험상 경쟁력 있는 성능을 확보. 다만 구체적 효율성(계산·지연), 하이퍼파라미터, 일반화성 등의 추가 검증이 필요.

Abstract: The Mamba architecture has emerged as a promising alternative to CNNs and
Transformers for image deblurring. However, its flatten-and-scan strategy often
results in local pixel forgetting and channel redundancy, limiting its ability
to effectively aggregate 2D spatial information. Although existing methods
mitigate this by modifying the scan strategy or incorporating local feature
modules, it increase computational complexity and hinder real-time performance.
In this paper, we propose a structure-aware image deblurring network without
changing the original Mamba architecture. Specifically, we design a memory
buffer mechanism to preserve historical information for later fusion, enabling
reliable modeling of relevance between adjacent features. Additionally, we
introduce an Ising-inspired regularization loss that simulates the energy
minimization of the physical system's "mutual attraction" between pixels,
helping to maintain image structure and coherence. Building on this, we develop
MBMamba. Experimental results show that our method outperforms state-of-the-art
approaches on widely used benchmarks.

</details>


### [64] [EgoLoc: A Generalizable Solution for Temporal Interaction Localization in Egocentric Videos](https://arxiv.org/abs/2508.12349)
*Junyi Ma,Erhang Zhang,Yin-Dong Zheng,Yuchen Xie,Yixuan Zhou,Hesheng Wang*

Main category: cs.CV

TL;DR: 제안된 EgoLoc은 손-물체 접촉 및 분리 시점을 제로샷으로 탐지하는 방법으로, 손 동작 기반 샘플링과 비전-언어 모델을 결합해 객체 마스크나 범주 주석 없이 시점(localization)을 수행한다.


<details>
  <summary>Details</summary>
Motivation: 기존 연구는 주로 ‘어떻게 상호작용하는가’(행동 패러다임)에 초점을 맞췄지만, 몰입형 MR과 로봇 계획에 필수적인 ‘언제 상호작용하는가’(접촉·분리 시점)를 정확히 포착하는 문제는 충분히 다루어지지 않음.

Method: EgoLoc은 손 동역학(움직임) 기반 샘플링으로 고품질 시각 프롬프트를 생성하고, 비전-언어 모델로 접촉/분리 속성을 식별해 특정 타임스탬프를 지역화하며, 폐쇄 루프 피드백으로 예측을 정제한다. 객체 마스크·동사-명사 분류 없이 제로샷으로 동작.

Result: 공개 데이터셋과 새로운 벤치마크에서 EgoLoc은 타임스탬프 기반의 TIL(temporal interaction localization)에 대해 합리적인 성능을 보였으며, 관련 다운스트림 작업(egocentric vision, 로봇 조작)에 유용함을 검증함.

Conclusion: EgoLoc은 객체 마스크와 카테고리 주석 없이 제로샷으로 손-물체 접촉/분리 시점을 로컬라이즈할 수 있으며, 실용적 응용(혼합현실·로봇)에서 유망한 접근법임.

Abstract: Analyzing hand-object interaction in egocentric vision facilitates VR/AR
applications and human-robot policy transfer. Existing research has mostly
focused on modeling the behavior paradigm of interactive actions (i.e., ``how
to interact''). However, the more challenging and fine-grained problem of
capturing the critical moments of contact and separation between the hand and
the target object (i.e., ``when to interact'') is still underexplored, which is
crucial for immersive interactive experiences in mixed reality and robotic
motion planning. Therefore, we formulate this problem as temporal interaction
localization (TIL). Some recent works extract semantic masks as TIL references,
but suffer from inaccurate object grounding and cluttered scenarios. Although
current temporal action localization (TAL) methods perform well in detecting
verb-noun action segments, they rely on category annotations during training
and exhibit limited precision in localizing hand-object contact/separation
moments. To address these issues, we propose a novel zero-shot approach dubbed
EgoLoc to localize hand-object contact and separation timestamps in egocentric
videos. EgoLoc introduces hand-dynamics-guided sampling to generate
high-quality visual prompts. It exploits the vision-language model to identify
contact/separation attributes, localize specific timestamps, and provide
closed-loop feedback for further refinement. EgoLoc eliminates the need for
object masks and verb-noun taxonomies, leading to generalizable zero-shot
implementation. Comprehensive experiments on the public dataset and our novel
benchmarks demonstrate that EgoLoc achieves plausible TIL for egocentric
videos. It is also validated to effectively facilitate multiple downstream
applications in egocentric vision and robotic manipulation tasks. Code and
relevant data will be released at https://github.com/IRMVLab/EgoLoc.

</details>


### [65] [Synthetic Data is Sufficient for Zero-Shot Visual Generalization from Offline Data](https://arxiv.org/abs/2508.12356)
*Ahmet H. Güzel,Ilija Bogunovic,Jack Parker-Holder*

Main category: cs.CV

TL;DR: 비전 기반 오프라인 강화학습에서 원본 데이터의 다양성 부족을 해결하기 위해, 먼저 데이터 증강으로 제로샷 일반화 능력을 높이고 이어서 잠재공간에서의 확산모델을 통해 합성 데이터를 생성하는 두 단계 방법을 제안한다. 기존 모델프리 오프라인 RL에 알고리듬 변경 없이 적용 가능하며 Visual D4RL(연속)과 Procgen(이산)에서 일반화 성능과 테스트 시 일반화 격차를 크게 줄였다.


<details>
  <summary>Details</summary>
Motivation: 오프라인 RL 에이전트는 수집된 데이터의 상태 다양성 부족으로 일반화에 취약하다. 특히 시각 입력은 노이즈·분산·가짜 상관관계로 인해 과적합 위험이 크므로 데이터 다양성 확대가 필요하다.

Method: 두 단계 접근: (1) 원본 오프라인 데이터를 다양한 형태로 증강하여 제로샷 일반화 개선, (2) 잠재공간에서 학습된 확산모델을 사용해 추가 합성 데이터를 생성. 합성 데이터는 기존 모델프리 오프라인 RL 알고리듬에 그대로 투입되어 학습에 사용됨.

Result: Visual D4RL(연속)과 Procgen(이산)에서 실험하여, 합성 데이터 사용 시 일반화 성능이 크게 향상되고 테스트 시 일반화 격차가 감소함을 보였다. 추가로 계산 효율성도 유지된다고 주장함.

Conclusion: 잠재공간 확산 기반 합성 데이터 생성과 사전 증강의 결합은 비전 기반 오프라인 RL에서 데이터 다양성을 늘려 강건한 일반화를 가능하게 한다. 별도의 알고리듬 수정 없이 기존 방법들과 호환되므로 향후 합성 데이터 활용 연구에 기여할 수 있다.

Abstract: Offline reinforcement learning (RL) offers a promising framework for training
agents using pre-collected datasets without the need for further environment
interaction. However, policies trained on offline data often struggle to
generalise due to limited exposure to diverse states. The complexity of visual
data introduces additional challenges such as noise, distractions, and spurious
correlations, which can misguide the policy and increase the risk of
overfitting if the training data is not sufficiently diverse. Indeed, this
makes it challenging to leverage vision-based offline data in training robust
agents that can generalize to unseen environments. To solve this problem, we
propose a simple approach generating additional synthetic training data. We
propose a two-step process, first augmenting the originally collected offline
data to improve zero-shot generalization by introducing diversity, then using a
diffusion model to generate additional data in latent space. We test our method
across both continuous action spaces (Visual D4RL) and discrete action spaces
(Procgen), demonstrating that it significantly improves generalization without
requiring any algorithmic changes to existing model-free offline RL methods. We
show that our method not only increases the diversity of the training data but
also significantly reduces the generalization gap at test time while
maintaining computational efficiency. We believe this approach could fuel
additional progress in generating synthetic data to train more general agents
in the future.

</details>


### [66] [IPGPhormer: Interpretable Pathology Graph-Transformer for Survival Analysis](https://arxiv.org/abs/2508.12381)
*Guo Tang,Songhan Jiang,Jinpeng Lu,Linghan Cai,Yongbing Zhang*

Main category: cs.CV

TL;DR: IPGPhormer는 종양 미세환경의 조직 및 세포 수준 특징을 그래프-트랜스포머로 모델링하여 WSI 기반 생존 예측의 정확도와 해석가능성을 동시에 개선한 방법이다.


<details>
  <summary>Details</summary>
Motivation: 기존의 multiple instance learning 기반 생존 분석은 장거리 공간관계와 로컬 문맥 의존성을 균형있게 모델링하기 어렵고, 후처리 주석이 없는 고유한 해석성을 제공하지 못해 임상 적용에 제약이 있다.

Method: IPGPhormer는 조직 내 세포·조직 단위 특징을 추출해 그래프로 표현하고, 그래프 구조와 트랜스포머 메커니즘을 결합해 공간적 종속성을 캡처한다. 추가로 조직 수준 및 세포 수준에서 직접적인 해석성을 제공하도록 설계되어 후속 수동 주석 없이 개별 WSI와 코호트 간 분석이 가능하다.

Result: 네 개의 공개 벤치마크 데이터셋에서 기존 최첨단 방법들보다 예측 성능과 해석가능성 모두에서 우수한 성능을 보였다.

Conclusion: IPGPhormer는 해석가능한 암 예후 예측을 위한 유망한 도구로, 임상적 의사결정 보조 시스템의 신뢰성과 투명성을 향상시킬 가능성이 있다.

Abstract: Pathological images play an essential role in cancer prognosis, while
survival analysis, which integrates computational techniques, can predict
critical clinical events such as patient mortality or disease recurrence from
whole-slide images (WSIs). Recent advancements in multiple instance learning
have significantly improved the efficiency of survival analysis. However,
existing methods often struggle to balance the modeling of long-range spatial
relationships with local contextual dependencies and typically lack inherent
interpretability, limiting their clinical utility. To address these challenges,
we propose the Interpretable Pathology Graph-Transformer (IPGPhormer), a novel
framework that captures the characteristics of the tumor microenvironment and
models their spatial dependencies across the tissue. IPGPhormer uniquely
provides interpretability at both tissue and cellular levels without requiring
post-hoc manual annotations, enabling detailed analyses of individual WSIs and
cross-cohort assessments. Comprehensive evaluations on four public benchmark
datasets demonstrate that IPGPhormer outperforms state-of-the-art methods in
both predictive accuracy and interpretability. In summary, our method,
IPGPhormer, offers a promising tool for cancer prognosis assessment, paving the
way for more reliable and interpretable decision-support systems in pathology.
The code is publicly available at
https://anonymous.4open.science/r/IPGPhormer-6EEB.

</details>


### [67] [ViT-EnsembleAttack: Augmenting Ensemble Models for Stronger Adversarial Transferability in Vision Transformers](https://arxiv.org/abs/2508.12384)
*Hanwen Cao,Haobo Lu,Xiaosen Wang,Kun He*

Main category: cs.CV

TL;DR: 논문은 서로게이트 비전 트랜스포머(ViT)에 대한 적대적 증강(adversarial augmentation)을 도입해 앙상블 기반 공격의 전달성(transferability)을 향상시킨다. 각 ViT에 대해 Multi-head dropping, Attention score scaling, MLP feature mixing의 세 가지 증강을 적용하고, 파라미터를 베이지안 최적화로 탐색해 증강 모델들을 앙상블하여 공격을 생성한다. 자동 재가중치 및 스텝 크기 확대 모듈을 추가해 성능을 더 끌어올린다.


<details>
  <summary>Details</summary>
Motivation: 기존 앙상블 기반 적대적 공격 연구는 주로 모델 가중치 최적화나 앙상블 경로에 집중했으며, 앙상블을 구성하는 개별 서브모델 자체를 다양화(증강)해 전달성을 높이는 관점은 거의 다루지 않았다. 또한 ViT에 특화된 앙상블 공격 방법은 부족했다.

Method: 각 서브 ViT에 대해 세 가지 구조적·연산적 증강 전략(멀티헤드 드롭, 어텐션 스코어 스케일링, MLP 피처 믹싱)을 적용해 여러 증강 모델을 생성한다. 각 증강의 하이퍼파라미터는 베이지안 최적화로 탐색한다. 생성된 증강 모델들을 앙상블해 공격을 만들고, 자동 재가중치(Automatic Reweighting)와 스텝 크기 확대(Step Size Enlargement) 모듈로 전달성을 추가 향상시킨다.

Result: 광범위한 실험에서 제안 방법(ViT-EnsembleAttack)은 기존 방법들보다 ViT 대상 공격의 전달성에서 큰 폭의 성능 향상을 보였다(구체적 수치 미기재). 코드가 공개되어 재현 가능함.

Conclusion: 서로게이트 ViT에 대한 적대적 증강을 통해 앙상블 기반 공격의 일반화와 전달성을 개선하는 첫 시도 중 하나이며, ViT 대상 블랙박스 공격 성능을 실질적으로 향상시킨다.

Abstract: Ensemble-based attacks have been proven to be effective in enhancing
adversarial transferability by aggregating the outputs of models with various
architectures. However, existing research primarily focuses on refining
ensemble weights or optimizing the ensemble path, overlooking the exploration
of ensemble models to enhance the transferability of adversarial attacks. To
address this gap, we propose applying adversarial augmentation to the surrogate
models, aiming to boost overall generalization of ensemble models and reduce
the risk of adversarial overfitting. Meanwhile, observing that ensemble Vision
Transformers (ViTs) gain less attention, we propose ViT-EnsembleAttack based on
the idea of model adversarial augmentation, the first ensemble-based attack
method tailored for ViTs to the best of our knowledge. Our approach generates
augmented models for each surrogate ViT using three strategies: Multi-head
dropping, Attention score scaling, and MLP feature mixing, with the associated
parameters optimized by Bayesian optimization. These adversarially augmented
models are ensembled to generate adversarial examples. Furthermore, we
introduce Automatic Reweighting and Step Size Enlargement modules to boost
transferability. Extensive experiments demonstrate that ViT-EnsembleAttack
significantly enhances the adversarial transferability of ensemble-based
attacks on ViTs, outperforming existing methods by a substantial margin. Code
is available at https://github.com/Trustworthy-AI-Group/TransferAttack.

</details>


### [68] [DeCoT: Decomposing Complex Instructions for Enhanced Text-to-Image Generation with Large Language Models](https://arxiv.org/abs/2508.12396)
*Xiaochuan Lin,Xiangyong Chen,Xuan Li,Yichen Su*

Main category: cs.CV

TL;DR: DeCoT은 LLM을 이용해 복잡한 T2I 지시문을 의미 단위로 분해하고 이를 계층적/최적화된 프롬프트로 통합해 기존 T2I 모델의 긴 지시문 이해와 실행력을 향상시킨 프레임워크다. LongBench-T2I에서 전반적 성능이 향상되었고, 텍스트·구성 등 어려운 항목에서 유의미한 개선을 보였다.


<details>
  <summary>Details</summary>
Motivation: 현행 T2I 모델은 복잡하고 장문의 지시문에서 세부묘사, 공간관계, 특정 제약조건을 정확히 반영하지 못한다(예: LongBench-T2I의 composition/text/texture 실패 사례). 사용자 의도와 모델 입력 간 간극을 좁힐 필요가 있다.

Method: 두 단계 접근: (1) LLM 기반 복합 지시분해 및 의미 보강 — 원문을 구조화된 행동 단위(semantic units)로 분해하고 모호성 해소, (2) 다단계 프롬프트 통합 및 적응형 생성 — 분해된 단위를 계층적 혹은 최적화된 단일 프롬프트로 변환해 기존 T2I에 입력. 다양한 LLM·T2I 조합과 절차적 통합을 사용.

Result: LongBench-T2I 전 항목에서 일관된 개선 관찰. 특히 'Text'와 'Composition'에서 큰 향상. 예시: DeCoT+Infinity-8B 평균점수 3.52 vs 베이스라인 3.44. Gemini-2.0-Flash, InternVL3-78B 같은 MLLM 평가기와 인간 평가로 검증. 구성요소별 제거 실험(ablations)으로 각 모듈의 기여 확인.

Conclusion: DeCoT는 고수준 사용자 의도와 T2I 모델 요구사항 사이의 간극을 효과적으로 메워 더 충실하고 정확한 이미지 생성을 달성한다. LLM 프롬프트 설계와 각 구성요소가 성능 향상에 핵심적이다.

Abstract: Despite remarkable advancements, current Text-to-Image (T2I) models struggle
with complex, long-form textual instructions, frequently failing to accurately
render intricate details, spatial relationships, or specific constraints. This
limitation is highlighted by benchmarks such as LongBench-T2I, which reveal
deficiencies in handling composition, specific text, and fine textures. To
address this, we propose DeCoT (Decomposition-CoT), a novel framework that
leverages Large Language Models (LLMs) to significantly enhance T2I models'
understanding and execution of complex instructions. DeCoT operates in two core
stages: first, Complex Instruction Decomposition and Semantic Enhancement,
where an LLM breaks down raw instructions into structured, actionable semantic
units and clarifies ambiguities; second, Multi-Stage Prompt Integration and
Adaptive Generation, which transforms these units into a hierarchical or
optimized single prompt tailored for existing T2I models. Extensive experiments
on the LongBench-T2I dataset demonstrate that DeCoT consistently and
substantially improves the performance of leading T2I models across all
evaluated dimensions, particularly in challenging aspects like "Text" and
"Composition". Quantitative results, validated by multiple MLLM evaluators
(Gemini-2.0-Flash and InternVL3-78B), show that DeCoT, when integrated with
Infinity-8B, achieves an average score of 3.52, outperforming the baseline
Infinity-8B (3.44). Ablation studies confirm the critical contribution of each
DeCoT component and the importance of sophisticated LLM prompting. Furthermore,
human evaluations corroborate these findings, indicating superior perceptual
quality and instruction fidelity. DeCoT effectively bridges the gap between
high-level user intent and T2I model requirements, leading to more faithful and
accurate image generation.

</details>


### [69] [Federated Cross-Modal Style-Aware Prompt Generation](https://arxiv.org/abs/2508.12399)
*Suraj Prasad,Navyansh Mahla,Sunny Gupta,Amit Sethi*

Main category: cs.CV

TL;DR: 연합학습 환경에서 CLIP의 저·중·고수준 비주얼 특징과 클라이언트별 스타일 지표를 결합해 문맥·스타일 민감한 프롬프트 토큰을 생성하는 FedCSAP을 제안한다. 최종층만 쓴 기존 방법보다 본·미지 클래스 일반화와 정확도가 향상된다.


<details>
  <summary>Details</summary>
Motivation: 프롬프트 학습이 경량화된 비전·언어 모델을 연합학습에 적합하게 만들지만, 기존 기법들이 최종층 특징만 사용해 멀티스케일 시각 신호와 도메인별 스타일 변이를 포착하지 못한다. 분산된 클라이언트 데이터의 비IID성과 스타일 차이를 고려한 프롬프트 학습 필요.

Method: CLIP 비전 인코더의 저·중·고수준 특징을 추출하고, 배치 수준 통계로부터 각 클라이언트의 스타일 지표를 계산한다. 시각 특징과 스타일 정보를 텍스트 맥락과 결합해 중복이 적고 구별 가능한 프롬프트 토큰을 생성한다. 로컬에서 프롬프트를 학습하고 글로벌 서버에서 집계하는 연합학습 파이프라인으로 개인정보를 보호하며 비IID 클래스 분포와 스타일 다양성에 대응.

Result: 여러 이미지 분류 데이터셋에서 기존의 연합 프롬프트 학습 방법들보다 본(학습된) 및 미지(미학습) 클래스 둘 다에서 정확도와 일반화 성능이 향상되는 것으로 보고된다.

Conclusion: 멀티스케일 특징과 클라이언트별 스타일 인디케이터를 통합한 FedCSAP은 연합학습 환경에서 프롬프트의 표현력을 높여 더 견고한 일반화를 실현한다. 향후에는 통신 비용, 대규모 클라이언트 확장성, 추가적인 강건성·프라이버시 분석이 필요하다.

Abstract: Prompt learning has propelled vision-language models like CLIP to excel in
diverse tasks, making them ideal for federated learning due to computational
efficiency. However, conventional approaches that rely solely on final-layer
features miss out on rich multi-scale visual cues and domain-specific style
variations in decentralized client data. To bridge this gap, we introduce
FedCSAP (Federated Cross-Modal Style-Aware Prompt Generation). Our framework
harnesses low, mid, and high-level features from CLIP's vision encoder
alongside client-specific style indicators derived from batch-level statistics.
By merging intricate visual details with textual context, FedCSAP produces
robust, context-aware prompt tokens that are both distinct and non-redundant,
thereby boosting generalization across seen and unseen classes. Operating
within a federated learning paradigm, our approach ensures data privacy through
local training and global aggregation, adeptly handling non-IID class
distributions and diverse domain-specific styles. Comprehensive experiments on
multiple image classification datasets confirm that FedCSAP outperforms
existing federated prompt learning methods in both accuracy and overall
generalization.

</details>


### [70] [MPCAR: Multi-Perspective Contextual Augmentation for Enhanced Visual Reasoning in Large Vision-Language Models](https://arxiv.org/abs/2508.12400)
*Amirul Rahman,Qiang Xu,Xueying Huang*

Main category: cs.CV

TL;DR: MPCAR은 LVLM의 추론 시 입력을 풍부하게 하기 위해 여러 관점에서 생성한 설명/추론 경로를 통합하는 3단계(다양한 관점 생성 → 통합된 컨텍스트 프롬프트 구성 → 최종 추론) 방식의 방법이다. 미세조정 없이 성능을 향상시키며 GQA, VQA-CP v2, ScienceQA에서 유의미한 정확도 향상을 보였다.


<details>
  <summary>Details</summary>
Motivation: 단일 샷 이미지 인코딩과 프롬프트로는 복잡한 시각 추론에 필요한 깊은 맥락 이해, 다각도 분석, 세부 인지가 부족하므로 LVLM이 자체 생성 가능한 추가 정보를 활용해 입력 컨텍스트를 보강하고자 함.

Method: (1) LVLM으로부터 N개의 다양한 보완적 설명 또는 예비 추론 경로를 생성한다. (2) 이 설명들을 지능적으로 원질문과 통합하여 컨텍스트-증강 프롬프트를 구성한다. (3) 증강된 프롬프트로 LVLM이 심층 추론을 수행해 최종 답변을 생성한다. 모든 과정은 추론 시점에서 이루어지며 모델 파라미터의 미세조정은 없음.

Result: GQA, VQA-CP v2, ScienceQA(이미지 VQA) 등에서 기존 베이스라인보다 일관되게 성능 개선. 특히 맥락 이해가 중요한 태스크에서 정확도 증가가 두드러지고, 인간 평가에서 응답의 일관성·완전성 향상이 관찰됨. 다양한 프롬프트 템플릿과 관점 수에 따른 소거 분석이 기여도를 확인.

Conclusion: LVLM의 생성 능력을 이용한 입력 컨텍스트 보강은 미세조정 없이도 복잡한 다중모달 추론 능력을 끌어낼 수 있으며, 관점 다양성과 프롬프트 디자인이 성능 결정에 중요한 역할을 함.

Abstract: Despite significant advancements, Large Vision-Language Models (LVLMs)
continue to face challenges in complex visual reasoning tasks that demand deep
contextual understanding, multi-angle analysis, or meticulous detail
recognition. Existing approaches often rely on single-shot image encoding and
prompts, limiting their ability to fully capture nuanced visual information.
Inspired by the notion that strategically generated "additional" information
can serve as beneficial contextual augmentation, we propose Multi-Perspective
Contextual Augmentation for Reasoning (MPCAR), a novel inference-time strategy
designed to enhance LVLM performance. MPCAR operates in three stages: first, an
LVLM generates N diverse and complementary descriptions or preliminary
reasoning paths from various angles; second, these descriptions are
intelligently integrated with the original question to construct a
comprehensive context-augmented prompt; and finally, this enriched prompt
guides the ultimate LVLM for deep reasoning and final answer generation.
Crucially, MPCAR achieves these enhancements without requiring any fine-tuning
of the underlying LVLM's parameters. Extensive experiments on challenging
Visual Question Answering (VQA) datasets, including GQA, VQA-CP v2, and
ScienceQA (Image-VQA), demonstrate that MPCAR consistently outperforms
established baseline methods. Our quantitative results show significant
accuracy gains, particularly on tasks requiring robust contextual
understanding, while human evaluations confirm improved coherence and
completeness of the generated answers. Ablation studies further highlight the
importance of diverse prompt templates and the number of generated
perspectives. This work underscores the efficacy of leveraging LVLMs' inherent
generative capabilities to enrich input contexts, thereby unlocking their
latent reasoning potential for complex multimodal tasks.

</details>


### [71] [LMAD: Integrated End-to-End Vision-Language Model for Explainable Autonomous Driving](https://arxiv.org/abs/2508.12404)
*Nan Song,Bozhou Zhang,Xiatian Zhu,Jiankang Deng,Li Zhang*

Main category: cs.CV

TL;DR: LMAD는 자율주행에 특화된 비전-언어 프레임워크로, 예비 장면 상호작용과 전문가 어댑터를 도입해 기존 VLM을 자율주행 장면 이해와 계획 시스템에 잘 정렬시키며 DriveLM 및 nuScenes-QA에서 성능을 크게 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 기존 방식은 온보드 다중뷰 이미지와 텍스트로 VLM을 미세조정하지만, 자율주행에 필요한 전체적·정교한 장면 인식과 강력한 공간 인식 능력이 부족해 복잡한 상황에서 한계가 있다.

Method: LMAD는 엔드투엔드 드라이빙 패러다임을 모사하여 VLM에 예비 장면 상호작용(preliminary scene interaction)과 동일한 드라이빙 태스크 구조 내의 전문화된 전문가 어댑터(expert adapters)를 삽입한다. 이는 기존 VLM과 호환되며 계획 지향 드라이빙 시스템과 통합되도록 설계되었다.

Result: DriveLM과 nuScenes-QA에서 실험한 결과, LMAD는 기존 VLM들의 주행 추론 능력을 유의미하게 향상시켜 설명 가능한 자율주행 성능의 새로운 기준을 제시했다.

Conclusion: LMAD는 VLM을 자율주행 시나리오에 더 잘 정렬시켜 장면 이해, 공간 인식, 설명 가능성을 개선하며 기존 시스템과의 호환성 및 계획 통합성을 제공한다.

Abstract: Large vision-language models (VLMs) have shown promising capabilities in
scene understanding, enhancing the explainability of driving behaviors and
interactivity with users. Existing methods primarily fine-tune VLMs on on-board
multi-view images and scene reasoning text, but this approach often lacks the
holistic and nuanced scene recognition and powerful spatial awareness required
for autonomous driving, especially in complex situations. To address this gap,
we propose a novel vision-language framework tailored for autonomous driving,
called LMAD. Our framework emulates modern end-to-end driving paradigms by
incorporating comprehensive scene understanding and a task-specialized
structure with VLMs. In particular, we introduce preliminary scene interaction
and specialized expert adapters within the same driving task structure, which
better align VLMs with autonomous driving scenarios. Furthermore, our approach
is designed to be fully compatible with existing VLMs while seamlessly
integrating with planning-oriented driving systems. Extensive experiments on
the DriveLM and nuScenes-QA datasets demonstrate that LMAD significantly boosts
the performance of existing VLMs on driving reasoning tasks,setting a new
standard in explainable autonomous driving.

</details>


### [72] [S5: Scalable Semi-Supervised Semantic Segmentation in Remote Sensing](https://arxiv.org/abs/2508.12409)
*Liang Lv,Di Wang,Jing Zhang,Lefei Zhang*

Main category: cs.CV

TL;DR: S5는 대규모 무라벨 위성/항공 영상 활용을 위한 반지도학습 확장 프레임워크로, 엔트로피 기반 필터링과 다양성 확장으로 RS4P-1M 데이터셋을 구성하고 이를 통해 다양한 크기의 RS 파운데이션 모델(RSFM)을 사전학습한 뒤 MoE 기반 멀티-데이터셋 파인튜닝으로 적응시켜 여러 RS 벤치마크에서 SOTA를 달성한다.


<details>
  <summary>Details</summary>
Motivation: 픽셀 단위 주석이 비용·시간 면에서 비싸서 방대한 원격탐사 데이터가 활용되지 못하며, 기존 반지도학습 연구는 소규모 데이터·모델에 국한되어 실무 적용성이 낮음.

Method: 엔트로피 기반 불확실도 필터링과 다양성 기반 확장을 결합한 데이터 선택으로 RS4P-1M 구축. 이 데이터로 여러 규모의 RSFM을 사전학습하고, Mixture-of-Experts(MoE) 구조를 활용한 멀티-데이터셋 파인튜닝으로 효율적 적응과 파라미터 절감을 도모.

Result: 사전학습된 RSFM과 RS4P-1M을 이용한 학습은 토지 피복 분할 및 객체 검출 성능을 크게 향상시켰고, MoE 파인튜닝은 일반화 성능과 효율성을 개선해 모든 평가 벤치마크에서 최첨단 성능을 보였음.

Conclusion: 대규모 반지도학습과 스케일 업은 원격탐사 응용에서 실질적 성능 향상을 가능하게 하며, 데이터·코드·모델 공개를 통해 커뮤니티 활용을 촉진한다.

Abstract: Semi-supervised semantic segmentation (S4) has advanced remote sensing (RS)
analysis by leveraging unlabeled data through pseudo-labeling and consistency
learning. However, existing S4 studies often rely on small-scale datasets and
models, limiting their practical applicability. To address this, we propose S5,
the first scalable framework for semi-supervised semantic segmentation in RS,
which unlocks the potential of vast unlabeled Earth observation data typically
underutilized due to costly pixel-level annotations. Built upon existing
large-scale RS datasets, S5 introduces a data selection strategy that
integrates entropy-based filtering and diversity expansion, resulting in the
RS4P-1M dataset. Using this dataset, we systematically scales S4 methods by
pre-training RS foundation models (RSFMs) of varying sizes on this extensive
corpus, significantly boosting their performance on land cover segmentation and
object detection tasks. Furthermore, during fine-tuning, we incorporate a
Mixture-of-Experts (MoE)-based multi-dataset fine-tuning approach, which
enables efficient adaptation to multiple RS benchmarks with fewer parameters.
This approach improves the generalization and versatility of RSFMs across
diverse RS benchmarks. The resulting RSFMs achieve state-of-the-art performance
across all benchmarks, underscoring the viability of scaling semi-supervised
learning for RS applications. All datasets, code, and models will be released
at https://github.com/MiliLab/S5

</details>


### [73] [SRMA-Mamba: Spatial Reverse Mamba Attention Network for Pathological Liver Segmentation in MRI Volumes](https://arxiv.org/abs/2508.12410)
*Jun Zeng,Yannan Huang,Elif Keles,Halil Ertugrul Aktas,Gorkem Durak,Nikhil Kumar Tomar,Quoc-Huy Trinh,Deepak Ranjan Nayak,Ulas Bagci,Debesh Jha*

Main category: cs.CV

TL;DR: SRMA-Mamba는 3D MRI에서 간경변 병변 분할을 위해 축(sagittal, coronal, axial) 정보를 결합하는 Spatial Anatomy-Based Mamba 모듈과 계층적 특징과 거친 분할을 이용해 세부를 보정하는 Spatial Reverse Attention 모듈을 통합한 네트워크로, 기존 방법보다 우수한 3D 병변 분할 성능을 보고한다. 코드 공개.


<details>
  <summary>Details</summary>
Motivation: 간경변의 조기 발견은 예후 개선에 중요하지만, 복잡한 해부학적 구조와 다양한 병변 패턴 때문에 3D MRI에서 정확한 병변 검출·분할이 어렵다. 기존 방법은 체적 MRI의 공간적 해부학 정보를 충분히 활용하지 못해 성능과 설명력이 제한된다.

Method: SRMA-Mamba는 (1) Spatial Anatomy-Based Mamba(SABMamba)를 통해 간 조직 내 선택적 Mamba 스캔을 수행하고 세 축의 해부학 정보를 결합해 전역 공간 문맥을 구성, (2) Spatial Reverse Attention(SRMA) 모듈로 거친 분할 맵과 계층적 인코더 특성을 이용해 병변 세부를 점진적으로 정제한다. 이를 통해 효율적인 체적 병변 분할을 수행한다.

Result: 광범위한 실험에서 SRMA-Mamba는 기존 최첨단 방법들보다 우수한 성능을 보였으며 3D 병변 분할에서 뛰어난 결과를 달성했다고 보고한다. 코드가 공개되어 있다.

Conclusion: 해부학 기반의 Mamba 모듈과 역주목(attention) 기반 정제 모듈의 결합은 체적 MRI에서 병변 분할 정확도와 설명력을 향상시켜 임상 적용 가능성을 높인다.

Abstract: Liver Cirrhosis plays a critical role in the prognosis of chronic liver
disease. Early detection and timely intervention are critical in significantly
reducing mortality rates. However, the intricate anatomical architecture and
diverse pathological changes of liver tissue complicate the accurate detection
and characterization of lesions in clinical settings. Existing methods
underutilize the spatial anatomical details in volumetric MRI data, thereby
hindering their clinical effectiveness and explainability. To address this
challenge, we introduce a novel Mamba-based network, SRMA-Mamba, designed to
model the spatial relationships within the complex anatomical structures of MRI
volumes. By integrating the Spatial Anatomy-Based Mamba module (SABMamba),
SRMA-Mamba performs selective Mamba scans within liver cirrhotic tissues and
combines anatomical information from the sagittal, coronal, and axial planes to
construct a global spatial context representation, enabling efficient
volumetric segmentation of pathological liver structures. Furthermore, we
introduce the Spatial Reverse Attention module (SRMA), designed to
progressively refine cirrhotic details in the segmentation map, utilizing both
the coarse segmentation map and hierarchical encoding features. Extensive
experiments demonstrate that SRMA-Mamba surpasses state-of-the-art methods,
delivering exceptional performance in 3D pathological liver segmentation. Our
code is available for public:
{\color{blue}{https://github.com/JunZengz/SRMA-Mamba}}.

</details>


### [74] [TiP4GEN: Text to Immersive Panorama 4D Scene Generation](https://arxiv.org/abs/2508.12415)
*Ke Xing,Hanwen Liang,Dejia Xu,Yuyang Yin,Konstantinos N. Plataniotis,Yao Zhao,Yunchao Wei*

Main category: cs.CV

TL;DR: TiP4GEN은 텍스트로부터 360° 파노라마 4D(동적) 장면을 생성하는 프레임워크로, 전역·지역 생성을 위한 이중 분기(파노라마/원근)와 양방향 교차 어텐션, 3D Gaussian Splatting 기반의 기하 정렬 복원으로 모션-일관성 및 기하학적 일관성을 확보한다.


<details>
  <summary>Details</summary>
Motivation: VR/AR의 보급으로부터 모든 관점에서의 360° 몰입형 동적 장면 생성 수요가 급증하고 있지만, 기존 연구는 정적 장면이나 제한된 원근 동적 장면에만 집중되어 진정한 전방위(어느 뷰에서도) 몰입 경험을 제공하지 못함.

Method: 영상 생성은 전역 파노라마 분기와 지역 원근 분기를 갖는 Dual-branch Generation Model로 처리하며, 두 분기 간 정보를 교환하기 위해 양방향 교차 어텐션을 사용한다. 장면 복원은 3D Gaussian Splatting 기반의 Geometry-aligned Reconstruction Model을 도입하여, 메트릭 깊이 맵으로 시공간 포인트클라우드를 정렬하고 추정된 카메라 포즈로 장면 카메라를 초기화해 기하학적 일관성과 시간적 연속성을 보장한다.

Result: 광범위한 실험에서 제안 기법이 시각적으로 우수하고 모션 일관성이 높은 동적 파노라마 장면을 생성함을 보였으며, 비교 방법들보다 우수하다고 주장함.

Conclusion: TiP4GEN은 텍스트-투-동적 파노라마 생성에서 세밀한 제어와 기하학적 일관성을 달성하며, 360° 몰입형 가상 환경 생성에 유망한 방향을 제시한다.

Abstract: With the rapid advancement and widespread adoption of VR/AR technologies,
there is a growing demand for the creation of high-quality, immersive dynamic
scenes. However, existing generation works predominantly concentrate on the
creation of static scenes or narrow perspective-view dynamic scenes, falling
short of delivering a truly 360-degree immersive experience from any viewpoint.
In this paper, we introduce \textbf{TiP4GEN}, an advanced text-to-dynamic
panorama scene generation framework that enables fine-grained content control
and synthesizes motion-rich, geometry-consistent panoramic 4D scenes. TiP4GEN
integrates panorama video generation and dynamic scene reconstruction to create
360-degree immersive virtual environments. For video generation, we introduce a
\textbf{Dual-branch Generation Model} consisting of a panorama branch and a
perspective branch, responsible for global and local view generation,
respectively. A bidirectional cross-attention mechanism facilitates
comprehensive information exchange between the branches. For scene
reconstruction, we propose a \textbf{Geometry-aligned Reconstruction Model}
based on 3D Gaussian Splatting. By aligning spatial-temporal point clouds using
metric depth maps and initializing scene cameras with estimated poses, our
method ensures geometric consistency and temporal coherence for the
reconstructed scenes. Extensive experiments demonstrate the effectiveness of
our proposed designs and the superiority of TiP4GEN in generating visually
compelling and motion-coherent dynamic panoramic scenes. Our project page is at
https://ke-xing.github.io/TiP4GEN/.

</details>


### [75] [Illusions in Humans and AI: How Visual Perception Aligns and Diverges](https://arxiv.org/abs/2508.12422)
*Jianyi Yang,Junyi Ye,Ankan Dash,Guiling Wang*

Main category: cs.CV

TL;DR: 논문들은 인간의 착시와 인공시각의 차이를 비교하여, 일부 착시 효과가 인공모델에서 재현되거나 훈련 중에 발생하지만 AI 특유의 '픽셀 민감성'과 환각 같은 현상도 존재함을 보고한다. 이러한 차이는 인간-친화적 AI 설계와 안전성 연구에 시사점을 준다.


<details>
  <summary>Details</summary>
Motivation: 인간 지각은 문맥적 가정에 의존해 시각적 현실을 구성하는데, AI가 인간 유사 작업을 수행할 때 유사한 착시를 경험하는지, 혹은 고유한 취약성이 있는지를 규명하면 더 신뢰성 있고 인간에 맞춘 비전 시스템 설계에 도움된다.

Method: 고전적인 색상·크기·형태·운동 착시 자극을 인공 비전 모델(여러 아키텍처와 훈련 조건)에 제시하여 반응을 비교. 대상에는 표적 학습을 통한 유도 실험과, 자연적 학습에서 부수적으로 발생한 착시 유사 효과 탐색이 포함됨.

Result: 일부 고전적 착시는 모델에서 재현되거나 특정 훈련으로 유도될 수 있었고, 반면 AI 고유의 현상(픽셀 수준 민감성, 환각)이 발견되어 인간과 다른 취약성 및 정렬 격차를 드러냄.

Conclusion: 인간-유사한 유익한 지각 편향은 유지하되 AI 고유의 왜곡을 줄이는 방향으로 연구와 모델 설계가 필요하며, 착시 비교는 정렬·해석 가능성·안전성 개선을 위한 유용한 진단 도구가 된다.

Abstract: By comparing biological and artificial perception through the lens of
illusions, we highlight critical differences in how each system constructs
visual reality. Understanding these divergences can inform the development of
more robust, interpretable, and human-aligned artificial intelligence (AI)
vision systems. In particular, visual illusions expose how human perception is
based on contextual assumptions rather than raw sensory data. As artificial
vision systems increasingly perform human-like tasks, it is important to ask:
does AI experience illusions, too? Does it have unique illusions? This article
explores how AI responds to classic visual illusions that involve color, size,
shape, and motion. We find that some illusion-like effects can emerge in these
models, either through targeted training or as by-products of pattern
recognition. In contrast, we also identify illusions unique to AI, such as
pixel-level sensitivity and hallucinations, that lack human counterparts. By
systematically comparing human and AI responses to visual illusions, we uncover
alignment gaps and AI-specific perceptual vulnerabilities invisible to human
perception. These findings provide insights for future research on vision
systems that preserve human-beneficial perceptual biases while avoiding
distortions that undermine trust and safety.

</details>


### [76] [Adversarial Attacks on VQA-NLE: Exposing and Alleviating Inconsistencies in Visual Question Answering Explanations](https://arxiv.org/abs/2508.12430)
*Yahsin Yeh,Yilun Wu,Bokai Ruan,Honghan Shuai*

Main category: cs.CV

TL;DR: 이 논문은 VQA-NLE(시각질문응답 자연어 설명) 시스템이 질문·이미지에 대한 미세한 교란으로 모순적·허위 설명을 생성할 수 있음을 보이고, 질문 교란과 새로 제안한 최소 이미지 변경 공격을 제시한 뒤, 외부 지식 기반 방어로 일관성 문제를 완화하는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: VQA-NLE 모델은 블랙박스 결정을 설명한다 주장하지만, 실제로는 맥락을 제대로 이해하지 못해 모순적이거나 근거 없는 설명을 생성한다. 이런 취약성은 보안·신뢰성 문제로 이어지므로 이를 진단하고 강화할 방법이 필요하다.

Method: (1) 기존의 적대적 질문 교란 전략을 활용해 설명·예측의 취약성을 드러냄. (2) 새로 제안된 전략으로 이미지의 최소한의 변경(미세한 시각적 변형)을 가해 모순적·스푸리어스한 출력 유도. (3) 외부 지식을 모델에 통합하는 방어 기법을 설계해 설명의 일관성과 견고성을 향상시킴.

Result: 두 개의 표준 벤치마크와 두 가지 VQA-NLE 모델에 대한 광범위한 평가에서 제안된 공격이 효과적임을 보였고, 지식 기반 완화 기법이 일관성 및 강건성을 개선하는 데 도움을 줌.

Conclusion: 현재 VQA-NLE 시스템은 보안 및 신뢰성 측면에서 심각한 취약점을 가짐. 제안된 공격·방어 연구는 이러한 문제를 부각시키며, 외부 지식 활용이 잠재적 해법임을 시사한다.

Abstract: Natural language explanations in visual question answering (VQA-NLE) aim to
make black-box models more transparent by elucidating their decision-making
processes. However, we find that existing VQA-NLE systems can produce
inconsistent explanations and reach conclusions without genuinely understanding
the underlying context, exposing weaknesses in either their inference pipeline
or explanation-generation mechanism. To highlight these vulnerabilities, we not
only leverage an existing adversarial strategy to perturb questions but also
propose a novel strategy that minimally alters images to induce contradictory
or spurious outputs. We further introduce a mitigation method that leverages
external knowledge to alleviate these inconsistencies, thereby bolstering model
robustness. Extensive evaluations on two standard benchmarks and two widely
used VQA-NLE models underscore the effectiveness of our attacks and the
potential of knowledge-based defenses, ultimately revealing pressing security
and reliability concerns in current VQA-NLE systems.

</details>


### [77] [X-Ray-CoT: Interpretable Chest X-ray Diagnosis with Vision-Language Models via Chain-of-Thought Reasoning](https://arxiv.org/abs/2508.12455)
*Chee Ng,Liliang Sun,Shaoqing Tang*

Main category: cs.CV

TL;DR: X-Ray-CoT는 다중모달 특징 추출과 구조화된 Chain-of-Thought(코트) 프롬프트를 결합해 흉부 X선의 진단과 해석 가능한 보고서 생성을 목표로 하는 LVLM 기반 프레임워크이다. CORDA에서 기존 블랙박스 모델을 약간 능가하는 성능을 보였고(BA 80.52%, F1 78.65%), 사람 평가에서 설명가능한 보고서를 생성함을 보였다.


<details>
  <summary>Details</summary>
Motivation: 흉부 X선 판독은 임상 경험에 크게 의존하고 판독자 간 편차가 크며, 높은 정확도의 딥러닝 모델은 설명가능성 부족으로 임상 도입에 제약이 있다. 이를 해결하기 위해 해석 가능한 진단 및 자연어 보고서 생성을 목표로 한다.

Method: 시스템은 멀티모달(영상+언어) 특징과 시각적 개념을 추출한 뒤, 구조화된 CoT 프롬프트를 사용하는 LLM 구성요소로 추론을 수행해 상세한 진단 보고서를 생성한다. 멀티모달 융합과 CoT 기반 추론이 핵심 요소이다.

Result: CORDA 데이터셋에서 질병 진단에 대해 Balanced Accuracy 80.52%, F1 78.65%를 달성하며 기존 블랙박스 모델을 소폭 초과했다. 인간 평가에서 생성된 보고서의 품질과 설명가능성을 긍정적으로 확인했고, 제거 실험(ablation)으로 각 구성요소의 기여를 검증했다.

Conclusion: 멀티모달 융합과 CoT 추론을 이용한 X-Ray-CoT는 성능과 해석가능성에서 유망한 결과를 보이며, 신뢰할 수 있고 임상적으로 활용 가능한 의료 영상 AI로 나아가는 의미 있는 진전이다.

Abstract: Chest X-ray imaging is crucial for diagnosing pulmonary and cardiac diseases,
yet its interpretation demands extensive clinical experience and suffers from
inter-observer variability. While deep learning models offer high diagnostic
accuracy, their black-box nature hinders clinical adoption in high-stakes
medical settings. To address this, we propose X-Ray-CoT (Chest X-Ray
Chain-of-Thought), a novel framework leveraging Vision-Language Large Models
(LVLMs) for intelligent chest X-ray diagnosis and interpretable report
generation. X-Ray-CoT simulates human radiologists' "chain-of-thought" by first
extracting multi-modal features and visual concepts, then employing an
LLM-based component with a structured Chain-of-Thought prompting strategy to
reason and produce detailed natural language diagnostic reports. Evaluated on
the CORDA dataset, X-Ray-CoT achieves competitive quantitative performance,
with a Balanced Accuracy of 80.52% and F1 score of 78.65% for disease
diagnosis, slightly surpassing existing black-box models. Crucially, it
uniquely generates high-quality, explainable reports, as validated by
preliminary human evaluations. Our ablation studies confirm the integral role
of each proposed component, highlighting the necessity of multi-modal fusion
and CoT reasoning for robust and transparent medical AI. This work represents a
significant step towards trustworthy and clinically actionable AI systems in
medical imaging.

</details>


### [78] [Inverse-LLaVA: Eliminating Alignment Pre-training Through Text-to-Vision Mapping](https://arxiv.org/abs/2508.12466)
*Xuhui Zhan,Tyler Derr*

Main category: cs.CV

TL;DR: Inverse-LLaVA는 시각 특징을 텍스트 토큰으로 투사하는 기존의 정렬 사전학습을 없애고, 대신 텍스트 임베딩을 연속적인 시각 표현 공간으로 매핑하여 트랜스포머 중간층에서 융합하는 새로운 패러다임을 제안한다. 이 방법은 계산비용을 45% 절감하면서 추론 중심의 작업에서는 성능 향상을 보였지만(예: cognitive reasoning +27.2%) 기억 기반 인식·OCR 과제에서는 큰 성능 저하를 보였다.


<details>
  <summary>Details</summary>
Motivation: 대규모 이미지-텍스트 정렬 사전학습이 비용이 크고, 모달리티별 특징을 희석할 수 있다는 문제를 해결하고자, 정렬 없이도 효과적인 멀티모달 융합이 가능한지를 탐구하려 함.

Method: 텍스트 임베딩을 시각 표현 공간으로 매핑하고(역방향 매핑), 트랜스포머의 중간층에서 선택적 가법(선택적 additive) 어텐션 구성요소를 통해 동적 융합을 수행한다. 이를 통해 대규모 정렬 데이터셋 없이도 텍스트·비주얼을 통합한다.

Result: 9개 멀티모달 벤치마크에서 평가해 추론·인지 과제에서 성능 개선을 보였고(MM-VET +0.2%, VizWiz +1.8%, ScienceQA +0.2%, cognitive reasoning +27.2%), 반면 인식 기반 과제에서는 대폭 성능 하락(유명인 인식 -49.5%, OCR -21.3%)이 관찰되었다. 전체 계산비용은 약 45% 절감됨.

Conclusion: 정렬 사전학습이 모든 멀티모달 학습에 필수적이라는 통념에 도전하며, 적어도 복합 추론 과제에서는 정렬 없이도 경쟁력 있는 성능을 달성할 수 있음을 보였다. 다만 인식·기억 기반 과제에선 정렬이 여전히 중요해 하이브리드 설계나 추가 보강이 필요하다.

Abstract: Traditional multimodal learning approaches require expensive alignment
pre-training to bridge vision and language modalities, typically projecting
visual features into discrete text token spaces. We challenge both fundamental
assumptions underlying this paradigm by proposing Inverse-LLaVA, a novel
approach that eliminates alignment pre-training entirely while inverting the
conventional mapping direction. Rather than projecting visual features to text
space, our method maps text embeddings into continuous visual representation
space and performs fusion within transformer intermediate layers. Through
selective additive components in attention mechanisms, we enable dynamic
integration of visual and textual representations without requiring massive
image-text alignment datasets. Comprehensive experiments across nine multimodal
benchmarks demonstrate nuanced performance trade-offs: Inverse-LLaVA achieves
notable improvements on reasoning-intensive and cognitive tasks (MM-VET: +0.2%,
VizWiz: +1.8%, ScienceQA: +0.2%, cognitive reasoning: +27.2%), while showing
expected decreases in perception tasks requiring memorized visual-text
associations (celebrity recognition: -49.5%, OCR: -21.3%). These results
provide the first empirical evidence that alignment pre-training is not
necessary for effective multimodal learning, particularly for complex reasoning
tasks. Our work establishes the feasibility of a new paradigm that reduces
computational requirements by 45%, challenges conventional wisdom about
modality fusion, and opens new research directions for efficient multimodal
architectures that preserve modality-specific characteristics. Our project
website with code and additional resources is available at
https://inverse-llava.github.io.

</details>


### [79] [Standardization of Neuromuscular Reflex Analysis -- Role of Fine-Tuned Vision-Language Model Consortium and OpenAI gpt-oss Reasoning LLM Enabled Decision Support System](https://arxiv.org/abs/2508.12473)
*Eranga Bandara,Ross Gore,Sachin Shetty,Ravi Mukkamala,Christopher Rhea,Atmaram Yarlagadda,Shaifali Kaushik,L. H. M. P. De Silva,Andriy Maznychenko,Inna Sokolowska,Amin Hass,Kasun De Zoysa*

Main category: cs.CV

TL;DR: H-반사(EMG) 파형 해석의 주관성과 변동성을 해결하기 위해, 본 연구는 파인튜닝된 복수의 비전-언어 모델(VLM) 컨소시엄과 추론용 대형언어모델(LLM)을 결합한 의사결정 지원 시스템을 제시한다. VLM들은 EMG 파형 이미지와 메타데이터로부터 전기생리학적 특징과 신경근 상태를 추출하고, 합의 기반 집계 및 LLM의 정교한 추론으로 해석을 제공한다. 실험에서 높은 정확도와 일관성, 해석 가능성을 보였다고 주장한다.


<details>
  <summary>Details</summary>
Motivation: H-반사 EMG 파형 해석은 스포츠과학·재활·임상신경학에서 중요하지만, 임상의·연구자 간 해석 편차가 크고 표준화가 어렵다. 자동화되고 일관된 진단 도구가 필요하다.

Method: 여러 VLM을 각각 H-반사 파형 이미지(임상 관찰·회복 타임라인·운동선수 메타데이터 주석 포함)로 파인튜닝하여 특징 추출 및 상태 예측(피로·부상·회복 등)을 수행한다. VLM 출력은 합의 기반 방식으로 집계되고, 추론에 특화된 LLM이 이를 정제·설명 가능하게 보완한다. 플랫폼은 VLM 앙상블과 LLM 간의 통신을 오케스트레이션하며 프롬프트 엔지니어링과 LLM 에이전트를 활용한 자동추론 워크플로를 사용한다.

Result: 저자들은 하이브리드 시스템이 높은 정확도·일관성·해석가능성을 제공한다고 보고한다(구체적 수치·데이터셋·비교 대상은 초록에 미기재). 또한 VLM-LLM 통합 방식이 H-반사 기반 진단의 자동화·표준화에 유의미한 진전을 가져온다고 주장한다.

Conclusion: 파인튜닝된 VLM 컨소시엄과 추론 LLM의 결합은 영상 기반 H-반사 분석에서 최초의 통합 시도로서 차세대 AI 지원 신경근 평가·선수 모니터링 플랫폼의 기반을 마련한다는 주장을 제시한다.

Abstract: Accurate assessment of neuromuscular reflexes, such as the H-reflex, plays a
critical role in sports science, rehabilitation, and clinical neurology.
Traditional analysis of H-reflex EMG waveforms is subject to variability and
interpretation bias among clinicians and researchers, limiting reliability and
standardization. To address these challenges, we propose a Fine-Tuned
Vision-Language Model (VLM) Consortium and a reasoning Large-Language Model
(LLM)-enabled Decision Support System for automated H-reflex waveform
interpretation and diagnosis. Our approach leverages multiple VLMs, each
fine-tuned on curated datasets of H-reflex EMG waveform images annotated with
clinical observations, recovery timelines, and athlete metadata. These models
are capable of extracting key electrophysiological features and predicting
neuromuscular states, including fatigue, injury, and recovery, directly from
EMG images and contextual metadata. Diagnostic outputs from the VLM consortium
are aggregated using a consensus-based method and refined by a specialized
reasoning LLM, which ensures robust, transparent, and explainable decision
support for clinicians and sports scientists. The end-to-end platform
orchestrates seamless communication between the VLM ensemble and the reasoning
LLM, integrating prompt engineering strategies and automated reasoning
workflows using LLM Agents. Experimental results demonstrate that this hybrid
system delivers highly accurate, consistent, and interpretable H-reflex
assessments, significantly advancing the automation and standardization of
neuromuscular diagnostics. To our knowledge, this work represents the first
integration of a fine-tuned VLM consortium with a reasoning LLM for image-based
H-reflex analysis, laying the foundation for next-generation AI-assisted
neuromuscular assessment and athlete monitoring platforms.

</details>


### [80] [Skin Cancer Classification: Hybrid CNN-Transformer Models with KAN-Based Fusion](https://arxiv.org/abs/2508.12484)
*Shubhi Agarwal,Amulya Kumar Mahto*

Main category: cs.CV

TL;DR: 하이브리드 CNN-Transformer 모델에 CKAN(Convolutional Kolmogorov-Arnold Network)을 결합해 피부암 이미지를 분류한 연구로, 데이터 증강·전이학습을 사용하여 HAM10000, BCN20000, PAD-UFES 데이터셋에서 높은 정확도와 F1을 보고함.


<details>
  <summary>Details</summary>
Motivation: 국소적 특징(CNN)과 전역적 문맥(Transformer)을 동시에 포착하고, 비선형적 특징 융합을 통해 더 판별력 있는 표현을 얻어 피부병변 분류 성능을 개선하려는 목적.

Method: Sequential 및 Parallel 형태의 CNN-Transformer 하이브리드 아키텍처에 CKAN을 삽입하여 비선형 융합(learnable activation functions 포함)을 수행. 전이학습과 광범위한 데이터 증강을 적용하고 세 가지 벤치마크 데이터셋으로 일반화 성능을 평가.

Result: HAM10000: 정확도 92.81%, F1 92.47%; PAD-UFES: 정확도·F1 97.83%; BCN20000: 정확도 91.17%, F1 91.79%. 하이브리드 구조와 CKAN이 특징 융합과 분류 성능을 향상시킴.

Conclusion: CNN과 Transformer의 결합 및 CKAN 기반 비선형 융합이 피부암 분류에서 경쟁력 있는 성능과 데이터셋 간 일반화 능력을 제공함을 주장.

Abstract: Skin cancer classification is a crucial task in medical image analysis, where
precise differentiation between malignant and non-malignant lesions is
essential for early diagnosis and treatment. In this study, we explore
Sequential and Parallel Hybrid CNN-Transformer models with Convolutional
Kolmogorov-Arnold Network (CKAN). Our approach integrates transfer learning and
extensive data augmentation, where CNNs extract local spatial features,
Transformers model global dependencies, and CKAN facilitates nonlinear feature
fusion for improved representation learning. To assess generalization, we
evaluate our models on multiple benchmark datasets (HAM10000,BCN20000 and
PAD-UFES) under varying data distributions and class imbalances. Experimental
results demonstrate that hybrid CNN-Transformer architectures effectively
capture both spatial and contextual features, leading to improved
classification performance. Additionally, the integration of CKAN enhances
feature fusion through learnable activation functions, yielding more
discriminative representations. Our proposed approach achieves competitive
performance in skin cancer classification, demonstrating 92.81% accuracy and
92.47% F1-score on the HAM10000 dataset, 97.83% accuracy and 97.83% F1-score on
the PAD-UFES dataset, and 91.17% accuracy with 91.79% F1- score on the BCN20000
dataset highlighting the effectiveness and generalizability of our model across
diverse datasets. This study highlights the significance of feature
representation and model design in advancing robust and accurate medical image
classification.

</details>


### [81] [Design and Validation of a Responsible Artificial Intelligence-based System for the Referral of Diabetic Retinopathy Patients](https://arxiv.org/abs/2508.12506)
*E. Ulises Moya-Sánchez,Abraham Sánchez-Perez,Raúl Nanclares Da Veiga,Alejandro Zarate-Macías,Edgar Villareal,Alejandro Sánchez-Montes,Edtna Jauregui-Ulloa,Héctor Moreno,Ulises Cortés*

Main category: cs.CV

TL;DR: RAIS-DR는 DR(당뇨망막병증) 선별을 위한 윤리적 책임(AI 윤리 원칙 포함)을 적용한 시스템으로, 전처리·화질평가·세 가지 전문 분류 모델을 통합해 FDA 승인 시스템(EyeArt)보다 로컬 데이터(1,046명)에 대해 F1·정확도·특이도 등에서 유의한 개선을 보였음.


<details>
  <summary>Details</summary>
Motivation: 망막사진 기반 AI 선별은 시력 상실 예방에 유망하나 저화질 데이터와 편향 때문에 임상 적용이 어렵다. 따라서 윤리적 원칙을 AI 수명주기에 적용해 성능과 공정성을 동시에 개선하는 솔루션이 필요하다.

Method: 효율적 컨볼루션 모델들을 이용해 영상 전처리와 화질 평가를 수행하고, 당뇨망막병증을 탐지하는 세 가지 특화된 분류 모델을 통합한 파이프라인(RAIS-DR)을 구축. 로컬 데이터(1,046명, 두 시스템 모두 미학습 데이터)에서 FDA 승인 EyeArt와 비교 평가. 공정성 지표로 Disparate Impact와 Equal Opportunity Difference 사용.

Result: RAIS-DR는 EyeArt 대비 F1 +5–12%, 정확도 +6–19%, 특이도 +10–20% 향상을 보였고, 공정성 지표에서도 인구통계학적 하위집단 간 성능 격차가 작아지는 등 형평성 개선을 확인함.

Conclusion: RAIS-DR는 성능과 공정성 면에서 임상 선별 도구로서 유망하며, 코드와 모델 가중치를 공개하여 책임 있는 AI 실천을 지향함.

Abstract: Diabetic Retinopathy (DR) is a leading cause of vision loss in working-age
individuals. Early detection of DR can reduce the risk of vision loss by up to
95%, but a shortage of retinologists and challenges in timely examination
complicate detection. Artificial Intelligence (AI) models using retinal fundus
photographs (RFPs) offer a promising solution. However, adoption in clinical
settings is hindered by low-quality data and biases that may lead AI systems to
learn unintended features. To address these challenges, we developed RAIS-DR, a
Responsible AI System for DR screening that incorporates ethical principles
across the AI lifecycle. RAIS-DR integrates efficient convolutional models for
preprocessing, quality assessment, and three specialized DR classification
models. We evaluated RAIS-DR against the FDA-approved EyeArt system on a local
dataset of 1,046 patients, unseen by both systems. RAIS-DR demonstrated
significant improvements, with F1 scores increasing by 5-12%, accuracy by
6-19%, and specificity by 10-20%. Additionally, fairness metrics such as
Disparate Impact and Equal Opportunity Difference indicated equitable
performance across demographic subgroups, underscoring RAIS-DR's potential to
reduce healthcare disparities. These results highlight RAIS-DR as a robust and
ethically aligned solution for DR screening in clinical settings. The code,
weights of RAIS-DR are available at
https://gitlab.com/inteligencia-gubernamental-jalisco/jalisco-retinopathy with
RAIL.

</details>


### [82] [LangVision-LoRA-NAS: Neural Architecture Search for Variable LoRA Rank in Vision Language Models](https://arxiv.org/abs/2508.12512)
*Krishna Teja Chitty-Venkata,Murali Emani,Venkatram Vishwanath*

Main category: cs.CV

TL;DR: LoRA의 가중치 저랭크 업데이트에 NAS를 결합해 VLM의 LoRA 랭크를 자동 탐색하여 성능과 효율을 균형시키는 프레임워크를 제안하고, LLaMA-3.2-11B에서 성능 향상과 미세조정 비용 절감을 보고함.


<details>
  <summary>Details</summary>
Motivation: 기존 LoRA는 고정된 랭크를 사용해 작업에 따라 최적의 저랭크 차원을 반영하지 못하고, 불필요한 계산/메모리 비용이 발생할 수 있음. 다양한 멀티모달 작업에 대해 성능과 계산 효율을 동시에 최적화하기 위해 NAS로 랭크를 동적으로 탐색하려는 동기.

Method: Vision Transformer + LLM 기반 VLM에서 LoRA 적용 위치의 저랭크 행렬 차원을 탐색하는 NAS 파이프라인을 설계. NAS가 각 레이어/모듈에 대한 LoRA 랭크 구성을 동적으로 결정하도록 하고, LLaMA-3.2-11B를 대상으로 여러 데이터셋에서 탐색·미세조정을 수행해 최적 구성 도출.

Result: LLaMA-3.2-11B 기반 Vision-Instruct 모델에서 검색된 LoRA 랭크 구성이 고정 랭크 대비 모델 성능을 개선하면서 미세조정 비용(계산/메모리)을 감소시켰음을 보고. 베이스 및 검색된 모델과 코드가 공개됨.

Conclusion: LoRA의 고정 랭크 한계를 NAS로 보완하면 VLM 미세조정에서 성능·효율의 좋은 절충을 얻을 수 있음. 그러나 NAS 비용, 일반화성, 실험 상세(비교 대상·측정 지표·검색 비용 등) 보고가 중요하며 추가 검증이 필요함.

Abstract: Vision Language Models (VLMs) integrate visual and text modalities to enable
multimodal understanding and generation. These models typically combine a
Vision Transformer (ViT) as an image encoder and a Large Language Model (LLM)
for text generation. LoRA (Low-Rank Adaptation) is an efficient fine-tuning
method to adapt pre-trained models to new tasks by introducing low-rank updates
to their weights. While LoRA has emerged as a powerful technique for
fine-tuning large models by introducing low-rank updates, current
implementations assume a fixed rank, potentially limiting flexibility and
efficiency across diverse tasks. This paper introduces
\textit{LangVision-LoRA-NAS}, a novel framework that integrates Neural
Architecture Search (NAS) with LoRA to optimize VLMs for variable-rank
adaptation. Our approach leverages NAS to dynamically search for the optimal
LoRA rank configuration tailored to specific multimodal tasks, balancing
performance and computational efficiency. Through extensive experiments using
the LLaMA-3.2-11B model on several datasets, LangVision-LoRA-NAS demonstrates
notable improvement in model performance while reducing fine-tuning costs. Our
Base and searched fine-tuned models on LLaMA-3.2-11B-Vision-Instruct can be
found
\href{https://huggingface.co/collections/krishnateja95/llama-32-11b-vision-instruct-langvision-lora-nas-6786cac480357a6a6fcc59ee}{\textcolor{blue}{here}}
and the code for LangVision-LoRA-NAS can be found
\href{https://github.com/krishnateja95/LangVision-NAS}{\textcolor{blue}{here}}.

</details>


### [83] [An Initial Study of Bird's-Eye View Generation for Autonomous Vehicles using Cross-View Transformers](https://arxiv.org/abs/2508.12520)
*Felipe Carlos dos Santos,Eric Aislan Antonelo,Gustavo Claudio Karl Couto*

Main category: cs.CV

TL;DR: 카메라 영상을 Cross-View Transformer(CVT)로 변환해 도로·차선·주행경로의 Bird's-Eye View(BEV) 3채널 맵을 학습함. 단일 도시 데이터로 학습했을 때 4-카메라 CVT + L1 손실이 미지의 도시에서 가장 강건한 성능을 보였음.


<details>
  <summary>Details</summary>
Motivation: 자율주행 인식에서 BEV 맵은 구조화된 상향식 표현으로 중요하다. 여러 전방 시점의 카메라로부터 신뢰성 있는 탑다운 BEV를 생성하는 방법을 연구하려 함.

Method: 현실적인 도시 주행 시뮬레이터를 사용해 카메라 입력 → BEV(도로, 차선표시, 계획 경로)로 매핑하는 Cross-View Transformer 기반 모델을 학습. 카메라 배치(카메라 수/레이아웃)와 손실 함수(포컬 vs L1)의 영향을 비교하고, 미지의 도시로의 일반화 성능을 평가.

Result: 단일 도시에서 학습한 경우 4-카메라 CVT를 L1 손실로 학습했을 때 새 도시 테스트에서 가장 안정적인 성능을 기록. 전반적으로 CVT가 카메라 입력을 합리적 정확도의 BEV로 변환하는 데 유망함.

Conclusion: CVT 기반 접근은 다중 카메라 입력으로부터 실용적 BEV 맵을 생성하는 데 효과적이며, 본 실험에서는 L1 손실과 4-카메라 구성 조합이 우수했음. 향후 더 다양한 환경·센서 배치와 종합적 평가가 필요하다.

Abstract: Bird's-Eye View (BEV) maps provide a structured, top-down abstraction that is
crucial for autonomous-driving perception. In this work, we employ Cross-View
Transformers (CVT) for learning to map camera images to three BEV's channels -
road, lane markings, and planned trajectory - using a realistic simulator for
urban driving. Our study examines generalization to unseen towns, the effect of
different camera layouts, and two loss formulations (focal and L1). Using
training data from only a town, a four-camera CVT trained with the L1 loss
delivers the most robust test performance, evaluated in a new town. Overall,
our results underscore CVT's promise for mapping camera inputs to reasonably
accurate BEV maps.

</details>


### [84] [MuSACo: Multimodal Subject-Specific Selection and Adaptation for Expression Recognition with Co-Training](https://arxiv.org/abs/2508.12522)
*Muhammad Osama Zeeshan,Natacha Gillet,Alessandro Lameiras Koerich,Marco Pedersoli,Francois Bremond,Eric Granger*

Main category: cs.CV

TL;DR: MuSACo는 멀티모달·다중 소스 도메인 적응(MSDA)을 이용해 개인별 표현 인식을 향상시키는 코트레이닝 기반 방법이다. 타깃과 관련된 출처(subject)를 선택하고, 우세 모달리티로 의사라벨을 생성해 클래스-의존 학습을 수행하며, 덜 확신하는 타깃 샘플에는 클래스-무관 손실을 적용한다. 모달별 소스 특징을 정렬하고 확신 있는 타깃 특징만 결합해 최종 적응을 진행한다. BioVid와 StressID에서 UDA(블렌딩) 및 기존 MSDA보다 우수한 성능을 보고한다.


<details>
  <summary>Details</summary>
Motivation: 개인별 표현(affective) 신호는 피험자 간 큰 변이가 있어 주체별 적응이 중요하다. 기존 MSDA 방법들은 종종 멀티모달 정보를 충분히 활용하지 못하거나 여러 소스를 하나의 도메인으로 섞어 주체 고유 특성을 잃는다. 의료·디지털 헬스 응용에서는 이런 주체 수준의 미세 차이가 중요하다.

Method: (1) 타깃에 관련된 소스 주체를 선택하는 주체 선택 단계, (2) 코트레이닝으로 우세 모달리티에서 의사라벨 생성하고 클래스-의존 학습 수행, (3) 불확신 타깃 샘플에 대해 클래스-무관 손실을 적용해 불확실한 정보도 이용, (4) 각 모달별로 소스 특징을 정렬하고 확신 있는 타깃 특징만 결합해 적응하는 파이프라인. 멀티모달 보완 정보를 활용하고 소스별(주체별) 특성을 보존하는 것이 핵심.

Result: 다중모달 ER 데이터셋(BioVid, StressID)에서 MuSACo가 기존 UDA(소스 블렌딩) 및 최신 MSDA 방법들보다 성능이 우수했다. 논문은 클래스-의존/무관 손실의 조합과 주체 선택, 모달별 정렬이 기여했음을 보이는 실험 결과(정확도/강건성 개선)를 보고한다.

Conclusion: 멀티모달 정보와 주체 선택을 결합한 코트레이닝 기반 MSDA가 개인화된 표현 인식에 효과적이다. 향후 더 많은 모달·실시간 적응, 의사라벨 노이즈·확신 기준에 대한 민감도 분석, 프라이버시·계산 비용 측면 검토가 필요하다.

Abstract: Personalized expression recognition (ER) involves adapting a machine learning
model to subject-specific data for improved recognition of expressions with
considerable interpersonal variability. Subject-specific ER can benefit
significantly from multi-source domain adaptation (MSDA) methods, where each
domain corresponds to a specific subject, to improve model accuracy and
robustness. Despite promising results, state-of-the-art MSDA approaches often
overlook multimodal information or blend sources into a single domain, limiting
subject diversity and failing to explicitly capture unique subject-specific
characteristics. To address these limitations, we introduce MuSACo, a
multi-modal subject-specific selection and adaptation method for ER based on
co-training. It leverages complementary information across multiple modalities
and multiple source domains for subject-specific adaptation. This makes MuSACo
particularly relevant for affective computing applications in digital health,
such as patient-specific assessment for stress or pain, where subject-level
nuances are crucial. MuSACo selects source subjects relevant to the target and
generates pseudo-labels using the dominant modality for class-aware learning,
in conjunction with a class-agnostic loss to learn from less confident target
samples. Finally, source features from each modality are aligned, while only
confident target features are combined. Our experimental results on challenging
multimodal ER datasets: BioVid and StressID, show that MuSACo can outperform
UDA (blending) and state-of-the-art MSDA methods.

</details>


### [85] [REVEAL -- Reasoning and Evaluation of Visual Evidence through Aligned Language](https://arxiv.org/abs/2508.12543)
*Ipsita Praharaj,Yukta Butala,Yash Butala*

Main category: cs.CV

TL;DR: 생성모델로 인한 이미지 위조 탐지를 비전-언어 모델(VLM)의 프롬프트 기반 시각적 추론 문제로 재정의한 REVEAL 프레임워크를 제안. 전체 장면 수준의 물리·의미·원근·현실성 평가와 영역 단위 이상 감지를 결합해 위조 탐지 및 근거 제공·국지화 수행.


<details>
  <summary>Details</summary>
Motivation: 생성모델의 고도화로 이미지 위조 탐지가 점점 어려워지고 있으며, 단순 분류나 임베딩 기반 이상치 탐지만으로는 도메인 일반화와 근거 제공(설명, 국지화)에 한계가 있음. 대형 비전-언어 모델의 의미 정렬 능력을 이용해 더 일반화 가능한 프롬프트 중심의 추론 방식으로 문제를 풀고자 함.

Method: REVEAL은 프롬프트로 구동되는 시각적 추론 프레임워크. (1) 홀리스틱 장면 평가: 장면 전체의 물리법칙(조명·그림자), 의미적 일관성(사물 관계), 원근·실재감 등을 프롬프트로 점검. (2) 영역별 이상 탐지: 이미지를 여러 영역으로 분할하여 각 영역별로 VLM에게 이상 여부와 이유를 묻고 국지화 정보를 수집. 두 접근을 결합해 판정과 설명을 생성하고, 포토샵·딥페이크·AIGC 편집 데이터셋에서 비교 평가 수행.

Result: 여러 도메인의 데이터셋에서 VLM 기반 접근이 경쟁적 베이스라인과 비교해 합리적인 탐지 성능과 설명(추론) 능력을 보임. 영역 기반 분석은 국지화 정보를 제공하며, 홀리스틱 평가는 전반적 부정합 감지에 유리. 다만 일반화와 정량적 우위는 모델·프롬프트·데이터셋에 따라 달라짐.

Conclusion: 프롬프트 기반 VLM 추론은 위조 탐지에 유망하며, 장면 수준과 영역 수준의 조합이 탐지·설명·국지화 균형을 맞출 수 있음. 향후 프롬프트 설계, 설명의 신뢰성 검증, 정량적 지표(예: IoU, AUC) 및 사용자 연구가 필요함.

Abstract: The rapid advancement of generative models has intensified the challenge of
detecting and interpreting visual forgeries, necessitating robust frameworks
for image forgery detection while providing reasoning as well as localization.
While existing works approach this problem using supervised training for
specific manipulation or anomaly detection in the embedding space,
generalization across domains remains a challenge. We frame this problem of
forgery detection as a prompt-driven visual reasoning task, leveraging the
semantic alignment capabilities of large vision-language models. We propose a
framework, `REVEAL` (Reasoning and Evaluation of Visual Evidence through
Aligned Language), that incorporates generalized guidelines. We propose two
tangential approaches - (1) Holistic Scene-level Evaluation that relies on the
physics, semantics, perspective, and realism of the image as a whole and (2)
Region-wise anomaly detection that splits the image into multiple regions and
analyzes each of them. We conduct experiments over datasets from different
domains (Photoshop, DeepFake and AIGC editing). We compare the Vision Language
Models against competitive baselines and analyze the reasoning provided by
them.

</details>


### [86] [Structure-preserving Feature Alignment for Old Photo Colorization](https://arxiv.org/abs/2508.12570)
*Yingxue Pang,Xin Jin,Jun Fu,Zhibo Chen*

Main category: cs.CV

TL;DR: 저자들은 큰 데이터 없이도 오래된 사진의 색채 복원을 목표로 하는 SFAC(Structure-preserving Feature Alignment Colorizer)를 제안한다. 두 장의 이미지(원본 흑백 사진과 참조 컬러 사진)로만 학습하며, 특징 분포 정렬 손실로 의미론적 대응을 성립하고 픽셀·특징 수준의 구조 보존 기법으로 구조 왜곡을 억제한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 참조 기반 컬러라이제이션은 대규모 데이터에 의존하고, 자연 회색사진과 오래된 사진 사이의 도메인 갭으로 인해 오래된 사진에 직접 적용하기 어렵다. 또한 오래된 사진은 정답(ground truth)이 부족하다. 저자들은 이러한 문제를 해결하기 위해 데이터 의존성을 제거하고 도메인 갭을 극복하는 방법을 제시하고자 한다.

Method: SFAC는 두 장의 이미지(대상 오래된 흑백 사진과 참조 컬러 이미지)만으로 학습한다. 핵심은 의미론적 대응을 위한 특징 분포 정렬 손실(feature distribution alignment loss)로, 다양한 거리(metric) 선택에 대해 강건하도록 설계되었다. 구조 왜곡을 줄이기 위해 특징 수준에서의 지각적 제약(perceptual constraint)과 픽셀 수준에서의 frozen-updated 피라미드 구조를 도입한다. 전체 모델은 CNN 기반이며, 참조로부터 색을 전이하면서 구조를 보존하도록 학습된다.

Result: 정성적, 정량적 실험에서 제안 방법은 오래된 사진 컬러라이제이션에 대해 우수한 성능을 보였다. 특히 적은 데이터 설정에서도 의미적 일관성 있는 색 전이와 구조 보존 능력을 보였다고 보고한다.

Conclusion: 두 장의 이미지만으로도 오래된 사진의 컬러라이제이션을 효과적으로 수행할 수 있음을 보였으며, 특징 분포 정렬과 구조 보존 메커니즘의 결합이 도메인 갭과 학습 데이터 부족 문제를 완화한다고 결론지었다.

Abstract: Deep learning techniques have made significant advancements in
reference-based colorization by training on large-scale datasets. However,
directly applying these methods to the task of colorizing old photos is
challenging due to the lack of ground truth and the notorious domain gap
between natural gray images and old photos. To address this issue, we propose a
novel CNN-based algorithm called SFAC, i.e., Structure-preserving Feature
Alignment Colorizer. SFAC is trained on only two images for old photo
colorization, eliminating the reliance on big data and allowing direct
processing of the old photo itself to overcome the domain gap problem. Our
primary objective is to establish semantic correspondence between the two
images, ensuring that semantically related objects have similar colors. We
achieve this through a feature distribution alignment loss that remains robust
to different metric choices. However, utilizing robust semantic correspondence
to transfer color from the reference to the old photo can result in inevitable
structure distortions. To mitigate this, we introduce a structure-preserving
mechanism that incorporates a perceptual constraint at the feature level and a
frozen-updated pyramid at the pixel level. Extensive experiments demonstrate
the effectiveness of our method for old photo colorization, as confirmed by
qualitative and quantitative metrics.

</details>


### [87] [Foundation Model for Skeleton-Based Human Action Understanding](https://arxiv.org/abs/2508.12586)
*Hongsong Wang,Wanjiang Weng,Junbo Wang,Fang Zhao,Guo-Sen Xie,Xin Geng,Liang Wang*

Main category: cs.CV

TL;DR: USDRL은 스켈레톤 기반 행동 이해를 위한 '파운데이션' 프레임워크로, Transformer 기반의 Dense Spatio-Temporal Encoder(듀얼 스트림), 시간/공간/인스턴스 차원에서의 Multi‑Grained Feature Decorrelation, 다중 뷰·다중 모달 일관성 학습(MPCT)을 결합하여 다양한 행동 이해 과제(코어스 예측·밀도 예측·전이 예측)를 하나의 모델로 처리하고, 25개 벤치마크에서 SOTA를 크게 상회한다고 주장한다.


<details>
  <summary>Details</summary>
Motivation: 기존 연구들이 다양한 행동 이해 과제에 대해 확장성과 일반화를 모두 갖춘 단일 스켈레톤 '파운데이션' 모델을 제공하지 못한다는 문제의식. 특히 밀도(프레임/관절 수준) 예측과 광범위한 전이 능력이 부족함.

Method: (1) DSTE: 시간적 동적 특징과 공간적 구조 특징을 병렬 스트림으로 학습하는 Transformer 기반 인코더. (2) MG‑FD: 시간/공간/인스턴스 도메인에서 특징의 상관을 제거해 차원 중복을 줄이고 표현의 정보를 강화. (3) MPCT: 다중 뷰(augmentation/view)와 다중 모달(예: 관절 위치·골격 속성 등) 간의 자기지도 일관성 손실을 도입해 고수준 의미와 멀티모달 유용 표현을 학습.

Result: 25개 벤치마크(9개 과제: 코스 예측, 밀도 예측, 전이 예측)를 대상으로 광범위 실험을 수행했고, 제안 방법이 현존 최첨단 기법들보다 성능 우위(저자 주장)를 보임.

Conclusion: USDRL은 스켈레톤 기반 행동 이해의 범위를 확장하고 특히 밀도 예측 과제에 대한 연구 관심을 촉진할 수 있는 단일 파운데이션 솔루션을 제안한다.

Abstract: Human action understanding serves as a foundational pillar in the field of
intelligent motion perception. Skeletons serve as a modality- and
device-agnostic representation for human modeling, and skeleton-based action
understanding has potential applications in humanoid robot control and
interaction. \RED{However, existing works often lack the scalability and
generalization required to handle diverse action understanding tasks. There is
no skeleton foundation model that can be adapted to a wide range of action
understanding tasks}. This paper presents a Unified Skeleton-based Dense
Representation Learning (USDRL) framework, which serves as a foundational model
for skeleton-based human action understanding. USDRL consists of a
Transformer-based Dense Spatio-Temporal Encoder (DSTE), Multi-Grained Feature
Decorrelation (MG-FD), and Multi-Perspective Consistency Training (MPCT). The
DSTE module adopts two parallel streams to learn temporal dynamic and spatial
structure features. The MG-FD module collaboratively performs feature
decorrelation across temporal, spatial, and instance domains to reduce
dimensional redundancy and enhance information extraction. The MPCT module
employs both multi-view and multi-modal self-supervised consistency training.
The former enhances the learning of high-level semantics and mitigates the
impact of low-level discrepancies, while the latter effectively facilitates the
learning of informative multimodal features. We perform extensive experiments
on 25 benchmarks across across 9 skeleton-based action understanding tasks,
covering coarse prediction, dense prediction, and transferred prediction. Our
approach significantly outperforms the current state-of-the-art methods. We
hope that this work would broaden the scope of research in skeleton-based
action understanding and encourage more attention to dense prediction tasks.

</details>


### [88] [Multimodal Chain of Continuous Thought for Latent-Space Reasoning in Vision-Language Models](https://arxiv.org/abs/2508.12587)
*Tan-Hanh Pham,Chris Ngo*

Main category: cs.CV

TL;DR: 이 논문은 멀티모달 추론에서 언어 시퀀스 기반의 CoT 한계를 지적하고, 자연어 대신 공동 잠재 공간에서 연속적 사고 상태를 반복적으로 정제하는 MCOUT(두 가지 변형)를 제안한다. 실험에서 여러 멀티모달 벤치마크에 대해 최대 약 8%대 성능 향상을 보고한다.


<details>
  <summary>Details</summary>
Motivation: 기존 Chain-of-Thought(문장 기반) 접근법은 텍스트에는 효과적이나 음성·이미지·텍스트를 동적으로 결합해야 하는 멀티모달 추론에는 부적절하다. 멀티모달 신호를 자연어로 완전히 변환하는 과정에서 정보 손실과 정렬 불일치가 발생한다는 문제가 동기이다.

Method: MCOUT는 추론 상태를 연속적인 잠재 벡터로 표현하고 반복적으로 정제·시각·문자 임베딩과 정렬시킨다. MCOUT-Base는 언어 모델의 마지막 히든 스테이트를 재사용해 연속 사고로 사용하고, MCOUT-Multi는 멀티모달 잠재 어텐션을 도입하여 시각·문자 간의 교차 정렬을 강화한다.

Result: MMMU, ScienceQA, MMStar 등에서 MCOUT가 강력한 베이스라인 대비 최대 8.23% 정확도 향상, BLEU 점수 최대 8.27% 향상을 보이며 멀티플 초이스와 개방형 과제 모두에서 일관된 개선을 보고한다.

Conclusion: 자연어 기반 CoT를 넘어서 잠재 연속 사고로 추론하는 접근은 멀티모달 모델의 교차 모달 정렬과 추론 성능을 향상시키는 유망한 방향이다. 확장성과 인간의 반성적 인지에 영감을 받은 설계로 향후 LMM 발전에 기여할 수 있다.

Abstract: Many reasoning techniques for large multimodal models adapt language model
approaches, such as Chain-of-Thought (CoT) prompting, which express reasoning
as word sequences. While effective for text, these methods are suboptimal for
multimodal contexts, struggling to align audio, visual, and textual information
dynamically. To explore an alternative paradigm, we propose the Multimodal
Chain of Continuous Thought (MCOUT), which enables reasoning directly in a
joint latent space rather than in natural language. In MCOUT, the reasoning
state is represented as a continuous hidden vector, iteratively refined and
aligned with visual and textual embeddings, inspired by human reflective
cognition. We develop two variants: MCOUT-Base, which reuses the language
model`s last hidden state as the continuous thought for iterative reasoning,
and MCOUT-Multi, which integrates multimodal latent attention to strengthen
cross-modal alignment between visual and textual features. Experiments on
benchmarks including MMMU, ScienceQA, and MMStar show that MCOUT consistently
improves multimodal reasoning, yielding up to 8.23% accuracy gains over strong
baselines and improving BLEU scores up to 8.27% across multiple-choice and
open-ended tasks. These findings highlight latent continuous reasoning as a
promising direction for advancing LMMs beyond language-bound CoT, offering a
scalable framework for human-like reflective multimodal inference. Code is
available at https://github.com/Hanhpt23/OmniMod.

</details>


### [89] [ViLaD: A Large Vision Language Diffusion Framework for End-to-End Autonomous Driving](https://arxiv.org/abs/2508.12603)
*Can Cui,Yupeng Zhou,Juntong Peng,Sung-Yeon Park,Zichong Yang,Prashanth Sankaranarayanan,Jiaru Zhang,Ruqi Zhang,Ziran Wang*

Main category: cs.CV

TL;DR: ViLaD는 마스킹된 확산 기반의 대형 비전-언어 확산(LVLD) 프레임워크로, 토큰 순차 생성 대신 전체 주행 결정 시퀀스를 병렬로 생성하여 추론 지연을 크게 줄이고 양방향 추론 및 반복적 품질 개선을 가능하게 한다. nuScenes와 실제 주차 실험에서 기존 autoregressive VLM을 능가하며 실패율 거의 0을 기록.


<details>
  <summary>Details</summary>
Motivation: Autoregressive VLM의 토큰별 순차 생성은 높은 추론 지연과 단방향(과거→미래) 추론 한계로 인해 동적이고 안전이 중요한 실제 주행 환경에 부적합하여, 이를 해결할 새로운 병렬·양방향 생성 프레임워크가 필요함.

Method: 마스킹된 확산(masked diffusion) 모델을 핵심으로 사용해 전체 주행 결정 시퀀스를 병렬로 생성한다. 이 구조는 양방향(reasoning both past and future) 추론을 지원하고, progressive easy-first 전략으로 반복적으로 의사결정 품질을 향상시킨다. 입력은 시각·언어 기반의 end-to-end 체인으로, 실시간성 향상을 목표로 설계됨.

Result: nuScenes 데이터셋에서 평가 시 기존 autoregressive VLM 기반 최첨단 모델보다 계획 정확도 및 추론 속도에서 우수한 성능을 보였고, 실패율은 거의 0에 가까웠다. 또한 실제 자율주행 차량에 배포하여 인터랙티브 주차 과제를 성공적으로 수행함으로써 실용성도 입증함.

Conclusion: ViLaD는 자율주행용 VLM 아키텍처의 패러다임 전환을 제안하며, 실시간성·안전성 측면에서 유의미한 개선을 이룸. 향후 다양한 기상·교통 상황에서의 일반화, 안전성 검증 및 대규모 실환경 테스트가 필요함.

Abstract: End-to-end autonomous driving systems built on Vision Language Models (VLMs)
have shown significant promise, yet their reliance on autoregressive
architectures introduces some limitations for real-world applications. The
sequential, token-by-token generation process of these models results in high
inference latency and cannot perform bidirectional reasoning, making them
unsuitable for dynamic, safety-critical environments. To overcome these
challenges, we introduce ViLaD, a novel Large Vision Language Diffusion (LVLD)
framework for end-to-end autonomous driving that represents a paradigm shift.
ViLaD leverages a masked diffusion model that enables parallel generation of
entire driving decision sequences, significantly reducing computational
latency. Moreover, its architecture supports bidirectional reasoning, allowing
the model to consider both past and future simultaneously, and supports
progressive easy-first generation to iteratively improve decision quality. We
conduct comprehensive experiments on the nuScenes dataset, where ViLaD
outperforms state-of-the-art autoregressive VLM baselines in both planning
accuracy and inference speed, while achieving a near-zero failure rate.
Furthermore, we demonstrate the framework's practical viability through a
real-world deployment on an autonomous vehicle for an interactive parking task,
confirming its effectiveness and soundness for practical applications.

</details>


### [90] [ViDA-UGC: Detailed Image Quality Analysis via Visual Distortion Assessment for UGC Images](https://arxiv.org/abs/2508.12605)
*Wenjie Liao,Jieyu Yuan,Yifang Xu,Chunle Guo,Zilong Zhang,Jihong Li,Jiachen Fu,Haotian Fan,Tao Li,Junhui Cui,Chongyi Li*

Main category: cs.CV

TL;DR: 저자들은 UGC 이미지에 특화된 대규모 시각 왜곡 평가 지시 조정 데이터셋 ViDA-UGC(11K)와 이를 기반으로 검증된 벤치마크 ViDA-UGC-Bench(476 이미지, 6,149 QA)을 제안한다. 인간 주석과 Chain-of-Thought(CoT)를 이용해 GPT-4o로 세부적 품질 기술을 생성·정제했으며, 이로써 다양한 MLLM들의 설명가능한 이미지 품질 분석 능력이 향상되었음을 보인다.


<details>
  <summary>Details</summary>
Motivation: 기존 설명가능 IQA 방법들이 UGC와 AIGC를 동일 기준으로 평가하고, 품질 모니터링·복원 지도를 위한 세부 품질 분석이 부족하다는 문제를 해결하기 위함.

Method: 왜곡 중심 파이프라인: 인간 주석 수집 → CoT 평가 프레임워크로 GPT-4o에 질적 서술 생성 유도 → 전문가가 476 이미지·6,149 QA를 선택·수정하여 벤치마크 제작. 데이터는 미세한 품질 그라운딩, 세부 지각 및 추론 서술 포함.

Result: ViDA-UGC와 CoT 프레임워크로 여러 기반 MLLM의 이미지 품질 분석 능력이 ViDA-UGC-Bench 및 Q-Bench에서 일관되게 향상되었고, 일부 경우 GPT-4o를 능가하는 성능을 보임.

Conclusion: UGC 특화의 세밀한 왜곡 중심 데이터셋과 CoT 기반 지시 조정은 설명가능 IQA 성능을 유의미하게 개선하며, 품질 모니터링과 복원 안내에 활용 가능한 실용적 자산을 제공한다.

Abstract: Recent advances in Multimodal Large Language Models (MLLMs) have introduced a
paradigm shift for Image Quality Assessment (IQA) from unexplainable image
quality scoring to explainable IQA, demonstrating practical applications like
quality control and optimization guidance. However, current explainable IQA
methods not only inadequately use the same distortion criteria to evaluate both
User-Generated Content (UGC) and AI-Generated Content (AIGC) images, but also
lack detailed quality analysis for monitoring image quality and guiding image
restoration. In this study, we establish the first large-scale Visual
Distortion Assessment Instruction Tuning Dataset for UGC images, termed
ViDA-UGC, which comprises 11K images with fine-grained quality grounding,
detailed quality perception, and reasoning quality description data. This
dataset is constructed through a distortion-oriented pipeline, which involves
human subject annotation and a Chain-of-Thought (CoT) assessment framework.
This framework guides GPT-4o to generate quality descriptions by identifying
and analyzing UGC distortions, which helps capturing rich low-level visual
features that inherently correlate with distortion patterns. Moreover, we
carefully select 476 images with corresponding 6,149 question answer pairs from
ViDA-UGC and invite a professional team to ensure the accuracy and quality of
GPT-generated information. The selected and revised data further contribute to
the first UGC distortion assessment benchmark, termed ViDA-UGC-Bench.
Experimental results demonstrate the effectiveness of the ViDA-UGC and CoT
framework for consistently enhancing various image quality analysis abilities
across multiple base MLLMs on ViDA-UGC-Bench and Q-Bench, even surpassing
GPT-4o.

</details>


### [91] [OpenMoCap: Rethinking Optical Motion Capture under Real-world Occlusion](https://arxiv.org/abs/2508.12610)
*Chen Qian,Danyang Li,Xinran Yu,Zheng Yang,Qiang Ma*

Main category: cs.CV

TL;DR: 제안된 OpenMoCap은 대규모 마커 가림(occlusion) 상황에 강인한 모션 솔빙 모델로, 현실적 가림 패턴을 시뮬레이션한 CMU-Occlu 데이터셋과 마커–관절 체인 추론을 결합해 기존 기법들보다 우수한 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 광학 모션 캡처 시스템은 VR·영상 제작 등에서 중요하지만 현실 환경에서는 대규모 마커 가림으로 성능이 크게 저하된다. 현행 모델은 현실적 가림 패턴을 반영한 학습 데이터 부족과 마커 간 장거리 의존성을 학습하는 전략의 부재라는 두 가지 한계가 있다.

Method: CMU-Occlu 데이터셋을 ray tracing으로 생성해 현실적 마커 가림을 재현하고, OpenMoCap이라는 새로운 모션 솔빙 모델을 제안한다. OpenMoCap은 마커-관절(chain) 추론 메커니즘을 통해 마커와 관절 사이의 깊은 제약을 동시에 구성·최적화하며 장거리 의존성을 포착한다. 실제 시스템인 MoSen에 통합해 실전 배포를 목표로 한다.

Result: 다양한 시나리오에서 비교 실험을 수행한 결과 OpenMoCap이 기존 방법들을 일관되게 능가함을 보여준다. CMU-Occlu 데이터셋은 강인한 모션 솔빙 연구를 위한 공개 자원으로 제시된다.

Conclusion: 현실적 가림 시나리오를 반영한 데이터셋과 마커-관절 체인 기반의 모델링을 결합해 대규모 마커 가림 상황에서도 안정적이고 정확한 모션 캡처가 가능함을 확인했다. 코드와 데이터 공개로 후속 연구를 촉진한다.

Abstract: Optical motion capture is a foundational technology driving advancements in
cutting-edge fields such as virtual reality and film production. However,
system performance suffers severely under large-scale marker occlusions common
in real-world applications. An in-depth analysis identifies two primary
limitations of current models: (i) the lack of training datasets accurately
reflecting realistic marker occlusion patterns, and (ii) the absence of
training strategies designed to capture long-range dependencies among markers.
To tackle these challenges, we introduce the CMU-Occlu dataset, which
incorporates ray tracing techniques to realistically simulate practical marker
occlusion patterns. Furthermore, we propose OpenMoCap, a novel motion-solving
model designed specifically for robust motion capture in environments with
significant occlusions. Leveraging a marker-joint chain inference mechanism,
OpenMoCap enables simultaneous optimization and construction of deep
constraints between markers and joints. Extensive comparative experiments
demonstrate that OpenMoCap consistently outperforms competing methods across
diverse scenarios, while the CMU-Occlu dataset opens the door for future
studies in robust motion solving. The proposed OpenMoCap is integrated into the
MoSen MoCap system for practical deployment. The code is released at:
https://github.com/qianchen214/OpenMoCap.

</details>


### [92] [WIPES: Wavelet-based Visual Primitives](https://arxiv.org/abs/2508.12615)
*Wenhao Zhang,Hao Zhu,Delong Wu,Di Kang,Linchao Bao,Zhan Ma,Xun Cao*

Main category: cs.CV

TL;DR: WIPES는 웨이블릿 기반의 시각 프리미티브와 웨이블릿 기반 미분가능 레스터라이저를 결합해 다차원 시각 신호를 연속적으로 표현한다. 저·고주파를 동시에 포착해 INR 기반 방식보다 빠르고, Gaussian 기반 방식보다 렌더링 품질이 우수하다고 주장한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 연속 시각 표현들은 주파수 유도(frequency guidance)나 복잡한 신경망 디코더에 의존해 스펙트럼 손실 또는 렌더링 속도 저하 문제가 있다. 이를 극복해 유연한 주파수 조절과 고속 렌더링이 가능한 범용 표현이 필요하다.

Method: 공간-주파수 지역화 성질을 지닌 웨이블릿을 시각 프리미티브로 사용해 저주파(전반적 구조)와 고주파(세부)를 모두 캡처한다. 또한 웨이블릿 기반의 미분가능 레스터라이저를 설계해 실시간(또는 고속) 렌더링을 지원한다. 2D 이미지, 5D 정적/6D 동적 novel view synthesis에 적용하여 평가하였다.

Result: 실험에서 WIPES는 INR(implicit neural representation) 계열보다 렌더링 품질이 높고 추론 속도가 빠르며, Gaussian 기반 표현보다 품질 면에서 우수한 성능을 보였다고 보고한다.

Conclusion: 웨이블릿 기반 시각 프리미티브와 레스터라이저 조합은 다차원 시각 신호의 연속 표현에서 유망한 대안이며, 품질과 속도 측면에서 장점을 가진다.

Abstract: Pursuing a continuous visual representation that offers flexible frequency
modulation and fast rendering speed has recently garnered increasing attention
in the fields of 3D vision and graphics. However, existing representations
often rely on frequency guidance or complex neural network decoding, leading to
spectrum loss or slow rendering. To address these limitations, we propose
WIPES, a universal Wavelet-based vIsual PrimitivES for representing
multi-dimensional visual signals. Building on the spatial-frequency
localization advantages of wavelets, WIPES effectively captures both the
low-frequency "forest" and the high-frequency "trees." Additionally, we develop
a wavelet-based differentiable rasterizer to achieve fast visual rendering.
Experimental results on various visual tasks, including 2D image
representation, 5D static and 6D dynamic novel view synthesis, demonstrate that
WIPES, as a visual primitive, offers higher rendering quality and faster
inference than INR-based methods, and outperforms Gaussian-based
representations in rendering quality.

</details>


### [93] [Creative4U: MLLMs-based Advertising Creative Image Selector with Comparative Reasoning](https://arxiv.org/abs/2508.12628)
*Yukang Lin,Xiang Zhang,Shichang Jia,Bowen Wan,Chenghan Fu,Xudong Ren,Yueran Liu,Wanxian Guan,Pengji Wang,Jian Xu,Bo Zheng,Baolin Liu*

Main category: cs.CV

TL;DR: This paper proposes the first explainable creative assessment and selection paradigm for advertising images using multimodal large language models (MLLMs). It introduces CreativePair (8k annotated image pairs) and Creative4U, an MLLM-based selector trained via Reason-to-Select RFT combining CoT-SFT and GRPO reinforcement learning. Offline and online experiments reportedly show accurate evaluation and selection; code and dataset will be released.


<details>
  <summary>Details</summary>
Motivation: Advertising creative images critically affect e-commerce performance. With AIGC enabling massive cheap generation, advertisers need explainable, user-aware selection mechanisms rather than opaque ranking to choose high-quality creatives.

Method: Frame assessment/selection as natural language generation using MLLMs. Create CreativePair dataset of comparative pairs. Build Creative4U that incorporates user interests. Train with Reason-to-Select RFT: supervised fine-tuning with Chain-of-Thought (CoT-SFT) and Group Relative Policy Optimization (GRPO) reinforcement learning to improve selection accuracy.

Result: Creative4U outperforms baselines in both offline evaluations on CreativePair and online A/B tests, demonstrating higher selection quality and better alignment with user interests (paper claims).

Conclusion: Provides a novel, explainable MLLM-based pipeline and dataset for creative selection in advertising; shows empirical gains and plans to publicize code/dataset to foster further research and industrial application.

Abstract: Creative image in advertising is the heart and soul of e-commerce platform.
An eye-catching creative image can enhance the shopping experience for users,
boosting income for advertisers and advertising revenue for platforms. With the
advent of AIGC technology, advertisers can produce large quantities of creative
images at minimal cost. However, they struggle to assess the creative quality
to select. Existing methods primarily focus on creative ranking, which fails to
address the need for explainable creative selection.
  In this work, we propose the first paradigm for explainable creative
assessment and selection. Powered by multimodal large language models (MLLMs),
our approach integrates the assessment and selection of creative images into a
natural language generation task. To facilitate this research, we construct
CreativePair, the first comparative reasoning-induced creative dataset
featuring 8k annotated image pairs, with each sample including a label
indicating which image is superior. Additionally, we introduce Creative4U
(pronounced Creative for You), a MLLMs-based creative selector that takes into
account users' interests. Through Reason-to-Select RFT, which includes
supervised fine-tuning with Chain-of-Thought (CoT-SFT) and Group Relative
Policy Optimization (GRPO) based reinforcement learning, Creative4U is able to
evaluate and select creative images accurately. Both offline and online
experiments demonstrate the effectiveness of our approach. Our code and dataset
will be made public to advance research and industrial applications.

</details>


### [94] [SpotVLM: Cloud-edge Collaborative Real-time VLM based on Context Transfer](https://arxiv.org/abs/2508.12638)
*Chen Qian,Xinran Yu,Zewen Huang,Danyang Li,Qiang Ma,Fan Dang,Xuan Ding,Guangyong Shang,Zheng Yang*

Main category: cs.CV

TL;DR: Proposes "Context Transfer": use delayed LVLM outputs as historical context to guide SVLMs for real-time vision tasks; implements SpotVLM with context replacement and visual focus, showing improved performance under cloud latency.


<details>
  <summary>Details</summary>
Motivation: Real-time VLM applications need both fast and accurate perception, but cloud-edge methods (partitioned LVLMs or offloading between LVLM/SVLM) don't handle cloud latency fluctuations nor exploit delayed accurate LVLM outputs.

Method: Introduce Context Transfer paradigm that treats delayed LVLM outputs as historical context for SVLM inference. Build SpotVLM with two modules: context replacement (refines historical textual context) and visual focus (improves grounding consistency).

Result: Extensive experiments on three real-time vision tasks across four datasets demonstrate the framework's effectiveness; shows improved latency-aware collaboration and better real-time guidance of SVLMs.

Conclusion: Context Transfer offers a new latency-aware cloud-edge collaboration strategy for VLMs, leveraging delayed but accurate LVLM outputs to improve real-time SVLM inference and laying groundwork for future methods.

Abstract: Vision-Language Models (VLMs) are increasingly deployed in real-time
applications such as autonomous driving and human-computer interaction, which
demand fast and reliable responses based on accurate perception. To meet these
requirements, existing systems commonly employ cloud-edge collaborative
architectures, such as partitioned Large Vision-Language Models (LVLMs) or task
offloading strategies between Large and Small Vision-Language Models (SVLMs).
However, these methods fail to accommodate cloud latency fluctuations and
overlook the full potential of delayed but accurate LVLM responses. In this
work, we propose a novel cloud-edge collaborative paradigm for VLMs, termed
Context Transfer, which treats the delayed outputs of LVLMs as historical
context to provide real-time guidance for SVLMs inference. Based on this
paradigm, we design SpotVLM, which incorporates both context replacement and
visual focus modules to refine historical textual input and enhance visual
grounding consistency. Extensive experiments on three real-time vision tasks
across four datasets demonstrate the effectiveness of the proposed framework.
The new paradigm lays the groundwork for more effective and latency-aware
collaboration strategies in future VLM systems.

</details>


### [95] [Synthesizing Accurate and Realistic T1-weighted Contrast-Enhanced MR Images using Posterior-Mean Rectified Flow](https://arxiv.org/abs/2508.12640)
*Bastian Brandstötter,Erich Kobler*

Main category: cs.CV

TL;DR: Two-stage method (posterior-mean 3D U-Net + time-conditioned 3D rectified flow) to synthesize contrast-enhanced T1w brain MRI from non-contrast inputs; achieves much lower perceptual scores (FID/KID) while keeping low volumetric MSE on a multi-institutional BraTS 2023–2025 test set of 360 volumes.


<details>
  <summary>Details</summary>
Motivation: Avoid gadolinium contrast agents due to cost, time, environmental impact, and patient risk by generating synthetic CE MRI from non-contrast scans while preserving diagnostic structures and adding realistic texture.

Method: Stage 1: patch-based 3D U-Net trained to predict voxel-wise posterior mean (MSE minimizer). Stage 2: time-conditioned 3D rectified flow (Posterior-Mean Rectified Flow, PMRF) refines the U-Net output to add realistic textures without degrading structural fidelity. Trained on paired pre/post-contrast T1w volumes from BraTS 2023–2025.

Result: On 360 held-out volumes, refined outputs achieved axial FID=12.46 and KID=0.007 (~68.7% lower FID vs posterior mean) and volumetric MSE=0.057 (~27% higher than posterior mean). Qualitatively, lesion margins and vascular details are more realistic, suggesting favorable perception–distortion trade-off.

Conclusion: PMRF effectively balances structural fidelity and perceptual realism for CE MRI synthesis, reducing perceptual error substantially with modest increase in MSE; promising for clinical deployment but needs further clinical validation.

Abstract: Contrast-enhanced (CE) T1-weighted MRI is central to neuro-oncologic
diagnosis but requires gadolinium-based agents, which add cost and scan time,
raise environmental concerns, and may pose risks to patients. In this work, we
propose a two-stage Posterior-Mean Rectified Flow (PMRF) pipeline for
synthesizing volumetric CE brain MRI from non-contrast inputs. First, a
patch-based 3D U-Net predicts the voxel-wise posterior mean (minimizing MSE).
Then, this initial estimate is refined by a time-conditioned 3D rectified flow
to incorporate realistic textures without compromising structural fidelity. We
train this model on a multi-institutional collection of paired pre- and
post-contrast T1w volumes (BraTS 2023-2025). On a held-out test set of 360
diverse volumes, our best refined outputs achieve an axial FID of $12.46$ and
KID of $0.007$ ($\sim 68.7\%$ lower FID than the posterior mean) while
maintaining low volumetric MSE of $0.057$ ($\sim 27\%$ higher than the
posterior mean). Qualitative comparisons confirm that our method restores
lesion margins and vascular details realistically, effectively navigating the
perception-distortion trade-off for clinical deployment.

</details>


### [96] [Learn Faster and Remember More: Balancing Exploration and Exploitation for Continual Test-time Adaptation](https://arxiv.org/abs/2508.12643)
*Pinci Yang,Peisong Wen,Ke Ma,Qianqian Xu*

Main category: cs.CV

TL;DR: 본 논문은 Mean Teacher 기반의 CTTA 방법 BEE를 제안한다. 중간층 정합을 위한 MCR과 역사적 체크포인트를 재활용하는 CAR로 탐색(exploration)을 가속하고 착취(exploitation)를 회복·유지해 기존 기법들보다 우수한 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: CTTA에서는 새로운 도메인에 빠르게 적응하면서 이전 도메인의 지식을 잃지 않고 재활용하는 균형이 필요하다. 기존 방법들은 주로 심층 출력 예측을 보정해 얕은 특성의 도메인 변화를 효과적으로 반영하지 못하고, 단일 모델의 지속적 적응 과정에서 과거 지식을 잃는 망각 문제를 겪는다.

Method: 제안된 BEE는 Mean Teacher 프레임워크를 기반으로 두 가지 핵심 구성요소를 가진다. 1) Multi-level Consistency Regularization(MCR): 학생·교사 모델의 중간층 특성들에 대한 정합 손실을 도입해 얕은 특징 레벨에서의 도메인 변화를 직접 조정하여 적응 속도를 높인다. 2) Complementary Anchor Replay(CAR): 과거 체크포인트(앵커)를 보관·선택적으로 재사용해 탐색 과정에서 소실된 보완적 지식을 복구하고 유사한 미래 도메인에 대한 활용성을 확보한다.

Result: 여러 벤치마크에서 제안 기법이 기존 최첨단 방법들보다 유의미하게 성능이 향상됨을 보였다고 보고한다(구체적 수치 및 데이터셋은 초록에 없음).

Conclusion: MCR과 CAR를 결합한 Mean Teacher 기반의 BEE는 CTTA에서 탐색과 착취 사이의 균형을 효과적으로 달성하며, 적응 속도와 과거 지식의 재활용 측면에서 개선을 제공한다.

Abstract: Continual Test-Time Adaptation (CTTA) aims to adapt a source pre-trained
model to continually changing target domains during inference. As a fundamental
principle, an ideal CTTA method should rapidly adapt to new domains
(exploration) while retaining and exploiting knowledge from previously
encountered domains to handle similar domains in the future. Despite
significant advances, balancing exploration and exploitation in CTTA is still
challenging: 1) Existing methods focus on adjusting predictions based on
deep-layer outputs of neural networks. However, domain shifts typically affect
shallow features, which are inefficient to be adjusted from deep predictions,
leading to dilatory exploration; 2) A single model inevitably forgets knowledge
of previous domains during the exploration, making it incapable of exploiting
historical knowledge to handle similar future domains. To address these
challenges, this paper proposes a mean teacher framework that strikes an
appropriate Balance between Exploration and Exploitation (BEE) during the CTTA
process. For the former challenge, we introduce a Multi-level Consistency
Regularization (MCR) loss that aligns the intermediate features of the student
and teacher models, accelerating adaptation to the current domain. For the
latter challenge, we employ a Complementary Anchor Replay (CAR) mechanism to
reuse historical checkpoints (anchors), recovering complementary knowledge for
diverse domains. Experiments show that our method significantly outperforms
state-of-the-art methods on several benchmarks, demonstrating its effectiveness
for CTTA tasks.

</details>


### [97] [Vision-G1: Towards General Vision Language Reasoning with Multi-Domain Data Curation](https://arxiv.org/abs/2508.12680)
*Yuheng Zha,Kun Zhou,Yujia Wu,Yushu Wang,Jie Feng,Zhi Xu,Shibo Hao,Zhengzhong Liu,Eric P. Xing,Zhiting Hu*

Main category: cs.CV

TL;DR: Vision-G1은 46개 소스, 8개 도메인을 아우르는 RL-적합 시각 추론 데이터셋과 영향함수 기반 샘플 선택·난이도 필터링, 데이터 커리큘럼 기반 다중 라운드 RL 훈련을 통해 다양한 시각 추론 벤치마크에서 SOTA 성능을 달성한 VLM이다.


<details>
  <summary>Details</summary>
Motivation: 기존 추론형 VLM 훈련 파이프라인은 수학·논리 등 제한된 과제에 집중되어 있어 보상 데이터 부족과 도메인 간 데이터 호환성 문제로 다양한 영역으로의 추론 일반화가 어렵다.

Method: 46개 데이터 소스에서 8개 차원(인포그래픽, 수학, 공간, 이미지 간, GUI, 의료, 상식, 일반과학)을 포함한 RL-준비 시각 추론 데이터셋 구축. 영향함수 기반 데이터 선택과 난이도 기반 필터링으로 고품질 샘플 식별. 데이터 커리큘럼을 적용한 다중 라운드 강화학습으로 모델(Vision-G1) 학습.

Result: 다양한 시각 추론 벤치마크에서 유사 크기 VLM 및 GPT-4o, Gemini-1.5 Flash 같은 상용 모델을 능가하는 성능을 보고. 데이터셋·코드·모델 공개.

Conclusion: 광범위한 도메인에 걸친 고품질 데이터 선별 및 커리큘럼 기반 RL 훈련이 시각 추론 일반화 능력을 크게 향상시키며, 공개 리소스를 통해 재현 가능성과 추가 연구를 촉진한다.

Abstract: Despite their success, current training pipelines for reasoning VLMs focus on
a limited range of tasks, such as mathematical and logical reasoning. As a
result, these models face difficulties in generalizing their reasoning
capabilities to a wide range of domains, primarily due to the scarcity of
readily available and verifiable reward data beyond these narrowly defined
areas. Moreover, integrating data from multiple domains is challenging, as the
compatibility between domain-specific datasets remains uncertain. To address
these limitations, we build a comprehensive RL-ready visual reasoning dataset
from 46 data sources across 8 dimensions, covering a wide range of tasks such
as infographic, mathematical, spatial, cross-image, graphic user interface,
medical, common sense and general science. We propose an influence function
based data selection and difficulty based filtering strategy to identify
high-quality training samples from this dataset. Subsequently, we train the
VLM, referred to as Vision-G1, using multi-round RL with a data curriculum to
iteratively improve its visual reasoning capabilities. Our model achieves
state-of-the-art performance across various visual reasoning benchmarks,
outperforming similar-sized VLMs and even proprietary models like GPT-4o and
Gemini-1.5 Flash. The model, code and dataset are publicly available at
https://github.com/yuh-zha/Vision-G1.

</details>


### [98] [DyCrowd: Towards Dynamic Crowd Reconstruction from a Large-scene Video](https://arxiv.org/abs/2508.12644)
*Hao Wen,Hongbo Kang,Jian Ma,Jing Huang,Yuanwang Yang,Haozhe Lin,Yu-Kun Lai,Kun Li*

Main category: cs.CV

TL;DR: DyCrowd: 첫 대규모 장면 비디오에서 수백 명의 사람들에 대해 시공간적으로 일관된 3D 포즈·위치·형상을 복원하는 프레임워크. 그룹 기반의 coarse-to-fine 모션 최적화, VAE 모션 프라이어, 세그먼트 수준의 그룹 최적화와 Asynchronous Motion Consistency 손실로 장기 동적 가림(occlusion)에 강한 복원을 달성. VirtualCrowd라는 가상 벤치마크도 제안.


<details>
  <summary>Details</summary>
Motivation: 정적인 단일 이미지 기반 군중 3D 복원은 시간적 일관성이 부족하고 가림(occlusion) 문제를 완화하지 못함. 대규모 장면에서 다수 인물의 시공간 일관된 동적 복원이 필요함.

Method: 장면 내 유사한 움직임을 보이는 사람들을 그룹화한 뒤 coarse-to-fine 그룹 유도 모션 최적화를 수행. VAE 기반 인간 모션 프라이어와 세그먼트 수준 그룹 최적화를 결합해, 동기화되지 않은(비동기적) 또는 리듬이 다른 모션에서도 잘 동작하도록 Asynchronous Motion Consistency(AMC) 손실을 도입. 이로써 가려진 구간을 유사한 비가려진 모션 세그먼트로부터 복구.

Result: 대규모 장면 동적 군중 3D 복원에서 SOTA 성능을 보고. VirtualCrowd 데이터셋을 공개하여 평가 기준을 제공하며 코드/데이터 공개 예정.

Conclusion: 집단 행동을 이용한 공동 최적화와 모션 프라이어의 결합으로, 장기적이고 동적인 가림 상황에서도 현실적이고 일관된 군중 3D 복원을 달성한 최초의 프레임워크 중 하나.

Abstract: 3D reconstruction of dynamic crowds in large scenes has become increasingly
important for applications such as city surveillance and crowd analysis.
However, current works attempt to reconstruct 3D crowds from a static image,
causing a lack of temporal consistency and inability to alleviate the typical
impact caused by occlusions. In this paper, we propose DyCrowd, the first
framework for spatio-temporally consistent 3D reconstruction of hundreds of
individuals' poses, positions and shapes from a large-scene video. We design a
coarse-to-fine group-guided motion optimization strategy for occlusion-robust
crowd reconstruction in large scenes. To address temporal instability and
severe occlusions, we further incorporate a VAE (Variational Autoencoder)-based
human motion prior along with a segment-level group-guided optimization. The
core of our strategy leverages collective crowd behavior to address long-term
dynamic occlusions. By jointly optimizing the motion sequences of individuals
with similar motion segments and combining this with the proposed Asynchronous
Motion Consistency (AMC) loss, we enable high-quality unoccluded motion
segments to guide the motion recovery of occluded ones, ensuring robust and
plausible motion recovery even in the presence of temporal desynchronization
and rhythmic inconsistencies. Additionally, in order to fill the gap of no
existing well-annotated large-scene video dataset, we contribute a virtual
benchmark dataset, VirtualCrowd, for evaluating dynamic crowd reconstruction
from large-scene videos. Experimental results demonstrate that the proposed
method achieves state-of-the-art performance in the large-scene dynamic crowd
reconstruction task. The code and dataset will be available for research
purposes.

</details>


### [99] [Stable Diffusion-Based Approach for Human De-Occlusion](https://arxiv.org/abs/2508.12663)
*Seung Young Noh,Ju Yong Chang*

Main category: cs.CV

TL;DR: 사람의 부분 가려짐을 복원하기 위해 두 단계(마스크 복원 → RGB 복원)로 나누고, 확산 기반 인체 구조 프라이어와 가려진 관절 히트맵을 이용해 아모달 마스크를 생성한 뒤 Stable Diffusion(여기에 VQA→CLIP로 얻은 인물 텍스트 피처를 조건으로 사용)과 디코더 파인튜닝으로 RGB를 복원한다. 기존 기법들보다 마스크·RGB 복원 성능이 우수하고, 복원된 이미지는 2D 포즈·3D 복원 성능을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 딥러닝 모델이 가려진(occluded) 인물의 신체 구조와 외형을 정확히 복원하는 것은 여전히 어려움. 특히 인체는 해부학적 제약과 의미적 제약이 있어 일반 오브젝트보다 특화된 프라이어를 활용하면 유리하다는 점에서 연구 동기가 생김.

Method: 두 단계 접근: (1) 마스크 복원 — 확산 기반 인체 바디 프라이어와 가려진 관절 히트맵(공간적 단서)을 결합해 아모달 마스크 생성. (2) RGB 복원 — 생성된 아모달 마스크를 조건으로 Stable Diffusion을 이용해 픽셀값 생성. 추가적으로 VQA 모델로 얻은 인간 특화 텍스트 정보를 CLIP 인코더로 임베딩해 RGB 생성에 보조조건으로 투입. 마지막에 디코더를 파인튜닝해 라텐트 변환으로 인한 가시 영역 열화를 완화함.

Result: 심한 가려짐 상황에서도 인체 외형과 구조를 효과적으로 재구성하고, 기존 방법들보다 마스크 및 RGB 복원에서 일관되게 우수한 성능을 보임. 생성된 비가려진(De-occluded) 이미지는 2D 포즈 추정과 3D 인체 복원 같은 다운스트림 작업의 성능을 향상시킴.

Conclusion: 인체 특화 프라이어와 명시적 공간 단서(관절 히트맵), 텍스트 조건, 그리고 디코더 파인튜닝을 결합하면 확산 기반 접근으로도 고품질의 인체 de-occlusion이 가능하며 실용적 개선(다운스트림 성능 향상)을 제공한다.

Abstract: Humans can infer the missing parts of an occluded object by leveraging prior
knowledge and visible cues. However, enabling deep learning models to
accurately predict such occluded regions remains a challenging task.
De-occlusion addresses this problem by reconstructing both the mask and RGB
appearance. In this work, we focus on human de-occlusion, specifically
targeting the recovery of occluded body structures and appearances. Our
approach decomposes the task into two stages: mask completion and RGB
completion. The first stage leverages a diffusion-based human body prior to
provide a comprehensive representation of body structure, combined with
occluded joint heatmaps that offer explicit spatial cues about missing regions.
The reconstructed amodal mask then serves as a conditioning input for the
second stage, guiding the model on which areas require RGB reconstruction. To
further enhance RGB generation, we incorporate human-specific textual features
derived using a visual question answering (VQA) model and encoded via a CLIP
encoder. RGB completion is performed using Stable Diffusion, with decoder
fine-tuning applied to mitigate pixel-level degradation in visible regions -- a
known limitation of prior diffusion-based de-occlusion methods caused by latent
space transformations. Our method effectively reconstructs human appearances
even under severe occlusions and consistently outperforms existing methods in
both mask and RGB completion. Moreover, the de-occluded images generated by our
approach can improve the performance of downstream human-centric tasks, such as
2D pose estimation and 3D human reconstruction. The code will be made publicly
available.

</details>


### [100] [WP-CLIP: Leveraging CLIP to Predict Wölfflin's Principles in Visual Art](https://arxiv.org/abs/2508.12668)
*Abhijay Ghildyal,Li-Yun Wang,Feng Liu*

Main category: cs.CV

TL;DR: CLIP은 사전학습 상태에서는 Wölfflin의 다섯 원리를 잘 포착하지 못했으나, 미술 이미지에 주석을 달아 CLIP을 미세조정한 WP-CLIP은 각 원리별 점수를 예측할 수 있으며 GAN 생성화와 Pandora-18K에서 스타일 일반화 능력을 보였다.


<details>
  <summary>Details</summary>
Motivation: Wölfflin의 다섯 원리는 회화 형식·양식 분석의 구조화된 틀을 제공하지만, 이를 일관되게 예측하는 자동화된 시각 메트릭은 부재하다. 최근 VLM(예: CLIP)의 추상적 이미지 속성 평가 능력은 이 문제 해결 가능성을 제시한다.

Method: 사전학습 CLIP의 성능을 먼저 평가하고, 실제 미술 이미지에 Wölfflin 원리 점수 주석을 달아 데이터셋을 구성한 뒤 CLIP을 미세조정(fine-tuning)하여 각 원리를 예측하는 회귀/분류 모델(WP-CLIP)을 학습시켰다. 학습된 모델을 GAN이 생성한 회화와 Pandora-18K 데이터셋에서 검증했다.

Result: 사전학습된 CLIP은 Wölfflin의 미묘한 양식적 속성을 충분히 포착하지 못했으나, WP-CLIP은 주석 데이터로 미세조정함으로써 각 원리의 점수를 예측할 수 있었고, 다양한 스타일로 구성된 평가셋에서 일반화 능력을 보였다.

Conclusion: VLM을 해당 도메인 주석으로 미세조정하면 전통적 미술사 이론(예: Wölfflin 원리)을 자동으로 분석·예측할 수 있는 실용적 도구를 만들 수 있다. 다만 주석 품질·데이터 편향·해석 가능성 같은 한계는 후속 연구에서 보완되어야 한다.

Abstract: W\"olfflin's five principles offer a structured approach to analyzing
stylistic variations for formal analysis. However, no existing metric
effectively predicts all five principles in visual art. Computationally
evaluating the visual aspects of a painting requires a metric that can
interpret key elements such as color, composition, and thematic choices. Recent
advancements in vision-language models (VLMs) have demonstrated their ability
to evaluate abstract image attributes, making them promising candidates for
this task. In this work, we investigate whether CLIP, pre-trained on
large-scale data, can understand and predict W\"olfflin's principles. Our
findings indicate that it does not inherently capture such nuanced stylistic
elements. To address this, we fine-tune CLIP on annotated datasets of real art
images to predict a score for each principle. We evaluate our model, WP-CLIP,
on GAN-generated paintings and the Pandora-18K art dataset, demonstrating its
ability to generalize across diverse artistic styles. Our results highlight the
potential of VLMs for automated art analysis.

</details>


### [101] [Refine-and-Contrast: Adaptive Instance-Aware BEV Representations for Multi-UAV Collaborative Object Detection](https://arxiv.org/abs/2508.12684)
*Zhongyao Li,Peirui Cheng,Liangjin Zhao,Chen Chen,Yundu Li,Zhechao Wang,Xue Yang,Xian Sun,Zhirui Wang*

Main category: cs.CV

TL;DR: AdaBEV는 인스턴스-인식 BEV 표현을 학습하는 경량 다중-UAV 3D 검출 프레임워크로, 박스-유도 정제와 인스턴스-배경 대조학습을 통해 저해상도 BEV에서 계산 비용을 낮추면서 검출 성능을 유지·향상한다.


<details>
  <summary>Details</summary>
Motivation: 다중 UAV의 협업 3D 검출은 시야와 피사체 가림 문제에 유리하지만, UAV의 연산 자원이 제한적이므로 모든 BEV 격자를 동등하게 처리하는 기존 접근은 비효율적이다. 중요(전경) 영역에 연산을 집중하고 표현의 판별력을 높일 필요가 있다.

Method: 두 가지 핵심 모듈을 제안: (1) Box-Guided Refinement Module (BG-RM) — 2D 감독과 공간 분할을 이용해 전경 인스턴스에 대응하는 BEV 격자만 선택적으로 정제; (2) Instance-Background Contrastive Learning (IBCL) — BEV 공간에서 전경과 배경 특징의 분리를 촉진하는 대조 학습. 전반적인 학습은 refine-and-contrast 패러다임으로 구성됨.

Result: Air-Co-Pred 데이터셋에서 다양한 모델 스케일 기준으로 정확도-계산량 트레이드오프가 우수함. 저해상도 BEV 입력에서 SOTA를 능가하며, 계산 오버헤드는 거의 없으면서 상한 성능에 근접.

Conclusion: 인스턴스-인지적 정제와 BEV 대조학습 결합으로, AdaBEV는 자원 제약 환경(UAV)에 적합한 효율적이고 판별력 있는 BEV 표현을 제공하여 저해상도에서도 높은 검출 성능을 달성한다.

Abstract: Multi-UAV collaborative 3D detection enables accurate and robust perception
by fusing multi-view observations from aerial platforms, offering significant
advantages in coverage and occlusion handling, while posing new challenges for
computation on resource-constrained UAV platforms. In this paper, we present
AdaBEV, a novel framework that learns adaptive instance-aware BEV
representations through a refine-and-contrast paradigm. Unlike existing methods
that treat all BEV grids equally, AdaBEV introduces a Box-Guided Refinement
Module (BG-RM) and an Instance-Background Contrastive Learning (IBCL) to
enhance semantic awareness and feature discriminability. BG-RM refines only BEV
grids associated with foreground instances using 2D supervision and spatial
subdivision, while IBCL promotes stronger separation between foreground and
background features via contrastive learning in BEV space. Extensive
experiments on the Air-Co-Pred dataset demonstrate that AdaBEV achieves
superior accuracy-computation trade-offs across model scales, outperforming
other state-of-the-art methods at low resolutions and approaching upper bound
performance while maintaining low-resolution BEV inputs and negligible
overhead.

</details>


### [102] [TTA-DAME: Test-Time Adaptation with Domain Augmentation and Model Ensemble for Dynamic Driving Conditions](https://arxiv.org/abs/2508.12690)
*Dongjae Jeon,Taeheon Kim,Seongwon Cho,Minhyuk Seo,Jonghyun Choi*

Main category: cs.CV

TL;DR: 제안한 TTA-DAME는 소스 데이터의 도메인 증강과 도메인 판별기/감지기를 결합하고 다수의 감지기 예측을 NMS로 통합하여 주행 장면의 날씨·시간대 변화에 대해 테스트 시 적응 성능을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 실제 주행 환경에서는 날씨와 시간대에 따른 도메인 변화가 빈번하게 발생하며, 고정된 모델은 이러한 급격한 변화(예: 주간→야간)에 취약하다. 따라서 테스트 시점에서 동적으로 적응해 안정적인 성능을 유지하는 방법이 필요하다.

Method: TTA-DAME은 (1) 소스 도메인 데이터를 목표(타깃) 도메인 방향으로 증강하여 적응 신호를 마련하고, (2) 도메인 판별기(domain discriminator)를 도입해 도메인 차이를 파악·완화하며, (3) 급격한 도메인 이동(특히 주간→야간)을 완화하기 위한 전문화된 도메인 감지기(domain detector)를 사용한다. 추가로 여러 감지기를 학습시켜 각기 예측을 생성한 뒤 Non-Maximum Suppression(NMS)으로 통합해 안정성을 높인다.

Result: 저자들이 제시한 실험에서 SHIFT Benchmark 상에서 유의미한 성능 향상이 보고되었다(구체적 수치·비교 대상은 초록에 명시되지 않음).

Conclusion: 방법은 실제 주행 장면의 도메인 변화에 대한 테스트 타임 적응력 향상에 효과적임을 시사하나, 구체적 수치·비교, 추가 데이터셋 일반화성 등은 더 확인이 필요하다.

Abstract: Test-time Adaptation (TTA) poses a challenge, requiring models to dynamically
adapt and perform optimally on shifting target domains. This task is
particularly emphasized in real-world driving scenes, where weather domain
shifts occur frequently. To address such dynamic changes, our proposed method,
TTA-DAME, leverages source domain data augmentation into target domains.
Additionally, we introduce a domain discriminator and a specialized domain
detector to mitigate drastic domain shifts, especially from daytime to
nighttime conditions. To further improve adaptability, we train multiple
detectors and consolidate their predictions through Non-Maximum Suppression
(NMS). Our empirical validation demonstrates the effectiveness of our method,
showing significant performance enhancements on the SHIFT Benchmark.

</details>


### [103] [Multi-Level Knowledge Distillation and Dynamic Self-Supervised Learning for Continual Learning](https://arxiv.org/abs/2508.12692)
*Taeheon Kim,San Kim,Minhyuk Seo,Dongjae Jeon,Wonje Jeong,Jonghyun Choi*

Main category: cs.CV

TL;DR: Class-incremental with repetition(CIR) 환경에서 풍부한 외부 무라벨 데이터를 활용해 안정성(stability)과 가소성(plasticity)을 유지하는 방법을 제안. 다중 이전 모델·다중 관점 지식 증류(MLKD)와 동적 자가지도학습 손실(dynamic SSL)을 결합하여 성능을 크게 향상시킴.


<details>
  <summary>Details</summary>
Motivation: 전통적인 클래스 점증 학습은 각 작업에 완전히 새로운 클래스만 포함된다고 가정하지만, 현실에서는 이전에 본 클래스들이 반복되어 나타나는 경우가 흔함(CIR). 또한 인터넷 등에서 풍부한 무라벨 데이터를 쉽게 얻을 수 있으므로 이를 효율적으로 활용하면 모델의 안정성(기존 지식 유지)과 가소성(신규 클래스 학습)을 동시에 개선할 수 있음.

Method: 1) 다중 수준 지식 증류(MLKD): 과거의 여러 모델들로부터 특징(feature)과 로짓(logit) 등 여러 관점에서 지식을 증류하여 다양한 이전 지식을 보존. 2) 동적 자가지도학습 손실(dynamic SSL): 외부 무라벨 데이터를 활용해 신규 클래스 학습을 가속하고, 학습 과정에서 자가지도 손실의 가중치를 동적으로 조절해 주요(레이블) 작업에 초점을 유지.

Result: 제안된 두 구성 요소는 CIR 환경에서 성능을 크게 개선했으며, CVPR 5th CLVISION Challenge에서 2위를 달성함.

Conclusion: MLKD와 동적 SSL의 결합은 무라벨 외부 데이터를 활용해 CIR에서 안정성과 가소성을 균형 있게 확보하는 실용적이고 효과적인 방법임.

Abstract: Class-incremental with repetition (CIR), where previously trained classes
repeatedly introduced in future tasks, is a more realistic scenario than the
traditional class incremental setup, which assumes that each task contains
unseen classes. CIR assumes that we can easily access abundant unlabeled data
from external sources, such as the Internet. Therefore, we propose two
components that efficiently use the unlabeled data to ensure the high stability
and the plasticity of models trained in CIR setup. First, we introduce
multi-level knowledge distillation (MLKD) that distills knowledge from multiple
previous models across multiple perspectives, including features and logits, so
the model can maintain much various previous knowledge. Moreover, we implement
dynamic self-supervised loss (SSL) to utilize the unlabeled data that
accelerates the learning of new classes, while dynamic weighting of SSL keeps
the focus of training to the primary task. Both of our proposed components
significantly improve the performance in CIR setup, achieving 2nd place in the
CVPR 5th CLVISION Challenge.

</details>


### [104] [Neural Rendering for Sensor Adaptation in 3D Object Detection](https://arxiv.org/abs/2508.12695)
*Felix Embacher,David Holtz,Jonas Uhrig,Marius Cordts,Markus Enzweiler*

Main category: cs.CV

TL;DR: CamShift는 CARLA에서 생성된 데이터셋으로, 차량 유형(서브컴팩트↔SUV)에 따른 카메라 센서 구성 차이로 발생하는 크로스-센서 도메인 갭이 3D 객체 검출 성능에 큰 악영향을 줌을 보여준다. BEV 기반(backward projection) 아키텍처가 상대적으로 강건하며, 제안된 신경 렌더링 기반 센서 적응 파이프라인으로 다른 센서 구성에 대한 데이터 변환이 가능해 성능 저하를 크게 완화한다.


<details>
  <summary>Details</summary>
Motivation: 차량마다 카메라 장착 위치·수·시야각 등이 달라 한 차량에서 학습한 3D 검출기가 다른 차량의 센서 구성에서 성능이 떨어지는 '크로스-센서 도메인 갭' 문제를 체계적으로 조사하고 해결법을 찾기 위해.

Method: nuScenes에서 영감을 받은 CamShift 데이터셋을 CARLA로 합성해 서브컴팩트와 SUV 간 센서 구성 차이를 시뮬레이션. 다양한 최신 3D 검출기(특히 BEV 기반 모델 포함)를 크로스-센서 평가해 취약점을 분석하고, 신경 렌더링 기반의 데이터 중심 센서 적응 파이프라인으로 전체 데이터셋을 다른 카메라 설정에 맞게 변환하는 방법을 제안.

Result: CamShift에서 유의미한 크로스-센서 성능 저하를 확인했고, BEV(BEVFormer 등)와 backward projection 기반 아키텍처가 상대적으로 강건함을 보임. 제안한 신경 렌더링 변환을 적용하면 조사된 모든 3D 검출기에서 성능이 개선되어 도메인 갭을 크게 줄였음.

Conclusion: 차량 간 카메라 구성 차이는 3D 검출 성능에 심각한 영향을 주며, BEV 기반 아키텍처 선택과 신경 렌더링 기반 데이터 적응으로 이를 완화할 수 있다. 따라서 새로운 차량 유형마다 대규모 재수집 없이 데이터 재활용이 가능해진다.

Abstract: Autonomous vehicles often have varying camera sensor setups, which is
inevitable due to restricted placement options for different vehicle types.
Training a perception model on one particular setup and evaluating it on a new,
different sensor setup reveals the so-called cross-sensor domain gap, typically
leading to a degradation in accuracy. In this paper, we investigate the impact
of the cross-sensor domain gap on state-of-the-art 3D object detectors. To this
end, we introduce CamShift, a dataset inspired by nuScenes and created in CARLA
to specifically simulate the domain gap between subcompact vehicles and sport
utility vehicles (SUVs). Using CamShift, we demonstrate significant
cross-sensor performance degradation, identify robustness dependencies on model
architecture, and propose a data-driven solution to mitigate the effect. On the
one hand, we show that model architectures based on a dense Bird's Eye View
(BEV) representation with backward projection, such as BEVFormer, are the most
robust against varying sensor configurations. On the other hand, we propose a
novel data-driven sensor adaptation pipeline based on neural rendering, which
can transform entire datasets to match different camera sensor setups. Applying
this approach improves performance across all investigated 3D object detectors,
mitigating the cross-sensor domain gap by a large margin and reducing the need
for new data collection by enabling efficient data reusability across vehicles
with different sensor setups. The CamShift dataset and the sensor adaptation
benchmark are available at https://dmholtz.github.io/camshift/.

</details>


### [105] [Drifting Away from Truth: GenAI-Driven News Diversity Challenges LVLM-Based Misinformation Detection](https://arxiv.org/abs/2508.12711)
*Fanxiao Li,Jiaying Wu,Tingchao Fu,Yunyun Dong,Bingbing Song,Wei Zhou*

Main category: cs.CV

TL;DR: GenAI로 생성된 뉴스의 다양성이 LVLM 기반의 다중모달 허위정보 탐지(MMD)에 다층적 드리프트(모델의 인지 드리프트 및 증거 수준 드리프트)를 유발하여 성능과 추론 안정성을 크게 저하시킨다. 이를 평가하기 위해 6가지 다양화 유형에 걸친 16,000개 인스턴스의 대규모 벤치마크 DriftBench를 제안하고, 진실 검증의 견고성·적대적 증거 오염·추론 일관성의 세 가지 과제를 정의했다. 여섯 가지 최신 LVLM 검출기에서 평균 F1 -14.8% 등 큰 성능 저하와 불안정한 추론이 관찰되며, 적대적 증거 삽입 시 실패가 더 심해진다.


<details>
  <summary>Details</summary>
Motivation: 멀티모달 허위정보가 확산되는 가운데 GenAI 도구들이 만들어내는 풍부하고 다양한 표현은 기존 LVLM 기반 탐지기의 신뢰성과 견고성을 약화시킬 수 있다. 다층적 드리프트 현상을 체계적으로 규명하고 실험적으로 평가할 필요가 있다.

Method: (1) GenAI 기반 다양화를 반영한 6가지 카테고리로 뉴스 데이터를 확장해 16,000개 인스턴스를 포함하는 DriftBench 구성. (2) 진실 검증 견고성, 적대적 증거 오염 취약성, 다양한 입력에 대한 추론 일관성 분석의 세 가지 평가 과제 설계. (3) 여섯 개의 최신 LVLM 기반 MMD 모델을 대상으로 실험 수행하여 성능 및 추론 추적(trace)의 안정성 측정.

Result: 평균 F1 지표가 약 -14.8%로 하락했고, 스타일·표현 변화에 따른 모델의 내부 추론이 불안정해지며, 검색된 외부 증거의 품질·적합성 저하도 관찰됨. 특히 적대적 증거 주입 시 실패율이 크게 증가.

Conclusion: 현행 LVLM 기반 MMD 시스템은 GenAI가 만들어낸 콘텐츠 다양성에 취약한 근본적 한계를 보인다. 증거 검색·추론의 견고성 강화를 포함한 새로운 방어 전략이 시급히 필요하다.

Abstract: The proliferation of multimodal misinformation poses growing threats to
public discourse and societal trust. While Large Vision-Language Models (LVLMs)
have enabled recent progress in multimodal misinformation detection (MMD), the
rise of generative AI (GenAI) tools introduces a new challenge: GenAI-driven
news diversity, characterized by highly varied and complex content. We show
that this diversity induces multi-level drift, comprising (1) model-level
misperception drift, where stylistic variations disrupt a model's internal
reasoning, and (2) evidence-level drift, where expression diversity degrades
the quality or relevance of retrieved external evidence. These drifts
significantly degrade the robustness of current LVLM-based MMD systems. To
systematically study this problem, we introduce DriftBench, a large-scale
benchmark comprising 16,000 news instances across six categories of
diversification. We design three evaluation tasks: (1) robustness of truth
verification under multi-level drift; (2) susceptibility to adversarial
evidence contamination generated by GenAI; and (3) analysis of reasoning
consistency across diverse inputs. Experiments with six state-of-the-art
LVLM-based detectors show substantial performance drops (average F1 -14.8%) and
increasingly unstable reasoning traces, with even more severe failures under
adversarial evidence injection. Our findings uncover fundamental
vulnerabilities in existing MMD systems and suggest an urgent need for more
resilient approaches in the GenAI era.

</details>


### [106] [Has GPT-5 Achieved Spatial Intelligence? An Empirical Study](https://arxiv.org/abs/2508.13142)
*Zhongang Cai,Yubo Wang,Qingping Sun,Ruisi Wang,Chenyang Gu,Wanqi Yin,Zhiqian Lin,Zhitao Yang,Chen Wei,Xuanke Shi,Kewang Deng,Xiaoyang Han,Zukai Chen,Jiaqi Li,Xiangyu Fan,Hanming Deng,Lewei Lu,Bo Li,Ziwei Liu,Quan Wang,Dahua Lin,Lei Yang*

Main category: cs.CV

TL;DR: GPT-5는 공간 지능에서 뛰어난 성능을 보이나 인간 수준에는 미치지 못하며, 가장 어려운 문제들에선 대형 독점 모델도 우위를 보이지 못함.


<details>
  <summary>Details</summary>
Motivation: 다중모달 모델의 공간 이해·추론 능력을 체계적으로 평가하고, GPT-5 등 최신 대형 모델들의 위치를 파악해 향후 연구 방향을 제시하려는 목적.

Method: 공간 과제의 포괄적 분류 체계를 제안하고, 기존 벤치마크를 통합해 8개 주요 벤치마크에서 최첨단(독점·오픈소스) 모델들을 평가함(총 비용 10억+ 토큰 소모). 정성평가도 수행.

Result: GPT-5는 전반적으로 최고 성능을 보였으나 인간 수준에는 미치지 못함. 가장 어려운 공간 문제에서는 독점 모델도 결정적 우위를 보이지 못함. 몇몇 특정 과제에서 오픈소스 모델이 경쟁력을 보임.

Conclusion: 현대 다중모달 모델은 공간 지능에서 큰 진전을 이뤘지만, 인간 수준의 일반화·추론 능력을 구현하려면 여전히 해결해야 할 어려운 과제가 남아있음; 향후 연구는 어려운 문제 영역에 초점을 맞춰야 함.

Abstract: Multi-modal models have achieved remarkable progress in recent years.
Nevertheless, they continue to exhibit notable limitations in spatial
understanding and reasoning, which are fundamental capabilities to achieving
artificial general intelligence. With the recent release of GPT-5, allegedly
the most powerful AI model to date, it is timely to examine where the leading
models stand on the path toward spatial intelligence. First, we propose a
comprehensive taxonomy of spatial tasks that unifies existing benchmarks and
discuss the challenges in ensuring fair evaluation. We then evaluate
state-of-the-art proprietary and open-source models on eight key benchmarks, at
a cost exceeding one billion total tokens. Our empirical study reveals that (1)
GPT-5 demonstrates unprecedented strength in spatial intelligence, yet (2)
still falls short of human performance across a broad spectrum of tasks.
Moreover, we (3) identify the more challenging spatial intelligence problems
for multi-modal models, and (4) proprietary models do not exhibit a decisive
advantage when facing the most difficult problems. In addition, we conduct a
qualitative evaluation across a diverse set of scenarios that are intuitive for
humans yet fail even the most advanced multi-modal models.

</details>


### [107] [Real-Time Sign Language Gestures to Speech Transcription using Deep Learning](https://arxiv.org/abs/2508.12713)
*Brandone Fonya*

Main category: cs.CV

TL;DR: 실시간 CNN 기반 수화-텍스트/음성 변환 시스템을 웹캠 입력과 TTS로 연결해 보조통신을 구현. Sign Language MNIST로 훈련해 높은 정확도와 실시간 성능(일부 지연)을 보고함.


<details>
  <summary>Details</summary>
Motivation: 청각·언어 장애인을 위한 일상적 상호작용의 제약을 해소하고, 수화를 실시간으로 텍스트·음성으로 변환해 접근성과 자율성을 향상시키려는 목적.

Method: Sign Language MNIST 데이터로 CNN 모델을 훈련. 웹캠으로 라이브 제스처를 캡처해 분류하고, 분류 결과를 즉시 의미로 매핑한 뒤 TTS로 음성 합성하여 출력. 실시간 처리 성능을 중심으로 실험 수행.

Result: 모델은 높은 분류 정확도와 실시간 처리에서의 견고한 성능을 보였으나 일부 지연(latency)이 관찰됨. 전반적으로 실용적이고 사용자 친화적임을 주장.

Conclusion: 제안 시스템은 수화 사용자의 사회적 통합과 자율성 향상에 기여할 수 있는 실용적 보조기술로 평가되지만, 데이터·모델·실환경 이슈에 대한 추가 개선 여지가 있음.

Abstract: Communication barriers pose significant challenges for individuals with
hearing and speech impairments, often limiting their ability to effectively
interact in everyday environments. This project introduces a real-time
assistive technology solution that leverages advanced deep learning techniques
to translate sign language gestures into textual and audible speech. By
employing convolution neural networks (CNN) trained on the Sign Language MNIST
dataset, the system accurately classifies hand gestures captured live via
webcam. Detected gestures are instantaneously translated into their
corresponding meanings and transcribed into spoken language using
text-to-speech synthesis, thus facilitating seamless communication.
Comprehensive experiments demonstrate high model accuracy and robust real-time
performance with some latency, highlighting the system's practical
applicability as an accessible, reliable, and user-friendly tool for enhancing
the autonomy and integration of sign language users in diverse social settings.

</details>


### [108] [Single-Reference Text-to-Image Manipulation with Dual Contrastive Denoising Score](https://arxiv.org/abs/2508.12718)
*Syed Muhmmad Israr,Feng Zhao*

Main category: cs.CV

TL;DR: 본 논문은 사전학습된 텍스트-투-이미지 확산모델의 중간 self-attention 표현을 이용해 실사 이미지 편집을 수행하는 Dual Contrastive Denoising Score(이하 DCDS)를 제안한다. 간단한 dual contrastive 손실로 입력 이미지의 구조를 보존하면서 원하는 영역만 유연하게 수정하고, 추가 네트워크 없이 제로샷 이미지-투-이미지 변환이 가능하다고 주장한다.


<details>
  <summary>Details</summary>
Motivation: 사용자가 입력 이미지의 모든 시각적 세부를 완벽히 기술하는 텍스트 프롬프트를 만들기 어렵고, 기존 텍스트 기반 확산 모델은 원하는 영역 외의 영역을 예기치 않게 크게 변경하는 경향이 있어 실제 이미지 편집에 직접 적용하기 어렵다.

Method: 라텐트 확산모델의 self-attention 중간 표현에서 공간 정보를 뽑아내고, unpaired image-to-image 번역의 대조학습 아이디어를 차용한 'dual contrastive' 손실을 도입하여 입력과 출력의 대응(유사성)을 강제한다. 보조 네트워크 없이 기존 사전학습 모델의 생성적 사전지식을 활용하며, denoising 과정에 손실을 결합해 편집을 수행한다.

Result: 제안된 방법은 입력 이미지 구조 보존과 원하는 내용 수정 사이의 절충을 잘 달성하며, 기존 방법들보다 실제 이미지 편집 성능이 우수하다고 보고한다. 또한 추가 훈련 없이 사전학습 텍스트-투-이미지 모델을 바로 사용해 제로샷 이미지-투-이미지 변환이 가능하다고 주장한다.

Conclusion: DCDS는 단순하지만 강력한 프레임워크로, 텍스트-투-이미지 확산모델의 내부 표현을 활용해 실사 이미지 편집 문제를 개선한다. 향후 세부 손실 구성, 레이어 선택, 정량평가 확장에 따라 더 넓은 적용 가능성이 기대된다.

Abstract: Large-scale text-to-image generative models have shown remarkable ability to
synthesize diverse and high-quality images. However, it is still challenging to
directly apply these models for editing real images for two reasons. First, it
is difficult for users to come up with a perfect text prompt that accurately
describes every visual detail in the input image. Second, while existing models
can introduce desirable changes in certain regions, they often dramatically
alter the input content and introduce unexpected changes in unwanted regions.
To address these challenges, we present Dual Contrastive Denoising Score, a
simple yet powerful framework that leverages the rich generative prior of
text-to-image diffusion models. Inspired by contrastive learning approaches for
unpaired image-to-image translation, we introduce a straightforward dual
contrastive loss within the proposed framework. Our approach utilizes the
extensive spatial information from the intermediate representations of the
self-attention layers in latent diffusion models without depending on auxiliary
networks. Our method achieves both flexible content modification and structure
preservation between input and output images, as well as zero-shot
image-to-image translation. Through extensive experiments, we show that our
approach outperforms existing methods in real image editing while maintaining
the capability to directly utilize pretrained text-to-image diffusion models
without further training.

</details>


### [109] [Quantifying and Alleviating Co-Adaptation in Sparse-View 3D Gaussian Splatting](https://arxiv.org/abs/2508.12720)
*Kangjie Chen,Yingji Zhong,Zhihao Li,Jiaqi Lin,Youyu Chen,Minghan Qin,Haoqian Wang*

Main category: cs.CV

TL;DR: 3D Gaussian Splatting(3DGS)는 밀집 뷰에서 우수한 결과를 내지만, 소수 뷰에서는 Gaussians들이 서로 과도하게 결합(co-adaptation)되어 학습 뷰에 과적합하고 새로운 시점에서 외관 아티팩트를 유발한다. 본 논문은 이를 정량화하는 Co-Adaptation Score(CA)를 제안하고, 이를 완화하기 위한 두 가지 경량 기법(랜덤 Gaussian 드롭아웃, 불투명도에 곱해지는 노이즈)을 제시하여 성능 개선을 보였다.


<details>
  <summary>Details</summary>
Motivation: 소수 뷰 조건에서 3DGS가 학습 뷰에는 사실적인 렌더링을 보이지만, 새로운 시점에서는 외관(appearance) 아티팩트를 보이는 문제를 해결하고자 함. 그 원인이 Gaussians 간의 과도한 상호의존(co-adaptation)인지 규명하고 이를 완화하는 실용적 방법을 제시하려 함.

Method: (1) Co-Adaptation Score(CA) 제안: 같은 시점에서 서로 다른 무작위 Gaussian 부분집합으로 렌더링을 여러 번 수행한 뒤 픽셀별 분산을 계산하여 Gaussians의 얽힘 정도를 정량화. (2) 분석 결과로부터 소수 뷰에서는 co-adaptation이 심하고 뷰 수가 늘어나면 완화됨을 관찰. (3) 이를 완화하기 위한 두 가지 플러그앤플레이 기법 제안: 랜덤 Gaussian 드롭아웃; 불투명도(opacity)에 대한 곱셈 노이즈 주입. 두 방법 모두 기존 3DGS 파이프라인에 쉽게 적용 가능.

Result: 제안한 두 기법이 다양한 방법과 벤치마크에서 co-adaptation 지표(CA)를 낮추고 소수 뷰에서의 새로운 시점 렌더링 품질을 개선함을 실험적으로 확인. 뷰 수가 많아질수록 co-adaptation 문제가 자연히 완화된다는 분석 결과도 제시.

Conclusion: co-adaptation이 소수 뷰 3DGS의 핵심 한계임을 규명하고, 이를 완화하는 경량의 실용적 기법들을 제안함으로써 소수 뷰 상황에서의 외관 아티팩트 문제를 개선. 커뮤니티 차원의 추가 연구 및 확장을 촉진하고자 함.

Abstract: 3D Gaussian Splatting (3DGS) has demonstrated impressive performance in novel
view synthesis under dense-view settings. However, in sparse-view scenarios,
despite the realistic renderings in training views, 3DGS occasionally manifests
appearance artifacts in novel views. This paper investigates the appearance
artifacts in sparse-view 3DGS and uncovers a core limitation of current
approaches: the optimized Gaussians are overly-entangled with one another to
aggressively fit the training views, which leads to a neglect of the real
appearance distribution of the underlying scene and results in appearance
artifacts in novel views. The analysis is based on a proposed metric, termed
Co-Adaptation Score (CA), which quantifies the entanglement among Gaussians,
i.e., co-adaptation, by computing the pixel-wise variance across multiple
renderings of the same viewpoint, with different random subsets of Gaussians.
The analysis reveals that the degree of co-adaptation is naturally alleviated
as the number of training views increases. Based on the analysis, we propose
two lightweight strategies to explicitly mitigate the co-adaptation in
sparse-view 3DGS: (1) random gaussian dropout; (2) multiplicative noise
injection to the opacity. Both strategies are designed to be plug-and-play, and
their effectiveness is validated across various methods and benchmarks. We hope
that our insights into the co-adaptation effect will inspire the community to
achieve a more comprehensive understanding of sparse-view 3DGS.

</details>


### [110] [Frequency-Driven Inverse Kernel Prediction for Single Image Defocus Deblurring](https://arxiv.org/abs/2508.12736)
*Ying Zhang,Xiongxin Tang,Chongyi Li,Qiao Chen,Yuquan Wu*

Main category: cs.CV

TL;DR: 주파수 도메인을 활용해 공간적 특징만으로는 잘 추정하기 어려운 심하게 블러된 영역의 역(逆) 커널을 보다 정확히 예측하고, 위치 적응 합성곱(PAC)과 다중 스케일 재발신 모듈(DSRM)으로 점진적 복원을 수행해 단일 이미지 디포커스 디블러링 성능을 향상시킨 방법(FDIKP)을 제안함.


<details>
  <summary>Details</summary>
Motivation: 공간적으로 변하는 블러(kernel)를 정확히 모델링하는 것이 단일 이미지 디포커스 복원의 핵심이나, 심한 블러 영역에서는 고주파 정보가 소실되어 공간 도메인 기반 커널 추정의 성능이 급락함. 주파수 도메인에서 블러를 판별하는 능력이 높으므로 이를 활용해 구조적 식별 가능성을 높이고자 함.

Method: 주파수 표현을 포함하는 Dual-Branch Inverse Kernel Prediction(DIKP) 전략으로 역 커널을 예측하고, 예측 가능한 커널 수가 제한적인 문제를 보완하기 위해 Position Adaptive Convolution(PAC)을 도입하여 위치별 적응형 역컨볼루션을 수행함. 마지막으로 Dual-Domain Scale Recurrent Module(DSRM)으로 다중 스케일에서 디컨볼루션 결과를 융합·점진적으로 개선함.

Result: 제안 방법이 기존 접근들보다 우수한 성능을 보였으며(논문 주장), 광범위한 실험을 통해 검증되었고 코드 공개 예정임.

Conclusion: 주파수 도메인 정보를 통합한 역 커널 예측과 위치 적응형·스케일 재발신 융합 설계가 디포커스 디블러링 문제에서 커널 식별성과 복원 품질을 향상시킴.

Abstract: Single image defocus deblurring aims to recover an all-in-focus image from a
defocus counterpart, where accurately modeling spatially varying blur kernels
remains a key challenge. Most existing methods rely on spatial features for
kernel estimation, but their performance degrades in severely blurry regions
where local high-frequency details are missing. To address this, we propose a
Frequency-Driven Inverse Kernel Prediction network (FDIKP) that incorporates
frequency-domain representations to enhance structural identifiability in
kernel modeling. Given the superior discriminative capability of the frequency
domain for blur modeling, we design a Dual-Branch Inverse Kernel Prediction
(DIKP) strategy that improves the accuracy of kernel estimation while
maintaining stability. Moreover, considering the limited number of predicted
inverse kernels, we introduce a Position Adaptive Convolution (PAC) to enhance
the adaptability of the deconvolution process. Finally, we propose a
Dual-Domain Scale Recurrent Module (DSRM) to fuse deconvolution results and
progressively improve deblurring quality from coarse to fine. Extensive
experiments demonstrate that our method outperforms existing approaches. Code
will be made publicly available.

</details>


### [111] [DCSCR: A Class-Specific Collaborative Representation based Network for Image Set Classification](https://arxiv.org/abs/2508.12745)
*Xizhan Gao,Wei Hu*

Main category: cs.CV

TL;DR: 저자는 프레임 수준과 개념 수준의 표현을 동시에 학습하고, 클래스 특이적 협력 표현(CSCR) 기반 대조 손실로 집합 간 거리 측정을 적응적으로 수행하는 DCSCR을 제안해 소량표본( few-shot ) 이미지 셋 분류 성능을 향상시켰다.


<details>
  <summary>Details</summary>
Motivation: 이미지 셋 분류(ISС)는 가변 수량·이질적 이미지로 구성된 집합 간 유사도를 비교하는 작업으로, 효과적 특징 학습과 집합 간 유사도 측정이 핵심 문제다. 기존 전통 기법은 원시 픽셀에 의존하고, 기존 딥 방법은 거리 측정 시 특징을 적응적으로 조정하지 못해 few-shot 상황에서 성능이 제한된다.

Method: DCSCR은 세 모듈로 구성된다: 1) 완전 합성곱 기반 딥 프레임 특징 추출기(로컬 특징), 2) 전역 특징 학습 모듈(글로벌 특징), 3) 클래스 특이적 협력 표현 기반(metric) 학습 모듈. 마지막 모듈은 집합의 개념 수준 표현을 적응적으로 학습하고, 새로운 CSCR 기반 대조 손실을 도입해 집합 간 거리(유사도)를 직접 최적화한다.

Result: 여러 잘 알려진 few-shot ISC 데이터셋에서의 광범위한 실험을 통해 제안 방법이 일부 최신 이미지 셋 분류 알고리즘보다 우수함을 보였다.

Conclusion: 전통 ISC와 딥 학습을 결합해 프레임·개념 수준 표현을 함께 학습하고, 클래스 특이적 협력 표현으로 집합 거리 측정을 적응적으로 수행함으로써 few-shot ISC 성능을 향상시켰다.

Abstract: Image set classification (ISC), which can be viewed as a task of comparing
similarities between sets consisting of unordered heterogeneous images with
variable quantities and qualities, has attracted growing research attention in
recent years. How to learn effective feature representations and how to explore
the similarities between different image sets are two key yet challenging
issues in this field. However, existing traditional ISC methods classify image
sets based on raw pixel features, ignoring the importance of feature learning.
Existing deep ISC methods can learn deep features, but they fail to adaptively
adjust the features when measuring set distances, resulting in limited
performance in few-shot ISC. To address the above issues, this paper combines
traditional ISC methods with deep models and proposes a novel few-shot ISC
approach called Deep Class-specific Collaborative Representation (DCSCR)
network to simultaneously learn the frame- and concept-level feature
representations of each image set and the distance similarities between
different sets. Specifically, DCSCR consists of a fully convolutional deep
feature extractor module, a global feature learning module, and a
class-specific collaborative representation-based metric learning module. The
deep feature extractor and global feature learning modules are used to learn
(local and global) frame-level feature representations, while the
class-specific collaborative representation-based metric learning module is
exploit to adaptively learn the concept-level feature representation of each
image set and thus obtain the distance similarities between different sets by
developing a new CSCR-based contrastive loss function. Extensive experiments on
several well-known few-shot ISC datasets demonstrate the effectiveness of the
proposed method compared with some state-of-the-art image set classification
algorithms.

</details>


### [112] [D2-Mamba: Dual-Scale Fusion and Dual-Path Scanning with SSMs for Shadow Removal](https://arxiv.org/abs/2508.12750)
*Linhao Li,Boya Jin,Zizhe Li,Lanqing Guo,Hao Cheng,Bo Li,Yongfeng Dong*

Main category: cs.CV

TL;DR: 이 논문은 비균일한 그림자 제거를 위해 'Dual-Scale Fusion Mamba Block'과 'Dual-Path Mamba Group'을 도입한 Mamba 기반 네트워크를 제안한다. 저해상도와 원본의 멀티스케일 융합으로 경계 아티팩트를 줄이고, 수평 스캔과 마스크 인식 적응형 스캔으로 전역 문맥과 지역별 변환을 선택적으로 전파하여 SOTA 성능을 달성했다고 주장한다.


<details>
  <summary>Details</summary>
Motivation: 그림자 제거는 국소적이고 비균일한 저하를 복원해야 하므로 비그림자 영역의 정보를 활용하면서도, 그림자와 비그림자에 필요한 보정 변환이 달라 지역별 적응적 모델링과 비국소 문맥 통합이 필요하다.

Method: Mamba 기반 구조를 채택해 두 가지 핵심 모듈을 설계: (1) Dual-Scale Fusion Mamba Block (DFMB): 원본 특징과 저해상도 특징을 융합해 멀티스케일 표현을 강화하고 경계 아티팩트를 완화. (2) Dual-Path Mamba Group (DPMG): 수평 스캔으로 전역 특징을 포착하고, 마스크 인식 적응형 스캔을 추가해 구조적 연속성과 세밀한 지역 모델링을 향상시킨다. 전체적으로 변환 유사성에 따라 문맥 정보를 선택적으로 전파한다.

Result: 벤치마크 실험에서 기존 최첨단 방법들보다 유의미한 성능 향상을 보였다고 보고하며, 경계 아티팩트와 구조적 불연속성이 개선되었음을 주장한다.

Conclusion: 제안한 이중 스케일 융합과 이중 경로 스캔 설계는 그림자 제거에서 지역별 변환 차이를 효과적으로 처리하고 전역/국부 문맥을 적절히 통합함으로써 기존 기법보다 우수한 복원 성능을 제공한다.

Abstract: Shadow removal aims to restore images that are partially degraded by shadows,
where the degradation is spatially localized and non-uniform. Unlike general
restoration tasks that assume global degradation, shadow removal can leverage
abundant information from non-shadow regions for guidance. However, the
transformation required to correct shadowed areas often differs significantly
from that of well-lit regions, making it challenging to apply uniform
correction strategies. This necessitates the effective integration of non-local
contextual cues and adaptive modeling of region-specific transformations. To
this end, we propose a novel Mamba-based network featuring dual-scale fusion
and dual-path scanning to selectively propagate contextual information based on
transformation similarity across regions. Specifically, the proposed Dual-Scale
Fusion Mamba Block (DFMB) enhances multi-scale feature representation by fusing
original features with low-resolution features, effectively reducing boundary
artifacts. The Dual-Path Mamba Group (DPMG) captures global features via
horizontal scanning and incorporates a mask-aware adaptive scanning strategy,
which improves structural continuity and fine-grained region modeling.
Experimental results demonstrate that our method significantly outperforms
existing state-of-the-art approaches on shadow removal benchmarks.

</details>


### [113] [CLAIRE-DSA: Fluoroscopic Image Classification for Quality Assurance of Computer Vision Pipelines in Acute Ischemic Stroke](https://arxiv.org/abs/2508.12755)
*Cristo J. van den Berg,Frank G. te Nijenhuis,Mirre J. Blaauboer,Daan T. W. van Erp,Carlijn M. Keppels,Matthijs van der Sluijs,Bob Roozenbeek,Wim van Zwam,Sandra Cornelissen,Danny Ruijters,Ruisheng Su,Theo van Walsum*

Main category: cs.CV

TL;DR: CLAIRE-DSA는 급성 허혈성 뇌졸중 환자의 기계적 혈전제거 중 획득한 최소강도투영(MinIP) 혈관조영 이미지의 품질·속성(예: 조영제 유무, 투영각, 운동 아티팩트 등)을 분류하는 딥러닝 기반 프레임워크로, ResNet 기반 분류기를 1,758장의 주석된 MinIP로 파인튜닝하여 9개 속성을 예측함. ROC-AUC 0.91–0.98, 정밀도 0.70–1.00의 높은 성능을 보였고, 품질이 낮은 이미지를 걸러내면 분할(segmentation) 성공률이 42%에서 69%로 유의하게 향상됨 (p<0.001). 코드 공개.


<details>
  <summary>Details</summary>
Motivation: 기계적 혈전제거 중 실시간 또는 후처리용 컴퓨터 비전 보조는 영상 품질 저하에 민감하므로, DSA(MinIP) 영상의 품질·속성 자동 분류를 통해 주석·품질관리 및 워크플로우 최적화를 지원할 필요가 있음.

Method: 사전학습된 ResNet 백본을 각각의 라벨(총 9개)에 대해 파인튜닝하여 별도의 분류기 학습. 데이터셋은 주석된 1,758장의 플루오로스코픽 MinIP로 구성됨. 분류 성능을 평가하고, 불량 이미지 필터링 후 세분화 태스크에서 성능 차이를 비교.

Result: 모든 라벨에서 우수한 분류 성능(ROC-AUC 0.91–0.98, 정밀도 0.70–1.00). 품질 필터링으로 세분화 성공률이 42%→69%로 증가(통계적 유의).

Conclusion: CLAIRE-DSA는 DSA 시리즈의 영상 속성 자동 분류 및 품질 관리를 통해 임상·연구용 주석 및 워크플로우 개선에 유용한 도구가 될 가능성이 높음. 소스 코드는 공개되어 있어 재현 가능성 및 추가 연구에 유리함.

Abstract: Computer vision models can be used to assist during mechanical thrombectomy
(MT) for acute ischemic stroke (AIS), but poor image quality often degrades
performance. This work presents CLAIRE-DSA, a deep learning--based framework
designed to categorize key image properties in minimum intensity projections
(MinIPs) acquired during MT for AIS, supporting downstream quality control and
workflow optimization. CLAIRE-DSA uses pre-trained ResNet backbone models,
fine-tuned to predict nine image properties (e.g., presence of contrast,
projection angle, motion artefact severity). Separate classifiers were trained
on an annotated dataset containing $1,758$ fluoroscopic MinIPs. The model
achieved excellent performance on all labels, with ROC-AUC ranging from $0.91$
to $0.98$, and precision ranging from $0.70$ to $1.00$. The ability of
CLAIRE-DSA to identify suitable images was evaluated on a segmentation task by
filtering poor quality images and comparing segmentation performance on
filtered and unfiltered datasets. Segmentation success rate increased from
$42%$ to $69%$, $p < 0.001$. CLAIRE-DSA demonstrates strong potential as an
automated tool for accurately classifying image properties in DSA series of
acute ischemic stroke patients, supporting image annotation and quality control
in clinical and research applications. Source code is available at
https://gitlab.com/icai-stroke-lab/wp3_neurointerventional_ai/claire-dsa.

</details>


### [114] [Harnessing Group-Oriented Consistency Constraints for Semi-Supervised Semantic Segmentation in CdZnTe Semiconductors](https://arxiv.org/abs/2508.12766)
*Peihao Li,Yan Fang,Man Liu,Huihui Bai,Anhong Wang,Yunchao Wei,Yao Zhao*

Main category: cs.CV

TL;DR: 저자들은 CdZnTe(카드뮴 아연 텔루라이드) 반도체 이미지의 ‘다중 뷰 → 단일 GT’ 특성을 이용해 그룹 기반 반(半)감독 세그멘테이션 파이프라인 ICAF를 제안한다. IVS로 그룹 일관성을 확인하고, PCN( VAM, VCM )을 통해 경계 정보가 강화된 합성 뷰를 만들고 다른 뷰와 상호작용시켜 의사라벨을 보정한다. 소량(2그룹, 데이터의 0.5%) 라벨로도 DeepLabV3+에서 70.6% mIoU를 달성했다.


<details>
  <summary>Details</summary>
Motivation: CdZnTe 이미지의 결함 경계가 낮은 대비로 식별이 어렵고, 동일한 GT를 공유하는 여러 뷰가 존재해 전통적인 이미지별(1대1) SSS 방법이 확인 편향과 에러 누적을 초래한다. 이를 그룹 단위(‘다대일’) 관점으로 바꿔 일관성을 이용하면 더 적은 라벨로도 성능을 높일 수 있다.

Method: (1) Intra-group View Sampling(IVS)으로 그룹 내 일관성 제약을 확인하고 그룹 기반 베이스라인을 설정. (2) Pseudo-label Correction Network(PCN): View Augmentation Module(VAM)은 여러 뷰를 집계해 경계 인식 합성 뷰를 동적으로 생성, View Correction Module(VCM)은 합성 뷰와 원뷰를 쌍으로 정보 상호작용시켜 중요한 영역을 강조하고 노이즈를 억제. 최종적으로 의사라벨 보정 및 SSS 학습에 활용.

Result: CdZnTe 데이터셋에서 DeepLabV3+ (ResNet-101) 기반으로 2그룹 라벨(데이터의 0.5%로 표기)만 사용해 70.6% mIoU 달성. 광범위한 실험으로 제안법의 효용성 입증.

Conclusion: ‘그룹 지향’ 관점과 합성·상호 교정된 뷰 기반 의사라벨 정제는 CdZnTe 같은 낮은 대비 다중뷰 데이터에서 소수 라벨로도 성능을 크게 향상시킨다.

Abstract: Labeling Cadmium Zinc Telluride (CdZnTe) semiconductor images is challenging
due to the low-contrast defect boundaries, necessitating annotators to
cross-reference multiple views. These views share a single ground truth (GT),
forming a unique ``many-to-one'' relationship. This characteristic renders
advanced semi-supervised semantic segmentation (SSS) methods suboptimal, as
they are generally limited by a ``one-to-one'' relationship, where each image
is independently associated with its GT. Such limitation may lead to error
accumulation in low-contrast regions, further exacerbating confirmation bias.
To address this issue, we revisit the SSS pipeline from a group-oriented
perspective and propose a human-inspired solution: the Intra-group Consistency
Augmentation Framework (ICAF). First, we experimentally validate the inherent
consistency constraints within CdZnTe groups, establishing a group-oriented
baseline using the Intra-group View Sampling (IVS). Building on this insight,
we introduce the Pseudo-label Correction Network (PCN) to enhance consistency
representation, which consists of two key modules. The View Augmentation Module
(VAM) improves boundary details by dynamically synthesizing a boundary-aware
view through the aggregation of multiple views. In the View Correction Module
(VCM), this synthesized view is paired with other views for information
interaction, effectively emphasizing salient regions while minimizing noise.
Extensive experiments demonstrate the effectiveness of our solution for CdZnTe
materials. Leveraging DeepLabV3+ with a ResNet-101 backbone as our segmentation
model, we achieve a 70.6\% mIoU on the CdZnTe dataset using only 2
group-annotated data (5\textperthousand). The code is available at
\href{https://github.com/pipixiapipi/ICAF}{https://github.com/pipixiapipi/ICAF}.

</details>


### [115] [SocialTrack: Multi-Object Tracking in Complex Urban Traffic Scenes Inspired by Social Behavior](https://arxiv.org/abs/2508.12777)
*Wenguang Tao,Xiaotian Wang,Tian Yan,Jie Yan,Guodong Li,Kun Bai*

Main category: cs.CV

TL;DR: UAV 영상에서의 소형 객체 추적을 목표로 하는 SocialTrack을 제안한다. 멀티스케일 소형물체 검출기, 속도 적응 큐베처 칼만 필터(VACKF), 군집 운동 보정 전략(GMCS), 시공간 메모리 예측(STMP)을 결합해 검출·예측·연관을 개선하고, UAVDT와 MOT17에서 MOTA·IDF1 등 지표에서 기존 SOTA를 능가한다.


<details>
  <summary>Details</summary>
Motivation: UAV 관측은 작은 물체 크기, 가려짐, 비선형 교차 운동, 모션 블러 등으로 인해 다중 객체 추적의 안정성이 크게 떨어진다. 도시 교통 분석 등 실제 응용에서 소형 목표의 정확하고 안정적인 추적이 필요하다.

Method: (1) 소형 대상 특화 검출기: 멀티스케일 특징 강화로 소형 물체 검출 성능 향상. (2) VACKF: 속도 기반 동적 모델링을 포함한 큐베처 칼만 필터로 궤적 예측 정확도 개선. (3) GMCS: 군집(사회적) 운동 우선순위를 모델링해 저품질 트랙의 상태 갱신을 안정화하고 연관 정확도 향상. (4) STMP: 과거 궤적을 활용한 시공간 예측으로 ID 스위치 완화. 전체는 모듈화되어 기존 트래커와 호환 가능.

Result: UAVDT 및 MOT17에서 광범위한 실험을 통해 MOTA, IDF1 등 핵심 지표에서 기존 기법들을 능가하는 성능을 보였다고 보고됨. 특히 소형 목표에 대한 견고성·적응성이 향상되었음.

Conclusion: SocialTrack은 소형 목표가 많은 UAV 환경에서 검출·예측·연관을 결합한 모듈식 프레임워크로 추적 성능과 ID 유지력을 개선한다. 기존 트래커와 결합해 추가 향상이 가능하다.

Abstract: As a key research direction in the field of multi-object tracking (MOT),
UAV-based multi-object tracking has significant application value in the
analysis and understanding of urban intelligent transportation systems.
However, in complex UAV perspectives, challenges such as small target scale
variations, occlusions, nonlinear crossing motions, and motion blur severely
hinder the stability of multi-object tracking. To address these challenges,
this paper proposes a novel multi-object tracking framework, SocialTrack, aimed
at enhancing the tracking accuracy and robustness of small targets in complex
urban traffic environments. The specialized small-target detector enhances the
detection performance by employing a multi-scale feature enhancement mechanism.
The Velocity Adaptive Cubature Kalman Filter (VACKF) improves the accuracy of
trajectory prediction by incorporating a velocity dynamic modeling mechanism.
The Group Motion Compensation Strategy (GMCS) models social group motion priors
to provide stable state update references for low-quality tracks, significantly
improving the target association accuracy in complex dynamic environments.
Furthermore, the Spatio-Temporal Memory Prediction (STMP) leverages historical
trajectory information to predict the future state of low-quality tracks,
effectively mitigating identity switching issues. Extensive experiments on the
UAVDT and MOT17 datasets demonstrate that SocialTrack outperforms existing
state-of-the-art (SOTA) methods across several key metrics. Significant
improvements in MOTA and IDF1, among other core performance indicators,
highlight its superior robustness and adaptability. Additionally, SocialTrack
is highly modular and compatible, allowing for seamless integration with
existing trackers to further enhance performance.

</details>


### [116] [Leveraging Diffusion Models for Stylization using Multiple Style Images](https://arxiv.org/abs/2508.12784)
*Dan Ruta,Abdelaziz Djelouah,Raphael Ortiz,Christopher Schroers*

Main category: cs.CV

TL;DR: 잠재 확산모델 기반 스타일 전송에서 다수의 스타일 이미지를 사용하고, 디노이징 과정의 교차-자기어텐션과 통계 정렬(clustering)을 통해 스타일 표현을 정제하여 SOTA 성능을 달성한 방법.


<details>
  <summary>Details</summary>
Motivation: 기존 확산/잠재 확산 기반 스타일 전송은 스타일 정확성 부족, 소수 스타일 이미지로 인한 표현 한계, 스타일 이미지로부터의 원치 않는 콘텐츠 유출(콘텐츠-스타일 혼선) 등의 문제가 있음. 다수의 스타일 샘플과 디노이저 내 개입으로 이를 해결하려고 함.

Method: 여러 스타일 이미지를 입력으로 받아 이미지 프롬프트 어댑터와 디노이징 과정 중 특징 통계 정렬을 결합. 교차-어텐션과 자기-어텐션 층 모두에서 개입 가능하도록 설계. 스타일 샘플로부터 추출한 많은 어텐션 값들을 클러스터링해 소수의 대표 어텐션 특징으로 증류(통계 정렬)하여 스타일 매칭과 콘텐츠 유출 방지에 활용.

Result: 실험에서 제안 방법이 스타일 재현성 및 콘텐츠 보존 측면에서 기존 기법들보다 우수하여 SOTA 성능을 달성한다고 보고.

Conclusion: 다수의 스타일 샘플과 어댑터+통계 정렬 기반 개입이 스타일 전송 품질을 크게 개선하며, 콘텐츠-스타일 분리를 강화하여 스타일 유출을 줄임.

Abstract: Recent advances in latent diffusion models have enabled exciting progress in
image style transfer. However, several key issues remain. For example, existing
methods still struggle to accurately match styles. They are often limited in
the number of style images that can be used. Furthermore, they tend to entangle
content and style in undesired ways. To address this, we propose leveraging
multiple style images which helps better represent style features and prevent
content leaking from the style images. We design a method that leverages both
image prompt adapters and statistical alignment of the features during the
denoising process. With this, our approach is designed such that it can
intervene both at the cross-attention and the self-attention layers of the
denoising UNet. For the statistical alignment, we employ clustering to distill
a small representative set of attention features from the large number of
attention values extracted from the style samples. As demonstrated in our
experimental section, the resulting method achieves state-of-the-art results
for stylization.

</details>


### [117] [Vehicle detection from GSV imagery: Predicting travel behaviour for cycling and motorcycling using Computer Vision](https://arxiv.org/abs/2508.12794)
*Kyriaki,Kokka,Rahul Goel,Ali Abbas,Kerry A. Nice,Luca Martial,SM Labib,Rihuan Ke,Carola Bibiane Schönlieb,James Woodcock*

Main category: cs.CV

TL;DR: 이 논문은 Google Street View 이미지와 YOLOv4 기반 딥러닝을 이용해 185개 도시에서 자전거·오토바이 관측치를 자동 추출하고, 도시별 통행조사(모드쉐어)를 목표변수로 베타 회귀모형을 만들어 모드쉐어를 예측한 연구입니다. 전반적으로 오토바이 관측치와 모드쉐어의 상관(0.78)은 강하고, 자전거는 중간(0.51) 수준이며 회귀모형의 R^2는 각각 약 0.61입니다.


<details>
  <summary>Details</summary>
Motivation: 교통수단은 신체활동·대기오염·재상해 위험 등 건강에 큰 영향을 미치지만 도시별 자전거·오토바이 행태를 비교하는 전지구적 데이터는 부족합니다. GSV 같은 스트리트뷰와 컴퓨터비전은 대규모로 행동 데이터를 저비용으로 수집할 수 있는 잠재력을 가집니다.

Method: 185개 도시에서 도시당 8000개 GSV 이미지를 샘플링해 자전거·오토바이를 검출. YOLOv4를 6개 도시 데이터로 파인튜닝해 mAP 89% 달성. 도시 수준 모드쉐어(여행조사/센서스)를 종속변수로, GSV 검출 카운트를 로그 변환한 설명변수와 인구밀도를 통제변수로 한 베타 회귀모형을 구축 및 검증. 모델을 최신 모드쉐어가 없는 60개 도시에 적용해 예측치 제공.

Result: GSV 기반 오토바이 카운트와 모드쉐어 상관 0.78, 자전거는 0.51. 베타 회귀의 설명력 R^2 ≈ 0.614(자전거), 0.612(오토바이). 중앙절대오차(MDAE)는 각각 1.3%, 1.4%. 일부 도시(Utrecht, Cali 등)는 예측에서 벗어남.

Conclusion: 스트리트뷰+컴퓨터비전은 전통적 자료를 보완해 도시별 자전거·오토바이 수준을 추정하는 데 유용하며, 저비용 전지구적 모니터링·비교 연구에 적용 가능하지만 일부 도시는 외현적 편향 또는 지역특성으로 예측오차가 큼을 인정함.

Abstract: Transportation influence health by shaping exposure to physical activity, air
pollution and injury risk.Comparative data on cycling and motorcycling
behaviours is scarce, particularly at a global scale.Street view imagery, such
as Google Street View (GSV), combined with computer vision, is a valuable
resource for efficiently capturing travel behaviour data.This study
demonstrates a novel approach using deep learning on street view images to
estimate cycling and motorcycling levels across diverse cities worldwide.We
utilized data from 185 global cities.The data on mode shares of cycling and
motorcycling estimated using travel surveys or censuses.We used GSV images to
detect cycles and motorcycles in sampled locations, using 8000 images per
city.The YOLOv4 model, fine-tuned using images from six cities, achieved a mean
average precision of 89% for detecting cycles and motorcycles in GSV images.A
global prediction model was developed using beta regression with city-level
mode shares as outcome, with log transformed explanatory variables of counts of
GSV-detected images with cycles and motorcycles, while controlling for
population density.We found strong correlations between GSV motorcycle counts
and motorcycle mode share (0.78) and moderate correlations between GSV cycle
counts and cycling mode share (0.51).Beta regression models predicted mode
shares with $R^2$ values of 0.614 for cycling and 0.612 for motorcycling,
achieving median absolute errors (MDAE) of 1.3% and 1.4%,
respectively.Scatterplots demonstrated consistent prediction accuracy, though
cities like Utrecht and Cali were outliers.The model was applied to 60 cities
globally for which we didn't have recent mode share data.We provided estimates
for some cities in the Middle East, Latin America and East Asia.With computer
vision, GSV images capture travel modes and activity, providing insights
alongside traditional data sources.

</details>


### [118] [Morphological classification of eclipsing binary stars using computer vision methods](https://arxiv.org/abs/2508.12802)
*Štefan Parimucha,Maksim Gabdeev,Yanna Markus,Martin Vaňko,Pavol Gajdoš*

Main category: cs.CV

TL;DR: 깊이학습 기반 컴퓨터비전으로 이클립싱 이진성의 형태(분리형/과접형) 분류는 매우 우수하지만(검증·관측 데이터에서 정확도 >94%), 미약한 광변화(스팟) 자동탐지는 실패해 한계가 분명함.


<details>
  <summary>Details</summary>
Motivation: 대규모 천문학적 시계열(예: Gaia, TESS)에서 사람 손으로 분류하기 어려운 이클립스성 이중성의 형태를 자동화하고, 관측 데이터에 적용 가능한 강인한 분류기를 만드는 것.

Method: 합성 데이터로 학습한 ResNet50 및 ViT 기반 사전학습 모델을 미세조정. 위상 접힌 광변동을 극좌표+hexbin 이미지로 변환해 입력 표현으로 사용. 계층적(1단계: 분리/과접, 2단계: 스팟 유무) 이진 분류 수행.

Result: 여러 밴드(G, I, TESS) 검증에서 96% 초과 정확도, OGLE/DEBCat/WUMaCat 관측 데이터에서 94% 이상(최대 100% TESS) 성능. 스팟 탐지는 성능 저조.

Conclusion: 이미지화된 위상곡선과 CV 모델은 EB 형태 분류에 강력하지만, 스팟 같은 미세 광학 신호 식별에는 추가 연구(더 현실적인 합성 데이터, 도메인 적응, 다른 표현/모델)가 필요하다.

Abstract: We present an application of computer vision methods to classify the light
curves of eclipsing binaries (EB). We have used pre-trained models based on
convolutional neural networks ($\textit{ResNet50}$) and vision transformers
($\textit{vit\_base\_patch16\_224}$), which were fine-tuned on images created
from synthetic datasets. To improve model generalisation and reduce
overfitting, we developed a novel image representation by transforming
phase-folded light curves into polar coordinates combined with hexbin
visualisation. Our hierarchical approach in the first stage classifies systems
into detached and overcontact types, and in the second stage identifies the
presence or absence of spots. The binary classification models achieved high
accuracy ($>96\%$) on validation data across multiple passbands (Gaia~$G$, $I$,
and $TESS$) and demonstrated strong performance ($>94\%$, up to $100\%$ for
$TESS$) when tested on extensive observational data from the OGLE, DEBCat, and
WUMaCat catalogues. While the primary binary classification was highly
successful, the secondary task of automated spot detection performed poorly,
revealing a significant limitation of our models for identifying subtle
photometric features. This study highlights the potential of computer vision
for EB morphological classification in large-scale surveys, but underscores the
need for further research into robust, automated spot detection.

</details>


### [119] [Next Visual Granularity Generation](https://arxiv.org/abs/2508.12811)
*Yikai Wang,Zhouxia Wang,Zhonghua Wu,Qingyi Tao,Kang Liao,Chen Change Loy*

Main category: cs.CV

TL;DR: NVG는 동일한 공간 해상도를 갖는 여러 단계의 시각 토큰 시퀀스를 생성해 이미지 품질을 점진적으로 개선하는 프레임워크로, ImageNet 클래스 조건 생성에서 VAR 계열 대비 FID가 일관되게 개선되었음을 보고한다.


<details>
  <summary>Details</summary>
Motivation: 이미지 생성을 전역 레이아웃에서 세부 묘사로 체계적으로 정제하는 계층적·레이어형 표현을 도입해 세밀한 제어와 고품질 생성을 달성하려는 목적.

Method: 빈 이미지에서 시작해 'Next Visual Granularity' 방식으로 동일 공간 해상도에서 서로 다른 고유 토큰 수를 가진 연속적인 시각 그라뉼러리티(sequence)를 순차 생성한다. 각 단계는 이전 단계를 기반으로 전역 구조에서 점차 세부를 채워넣는 방식으로 작동하며, 클래스 조건 부여하여 ImageNet에서 학습한다.

Result: VAR 시리즈와 비교해 FID가 일관되게 향상됨(예: 3.30→3.03, 2.57→2.44, 2.09→2.06). 또한 확장성(scaling behavior) 관찰 및 다양한 분석을 통해 NVG의 능력과 잠재력을 제시.

Conclusion: NVG는 계층적 그라뉼러리티 시퀀스라는 새로운 표현을 통해 이미지 생성 품질과 제어를 개선하며, 추가 연구와 공개된 코드/모델을 통해 더 넓게 검증될 여지가 있다.

Abstract: We propose a novel approach to image generation by decomposing an image into
a structured sequence, where each element in the sequence shares the same
spatial resolution but differs in the number of unique tokens used, capturing
different level of visual granularity. Image generation is carried out through
our newly introduced Next Visual Granularity (NVG) generation framework, which
generates a visual granularity sequence beginning from an empty image and
progressively refines it, from global layout to fine details, in a structured
manner. This iterative process encodes a hierarchical, layered representation
that offers fine-grained control over the generation process across multiple
granularity levels. We train a series of NVG models for class-conditional image
generation on the ImageNet dataset and observe clear scaling behavior. Compared
to the VAR series, NVG consistently outperforms it in terms of FID scores (3.30
-> 3.03, 2.57 ->2.44, 2.09 -> 2.06). We also conduct extensive analysis to
showcase the capability and potential of the NVG framework. Our code and models
will be released.

</details>


### [120] [SIS-Challenge: Event-based Spatio-temporal Instance Segmentation Challenge at the CVPR 2025 Event-based Vision Workshop](https://arxiv.org/abs/2508.12813)
*Friedhelm Hamann,Emil Mededovic,Fabian Gülhan,Yuli Wu,Johannes Stegmaier,Jing He,Yiqing Wang,Kexin Zhang,Lingling Li,Licheng Jiao,Mengru Ma,Hongxiang Huang,Yuhao Yan,Hongwei Ren,Xiaopeng Lin,Yulong Huang,Bojun Cheng,Se Hyun Lee,Gyu Sung Ham,Kanghan Oh,Gi Hyun Lim,Boxuan Yang,Bowen Du,Guillermo Gallego*

Main category: cs.CV

TL;DR: 이 논문은 CVPR 2025 Event-based Vision Workshop 부속 Spatio-temporal Instance Segmentation(SIS) 챌린지 개요를 제시하며, 이벤트 카메라와 회색조 카메라의 시공간 정렬 데이터를 사용해 클래스별 픽셀 단위 마스크를 예측하는 과제, 데이터셋, 챌린지 운영 및 상위 5개 팀의 방법을 요약한다.


<details>
  <summary>Details</summary>
Motivation: 이벤트 카메라의 고속, 고동적 범위 장점과 기존 영상의 정밀한 외형 정보를 결합해 시공간적 변화가 큰 환경에서도 정확한 인스턴스 분할을 수행하려는 필요성. 표준 RGB/비디오 기반 방법만으로는 처리하기 어려운 빠른 움직임·저조도 상황에서의 픽셀 단위 예측 문제를 해결하려는 의도.

Method: 챌린지 형식으로 데이터셋(이벤트 + 정렬된 그레이스케일 프레임)과 평가 지표를 제공하고, 참가자들은 이 데이터를 입력으로 픽셀 단위 인스턴스 마스크를 예측하는 모델들을 제출함. 상위 5개 팀의 방법은 이벤트-프레임 퓨전, 시공간적 특징 추출 모듈, 시퀀스 기반 학습(예: 시계열 네트워크 또는 시간적 어텐션), 그리고 인스턴스 분할을 위한 후처리(예: 픽셀별 분류 + 경계 정제)를 조합한 방식들이 주를 이룸.

Result: 챌린지로 다양한 경쟁 방법들이 제시되었고, 상위권 팀들의 접근법이 이벤트+그레이스케일 융합 설계와 시간적 정보를 처리하는 방식에서 차별화됨. 구체적 수치(정확도, mIoU 등)는 초록에 제시되지 않으며, 상세 결과와 코드/리소스는 제공된 GitHub 링크에 공개됨.

Conclusion: 이 챌린지는 이벤트 비전과 전통적 영상 기반 인스턴스 분할 간 결합 가능성을 보여주었고, 시공간적 정렬 데이터셋을 통한 연구 촉진과 실무 적용 가능성 검증에 기여함. 참가자 코드와 결과 공유로 후속 연구 재현성과 발전이 용이해짐.

Abstract: We present an overview of the Spatio-temporal Instance Segmentation (SIS)
challenge held in conjunction with the CVPR 2025 Event-based Vision Workshop.
The task is to predict accurate pixel-level segmentation masks of defined
object classes from spatio-temporally aligned event camera and grayscale camera
data. We provide an overview of the task, dataset, challenge details and
results. Furthermore, we describe the methods used by the top-5 ranking teams
in the challenge. More resources and code of the participants' methods are
available here:
https://github.com/tub-rip/MouseSIS/blob/main/docs/challenge_results.md

</details>


### [121] [DEEP-SEA: Deep-Learning Enhancement for Environmental Perception in Submerged Aquatics](https://arxiv.org/abs/2508.12824)
*Shuang Chen,Ronald Thenius,Farshad Arvin,Amir Atapour-Abarghouei*

Main category: cs.CV

TL;DR: DEEP-SEA는 저주파와 고주파 정보를 동시에 강화하는 Dual-Frequency self-attention 기반의 수중 이미지 복원 딥러닝 모델로, EUVP와 LSUI 데이터셋에서 세부 복원과 구조 보존 성능이 기존 기법보다 우수하다고 주장함.


<details>
  <summary>Details</summary>
Motivation: 수중 모니터링에서 광 산란·흡수·혼탁으로 인해 이미지 선명도와 색상 정보가 손상되어 정확한 생태 관측·종 식별·자율 탐사에 제약이 발생함. 이를 개선하기 위해 주파수별 정보와 공간 정보를 모두 고려한 복원 모델을 제안하려 함.

Method: Dual-Frequency Enhanced Self-Attention Spatial and Frequency Modulator(약칭 DEEP-SEA)를 도입. 주파수 도메인에서 저·고주파 특징을 적응적으로 정제하고, 동시에 공간적 정보(구조)를 보존하도록 self-attention 기반의 모듈을 설계하여 특징 표현을 향상시킴.

Result: EUVP와 LSUI에서 실험을 통해 미세한 디테일 복원과 구조적 일관성 측면에서 기존 최첨단 기법들보다 우수함을 보고함. (정량·정성 비교로 우위 주장)

Conclusion: DEEP-SEA는 수중 시각 열화 문제를 효과적으로 완화하여 수중 모니터링의 신뢰도를 높이고, 생태 관측·종 식별·자율 항법에 기여할 잠재력이 있음.

Abstract: Continuous and reliable underwater monitoring is essential for assessing
marine biodiversity, detecting ecological changes and supporting autonomous
exploration in aquatic environments. Underwater monitoring platforms rely on
mainly visual data for marine biodiversity analysis, ecological assessment and
autonomous exploration. However, underwater environments present significant
challenges due to light scattering, absorption and turbidity, which degrade
image clarity and distort colour information, which makes accurate observation
difficult. To address these challenges, we propose DEEP-SEA, a novel deep
learning-based underwater image restoration model to enhance both low- and
high-frequency information while preserving spatial structures. The proposed
Dual-Frequency Enhanced Self-Attention Spatial and Frequency Modulator aims to
adaptively refine feature representations in frequency domains and
simultaneously spatial information for better structural preservation. Our
comprehensive experiments on EUVP and LSUI datasets demonstrate the superiority
over the state of the art in restoring fine-grained image detail and structural
consistency. By effectively mitigating underwater visual degradation, DEEP-SEA
has the potential to improve the reliability of underwater monitoring platforms
for more accurate ecological observation, species identification and autonomous
navigation.

</details>


### [122] [Multi-source Multimodal Progressive Domain Adaption for Audio-Visual Deception Detection](https://arxiv.org/abs/2508.12842)
*Ronghao Lin,Sijie Mai,Ying Zeng,Qiaolin He,Aolin Xiong,Haifeng Hu*

Main category: cs.CV

TL;DR: 제안된 MMPDA는 다수의 소스 도메인에서 오디오·비주얼 지식을 대상 도메인으로 점진적으로 적응(피처 및 결정 수준에서 정렬)시키는 다중-소스 멀티모달 도메인 적응 프레임워크다. MMDD 챌린지에서 상위권 성적을 기록했으며(스테이지2: 정확도 60.43%, F1 56.99%) 코드 공개.


<details>
  <summary>Details</summary>
Motivation: 서로 다른 멀티모달 데이터셋 간 도메인 시프트가 속임수(Deception) 검출 성능을 저하시켜, 다양한 출처의 지식을 대상 도메인으로 안정적으로 이전할 필요가 있다.

Method: 여러 소스 도메인으로부터 오디오·비주얼 특성을 수집하고, 소스와 타깃을 점진적으로 정렬하는 다단계(진행적) 적응을 수행한다. 적응은 피처 수준과 의사결정(결정) 수준에서 모두 이루어져 도메인 간 갭을 줄인다(멀티소스·멀티모달 설정).

Result: 대회 스테이지2에서 정확도 60.43%, F1-score 56.99%를 기록하며 Top-2 성적을 확보. 보고서는 1위 팀 대비 F1에서 +5.59%, 3위 대비 정확도에서 +6.75%의 우위를 주장. 코드: https://github.com/RH-Lin/MMPDA

Conclusion: MMPDA는 멀티소스·멀티모달 도메인 적응으로 도메인 시프트 문제를 완화해 속임수 검출 성능을 향상시켰음을 보인다. 다만 논문/초록에는 구조적 상세, 데이터별 결과 및 통계적 검증이 부족해 추가 검증이 필요하다.

Abstract: This paper presents the winning approach for the 1st MultiModal Deception
Detection (MMDD) Challenge at the 1st Workshop on Subtle Visual Computing
(SVC). Aiming at the domain shift issue across source and target domains, we
propose a Multi-source Multimodal Progressive Domain Adaptation (MMPDA)
framework that transfers the audio-visual knowledge from diverse source domains
to the target domain. By gradually aligning source and the target domain at
both feature and decision levels, our method bridges domain shifts across
diverse multimodal datasets. Extensive experiments demonstrate the
effectiveness of our approach securing Top-2 place. Our approach reaches 60.43%
on accuracy and 56.99\% on F1-score on competition stage 2, surpassing the 1st
place team by 5.59% on F1-score and the 3rd place teams by 6.75% on accuracy.
Our code is available at https://github.com/RH-Lin/MMPDA.

</details>


### [123] [Cross-Domain Few-Shot Learning via Multi-View Collaborative Optimization with Vision-Language Models](https://arxiv.org/abs/2508.12861)
*Dexia Chen,Wentao Zhang,Qianjie Zhu,Ping Hu,Weibing Li,Tong Zhang,Ruixuan Wang*

Main category: cs.CV

TL;DR: CoMuCo는 두 개의 상호보완적 전문가 모듈로 다중 뷰 특징을 추출하고, 사전 지식 기반 일관성 제약 및 정보기하학 기반 합의를 이용해 VLM 미세조정의 강건성을 높여 교차 도메인 소수샷 성능을 향상시키는 기법이다. 신규 교차도메인 소수샷 벤치마크를 제시하며 기존 방법들보다 일관되게 우수한 성능을 보고한다.


<details>
  <summary>Details</summary>
Motivation: 자연 이미지로 사전학습된 VLM(예: CLIP)은 표준 데이터셋에서 소수샷 전이 성능이 우수하나, 의료·위성·현미경 등 자연 이미지와 다른 도메인에서는 성능이 저하된다. 이러한 교차도메인 전이 문제를 해결하여 VLM의 실용성을 확대하려는 동기가 있다.

Method: CoMuCo는 두 개의 기능적으로 보완되는 전문가 모듈을 사용해 서로 다른 ‘뷰’의 특징을 추출한다. 추출된 표현들 사이에 사전 지식 기반의 일관성 제약(constraints)을 적용하고, 정보기하학적 관점에서 합의(consensus) 메커니즘을 도입하여 특징 학습의 로버스트성을 강화한다. 이를 통해 미세조정 과정에서 과적합을 줄이고 도메인 분포 차이를 완화한다.

Result: 기존 벤치마크와 저자들이 제안한 교차도메인 소수샷 벤치마크 양쪽에서 CoMuCo가 일관되게 우수한 성능을 기록했다는 실험 결과를 보고한다(자세한 수치·통계는 초록에 없음). 코드와 벤치마크 공개 예정.

Conclusion: CoMuCo는 다중 뷰 협업 최적화와 일관성/합의 제약을 결합해 VLM의 교차도메인 소수샷 성능을 개선하며, 도메인 간 일반화 문제에 대한 실용적 접근을 제시한다.

Abstract: Vision-language models (VLMs) pre-trained on natural image and language data,
such as CLIP, have exhibited significant potential in few-shot image
recognition tasks, leading to development of various efficient transfer
learning methods. These methods exploit inherent pre-learned knowledge in VLMs
and have achieved strong performance on standard image datasets. However, their
effectiveness is often limited when confronted with cross-domain tasks where
imaging domains differ from natural images. To address this limitation, we
propose Consistency-guided Multi-view Collaborative Optimization (CoMuCo), a
novel fine-tuning strategy for VLMs. This strategy employs two functionally
complementary expert modules to extract multi-view features, while
incorporating prior knowledge-based consistency constraints and information
geometry-based consensus mechanisms to enhance the robustness of feature
learning. Additionally, a new cross-domain few-shot benchmark is established to
help comprehensively evaluate methods on imaging domains distinct from natural
images. Extensive empirical evaluations on both existing and newly proposed
benchmarks suggest CoMuCo consistently outperforms current methods in few-shot
tasks. The code and benchmark will be released.

</details>


### [124] [Preserve and Sculpt: Manifold-Aligned Fine-tuning of Vision-Language Models for Few-Shot Learning](https://arxiv.org/abs/2508.12877)
*Dexia Chen,Qianjie Zhu,Weibing Li,Yue Yu,Tong Zhang,Ruixuan Wang*

Main category: cs.CV

TL;DR: MPS-Tuning은 CLIP 같은 VLM을 도메인 적응할 때 피처 공간의 의미적 매니폴드 구조를 보존하면서 클래스 분리도를 높이도록 미세조정하는 방법이다. Gram 행렬 정합을 통해 거시·미시 토폴로지를 유지하고, 이미지·텍스트 쌍의 유사도를 조정해 판별력을 강화한다. 이 제약은 Gromov–Wasserstein 거리의 상한을 근사한다고 주장하며, 실험에서 성능 향상과 매니폴드 구조 보존을 보였다.


<details>
  <summary>Details</summary>
Motivation: 기존의 파라미터 효율 튜닝이나 인스턴스 기반 정규화는 과적합을 줄이지만 데이터 분포의 기하학적 구조(매니폴드)를 무시해 의미적 표현이 왜곡될 수 있다. 이를 보완해 원래의 매니폴드 구조를 유지하면서 도메인 적응 성능을 높이려는 목적.

Method: (1) 피처 공간을 의미적 매니폴드로 간주하고, fine-tuning 전후의 Gram 행렬을 정렬하여 거시(macroscopic) 및 미시(microscopic) 토폴로지를 보존한다. (2) 이미지와 텍스트 모달리티의 피처를 짝지어 쌍별 유사도를 최적화함으로써 클래스 분리도를 조각(sculpt)한다. (3) 이 Gram 정합 제약이 Gromov–Wasserstein 거리 상한의 근사임을 이론적으로 제시.

Result: 광범위한 실험에서 MPS-Tuning은 기존 방식보다 모델 성능을 유의미하게 개선했고, 동시에 의미적 매니폴드의 구조 왜곡을 억제했다(구체적 데이터·수치 미제공).

Conclusion: 매니폴드 보존과 판별력 향상을 동시에 추구하는 제약을 통해 VLM의 도메인 적응 성능을 개선했으며, 이론적 근거(GW 상한 근사)와 실험적 검증을 제시했다.

Abstract: Pretrained vision-language models (VLMs), such as CLIP, have shown remarkable
potential in few-shot image classification and led to numerous effective
transfer learning strategies. These methods leverage the pretrained knowledge
of VLMs to enable effective domain adaptation while mitigating overfitting
through parameter-efficient tuning or instance-based consistency constraints.
However, such regularizations often neglect the geometric structure of data
distribution, which may lead to distortion of the overall semantic
representation. To overcome this limitation, we propose a novel fine-tuning
method, Manifold-Preserving and Sculpting Tuning (MPS-Tuning). Regarding the
data distribution in feature space as a semantic manifold, MPS-Tuning
explicitly constrains the intrinsic geometry of this manifold while further
sculpting it to enhance class separability. Specifically, MPS-Tuning preserves
both macroscopic and microscopic topological structures of the original
manifold by aligning Gram matrices of features before and after fine-tuning.
Theoretically, this constraint is shown to approximate an upper bound of the
Gromov-Wasserstein distance. Furthermore, features from the image and text
modalities are paired, and pairwise similarities are optimized to enhance the
manifold's class discriminability. Extensive experiments demonstrate that
MPS-Tuning significantly improves model performance while effectively
preserving the structure of the semantic manifold. The code will be released.

</details>


### [125] [S^2-Guidance: Stochastic Self Guidance for Training-Free Enhancement of Diffusion Models](https://arxiv.org/abs/2508.12880)
*Chubin Chen,Jiashu Zhu,Xiaokun Feng,Nisha Huang,Meiqi Wu,Fangyuan Mao,Jiahong Wu,Xiangxiang Chu,Xiu Li*

Main category: cs.CV

TL;DR: S^2-Guidance는 분류기-무관여(Classifier-free Guidance)의 서브옵티멀한 예측 문제를 해결하기 위해, 전방(forward) 과정에서 블록을 확률적으로 드롭하여 모델의 확률적 서브네트워크를 구성하고 이를 통해 낮은 품질의 예측을 회피하도록 유도하는 새로운 가이던스 기법이다. 텍스트-이미지와 텍스트-비디오 생성에서 CFG 및 다른 고급 가이던스보다 일관되게 우수한 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: CFG는 샘플 품질과 프롬프트 일치도를 개선하지만, 폐쇄형 해가 존재하는 가우시안 혼합 모델 실험에서 CFG가 생성하는 예측이 실제 지상해와 불일치하는 서브옵티멀한 경향을 보였고, 모델이 이런 서브옵티멀한 예측에 과도하게 의존하면 의미적 비일관성과 낮은 품질이 발생한다는 점을 해결하려 함.

Method: 모델 자체의 서브네트워크가 서브옵티멀 예측을 정제할 수 있음을 실험적으로 보여준 뒤, 전방 과정에서 확률적 블록-드롭(stochastic block-dropping)을 적용해 다양한 확률적 서브네트워크를 구성한다. 이러한 서브네트워크 출력을 이용해 모델의 샘플링 경로를 '저품질 예측'에서 '고품질 출력'으로 유도하는 가이던스(S^2-Guidance)를 제안한다.

Result: 텍스트-이미지 및 텍스트-비디오 생성에서 질적·양적으로 광범위한 실험을 수행한 결과, S^2-Guidance가 CFG 및 기타 고급 가이던스 전략들을 지속적으로 능가함을 보였다. 코드 공개 예정.

Conclusion: S^2-Guidance는 간단한 블록 드롭 기반 서브네트워크 구축으로 모델의 서브옵티멀 예측을 회피하여 출력 품질과 의미적 일관성을 개선하는 실용적·효과적인 가이던스 기법으로 제안되며, 다양한 생성 태스크에서 우수한 성능을 보인다.

Abstract: Classifier-free Guidance (CFG) is a widely used technique in modern diffusion
models for enhancing sample quality and prompt adherence. However, through an
empirical analysis on Gaussian mixture modeling with a closed-form solution, we
observe a discrepancy between the suboptimal results produced by CFG and the
ground truth. The model's excessive reliance on these suboptimal predictions
often leads to semantic incoherence and low-quality outputs. To address this
issue, we first empirically demonstrate that the model's suboptimal predictions
can be effectively refined using sub-networks of the model itself. Building on
this insight, we propose S^2-Guidance, a novel method that leverages stochastic
block-dropping during the forward process to construct stochastic sub-networks,
effectively guiding the model away from potential low-quality predictions and
toward high-quality outputs. Extensive qualitative and quantitative experiments
on text-to-image and text-to-video generation tasks demonstrate that
S^2-Guidance delivers superior performance, consistently surpassing CFG and
other advanced guidance strategies. Our code will be released.

</details>


### [126] [ONG: One-Shot NMF-based Gradient Masking for Efficient Model Sparsification](https://arxiv.org/abs/2508.12891)
*Sankar Behera,Yamuna Prasad*

Main category: cs.CV

TL;DR: 원샷 NMF 기반 중요도 판별과 기울기 마스킹으로 훈련 전·훈련 중 희소성을 엄격히 유지하는 방법. CIFAR-10/100의 ResNet 계열에서 다양한 희소도에서 동등하거나 우수한 성능을 보임.


<details>
  <summary>Details</summary>
Motivation: 대형 DNN의 배포 제약을 완화하고자, 반복적/복잡한 가지치기 과정 없이 훈련 내내 목표 희소도를 엄격히 유지하는 단순하고 명확한 방법이 필요함.

Method: 훈련 시작에서 가중치 구조에 대해 비음수 행렬 분해(NMF)를 적용해 보존할 가중치를 한 번에 결정한 뒤, 정밀한 기울기 마스킹을 통해 비보존 가중치는 업데이트되지 않게 하여 희소도를 고정. BIMP 프레임워크에 통합해 표준 데이터셋·모델과 비교 평가.

Result: ResNet56/34/18를 CIFAR-10/100에서 실험한 결과, 다양한 희소도에서 기존 안정화된 희소화 기법들과 비교 시 동등하거나 더 나은 정확도 및 구조 보존을 달성함.

Conclusion: ONG는 단일 단계로 실용적인 희소화와 훈련 중 희소도 보장을 제공하지만, NMF의 계산 비용·스케일 문제와 대규모 데이터셋·다른 아키텍처에 대한 일반화 가능성은 추가 검증이 필요함.

Abstract: Deep Neural Networks (DNNs) have achieved remarkable success but their large
size poses deployment challenges. While various pruning techniques exist, many
involve complex iterative processes, specialized criteria, or struggle to
maintain sparsity effectively during training. We introduce ONG (One-shot
NMF-based Gradient Masking), a novel sparsification strategy that identifies
salient weight structures using Non-negative Matrix Factorization (NMF) for
one-shot pruning at the outset of training. Subsequently, ONG employs a precise
gradient masking mechanism to ensure that only unpruned weights are updated,
strictly preserving the target sparsity throughout the training phase. We
integrate ONG into the BIMP comparative framework and evaluate it on CIFAR-10
and CIFAR-100 with ResNet56, ResNet34, and ResNet18 against established stable
sparsification methods. Our experiments demonstrate ONG's ability to achieve
comparable or superior performance at various sparsity levels while maintaining
structural integrity post-pruning and offering a clear mechanism for targeting
desired sparsities.

</details>


### [127] [CTFlow: Video-Inspired Latent Flow Matching for 3D CT Synthesis](https://arxiv.org/abs/2508.12900)
*Jiayi Wang,Hadrien Reynaud,Franciskus Xaverius Erick,Bernhard Kainz*

Main category: cs.CV

TL;DR: CTFlow는 CT-RATE 데이터셋과 A-VAE/CT-CLIP을 활용해 임상 리포트 조건으로 전체 3D CT 볼륨을 생성하는 0.5B 매개변수 잠재 플로우-매칭 트랜스포머이다. 메모리 제약을 해소하기 위해 시퀀스 단위의 자율회귀(slice-by-slice) 생성 방식을 사용하며, 기존 방법들보다 시공간 일관성, 다양성, 텍스트-이미지 정합성에서 우수하다고 주장한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 3D CT와 텍스트 페어링(CT-RATE)으로 임상 리포트 조건의 전체 CT 볼륨 합성이 가능해져 데이터 증강·프라이버시 보존·연구 가속화의 필요를 충족하려 함.

Method: A-VAE로 정의한 잠재공간에서 0.5B latent flow matching 트랜스포머를 학습하고, CT-CLIP으로 리포트를 인코딩한다. 메모리 문제를 해결하기 위해 텍스트만으로 처음 몇 슬라이스를 생성한 뒤 이전에 생성한 슬라이스와 텍스트를 입력해 다음 슬라이스 시퀀스를 예측하는 맞춤형 자율회귀 전략을 사용.

Result: FID, FVD, IS, CLIP score 등으로 비교해 시공간 일관성(temporal coherence), 이미지 다양성, 텍스트-이미지 정합성에서 SOTA보다 우수함을 보고.

Conclusion: 자율회귀 잠재 플로우 모델은 전체 CT 볼륨의 텍스트 조건 합성에 실용적인 방향을 제시하나, 임상적 검증·윤리·개인정보 리스크 평가가 필요하다.

Abstract: Generative modelling of entire CT volumes conditioned on clinical reports has
the potential to accelerate research through data augmentation,
privacy-preserving synthesis and reducing regulator-constraints on patient data
while preserving diagnostic signals. With the recent release of CT-RATE, a
large-scale collection of 3D CT volumes paired with their respective clinical
reports, training large text-conditioned CT volume generation models has become
achievable. In this work, we introduce CTFlow, a 0.5B latent flow matching
transformer model, conditioned on clinical reports. We leverage the A-VAE from
FLUX to define our latent space, and rely on the CT-Clip text encoder to encode
the clinical reports. To generate consistent whole CT volumes while keeping the
memory constraints tractable, we rely on a custom autoregressive approach,
where the model predicts the first sequence of slices of the volume from
text-only, and then relies on the previously generated sequence of slices and
the text, to predict the following sequence. We evaluate our results against
state-of-the-art generative CT model, and demonstrate the superiority of our
approach in terms of temporal coherence, image diversity and text-image
alignment, with FID, FVD, IS scores and CLIP score.

</details>


### [128] [CMF-IoU: Multi-Stage Cross-Modal Fusion 3D Object Detection with IoU Joint Prediction](https://arxiv.org/abs/2508.12917)
*Zhiwei Ning,Zhaojiang Liu,Xuanang Gao,Yifan Zuo,Jie Yang,Yuming Fang,Wei Liu*

Main category: cs.CV

TL;DR: 카메라의 2D 시맨틱 정보와 라이다의 3D 공간 정보를 다단계로 융합해 성능을 끌어올린 3D 검출 프레임워크(CMF-IOU)를 제안한다. 깊이 보완으로 생성한 의사 포인트와 라이다를 통합 처리하고, 두 개의 보강 브랜치 및 반복적 정밀 풀링과 IoU 예측을 통해 제안 박스를 정제한다.


<details>
  <summary>Details</summary>
Motivation: 단일·부분 단계의 멀티모달 융합은 2D 시맨틱과 3D 공간 정보를 충분히 정렬·추출하지 못해 성능 한계가 발생한다. 따라서 2D와 3D 정보를 더 정교하게 정렬·융합할 필요가 있다.

Method: (1) 깊이 보완 네트워크로 픽셀을 3D로 투영해 의사 포인트 생성(카메라→라이다 표현 통일). (2) 양방향 크로스뷰 강화 3D 백본 설계: S2D 브랜치(인코더-디코더로 희박 라이다 표현 강화)와 ResVC 브랜치(부정확한 의사 포인트 영향 완화, 3D·2D 컨볼루션 활용). (3) 반복적 바운딩박스 정제를 위한 voxel-point 인식 정밀 풀링(라이다 공간정보 + 의사 포인트의 텍스처 정보 획득). (4) IoU 공동 예측 브랜치와 새로운 제안 생성 기법으로 IoU와 분류 점수가 모두 높은 박스 유지.

Result: KITTI, nuScenes, Waymo 데이터셋에서 제안 기법이 우수한 성능을 보였다고 보고됨.

Conclusion: 다단계 크로스모달 융합과 IoU 기반 정제로 2D 시맨틱과 3D 공간 정렬을 개선하고, 의사 포인트의 불확실성을 완화하여 제안 박스 정밀도를 향상시킨 방법이다.

Abstract: Multi-modal methods based on camera and LiDAR sensors have garnered
significant attention in the field of 3D detection. However, many prevalent
works focus on single or partial stage fusion, leading to insufficient feature
extraction and suboptimal performance. In this paper, we introduce a
multi-stage cross-modal fusion 3D detection framework, termed CMF-IOU, to
effectively address the challenge of aligning 3D spatial and 2D semantic
information. Specifically, we first project the pixel information into 3D space
via a depth completion network to get the pseudo points, which unifies the
representation of the LiDAR and camera information. Then, a bilateral
cross-view enhancement 3D backbone is designed to encode LiDAR points and
pseudo points. The first sparse-to-distant (S2D) branch utilizes an
encoder-decoder structure to reinforce the representation of sparse LiDAR
points. The second residual view consistency (ResVC) branch is proposed to
mitigate the influence of inaccurate pseudo points via both the 3D and 2D
convolution processes. Subsequently, we introduce an iterative voxel-point
aware fine grained pooling module, which captures the spatial information from
LiDAR points and textural information from pseudo points in the proposal
refinement stage. To achieve more precise refinement during iteration, an
intersection over union (IoU) joint prediction branch integrated with a novel
proposals generation technique is designed to preserve the bounding boxes with
both high IoU and classification scores. Extensive experiments show the
superior performance of our method on the KITTI, nuScenes and Waymo datasets.

</details>


### [129] [7Bench: a Comprehensive Benchmark for Layout-guided Text-to-image Models](https://arxiv.org/abs/2508.12919)
*Elena Izzo,Luca Parolari,Davide Vezzaro,Lamberto Ballan*

Main category: cs.CV

TL;DR: 7Bench는 텍스트·레이아웃 기반 이미지 생성의 의미적 및 공간적 정렬을 동시에 평가하는 최초의 벤치마크로, 7가지 시나리오와 레이아웃 정합 점수를 도입해 SOTA 확산모델들의 강약점을 분석한다.


<details>
  <summary>Details</summary>
Motivation: 레이아웃 가이디드 텍스트-투-이미지 모델은 공간 제어를 제공하지만, 기존 평가는 텍스트 정합성에 치중되어 레이아웃(공간) 정합성 평가는 부족했다. 합성 데이터 품질 보증을 위해 의미와 공간 정합을 함께 측정할 필요가 있었다.

Method: 7Bench는 객체 생성, 색상·속성 인식, 객체 간 관계, 공간 제어 등 7개 어려운 시나리오의 텍스트·레이아웃 쌍을 수집·설계하고, 기존 프레임워크에 레이아웃 정합 점수를 추가한 평가 프로토콜을 제안해 여러 확산모델을 비교 평가했다.

Result: 벤치마크를 통해 모델별로 의미적 정합과 공간적 정합에서 상이한 강점과 약점을 드러냈으며, 일부 모델은 텍스트 일치는 양호하나 레이아웃 준수에서 취약함을 보였다.

Conclusion: 7Bench는 공간적 정합성까지 포함한 종합적 평가 도구로서 합성 데이터 생성 및 모델 개발에 유용하며, 공개 리포지터리를 통해 커뮤니티 확장과 추가 평가를 기대한다.

Abstract: Layout-guided text-to-image models offer greater control over the generation
process by explicitly conditioning image synthesis on the spatial arrangement
of elements. As a result, their adoption has increased in many computer vision
applications, ranging from content creation to synthetic data generation. A
critical challenge is achieving precise alignment between the image, textual
prompt, and layout, ensuring semantic fidelity and spatial accuracy. Although
recent benchmarks assess text alignment, layout alignment remains overlooked,
and no existing benchmark jointly evaluates both. This gap limits the ability
to evaluate a model's spatial fidelity, which is crucial when using
layout-guided generation for synthetic data, as errors can introduce noise and
degrade data quality. In this work, we introduce 7Bench, the first benchmark to
assess both semantic and spatial alignment in layout-guided text-to-image
generation. It features text-and-layout pairs spanning seven challenging
scenarios, investigating object generation, color fidelity, attribute
recognition, inter-object relationships, and spatial control. We propose an
evaluation protocol that builds on existing frameworks by incorporating the
layout alignment score to assess spatial accuracy. Using 7Bench, we evaluate
several state-of-the-art diffusion models, uncovering their respective
strengths and limitations across diverse alignment tasks. The benchmark is
available at https://github.com/Elizzo/7Bench.

</details>


### [130] [Towards High-Resolution Industrial Image Anomaly Detection](https://arxiv.org/abs/2508.12931)
*Ximiao Zhang,Min Xu,Xiuzhuang Zhou*

Main category: cs.CV

TL;DR: Proposes HiAD, a general framework for high-resolution anomaly detection using a dual-branch architecture, multi-resolution feature fusion, and a detector pool with adaptive assignment; shows superior performance on newly constructed high-res benchmarks (MVTec-HD, VisA-HD, RealIAD-HD).


<details>
  <summary>Details</summary>
Motivation: Existing anomaly detection focuses on low-resolution images; downsampling high-res images loses fine-grained discriminative details, causing missed subtle anomalies. Prior attempts (lightweight nets, tiling, ensembles) trade off accuracy/efficiency and fail practical industrial demands.

Method: HiAD uses a dual-branch architecture to capture both subtle and large-scale anomalies, multi-resolution feature fusion to handle fine-grained texture variations, and a detector pool with adaptive detector assignment strategies based on patch features to balance performance and computational cost.

Result: Extensive experiments on constructed high-resolution benchmarks (MVTec-HD, VisA-HD, RealIAD-HD) demonstrate HiAD's superior detection performance. Code is released.

Conclusion: HiAD effectively addresses high-resolution anomaly detection challenges by integrating multi-scale cues and adaptive detector allocation, achieving improved accuracy and efficiency for industrially-relevant high-res scenarios.

Abstract: Current anomaly detection methods primarily focus on low-resolution
scenarios. For high-resolution images, conventional downsampling often results
in missed detections of subtle anomalous regions due to the loss of
fine-grained discriminative information. Despite some progress, recent studies
have attempted to improve detection resolution by employing lightweight
networks or using simple image tiling and ensemble methods. However, these
approaches still struggle to meet the practical demands of industrial scenarios
in terms of detection accuracy and efficiency. To address the above issues, we
propose HiAD, a general framework for high-resolution anomaly detection. HiAD
is capable of detecting anomalous regions of varying sizes in high-resolution
images under limited computational resources. Specifically, HiAD employs a
dual-branch architecture that integrates anomaly cues across different scales
to comprehensively capture both subtle and large-scale anomalies. Furthermore,
it incorporates a multi-resolution feature fusion strategy to tackle the
challenges posed by fine-grained texture variations in high-resolution images.
To enhance both adaptability and efficiency, HiAD utilizes a detector pool in
conjunction with various detector assignment strategies, enabling detectors to
be adaptively assigned based on patch features, ensuring detection performance
while effectively controlling computational costs. We conduct extensive
experiments on our specifically constructed high-resolution anomaly detection
benchmarks, including MVTec-HD, VisA-HD, and the real-world benchmark
RealIAD-HD, demonstrating the superior performance of HiAD. The code is
available at https://github.com/cnulab/HiAD.

</details>


### [131] [SEDEG:Sequential Enhancement of Decoder and Encoder's Generality for Class Incremental Learning with Small Memory](https://arxiv.org/abs/2508.12932)
*Hongyang Chen,Shaoling Pu,Lingyu Zheng,Zhongwu Sun*

Main category: cs.CV

TL;DR: SEDEG는 비전 트랜스포머 기반 증분 학습에서 인코더와 디코더의 범용성(generality)을 단계적으로 향상시키는 두 단계 학습 프레임워크이다. 먼저 feature boosting으로 앙상블 인코더를 학습해 표현을 일반화하고 디코더와 클래스 균형을 개선한 뒤, 균형 지식증류와 feature KD로 앙상블을 압축해 더 일반화된 단일 인코더를 얻는다. 소규모 메모리 상황에서도 기존 방법보다 성능 우수함을 보였다.


<details>
  <summary>Details</summary>
Motivation: 증분 학습에서 장기적 지식 손실(치명적 망각)을 줄이려면 단순히 하나의 구성요소만 개선하는 것이 아니라 인코더와 디코더 둘 다의 일반화 능력을 강화해야 한다. 특히 저장 가능한 이전 샘플이 적은 소메모리 환경에서 기존 방법들은 효과가 떨어진다.

Method: 두 단계: (1) feature boosting을 통해 여러 인코더를 결합한 앙상블 인코더를 학습하여 보다 일반화된 특징 표현과 균형 잡힌 분류 경계를 획득하고 디코더를 개선한다. (2) 앙상블 인코더를 단일 모델로 압축하기 위해 균형 지식증류(balanced KD)와 feature-level KD를 적용하여 일반화된 인코더를 얻는다. 전 과정은 ViT 기반으로 설계됨.

Result: 세 개의 벤치마크 데이터셋에서 광범위한 실험을 통해 SEDEG가 기존 증분 학습 기법들보다 우수한 성능을 보였고, 구성요소별 제거(ablations) 실험으로 각 모듈의 유효성이 확인되었다.

Conclusion: 인코더와 디코더의 범용성을 순차적으로 향상시키는 전략(앙상블→지식증류)은 증분 학습에서 치명적 망각을 완화하고 소메모리 조건에서도 성능을 유지하는 데 효과적이다.

Abstract: In incremental learning, enhancing the generality of knowledge is crucial for
adapting to dynamic data inputs. It can develop generalized representations or
more balanced decision boundaries, preventing the degradation of long-term
knowledge over time and thus mitigating catastrophic forgetting. Some emerging
incremental learning methods adopt an encoder-decoder architecture and have
achieved promising results. In the encoder-decoder achitecture, improving the
generalization capabilities of both the encoder and decoder is critical, as it
helps preserve previously learned knowledge while ensuring adaptability and
robustness to new, diverse data inputs. However, many existing continual
methods focus solely on enhancing one of the two components, which limits their
effectiveness in mitigating catastrophic forgetting. And these methods perform
even worse in small-memory scenarios, where only a limited number of historical
samples can be stored. To mitigate this limitation, we introduces SEDEG, a
two-stage training framework for vision transformers (ViT), focusing on
sequentially improving the generality of both Decoder and Encoder. Initially,
SEDEG trains an ensembled encoder through feature boosting to learn generalized
representations, which subsequently enhance the decoder's generality and
balance the classifier. The next stage involves using knowledge distillation
(KD) strategies to compress the ensembled encoder and develop a new, more
generalized encoder. This involves using a balanced KD approach and feature KD
for effective knowledge transfer. Extensive experiments on three benchmark
datasets show SEDEG's superior performance, and ablation studies confirm the
efficacy of its components. The code is available at
https://github.com/ShaolingPu/CIL.

</details>


### [132] [Fully Automated Segmentation of Fiber Bundles in Anatomic Tracing Data](https://arxiv.org/abs/2508.12942)
*Kyriaki-Margarita Bintsi,Yaël Balbastre,Jingjing Wu,Julia F. Lehman,Suzanne N. Haber,Anastasia Yendiki*

Main category: cs.CV

TL;DR: Streamlined automated pipeline using a U-Net (large patches + foreground-aware sampling + semi-supervised pretraining) segments fiber bundles in macaque tracer histology, improving sparse-bundle detection by >20% and lowering FDR by 40% vs SOTA, and works on standalone slices.


<details>
  <summary>Details</summary>
Motivation: Manual annotation of tracer-labeled fiber bundles on histological slides is laborious; existing automated methods miss sparse bundles or depend on complex cross-section post-processing, limiting scalability for large tracer datasets used to validate dMRI tractography.

Method: A U-Net segmentation model trained with large image patches, foreground-aware sampling to focus on rare fibers, and semi-supervised pretraining to leverage unlabeled data; designed to operate on single histological slices without requiring slice-to-slice postprocessing.

Result: Reduced common errors (e.g., terminals mislabeled as bundles); >20% better detection of sparse bundles; 40% reduction in False Discovery Rate compared to previous best methods; enables standalone-slice analysis, facilitating high-throughput processing.

Conclusion: The framework enables scalable, more accurate automated annotation of anatomic tracer datasets, producing richer ground-truth for validation and improvement of dMRI tractography pipelines.

Abstract: Anatomic tracer studies are critical for validating and improving diffusion
MRI (dMRI) tractography. However, large-scale analysis of data from such
studies is hampered by the labor-intensive process of annotating fiber bundles
manually on histological slides. Existing automated methods often miss sparse
bundles or require complex post-processing across consecutive sections,
limiting their flexibility and generalizability. We present a streamlined,
fully automated framework for fiber bundle segmentation in macaque tracer data,
based on a U-Net architecture with large patch sizes, foreground aware
sampling, and semisupervised pre-training. Our approach eliminates common
errors such as mislabeling terminals as bundles, improves detection of sparse
bundles by over 20% and reduces the False Discovery Rate (FDR) by 40% compared
to the state-of-the-art, all while enabling analysis of standalone slices. This
new framework will facilitate the automated analysis of anatomic tracing data
at a large scale, generating more ground-truth data that can be used to
validate and optimize dMRI tractography methods.

</details>


### [133] [Lumen: Consistent Video Relighting and Harmonious Background Replacement with Video Generative Models](https://arxiv.org/abs/2508.12945)
*Jianshu Zeng,Yuxuan Liu,Yutong Feng,Chenxuan Miao,Zixiang Gao,Jiwang Qu,Jianzhang Zhang,Bin Wang,Kun Yuan*

Main category: cs.CV

TL;DR: Lumen은 텍스트 제어가 가능한 end-to-end 비디오 리라이팅(frames relighting + background replacement) 프레임워크로, 3D 렌더링 기반 합성 데이터와 HDR 기반 현실 데이터 결합한 대규모 페어 데이터셋과 도메인 어댑터·공동 학습 커리큘럼을 통해 일관된 시간적 조명 변화와 엄격한 전경 보존을 달성한다.


<details>
  <summary>Details</summary>
Motivation: 비디오 리라이팅에서는 전경의 물리적 속성(예: 알베도) 보존과 프레임 간 일관된 조명 전파가 중요하다. 그러나 동일한 전경에 대해 다양한 조명 조건을 갖춘 고품질 페어 비디오가 부족하여 학습이 어렵다. 텍스트로 조명·배경을 제어할 수 있는 유연한 시스템 필요.

Method: Lumen: (1) 대규모 혼합 데이터셋 구축 — 합성 도메인은 3D 렌더러로 다양한 환경에서 페어 비디오 생성, 현실 도메인은 HDR 기반 조명 시뮬레이션으로 보완; (2) 도메인별 장점(합성의 물리적 일관성, 현실의 분포 일반성)을 살리는 공동 학습 커리큘럼 설계; (3) 리라이팅과 도메인 외형 분포 학습을 분리하는 도메인-어웨어 어댑터 주입; (4) 텍스트 입력으로 조명/배경 제어 가능, 대규모 비디오 생성 모델 기반 엔드-투-엔드 학습.

Result: 제안된 벤치마크에서 기존 방법 대비 전경 보존성과 시간적 일관성 측면에서 우수한 성능을 보이며, 시네마틱한 리라이트 결과를 산출한다는 주장.

Conclusion: 혼합 데이터와 도메인 분리 설계로 비디오 리라이팅의 핵심 문제(전경 보존·시간 일관성)를 실용적 수준으로 개선. 다만 실세계 일반화·계산 비용·윤리적 오용 가능성 등의 한계는 검증·완화가 필요하다.

Abstract: Video relighting is a challenging yet valuable task, aiming to replace the
background in videos while correspondingly adjusting the lighting in the
foreground with harmonious blending. During translation, it is essential to
preserve the original properties of the foreground, e.g., albedo, and propagate
consistent relighting among temporal frames. In this paper, we propose Lumen,
an end-to-end video relighting framework developed on large-scale video
generative models, receiving flexible textual description for instructing the
control of lighting and background. Considering the scarcity of high-qualified
paired videos with the same foreground in various lighting conditions, we
construct a large-scale dataset with a mixture of realistic and synthetic
videos. For the synthetic domain, benefiting from the abundant 3D assets in the
community, we leverage advanced 3D rendering engine to curate video pairs in
diverse environments. For the realistic domain, we adapt a HDR-based lighting
simulation to complement the lack of paired in-the-wild videos. Powered by the
aforementioned dataset, we design a joint training curriculum to effectively
unleash the strengths of each domain, i.e., the physical consistency in
synthetic videos, and the generalized domain distribution in realistic videos.
To implement this, we inject a domain-aware adapter into the model to decouple
the learning of relighting and domain appearance distribution. We construct a
comprehensive benchmark to evaluate Lumen together with existing methods, from
the perspectives of foreground preservation and video consistency assessment.
Experimental results demonstrate that Lumen effectively edit the input into
cinematic relighted videos with consistent lighting and strict foreground
preservation. Our project page: https://lumen-relight.github.io/

</details>


### [134] [MaskSem: Semantic-Guided Masking for Learning 3D Hybrid High-Order Motion Representation](https://arxiv.org/abs/2508.12948)
*Wei Wei,Shaojie Zhang,Yonghao Dang,Jianqin Yin*

Main category: cs.CV

TL;DR: MaskSem은 Grad-CAM 기반의 의미적 마스킹과 저·고차 운동(속도+가속도)을 재구성 목표로 결합해 골격 기반 자기지도 학습에서 더 풍부한 고차 모션 표현을 학습하도록 설계된 방법이다. 표준 트랜스포머와 결합해 NTU60/NTU120/PKU-MMD 데이터셋에서 성능 향상을 보였다.


<details>
  <summary>Details</summary>
Motivation: 기존 마스크 기반 자기지도 골격 행동 인식 기법들은 일부 관절과 저차(주로 위치/속도) 모션에만 집중해 복잡한 고차 모션 패턴을 잘 포착하지 못한다. 사람-로봇 상호작용과 같은 응용에서는 더 의미론적이고 고차원적인 모션 표현이 필요하다.

Method: (1) Grad-CAM을 상대적 운동(relative motion)에 적용해 시간적으로 의미가 풍부한 관절(temporal origins)을 식별하고 이를 기반으로 의미-유도 마스킹(semantic-guided masking)을 수행한다. (2) 재구성 목표를 저차 운동(속도)과 고차 운동(가속도)을 결합한 하이브리드 고차 모션으로 설정해 모델이 다중 차수의 운동 패턴을 학습하도록 한다. 전체적으로 마스크-재구성 패러다임 위에 의미적 마스킹과 복합 재구성 목표를 얹은 구조이며, 베이스라인은 표준 트랜스포머.

Result: NTU60, NTU120, PKU-MMD에서 MaskSem이 베이스라인(바닐라 트랜스포머)에 비해 행동 인식 성능을 향상시켰다고 보고한다. 자세한 수치와 비교는 초록에 없으나 개선을 주장한다.

Conclusion: 의미-유도 마스킹과 저·고차 운동을 재구성 대상으로 사용하면 마스크 기반 자기지도 골격 행동 인식에서 더 판별력 있는 특징과 복합 모션 패턴을 학습할 수 있으며, 이는 인간-로봇 협업 응용에 적합하다.

Abstract: Human action recognition is a crucial task for intelligent robotics,
particularly within the context of human-robot collaboration research. In
self-supervised skeleton-based action recognition, the mask-based
reconstruction paradigm learns the spatial structure and motion patterns of the
skeleton by masking joints and reconstructing the target from unlabeled data.
However, existing methods focus on a limited set of joints and low-order motion
patterns, limiting the model's ability to understand complex motion patterns.
To address this issue, we introduce MaskSem, a novel semantic-guided masking
method for learning 3D hybrid high-order motion representations. This novel
framework leverages Grad-CAM based on relative motion to guide the masking of
joints, which can be represented as the most semantically rich temporal
orgions. The semantic-guided masking process can encourage the model to explore
more discriminative features. Furthermore, we propose using hybrid high-order
motion as the reconstruction target, enabling the model to learn multi-order
motion patterns. Specifically, low-order motion velocity and high-order motion
acceleration are used together as the reconstruction target. This approach
offers a more comprehensive description of the dynamic motion process,
enhancing the model's understanding of motion patterns. Experiments on the
NTU60, NTU120, and PKU-MMD datasets show that MaskSem, combined with a vanilla
transformer, improves skeleton-based action recognition, making it more
suitable for applications in human-robot interaction.

</details>


### [135] [Breaking Reward Collapse: Adaptive Reinforcement for Open-ended Medical Reasoning with Enhanced Semantic Discrimination](https://arxiv.org/abs/2508.12957)
*Yizhou Liu,Jingwei Wei,Zizhi Chen,Minghao Han,Xukun Zhang,Keliang Liu,Lihua Zhang*

Main category: cs.CV

TL;DR: ARMed는 의료 오픈엔디드 VQA를 위해 체인오브쏘트(SFT)로 도메인 지식을 주입한 뒤, 텍스트 정답성(reward for correctness)과 적응적 의미 보상(adaptive semantic rewards)을 결합한 RL로 추론 품질을 향상시키는 프레임워크다. 6개 벤치에서 인도메인 32.64%, 아웃오브도메인 11.65% 향상을 보고한다.


<details>
  <summary>Details</summary>
Motivation: 의료 영상의 임상적 추론을 반영하는 오픈엔디드 VQA에서 기존 RFT가 폐쇄형 VQA 중심으로 제한되고, 의미 기반 보상이 보상 붕괴(reward collapse)를 겪는 문제를 해결할 필요가 있다.

Method: ARMed는 먼저 체인오브쏘트 데이터로 SFT를 수행하여 추론 능력과 도메인 지식을 주입하고, 이후 텍스트 정답성 보상과 적응적 의미 보상을 결합한 RL로 모델을 미세조정한다. 의미 보상은 응답 간 의미적 차이를 더 잘 구분하도록 적응적으로 조정된다.

Result: 6개의 의료 VQA 벤치마크에서 일관된 성능 향상을 관찰했다. 인도메인 평균 32.64% 상승, 아웃오브도메인 평균 11.65% 상승을 보고하며, 보상 판별력(reward discriminability)이 성능에 중요한 요소임을 보인다.

Conclusion: 의료 RL에서 보상 판별성 확보가 임상적이고 일반화 가능한 추론을 위해 중요하며, 적응적 의미 보상을 포함한 ARMed는 의료 멀티모달 추론의 견고성과 임상 유의미성을 높이는 유망한 접근이다.

Abstract: Reinforcement learning (RL) with rule-based rewards has demonstrated strong
potential in enhancing the reasoning and generalization capabilities of
vision-language models (VLMs) and large language models (LLMs), while reducing
computational overhead. However, its application in medical imaging remains
underexplored. Existing reinforcement fine-tuning (RFT) approaches in this
domain primarily target closed-ended visual question answering (VQA), limiting
their applicability to real-world clinical reasoning. In contrast, open-ended
medical VQA better reflects clinical practice but has received limited
attention. While some efforts have sought to unify both formats via
semantically guided RL, we observe that model-based semantic rewards often
suffer from reward collapse, where responses with significant semantic
differences receive similar scores. To address this, we propose ARMed (Adaptive
Reinforcement for Medical Reasoning), a novel RL framework for open-ended
medical VQA. ARMed first incorporates domain knowledge through supervised
fine-tuning (SFT) on chain-of-thought data, then applies reinforcement learning
with textual correctness and adaptive semantic rewards to enhance reasoning
quality. We evaluate ARMed on six challenging medical VQA benchmarks. Results
show that ARMed consistently boosts both accuracy and generalization, achieving
a 32.64% improvement on in-domain tasks and an 11.65% gain on out-of-domain
benchmarks. These results highlight the critical role of reward
discriminability in medical RL and the promise of semantically guided rewards
for enabling robust and clinically meaningful multimodal reasoning.

</details>


### [136] [Multi-Phase Automated Segmentation of Dental Structures in CBCT Using a Lightweight Auto3DSeg and SegResNet Implementation](https://arxiv.org/abs/2508.12962)
*Dominic LaBella,Keshav Jha,Jared Robbins,Esther Yu*

Main category: cs.CV

TL;DR: CBCT 치아 다중클래스 분할을 위해 MONAI Auto3DSeg과 3D SegResNet을 사용한 파이프라인을 제안함. 63개의 ToothFairy3 스캔으로 5-폴드 교차검증, 0.6 mm 등방성 리샘플링과 강도 클리핑 전처리, 5개 폴드 예측에 Multi-Label STAPLE 앙상블을 적용하고 턱골을 기준으로 타이트 크롭 후 신경 구조를 위한 2단계 분할을 수행함. 대회 검증 세트에서 평균 Dice 0.87 달성.


<details>
  <summary>Details</summary>
Motivation: 치과 CBCT에서 자동 분할은 병변 식별 및 두경부 방사선치료 계획 등 임상적 활용이 높아, 시간 절약과 일관성 제공을 목적으로 함.

Method: MONAI Auto3DSeg 프레임워크, 3D SegResNet 아키텍처, 63 스캔으로 5-fold CV, 0.6 mm 리샘플링, intensity clipping, Multi-Label STAPLE 앙상블, Phase1(턱골 중심 분할)→tight crop→Phase2(작은 신경 구조 분할) 2단계 전략.

Result: ToothFairy3 오프-샘플 검증에서 평균 Dice 0.87. 세부 클래스별 성능과 추가 지표는 초록에 없음.

Conclusion: 정량적 성능은 유망하나 데이터 양, 클래스 불균형, 작은 구조(신경) 분할의 불확실성 및 일반화성 검증이 필요. 추가적인 성능 분석(클래스별 Dice, Hausdorff, 민감도/특이도), 외부 검증, 불확실성 추정 및 후처리/데이터 증강 전략 검토를 권장.

Abstract: Cone-beam computed tomography (CBCT) has become an invaluable imaging
modality in dentistry, enabling 3D visualization of teeth and surrounding
structures for diagnosis and treatment planning. Automated segmentation of
dental structures in CBCT can efficiently assist in identifying pathology
(e.g., pulpal or periapical lesions) and facilitate radiation therapy planning
in head and neck cancer patients. We describe the DLaBella29 team's approach
for the MICCAI 2025 ToothFairy3 Challenge, which involves a deep learning
pipeline for multi-class tooth segmentation. We utilized the MONAI Auto3DSeg
framework with a 3D SegResNet architecture, trained on a subset of the
ToothFairy3 dataset (63 CBCT scans) with 5-fold cross-validation. Key
preprocessing steps included image resampling to 0.6 mm isotropic resolution
and intensity clipping. We applied an ensemble fusion using Multi-Label STAPLE
on the 5-fold predictions to infer a Phase 1 segmentation and then conducted
tight cropping around the easily segmented Phase 1 mandible to perform Phase 2
segmentation on the smaller nerve structures. Our method achieved an average
Dice of 0.87 on the ToothFairy3 challenge out-of-sample validation set. This
paper details the clinical context, data preparation, model development,
results of our approach, and discusses the relevance of automated dental
segmentation for improving patient care in radiation oncology.

</details>


### [137] [GazeDETR: Gaze Detection using Disentangled Head and Gaze Representations](https://arxiv.org/abs/2508.12966)
*Ryan Anthony Jalova de Belen,Gelareh Mohammadi,Arcot Sowmya*

Main category: cs.CV

TL;DR: GazeDETR은 머리 위치 탐지와 시선 타깃 예측을 분리된 두 디코더로 처리하는 end-to-end 아키텍처로, 각 서브태스크에 맞는 고유 표현과 주의 영역을 학습해 GazeFollow, VideoAttentionTarget, ChildPlay 데이터셋에서 SOTA 성능을 달성한다.


<details>
  <summary>Details</summary>
Motivation: 기존 end-to-end 모델은 단일 디코더로 머리 영역 검출과 시선 예측을 동시에 수행하여 두 태스크 표현이 얽히고 최적화에 제약을 받아 성능 한계가 발생한다는 문제의식에서 출발.

Method: DETR 계열 구조를 바탕으로 두 개의 분리된 디코더(head decoder, gaze decoder)를 설계. head decoder는 주로 지역 정보(local)를, gaze decoder는 지역과 전역 정보(local+global)를 통합하도록 주의(attention) 메커니즘을 조정하여 각 태스크에 적합한 표현을 학습.

Result: 제안된 GazeDETR은 GazeFollow, VideoAttentionTarget, ChildPlay에서 기존 end-to-end 모델들을 상당한 차이로 앞서며 SOTA 성능을 보고함.

Conclusion: 디코더 분리를 통해 머리 위치와 시선 예측에 특화된 표현과 주의 영역을 얻을 수 있으며, 이는 성능 및 해석 가능성을 모두 개선한다.

Abstract: Gaze communication plays a crucial role in daily social interactions.
Quantifying this behavior can help in human-computer interaction and digital
phenotyping. While end-to-end models exist for gaze target detection, they only
utilize a single decoder to simultaneously localize human heads and predict
their corresponding gaze (e.g., 2D points or heatmap) in a scene. This
multitask learning approach generates a unified and entangled representation
for human head localization and gaze location prediction. Herein, we propose
GazeDETR, a novel end-to-end architecture with two disentangled decoders that
individually learn unique representations and effectively utilize coherent
attentive fields for each subtask. More specifically, we demonstrate that its
human head predictor utilizes local information, while its gaze decoder
incorporates both local and global information. Our proposed architecture
achieves state-of-the-art results on the GazeFollow, VideoAttentionTarget and
ChildPlay datasets. It outperforms existing end-to-end models with a notable
margin.

</details>


### [138] [Compact Attention: Exploiting Structured Spatio-Temporal Sparsity for Fast Video Generation](https://arxiv.org/abs/2508.12969)
*Qirui Li,Guangcong Zheng,Qi Zhao,Jie Li,Bin Dong,Yiwu Yao,Xi Li*

Main category: cs.CV

TL;DR: DiT(비디오 디퓨전 트랜스포머)의 주의(attention) 행렬은 특화된 헤드들이 서로 다른 시공간 패턴(지역, 십자형, 전역 등)에 동적으로 주목하는 구조적이면서 이질적인 희소성을 보인다. 이를 활용해 하드웨어 친화적 희소화인 Compact Attention을 제안하여 어텐션 계산을 단일 GPU에서 1.6~2.5배 가속하면서 시각적 품질을 유지한다.


<details>
  <summary>Details</summary>
Motivation: 자기-주의(self-attention)의 계산 비용이 비디오 생성에서 결정적 병목이며, 기존의 고정 희소 패턴이나 단순 분해된 어텐션은 비디오의 시공간적 중복성을 충분히 활용하지 못해 초장기 시퀀스 합성이 비효율적이다.

Method: (1) 적응형 타일링: 다양한 공간 상호작용 패턴을 동적 타일 그룹화로 근사, (2) 시간에 따라 변하는 윈도우: 프레임 거리 기반으로 희소 수준을 조절하여 시간적 상관성을 반영, (3) 자동 구성 검색: 주요 어텐션 경로를 보존하면서 희소 패턴을 하드웨어 관점에서 최적화하는 탐색 알고리즘.

Result: 단일 GPU 환경에서 어텐션 계산을 1.6~2.5배 가속했고, 전체 모델의 시각적 품질은 풀 어텐션 기준과 유사하게 유지되었다(추가 실험/정량·정성 평가 포함).

Conclusion: 시공간적 고유 구조를 반영한 동적·구조적 희소화는 초장기 비디오 생성의 효율을 크게 향상시키며, 하드웨어 인식적 설계와 자동 최적화를 결합하면 실무적 가속을 실현할 수 있다.

Abstract: The computational demands of self-attention mechanisms pose a critical
challenge for transformer-based video generation, particularly in synthesizing
ultra-long sequences. Current approaches, such as factorized attention and
fixed sparse patterns, fail to fully exploit the inherent spatio-temporal
redundancies in video data. Through systematic analysis of video diffusion
transformers (DiT), we uncover a key insight: Attention matrices exhibit
structured, yet heterogeneous sparsity patterns, where specialized heads
dynamically attend to distinct spatiotemporal regions (e.g., local pattern,
cross-shaped pattern, or global pattern). Existing sparse attention methods
either impose rigid constraints or introduce significant overhead, limiting
their effectiveness. To address this, we propose Compact Attention, a
hardware-aware acceleration framework featuring three innovations: 1) Adaptive
tiling strategies that approximate diverse spatial interaction patterns via
dynamic tile grouping, 2) Temporally varying windows that adjust sparsity
levels based on frame proximity, and 3) An automated configuration search
algorithm that optimizes sparse patterns while preserving critical attention
pathways. Our method achieves 1.6~2.5x acceleration in attention computation on
single-GPU setups while maintaining comparable visual quality with
full-attention baselines. This work provides a principled approach to unlocking
efficient long-form video generation through structured sparsity exploitation.
Project Page: https://yo-ava.github.io/Compact-Attention.github.io/

</details>


### [139] [Dextr: Zero-Shot Neural Architecture Search with Singular Value Decomposition and Extrinsic Curvature](https://arxiv.org/abs/2508.12977)
*Rohan Asthana,Joschua Conrad,Maurits Ortmanns,Vasileios Belagiannis*

Main category: cs.CV

TL;DR: 레이블 없는(single label-free) 단일 샘플로 네트워크 성능을 예측하는 제로-샷 NAS 프록시를 제안한다. SVD로 얻은 피처의 컨디션(채널 공선성)과 네트워크 출력의 외재 곡률을 결합해 수렴성·일반화·표현력을 동시에 반영한다.


<details>
  <summary>Details</summary>
Motivation: 기존 제로-샷 프록시는 보통 레이블이 필요하거나(실제 환경에서 불가) 수렴성·일반화와 표현력 중 하나만 평가하는 경향이 있다. 저자들은 채널 공선성이 수렴성과 일반화에 미치는 영향을 보이고, 이를 포함한 통합 프록시가 필요하다고 주장한다.

Method: 각 레이어 특징에 대해 SVD로 특이값을 구해 컨디션 넘버(채널 공선성)를 산정하고, 네트워크 출력의 외재 곡률(extrinsic curvature)을 계산한다. 두 구성요소(특징 컨디션의 역수 합, 출력 곡률)의 로그를 취해 단순화된 조화평균으로 결합한 값을 프록시 점수로 사용한다. 모든 계산은 레이블을 요구하지 않으며 단일 데이터 샘플로 수행 가능하다.

Result: NAS-Bench-101/201, TransNAS-Bench-101-micro 및 DARTS/AutoFormer 검색 공간에서 여러 상관성 벤치마크(랭킹 상관 등)에서 우수한 성능을 보였고 계산 효율도 높다고 보고한다.

Conclusion: 수렴성·일반화·표현력을 통합한 레이블 프리 제로-샷 프록시로서 실용적 가능성을 제시하며, 코드(공개 링크)를 통해 재현성을 제공한다.

Abstract: Zero-shot Neural Architecture Search (NAS) typically optimises the
architecture search process by exploiting the network or gradient properties at
initialisation through zero-cost proxies. The existing proxies often rely on
labelled data, which is usually unavailable in real-world settings.
Furthermore, the majority of the current methods focus either on optimising the
convergence and generalisation attributes or solely on the expressivity of the
network architectures. To address both limitations, we first demonstrate how
channel collinearity affects the convergence and generalisation properties of a
neural network. Then, by incorporating the convergence, generalisation and
expressivity in one approach, we propose a zero-cost proxy that omits the
requirement of labelled data for its computation. In particular, we leverage
the Singular Value Decomposition (SVD) of the neural network layer features and
the extrinsic curvature of the network output to design our proxy. %As a
result, the proposed proxy is formulated as the simplified harmonic mean of the
logarithms of two key components: the sum of the inverse of the feature
condition number and the extrinsic curvature of the network output. Our
approach enables accurate prediction of network performance on test data using
only a single label-free data sample. Our extensive evaluation includes a total
of six experiments, including the Convolutional Neural Network (CNN) search
space, i.e. DARTS and the Transformer search space, i.e. AutoFormer. The
proposed proxy demonstrates a superior performance on multiple correlation
benchmarks, including NAS-Bench-101, NAS-Bench-201, and
TransNAS-Bench-101-micro; as well as on the NAS task within the DARTS and the
AutoFormer search space, all while being notably efficient. The code is
available at https://github.com/rohanasthana/Dextr.

</details>


### [140] [Omni Survey for Multimodality Analysis in Visual Object Tracking](https://arxiv.org/abs/2508.13000)
*Zhangyong Tang,Tianyang Xu,Xuefeng Zhu,Hui Li,Shaochuan Zhao,Tao Zhou,Chunyang Cheng,Xiaojun Wu,Josef Kittler*

Main category: cs.CV

TL;DR: 본 논문은 RGB와 T/D/E/NIR/L/S 등 이종 모달을 통합한 다중모달 시각 객체 추적(MMVOT)을 포괄적으로 정리한 설문조사로, 데이터 수집·정렬·주석, 모델 설계, 평가의 4가지 관점에서 기존 연구를 분류·고찰하고 벤치마크와 데이터셋의 분포(긴 꼬리·동물 범주 부족)를 분석한다.


<details>
  <summary>Details</summary>
Motivation: 스마트시티 등 실제 환경에서 대규모 다중모달 데이터가 생성됨에 따라 단일 모달 추적의 한계를 극복하고 다양한 센서 정보를 결합하는 MMVOT 연구의 필요성이 증대되었기 때문에, 이 분야의 전반을 정리하고 연구 방향과 한계를 제시하려는 목적.

Method: 관련 모달리티(RGB, 열(T), 깊이(D), 이벤트(E), 근적외선(NIR), 언어(L), 소나(S))를 소개하고, 데이터 수집·정렬·주석 과정의 도전 과제를 논의한 뒤, RGB와 보조 X 모달리티를 어떻게 결합(복제/비복제 구성 등)하는지에 따라 기존 방법들을 분류. 마지막으로 평가 지표·벤치마크와 데이터셋의 카테고리 분포를 분석.

Result: 6개 MMVOT 과제와 338개 참고문헌을 아우르는 포괄적 서베이를 제공하고, 데이터셋의 객체 범주가 장기 꼬리 분포를 보이며 RGB 데이터셋에 비해 동물 카테고리가 현저히 부족하다는 통계적 분석 결과를 제시함.

Conclusion: 다중모달 정보 융합이 항상 단일 모달보다 우수한 해법을 보장하지는 않으며, 데이터 품질·정렬·주석·모델 설계와 적용 환경에 따라 유효성이 달라진다. 따라서 데이터 다양성 확보, 정렬·주석 표준화, 성능 우위를 평가할 수 있는 엄격한 벤치마크가 필요하다는 결론.

Abstract: The development of smart cities has led to the generation of massive amounts
of multi-modal data in the context of a range of tasks that enable a
comprehensive monitoring of the smart city infrastructure and services. This
paper surveys one of the most critical tasks, multi-modal visual object
tracking (MMVOT), from the perspective of multimodality analysis. Generally,
MMVOT differs from single-modal tracking in four key aspects, data collection,
modality alignment and annotation, model designing, and evaluation.
Accordingly, we begin with an introduction to the relevant data modalities,
laying the groundwork for their integration. This naturally leads to a
discussion of challenges of multi-modal data collection, alignment, and
annotation. Subsequently, existing MMVOT methods are categorised, based on
different ways to deal with visible (RGB) and X modalities: programming the
auxiliary X branch with replicated or non-replicated experimental
configurations from the RGB branch. Here X can be thermal infrared (T), depth
(D), event (E), near infrared (NIR), language (L), or sonar (S). The final part
of the paper addresses evaluation and benchmarking. In summary, we undertake an
omni survey of all aspects of multi-modal visual object tracking (VOT),
covering six MMVOT tasks and featuring 338 references in total. In addition, we
discuss the fundamental rhetorical question: Is multi-modal tracking always
guaranteed to provide a superior solution to unimodal tracking with the help of
information fusion, and if not, in what circumstances its application is
beneficial. Furthermore, for the first time in this field, we analyse the
distributions of the object categories in the existing MMVOT datasets,
revealing their pronounced long-tail nature and a noticeable lack of animal
categories when compared with RGB datasets.

</details>


### [141] [Empirical Evidences for the Effects of Feature Diversity in Open Set Recognition and Continual Learning](https://arxiv.org/abs/2508.13005)
*Jiawen Xu,Odej Kao*

Main category: cs.CV

TL;DR: 특징(feature) 다양성을 증가시키면 개방집합 인식(Open Set Recognition) 성능이 개선되고, 연속학습(Continual Learning)에서 이전 지식 유지와 신규 클래스 통합이 더 수월해진다는 실험적 증거를 제시함.


<details>
  <summary>Details</summary>
Motivation: OSR은 추론 시 미지 클래스 탐지, 연속학습은 새 클래스 학습 시 기존 지식 보존이 핵심 문제임. 기존 연구들은 주로 휴리스틱하게 특징 다양성 증대를 이용했으나, 특징 다양성이 두 문제에 미치는 직접적 영향은 체계적으로 검증된 바가 적음.

Method: 특징 다양성 조절 기법들을 적용해 다양한 데이터셋과 설정에서 실험을 수행하고, 특징 다양성 측정 지표와 OSR/연속학습 성능 간의 관계를 분석함. 비교 실험을 통해 다양성 증대가 성능에 미치는 영향을 정량적으로 평가함.

Result: 특징 다양성이 증가할수록 미지 클래스 탐지 성능이 개선되었고, 연속학습 환경에서는 이전 데이터의 유지(망각 감소)와 신규 클래스 통합 성능이 함께 향상됨을 관찰함.

Conclusion: 특징 다양성은 OSR과 연속학습 모두에서 중요한 역할을 하며, 이를 활용한 실용적 방법 개발과 이론적 이해가 향후 연구에서 유망한 방향임.

Abstract: Open set recognition (OSR) and continual learning are two critical challenges
in machine learning, focusing respectively on detecting novel classes at
inference time and updating models to incorporate the new classes. While many
recent approaches have addressed these problems, particularly OSR, by
heuristically promoting feature diversity, few studies have directly examined
the role that feature diversity plays in tackling them. In this work, we
provide empirical evidence that enhancing feature diversity improves the
recognition of open set samples. Moreover, increased feature diversity also
facilitates both the retention of previously learned data and the integration
of new data in continual learning. We hope our findings can inspire further
research into both practical methods and theoretical understanding in these
domains.

</details>


### [142] [SlimComm: Doppler-Guided Sparse Queries for Bandwidth-Efficient Cooperative 3-D Perception](https://arxiv.org/abs/2508.13007)
*Melih Yazgan,Qiyuan Wu,Iramm Hamdard,Shiqi Li,J. Marius Zoellner*

Main category: cs.CV

TL;DR: 4D 레이더 도플러와 쿼리 기반 희소 전송을 결합해 BEV 기능 맵 전송량을 크게 줄인 CAV 협업 인식 프레임워크 SlimComm를 제안한다.


<details>
  <summary>Details</summary>
Motivation: BEV 특징 맵을 통째로 공유하면 대역폭 부담이 심해 협업 자율주행에 제약이 있으므로, 이동성 중심의 정보만 선택적으로 교환해 통신 효율을 높이고자 한다.

Method: 4D 레이더 도플러로 동적 맵을 만들고, 동적/고신뢰 영역에 대한 참조 쿼리와 가려진 영역을 탐색하는 탐사 쿼리(2단계 오프셋) 두 종류의 쿼리를 생성한다. 쿼리별 BEV 특징만 교환하고 멀티스케일 게이트형 변형 어텐션으로 융합해 페이로드를 줄인다.

Result: OPV2V-R 및 Adver-City-R(포인트 단위 도플러 포함) 데이터셋에서 전체 맵 공유 대비 최대 90% 통신량 절감. 다양한 교통 밀도와 가림 상황에서 기존 기법과 동등하거나 우수한 성능을 달성.

Conclusion: 도플러 기반 동적 쿼리와 희소 전송, 변형 어텐션 융합의 조합으로 통신 효율을 크게 개선하면서 협업 인식 정확도를 유지하거나 향상시킨다.

Abstract: Collaborative perception allows connected autonomous vehicles (CAVs) to
overcome occlusion and limited sensor range by sharing intermediate features.
Yet transmitting dense Bird's-Eye-View (BEV) feature maps can overwhelm the
bandwidth available for inter-vehicle communication. We present SlimComm, a
communication-efficient framework that integrates 4D radar Doppler with a
query-driven sparse scheme. SlimComm builds a motion-centric dynamic map to
distinguish moving from static objects and generates two query types: (i)
reference queries on dynamic and high-confidence regions, and (ii) exploratory
queries probing occluded areas via a two-stage offset. Only query-specific BEV
features are exchanged and fused through multi-scale gated deformable
attention, reducing payload while preserving accuracy. For evaluation, we
release OPV2V-R and Adver-City-R, CARLA-based datasets with per-point Doppler
radar. SlimComm achieves up to 90% lower bandwidth than full-map sharing while
matching or surpassing prior baselines across varied traffic densities and
occlusions. Dataset and code will be available at: https://url.fzi.de/SlimComm.

</details>


### [143] [Matrix-Game 2.0: An Open-Source, Real-Time, and Streaming Interactive World Model](https://arxiv.org/abs/2508.13009)
*Xianglong He,Chunli Peng,Zexiang Liu,Boyang Wang,Yifan Zhang,Qi Cui,Fei Kang,Biao Jiang,Mengyin An,Yangyang Ren,Baixin Xu,Hao-Xiang Guo,Kaixiong Gong,Cyrus Wu,Wei Li,Xuchen Song,Yang Liu,Eric Li,Yahui Zhou*

Main category: cs.CV

TL;DR: Matrix-Game 2.0은 프레임 단위의 마우스/키보드 입력을 조건으로 few-step auto-regressive diffusion을 이용해 실시간(약 25FPS)으로 분 단위 고화질 비디오를 생성하는 인터랙티브 월드 모델이다. 대규모(약 1200시간) Unreal/GTA5 데이터 파이프라인, 액션 인젝션 모듈, 인과적 구조 기반 few-step 증류를 결합해 지연을 최소화했다.


<details>
  <summary>Details</summary>
Motivation: 기존 상호작용형 월드 모델들은 양방향 어텐션과 긴 추론 단계에 의존해 실시간 반응성과 스트리밍 처리가 어려웠다. 실제 환경에서는 과거 문맥과 현재 행동에 따라 결과가 즉시 갱신되어야 하므로, 저지연의 온더플라이 생성이 필요하다.

Method: (1) Unreal Engine과 GTA5에서 대규모 상호작용 비디오 데이터(약 1200시간) 자동생산 파이프라인 구축, (2) 프레임 수준 마우스/키보드 입력을 조건으로 주입하는 액션 인젝션 모듈 설계, (3) 인과적(causal) 아키텍처와 few-step 증류(distillation)를 통해 다단계 확산 모델을 소수 단계의 auto-regressive 생성기로 압축하여 실시간·스트리밍 생성 구현.

Result: 다양한 장면에서 분 단위 고화질 비디오를 초고속(약 25 FPS)으로 생성 가능하다고 보고. 모델 가중치와 코드베이스를 오픈소스화하여 재현과 후속 연구를 지원.

Conclusion: Matrix-Game 2.0은 인터랙티브 월드 모델의 실시간성 문제를 해결하는 실용적 접근을 제시한다. 대규모 합성 데이터와 액션 조건화, few-step 증류의 조합으로 온더플라이 시뮬레이션이 가능해졌으나, 합성↔실세계 갭·평가 지표·하드웨어 요구사항 등은 추가 검증이 필요하다.

Abstract: Recent advances in interactive video generations have demonstrated diffusion
model's potential as world models by capturing complex physical dynamics and
interactive behaviors. However, existing interactive world models depend on
bidirectional attention and lengthy inference steps, severely limiting
real-time performance. Consequently, they are hard to simulate real-world
dynamics, where outcomes must update instantaneously based on historical
context and current actions. To address this, we present Matrix-Game 2.0, an
interactive world model generates long videos on-the-fly via few-step
auto-regressive diffusion. Our framework consists of three key components: (1)
A scalable data production pipeline for Unreal Engine and GTA5 environments to
effectively produce massive amounts (about 1200 hours) of video data with
diverse interaction annotations; (2) An action injection module that enables
frame-level mouse and keyboard inputs as interactive conditions; (3) A few-step
distillation based on the casual architecture for real-time and streaming video
generation. Matrix Game 2.0 can generate high-quality minute-level videos
across diverse scenes at an ultra-fast speed of 25 FPS. We open-source our
model weights and codebase to advance research in interactive world modeling.

</details>


### [144] [EgoTwin: Dreaming Body and View in First Person](https://arxiv.org/abs/2508.13013)
*Jingqiao Xiu,Fangzhou Hong,Yicong Li,Mengze Li,Wentao Wang,Sirui Han,Liang Pan,Ziwei Liu*

Main category: cs.CV

TL;DR: EgoTwin은 확산 트랜스포머 기반으로 영상과 인간 모션을 동시에 생성하는 프레임워크로, 머리 관절 중심 표현과 비디오-모션 간의 인과적 상호작용을 주의(attention) 연산에 도입해 시점 정렬과 인과적 일치 문제를 해결한다. 대규모 동기화 텍스트-비디오-모션 데이터셋과 새로운 평가 지표를 통해 효과를 입증한다.


<details>
  <summary>Details</summary>
Motivation: 기존 연구는 주로 외부 시점(exocentric) 비디오 합성에 초점이 맞춰져 있어, 착용자 신체 움직임에 따라 변하는 1인칭(egocentric) 시점과 카메라(머리) 궤적을 함께 모델링해야 하는 문제는 미해결로 남아 있다. 이를 해결하려면 영상의 카메라 궤적과 인간 모션의 머리 궤적을 정렬하고, 인접 프레임의 시각적 변화와 인간 모션 사이의 인과 관계를 명시적으로 반영해야 한다.

Method: EgoTwin은 확산(denoising) 트랜스포머 구조를 기반으로 한다. 핵심 요소로는: (1) 머리 중심(head-centric) 모션 표현을 도입해 인간 모션을 머리 관절에 고정시키고; (2) 사이버네틱스에서 영감을 받은 상호작용 메커니즘을 통해 비디오와 모션 간의 인과적 상호작용을 주의 연산 내부에 명시적으로 반영한다. 텍스트 조건부 생성도 포함된 것으로 보이며, 비디오-모션 동시 생성 파이프라인을 설계했다.

Result: 저자들은 대규모의 동기화된 텍스트-비디오-모션 트리플렛 데이터셋을 구축하고, 비디오-모션 일관성 평가를 위한 새로운 지표들을 제안했다. 광범위한 실험에서 EgoTwin이 시점 정렬(Viewpoint Alignment)과 인과적 일치(Causal Interplay) 측면에서 성능 우위를 보였다고 보고한다.

Conclusion: EgoTwin은 머리 중심 모션 표현과 인과적 상호작용 메커니즘을 결합해, egocentric 비디오와 인간 모션을 일관되게 동시에 생성할 수 있음을 제시한다. 제안 방법과 데이터셋·평가지표는 이 새로운 연구 방향의 기반을 마련한다.

Abstract: While exocentric video synthesis has achieved great progress, egocentric
video generation remains largely underexplored, which requires modeling
first-person view content along with camera motion patterns induced by the
wearer's body movements. To bridge this gap, we introduce a novel task of joint
egocentric video and human motion generation, characterized by two key
challenges: 1) Viewpoint Alignment: the camera trajectory in the generated
video must accurately align with the head trajectory derived from human motion;
2) Causal Interplay: the synthesized human motion must causally align with the
observed visual dynamics across adjacent video frames. To address these
challenges, we propose EgoTwin, a joint video-motion generation framework built
on the diffusion transformer architecture. Specifically, EgoTwin introduces a
head-centric motion representation that anchors the human motion to the head
joint and incorporates a cybernetics-inspired interaction mechanism that
explicitly captures the causal interplay between video and motion within
attention operations. For comprehensive evaluation, we curate a large-scale
real-world dataset of synchronized text-video-motion triplets and design novel
metrics to assess video-motion consistency. Extensive experiments demonstrate
the effectiveness of the EgoTwin framework.

</details>


### [145] [HierAdaptMR: Cross-Center Cardiac MRI Reconstruction with Hierarchical Feature Adapters](https://arxiv.org/abs/2508.13026)
*Ruru Xu,Ilkay Oksuz*

Main category: cs.CV

TL;DR: HierAdaptMR은 프로토콜-레벨 어댑터와 센터-레벨 어댑터, 그리고 미지 센터 일반화를 위한 유니버설 어댑터를 변분 언롤링 백본 위에 계층적으로 결합해 병원·스캐너 간 도메인 편차를 파라미터 효율적으로 보정하는 심장 MRI 재구성 프레임워크이다. 다중 스케일 SSIM과 주파수 도메인 강조, 콘트라스트 적응 가중치를 이용해 안정적으로 학습하며, CMRxRecon2025 데이터셋에서 뛰어난 크로스-센터 일반화를 보였다.


<details>
  <summary>Details</summary>
Motivation: 심장 MRI 재구성 모델은 병원별 스캐너·프로토콜 차이(도메인 시프트)에 민감해 실제 다중 센터 배포 시 성능 저하가 심함. 전체 모델을 재학습하지 않고도 센터·프로토콜 종속성을 효율적으로 보정하는 방법 필요.

Method: 변분 언롤링 기반 재구성 백본에 파라미터 효율적인 어댑터를 계층적으로 삽입: 프로토콜-레벨 어댑터(시퀀스 특이성), 센터-레벨 어댑터(스캐너 특이성), 그리고 미지 센터에 대응하기 위한 확률적 학습으로 훈련된 유니버설 어댑터. 손실로는 다중 스케일 SSIM과 주파수 도메인 강화, 콘트라스트 적응 가중치를 사용.

Result: CMRxRecon2025(5+ 센터, 10+ 스캐너, 9 모달리티)에서 다른 방법들보다 크로스-센터 일반화 성능 우수. 재구성 품질을 유지하면서 파라미터 효율을 달성했다고 보고.

Conclusion: 계층적 어댑터 설계와 유니버설 어댑터의 확률적 학습을 통해 다중 센터 환경에서 실용적이고 확장 가능한 MRI 재구성 일반화를 달성. 파라미터 효율성과 견고한 손실 설계가 핵심.

Abstract: Deep learning-based cardiac MRI reconstruction faces significant domain shift
challenges when deployed across multiple clinical centers with heterogeneous
scanner configurations and imaging protocols. We propose HierAdaptMR, a
hierarchical feature adaptation framework that addresses multi-level domain
variations through parameter-efficient adapters. Our method employs
Protocol-Level Adapters for sequence-specific characteristics and Center-Level
Adapters for scanner-dependent variations, built upon a variational unrolling
backbone. A Universal Adapter enables generalization to entirely unseen centers
through stochastic training that learns center-invariant adaptations. The
framework utilizes multi-scale SSIM loss with frequency domain enhancement and
contrast-adaptive weighting for robust optimization. Comprehensive evaluation
on the CMRxRecon2025 dataset spanning 5+ centers, 10+ scanners, and 9
modalities demonstrates superior cross-center generalization while maintaining
reconstruction quality. code: https://github.com/Ruru-Xu/HierAdaptMR

</details>


### [146] [IntelliCap: Intelligent Guidance for Consistent View Sampling](https://arxiv.org/abs/2508.13043)
*Ayaka Yasunaga,Hideo Saito,Dieter Schmalstieg,Shohei Mori*

Main category: cs.CV

TL;DR: 다중 스케일 스캔 중 시각적 가이드를 제공해 인간 촬영자가 고품질 뷰 합성을 위한 균일·조밀한 이미지 샘플을 쉽게 수집하도록 돕는 방법을 제안한다. 객체 중요도를 VLM(비전-언어 모델)로 평가하고, 고랭크 객체 주위에 구형 프록시를 만들어 사용자를 유도한다.


<details>
  <summary>Details</summary>
Motivation: 고품질 신뷰 합성(예: 3D Gaussian splatting)은 균일하고 조밀한 뷰 샘플이 필요하나, 인간 촬영자는 시간·지식 제약으로 이를 충족시키기 어렵다. 기존 유도 방법은 단일 객체에 집중하거나 시야 의존성(재질)을 무시한다.

Method: 장면을 스캔할 때 의미 분할과 카테고리 식별을 수행하고, VLM로 객체 중요도를 랭킹한다. 높은 순위의 객체 주위에 구형 프록시(시추 가이드)를 생성해 다중 스케일로 사용자에게 시각적 피드백을 제공한다.

Result: 실제 장면에서 기존 뷰 샘플링 전략보다 우수한 성능을 보여주며, 특히 시야 의존적 외관을 가진 객체에서 추가 촬영이 요구되는 부분을 효과적으로 강조한다.

Conclusion: 시맨틱+VLM 기반의 다중 스케일 시각화가 인간 촬영자가 고품질 신뷰 합성용 입력을 효율적으로 수집하도록 도울 수 있음을 보인다.

Abstract: Novel view synthesis from images, for example, with 3D Gaussian splatting,
has made great progress. Rendering fidelity and speed are now ready even for
demanding virtual reality applications. However, the problem of assisting
humans in collecting the input images for these rendering algorithms has
received much less attention. High-quality view synthesis requires uniform and
dense view sampling. Unfortunately, these requirements are not easily addressed
by human camera operators, who are in a hurry, impatient, or lack understanding
of the scene structure and the photographic process. Existing approaches to
guide humans during image acquisition concentrate on single objects or neglect
view-dependent material characteristics. We propose a novel situated
visualization technique for scanning at multiple scales. During the scanning of
a scene, our method identifies important objects that need extended image
coverage to properly represent view-dependent appearance. To this end, we
leverage semantic segmentation and category identification, ranked by a
vision-language model. Spherical proxies are generated around highly ranked
objects to guide the user during scanning. Our results show superior
performance in real scenes compared to conventional view sampling strategies.

</details>


### [147] [Odo: Depth-Guided Diffusion for Identity-Preserving Body Reshaping](https://arxiv.org/abs/2508.13065)
*Siddharth Khandelwal,Sridhar Kamath,Arjun Jain*

Main category: cs.CV

TL;DR: Introduces the first large-scale controlled human shape-editing dataset (18,573 images, 1,523 subjects) and proposes Odo, a diffusion-based method combining a frozen UNet for appearance preservation with a ControlNet guided by target SMPL depth maps to reshape body shape. Achieves per-vertex error 7.5mm vs 13.6mm for baselines and produces realistic results matching target shapes.


<details>
  <summary>Details</summary>
Motivation: Human shape editing is underexplored compared to pose editing due to lack of large-scale datasets and challenges from 3D model or warping-based methods (unrealistic proportions, texture/background distortions). Authors aim to enable controllable, realistic body reshaping while keeping pose, identity, clothing, and background consistent.

Method: Create a curated dataset of 18,573 images across 1,523 identities with controlled variations in body shape. Propose Odo: an end-to-end diffusion-based image-to-image model. It uses a frozen UNet to preserve fine-grained appearance and background, and a ControlNet that conditions generation on target SMPL-derived depth maps to guide shape change. Training leverages paired images of same identity/pose with different shapes and semantic attribute guidance for intuitive control.

Result: Outperforms prior approaches quantitatively (per-vertex reconstruction error as low as 7.5mm vs 13.6mm baseline) and qualitatively (realistic, accurate shape changes that preserve clothing and background). Extensive experiments and comparisons are reported.

Conclusion: Providing a large, controlled dataset plus the Odo method substantially advances practical human shape editing: more accurate reconstruction, better appearance/background preservation, and intuitive semantic control. The work highlights dataset importance and shows diffusion+ControlNet as an effective paradigm for realistic shape manipulation.

Abstract: Human shape editing enables controllable transformation of a person's body
shape, such as thin, muscular, or overweight, while preserving pose, identity,
clothing, and background. Unlike human pose editing, which has advanced
rapidly, shape editing remains relatively underexplored. Current approaches
typically rely on 3D morphable models or image warping, often introducing
unrealistic body proportions, texture distortions, and background
inconsistencies due to alignment errors and deformations. A key limitation is
the lack of large-scale, publicly available datasets for training and
evaluating body shape manipulation methods. In this work, we introduce the
first large-scale dataset of 18,573 images across 1523 subjects, specifically
designed for controlled human shape editing. It features diverse variations in
body shape, including fat, muscular and thin, captured under consistent
identity, clothing, and background conditions. Using this dataset, we propose
Odo, an end-to-end diffusion-based method that enables realistic and intuitive
body reshaping guided by simple semantic attributes. Our approach combines a
frozen UNet that preserves fine-grained appearance and background details from
the input image with a ControlNet that guides shape transformation using target
SMPL depth maps. Extensive experiments demonstrate that our method outperforms
prior approaches, achieving per-vertex reconstruction errors as low as 7.5mm,
significantly lower than the 13.6mm observed in baseline methods, while
producing realistic results that accurately match the desired target shapes.

</details>


### [148] [Eyes on the Image: Gaze Supervised Multimodal Learning for Chest X-ray Diagnosis and Report Generation](https://arxiv.org/abs/2508.13068)
*Tanjim Islam Riju,Shuchismita Anwar,Saman Sarker Joy,Farig Sadeque,Swakkhar Shatabda*

Main category: cs.CV

TL;DR: 저자들은 방사선과 의사 시선(gaze)을 활용해 흉부 X선의 질환 분류와 부위별 보고서 생성 성능을 개선하는 두 단계 멀티모달 프레임워크를 제안한다. 시선-유도 콘트라스티브 학습과 다항식 시선-어텐션 손실을 도입해 분류 성능을 높였고, 확신도 가중 키워드와 해부학 사전 기반 매핑을 통해 영역 정렬된 보고서를 생성하여 임상 키워드 재현율과 ROUGE를 개선했다.


<details>
  <summary>Details</summary>
Motivation: 시선 정보는 방사선과 전문의가 영상에서 주목하는 부위를 직접적으로 반영하므로, 이를 분류와 보고서 생성 과정에 통합하면 성능과 해석가능성을 동시에 높일 수 있다는 가정에서 출발한다.

Method: 1) 시선, 바운딩 박스, 영상 특징, 임상 레이블을 통합한 시선-유도 콘트라스티브 학습 아키텍처 도입. 새로운 다중 항목 시선-어텐션 손실(MSE, KL, 상관계수, 무게 중심 정렬)을 사용해 어텐션을 감독함. 2) 신뢰도 가중 진단 키워드 추출 → 도메인 사전으로 해부학적 영역 매핑 → 구조화된 프롬프트로 영역 정렬 문장 생성하는 모듈형 보고서 생성 파이프라인.

Result: 시선을 포함하면 F1 0.597→0.631 (+5.7%), AUC 0.821→0.849 (+3.41%) 등 분류 성능 향상. 보고서는 임상 키워드 재현율과 ROUGE 점수 개선을 보였음.

Conclusion: 의사 시선 데이터를 통합하면 분류 성능과 보고서의 해석가능성을 개선할 수 있으며, 시선 기반 어텐션 감독과 영역 정렬된 생성 파이프라인이 효과적임을 시사한다.

Abstract: We propose a two-stage multimodal framework that enhances disease
classification and region-aware radiology report generation from chest X-rays,
leveraging the MIMIC-Eye dataset. In the first stage, we introduce a
gaze-guided contrastive learning architecture for disease classification. It
integrates visual features, clinical labels, bounding boxes, and radiologist
eye-tracking signals and is equipped with a novel multi-term gaze-attention
loss combining MSE, KL divergence, correlation, and center-of-mass alignment.
Incorporating fixations improves F1 score from 0.597 to 0.631 (+5.70%) and AUC
from 0.821 to 0.849 (+3.41%), while also improving precision and recall,
highlighting the effectiveness of gaze-informed attention supervision. In the
second stage, we present a modular report generation pipeline that extracts
confidence-weighted diagnostic keywords, maps them to anatomical regions using
a curated dictionary constructed from domain-specific priors, and generates
region-aligned sentences via structured prompts. This pipeline improves report
quality as measured by clinical keyword recall and ROUGE overlap. Our results
demonstrate that integrating gaze data improves both classification performance
and the interpretability of generated medical reports.

</details>


### [149] [ID-Card Synthetic Generation: Toward a Simulated Bona fide Dataset](https://arxiv.org/abs/2508.13078)
*Qingwen Zeng,Juan E. Tapia,Izan Garcia,Juan M. Espin,Christoph Busch*

Main category: cs.CV

TL;DR: Stable Diffusion으로 신분증의 bona fide 이미지를 합성하여 PAD(프레젠테이션 공격 탐지) 성능과 일반화 능력을 향상시키는 접근. 합성 이미지는 PAD 시스템에서 bona fide로 인식되어 데이터 제약 완화 및 검출 성능 개선에 긍정적 영향을 보임.


<details>
  <summary>Details</summary>
Motivation: PAD용 학습 데이터 중 bona fide(정상) 이미지가 부족하고 공격 종류가 다양해 일반화가 어려움. 기존 연구는 주로 공격(attack) 샘플 생성에 집중하고 bona fide 데이터 부족 문제는 간과함.

Method: 원본 bona fide 신분증 이미지를 바탕으로 Stable Diffusion을 이용해 합성 bona fide 이미지를 생성하고, 이를 새로 학습한 PAD 모델과 상용 솔루션에 입력하여 성능 변화를 평가.

Result: 생성된 합성 이미지가 PAD 시스템에서 bona fide로 판별되어, 합성 데이터를 활용한 경우 검출 성능과 데이터 제약 해소에 긍정적 영향이 관찰됨.

Conclusion: Stable Diffusion 기반의 bona fide 합성은 PAD 데이터 확장에 유용한 전략으로 보이나, 더 많은 실험(다양한 데이터셋·공격 유형·정량적 지표)을 통한 추가 검증이 필요함.

Abstract: Nowadays, the development of a Presentation Attack Detection (PAD) system for
ID cards presents a challenge due to the lack of images available to train a
robust PAD system and the increase in diversity of possible attack instrument
species. Today, most algorithms focus on generating attack samples and do not
take into account the limited number of bona fide images. This work is one of
the first to propose a method for mimicking bona fide images by generating
synthetic versions of them using Stable Diffusion, which may help improve the
generalisation capabilities of the detector. Furthermore, the new images
generated are evaluated in a system trained from scratch and in a commercial
solution. The PAD system yields an interesting result, as it identifies our
images as bona fide, which has a positive impact on detection performance and
data restrictions.

</details>


### [150] [Checkmate: interpretable and explainable RSVQA is the endgame](https://arxiv.org/abs/2508.13086)
*Lucrezia Tosato,Christel Tartini Chappuis,Syrielle Montariol,Flora Weissgerber,Sylvain Lobry,Devis Tuia*

Main category: cs.CV

TL;DR: 새로운 RSVQA 데이터셋 Chessboard(3,123,253문항, 균형된 답 분포)를 제안하고, 각 답을 이미지의 하나 이상의 셀(cell)에 연결해 미세 수준의 시각적 근거를 제공함. 이를 바탕으로 의사결정 시 관련 셀을 식별하는 설명가능한 모델 Checkmate를 제시하여 해석가능성 향상과 신뢰성 개선을 보임.


<details>
  <summary>Details</summary>
Motivation: 기존 RSVQA 모델들은 해석가능성과 설명가능성이 부족하고 데이터 편향으로 인한 shortcut learning 문제가 존재함. 모델의 결정이 실제 시각적 근거에 기반했는지 보장하고 데이터 편향을 줄이려는 목적.

Method: 1) 대규모 균형형 RSVQA 데이터셋 Chessboard 생성(각 답을 하나 이상의 이미지 셀에 매핑). 2) 셀 기반의 미세 시각 추론을 허용하는 모델 아키텍처 Checkmate 설계 — 모델이 결정에 기여한 이미지 셀을 식별하도록 함. 3) 여러 모델 아키텍처에 걸친 광범위한 실험을 통해 투명성 및 설명성 개선을 평가.

Result: Chessboard와 Checkmate 조합이 모델의 투명성을 향상시키고 보다 신뢰할 수 있는 의사결정을 지원함을 실험적으로 보였음(다양한 아키텍처에서 확인).

Conclusion: 셀-연결형 데이터와 셀-기반 설명모델은 RSVQA에서 편향을 완화하고 시각적 근거를 제공하는 데 효과적. 향후 세부 성능 지표, 생성 방식, 인간 평가 등 추가 검증이 필요함.

Abstract: Remote Sensing Visual Question Answering (RSVQA) presents unique challenges
in ensuring that model decisions are both understandable and grounded in visual
content. Current models often suffer from a lack of interpretability and
explainability, as well as from biases in dataset distributions that lead to
shortcut learning. In this work, we tackle these issues by introducing a novel
RSVQA dataset, Chessboard, designed to minimize biases through 3'123'253
questions and a balanced answer distribution. Each answer is linked to one or
more cells within the image, enabling fine-grained visual reasoning.
  Building on this dataset, we develop an explainable and interpretable model
called Checkmate that identifies the image cells most relevant to its
decisions. Through extensive experiments across multiple model architectures,
we show that our approach improves transparency and supports more trustworthy
decision-making in RSVQA systems.

</details>


### [151] [DMS:Diffusion-Based Multi-Baseline Stereo Generation for Improving Self-Supervised Depth Estimation](https://arxiv.org/abs/2508.13091)
*Zihua Liu,Yizhou Li,Songyan Zhang,Masatoshi Okutomi*

Main category: cs.CV

TL;DR: DMS는 방향성 프롬프트로 에피폴라 방향의 신규 뷰를 생성하기 위해 Stable Diffusion을 파인튜닝하고, 합성된 좌-좌/우-우/중간 뷰를 이용해 자가-지도(photometric) 재구성을 보완하여 폐색(occlusion)과 프레임 바깥 영역 문제를 줄인다. 레이블 없는 스테레오 쌍만으로 작동하며, 플러그-앤-플레이 방식으로 기존 자가-지도 스테레오/단안 깊이 방법에 적용해 최대 35% outlier 감소와 SOTA 성능 향상을 보였다고 주장한다.


<details>
  <summary>Details</summary>
Motivation: 포토메트릭 재구성은 대상 뷰에서 대응하는 픽셀이 존재하지 않는 폐색이나 프레임 밖 영역 때문에 모호성이 생김. 이로 인해 자가-지도 스테레오/단안 깊이 학습의 신뢰도가 떨어지며, 명시적 픽셀 대응을 보강할 방법이 필요함.

Method: Stable Diffusion을 방향성 프롬프트로 파인튜닝하여 에피폴라 축을 따라 좌측/우측으로 이동한 ‘좌-좌’, ‘우-우’ 뷰와 좌우 사이의 중간(new) 뷰를 합성. 합성된 뷰의 픽셀로 폐색된 영역을 보완하여 포토메트릭 손실에서 명시적 대응을 생성. 모델-무관(plug-and-play) 방식으로 기존 자가-지도 학습 파이프라인에 통합되며, 학습·합성 모두 레이블 없는 스테레오 이미지 쌍만 사용.

Result: 다수 벤치마크에서 성능 향상 및 최대 35% outlier 감소 보고. 자가-지도 스테레오 매칭 및 단안 깊이 추정에서 SOTA 수준 성능 달성했다고 주장.

Conclusion: 지오메트릭 프라이어를 이용한 방향성 확산 합성이 자가-지도 포토메트릭 재구성의 빈 공간을 메우는 실용적·비용 효율적 방법이며, 기존 방법에 쉽게 통합되어 안정적으로 성능 개선을 가져온다.

Abstract: While supervised stereo matching and monocular depth estimation have advanced
significantly with learning-based algorithms, self-supervised methods using
stereo images as supervision signals have received relatively less focus and
require further investigation. A primary challenge arises from ambiguity
introduced during photometric reconstruction, particularly due to missing
corresponding pixels in ill-posed regions of the target view, such as
occlusions and out-of-frame areas. To address this and establish explicit
photometric correspondences, we propose DMS, a model-agnostic approach that
utilizes geometric priors from diffusion models to synthesize novel views along
the epipolar direction, guided by directional prompts. Specifically, we
finetune a Stable Diffusion model to simulate perspectives at key positions:
left-left view shifted from the left camera, right-right view shifted from the
right camera, along with an additional novel view between the left and right
cameras. These synthesized views supplement occluded pixels, enabling explicit
photometric reconstruction. Our proposed DMS is a cost-free, ''plug-and-play''
method that seamlessly enhances self-supervised stereo matching and monocular
depth estimation, and relies solely on unlabeled stereo image pairs for both
training and synthesizing. Extensive experiments demonstrate the effectiveness
of our approach, with up to 35% outlier reduction and state-of-the-art
performance across multiple benchmark datasets.

</details>


### [152] [Real-Time Beach Litter Detection and Counting: A Comparative Analysis of RT-DETR Model Variants](https://arxiv.org/abs/2508.13101)
*Miftahul Huda,Arsyiah Azahra,Putri Maulida Chairani,Dimas Rizky Ramadhani,Nabila Azhari,Ade Lailani*

Main category: cs.CV

TL;DR: RT-DETR-X는 mAP에서 약간 우수하지만 추론 속도가 느려 실시간 배치에서는 RT-DETR-L이 실용적이다.


<details>
  <summary>Details</summary>
Motivation: 해안 오염 모니터링의 자동화·확장성을 확보하기 위해, 최신 Transformer 기반 객체검출기(RT-DETR)의 해변 쓰레기 탐지·계수 성능과 실전 배치 적합성을 평가하고자 함.

Method: 공개된 해안 쓰레기 데이터셋으로 RT-DETR-Large와 RT-DETR-Extra-Large 두 변형을 훈련·비교. 평가 지표로 mAP@50, mAP@50-95 및 평균 추론 시간(밀리초)을 사용해 정확도와 실시간성 트레이드오프를 분석.

Result: RT-DETR-X: mAP@50=0.816, mAP@50-95=0.612, 추론시간=34.5 ms. RT-DETR-L: mAP@50=0.810, mAP@50-95=0.606, 추론시간=20.1 ms. 정확도 차이는 미미하지만 RT-DETR-L이 속도 면에서 큰 이득을 보임.

Conclusion: 운영상·현장 적용성을 고려하면 RT-DETR-L이 현실적 선택이다. 모델 복잡도 증가로 인한 정확도 향상은 제한적이며, 실시간 모니터링에서는 처리 속도와 자원 소모가 더 중요한 요소임.

Abstract: Coastal pollution is a pressing global environmental issue, necessitating
scalable and automated solutions for monitoring and management. This study
investigates the efficacy of the Real-Time Detection Transformer (RT-DETR), a
state-of-the-art, end-to-end object detection model, for the automated
detection and counting of beach litter. A rigorous comparative analysis is
conducted between two model variants, RT-DETR-Large (RT-DETR-L) and
RT-DETR-Extra-Large (RT-DETR-X), trained on a publicly available dataset of
coastal debris. The evaluation reveals that the RT-DETR-X model achieves
marginally superior accuracy, with a mean Average Precision at 50\% IoU
(mAP@50) of 0.816 and a mAP@50-95 of 0.612, compared to the RT-DETR-L model's
0.810 and 0.606, respectively. However, this minor performance gain is realized
at a significant computational cost; the RT-DETR-L model demonstrates a
substantially faster inference time of 20.1 ms versus 34.5 ms for the
RT-DETR-X. The findings suggest that the RT-DETR-L model offers a more
practical and efficient solution for real-time, in-field deployment due to its
superior balance of processing speed and detection accuracy. This research
provides valuable insights into the application of advanced Transformer-based
detectors for environmental conservation, highlighting the critical trade-offs
between model complexity and operational viability.

</details>


### [153] [Precise Action-to-Video Generation Through Visual Action Prompts](https://arxiv.org/abs/2508.13104)
*Yuang Wang,Chao Wen,Haoyu Guo,Sida Peng,Minghan Qin,Hujun Bao,Xiaowei Zhou,Ruizhen Hu*

Main category: cs.CV

TL;DR: Visual Action Prompts (VAP): 행동을 도메인 불문 시각적 스켈레톤으로 렌더링해 고차원 상호작용(action-to-video)에서 정밀한 제어와 도메인 간 동적 전이를 동시에 달성하는 방법. HOI와 로봇 조작 데이터에서 스켈레톤을 추출하고, 사전학습된 비디오 생성모델에 경량 파인튜닝으로 통합하여 인간·로봇 도메인 모두에서 효과를 보임.


<details>
  <summary>Details</summary>
Motivation: 기존의 행동 기반 비디오 생성은 '정밀성 vs. 일반성'의 트레이드오프에 직면: 텍스트/거친 마스크 등은 일반성은 높지만 정밀 제어가 부족하고, 에이전트 중심 신호는 정밀하지만 도메인 전이가 어렵다. 따라서 정밀하면서도 도메인에 무관한 표현이 필요하다.

Method: 행동을 도메인-중립적 시각적 프롬프트(스켈레톤)로 렌더링. HOI(인간-물체 상호작용)와 로봇 조작 데이터에서 견고한 파이프라인으로 스켈레톤을 구성하고, 이를 사전학습된 비디오 생성 모델에 경량 파인튜닝하여 정밀한 행동 제어와 도메인 간 동적 전이를 유지하도록 학습.

Result: EgoVid, RT-1, DROID 데이터셋에서 적용해 정밀한 행동 제어와 도메인 전이 성능 향상을 보였다고 보고. (정량·정성 실험에서 기존 텍스트/프리미티브/에이전트 기반 방법 대비 개선을 시사)

Conclusion: 시각적 행동 프롬프트(스켈레톤)는 고차원 상호작용의 정확한 제어와 도메인 불문 동적 학습을 동시에 달성할 수 있는 유효한 통합 표현이며, 인간-로봇 교차 도메인 학습에 실용적이다.

Abstract: We present visual action prompts, a unified action representation for
action-to-video generation of complex high-DoF interactions while maintaining
transferable visual dynamics across domains. Action-driven video generation
faces a precision-generality trade-off: existing methods using text, primitive
actions, or coarse masks offer generality but lack precision, while
agent-centric action signals provide precision at the cost of cross-domain
transferability. To balance action precision and dynamic transferability, we
propose to "render" actions into precise visual prompts as domain-agnostic
representations that preserve both geometric precision and cross-domain
adaptability for complex actions; specifically, we choose visual skeletons for
their generality and accessibility. We propose robust pipelines to construct
skeletons from two interaction-rich data sources - human-object interactions
(HOI) and dexterous robotic manipulation - enabling cross-domain training of
action-driven generative models. By integrating visual skeletons into
pretrained video generation models via lightweight fine-tuning, we enable
precise action control of complex interaction while preserving the learning of
cross-domain dynamics. Experiments on EgoVid, RT-1 and DROID demonstrate the
effectiveness of our proposed approach. Project page:
https://zju3dv.github.io/VAP/.

</details>


### [154] [Motion2Motion: Cross-topology Motion Transfer with Sparse Correspondence](https://arxiv.org/abs/2508.13139)
*Ling-Hao Chen,Yuhong Zhang,Zixin Yin,Zhiyang Dou,Xin Chen,Jingbo Wang,Taku Komura,Lei Zhang*

Main category: cs.CV

TL;DR: Motion2Motion은 훈련이 필요없는(fraining-free) 애니메이션 리타게팅 프레임워크로, 서로 다른 골격(topology)을 가진 캐릭터 간에 한두 개의 예시 모션과 희소한 뼈 대응정보만으로 모션을 안정적으로 이전한다.


<details>
  <summary>Details</summary>
Motivation: 골격 구조가 크게 다른 소스와 타겟 간에는 일대일 뼈 대응을 세우기 어렵고, 다양한 토폴로지를 포괄하는 대규모 페어 모션 데이터셋이 부족해 데이터 기반 학습법의 적용이 제한적이다.

Method: 학습과정 없이 동작하는 방식으로, 타겟 골격에서 한두 개의 예시 모션과 소수의 뼈 대응만을 입력으로 받아 모션을 변환한다(희소한 대응을 바탕으로 한 변형/매핑 절차 및 최적화 기반 보간/정렬을 사용한다고 기술).

Result: 유사 골격 간 전이와 종(크로스-스피시즈) 전이 모두에서 정성적·정량적 평가를 통해 효율적이고 신뢰성 있는 성능을 보였으며, 하위 응용 및 사용자 인터페이스에 통합해 실무적 활용 가능성을 입증했다.

Conclusion: 대규모 학습 데이터 없이도 실용적인 골격 간 모션 전이를 가능하게 해 산업적 응용 가능성이 높으며, 코드와 데이터가 공개되어 있다.

Abstract: This work studies the challenge of transfer animations between characters
whose skeletal topologies differ substantially. While many techniques have
advanced retargeting techniques in decades, transfer motions across diverse
topologies remains less-explored. The primary obstacle lies in the inherent
topological inconsistency between source and target skeletons, which restricts
the establishment of straightforward one-to-one bone correspondences. Besides,
the current lack of large-scale paired motion datasets spanning different
topological structures severely constrains the development of data-driven
approaches. To address these limitations, we introduce Motion2Motion, a novel,
training-free framework. Simply yet effectively, Motion2Motion works with only
one or a few example motions on the target skeleton, by accessing a sparse set
of bone correspondences between the source and target skeletons. Through
comprehensive qualitative and quantitative evaluations, we demonstrate that
Motion2Motion achieves efficient and reliable performance in both
similar-skeleton and cross-species skeleton transfer scenarios. The practical
utility of our approach is further evidenced by its successful integration in
downstream applications and user interfaces, highlighting its potential for
industrial applications. Code and data are available at
https://lhchen.top/Motion2Motion.

</details>


### [155] [IGFuse: Interactive 3D Gaussian Scene Reconstruction via Multi-Scans Fusion](https://arxiv.org/abs/2508.13153)
*Wenhao Hu,Zesheng Li,Haonan Zhou,Liu Liu,Xuexiang Wen,Zhizhong Su,Xi Li,Gaoang Wang*

Main category: cs.CV

TL;DR: IGFuse는 여러 번의 스캔에서 객체 재배치를 이용해 가려진 부분을 복원하고, 분할 인식 가우시안 필드를 구성해 스캔들을 융합함으로써 고충실도의 인터랙티브 3D 장면을 재구성한다. 복잡한 다단계 파이프라인이나 밀집 스캔 없이도 렌더링과 객체 수준 조작이 가능하다.


<details>
  <summary>Details</summary>
Motivation: 대상 장면의 지속적 객체 가림과 제한된 센서 커버리지 때문에 단일 멀티뷰 스캔만으로는 구조적 세부를 모두 캡처하기 어렵다. 기존 방법들은 분할·보완·인페인팅 같은 다단계 파이프라인이나 개별 객체의 밀집 스캔에 의존해 오류가 누적되고 확장성이 떨어진다.

Method: 스캔 간 자연스러운 객체 재배치를 이용해 관측을 결합하고, 분할 인식(segmentation-aware) 가우시안 필드를 구성한다. 스캔 간 양방향 광도(photometric)와 의미적(semantic) 일관성을 강제하고, 공간적 불일치를 처리하기 위해 의사-중간(pseudo-intermediate) 장면 상태를 도입해 정렬을 통일한다. 또한 협력적(co-pruning) 기하 정제 전략으로 형상을 다듬는다.

Result: 복잡한 전처리나 밀집 관측 없이 고충실도 렌더링과 객체 단위 장면 조작을 달성했다. 다양한 실험에서 새로운 장면 구성으로의 일반화 능력을 보였고, 실세계 3D 재구성과 real-to-sim 전이에서 유효함을 입증했다.

Conclusion: IGFuse는 객체 재배치를 활용한 관측 융합과 정렬·정제 기법으로 기존의 다단계·밀집 스캔 기반 접근을 대체할 수 있는 실용적이고 확장성 있는 3D 장면 재구성 프레임워크를 제시한다.

Abstract: Reconstructing complete and interactive 3D scenes remains a fundamental
challenge in computer vision and robotics, particularly due to persistent
object occlusions and limited sensor coverage. Multiview observations from a
single scene scan often fail to capture the full structural details. Existing
approaches typically rely on multi stage pipelines, such as segmentation,
background completion, and inpainting or require per-object dense scanning,
both of which are error-prone, and not easily scalable. We propose IGFuse, a
novel framework that reconstructs interactive Gaussian scene by fusing
observations from multiple scans, where natural object rearrangement between
captures reveal previously occluded regions. Our method constructs segmentation
aware Gaussian fields and enforces bi-directional photometric and semantic
consistency across scans. To handle spatial misalignments, we introduce a
pseudo-intermediate scene state for unified alignment, alongside collaborative
co-pruning strategies to refine geometry. IGFuse enables high fidelity
rendering and object level scene manipulation without dense observations or
complex pipelines. Extensive experiments validate the framework's strong
generalization to novel scene configurations, demonstrating its effectiveness
for real world 3D reconstruction and real-to-simulation transfer. Our project
page is available online.

</details>


### [156] [4DNeX: Feed-Forward 4D Generative Modeling Made Easy](https://arxiv.org/abs/2508.13154)
*Zhaoxi Chen,Tianqi Liu,Long Zhuo,Jiawei Ren,Zeng Tao,He Zhu,Fangzhou Hong,Liang Pan,Ziwei Liu*

Main category: cs.CV

TL;DR: 4DNeX는 단일 이미지에서 동적 3D(4D) 장면을 feed‑forward로 생성하는 최초의 프레임워크다. 대규모 4DNeX‑10M 데이터셋, RGB+XYZ를 통합한 6D 표현, 그리고 사전학습된 비디오 확산모델의 간단한 적응 기법을 통해 고품질 동적 포인트클라우드와 신규 시점 영상 합성을 효율적으로 달성한다.


<details>
  <summary>Details</summary>
Motivation: 기존 4D 생성 방법들은 계산 비용이 크고 최적화 기반이거나 다중 프레임 입력을 요구해 단일 이미지에서의 실용적·확장 가능한 4D 생성을 어렵게 한다. 이를 해결할 효율적이고 엔드‑투‑엔드인 이미지→4D 방법이 필요하다.

Method: (1) 4DNeX‑10M이라는 대규모 고품질 4D 주석 데이터셋 구축(재구성 기법 사용). (2) RGB와 XYZ 시퀀스를 함께 다루는 통일된 6D 비디오 표현 제안. (3) 사전학습된 비디오 확산모델을 4D 모델링에 맞게 미세조정하는 단순·효과적인 적응 전략을 적용하여 feed‑forward로 이미지에서 4D 생성 수행.

Result: 4DNeX는 동적 포인트클라우드를 생성해 신규 시점 비디오 합성을 지원하며, 효율성과 일반화 측면에서 기존 4D 생성법을 능가하는 실험적 결과를 보인다.

Conclusion: 4DNeX는 단일 이미지 기반 4D 모델링에 대한 확장 가능하고 실용적인 솔루션을 제시하며, 동적 장면 진화를 시뮬레이션하는 생성적 4D 월드 모델 연구의 기반을 마련한다.

Abstract: We present 4DNeX, the first feed-forward framework for generating 4D (i.e.,
dynamic 3D) scene representations from a single image. In contrast to existing
methods that rely on computationally intensive optimization or require
multi-frame video inputs, 4DNeX enables efficient, end-to-end image-to-4D
generation by fine-tuning a pretrained video diffusion model. Specifically, 1)
to alleviate the scarcity of 4D data, we construct 4DNeX-10M, a large-scale
dataset with high-quality 4D annotations generated using advanced
reconstruction approaches. 2) we introduce a unified 6D video representation
that jointly models RGB and XYZ sequences, facilitating structured learning of
both appearance and geometry. 3) we propose a set of simple yet effective
adaptation strategies to repurpose pretrained video diffusion models for 4D
modeling. 4DNeX produces high-quality dynamic point clouds that enable
novel-view video synthesis. Extensive experiments demonstrate that 4DNeX
outperforms existing 4D generation methods in efficiency and generalizability,
offering a scalable solution for image-to-4D modeling and laying the foundation
for generative 4D world models that simulate dynamic scene evolution.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [157] [Deep Language Geometry: Constructing a Metric Space from LLM Weights](https://arxiv.org/abs/2508.11676)
*Maksym Shamrai,Vladyslav Hamolia*

Main category: cs.CL

TL;DR: LLM 내부 가중치 중요도를 기반으로 언어 간 거리 공간을 구성하여 106개 언어에 대해 언어군을 잘 재현하고 예상치 못한 상호연결을 드러낸 새 프레임워크. 코드·벡터·시각화 공개.


<details>
  <summary>Details</summary>
Motivation: 수작업 언어 특성에 의존하지 않고, 대형 언어모델의 내부 표현에서 자동으로 언어별 고차원 벡터를 추출해 언어 간 기하학적 관계를 드러내려는 것.

Method: LLM의 가중치 활성화를 분석하고, 적응된 프루닝(가지치기) 알고리즘으로 가중치 중요도를 계산해 언어별 고차원 벡터(잠재 벡터)를 생성. 이 벡터들로 거리/유사도 공간을 구성하고 다양한 데이터셋과 다국어 LLM(106개 언어)에 대해 검증 및 시각화 수행.

Result: 생성된 언어 벡터들이 기존의 언어 계통군과 잘 일치하며, 일부는 역사적 접촉이나 언어 변화의 신호로 해석될 수 있는 비정상적 연관성을 보여줌. 방법은 모델·데이터셋 전반에서 일관된 결과를 보였음.

Conclusion: LLM의 내부 가중치는 언어의 본질적 특성을 반영하며, 데이터 기반의 언어 기하학(geometry)을 구성하는 실용적 도구가 될 수 있다. 연구 자료와 도구를 공개해 재현성과 확장성을 보장함.

Abstract: We introduce a novel framework that utilizes the internal weight activations
of modern Large Language Models (LLMs) to construct a metric space of
languages. Unlike traditional approaches based on hand-crafted linguistic
features, our method automatically derives high-dimensional vector
representations by computing weight importance scores via an adapted pruning
algorithm. Our approach captures intrinsic language characteristics that
reflect linguistic phenomena. We validate our approach across diverse datasets
and multilingual LLMs, covering 106 languages. The results align well with
established linguistic families while also revealing unexpected inter-language
connections that may indicate historical contact or language evolution. The
source code, computed language latent vectors, and visualization tool are made
publicly available at https://github.com/mshamrai/deep-language-geometry.

</details>


### [158] [Can we Evaluate RAGs with Synthetic Data?](https://arxiv.org/abs/2508.11758)
*Jonas van Elburg,Peter van der Putten,Maarten Marx*

Main category: cs.CL

TL;DR: LLM으로 생성한 합성 QA 데이터가 인간 라벨 데이터가 없을 때 RAG(검색연계생성) 구성의 평가 대용으로 유용한지 검토함. 리트리버 변형 평가에서는 합성 벤치마크가 인간 벤치마크와 잘 일치했으나, 생성기 아키텍처를 비교할 때는 일관된 순위를 제공하지 못함.


<details>
  <summary>Details</summary>
Motivation: 실제 인간 라벨이 없거나 비용상 확보 불가능한 상황에서, LLM이 만든 합성 QA 데이터로 시스템(특히 RAG)의 성능 비교·선별을 할 수 있는지 확인하려 함.

Method: 두 실험을 설계: (1) 생성기 고정, 리트리버 파라미터 변화; (2) 리트리버 고정, 생성기(아키텍처) 변화. 네 개 데이터셋(오픈도메인 2, 사유 2)에서 합성 벤치마크와 인간 라벨 벤치마크의 RAG 순위 일치도를 비교.

Result: 리트리버 구성 비교에서는 합성 벤치마크가 인간 벤치마크와 신뢰성 있게 순위를 맞췄으나, 생성기 아키텍처 비교에서는 일관된 순위를 재현하지 못함.

Conclusion: 생성기 간 비교 실패는 합성 데이터와 인간 벤치마크의 과제 불일치 및 특정 생성기 스타일 편향의 결합 때문일 가능성이 높음; 따라서 합성 벤치마크는 조건에 따라 유용하나 한계가 있음.

Abstract: We investigate whether synthetic question-answer (QA) data generated by large
language models (LLMs) can serve as an effective proxy for human-labeled
benchmarks when such data is unavailable. We assess the reliability of
synthetic benchmarks across two experiments: one varying retriever parameters
while keeping the generator fixed, and another varying the generator with fixed
retriever parameters. Across four datasets, of which two open-domain and two
proprietary, we find that synthetic benchmarks reliably rank the RAGs varying
in terms of retriever configuration, aligning well with human-labeled benchmark
baselines. However, they fail to produce consistent RAG rankings when comparing
generator architectures. The breakdown possibly arises from a combination of
task mismatch between the synthetic and human benchmarks, and stylistic bias
favoring certain generators.

</details>


### [159] [Limitation Learning: Catching Adverse Dialog with GAIL](https://arxiv.org/abs/2508.11767)
*Noah Kasmanoff,Rahul Zalkikar*

Main category: cs.CL

TL;DR: 모사학습을 대화에 적용해 전문가 시연으로부터 입력(prompt)→응답 정책과 전문가/합성 대화를 구분하는 판별기를 학습. 정책은 잘 작동하지만 판별기 결과는 대화 모델의 한계와 잠재적 부작용을 드러냄.


<details>
  <summary>Details</summary>
Motivation: 대화 작업은 명시적 보상이 없을 때 정책을 학습하기 어렵다. 전문가 시연을 이용해 보상 없이 대화 정책을 얻고, 동시에 모델의 바람직하지 않은 행동을 탐지할 방법이 필요함.

Method: 전문가 대화 시연으로 모사학습(이미테이션 러닝)을 수행해 prompt→응답 정책을 학습하고, 전문가 대화와 합성 대화를 구분하는 판별기를 함께 학습하여 판별기 출력으로 모델 행동을 분석.

Result: 학습된 정책은 사용자의 프롬프트에 대해 효과적인 응답을 생성함. 판별기는 전문가와 합성 대화를 구분하면서 합성(모델) 대화의 한계와 이상 행태를 식별함.

Conclusion: 이 접근법은 보상 없이 대화 정책을 얻는 실용적 방법일 뿐 아니라, 판별기를 통해 대화 모델의 유해·부적절·비자연적 행동을 탐지·분석하는 도구로서 활용 가능하다.

Abstract: Imitation learning is a proven method for creating a policy in the absence of
rewards, by leveraging expert demonstrations. In this work, we apply imitation
learning to conversation. In doing so, we recover a policy capable of talking
to a user given a prompt (input state), and a discriminator capable of
classifying between expert and synthetic conversation. While our policy is
effective, we recover results from our discriminator that indicate the
limitations of dialog models. We argue that this technique can be used to
identify adverse behavior of arbitrary data models common for dialog oriented
tasks.

</details>


### [160] [Investigating Transcription Normalization in the Faetar ASR Benchmark](https://arxiv.org/abs/2508.11771)
*Leo Peckham,Michael Ong,Naomi Nagy,Ewan Dunbar*

Main category: cs.CL

TL;DR: Faetar ASR 데이터셋의 전사 불일치가 존재하나 주요 난제는 아니며, 소규모 수작업 어휘를 쓰면 어휘 제한 디코딩이 유리하고, 단순한 bigram 단어 LM은 도움되지 않는다. 전체 과제는 여전히 매우 어렵다.


<details>
  <summary>Details</summary>
Motivation: 저자들은 저자원어(Faetar)에서 전사 불일치가 ASR 성능에 미치는 영향을 규명하고, 간단한 언어모형이나 어휘 제한이 성능에 도움이 되는지 평가하려 함.

Method: 소규모 수작업 어휘를 구축하고 이를 이용해 디코딩을 어휘로 제한하거나 단어 단위 bigram LM을 적용해 실험을 수행. 전사 일관성 여부를 분석.

Result: 전사 불일치는 존재하지만 주된 성능 저하 요인은 아니었음. bigram 단어 LM은 성능 향상에 기여하지 못했고, 어휘로 디코딩을 제한하는 것은 이득이 될 수 있었음. 전반적으로 과제 난이도는 매우 높음.

Conclusion: 전사 정합성 문제만으로는 Faetar ASR 난이도를 설명할 수 없으며, 단순한 n-gram LM보다 어휘 제약이나 다른 접근법이 더 유용할 수 있음. 추가 연구가 필요함.

Abstract: We examine the role of transcription inconsistencies in the Faetar Automatic
Speech Recognition benchmark, a challenging low-resource ASR benchmark. With
the help of a small, hand-constructed lexicon, we conclude that find that,
while inconsistencies do exist in the transcriptions, they are not the main
challenge in the task. We also demonstrate that bigram word-based language
modelling is of no added benefit, but that constraining decoding to a finite
lexicon can be beneficial. The task remains extremely difficult.

</details>


### [161] [A Multi-Task Evaluation of LLMs' Processing of Academic Text Input](https://arxiv.org/abs/2508.11779)
*Tianyi Li,Yu Qin,Olivia R. Liu Sheng*

Main category: cs.CL

TL;DR: LLM들이 학술 텍스트 처리에서 요약·바꾸기 능력은 쓸만하지만, 비교·채점·심층적 성찰에서는 신뢰도가 떨어져, 무분별한 동료심사 대체는 권장되지 않는다.


<details>
  <summary>Details</summary>
Motivation: LLM의 학술적 활용성, 특히 동료심사 보조로서의 현실적 가능성과 한계를 체계적으로 검증하려는 목적.

Method: 학술 텍스트 처리 작업을 재현/비교/채점/성찰의 4개 태스크로 분류하고, 각 태스크에 맞춘 역할(oracle/판별자/채점자/협업자)을 LLM에 부여해 표준 프롬프트와 다수의 텍스트 지표로 성능을 평가. 최상위 정보시스템 저널의 논문들을 입력으로 사용하고, 내부(언어적)·외부(정답과의 비교)·인간 평가로 검증.

Result: Google의 Gemini를 시험한 결과: 요약·패러프레이즈는 수용 가능, 문서간 쌍비교(rank)는 확장성 약함, 채점은 식별력 부족(등급 분화 어려움), 질적 성찰은 자기일관적이나 통찰력 부족. 결과는 다양한 지표와 프롬프트 변형에 대해 일관되게 관찰됨.

Conclusion: 현재의 LLM을 동료심사 자동화나 무검증 사용에 의존하는 것은 부적절. 인간-모델 협업, 더 엄격한 벤치마크와 보완적 방법이 필요하다.

Abstract: How much large language models (LLMs) can aid scientific discovery, notably
in assisting academic peer review, is in heated debate. Between a literature
digest and a human-comparable research assistant lies their practical
application potential. We organize individual tasks that computer science
studies employ in separate terms into a guided and robust workflow to evaluate
LLMs' processing of academic text input. We employ four tasks in the
assessment: content reproduction/comparison/scoring/reflection, each demanding
a specific role of the LLM (oracle/judgmental arbiter/knowledgeable
arbiter/collaborator) in assisting scholarly works, and altogether testing LLMs
with questions that increasingly require intellectual capabilities towards a
solid understanding of scientific texts to yield desirable solutions. We
exemplify a rigorous performance evaluation with detailed instructions on the
prompts. Adopting first-rate Information Systems articles at three top journals
as the input texts and an abundant set of text metrics, we record a compromised
performance of the leading LLM - Google's Gemini: its summary and paraphrase of
academic text is acceptably reliable; using it to rank texts through pairwise
text comparison is faintly scalable; asking it to grade academic texts is prone
to poor discrimination; its qualitative reflection on the text is
self-consistent yet hardly insightful to inspire meaningful research. This
evidence against an endorsement of LLMs' text-processing capabilities is
consistent across metric-based internal (linguistic assessment), external
(comparing to the ground truth), and human evaluation, and is robust to the
variations of the prompt. Overall, we do not recommend an unchecked use of LLMs
in constructing peer reviews.

</details>


### [162] [LLM-Guided Planning and Summary-Based Scientific Text Simplification: DS@GT at CLEF 2025 SimpleText](https://arxiv.org/abs/2508.11816)
*Krishna Chaitanya Marturi,Heba H. Elwazzan*

Main category: cs.CL

TL;DR: Two-stage LLM-based approach: (1) sentence-level: LLM generates structured plans, then simplifies sentences guided by plans; (2) document-level: LLM produces concise summaries to guide simplification. Aims for coherent, contextually faithful scientific text simplification.


<details>
  <summary>Details</summary>
Motivation: Scientific text is complex; single-shot simplification by LLMs may miss document context or produce incoherent changes. Using intermediate plans/summaries can preserve meaning, improve coherence, and control simplification at sentence and document scales.

Method: Sentence-level: prompt an LLM to output a structured plan (e.g., key points, target simplification operations) per sentence, then perform plan-driven rewriting. Document-level: generate concise summaries via LLM, then use summaries to guide simplification of passages or the whole document. Two-stage pipeline leverages LLMs both for planning and rewriting.

Result: Claims: improved coherence and contextual faithfulness of simplified scientific text compared to naive single-step LLM rewriting. No quantitative results provided in the abstract; evaluation likely performed in CLEF 2025 task.

Conclusion: A structured, two-stage LLM pipeline (planning + plan-guided simplification) is proposed for sentence- and document-level scientific text simplification, intended to produce more coherent and faithful outputs. Further empirical validation and ablations would clarify advantages and limitations.

Abstract: In this paper, we present our approach for the CLEF 2025 SimpleText Task 1,
which addresses both sentence-level and document-level scientific text
simplification. For sentence-level simplification, our methodology employs
large language models (LLMs) to first generate a structured plan, followed by
plan-driven simplification of individual sentences. At the document level, we
leverage LLMs to produce concise summaries and subsequently guide the
simplification process using these summaries. This two-stage, LLM-based
framework enables more coherent and contextually faithful simplifications of
scientific text.

</details>


### [163] [Every 28 Days the AI Dreams of Soft Skin and Burning Stars: Scaffolding AI Agents with Hormones and Emotions](https://arxiv.org/abs/2508.11829)
*Leigh Levinson,Christopher J. Agostino*

Main category: cs.CL

TL;DR: Paper hypothesizes embedding simulated hormonal cycles via system prompts into LLMs to act as contextual relevance filters, reporting subtle emotion/style and benchmark performance shifts aligned with biological phases.


<details>
  <summary>Details</summary>
Motivation: Address the frame problem by using biological rhythms (menstrual and circadian) as periodic, low-dimensional context signals to filter relevance from large information spaces.

Method: Generate system prompts from periodic functions modeling estrogen, testosterone, cortisol; apply these prompts to multiple LLMs; analyze linguistic sentiment/style and benchmark performance on SQuAD, MMLU, Hellaswag, AI2-ARC across simulated phases.

Result: Observed linguistic/emotional variations matching expected phases (e.g., sadness in menstruation, happiness in ovulation; morning optimism to night introspection) and modest but consistent performance fluctuations, with optimal performance at moderate hormone levels.

Conclusion: Suggests a novel contextualization approach using rhythmic signals and highlights embedded societal/gender biases in LLMs; proposes physiological cycles as a lens for contextual AI while raising ethical considerations.

Abstract: Despite significant advances, AI systems struggle with the frame problem:
determining what information is contextually relevant from an exponentially
large possibility space. We hypothesize that biological rhythms, particularly
hormonal cycles, serve as natural relevance filters that could address this
fundamental challenge. We develop a framework that embeds simulated menstrual
and circadian cycles into Large Language Models through system prompts
generated from periodic functions modeling key hormones including estrogen,
testosterone, and cortisol. Across multiple state-of-the-art models, linguistic
analysis reveals emotional and stylistic variations that track biological
phases; sadness peaks during menstruation while happiness dominates ovulation
and circadian patterns show morning optimism transitioning to nocturnal
introspection. Benchmarking on SQuAD, MMLU, Hellaswag, and AI2-ARC demonstrates
subtle but consistent performance variations aligning with biological
expectations, including optimal function in moderate rather than extreme
hormonal ranges. This methodology provides a novel approach to contextual AI
while revealing how societal biases regarding gender and biology are embedded
within language models.

</details>


### [164] [Hallucination Detection and Mitigation in Scientific Text Simplification using Ensemble Approaches: DS@GT at CLEF 2025 SimpleText](https://arxiv.org/abs/2508.11823)
*Krishna Chaitanya Marturi,Heba H. Elwazzan*

Main category: cs.CL

TL;DR: CLEF 2025 SimpleText Task 2 참가 시스템: BERT 기반 분류기, 의미 유사도, 자연어 추론, LLM 추론을 앙상블하고 메타 분류기로 결합. LLM 기반 사후 편집으로 원문에 근거한 단순화문 생성 보정.


<details>
  <summary>Details</summary>
Motivation: 과학 문서 단순화 과정에서 창의적 생성(허위 또는 비근거한 정보)과 정보 왜곡을 탐지하고, 단순화문을 원문에 근거해 수정함으로써 신뢰성 있는 단순화를 제작하려는 목적.

Method: BERT 계열 분류기, 의미 유사도 측정, NLI 모델, LLM 추론 신호를 다중 입력으로 사용. 이 신호들을 메타 분류기로 통합해 스푸리어스 및 왜곡 여부를 판별. 추가로 LLM 기반 사후 편집기로 단순화문을 원문에 맞게 수정.

Result: (초록에 결과 수치 없음) 다양한 신호 결합과 메타 분류기, LLM 사후 편집으로 강인한 탐지 및 근거 기반 단순화 개선을 목표로 함.

Conclusion: 멀티모달 모델 신호와 LLM 사후 편집을 결합하면 과학 텍스트 단순화의 왜곡 및 비근거 생성 문제를 줄이고 신뢰성 있는 단순화를 제공할 수 있음.

Abstract: In this paper, we describe our methodology for the CLEF 2025 SimpleText Task
2, which focuses on detecting and evaluating creative generation and
information distortion in scientific text simplification. Our solution
integrates multiple strategies: we construct an ensemble framework that
leverages BERT-based classifier, semantic similarity measure, natural language
inference model, and large language model (LLM) reasoning. These diverse
signals are combined using meta-classifiers to enhance the robustness of
spurious and distortion detection. Additionally, for grounded generation, we
employ an LLM-based post-editing system that revises simplifications based on
the original input texts.

</details>


### [165] [A Survey of Idiom Datasets for Psycholinguistic and Computational Research](https://arxiv.org/abs/2508.11828)
*Michael Flor,Xinyi Liu,Anna Feldman*

Main category: cs.CL

TL;DR: 관용구 연구를 위한 심리언어학·계산언어학 데이터셋 53종을 검토한 서베이로, 심리언어학 자료는 친숙도·투명성 등 규범화 평점을 제공하고, 계산언어학 자료는 관용성 판별·의역·다국어 모델링 등 과제를 지원함. 최근 언어·과제 다양성은 늘었지만 두 분야 간 연계는 부족함.


<details>
  <summary>Details</summary>
Motivation: 관용구는 단어의 합으로 의미를 추론하기 어려워 계산 처리가 어렵고 실험적 연구에도 도전적임. 이에 사용되는 데이터 자원들을 정리·비교해 연구 관행과 갭을 파악하고자 함.

Method: 심리언어학과 계산언어학에서 개발된 관용구 관련 데이터셋 53종을 수집·분류하여 내용(어휘·문맥), 형식(주석 유형), 용도(지원되는 과제)를 기준으로 분석하고 주석 관행·범위·과제 설정의 경향을 제시함.

Result: 심리언어학 자원은 친숙도(familiarity), 투명성(transparency), 합성성(compositionality) 등 규범화 평점을 제공하는 반면, 계산언어학 데이터셋은 관용성 판별, 의역(paraphrasing), 교차언어 모델링 등을 위한 형식이 많음. 최근 언어 커버리지와 과제 다양성은 증가했으나, 심리언어학적 규범화와 계산적 데이터·과제 사이에는 뚜렷한 연계가 없음.

Conclusion: 향후 연구는 심리언어학적 규범화 지표를 계산언어학 데이터와 통합하고 주석 표준화·문맥 기반 라벨링·다국어 정렬을 통해 두 분야를 잇는 노력이 필요함.

Abstract: Idioms are figurative expressions whose meanings often cannot be inferred
from their individual words, making them difficult to process computationally
and posing challenges for human experimental studies. This survey reviews
datasets developed in psycholinguistics and computational linguistics for
studying idioms, focusing on their content, form, and intended use.
Psycholinguistic resources typically contain normed ratings along dimensions
such as familiarity, transparency, and compositionality, while computational
datasets support tasks like idiomaticity detection/classification,
paraphrasing, and cross-lingual modeling. We present trends in annotation
practices, coverage, and task framing across 53 datasets. Although recent
efforts expanded language coverage and task diversity, there seems to be no
relation yet between psycholinguistic and computational research on idioms.

</details>


### [166] [When Does Language Transfer Help? Sequential Fine-Tuning for Cross-Lingual Euphemism Detection](https://arxiv.org/abs/2508.11831)
*Julia Sammartino,Libby Barak,Jing Peng,Anna Feldman*

Main category: cs.CL

TL;DR: 순차적 파인튜닝(sequential fine-tuning)은 고자원 언어(L1)로 먼저 학습한 뒤 저자원 언어(L2)에 전이하면 완곡어(euphemism) 탐지 성능을 향상시키며, 특히 요루바와 터키어 같은 저자원 언어에서 효과가 큽니다. XLM-R은 더 큰 성능 향상을 보이나 사전학습 커버리지 격차와 재망각(catastrophic forgetting)에 민감하고, mBERT는 보다 안정적이지만 성능 향상 폭은 작습니다.


<details>
  <summary>Details</summary>
Motivation: 완곡어 표현은 문화마다 다양하고 애매모호해 데이터가 부족한 언어에서는 모델 학습이 어려움. 저자원 언어에서의 완곡어 탐지 성능을 높이기 위해 크로스-링구얼 전이 기법(특히 순차적 파인튜닝)의 유효성을 평가하려는 목적.

Method: 5개 언어(영어, 스페인어, 중국어, 터키어, 요루바)를 대상으로 XLM-R과 mBERT를 사용해 세 가지 학습 전략(모노링구얼, 동시 파인튜닝, 순차적 파인튜닝)을 비교. 언어 쌍, 형태학·통사적 유사성·사전학습 커버리지 같은 요인이 성능에 미치는 영향을 분석.

Result: 순차적 파인튜닝은 고자원→저자원 전이에서 L2 성능을 개선함. 요루바·터키어처럼 저자원인 경우 효과가 두드러짐. XLM-R은 더 큰 이득을 보였으나 사전학습 데이터 격차와 재망각에 더 취약. mBERT는 상대적으로 안정적이지만 향상 폭은 작음.

Conclusion: 순차적 파인튜닝은 저자원 언어의 완곡어 탐지 성능을 비교적 간단하게 개선할 수 있는 실용적 전략이며, 모델 선택과 사전학습 커버리지 고려가 중요하다.

Abstract: Euphemisms are culturally variable and often ambiguous, posing challenges for
language models, especially in low-resource settings. This paper investigates
how cross-lingual transfer via sequential fine-tuning affects euphemism
detection across five languages: English, Spanish, Chinese, Turkish, and
Yoruba. We compare sequential fine-tuning with monolingual and simultaneous
fine-tuning using XLM-R and mBERT, analyzing how performance is shaped by
language pairings, typological features, and pretraining coverage. Results show
that sequential fine-tuning with a high-resource L1 improves L2 performance,
especially for low-resource languages like Yoruba and Turkish. XLM-R achieves
larger gains but is more sensitive to pretraining gaps and catastrophic
forgetting, while mBERT yields more stable, though lower, results. These
findings highlight sequential fine-tuning as a simple yet effective strategy
for improving euphemism detection in multilingual models, particularly when
low-resource languages are involved.

</details>


### [167] [SupraTok: Cross-Boundary Tokenization for Enhanced Language Model Performance](https://arxiv.org/abs/2508.11857)
*Andrei-Valentin Tănase,Elena Pelican*

Main category: cs.CL

TL;DR: SupraTok은 다중단어 '슈퍼워드'를 학습하고, 엔트로피 기반 데이터 선별과 다단계 커리큘럼 학습을 도입해 BPE를 확장한 토크나이저로, 영어에서 문자당 토큰 효율을 약 30% 개선하고 GPT-2(124M) 규모 모델에서 일부 벤치마크 성능을 소폭 향상시켰다고 주장한다.


<details>
  <summary>Details</summary>
Motivation: 기존 토크나이저들이 고정적이고 서브워드 중심인 반면, 더 큰 의미 단위를 포착하고 훈련 데이터 품질을 최적화하면 토큰 효율과 실사용 성능을 개선할 수 있다는 가정에서 출발한다.

Method: (1) 경계 횡단 패턴 학습으로 의미적으로 결속된 다중단어 '슈퍼워드'를 학습, (2) 엔트로피 기반 데이터 큐레이션으로 학습 코퍼스 품질을 최적화, (3) 다단계 커리큘럼 학습으로 안정적 수렴을 유도. BPE를 확장하여 더 큰 단위를 단어사전으로 추가한다.

Result: 영어에서 문자당 토큰 효율 5.91 vs 4.51(≈31% 개선) 등 토큰화 효율성 향상, 38개 언어에서 경쟁력 유지, GPT-2(124M)로 학습 시 HellaSWAG +8.4%, MMLU +9.5% 향상 보고. 대규모 모델 검증은 추후 필요.

Conclusion: 효율적 토크나이제이션이 아키텍처 혁신을 보완해 모델 성능을 높일 수 있음을 시사하나, 스케일·재현성·세부 구현에 대한 추가 검증이 필요하다.

Abstract: Tokenization remains a fundamental yet underexplored bottleneck in natural
language processing, with strategies largely static despite remarkable progress
in model architectures. We present SupraTok, a novel tokenization architecture
that reimagines subword segmentation through three innovations: cross-boundary
pattern learning that discovers multi-word semantic units, entropy-driven data
curation that optimizes training corpus quality, and multi-phase curriculum
learning for stable convergence. Our approach extends Byte-Pair Encoding by
learning "superword" tokens, coherent multi-word expressions that preserve
semantic unity while maximizing compression efficiency. SupraTok achieves 31%
improvement in English tokenization efficiency (5.91 versus 4.51 characters per
token) compared to OpenAI's o200k tokenizer and 30% improvement over Google's
Gemma 3 tokenizer (256k vocabulary), while maintaining competitive performance
across 38 languages. When integrated with a GPT-2 scale model (124M parameters)
trained on 10 billion tokens from the FineWeb-Edu dataset, SupraTok yields 8.4%
improvement on HellaSWAG and 9.5% on MMLU benchmarks without architectural
modifications. While these results are promising at this scale, further
validation at larger model scales is needed. These findings suggest that
efficient tokenization can complement architectural innovations as a path to
improved language model performance.

</details>


### [168] [In-Context Examples Matter: Improving Emotion Recognition in Conversation with Instruction Tuning](https://arxiv.org/abs/2508.11889)
*Hui Ma,Bo Zhang,Jinpeng Hu,Zenglin Shi*

Main category: cs.CL

TL;DR: InitERC는 화자 특성, 대화 맥락, 감정 상태를 하나의 단계에서 정렬하도록 설계된 in-context instruction tuning 기반의 ERC 프레임워크이다. 데모 풀 구성, 예시 선택, 프롬프트 설계, in-context 튜닝의 4개 구성요소를 갖추고 예시 검색·순서·개수의 영향을 실험하여 세 데이터셋에서 SOTA를 크게 상회한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 다단계 튜닝(먼저 화자 특성 부여 후 문맥 기반 튜닝)은 화자-문맥-감정 간의 동적 상호작용을 통합적으로 포착하지 못해 정렬이 약하다는 문제의식에서 출발한다.

Method: InitERC는 한 단계의 in-context instruction tuning으로 LLM에게 예시를 통해 화자-문맥-감정 정렬을 학습시킨다. 구체적으로 데모 풀 생성, 유사도 기반 등 예시 검색 전략, 예시 배치(순서) 설계, 프롬프트 템플릿 구성, 그리고 in-context 튜닝을 수행한다. 또한 검색 전략·예시 순서·예시 수 등 세 가지 요인을 체계적으로 연구한다.

Result: 세 가지 널리 쓰이는 데이터셋에서 광범위한 실험을 통해 제안 방법이 기존 최첨단 방법들보다 상당한 성능 향상을 달성했다고 보고한다.

Conclusion: 한 단계의 in-context instruction tuning으로 화자·문맥·감정의 정렬을 효과적으로 학습할 수 있으며, 적절한 예시 선택과 배치가 성능에 중요한 영향을 미친다.

Abstract: Emotion recognition in conversation (ERC) aims to identify the emotion of
each utterance in a conversation, playing a vital role in empathetic artificial
intelligence. With the growing of large language models (LLMs), instruction
tuning has emerged as a critical paradigm for ERC. Existing studies mainly
focus on multi-stage instruction tuning, which first endows LLMs with speaker
characteristics, and then conducts context-aware instruction tuning to
comprehend emotional states. However, these methods inherently constrains the
capacity to jointly capture the dynamic interaction between speaker
characteristics and conversational context, resulting in weak alignment among
speaker identity, contextual cues, and emotion states within a unified
framework. In this paper, we propose InitERC, a simple yet effective one-stage
in-context instruction tuning framework for ERC. InitERC adapts LLMs to learn
speaker-context-emotion alignment from context examples via in-context
instruction tuning. Specifically, InitERC comprises four components, i.e.,
demonstration pool construction, in-context example selection, prompt template
design, and in-context instruction tuning. To explore the impact of in-context
examples, we conduct a comprehensive study on three key factors: retrieval
strategy, example ordering, and the number of examples. Extensive experiments
on three widely used datasets demonstrate that our proposed InitERC achieves
substantial improvements over the state-of-the-art baselines.

</details>


### [169] [CORE: Measuring Multi-Agent LLM Interaction Quality under Game-Theoretic Pressures](https://arxiv.org/abs/2508.11915)
*Punya Syon Pandey,Yongjin Yang,Jiarui Liu,Zhijing Jin*

Main category: cs.CL

TL;DR: CORE은 다중 에이전트 LLM 대화에서 언어 사용의 효과성을 정량화하는 지표로, 클러스터 엔트로피·어휘 반복·의미 유사도를 결합해 경쟁·협력·중립 상황에서 언어 다양성을 측정하고 Zipf·Heaps 법칙으로 단어 빈도와 어휘 성장 특성을 분석한다.


<details>
  <summary>Details</summary>
Motivation: LLM 간 게임 이론적 상호작용에서 emergent 능력은 활발히 연구되었으나, 대화의 언어적 다양성과 강인성(robustness)을 계량화한 연구는 부족하므로 이를 보완하기 위함.

Method: CORE 지표를 제안해 클러스터 엔트로피, 어휘 반복률, 문장 수준 의미 유사도를 통합하고, 페어와이즈 LLM 대화를 경쟁·협력·중립 환경에서 수집해 CORE와 함께 Zipf·Heaps 법칙을 적용해 분석함.

Result: 협력적 대화는 더 가파른 Zipf 분포(높은 반복)와 높은 Heaps 지수(어휘 확장)를 보였고, 경쟁적 대화는 낮은 Zipf·Heaps 지수를 보이며 반복은 적고 어휘는 제약됨. CORE는 대화 품질과 언어 적응 차이를 구분함.

Conclusion: 사회적 인센티브가 언어 적응에 영향을 미치며, CORE는 다중 에이전트 LLM 시스템의 언어적 강인성을 진단하는 유용한 도구임.

Abstract: Game-theoretic interactions between agents with Large Language Models (LLMs)
have revealed many emergent capabilities, yet the linguistic diversity of these
interactions has not been sufficiently quantified. In this paper, we present
the Conversational Robustness Evaluation Score: CORE, a metric to quantify the
effectiveness of language use within multi-agent systems across different
game-theoretic interactions. CORE integrates measures of cluster entropy,
lexical repetition, and semantic similarity, providing a direct lens of dialog
quality. We apply CORE to pairwise LLM dialogs across competitive, cooperative,
and neutral settings, further grounding our analysis in Zipf's and Heaps' Laws
to characterize word frequency distributions and vocabulary growth. Our
findings show that cooperative settings exhibit both steeper Zipf distributions
and higher Heap exponents, indicating more repetition alongside greater
vocabulary expansion. In contrast, competitive interactions display lower Zipf
and Heaps exponents, reflecting less repetition and more constrained
vocabularies. These results provide new insights into how social incentives
influence language adaptation, and highlight CORE as a robust diagnostic for
measuring linguistic robustness in multi-agent LLM systems. Our code is
available at https://github.com/psyonp/core.

</details>


### [170] [LLMs Struggle with NLI for Perfect Aspect: A Cross-Linguistic Study in Chinese and Japanese](https://arxiv.org/abs/2508.11927)
*Jie Lu,Du Jin,Hitomi Yanaka*

Main category: cs.CL

TL;DR: 중국어·일본어의 완료상(perfect aspect)에서 시제 표지가 영어와 달라 NLI가 어려워지는 문제를 다루며, 이를 위해 문법적으로 설계된 템플릿 기반의 NLI 데이터셋(각 언어당 1,350 쌍)을 만들고 고급 LLM들을 평가한 결과 시제·참조시간의 미세한 변화 추론에서 모델들이 취약함을 보였다는 연구.


<details>
  <summary>Details</summary>
Motivation: 영어는 완료상에서 시제형태(예: had/has/will have)가 분명하지만 중국어와 일본어는 완료상 내에서 시제 형태가 분리되어 있지 않아 시간적 추론(특히 참조시간·시제 이동)에서 혼란이 발생한다. 따라서 기계추론 모델의 한계와 범용성 문제를 밝히기 위해 교차언어적 평가가 필요하다.

Method: 언어학적 근거에 기반한 템플릿을 설계해 중국어·일본어 각각 1,350개의 NLI 문장쌍(전제-가설)을 생성하고, 이를 사용해 여러 최신 LLM(논문에 구체적 모델명 명시 여부 미기재)을 평가하여 완료상 관련 시간추론 능력을 진단하였다.

Result: 평가 결과 LLM들은 특히 미묘한 시제 변이와 참조시간(예: 발화시점과 사건시점의 관계) 전환을 감지하는 데 유의미한 실패를 보였다. 이는 모델이 시간적 의미를 충분히 이해하지 못함을 시사한다.

Conclusion: 교차언어적 관점에서 시간 의미론을 평가할 필요가 있으며, 제시된 데이터셋은 이러한 평가와 후속 연구(모델 개선·세부 오류분석)에 유용한 자원임을 주장한다.

Abstract: Unlike English, which uses distinct forms (e.g., had, has, will have) to mark
the perfect aspect across tenses, Chinese and Japanese lack separate
grammatical forms for tense within the perfect aspect, which complicates
Natural Language Inference (NLI). Focusing on the perfect aspect in these
languages, we construct a linguistically motivated, template-based NLI dataset
(1,350 pairs per language). Experiments reveal that even advanced LLMs struggle
with temporal inference, particularly in detecting subtle tense and
reference-time shifts. These findings highlight model limitations and
underscore the need for cross-linguistic evaluation in temporal semantics. Our
dataset is available at https://github.com/Lujie2001/CrossNLI.

</details>


### [171] [CAMF: Collaborative Adversarial Multi-agent Framework for Machine Generated Text Detection](https://arxiv.org/abs/2508.11933)
*Yue Wang,Liesheng Wei,Yuxiang Wang*

Main category: cs.CL

TL;DR: CAMF는 다중 LLM 에이전트가 스타일·의미·논리 등 여러 언어적 차원을 추출하고, 적대적(검증적) 일관성 검사를 수행한 뒤 판단을 종합하여 제로샷 기계생성문장(MGT)을 탐지하는 프레임워크로, 기존 제로샷 기법들보다 우수하다고 주장한다.


<details>
  <summary>Details</summary>
Motivation: 기계생성 텍스트 감지의 중요성이 커졌으나 기존 제로샷 방법들은 피상적 특징에만 의존하거나 스타일·의미·논리 같은 다차원 일관성 검토가 부족해 실제 활용에서 한계가 존재한다는 문제의식에서 출발한다.

Method: 세 단계 협업적·적대적 프로세스를 제안: (1) 다차원 언어특성(스타일, 의미, 논리 등)을 추출하는 전문 에이전트들, (2) 에이전트들 간 상호검증·적대적 질의를 통한 일관성 검증(Adversarial Consistency Probing), (3) 여러 판단을 합성해 최종 탐지결정(Synthesized Judgment Aggregation).

Result: 저자들은 경험적 평가에서 CAMF가 기존 최첨단 제로샷 MGT 탐지 기법들보다 성능이 유의미하게 우수하다고 보고한다(구체적 수치·데이터셋·베이스라인은 초록에 없음).

Conclusion: 다중 에이전트 기반의 협업·적대적 검사로 텍스트의 교차차원 불일치를 포착해 제로샷 탐지 성능을 높였다는 점에서 유망하나, 재현성·계산비용·에이전트 구성·실제 데이터셋에 대한 일반화성 검증이 필요하다.

Abstract: Detecting machine-generated text (MGT) from contemporary Large Language
Models (LLMs) is increasingly crucial amid risks like disinformation and
threats to academic integrity. Existing zero-shot detection paradigms, despite
their practicality, often exhibit significant deficiencies. Key challenges
include: (1) superficial analyses focused on limited textual attributes, and
(2) a lack of investigation into consistency across linguistic dimensions such
as style, semantics, and logic. To address these challenges, we introduce the
\textbf{C}ollaborative \textbf{A}dversarial \textbf{M}ulti-agent
\textbf{F}ramework (\textbf{CAMF}), a novel architecture using multiple
LLM-based agents. CAMF employs specialized agents in a synergistic three-phase
process: \emph{Multi-dimensional Linguistic Feature Extraction},
\emph{Adversarial Consistency Probing}, and \emph{Synthesized Judgment
Aggregation}. This structured collaborative-adversarial process enables a deep
analysis of subtle, cross-dimensional textual incongruities indicative of
non-human origin. Empirical evaluations demonstrate CAMF's significant
superiority over state-of-the-art zero-shot MGT detection techniques.

</details>


### [172] [Learning Wisdom from Errors: Promoting LLM's Continual Relation Learning through Exploiting Error Cases](https://arxiv.org/abs/2508.12031)
*Shaozhe Yin,Jinyu Guo,Kai Shuang,Xia Liu,Ruize Ou*

Main category: cs.CL

TL;DR: 제안된 방법은 학습·메모리 데이터를 초기 응답의 정오 여부로 분리해 오류 케이스를 집중적으로 활용하고, LLM의 지시문 추종 능력을 이용한 지시 기반 대조적 튜닝으로 계속 학습 시 인지적 편향을 보정하여 CRE 성능을 크게 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 기존 CRE는 메모리 리플레이와 대조학습 위주로 망각을 줄이지만, 모델의 인지적 편향을 더 잘 드러내는 오류 사례에는 주목하지 않아 효과적 교정이 어렵다.

Method: 각 작업의 훈련·메모리 데이터를 초기 응답이 정답인지로 분리해 서로 다르게 처리하는 이중 과제(dual-task) 파인튜닝을 적용하고, 이전 데이터의 지침을 활용해 LLM을 지시-기반 대조적 튜닝으로 지속적으로 편향을 교정하도록 한다.

Result: TACRED와 FewRel에서 실험하여 기존 CRE 대비 유의미한 성능 향상으로 새로운 SOTA를 달성하였다.

Conclusion: 오류 사례를 전문적으로 활용하고 LLM의 지시문 기반 튜닝을 결합하면 CRE에서 망각 완화와 신규 관계 적응 모두에 효과적이며, 향후 메모리 효율성·지시 설계·잡음에 대한 민감도 분석이 필요하다.

Abstract: Continual Relation Extraction (CRE) aims to continually learn new emerging
relations while avoiding catastrophic forgetting. Existing CRE methods mainly
use memory replay and contrastive learning to mitigate catastrophic forgetting.
However, these methods do not attach importance to the error cases that can
reveal the model's cognitive biases more effectively. To address this issue, we
propose an instruction-based continual contrastive tuning approach for Large
Language Models (LLMs) in CRE. Different from existing CRE methods that
typically handle the training and memory data in a unified manner, this
approach splits the training and memory data of each task into two parts
respectively based on the correctness of the initial responses and treats them
differently through dual-task fine-tuning. In addition, leveraging the
advantages of LLM's instruction-following ability, we propose a novel
instruction-based contrastive tuning strategy for LLM to continuously correct
current cognitive biases with the guidance of previous data in an
instruction-tuning manner, which mitigates the gap between old and new
relations in a more suitable way for LLMs. We experimentally evaluate our model
on TACRED and FewRel, and the results show that our model achieves new
state-of-the-art CRE performance with significant improvements, demonstrating
the importance of specializing in exploiting error cases.

</details>


### [173] [A Question Answering Dataset for Temporal-Sensitive Retrieval-Augmented Generation](https://arxiv.org/abs/2508.12282)
*Ziyang Chen,Erxue Min,Xiang Zhao,Yunxin Li,Xin Jia,Jinzhi Liao,Jichao Li,Shuaiqiang Wang,Baotian Hu,Dawei Yin*

Main category: cs.CL

TL;DR: ChronoQA는 중국어 시시각적(시간적) 추론을 검사하기 위해 설계된 대규모 RAG 평가용 QA 데이터셋이다. 2019–2024년 뉴스 30만+건에서 구성된 5,176개 고품질 질문을 포함하며, 절대·집계·상대형 시간 유형과 명시·암시 시간표현을 모두 다루고 단일·다문서 시나리오를 지원한다. 다단계 검증(규칙·LLM·사람)을 거쳐 구조적 주석을 제공한다.


<details>
  <summary>Details</summary>
Motivation: RAG 시스템이 외부 지식을 검색해 답변할 때 시간 일치성(temporal alignment)과 논리적 일관성(특히 시점·기간 관련)을 제대로 다루는지를 평가할 표준화된 중국어 벤치가 부족하므로 이를 보완하기 위해 제안됨.

Method: 2019–2024년 뉴스 코퍼스에서 샘플링해 질문을 생성·선별하고, 질문은 절대·집계·상대형 및 명시·암시 시간표현을 포괄하도록 설계. 단일·다문서 설정을 모두 구성하고, 각 QA 쌍에 대해 구조적 메타주석을 부여. 품질 확보를 위해 규칙 기반 검증, LLM 기반 자동 검증, 최종 인간 검토의 다단계 검증 파이프라인을 적용.

Result: 최종 데이터셋: 5,176개 고품질 질문, 시간 유형별·표현 방식별 태그, 단일·다문서 케이스 포함, 2019–2024년 뉴스 기반으로 실제성 확보. 데이터 품질은 규칙·LLM·휴먼 검증으로 담보됨.

Conclusion: ChronoQA는 시간 민감한 RAG QA 연구를 위한 동적이고 신뢰할 수 있는 확장형 벤치마크를 제공하여 시간 추론·정렬·일관성 측면의 체계적 평가를 가능하게 함.

Abstract: We introduce ChronoQA, a large-scale benchmark dataset for Chinese question
answering, specifically designed to evaluate temporal reasoning in
Retrieval-Augmented Generation (RAG) systems. ChronoQA is constructed from over
300,000 news articles published between 2019 and 2024, and contains 5,176
high-quality questions covering absolute, aggregate, and relative temporal
types with both explicit and implicit time expressions. The dataset supports
both single- and multi-document scenarios, reflecting the real-world
requirements for temporal alignment and logical consistency. ChronoQA features
comprehensive structural annotations and has undergone multi-stage validation,
including rule-based, LLM-based, and human evaluation, to ensure data quality.
By providing a dynamic, reliable, and scalable resource, ChronoQA enables
structured evaluation across a wide range of temporal tasks, and serves as a
robust benchmark for advancing time-sensitive retrieval-augmented question
answering systems.

</details>


### [174] [Mind the Generation Process: Fine-Grained Confidence Estimation During LLM Generation](https://arxiv.org/abs/2508.12040)
*Jinyi Han,Tingyun Li,Shisong Chen,Jie Shi,Xinyi Wang,Guanglei Yue,Jiaqing Liang,Xin Lin,Liqian Wen,Zulong Chen,Yanghua Xiao*

Main category: cs.CL

TL;DR: 본 논문은 생성 과정 전반에 걸쳐 세밀한 신뢰도(continuous confidence)를 추정하는 FineCE를 제안한다. 학습 데이터 파이프라인으로 LLM 응답의 확률 분포를 포착하고, 임의의 텍스트 시퀀스에 대해 감독학습으로 신뢰도를 예측하는 모델을 훈련한다. 또한 이후 토큰 정보를 활용하는 Backward Confidence Integration(BCI)과 신뢰도 측정 위치 선정 전략 3가지를 제시하여 기존 방법보다 우수한 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어모델은 자기 인식(self-awareness)이 부족해 잘못된 예측에도 과도한 확신을 보이며, 기존 신뢰도 추정기법은 조악한(거친) 점수화 방식을 사용해 생성 과정 중 세밀하고 연속적인(continuous) 신뢰도 제공에 한계가 있다. 따라서 더 정확하고 생성 단계별로 연속적인 신뢰도 추정이 필요하다.

Method: (1) LLM 응답의 기반 확률 분포를 잘 반영하는 학습 데이터 생성 파이프라인을 설계한다. (2) 임의 텍스트 시퀀스에 대해 신뢰도를 예측하도록 모델을 감독학습으로 훈련한다. (3) 추후 생성된 텍스트 정보를 활용해 현재 시퀀스의 신뢰도를 보완하는 Backward Confidence Integration(BCI)을 제안한다. (4) 생성 과정에서 신뢰도 추정을 수행할 최적 위치를 찾는 세 가지 전략을 도입한다.

Result: 다양한 벤치마크에서 기존의 고전적 신뢰도 추정 방법을 일관되게 능가하는 성능을 보였으며, 코드와 비교군을 공개했다.

Conclusion: FineCE는 생성 과정 전체에 걸쳐 보다 정확하고 미세한 신뢰도 점수를 제공해 LLM 출력의 신뢰성·타당성을 향상시키며, BCI와 위치 선정 전략을 통해 실용적 추정 성능을 확보한다.

Abstract: While large language models (LLMs) have demonstrated remarkable performance
across diverse tasks, they fundamentally lack self-awareness and frequently
exhibit overconfidence, assigning high confidence scores to incorrect
predictions. Accurate confidence estimation is therefore critical for enhancing
the trustworthiness and reliability of LLM-generated outputs. However, existing
approaches suffer from coarse-grained scoring mechanisms that fail to provide
fine-grained, continuous confidence estimates throughout the generation
process. To address these limitations, we introduce FineCE, a novel confidence
estimation method that delivers accurate, fine-grained confidence scores during
text generation. Specifically, we first develop a comprehensive pipeline for
constructing training data that effectively captures the underlying
probabilistic distribution of LLM responses, and then train a model to predict
confidence scores for arbitrary text sequences in a supervised manner.
Furthermore, we propose a Backward Confidence Integration (BCI) strategy that
leverages information from the subsequent text to enhance confidence estimation
for the current sequence during inference. We also introduce three strategies
for identifying optimal positions to perform confidence estimation within the
generation process. Extensive experiments on multiple benchmark datasets
demonstrate that FineCE consistently outperforms existing classical confidence
estimation methods. Our code and all baselines used in the paper are available
on GitHub.

</details>


### [175] [All for law and law for all: Adaptive RAG Pipeline for Legal Research](https://arxiv.org/abs/2508.13107)
*Figarri Keisha,Prince Singh,Pallavi,Dion Fernandes,Aravindh Manivannan,Ilham Wicaksono,Faisal Ahmad*

Main category: cs.CL

TL;DR: 법률 도메인에서 RAG의 환각 문제를 줄이기 위해 문맥 인식 질의 변환기, SBERT·GTE 기반 오픈소스 검색 전략, 그리고 RAGAS·BERTScore-F1·ROUGE-Recall을 결합한 평가 프레임워크를 제안한다. 오픈소스 파이프라인이 검색 품질에서 상용 접근과 경쟁하며, 법률 특화 프롬프트가 더 충실한 응답을 생성함을 보인다.


<details>
  <summary>Details</summary>
Motivation: 법률 분야에서는 모델의 근거 표기가 필수적이므로 LLM의 환각을 줄이고 출처로 응답을 근거화하는 RAG의 성능을 높여 법률 연구 보조에 실용적인 시스템을 만들고자 한다.

Method: (i) 문서 참조와 자연어 질문을 분리하고 전문성·구체성에 따라 검색 깊이와 응답 스타일을 조정하는 문맥 인식 질의 변환기, (ii) SBERT 및 GTE 임베딩을 활용한 비용 효율적 오픈소스 검색 전략으로 Recall@K 및 Precision@K 개선, (iii) RAGAS, BERTScore-F1, ROUGE-Recall을 결합한 종합적 평가·생성 프레임워크로 의미적 정렬성과 충실성 평가.

Result: 오픈소스 검색이 Recall@K을 30–95% 향상시키고 K>4에서 Precision@K를 약 2.5배 개선하는 등 검색 성능에서 큰 향상을 보였고, 법률 특화 프롬프트는 기본 프롬프트 대비 더 충실하고 문맥 적합한 답변을 생성했다.

Conclusion: 구성 요소별·작업 인지적 튜닝을 통해 재현 가능하고 비용 효율적인 법률 RAG 시스템을 구축할 수 있으며, 잘 설계된 오픈소스 파이프라인이 상용 대안과 대등하거나 우수할 수 있음을 시사한다.

Abstract: Retrieval-Augmented Generation (RAG) mitigates hallucinations by grounding
large language model outputs in cited sources, a capability that is especially
critical in the legal domain. We present an end-to-end RAG pipeline that
revisits and extends the LegalBenchRAG baseline with three targeted
enhancements: (i) a context-aware query translator that disentangles document
references from natural-language questions and adapts retrieval depth and
response style based on expertise and specificity, (ii) open-source retrieval
strategies using SBERT and GTE embeddings that achieve substantial performance
gains (improving Recall@K by 30-95\% and Precision@K by $\sim$2.5$\times$ for
$K>4$) while remaining cost-efficient, and (iii) a comprehensive evaluation and
generation framework that combines RAGAS, BERTScore-F1, and ROUGE-Recall to
assess semantic alignment and faithfulness across models and prompt designs.
Our results show that carefully designed open-source pipelines can rival or
outperform proprietary approaches in retrieval quality, while a custom
legal-grounded prompt consistently produces more faithful and contextually
relevant answers than baseline prompting. Taken together, these contributions
demonstrate the potential of task-aware, component-level tuning to deliver
legally grounded, reproducible, and cost-effective RAG systems for legal
research assistance.

</details>


### [176] [J6: Jacobian-Driven Role Attribution for Multi-Objective Prompt Optimization in LLMs](https://arxiv.org/abs/2508.12086)
*Yao Wu*

Main category: cs.CL

TL;DR: J6는 LLM 적응에서 목적들 간의 그라디언트 상호작용(자코비안)을 6가지 해석 가능한 성분으로 분해해, argmax 기반의 강한 결정과 softmax 기반의 가중치 결합을 혼합하여 충돌-친화성에 따라 동적으로 프롬프트 파라미터를 업데이트하는 구조화된 방법이다.


<details>
  <summary>Details</summary>
Motivation: 스칼라 그라디언트 합산은 목적들 및 프롬프트 파라미터(예: hidden-layer 삽입 h, 임베딩 변경 w) 사이의 기하학적 상호작용을 무시하므로, 충돌 감지와 해석 가능한 업데이트 규칙이 필요하다.

Method: 그라디언트 상호작용 행렬을 6개 구성요소(J6)로 분해하고, 각 성분을 이용해 hard(지배 방향 선택) 또는 soft(attention-style 가중치) 업데이트를 결정하는 동적 프레임워크를 제시한다. 이 구조는 파라미터 귀속과 작업 간섭 분석을 가능하게 한다.

Result: J6는 충돌 상황에서 적절한 업데이트 방향을 선택해 다목적 튜닝의 해석성 및 성능을 개선할 수 있으며, 파라미터·작업 간섭·기하학 정렬에 대한 인사이트를 제공한다.

Conclusion: 구조화된 자코비안 분해는 다목적 LLM 튜닝을 위한 충돌 인식·해석 가능한 메커니즘을 제공하며, 향후 확장성과 자코비안 기반 추론을 통한 최적화 연구에 새로운 길을 연다.

Abstract: In large language model (LLM) adaptation, balancing multiple optimization
objectives such as improving factuality (heat) and increasing confidence (via
low entropy) poses a fundamental challenge, especially when prompt parameters
(e.g., hidden-layer insertions h and embedding modifications w) interact in
non-trivial ways. Existing multi-objective optimization strategies often rely
on scalar gradient aggregation, ignoring the deeper geometric structure between
objectives and parameters. We propose J6, a structured Jacobian-based method
that decomposes the gradient interaction matrix into six interpretable
components. This decomposition enables both hard decision-making (e.g.,
choosing the dominant update direction via argmax) and soft strategies (e.g.,
attention-style weighting via softmax over J6), forming a dynamic update
framework that adapts to local conflict and synergy. Moreover, the
interpretable structure of J6 provides insight into parameter attribution, task
interference, and geometry-aligned adaptation. Our work introduces a principled
and extensible mechanism for conflict-aware prompt optimization, and opens a
new avenue for incorporating structured Jacobian reasoning into multi-objective
neural tuning.

</details>


### [177] [STEM: Efficient Relative Capability Evaluation of LLMs through Structured Transition Samples](https://arxiv.org/abs/2508.12096)
*Haiquan Hu,Jiazhi Jiang,Shiyou Xu,Ruhan Zeng,Tian Wang*

Main category: cs.CL

TL;DR: Proposes STEM (Structured Transition Evaluation Method) to efficiently estimate relative capabilities of LLMs by selecting Significant Transition Samples (STS) from performance transitions across same-architecture, different-scale models; validates using Qwen3 family on six benchmarks and reports alignment with ground-truth rankings.


<details>
  <summary>Details</summary>
Motivation: Existing benchmark improvements don't reliably reflect real-world reasoning; overfitting to public benchmarks and the high cost of full evaluations make fine-grained, scalable comparison of LLMs difficult.

Method: Identify STS by analyzing consistent performance transitions among same-architecture models of varying parameter scales; build STS pool (using Qwen3 family) across six benchmarks; use STS to estimate capability position of unknown models efficiently and architecture-agnostically.

Result: STEM captures performance trends reliably and aligns with ground-truth model rankings in experiments, suggesting it's a practical, scalable method for fine-grained LLM evaluation.

Conclusion: STEM offers an interpretable, lightweight, and scalable alternative to full evaluations by leveraging transition-consistent samples; further validation across more architectures and diverse model families would strengthen generalizability.

Abstract: Evaluating large language models (LLMs) has become increasingly challenging
as model capabilities advance rapidly. While recent models often achieve higher
scores on standard benchmarks, these improvements do not consistently reflect
enhanced real-world reasoning capabilities. Moreover, widespread overfitting to
public benchmarks and the high computational cost of full evaluations have made
it both expensive and less effective to distinguish meaningful differences
between models. To address these challenges, we propose the \textbf{S}tructured
\textbf{T}ransition \textbf{E}valuation \textbf{M}ethod (STEM), a lightweight
and interpretable evaluation framework for efficiently estimating the relative
capabilities of LLMs. STEM identifies \textit{significant transition samples}
(STS) by analyzing consistent performance transitions among LLMs of the same
architecture but varying parameter scales. These samples enable STEM to
effectively estimate the capability position of an unknown model. Qwen3 model
family is applied to construct the STS pool on six diverse and representative
benchmarks. To assess generalizability. Experimental results indicate that STEM
reliably captures performance trends, aligns with ground-truth rankings of
model capability. These findings highlight STEM as a practical and scalable
method for fine-grained, architecture-agnostic evaluation of LLMs.

</details>


### [178] [Exploring Efficiency Frontiers of Thinking Budget in Medical Reasoning: Scaling Laws between Computational Resources and Reasoning Quality](https://arxiv.org/abs/2508.12140)
*Ziqian Bi,Lu Chen,Junhao Song,Hongying Luo,Enze Ge,Junmin Huang,Tianyang Wang,Keyu Chen,Chia Xin Liang,Zihan Wei,Huafeng Liu,Chunjie Tian,Jibin Guan,Joe Yeong,Yongzhi Xu,Peng Wang,Junfeng Hao*

Main category: cs.CL

TL;DR: 본 논문은 의료 추론(task)에서 "thinking budget"(추론 토큰 예산)의 효용을 체계적으로 평가하여 계산 자원과 추론 성능 간의 로그 스케일 법칙을 규명한다. Qwen3 및 DeepSeek-R1 계열 모델들을 15개 의료 데이터셋에서 테스트하고, 토큰 예산을 0부터 무제한까지 조절해 효과를 분석하였다.


<details>
  <summary>Details</summary>
Motivation: 의료 환경에서 추론 성능을 향상시키되 실시간성·비용 제약을 고려한 자원 할당 전략(=thinking budget) 필요성. 모델 크기와 계산 예산 간의 상호작용을 정량화해 임상 적용 시 최적의 비용-성능 균형을 찾고자 함.

Method: Qwen3(1.7B–235B)와 DeepSeek-R1(1.5B–70B) 두 모델군을 사용해 15개 전문 영역·난이도의 의료 데이터셋에서 통제된 실험 수행. thinking budget(토큰 수)을 0→무제한 범위로 변화시키고 정확도 변화를 측정. DeepSeek-R1에는 트렁케이션(truncation) 방식으로 예산을 모사해 Qwen3 네이티브 API와 비교.

Result: 정확도는 모델 크기와 토큰 예산에 대해 로그적(=예측 가능한) 스케일링을 보임. 0–256토큰(고효율), 256–512토큰(균형), >512토큰(고정밀)의 세 가지 효율 구간 제시. 작은 모델은 추가 토큰에서 상대적 이득(15–20%)이 크고, 대형 모델은 5–10% 수준의 이득. 신경과·위장과 같은 분야는 심폐·호흡기보다 더 깊은 추론 필요. Qwen3 네이티브와 DeepSeek 트렁케이션 간 일관성으로 개념의 아키텍처 일반화 가능성 제시.

Conclusion: thinking budget 제어는 의료 AI의 동적 자원 배분 및 임상 필요에 따른 투명한 운영을 위해 중요하며, 모델 크기·도메인에 따라 예산을 달리 적용하는 정책이 실용적임.

Abstract: This study presents the first comprehensive evaluation of thinking budget
mechanisms in medical reasoning tasks, revealing fundamental scaling laws
between computational resources and reasoning quality. We systematically
evaluated two major model families, Qwen3 (1.7B to 235B parameters) and
DeepSeek-R1 (1.5B to 70B parameters), across 15 medical datasets spanning
diverse specialties and difficulty levels. Through controlled experiments with
thinking budgets ranging from zero to unlimited tokens, we establish
logarithmic scaling relationships where accuracy improvements follow a
predictable pattern with both thinking budget and model size. Our findings
identify three distinct efficiency regimes: high-efficiency (0 to 256 tokens)
suitable for real-time applications, balanced (256 to 512 tokens) offering
optimal cost-performance tradeoffs for routine clinical support, and
high-accuracy (above 512 tokens) justified only for critical diagnostic tasks.
Notably, smaller models demonstrate disproportionately larger benefits from
extended thinking, with 15 to 20% improvements compared to 5 to 10% for larger
models, suggesting a complementary relationship where thinking budget provides
greater relative benefits for capacity-constrained models. Domain-specific
patterns emerge clearly, with neurology and gastroenterology requiring
significantly deeper reasoning processes than cardiovascular or respiratory
medicine. The consistency between Qwen3 native thinking budget API and our
proposed truncation method for DeepSeek-R1 validates the generalizability of
thinking budget concepts across architectures. These results establish thinking
budget control as a critical mechanism for optimizing medical AI systems,
enabling dynamic resource allocation aligned with clinical needs while
maintaining the transparency essential for healthcare deployment.

</details>


### [179] [LLM-as-a-Judge for Privacy Evaluation? Exploring the Alignment of Human and LLM Perceptions of Privacy in Textual Data](https://arxiv.org/abs/2508.12158)
*Stephen Meisenbacher,Alexandra Klymenko,Florian Matthes*

Main category: cs.CL

TL;DR: 저자들은 ‘LLM-as-a-Judge’ 패러다임을 개인정보 민감도 평가에 적용해, 10개 데이터셋·13개 LLM·677명 인간 참여자 비교 실험을 수행했다. 인간 간 합의도가 낮았음에도 불구하고 LLM들은 전반적(글로벌) 인간 관점과 잘 일치하는 경향을 보였고, 인간·LLM 추론 패턴 분석을 통해 장단점을 논의했다.


<details>
  <summary>Details</summary>
Motivation: 텍스트 기반 개인정보 민감도는 정의가 모호하고 주관적이라 정확한 평가가 어렵다. 기존의 개인정보 보호 NLP 발전에도 불구하고 평가 방법론(측정 도구)이 부족하므로, 다른 NLP 평가 과제에서 성공을 거둔 LLM을 ‘심판자’로 활용하는 가능성을 탐색하고자 함.

Method: 10개 데이터셋에서 677명의 사람 평가자와 13개의 LLM을 사용해 각 텍스트의 개인정보 민감도 평가를 수집하고 비교함. 인간-인간 합의(inter-human agreement), LLM-인간 일치도, 그리고 인간 및 LLM의 추론(설명) 패턴을 정성·정량적으로 분석함.

Result: 인간 평가자들 간 합의도는 전반적으로 낮아 개인정보 민감도 자체가 측정하기 어려운 개념임을 확인함. 그럼에도 불구하고 다수의 LLM은 글로벌(다수 인간의 평균적 관점) 판단을 잘 모델링했고, 사례별로는 LLM과 인간이 다른 이유(추론 차이)가 존재함을 보였음.

Conclusion: LLM-as-a-Judge는 개인정보 민감도 평가의 유망한 도구이나, 주관성·합의도 저하, 상황별 오판 가능성 등 한계가 있어 단독 평가자보다는 보조 도구 또는 인간-검증 결합 형태로 활용하는 것이 바람직하다.

Abstract: Despite advances in the field of privacy-preserving Natural Language
Processing (NLP), a significant challenge remains the accurate evaluation of
privacy. As a potential solution, using LLMs as a privacy evaluator presents a
promising approach $\unicode{x2013}$ a strategy inspired by its success in
other subfields of NLP. In particular, the so-called $\textit{LLM-as-a-Judge}$
paradigm has achieved impressive results on a variety of natural language
evaluation tasks, demonstrating high agreement rates with human annotators.
Recognizing that privacy is both subjective and difficult to define, we
investigate whether LLM-as-a-Judge can also be leveraged to evaluate the
privacy sensitivity of textual data. Furthermore, we measure how closely LLM
evaluations align with human perceptions of privacy in text. Resulting from a
study involving 10 datasets, 13 LLMs, and 677 human survey participants, we
confirm that privacy is indeed a difficult concept to measure empirically,
exhibited by generally low inter-human agreement rates. Nevertheless, we find
that LLMs can accurately model a global human privacy perspective, and through
an analysis of human and LLM reasoning patterns, we discuss the merits and
limitations of LLM-as-a-Judge for privacy evaluation in textual data. Our
findings pave the way for exploring the feasibility of LLMs as privacy
evaluators, addressing a core challenge in solving pressing privacy issues with
innovative technical solutions.

</details>


### [180] [Arabic Multimodal Machine Learning: Datasets, Applications, Approaches, and Challenges](https://arxiv.org/abs/2508.12227)
*Abdelhamid Haouhat,Slimane Bellaouar,Attia Nehar,Hadda Cherroun,Ahmed Abdelali*

Main category: cs.CL

TL;DR: Survey of Arabic Multimodal Machine Learning proposing a taxonomy that organizes prior work into datasets, applications, approaches, and challenges; identifies gaps and suggests directions for future research.


<details>
  <summary>Details</summary>
Motivation: Arabic MML has reached foundational maturity and needs a comprehensive, structured survey to consolidate progress and reveal gaps.

Method: Construct a novel taxonomy with four categories (datasets, applications, approaches, challenges), collect and analyze existing Arabic multimodal literature, and map resources and research trends to that taxonomy.

Result: Provides a structured overview of datasets, highlighted application areas, common methodological approaches, and major challenges; identifies under-investigated topics and critical research gaps (e.g., lack of large-scale annotated datasets, dialect coverage, standardized benchmarks, scarce pretrained multimodal models for Arabic).

Conclusion: The survey synthesizes the current state and offers a roadmap for researchers to build resources, improve evaluation, and address methodological and ethical challenges in Arabic MML.

Abstract: Multimodal Machine Learning (MML) aims to integrate and analyze information
from diverse modalities, such as text, audio, and visuals, enabling machines to
address complex tasks like sentiment analysis, emotion recognition, and
multimedia retrieval. Recently, Arabic MML has reached a certain level of
maturity in its foundational development, making it time to conduct a
comprehensive survey. This paper explores Arabic MML by categorizing efforts
through a novel taxonomy and analyzing existing research. Our taxonomy
organizes these efforts into four key topics: datasets, applications,
approaches, and challenges. By providing a structured overview, this survey
offers insights into the current state of Arabic MML, highlighting areas that
have not been investigated and critical research gaps. Researchers will be
empowered to build upon the identified opportunities and address challenges to
advance the field.

</details>


### [181] [SEA-BED: Southeast Asia Embedding Benchmark](https://arxiv.org/abs/2508.12243)
*Wuttikorn Ponwitayarat,Raymond Ng,Jann Railey Montalan,Thura Aung,Jian Gang Ngui,Yosephine Susanto,William Tjhi,Panuthep Tasawong,Erik Cambria,Ekapol Chuangsuwanich,Sarana Nutanong,Peerat Limkonchotiwat*

Main category: cs.CL

TL;DR: SEA-BED는 동남아 10개 언어·9개 과제에 걸친 최초의 대규모 문장 임베딩 벤치마크(169개 데이터셋)로, 71%가 인간 작성이다. 17개 임베딩 모델을 평가하여 모델 순위의 급격한 변화, 언어별 성능 불일치, 저자원 언어(예: 버마어)에 대한 인간 큐레이션의 중요성을 확인했다.


<details>
  <summary>Details</summary>
Motivation: 기존 다국어 벤치마크는 범위는 넓지만 동남아 언어에 대한 데이터셋이 부족하거나 기계 번역에 의존해 고유한 언어적 특성을 반영하지 못한다. 인구가 거의 7억인 SEA 지역을 위한 특화된 임베딩 벤치마크가 필요하다.

Method: SEA-BED를 구성(169개 데이터셋, 9개 과제, 10개 언어; 71% 인간 작성). 17개 임베딩 모델을 선정해 6가지 연구(과제·언어 난이도 분석, 크로스 벤치마크 비교, 인간 대 기계 번역 영향 평가 등)를 수행하고 성능·순위 변동을 분석.

Result: 모델 간 순위가 급격히 변동하고, SEA 내 언어들에서 일관되지 않은 성능 패턴이 관찰됨. 특히 버마어 같은 저자원 언어는 인간 큐레이션 데이터가 있으면 평가 결과가 크게 달라짐. 기계 번역 기반 데이터는 평가 편향을 유발할 수 있음.

Conclusion: 동남아 특화 벤치마크와 인간 큐레이션 데이터는 임베딩 모델의 올바른 평가에 필수적이다. 연구는 모델 선택과 벤치마크 설계에서 언어별·데이터 출처별 고려가 필요함을 제시한다.

Abstract: Sentence embeddings are essential for NLP tasks such as semantic search,
re-ranking, and textual similarity. Although multilingual benchmarks like MMTEB
broaden coverage, Southeast Asia (SEA) datasets are scarce and often
machine-translated, missing native linguistic properties. With nearly 700
million speakers, the SEA region lacks a region-specific embedding benchmark.
We introduce SEA-BED, the first large-scale SEA embedding benchmark with 169
datasets across 9 tasks and 10 languages, where 71% are formulated by humans,
not machine generation or translation. We address three research questions: (1)
which SEA languages and tasks are challenging, (2) whether SEA languages show
unique performance gaps globally, and (3) how human vs. machine translations
affect evaluation. We evaluate 17 embedding models across six studies,
analyzing task and language challenges, cross-benchmark comparisons, and
translation trade-offs. Results show sharp ranking shifts, inconsistent model
performance among SEA languages, and the importance of human-curated datasets
for low-resource languages like Burmese.

</details>


### [182] [What do Speech Foundation Models Learn? Analysis and Applications](https://arxiv.org/abs/2508.12255)
*Ankita Pasad*

Main category: cs.CL

TL;DR: 본 논문은 통계 도구와 학습 없는 프로브를 이용해 음성 파운데이션 모델(SFM)의 층별 음향·언어 지식을 분석하고, SLU(특히 음성 기반 개체명 인식/위치화)용 데이터와 E2E SFM 기반 방법을 제안해 성능 이점을 보였음을 보고한다.


<details>
  <summary>Details</summary>
Motivation: SFM들이 빠르게 증가했으나 내부에 어떤 지식이 어떻게 축적되는지에 대한 이해가 부족하며, 특히 심층적 이해를 요구하는 SLU 과제에 대한 검증과 적절한 데이터가 부족했다.

Method: 학습이 필요 없는 통계 기반 분석 도구들과 프로브 태스크를 경량 프레임워크로 구성하여 여러 SFM의 층별 표현을 비교 분석했고, SLU 평가를 위해 음성 NER 및 NEL 태스크와 데이터를 SLEE 벤치마크에 추가했다. 또한 SFM 기반 E2E 모델과 전통적 캐스케이드 접근(ASR→텍스트 모델)을 비교하고, 다양한 적응 전략을 평가했다.

Result: 층별 분석을 통해 음향·언어 정보의 분포와 모델 간 차이를 확인했고, E2E SFM 기반 모델이 일부 경우에서 캐스케이드 방식을 능가함을 보였다. 분석적 통찰이 실제 다운스트림 성능 향상과 연계됨을 제시했다.

Conclusion: SFM 내부 지식에 대한 경량·해석 가능한 분석 도구와 SLU용 데이터·모델을 제공함으로써 연구자들이 모델 설계·선택·적응 전략을 더 잘 결정할 수 있게 기여한다.

Abstract: Speech foundation models (SFMs) are designed to serve as general-purpose
representations for a wide range of speech-processing tasks. The last five
years have seen an influx of increasingly successful self-supervised and
supervised pre-trained models with impressive performance on various downstream
tasks.
  Although the zoo of SFMs continues to grow, our understanding of the
knowledge they acquire lags behind. This thesis presents a lightweight analysis
framework using statistical tools and training-free tasks to investigate the
acoustic and linguistic knowledge encoded in SFM layers. We conduct a
comparative study across multiple SFMs and statistical tools. Our study also
shows that the analytical insights have concrete implications for downstream
task performance.
  The effectiveness of an SFM is ultimately determined by its performance on
speech applications. Yet it remains unclear whether the benefits extend to
spoken language understanding (SLU) tasks that require a deeper understanding
than widely studied ones, such as speech recognition. The limited exploration
of SLU is primarily due to a lack of relevant datasets. To alleviate that, this
thesis contributes tasks, specifically spoken named entity recognition (NER)
and named entity localization (NEL), to the Spoken Language Understanding
Evaluation benchmark. We develop SFM-based approaches for NER and NEL, and find
that end-to-end (E2E) models leveraging SFMs can surpass traditional cascaded
(speech recognition followed by a text model) approaches. Further, we evaluate
E2E SLU models across SFMs and adaptation strategies to assess the impact on
task performance.
  Collectively, this thesis tackles previously unanswered questions about SFMs,
providing tools and datasets to further our understanding and to enable the
community to make informed design choices for future model development and
adoption.

</details>


### [183] [Structuring the Unstructured: A Systematic Review of Text-to-Structure Generation for Agentic AI with a Universal Evaluation Framework](https://arxiv.org/abs/2508.12257)
*Zheye Deng,Chunkit Chan,Tianshi Zheng,Wei Fan,Weiqi Wang,Yangqiu Song*

Main category: cs.CL

TL;DR: 비정형 텍스트를 표·지식 그래프·차트 등 구조화하는 연구를 체계적으로 검토하고, 기법·데이터셋·평가 기준을 정리하며 보편적 평가 프레임워크를 제안하여 텍스트→구조화 작업을 차세대 AI 인프라로 규정함.


<details>
  <summary>Details</summary>
Motivation: 에이전트형·문맥인식 AI의 성장으로 비정형 텍스트를 기계가 처리 가능한 구조적 표현으로 바꾸는 일이 필수적이나, 관련 방법론·데이터·평가의 통합적 검토가 부재하여 연구 방향과 표준이 필요함.

Method: 문헌·기법의 분류·비교 분석, 공개 데이터셋 및 평가 지표의 현황 조사, 공통 과제(정확성·일관성·범용성 등) 도출, 구조화 출력에 대한 보편적 평가 프레임워크 설계 제안.

Result: 각 접근법의 강점·약점, 데이터셋의 편향과 한계, 평가 지표 간 불일치 등을 정리하고, 구조화 결과를 비교·평가할 수 있는 통합 기준을 제시함.

Conclusion: 텍스트→구조화는 다음 세대 AI의 핵심 인프라이며, 표준화된 데이터·평가·벤치마크·도구의 구축과 실험적 검증이 향후 연구의 우선 과제라고 결론지음.

Abstract: The evolution of AI systems toward agentic operation and context-aware
retrieval necessitates transforming unstructured text into structured formats
like tables, knowledge graphs, and charts. While such conversions enable
critical applications from summarization to data mining, current research lacks
a comprehensive synthesis of methodologies, datasets, and metrics. This
systematic review examines text-to-structure techniques and the encountered
challenges, evaluates current datasets and assessment criteria, and outlines
potential directions for future research. We also introduce a universal
evaluation framework for structured outputs, establishing text-to-structure as
foundational infrastructure for next-generation AI systems.

</details>


### [184] [Fast, Slow, and Tool-augmented Thinking for LLMs: A Review](https://arxiv.org/abs/2508.12265)
*Xinda Jia,Jinpeng Li,Zezhong Wang,Jingjing Li,Xingshan Zeng,Yasheng Wang,Weinan Zhang,Yong Yu,Weiwen Liu*

Main category: cs.CL

TL;DR: 이 논문은 인지심리학의 fast/slow 개념과 내부/외부 지식 경계를 차용해 LLM의 추론 전략을 분류하고, 적응형(reasoning) 방법들을 체계적으로 정리하며 향후 과제와 연구 방향을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 실세계 문제 해결에는 상황에 맞는 추론 전략(빠르고 직관적인 응답부터 단계적·도구 보조적 추론까지)을 선택하는 능력이 필요하며, 현재 LLM들은 다양한 추론 방식을 요구하는 문제들에 대해 적응적으로 전략을 선택하는 데 한계가 있다.

Method: 인지심리학의 fast/slow 이원론과 내부/외부 지식 경계를 결합한 새로운 분류체계를 제안하고, 최근 적응형 추론 관련 연구들을 이 분류에 따라 체계적으로 조사·분류한다. 또한 핵심 의사결정 요소들(언제 느린 추론을 사용할지, 언제 외부 도구를 활용할지 등)에 따른 방법들을 정리한다.

Result: 분류체계와 함께 다양한 연구들이 제시한 기법들(예: 단계적 추론, 도구 사용, 메모리·외부 지식 통합, 추론 중지·스킵핑 결정 등)을 주요 결정 요인에 따라 정리했다. 각 접근의 장단점과 적용 상황을 비교·분석했다.

Conclusion: 향후 연구로는 추론 전략의 동적 전환, 비용·정확도 균형, 도구 통합의 안정성, 인간-모델 협업 향상, 벤치마크와 평가 지표 개발 등이 필요하다.

Abstract: Large Language Models (LLMs) have demonstrated remarkable progress in
reasoning across diverse domains. However, effective reasoning in real-world
tasks requires adapting the reasoning strategy to the demands of the problem,
ranging from fast, intuitive responses to deliberate, step-by-step reasoning
and tool-augmented thinking. Drawing inspiration from cognitive psychology, we
propose a novel taxonomy of LLM reasoning strategies along two knowledge
boundaries: a fast/slow boundary separating intuitive from deliberative
processes, and an internal/external boundary distinguishing reasoning grounded
in the model's parameters from reasoning augmented by external tools. We
systematically survey recent work on adaptive reasoning in LLMs and categorize
methods based on key decision factors. We conclude by highlighting open
challenges and future directions toward more adaptive, efficient, and reliable
LLMs.

</details>


### [185] [The Self-Execution Benchmark: Measuring LLMs' Attempts to Overcome Their Lack of Self-Execution](https://arxiv.org/abs/2508.12277)
*Elon Ezra,Ariel Weizman,Amos Azaria*

Main category: cs.CL

TL;DR: LLM들이 자신의 응답을 예측할 수 있는 능력을 평가하는 'Self-Execution Benchmark'를 제안함. 모델들은 일반적으로 이 벤치마크에서 성능이 낮고, 모델 크기/능력 증가가 일관된 개선으로 이어지지 않음을 보임.


<details>
  <summary>Details</summary>
Motivation: 기존 평가는 주로 지식·추론 능력에 초점을 맞추는데, 모델이 자신의 행동(응답 난이도, 거부 여부, 연상 내용 등)을 사전에 예측할 수 있는지, 즉 자기예측(self-prediction) 능력을 평가하는 것이 필요하다고 봄. LLM은 자체 실행(self-execution) 능력이 없어 이를 측정하는 별도 벤치마크가 요구됨.

Method: Self-Execution Benchmark를 설계해 모델에게 자신이 생성할 응답의 속성들을 예측하게 함(예: 질문의 난이도, 응답 거부 여부, 생성될 연상 유형 등). 다양한 모델과 크기를 대상으로 실험을 수행하고, 예측된 속성과 실제 생성물 간의 일치도를 비교·분석함.

Result: 대부분의 모델이 자기예측 문제에서 낮은 성능을 보였고, 모델 크기나 능력이 커졌다고 해서 일관되게 성능이 개선되지는 않았음. 자기예측의 정확도는 전반적으로 제한적이었음.

Conclusion: LLM이 자기 행동을 표현·추론하는 데 근본적 한계가 있을 가능성을 제기함. 단순한 규모 확장만으로는 해결되지 않으며, 모델 설계·학습 방식의 변화가 필요함.

Abstract: Large language models (LLMs) are commonly evaluated on tasks that test their
knowledge or reasoning abilities. In this paper, we explore a different type of
evaluation: whether an LLM can predict aspects of its own responses. Since LLMs
lack the ability to execute themselves, we introduce the Self-Execution
Benchmark, which measures a model's ability to anticipate properties of its
output, such as whether a question will be difficult for it, whether it will
refuse to answer, or what kinds of associations it is likely to produce. Our
experiments show that models generally perform poorly on this benchmark, and
that increased model size or capability does not consistently lead to better
performance. These results suggest a fundamental limitation in how LLMs
represent and reason about their own behavior.

</details>


### [186] [Legal$Δ$: Enhancing Legal Reasoning in LLMs via Reinforcement Learning with Chain-of-Thought Guided Information Gain](https://arxiv.org/abs/2508.12281)
*Xin Dai,Buqiang Xu,Zhenghao Liu,Yukun Yan,Huiyuan Xie,Xiaoyuan Yi,Shuo Wang,Ge Yu*

Main category: cs.CL

TL;DR: LegalΔ는 LLM 기반 법률 AI의 추론 품질을 강화하기 위한 강화학습 프레임워크로, 체인-오브-생각(SoT) 방식의 정보 이득을 최대화해 신뢰성 있고 해석 가능한 법률 추론을 유도한다.


<details>
  <summary>Details</summary>
Motivation: 기존 법률 LLM은 직관적(빠른 생각) 답변을 주로 생성해 다단계·근거 중심의 추론을 제공하지 못해 복잡한 법률 판단에서 설명력과 신뢰성이 부족하다.

Method: 이중 모드 입력(직접 답변 모드와 추론 보강 모드)을 사용해 두 모드 간 정보 이득을 최대화하는 강화학습 프레임워크 LegalΔ를 제안. 두 단계로 진행: (1) 강력한 대규모 추론 모델(DeepSeek-R1)로부터 잠재 추론 능력 증류, (2) 차별적 비교와 구조적·도메인 특화 보상으로 추론 품질 정제.

Result: 여러 법률 추론 과제에서 정확도와 해석 가능성 모두 강한 기준선들을 능가. 라벨된 선호 데이터 없이도 더 견고하고 신뢰 가능한 법률 판단을 생성.

Conclusion: LegalΔ는 법률 도메인에서 다단계 근거 기반 추론을 효과적으로 학습시켜 신뢰성과 해석성을 높이며, 공개 코드·데이터를 통해 재현성을 제공한다.

Abstract: Legal Artificial Intelligence (LegalAI) has achieved notable advances in
automating judicial decision-making with the support of Large Language Models
(LLMs). However, existing legal LLMs still struggle to generate reliable and
interpretable reasoning processes. They often default to fast-thinking behavior
by producing direct answers without explicit multi-step reasoning, limiting
their effectiveness in complex legal scenarios that demand rigorous
justification. To address this challenge, we propose Legal$\Delta$, a
reinforcement learning framework designed to enhance legal reasoning through
chain-of-thought guided information gain. During training, Legal$\Delta$
employs a dual-mode input setup-comprising direct answer and
reasoning-augmented modes-and maximizes the information gain between them. This
encourages the model to acquire meaningful reasoning patterns rather than
generating superficial or redundant explanations. Legal$\Delta$ follows a
two-stage approach: (1) distilling latent reasoning capabilities from a
powerful Large Reasoning Model (LRM), DeepSeek-R1, and (2) refining reasoning
quality via differential comparisons, combined with a multidimensional reward
mechanism that assesses both structural coherence and legal-domain specificity.
Experimental results on multiple legal reasoning tasks demonstrate that
Legal$\Delta$ outperforms strong baselines in both accuracy and
interpretability. It consistently produces more robust and trustworthy legal
judgments without relying on labeled preference data. All code and data will be
released at https://github.com/NEUIR/LegalDelta.

</details>


### [187] [Incorporating Legal Logic into Deep Learning: An Intelligent Approach to Probation Prediction](https://arxiv.org/abs/2508.12286)
*Qinghua Wang,Xu Zhang,Lingyan Yang,Rui Shao,Bonan Wang,Fang Wang,Cunquan Qu*

Main category: cs.CL

TL;DR: 본 논문은 보호관찰(Probation) 예측을 위해 법리(legal logic)를 딥러닝에 결합한 3단계 접근을 제안한다. 보호관찰 관련 사실·법률요소를 포함한 전용 데이터셋을 구축하고, ‘Multi-Task Dual-Theory (MT-DT)’ 모델을 설계해 기존 데이터 기반 모델보다 예측 성능이 우수함을 보였다.


<details>
  <summary>Details</summary>
Motivation: 현행 지능형 사법 보조시스템(IJAS)은 보호관찰 예측 전용 방법이 부족하고, 보호관찰 적격성에 영향을 미치는 요인(범죄사정·반성 등)에 대한 연구가 제한적이다. 또한 기존 데이터 중심 연구는 판결의 법적 논리를 충분히 반영하지 못한다.

Method: 세 단계로 구성: (1) 사실기술과 보호관찰 법률요소(PLEs)를 포함한 전용 보호관찰 데이터셋 구축, (2) 보호관찰의 법리와 이중처벌이론(Dual-Track Theory of Punishment)에 근거한 다중과제(Multi-Task)·이중이론 구조의 MT-DT 모델 설계(법률요소 예측과 보호관찰 판정 등을 함께 학습), (3) 데이터셋에서 모델을 실험·비교하고 법리적 분석으로 모델 결정을 해석·검증.

Result: MT-DT가 제시한 보호관찰 데이터셋에서 베이스라인 모델들보다 성능이 우수하게 나타났으며, 추가적인 법리 기반 분석이 모델의 예측과 법적 판단 논리의 정합성을 뒷받침했다.

Conclusion: 법적 논리를 딥러닝에 통합하면 보호관찰 예측 성능과 판결 해석 가능성이 향상된다. 구축된 데이터셋과 MT-DT 모델은 IJAS에서 보호관찰 예측 연구의 기초를 제공하며, 향후 법리 반영 방법론과 요인 해석 연구가 필요하다.

Abstract: Probation is a crucial institution in modern criminal law, embodying the
principles of fairness and justice while contributing to the harmonious
development of society. Despite its importance, the current Intelligent
Judicial Assistant System (IJAS) lacks dedicated methods for probation
prediction, and research on the underlying factors influencing probation
eligibility remains limited. In addition, probation eligibility requires a
comprehensive analysis of both criminal circumstances and remorse. Much of the
existing research in IJAS relies primarily on data-driven methodologies, which
often overlooks the legal logic underpinning judicial decision-making. To
address this gap, we propose a novel approach that integrates legal logic into
deep learning models for probation prediction, implemented in three distinct
stages. First, we construct a specialized probation dataset that includes fact
descriptions and probation legal elements (PLEs). Second, we design a distinct
probation prediction model named the Multi-Task Dual-Theory Probation
Prediction Model (MT-DT), which is grounded in the legal logic of probation and
the \textit{Dual-Track Theory of Punishment}. Finally, our experiments on the
probation dataset demonstrate that the MT-DT model outperforms baseline models,
and an analysis of the underlying legal logic further validates the
effectiveness of the proposed approach.

</details>


### [188] [CarelessWhisper: Turning Whisper into a Causal Streaming Model](https://arxiv.org/abs/2508.12301)
*Tomer Krichli,Bhiksha Raj,Joseph Keshet*

Main category: cs.CL

TL;DR: 오프라인 SOTA 트랜스포머 기반 ASR(예: Whisper, Canary)을 저지연 스트리밍 모델로 전환하기 위해, 비인과(non-causal) 인코더를 인과(causal) 인코더로 바꾼 뒤 LoRA와 약한 정렬(weak alignment) 데이터로 인코더·디코더를 파인튜닝하고, 이를 활용하는 새로운 추론(그리디·빔서치) 방식을 제안한다. 300ms 미만의 청크에서 기존 비파인튜닝 스트리밍 방법보다 성능이 우수하고 복잡도도 낮으며, 단어 수준 타임스탬프 추출이 용이해진다. 코드와 모델을 공개함.


<details>
  <summary>Details</summary>
Motivation: 최신 ASR 모델들은 오프라인 전사에서 SOTA를 달성했으나, 아키텍처 및 훈련 방식 때문에 실시간·스트리밍(저지연) 전사에 바로 쓸 수 없다. 실시간 처리에 맞게 트랜스포머 인코더-디코더를 변환하는 실용적이고 낮은 복잡도의 방법이 필요하다.

Method: 기존 비인과 인코더를 인과 인코더로 변환하기 위해 인코더와 디코더를 LoRA(저랭크 적응)로 파인튜닝한다. 파인튜닝에는 약하게 정렬된 데이터(weakly aligned dataset)를 사용하고, 업데이트된 인과 인코더·디코더를 사용하는 새로운 추론 절차를 설계하여 그리디 및 빔서치 디코딩에서 지역적 최적성을 확보한다.

Result: 저지연 청크(<300ms) 실험에서 제안한 파인튜닝 모델은 대부분의 경우 기존의 비파인튜닝 스트리밍 방법보다 성능이 우수했고 계산 복잡도는 더 낮았다. 또한 훈련으로 인해 정렬 품질이 좋아져 단어 단위 타임스탬프를 간단히 추출할 수 있게 되었다.

Conclusion: LoRA 기반의 약간의 파인튜닝과 추론 알고리즘 변경만으로도 오프라인 트랜스포머 ASR을 실시간/저지연 환경에서 실용적으로 활용할 수 있으며, 공개된 코드와 모델은 후속 연구·응용에 기여할 것이다.

Abstract: Automatic Speech Recognition (ASR) has seen remarkable progress, with models
like OpenAI Whisper and NVIDIA Canary achieving state-of-the-art (SOTA)
performance in offline transcription. However, these models are not designed
for streaming (online or real-time) transcription, due to limitations in their
architecture and training methodology. We propose a method to turn the
transformer encoder-decoder model into a low-latency streaming model that is
careless about future context. We present an analysis explaining why it is not
straightforward to convert an encoder-decoder transformer to a low-latency
streaming model. Our proposed method modifies the existing (non-causal) encoder
to a causal encoder by fine-tuning both the encoder and decoder using Low-Rank
Adaptation (LoRA) and a weakly aligned dataset. We then propose an updated
inference mechanism that utilizes the fine-tune causal encoder and decoder to
yield greedy and beam-search decoding, and is shown to be locally optimal.
Experiments on low-latency chunk sizes (less than 300 msec) show that our
fine-tuned model outperforms existing non-fine-tuned streaming approaches in
most cases, while using a lower complexity. Additionally, we observe that our
training process yields better alignment, enabling a simple method for
extracting word-level timestamps. We release our training and inference code,
along with the fine-tuned models, to support further research and development
in streaming ASR.

</details>


### [189] [Consensus or Conflict? Fine-Grained Evaluation of Conflicting Answers in Question-Answering](https://arxiv.org/abs/2508.12355)
*Eviatar Nachshoni,Arie Cattan,Shmuel Amar,Ori Shapira,Ido Dagan*

Main category: cs.CL

TL;DR: 새로운 벤치마크 NATCONFQA를 도입해 다중정답(MAQA) 질문에서 서로 충돌하는 답변 쌍을 식별하도록 확장한 연구. 팩트체크 데이터셋을 비용효율적으로 활용해 충돌 라벨을 가진 현실적 데이터셋을 구성하고, 8개 고성능 LLM 평가는 모델들이 다양한 충돌 유형 처리에 취약하고 잘못된 해결 전략을 사용함을 드러냄.


<details>
  <summary>Details</summary>
Motivation: 기존 QA는 보통 단일 정답이나 증거 간 일관성을 가정하나, 실제 MAQA는 여러 유효한 답과 증거 간 상충(conflict)이 존재할 수 있음. 현실적이고 충돌을 반영한 데이터셋 구축은 비용·노동 집약적이며, 기존 벤치마크는 합성 데이터·예/아니오 제한·자동 라벨링 오류 등의 한계가 있음.

Method: 팩트체크 데이터셋을 비용효율적으로 활용하는 새로운 방법론을 제안하여 NATCONFQA를 생성. 질문에 대해 모든 유효한 답을 식별하는 것뿐 아니라, 존재 시 특정 답변 쌍 간의 충돌을 상세히 라벨링함. 이를 바탕으로 충돌 감지까지 요구하는 확장된 MAQA 과제를 정의하고 8개 고성능 LLM을 평가함.

Result: 구성된 NATCONFQA와 평가 결과에서 LLM들은 다양한 충돌 유형(예: 증거 간 상반, 시간에 따른 변경 등)에 대해 취약했으며, 일관되지 않은 추론·무리한 일반화·불완전한 증거 비교 등 잘못된 해결 전략을 자주 사용함.

Conclusion: NATCONFQA는 충돌을 고려한 현실적인 MAQA 연구를 촉진할 수 있는 자원이며, 현재 고성능 LLM들이 충돌 감지·해결에 여전히 취약함을 입증. 향후 연구는 데이터셋 확대·충돌 인식 모델링·증거 추적 메커니즘 개선이 필요함.

Abstract: Large Language Models (LLMs) have demonstrated strong performance in question
answering (QA) tasks. However, Multi-Answer Question Answering (MAQA), where a
question may have several valid answers, remains challenging. Traditional QA
settings often assume consistency across evidences, but MAQA can involve
conflicting answers. Constructing datasets that reflect such conflicts is
costly and labor-intensive, while existing benchmarks often rely on synthetic
data, restrict the task to yes/no questions, or apply unverified automated
annotation. To advance research in this area, we extend the conflict-aware MAQA
setting to require models not only to identify all valid answers, but also to
detect specific conflicting answer pairs, if any. To support this task, we
introduce a novel cost-effective methodology for leveraging fact-checking
datasets to construct NATCONFQA, a new benchmark for realistic, conflict-aware
MAQA, enriched with detailed conflict labels, for all answer pairs. We evaluate
eight high-end LLMs on NATCONFQA, revealing their fragility in handling various
types of conflicts and the flawed strategies they employ to resolve them.

</details>


### [190] [ReaLM: Reflection-Enhanced Autonomous Reasoning with Small Language Models](https://arxiv.org/abs/2508.12387)
*Yuanfeng Xu,Zehui Dai,Jian Liang,Jiapeng Guan,Guangrun Wang,Liang Lin,Xiaohui Lv*

Main category: cs.CL

TL;DR: ReaLM은 강화학습 기반의 프레임워크로, SLM의 복합 추론 성능·자율성·일반화 문제를 동시에 개선한다. MRPV로 긍정·부정 추론 경로를 대조 학습하고, EAAI로 외부 신호를 점진적으로 줄이며, guided CoT 증류로 도메인 규칙을 모델 파라미터에 내재화한다. 실험에서 종합적 성능 향상을 보고함.


<details>
  <summary>Details</summary>
Motivation: 작은 언어모델(SLM)은 비용 효율적이지만 다단계 추론에서 용량 한계와 오류·비일관성 문제를 보인다. 기존 방법들은 부정적 경로에서 배우지 못하거나 외부 신호에 과도하게 의존하고, 교사 패턴에 과적합해 일반화가 떨어지는 문제를 가지고 있다.

Method: ReaLM 프레임워크를 제안: (1) Multi-Route Process Verification(MRPV) — 긍정적/부정적 추론 경로를 대비시켜 결정적 패턴을 추출하도록 보상 설계; (2) Enabling Autonomy via Asymptotic Induction(EAAI) — 훈련 동안 외부 추론 신호를 점진적으로 약화시켜 모델의 자율성 강화; (3) guided chain-of-thought 증류 — 도메인 규칙/전문 지식을 SLM 파라미터에 증류하여 일반화 향상. 강화학습 보상·증류를 결합한 학습 파이프라인을 구성.

Result: 수직(도메인) 및 일반 추론 벤치마크에서 SLM의 성능이 유의미하게 향상되었으며, (1) 추론 능력, (2) 자율성(외부 신호 의존도 감소), (3) 일반화(교사 특화 패턴 의존성 감소)에서 개선을 보고함.

Conclusion: ReaLM은 SLM의 실무적 추론 한계를 다각도로 개선하는 유망한 접근이다. 다만 논문은 세부 재현성(데이터/보상 설계/하이퍼파라미터), 계산 비용, 다양한 도메인에 대한 확장성 검증, 부정적 경로의 생성/선택 방법에 대한 민감도 분석을 더 명확히 할 필요가 있다.

Abstract: Small Language Models (SLMs) are a cost-effective alternative to Large
Language Models (LLMs), but often struggle with complex reasoning due to their
limited capacity and a tendency to produce mistakes or inconsistent answers
during multi-step reasoning. Existing efforts have improved SLM performance,
but typically at the cost of one or more of three key aspects: (1) reasoning
capability, due to biased supervision that filters out negative reasoning paths
and limits learning from errors; (2) autonomy, due to over-reliance on
externally generated reasoning signals; and (3) generalization, which suffers
when models overfit to teacher-specific patterns. In this paper, we introduce
ReaLM, a reinforcement learning framework for robust and self-sufficient
reasoning in vertical domains. To enhance reasoning capability, we propose
Multi-Route Process Verification (MRPV), which contrasts both positive and
negative reasoning paths to extract decisive patterns. To reduce reliance on
external guidance and improve autonomy, we introduce Enabling Autonomy via
Asymptotic Induction (EAAI), a training strategy that gradually fades external
signals. To improve generalization, we apply guided chain-of-thought
distillation to encode domain-specific rules and expert knowledge into SLM
parameters, making them part of what the model has learned. Extensive
experiments on both vertical and general reasoning tasks demonstrate that ReaLM
significantly improves SLM performance across aspects (1)-(3) above.

</details>


### [191] [MedKGent: A Large Language Model Agent Framework for Constructing Temporally Evolving Medical Knowledge Graph](https://arxiv.org/abs/2508.12393)
*Duzhen Zhang,Zixiao Wang,Zhong-Zhi Li,Yahan Yu,Shuncheng Jia,Jiahua Dong,Haotian Xu,Xing Wu,Yingying Zhang,Tielin Zhang,Jie Yang,Xiuying Chen,Le Song*

Main category: cs.CL

TL;DR: MedKGent은 1975–2023년 약 1,000만 PubMed 초록을 일별 시계열로 시뮬레이션하여 Qwen2.5-32B 기반의 두 에이전트(Extractor, Constructor)를 통해 일별로 누적되는 시계열 의료 지식그래프를 구축한다. 샘플링 기반 신뢰도 평가로 낮은 확신 추출을 걸러내고, 시간·신뢰도로 충돌을 해결하여 156K 개체·2.97M 삼중항을 생성, 평가에서 약 90% 정확도 및 RAG 기반 QA 성능 개선을 보고한다.


<details>
  <summary>Details</summary>
Motivation: 의학 문헌의 급증으로 인해 시공간적 변화와 불확실성을 반영하지 못하는 기존 KG 구축법(감독적 파이프라인·단순 LLM 집계)의 한계를 극복하고, 시간에 따라 진화하는 신뢰도 기반 의료 KG를 자동화하려는 목적.

Method: Qwen2.5-32B-Instruct 기반 Extractor 에이전트가 문헌에서 삼중항을 추출하고 샘플링으로 확신도(신뢰도)를 추정해 저확신을 필터링. Constructor 에이전트는 타임스탬프·신뢰도를 활용해 일별로 누적·통합·충돌 해결을 수행. 전체 파이프라인은 1975–2023년 PubMed 초록을 일단위로 순차 처리.

Result: 최종 KG: 156,275 개체, 2,971,384 관계 삼중항. SOTA LLMs 및 3명의 도메인 전문가 평가에서 약 90% 정확도(높은 평가자 일치). 7개 의료 QA 벤치마크에서 RAG를 통해 여러 LLM에 걸쳐 비증강 대비 유의미한 성능 향상. 약물 재창출 사례 연구에서 신뢰도 기반 인과추론 적용.

Conclusion: MedKGent는 시간·신뢰도 인식을 결합해 대규모 시계열 의료 KG를 자동 구축하고, KG가 QA 및 약물 재창출과 같은 다운스트림 작업에 실질적 가치를 제공함을 보였다. 다만 데이터 소스(초록 한정), LLM 편향·환각, 계산 비용·재현성 등 한계와 세부 방법 공개가 필요하다.

Abstract: The rapid expansion of medical literature presents growing challenges for
structuring and integrating domain knowledge at scale. Knowledge Graphs (KGs)
offer a promising solution by enabling efficient retrieval, automated
reasoning, and knowledge discovery. However, current KG construction methods
often rely on supervised pipelines with limited generalizability or naively
aggregate outputs from Large Language Models (LLMs), treating biomedical
corpora as static and ignoring the temporal dynamics and contextual uncertainty
of evolving knowledge. To address these limitations, we introduce MedKGent, a
LLM agent framework for constructing temporally evolving medical KGs.
Leveraging over 10 million PubMed abstracts published between 1975 and 2023, we
simulate the emergence of biomedical knowledge via a fine-grained daily time
series. MedKGent incrementally builds the KG in a day-by-day manner using two
specialized agents powered by the Qwen2.5-32B-Instruct model. The Extractor
Agent identifies knowledge triples and assigns confidence scores via
sampling-based estimation, which are used to filter low-confidence extractions
and inform downstream processing. The Constructor Agent incrementally
integrates the retained triples into a temporally evolving graph, guided by
confidence scores and timestamps to reinforce recurring knowledge and resolve
conflicts. The resulting KG contains 156,275 entities and 2,971,384 relational
triples. Quality assessments by two SOTA LLMs and three domain experts
demonstrate an accuracy approaching 90\%, with strong inter-rater agreement. To
evaluate downstream utility, we conduct RAG across seven medical question
answering benchmarks using five leading LLMs, consistently observing
significant improvements over non-augmented baselines. Case studies further
demonstrate the KG's value in literature-based drug repurposing via
confidence-aware causal inference.

</details>


### [192] [Extracting Post-Acute Sequelae of SARS-CoV-2 Infection Symptoms from Clinical Notes via Hybrid Natural Language Processing](https://arxiv.org/abs/2508.12405)
*Zilong Bai,Zihan Xu,Cong Sun,Chengxi Zang,H. Timothy Bunnell,Catherine Sinfield,Jacqueline Rutter,Aaron Thomas Martinez,L. Charles Bailey,Mark Weiner,Thomas R. Campion,Thomas Carton,Christopher B. Forrest,Rainu Kaushal,Fei Wang,Yifan Peng*

Main category: cs.CL

TL;DR: 복합 규칙 기반 NER과 BERT 기반 판정 모듈을 결합한 PASC 증상 추출 파이프라인을 제안하여 내부 F1 0.82, 외부 F1 0.76, 노트당 평균 처리시간 ≈2.45초를 달성했고, 대규모 진료노트 집단연구에서 양/음 언급 빈도와 높은 상관관계를 보였다.


<details>
  <summary>Details</summary>
Motivation: PASC(포스트 코로나 후유증)는 증상이 다양하고 시간 경과가 길어 임상기록에서 정확하고 효율적으로 증상을 추출·판정하기 어렵다. 이를 자동화해 진단·역학 연구를 지원하려는 목적.

Method: 임상전문가와 공동으로 구축한 포괄적 PASC 용어사전을 기반으로 규칙 기반 NER로 개체를 추출하고, BERT 기반의 assertion detection 모델로 증상 언급의 존재·부재 등 판정. 11개 기관에서 160개의 개발/평가용 intake progress notes와 47,654개의 집단연구용 노트 사용.

Result: 내부 검증 F1=0.82, 10개 사이트 외부 검증 F1=0.76. 노트당 처리시간 평균 2.448±0.812초. 양성 언급과 음성 언급 빈도의 스피어만 상관계수 각각 ρ>0.83, ρ>0.72 (P<0.0001).

Conclusion: 제안한 하이브리드 파이프라인은 PASC 증상 추출·판정에서 효율성과 실무적 유용성을 보였으나, 제한된 주석 데이터와 장기·시간적 문맥 처리 등에서 추가 개선과 광범위한 검증이 필요하다.

Abstract: Accurately and efficiently diagnosing Post-Acute Sequelae of COVID-19 (PASC)
remains challenging due to its myriad symptoms that evolve over long- and
variable-time intervals. To address this issue, we developed a hybrid natural
language processing pipeline that integrates rule-based named entity
recognition with BERT-based assertion detection modules for PASC-symptom
extraction and assertion detection from clinical notes. We developed a
comprehensive PASC lexicon with clinical specialists. From 11 health systems of
the RECOVER initiative network across the U.S., we curated 160 intake progress
notes for model development and evaluation, and collected 47,654 progress notes
for a population-level prevalence study. We achieved an average F1 score of
0.82 in one-site internal validation and 0.76 in 10-site external validation
for assertion detection. Our pipeline processed each note at $2.448\pm 0.812$
seconds on average. Spearman correlation tests showed $\rho >0.83$ for positive
mentions and $\rho >0.72$ for negative ones, both with $P <0.0001$. These
demonstrate the effectiveness and efficiency of our models and their potential
for improving PASC diagnosis.

</details>


### [193] [ZigzagAttention: Efficient Long-Context Inference with Exclusive Retrieval and Streaming Heads](https://arxiv.org/abs/2508.12407)
*Zhuorui Liu,Chen Zhang,Dawei Song*

Main category: cs.CL

TL;DR: ZigzagAttention은 동일 레이어 내에서 retrieval 헤드와 streaming 헤드를 분리(한 레이어는 오직 한 종류의 헤드만 존재)하여 KV 캐시 메모리와 추가 텐서 접근 지연을 동시에 줄이는 방법이다. 성능 저하는 거의 없으면서 지연 시간 감소와 메모리 절감이 가능하다.


<details>
  <summary>Details</summary>
Motivation: LLM의 장문(context) 처리에 따라 KV 캐시 규모가 커져 배포·추론 비용이 증가한다. 기존 연구는 attention 헤드를 retrieval(중요)와 streaming(덜 중요)로 나눠 streaming 헤드의 KV 캐시를 생략해 메모리를 줄였지만, 같은 레이어에 두 종류가 섞이면 attention 연산이 분해되어 텐서 접근·인덱싱에서 추가 지연이 발생할 수 있다.

Method: 헤드 식별 기준을 설계해 각 레이어가 오직 retrieval 혹은 streaming 헤드만 갖도록 강제(레이어 단위의 독점 집계). 이를 통해 streaming 헤드의 KV 캐시 생략은 유지하면서, 한 레이어 내 연산 분해로 인한 추가 latency를 없앰. 알고리즘 이름: ZigzagAttention.

Result: 기본 벤치마크에서 기존 baseline들과 비교했을 때 지연시간이 감소하고 성능(정확도·생성 품질 등)은 거의 동일하여 실용적 트레이드오프를 보임. KV 캐시 사용량도 감소.

Conclusion: 레이어 단위로 헤드 타입을 분리하면 메모리 절감과 latency 감소를 동시에 달성할 수 있다. ZigzagAttention은 실전 배포 관점에서 유의미한 개선을 제공하며, 추가로 자동화된 헤드 분류·다양한 아키텍처 적용 검증이 필요한 부분이 남아 있다.

Abstract: With the rapid development of large language models (LLMs), handling long
context has become one of the vital abilities in LLMs. Such long-context
ability is accompanied by difficulties in deployment, especially due to the
increased consumption of KV cache. There is certain work aiming to optimize the
memory footprint of KV cache, inspired by the observation that attention heads
can be categorized into retrieval heads that are of great significance and
streaming heads that are of less significance. Typically, identifying the
streaming heads and and waiving the KV cache in the streaming heads would
largely reduce the overhead without hurting the performance that much. However,
since employing both retrieval and streaming heads in one layer decomposes one
large round of attention computation into two small ones, it may unexpectedly
bring extra latency on accessing and indexing tensors. Based on this intuition,
we impose an important improvement to the identification process of retrieval
and streaming heads, in which we design a criterion that enforces exclusively
retrieval or streaming heads gathered in one unique layer. In this way, we
further eliminate the extra latency and only incur negligible performance
degradation. Our method named \textsc{ZigzagAttention} is competitive among
considered baselines owing to reduced latency and comparable performance.

</details>


### [194] [The Cultural Gene of Large Language Models: A Study on the Impact of Cross-Corpus Training on Model Values and Biases](https://arxiv.org/abs/2508.12411)
*Emanuel Z. Fenech-Borg,Tilen P. Meznaric-Kos,Milica D. Lekovic-Bojovic,Arni J. Hentze-Djurhuus*

Main category: cs.CL

TL;DR: 저자들은 LLM이 학습 코퍼스에 내재된 문화적 가치지향(‘문화 유전자’)을 반영한다고 보고, 200개 문항의 Cultural Probe Dataset(CPD)을 사용해 GPT-4(서구중심)와 ERNIE Bot(동양중심)을 개인주의-집단주의(IDV)와 권력거리(PDI) 차원에서 비교했다. 결과는 두 모델이 통계적으로 유의미하게 다른 문화적 성향을 보이며 각기 미국·중국의 호프스테드 지표와 정렬됨을 보였다.


<details>
  <summary>Details</summary>
Motivation: LLM의 문화적·윤리적 가정이 전세계적으로 영향을 미치지만, 이러한 내재적 문화성향이 충분히 분석되지 않았기 때문에, 모델의 문화적 편향을 체계적으로 탐색하고 평가할 필요가 있다.

Method: 200개 표준화된 제로샷 프롬프트(CPD)를 설계하여 IDV와 PDI에 대한 응답을 수집하고, 인간 주석가가 응답을 레이블링함. GPT-4와 ERNIE Bot의 점수를 비교하고, 호프스테드 국가별 점수와의 정렬도를 측정하는 Cultural Alignment Index(CAI)를 계산함.

Result: GPT-4는 개인주의·저권력거리 성향(예: IDV≈1.21, PDI≈-1.05), ERNIE Bot은 집단주의·고권력거리 성향(IDV≈-0.89, PDI≈0.76)을 보였고, 차이는 p<0.001로 유의미함. CAI 결과는 GPT-4가 미국과, ERNIE Bot이 중국과 더 높은 정렬도를 보였음.

Conclusion: LLM은 학습 코퍼스의 문화적 통계적 거울로 기능할 수 있으며, 문화적 헤게모니를 방지하기 위해 문화 인지적 평가·배치 방안과 다문화적 책임성이 필요하다는 주장을 제시함.

Abstract: Large language models (LLMs) are deployed globally, yet their underlying
cultural and ethical assumptions remain underexplored. We propose the notion of
a "cultural gene" -- a systematic value orientation that LLMs inherit from
their training corpora -- and introduce a Cultural Probe Dataset (CPD) of 200
prompts targeting two classic cross-cultural dimensions:
Individualism-Collectivism (IDV) and Power Distance (PDI). Using standardized
zero-shot prompts, we compare a Western-centric model (GPT-4) and an
Eastern-centric model (ERNIE Bot). Human annotation shows significant and
consistent divergence across both dimensions. GPT-4 exhibits individualistic
and low-power-distance tendencies (IDV score approx 1.21; PDI score approx
-1.05), while ERNIE Bot shows collectivistic and higher-power-distance
tendencies (IDV approx -0.89; PDI approx 0.76); differences are statistically
significant (p < 0.001). We further compute a Cultural Alignment Index (CAI)
against Hofstede's national scores and find GPT-4 aligns more closely with the
USA (e.g., IDV CAI approx 0.91; PDI CAI approx 0.88) whereas ERNIE Bot aligns
more closely with China (IDV CAI approx 0.85; PDI CAI approx 0.81). Qualitative
analyses of dilemma resolution and authority-related judgments illustrate how
these orientations surface in reasoning. Our results support the view that LLMs
function as statistical mirrors of their cultural corpora and motivate
culturally aware evaluation and deployment to avoid algorithmic cultural
hegemony.

</details>


### [195] [Uncovering Emergent Physics Representations Learned In-Context by Large Language Models](https://arxiv.org/abs/2508.12448)
*Yeongwoo Song,Jaeyong Bae,Dong-Kyum Kim,Hawoong Jeong*

Main category: cs.CL

TL;DR: 이 논문은 물리계의 동역학 예측을 통해 LLM의 in-context learning(ICL) 능력을 조사한다. 입력 컨텍스트가 길어질수록 동역학 예측 성능이 향상되며, 모델의 residual stream activation을 sparse autoencoders(SAE)로 분석한 결과 SAE가 에너지 같은 주요 물리량과 상관된 특징을 포착함을 보인다. 즉, ICL 중에 의미 있는 물리 개념이 내부 표현에 인코딩된다는 증거를 제공한다.


<details>
  <summary>Details</summary>
Motivation: ICL의 정확한 내부 메커니즘을 이해하는 것은 어렵다. 합성적 문제보다 통제 가능한 실험적 데이터와 구조화된 역학 법칙을 갖는 물리 시스템은 LLM의 추론 동작을 현실적이면서도 해석 가능한 방식으로 연구하기에 적합하므로 이를 통해 ICL의 기제를 규명하려는 목적.

Method: 물리계 동역학 예측(task)으로 ICL 성능을 평가하고, 입력 컨텍스트 길이를 변화시켜 성능 변화를 관찰한다. 모델의 residual stream 활성화를 수집하여 SAE로 희소한 잠재 특징을 학습하고, 이 특징들과 물리량(예: 에너지) 간의 상관관계를 분석한다.

Result: 컨텍스트 길이에 따라 동역학 예측 성능이 개선되었고, SAE가 추출한 일부 특징은 물리적 변수(특히 에너지)와 유의미한 상관관계를 보였다. 이는 LLM이 프롬프트 내에서 물리적 개념을 암묵적으로 학습·표현할 수 있음을 시사한다.

Conclusion: 물리 기반 예측 과제를 통해 LLM의 ICL이 단순 패턴매칭을 넘어 물리적 개념을 내부 표현으로 구축함을 보이는 사례를 제시한다. 더 넓은 모델 해석·원인 규명 연구에 유용한 출발점이 될 수 있다.

Abstract: Large language models (LLMs) exhibit impressive in-context learning (ICL)
abilities, enabling them to solve wide range of tasks via textual prompts
alone. As these capabilities advance, the range of applicable domains continues
to expand significantly. However, identifying the precise mechanisms or
internal structures within LLMs that allow successful ICL across diverse,
distinct classes of tasks remains elusive. Physics-based tasks offer a
promising testbed for probing this challenge. Unlike synthetic sequences such
as basic arithmetic or symbolic equations, physical systems provide
experimentally controllable, real-world data based on structured dynamics
grounded in fundamental principles. This makes them particularly suitable for
studying the emergent reasoning behaviors of LLMs in a realistic yet tractable
setting. Here, we mechanistically investigate the ICL ability of LLMs,
especially focusing on their ability to reason about physics. Using a dynamics
forecasting task in physical systems as a proxy, we evaluate whether LLMs can
learn physics in context. We first show that the performance of dynamics
forecasting in context improves with longer input contexts. To uncover how such
capability emerges in LLMs, we analyze the model's residual stream activations
using sparse autoencoders (SAEs). Our experiments reveal that the features
captured by SAEs correlate with key physical variables, such as energy. These
findings demonstrate that meaningful physical concepts are encoded within LLMs
during in-context learning. In sum, our work provides a novel case study that
broadens our understanding of how LLMs learn in context.

</details>


### [196] [M3PO: Multimodal-Model-Guided Preference Optimization for Visual Instruction Following](https://arxiv.org/abs/2508.12458)
*Ruirui Gao,Emily Johnson,Bowen Tan,Yanfei Qian*

Main category: cs.CL

TL;DR: Proposes M3PO, a data-efficient method that selects high-value preference pairs from LVLM-generated candidates using a Multimodal Alignment Score (MAS) and model self-consistency (log-prob) combined into an M3P-Score, then fine-tunes with DPO+LoRA; claims consistent gains over SFT, RLHF, vanilla DPO, RM-DPO across multiple multimodal benchmarks.


<details>
  <summary>Details</summary>
Motivation: Human preference labels are costly and inconsistent; existing SFT/RLHF/DPO approaches underutilize the model's own generation space for finding informative hard negatives. The goal is to leverage model generations to construct high-quality preference pairs for efficient preference optimization.

Method: Generate diverse candidate responses from LVLMs; compute external Multimodal Alignment Score (MAS) for quality and internal Self-Consistency/Confidence (log-prob) for belief; combine into M3P-Score to select preferred and challenging dispreferred examples; use these pairs to fine-tune base LVLMs (LLaVA-1.5 7B/13B) via Direct Preference Optimization (DPO) with LoRA.

Result: M3PO yields consistent improvements over strong baselines (SFT, simulated RLHF, vanilla DPO, RM-DPO) on MME-Bench, POPE, IFT, and Human Preference Score, demonstrating higher sample efficiency and better identification of hard negatives.

Conclusion: Model-guided selection of preference pairs (combining external alignment and internal confidence) is an effective, cost-efficient strategy to improve LVLM instruction-following via DPO fine-tuning; M3PO is a practical enhancement over existing preference optimization methods.

Abstract: Large Vision-Language Models (LVLMs) hold immense potential for complex
multimodal instruction following, yet their development is often hindered by
the high cost and inconsistency of human annotation required for effective
fine-tuning and preference alignment. Traditional supervised fine-tuning (SFT)
and existing preference optimization methods like RLHF and DPO frequently
struggle to efficiently leverage the model's own generation space to identify
highly informative "hard negative" samples. To address these challenges, we
propose Multimodal-Model-Guided Preference Optimization (M3PO), a novel and
data-efficient method designed to enhance LVLMs' capabilities in visual
instruction following. M3PO intelligently selects the most "learning-valuable"
preference sample pairs from a diverse pool of LVLM-generated candidates. This
selection is driven by a sophisticated mechanism that integrates two crucial
signals: a Multimodal Alignment Score (MAS) to assess external quality and the
model's Self-Consistency / Confidence (log-probability) to gauge internal
belief. These are combined into a novel M3P-Score, which specifically
identifies preferred responses and challenging dispreferred responses that the
model might confidently generate despite being incorrect. These high-quality
preference pairs are then used for efficient Direct Preference Optimization
(DPO) fine-tuning on base LVLMs like LLaVA-1.5 (7B/13B) using LoRA. Our
extensive experiments demonstrate that M3PO consistently outperforms strong
baselines, including SFT, simulated RLHF, vanilla DPO, and RM-DPO, across a
comprehensive suite of multimodal instruction following benchmarks (MME-Bench,
POPE, IFT, Human Pref. Score).

</details>


### [197] [LoraxBench: A Multitask, Multilingual Benchmark Suite for 20 Indonesian Languages](https://arxiv.org/abs/2508.12459)
*Alham Fikri Aji,Trevor Cohn*

Main category: cs.CL

TL;DR: 인도네시아의 저자원 언어 20개(일부는 격식 레지스터 포함)를 대상으로 6개 과제를 묶은 LoraxBench를 제안하고, 다양한 다국어·지역 모델을 평가하여 저자원 언어에서 성능이 낮고 격식 변화가 성능에 큰 영향을 미친다는 점을 보였다.


<details>
  <summary>Details</summary>
Motivation: 인구가 많고 언어 다양성이 큰 인도네시아는 NLP 진척이 뒤처져 있으며, 특히 저자원 언어와 격식(레이스터) 차이를 다루는 벤치마크가 부족하다.

Method: 20개 언어(세 언어는 두 개의 격식 레지스터 포함)에 대해 독해, 오픈도메인 QA, 언어 추론, 인과 추론, 번역, 문화 QA의 6개 과제로 데이터셋을 구성한 LoraxBench를 만들고, 다국어 및 지역 특화 대형언어모델들을 대상으로 광범위한 평가를 수행했다.

Result: 전반적으로 벤치마크는 도전적이며 인도네시아어는 상대적으로 높은 성능을 보이나 저자원 언어들에서는 큰 성능 저하가 관찰된다. 지역 특화 모델이 범용 다국어 모델보다 일관되게 우수하지 않았고, 특히 드물게 등장하는 격식(예: 자바어 Krama)에서는 성능이 크게 떨어졌다.

Conclusion: 저자원 언어와 격식 차이를 포함하는 데이터·평가 확장, 지역 특화 데이터 수집·적응 및 모델 개선이 필요하며, 사회·문화적 레지스터를 고려한 연구가 필수적이다.

Abstract: As one of the world's most populous countries, with 700 languages spoken,
Indonesia is behind in terms of NLP progress. We introduce LoraxBench, a
benchmark that focuses on low-resource languages of Indonesia and covers 6
diverse tasks: reading comprehension, open-domain QA, language inference,
causal reasoning, translation, and cultural QA. Our dataset covers 20
languages, with the addition of two formality registers for three languages. We
evaluate a diverse set of multilingual and region-focused LLMs and found that
this benchmark is challenging. We note a visible discrepancy between
performance in Indonesian and other languages, especially the low-resource
ones. There is no clear lead when using a region-specific model as opposed to
the general multilingual model. Lastly, we show that a change in register
affects model performance, especially with registers not commonly found in
social media, such as high-level politeness `Krama' Javanese.

</details>


### [198] [Is GPT-OSS Good? A Comprehensive Evaluation of OpenAI's Latest Open Source Models](https://arxiv.org/abs/2508.12461)
*Ziqian Bi,Keyu Chen,Chiung-Yi Tseng,Danyang Zhang,Tianyang Wang,Hongying Luo,Lu Chen,Junming Huang,Jibin Guan,Junfeng Hao,Junhao Song*

Main category: cs.CL

TL;DR: OpenAI의 GPT-OSS(120B, 20B) 평가에서 20B가 120B보다 몇몇 벤치마크(HumanEval, MMLU)에서 더 우수함. 두 모델 모두 오픈소스 모델군에서 중간 수준 성능을 보이며 코드 생성은 강점, 다국어는 약점. 희소(MoE) 스케일링이 성능 향상으로 직결되지 않음을 시사.


<details>
  <summary>Details</summary>
Motivation: OpenAI의 첫 오픈 가중치 대형 언어모델(GPT-OSS) 공개에 따라, 희소(MoE) 아키텍처의 스케일링이 실제 성능에 미치는 영향을 실증적으로 평가하고, 오픈소스 LLM 생태계 내에서의 상대적 위치와 효율성을 파악하려 함.

Method: GPT-OSS 120B/20B와 다른 6개 공개 모델(14.7B~235B, dense·sparse 포함)을 선택하여 10개 벤치마크(일반지식, 수리추론, 코드생성, 다국어, 대화능력 등)로 비교. 모든 모델을 비양자화(unquantised) 상태에서 표준화된 추론 설정으로 평가했고, McNemar 검정과 효과크기 분석으로 통계적 유의성 검증을 수행.

Result: gpt-oss-20B가 메모리·에너지 소비가 적으면서도 HumanEval, MMLU 등에서 120B보다 일관되게 우수함. 두 모델은 전체적으로 오픈소스 중간 수준 성능을 보였고, 코드생성에서 강점, 다국어 과제에서 약점을 보임. 희소 스케일업이 비례적 성능 향상을 보장하지 않음.

Conclusion: MoE 기반 대형모델의 단순한 파라미터 스케일링만으로는 성능 향상을 얻기 어렵다는 증거를 제공. 최적화 전략(라우팅, 전문가 수/구성, 학습·정규화 기법) 재검토와 효율성(메모리·에너지) 기반 모델 선택이 필요함.

Abstract: In August 2025, OpenAI released GPT-OSS models, its first open weight large
language models since GPT-2 in 2019, comprising two mixture of experts
architectures with 120B and 20B parameters. We evaluated both variants against
six contemporary open source large language models ranging from 14.7B to 235B
parameters, representing both dense and sparse designs, across ten benchmarks
covering general knowledge, mathematical reasoning, code generation,
multilingual understanding, and conversational ability. All models were tested
in unquantised form under standardised inference settings, with statistical
validation using McNemars test and effect size analysis. Results show that
gpt-oss-20B consistently outperforms gpt-oss-120B on several benchmarks, such
as HumanEval and MMLU, despite requiring substantially less memory and energy
per response. Both models demonstrate mid-tier overall performance within the
current open source landscape, with relative strength in code generation and
notable weaknesses in multilingual tasks. These findings provide empirical
evidence that scaling in sparse architectures may not yield proportional
performance gains, underscoring the need for further investigation into
optimisation strategies and informing more efficient model selection for future
open source deployments.

</details>


### [199] [The Structural Sources of Verb Meaning Revisited: Large Language Models Display Syntactic Bootstrapping](https://arxiv.org/abs/2508.12482)
*Xiaomeng Zhu,R. Thomas McCoy,Robert Frank*

Main category: cs.CL

TL;DR: 대규모 언어모델(RoBERTa, GPT-2)을 문장 내 통사적 정보 또는 공기호(공동발생) 정보를 제거한 학습 데이터로 재학습시켜, 통사 단서가 동사 의미 학습에 특히 중요함을 확인함. 특히 정신동사는 통사 정보 제거에 더 민감하고, 명사는 공동발생 왜곡에 더 민감함.


<details>
  <summary>Details</summary>
Motivation: 어린이의 '통사적 부트스트래핑' 가설(동사 의미 학습에 문장 내 통사 환경이 중요)을 대규모 언어모델에 적용해 모델도 유사한 전략을 사용하는지 검증하고, 발달심리학적 가설을 대규모 실험으로 검사할 수 있는지 확인하려 함.

Method: RoBERTa와 GPT-2를 사용해 학습 데이터의 통사 정보를 제거하거나 단어 공동발생 통계를 왜곡한 변형 코퍼스로 재학습시킴. 그 후 동사·명사 임베딩 및 특정 동사 클래스(정신동사 vs 물리동사)의 표현 품질 변화를 비교 평가함.

Result: 통사 정보가 제거되었을 때 동사 표현이 공동발생 정보가 제거되었을 때보다 더 크게 악화됨. 특히 정신동사 표현은 통사 제거에 더 민감했고, 명사 표현은 공동발생 왜곡에 더 민감하게 반응함.

Conclusion: 사람의 동사 학습에서 제안된 통사적 부트스트래핑의 중요성이 모델 수준에서도 재현되며, 대규모 언어모델의 학습환경을 조작해 발달 가설을 대규모로 검증하는 것이 실현 가능함.

Abstract: Syntactic bootstrapping (Gleitman, 1990) is the hypothesis that children use
the syntactic environments in which a verb occurs to learn its meaning. In this
paper, we examine whether large language models exhibit a similar behavior. We
do this by training RoBERTa and GPT-2 on perturbed datasets where syntactic
information is ablated. Our results show that models' verb representation
degrades more when syntactic cues are removed than when co-occurrence
information is removed. Furthermore, the representation of mental verbs, for
which syntactic bootstrapping has been shown to be particularly crucial in
human verb learning, is more negatively impacted in such training regimes than
physical verbs. In contrast, models' representation of nouns is affected more
when co-occurrences are distorted than when syntax is distorted. In addition to
reinforcing the important role of syntactic bootstrapping in verb learning, our
results demonstrated the viability of testing developmental hypotheses on a
larger scale through manipulating the learning environments of large language
models.

</details>


### [200] [Mitigating Hallucinations in Large Language Models via Causal Reasoning](https://arxiv.org/abs/2508.12495)
*Yuangang Li,Yiqing Shen,Yi Nian,Jiechao Gao,Ziyi Wang,Chenxiao Yu,Shawn Li,Jie Wang,Xiyang Hu,Yue Zhao*

Main category: cs.CL

TL;DR: LLM을 변수 수준의 인과 DAG을 생성하고 이에 기반해 그래프 추론을 수행하도록 지도학습 파인튜닝(CDCR-SFT)하는 프레임워크를 제안한다. CausalDR(25,368 샘플) 데이터셋을 구축했으며, 여러 LLM과 8개 과제에서 실험해 CLADDER에서 95.33%로 인간 성능을 처음으로 능가하고 HaluEval의 환각을 10% 개선했다.


<details>
  <summary>Details</summary>
Motivation: 기존 CoT 등 토큰 수준 추론은 변수 간 인과관계, 조건부 독립성, 인과적 식별 가정 등을 명시적으로 모델링하지 못해 논리적 불일치(인과적 환각)가 발생한다. 이에 변수 수준의 인과구조를 명시적으로 학습시켜 환각을 줄이고 인과추론 능력을 향상하려는 동기.

Method: CDCR-SFT: LLM을 감독식 파인튜닝해 (1) 질문으로부터 변수 수준의 방향성 비순환그래프(DAG)를 명시적으로 구성하고, (2) 구성된 그래프 위에서 그래프 기반 추론 트레이스(변수간 인과 추론 경로)를 생성해 답변을 도출한다. 이를 위해 입력 질문, 명시적 DAG, 그래프 추론 트레이스, 검증된 정답을 포함한 CausalDR 데이터셋(25,368 샘플)을 제작하고 4개 LLM에 대해 학습·평가.

Result: CDCR-SFT 적용으로 인과추론 성능이 향상되어 CLADDER에서 95.33% 정확도(인간 94.8% 초과)를 달성하고, HaluEval에서는 환각 사례가 약 10% 개선되었다. 전반적으로 8개 과제에서 성능 향상을 보고함.

Conclusion: LLM에 명시적 변수 수준 인과구조(DAG)를 학습·활용하게 하면 논리적 불일치(인과적 환각)를 효과적으로 완화하고 인과추론 능력을 크게 향상시킬 수 있다. 코드·데이터 공개로 재현 가능성을 제공한다.

Abstract: Large language models (LLMs) exhibit logically inconsistent hallucinations
that appear coherent yet violate reasoning principles, with recent research
suggesting an inverse relationship between causal reasoning capabilities and
such hallucinations. However, existing reasoning approaches in LLMs, such as
Chain-of-Thought (CoT) and its graph-based variants, operate at the linguistic
token level rather than modeling the underlying causal relationships between
variables, lacking the ability to represent conditional independencies or
satisfy causal identification assumptions. To bridge this gap, we introduce
causal-DAG construction and reasoning (CDCR-SFT), a supervised fine-tuning
framework that trains LLMs to explicitly construct variable-level directed
acyclic graph (DAG) and then perform reasoning over it. Moreover, we present a
dataset comprising 25,368 samples (CausalDR), where each sample includes an
input question, explicit causal DAG, graph-based reasoning trace, and validated
answer. Experiments on four LLMs across eight tasks show that CDCR-SFT improves
the causal reasoning capability with the state-of-the-art 95.33% accuracy on
CLADDER (surpassing human performance of 94.8% for the first time) and reduces
the hallucination on HaluEval with 10% improvements. It demonstrates that
explicit causal structure modeling in LLMs can effectively mitigate logical
inconsistencies in LLM outputs. Code is available at
https://github.com/MrLYG/CDCR-SFT.

</details>


### [201] [CorrSteer: Steering Improves Task Performance and Safety in LLMs through Correlation-based Sparse Autoencoder Feature Selection](https://arxiv.org/abs/2508.12535)
*Seonglae Cho,Zekun Wu,Adriano Koshiyama*

Main category: cs.CL

TL;DR: CorrSteer은 추론 시 생성된 토큰의 SAE 활성화와 샘플 정답성(correctness)을 상관분석하여 유효한 SAE 특징을 자동 선택·가중하는 방법이다. 대비 데이터셋이나 대규모 활성화 저장 없이도 관련 특징을 추출해 QA, 편향 완화, 탈옥 방지, 추론 과제에서 성능 향상을 보고한다.


<details>
  <summary>Details</summary>
Motivation: SAE는 LLM에서 해석 가능한 특징을 추출할 수 있지만, downstream steering을 위해서는 대조(contrastive) 데이터나 대규모 활성화 저장이 필요해 확장성과 자동화에 한계가 있다. 이 한계를 해소할 자동적이고 효율적인 특징 선택 방법이 필요하다.

Method: 추론 시 생성된 토큰들에 대한 SAE 활성화만을 사용해 각 샘플의 ‘정답 여부’와 활성화 간의 상관관계를 계산한다. 상관이 높은 특징을 선택하고, 평균 활성화로부터 스티어링 계수를 얻어 기능 억제/증강을 자동화한다. 이 과정은 추가적인 대비 데이터나 전체 활성화 저장 없이 수행된다.

Result: Gemma 2 2B와 LLaMA 3.1 8B에서 여러 벤치(질문응답, 편향 측정, 탈옥 방지, 추론)에서 개선을 보였으며, 예: MMLU +4.1%, HarmBench +22.9% (4,000 샘플 사용). 선택된 특징은 각 과제 요구와 일치하는 의미론적 패턴을 보였다.

Conclusion: 추론-기반 상관(selection)을 통한 SAE 특징 선택은 자동화·확장성 측면에서 유효한 접근으로, 거짓 상관(spurious correlations)을 줄이고 적은 샘플로도 실용적 스티어링을 가능하게 한다.

Abstract: Sparse Autoencoders (SAEs) can extract interpretable features from large
language models (LLMs) without supervision. However, their effectiveness in
downstream steering tasks is limited by the requirement for contrastive
datasets or large activation storage. To address these limitations, we propose
CorrSteer, which selects features by correlating sample correctness with SAE
activations from generated tokens at inference time. This approach uses only
inference-time activations to extract more relevant features, thereby avoiding
spurious correlations. It also obtains steering coefficients from average
activations, automating the entire pipeline. Our method shows improved task
performance on QA, bias mitigation, jailbreaking prevention, and reasoning
benchmarks on Gemma 2 2B and LLaMA 3.1 8B, notably achieving a +4.1%
improvement in MMLU performance and a +22.9% improvement in HarmBench with only
4000 samples. Selected features demonstrate semantically meaningful patterns
aligned with each task's requirements, revealing the underlying capabilities
that drive performance. Our work establishes correlationbased selection as an
effective and scalable approach for automated SAE steering across language
model applications.

</details>


### [202] [Beyond Modality Limitations: A Unified MLLM Approach to Automated Speaking Assessment with Effective Curriculum Learning](https://arxiv.org/abs/2508.12591)
*Yu-Hsuan Fang,Tien-Hong Lo,Yao-Ting Sung,Berlin Chen*

Main category: cs.CL

TL;DR: The paper systematically investigates Multimodal Large Language Models (MLLMs) for Automated Speaking Assessment (ASA), showing MLLMs outperform unimodal baselines in content and language-use scoring but struggle on delivery. It proposes Speech-First Multimodal Training (SFMT) — a curriculum-learning approach that first strengthens speech modeling before cross-modal fusion — and reports holistic PCC improvement from 0.783 to 0.846 and a 4% absolute gain in delivery accuracy.


<details>
  <summary>Details</summary>
Motivation: Existing ASA systems are limited: text-based methods miss acoustic cues and audio-only methods lack semantic/contextual understanding. MLLMs can jointly process audio and text, potentially providing more comprehensive, unified assessment across content, language use, and delivery.

Method: Conduct a systematic study of MLLMs for ASA and identify delivery as a weak point. Introduce Speech-First Multimodal Training (SFMT), which uses curriculum learning to prioritize robust speech representation learning before cross-modal fusion, aiming to improve delivery modeling and overall assessment.

Result: MLLM-based systems improve holistic assessment performance (PCC) from 0.783 to 0.846 on a benchmark dataset. SFMT specifically improves delivery evaluation, achieving an absolute accuracy increase of 4% over conventional training strategies.

Conclusion: MLLMs are promising for comprehensive ASA, especially for content and language-use scoring. However, delivery requires tailored training; SFMT is an effective strategy to address this, indicating that specialized curriculum-based multimodal training can unlock stronger ASA performance.

Abstract: Traditional Automated Speaking Assessment (ASA) systems exhibit inherent
modality limitations: text-based approaches lack acoustic information while
audio-based methods miss semantic context. Multimodal Large Language Models
(MLLM) offer unprecedented opportunities for comprehensive ASA by
simultaneously processing audio and text within unified frameworks. This paper
presents a very first systematic study of MLLM for comprehensive ASA,
demonstrating the superior performance of MLLM across the aspects of content
and language use . However, assessment on the delivery aspect reveals unique
challenges, which is deemed to require specialized training strategies. We thus
propose Speech-First Multimodal Training (SFMT), leveraging a curriculum
learning principle to establish more robust modeling foundations of speech
before cross-modal synergetic fusion. A series of experiments on a benchmark
dataset show MLLM-based systems can elevate the holistic assessment performance
from a PCC value of 0.783 to 0.846. In particular, SFMT excels in the
evaluation of the delivery aspect, achieving an absolute accuracy improvement
of 4% over conventional training approaches, which also paves a new avenue for
ASA.

</details>


### [203] [Semantic Anchoring in Agentic Memory: Leveraging Linguistic Structures for Persistent Conversational Context](https://arxiv.org/abs/2508.12630)
*Maitreyi Chatterjee,Devansh Agarwal*

Main category: cs.CL

TL;DR: Introduce 'Semantic Anchoring', a hybrid memory for long-term dialogues that augments vector-based RAG with explicit linguistic cues (dependency parses, discourse relations, coreference) to improve recall and coherence; reports up to 18% gains over strong RAG baselines with ablations and human evals.


<details>
  <summary>Details</summary>
Motivation: RAG systems store history as dense vectors capturing semantics but miss fine-grained linguistic structure (syntax, discourse, coreference), which limits accurate recall and coherence in multi-session/long-term dialogs.

Method: Build structured memory entries by extracting dependency parses, discourse-relation tags, and coreference chains from dialogue turns; store these alongside dense embeddings in a hybrid agentic memory architecture ('semantic anchors') and use them during retrieval-augmented generation.

Result: On adapted long-term dialogue datasets, semantic anchoring yields up to 18% improvement in factual recall and discourse coherence compared to strong RAG baselines. Ablation studies, human evaluations, and error analysis support robustness and interpretability claims.

Conclusion: Enriching vector memories with explicit linguistic structure improves long-term conversational performance and interpretability, though practical limits include parser errors, extra computational/storage cost, and potential domain transfer issues.

Abstract: Large Language Models (LLMs) have demonstrated impressive fluency and task
competence in conversational settings. However, their effectiveness in
multi-session and long-term interactions is hindered by limited memory
persistence. Typical retrieval-augmented generation (RAG) systems store
dialogue history as dense vectors, which capture semantic similarity but
neglect finer linguistic structures such as syntactic dependencies, discourse
relations, and coreference links. We propose Semantic Anchoring, a hybrid
agentic memory architecture that enriches vector-based storage with explicit
linguistic cues to improve recall of nuanced, context-rich exchanges. Our
approach combines dependency parsing, discourse relation tagging, and
coreference resolution to create structured memory entries. Experiments on
adapted long-term dialogue datasets show that semantic anchoring improves
factual recall and discourse coherence by up to 18% over strong RAG baselines.
We further conduct ablation studies, human evaluations, and error analysis to
assess robustness and interpretability.

</details>


### [204] [Beyond GPT-5: Making LLMs Cheaper and Better via Performance-Efficiency Optimized Routing](https://arxiv.org/abs/2508.12631)
*Yiqun Zhang,Hao Li,Jianhao Chen,Hangfan Zhang,Peng Ye,Lei Bai,Shuyue Hu*

Main category: cs.CL

TL;DR: Avengers-Pro는 입력 쿼리를 임베딩해 클러스터링하고, 성능-효율성 점수에 따라 적절한 LLM으로 실시간 라우팅하여 단일 모델 대비 정확도 또는 비용에서 우수한 성능-효율성 균형을 달성하는 테스트타임 라우팅 프레임워크다.


<details>
  <summary>Details</summary>
Motivation: 대형언어모델은 고성능과 고비용 사이의 트레이드오프가 뚜렷함. 특정 쿼리엔 경량 모델로도 충분하고, 다른 쿼리엔 고성능 모델이 필요하므로 테스트타임에 쿼리별로 모델을 선택하면 전체 비용을 줄이면서 성능을 유지․향상할 수 있다.

Method: 여러 용량의 LLM을 앙상블하고, 들어오는 쿼리를 임베딩한 뒤 클러스터링하여 각 클러스터별로 성능-효율성 점수를 기반으로 최적 모델로 라우팅한다. 조절 가능한 트레이드오프 파라미터로 비용과 성능 사이의 균형을 제어한다.

Result: 6개 벤치마크와 8개 모델(GPT-5-medium, Gemini-2.5-pro, Claude-opus-4.1 등)에서 실험. 최고 단일 모델 대비 평균 정확도 +7% 달성. 동일 평균 정확도를 약 27% 낮은 비용으로 달성, 또는 약 90% 성능을 63% 낮은 비용으로 달성. 모든 비용 수준에서 단일 모델 대비 파레토 우위.

Conclusion: 입력 기반 라우팅으로 모델 앙상블의 성능-효율성 트레이드오프를 효과적으로 탐색할 수 있으며, 실용적인 비용 절감과 성능 향상을 동시에 제공한다.

Abstract: Balancing performance and efficiency is a central challenge in large language
model (LLM) advancement. GPT-5 addresses this with test-time routing,
dynamically assigning queries to either an efficient or a high-capacity model
during inference. In this work, we present Avengers-Pro, a test-time routing
framework that ensembles LLMs of varying capacities and efficiencies, providing
a unified solution for all performance-efficiency tradeoffs. The Avengers-Pro
embeds and clusters incoming queries, then routes each to the most suitable
model based on a performance-efficiency score. Across 6 challenging benchmarks
and 8 leading models -- including GPT-5-medium, Gemini-2.5-pro, and
Claude-opus-4.1 -- Avengers-Pro achieves state-of-the-art results: by varying a
performance-efficiency trade-off parameter, it can surpass the strongest single
model (GPT-5-medium) by +7% in average accuracy. Moreover, it can match the
average accuracy of the strongest single model at 27% lower cost, and reach
~90% of that performance at 63% lower cost. Last but not least, it achieves a
Pareto frontier, consistently yielding the highest accuracy for any given cost,
and the lowest cost for any given accuracy, among all single models. Code is
available at https://github.com/ZhangYiqun018/AvengersPro.

</details>


### [205] [Prompt-Induced Linguistic Fingerprints for LLM-Generated Fake News Detection](https://arxiv.org/abs/2508.12632)
*Chi Wang,Min Gao,Zongwei Wang,Junwei Yin,Kai Shu,Chenghua Lin*

Main category: cs.CL

TL;DR: 제안된 LIFE 방법은 LLM이 악의적 프롬프트에 반응할 때 생기는 단어 수준의 확률분포 변화(프롬프트 유도 언어 지문)를 재구성·추출하여 LLM 생성 가짜뉴스를 탐지한다. 핵심 기법은 단어 레벨 확률분포 재구성과 key-fragment 기법으로 미세한 차이를 증폭시키는 것이다.


<details>
  <summary>Details</summary>
Motivation: LLM의 발전으로 가짜뉴스 생성이 쉬워지면서 텍스트 자체로는 진위 판별이 어려워졌고, 기존 방법들이 놓치는 미묘한 생성 흔적을 찾아 검출력을 높일 필요가 있다.

Method: 프롬프트 유도 분포 발산을 분석해 LLM 생성(특히 악의적 프롬프트에 의해 생성된) 진짜/가짜 뉴스 사이의 통계적 확률 이동을 규명한다. LIFE는 단어 수준의 확률분포를 재구성해 판별에 유용한 패턴을 추출하고, key-fragment 기법으로 미세한 차이를 강조한다.

Result: 실험에서 LIFE는 LLM 생성 가짜뉴스 검출에서 SOTA 성능을 달성했고, 인간 작성 가짜뉴스에서도 높은 성능을 유지했다. 코드와 데이터가 공개되었다.

Conclusion: 프롬프트가 유발하는 확률적 ‘언어 지문’은 LLM 생성 가짜뉴스 탐지에 강력한 단서가 되며, LIFE는 이를 효과적으로 추출·증폭해 실전 검출 성능을 향상시킨다.

Abstract: With the rapid development of large language models, the generation of fake
news has become increasingly effortless, posing a growing societal threat and
underscoring the urgent need for reliable detection methods. Early efforts to
identify LLM-generated fake news have predominantly focused on the textual
content itself; however, because much of that content may appear coherent and
factually consistent, the subtle traces of falsification are often difficult to
uncover. Through distributional divergence analysis, we uncover prompt-induced
linguistic fingerprints: statistically distinct probability shifts between
LLM-generated real and fake news when maliciously prompted. Based on this
insight, we propose a novel method named Linguistic Fingerprints Extraction
(LIFE). By reconstructing word-level probability distributions, LIFE can find
discriminative patterns that facilitate the detection of LLM-generated fake
news. To further amplify these fingerprint patterns, we also leverage
key-fragment techniques that accentuate subtle linguistic differences, thereby
improving detection reliability. Our experiments show that LIFE achieves
state-of-the-art performance in LLM-generated fake news and maintains high
performance in human-written fake news. The code and data are available at
https://anonymous.4open.science/r/LIFE-E86A.

</details>


### [206] [Breaking Language Barriers: Equitable Performance in Multilingual Language Models](https://arxiv.org/abs/2508.12662)
*Tanay Nagar,Grigorii Khvatskii,Anna Sokol,Nitesh V. Chawla*

Main category: cs.CL

TL;DR: 저자들은 합성 코드스위칭(언어 혼합) 데이터로 LLM을 미세조정하여 저자원 언어(LRL)의 상식추론(CSR) 성능을 크게 향상시키고, 고자원 언어(HRL) 성능은 유지하거나 향상시켰음을 보입니다. CommonSenseQA에서 파생한 합성 코드스위칭 데이터셋(세 가지 언어 비율 구성)을 제시합니다.


<details>
  <summary>Details</summary>
Motivation: LLM이 다국어 커뮤니케이션에 강력하지만, 저자원 언어로 프롬프트할 때 상식추론 성능이 HRL(예: 영어)보다 떨어져 공정성 문제와 접근성 격차가 발생함. 이를 해소해 다양한 언어 커뮤니티에 공정한 성능을 제공해야 함.

Method: 제어된 언어 혼합 방법으로 합성 코드스위칭 텍스트를 생성하고, 해당 합성 데이터로 LLM을 미세조정(fine-tuning)함. 데이터셋은 CommonSenseQA를 기반으로 세 가지 다른 언어 비율 설정으로 구성됨.

Result: 합성 코드스위칭 데이터로 미세조정한 모델이 LRL에서 유의미한 성능 향상을 보였으며, HRL 성능은 보존되거나 개선됨.

Conclusion: 합성 코드스위칭을 활용한 미세조정은 LRL에서의 상식추론 성능 격차를 줄이는 실용적 접근법이며, 제안된 데이터셋은 추가 연구와 재현에 유용함.

Abstract: Cutting-edge LLMs have emerged as powerful tools for multilingual
communication and understanding. However, LLMs perform worse in Common Sense
Reasoning (CSR) tasks when prompted in low-resource languages (LRLs) like Hindi
or Swahili compared to high-resource languages (HRLs) like English. Equalizing
this inconsistent access to quality LLM outputs is crucial to ensure fairness
for speakers of LRLs and across diverse linguistic communities. In this paper,
we propose an approach to bridge this gap in LLM performance. Our approach
involves fine-tuning an LLM on synthetic code-switched text generated using
controlled language-mixing methods. We empirically demonstrate that fine-tuning
LLMs on synthetic code-switched datasets leads to substantial improvements in
LRL model performance while preserving or enhancing performance in HRLs.
Additionally, we present a new dataset of synthetic code-switched text derived
from the CommonSenseQA dataset, featuring three distinct language ratio
configurations.

</details>


### [207] [Leveraging Large Language Models for Predictive Analysis of Human Misery](https://arxiv.org/abs/2508.12669)
*Bishanka Seal,Rahul Seetharaman,Aman Bansal,Abhilash Nandy*

Main category: cs.CL

TL;DR: LLM을 이용해 자연어 문장에서 사람의 체감 ‘misery’ 점수(0–100)를 회귀로 예측하고, 제로샷·고정 컨텍스트 few-shot·BERT 기반 검색(few-shot) 등 프롬프트 전략을 비교했다. Few-shot이 제로샷보다 우수하며, ‘Misery Game Show’라는 게임화된 평가로 피드백 기반 적응 능력도 평가했다. 코드·데이터 공개.


<details>
  <summary>Details</summary>
Motivation: 자연어로 서술된 실제 상황에서 사람의 감정적 고통(혹은 불쾌감)을 수치화해 예측하는 실용적·심리측정적 과제를 해결하고, 단순 정적 성능 평가를 넘어 피드백에 따른 모델의 적응 능력을 검증하기 위해.

Method: 입력 문장에 대해 0–100 스칼라를 예측하는 회귀 문제로 설정. 프롬프트 방식으로 제로샷, 고정 컨텍스트 few-shot, BERT 문장 임베딩을 이용한 검색 기반 few-shot을 비교. 평가 확장을 위해 TV 쇼 형식에서 영감을 받은 ‘Misery Game Show’—순위 비교, 이진 분류, 스칼라 추정, 피드백 기반 추론 라운드로 구성된 게임화된 프로토콜—를 설계해 모델의 적응성 및 감정 추론 능력을 테스트.

Result: Few-shot 방식이 일관되게 제로샷을 능가. 검색 기반 예시 선택이 성능 향상에 기여. 게임화된 평가에서 모델은 피드백을 통해 성능 개선 가능성을 보였고, 단순 회귀보다 더 풍부한 질적·순차적 평가를 제공.

Conclusion: 문맥 예시(특히 검색 기반 few-shot)와 피드백 루프가 감정적 스칼라 예측 성능 향상에 중요하다. ‘Misery Game Show’는 동적·상호작용적 감정 추론 평가의 유망한 틀이며, 더 폭넓은 검증(교차모델·교차데이터·캘리브레이션·공정성 평가)이 필요하다.

Abstract: This study investigates the use of Large Language Models (LLMs) for
predicting human-perceived misery scores from natural language descriptions of
real-world scenarios. The task is framed as a regression problem, where the
model assigns a scalar value from 0 to 100 to each input statement. We evaluate
multiple prompting strategies, including zero-shot, fixed-context few-shot, and
retrieval-based prompting using BERT sentence embeddings. Few-shot approaches
consistently outperform zero-shot baselines, underscoring the value of
contextual examples in affective prediction. To move beyond static evaluation,
we introduce the "Misery Game Show", a novel gamified framework inspired by a
television format. It tests LLMs through structured rounds involving ordinal
comparison, binary classification, scalar estimation, and feedback-driven
reasoning. This setup enables us to assess not only predictive accuracy but
also the model's ability to adapt based on corrective feedback. The gamified
evaluation highlights the broader potential of LLMs in dynamic emotional
reasoning tasks beyond standard regression. Code and data link:
https://github.com/abhi1nandy2/Misery_Data_Exps_GitHub

</details>


### [208] [ToolACE-MT: Non-Autoregressive Generation for Agentic Multi-Turn Interaction](https://arxiv.org/abs/2508.12685)
*Xingshan Zeng,Weiwen Liu,Lingzhi Wang,Liangyou Li,Fei Mi,Yasheng Wang,Lifeng Shang,Xin Jiang,Qun Liu*

Main category: cs.CL

TL;DR: ToolACE-MT는 자율적(Agentic) 다중턴 대화를 비(非)자기회귀 방식으로 생성하는 3단계(초기 골격화, 반복적 정제, 오프라인 검증) 프레임워크로, 비용과 불확실성을 줄이며 고품질 도구 보조 대화 데이터를 효율적으로 구성한다.


<details>
  <summary>Details</summary>
Motivation: 기존 시뮬레이션 방식은 여러 LLM 에이전트 간의 고비용 자가회귀 상호작용에 의존해 실제 에이전트 성능으로 일반화되기 어렵고 비용이 크다. 이에 따라 효율적이면서 현실적인 다중턴 에이전트 대화 데이터 생성법이 필요하다.

Method: ToolACE-MT는 (1) 구조적으로 완전하나 의미적으로 거친 대화 골격을 만드는 초기화, (2) 마스크-채우기(mask-and-fill) 기반 반복 정제를 통해 현실적 복잡성과 세부를 채워넣는 단계, (3) 규칙 및 모델 기반의 오프라인 검증으로 일관성과 정합성을 확인하는 3단계 절차로 전체 대화 궤적을 비자기회귀 방식으로 생성한다.

Result: 실험에서 ToolACE-MT는 생성 비용을 낮추면서도 에이전트 대화의 현실성·정확성·일반화 능력을 향상시켰음이 보고되었다(효율적·효과적·일반화 가능하다는 주장).

Conclusion: ToolACE-MT는 도구 보조 LLM 시나리오에서 고품질 다중턴 에이전트 대화 데이터 구축의 새로운 패러다임을 제시하며, 비용 절감과 품질 확보를 동시에 달성할 수 있음을 보여준다.

Abstract: Agentic task-solving with Large Language Models (LLMs) requires multi-turn,
multi-step interactions, often involving complex function calls and dynamic
user-agent exchanges. Existing simulation-based data generation methods for
such scenarios rely heavily on costly autoregressive interactions between
multiple LLM agents, thereby limiting real-world performance of agentic tasks.
In this paper, we propose a novel Non-Autoregressive Iterative Generation
framework, called ToolACE-MT, for constructing high-quality multi-turn agentic
dialogues. ToolACE-MT generates full conversational trajectories through three
stages: coarse-grained initialization, iterative refinement, and offline
verification. The initialization phase builds a structurally complete yet
semantically coarse dialogue skeleton; the iterative refinement phase
introduces realistic complexities and continued refinement via mask-and-fill
operations; and the offline verification phase ensures correctness and
coherence via rule- and model-based checks. Experiments demonstrate that
ToolACE-MT enables efficient, effective and generalizable agentic data
generation, offering a new paradigm for high-quality data construction in
tool-augmented LLM scenarios.

</details>


### [209] [DESIGNER: Design-Logic-Guided Multidisciplinary Data Synthesis for LLM Reasoning](https://arxiv.org/abs/2508.12726)
*Weize Liu,Yongchi Zhao,Yijia Luo,Mingyu Xu,Jiaheng Liu,Yanan Li,Xiguo Hu,Yuchi Xu,Wenbo Su,Bo Zheng*

Main category: cs.CL

TL;DR: DESIGNER은 사람 교사의 문제 설계 과정을 모사한 'Design Logic'을 LLM으로 역추적해 다양한 교재·웹 코퍼스에서 다학제 고난이도 추론 문제를 대규모로 합성한 파이프라인이다. 결과물로 75개 학문을 아우르는 DLR-Book(3.04M)과 DLR-Web(1.66M)를 얻었고, SFT 실험에서 동일 규모의 기존 데이터보다 모델 성능을 크게 향상시켰다.


<details>
  <summary>Details</summary>
Motivation: 기존 추론 데이터셋은 학문적 범위나 구조적 깊이(다단계, 설계적 문제 생성)가 부족해 LLM의 복합·다학제적 추론 능력을 충분히 평가하거나 향상시키지 못함. 이에 자연문서(책·웹)로부터 더 어려우면서 다양한 문제를 자동 합성하려는 동기.

Method: (1) 기존 문제들로부터 LLM을 이용해 12만개 이상의 'Design Logic'을 역추적·추상화, (2) 각 Design Logic을 책·웹 코퍼스의 자료와 매칭해 문맥·근거가 있는 질문을 자동 생성, (3) 필터링·정제 과정을 통해 최종 문제집합 구축. 대규모 합성으로 DLR-Book(3.04M)과 DLR-Web(1.66M)을 생산.

Result: 합성된 문제들은 난이도·다양성에서 기존 베이스라인 데이터셋을 능가함. Qwen3-8B/4B 기반 모델을 SFT한 결과, 동일 볼륨의 기존 다학제 데이터보다 우수한 추론 성능을 보여주었고 전체 데이터로 학습 시 공식 Qwen3 모델 성능을 초과함.

Conclusion: Design Logic 기반 자동 합성은 다학제·다단계 추론 데이터 생성의 확장성과 효율성 측면에서 유의미한 진전이며, 대규모 질적 데이터가 LLM의 복합 추론 능력 향상에 실질적 기여를 함.

Abstract: Large language models (LLMs) have achieved remarkable success in many natural
language tasks but still struggle with complex, multi-step reasoning,
particularly across diverse disciplines. Existing reasoning datasets often
either lack disciplinary breadth or the structural depth necessary to elicit
robust reasoning behaviors. We propose DESIGNER: a DESIGN-logic-guidEd
Reasoning data synthesis pipeline that leverages naturally available, extensive
raw documents (book corpus and web corpus) to generate multidisciplinary
challenging questions. A core innovation of our approach is the introduction of
a Design Logic concept, which mimics the question-creation process of human
educators. We use LLMs to reverse-engineer and abstract over 120,000 design
logics from existing questions across various disciplines. By matching these
design logics with disciplinary source materials, we are able to create
reasoning questions that far surpass the difficulty and diversity of existing
datasets. Based on this pipeline, we synthesized two large-scale reasoning
datasets that span 75 disciplines: Design-Logic-Reasoning-Book (DLR-Book),
containing 3.04 million challenging questions synthesized from the book corpus,
and Design-Logic-Reasoning-Web (DLR-Web), with 1.66 million challenging
questions from the web corpus. Our data analysis demonstrates that the
questions synthesized by our method exhibit substantially greater difficulty
and diversity than those in the baseline datasets. We validate the
effectiveness of these datasets by conducting SFT experiments on the
Qwen3-8B-Base and Qwen3-4B-Base models. The results show that our dataset
significantly outperforms existing multidisciplinary datasets of the same
volume. Training with the full datasets further enables the models to surpass
the multidisciplinary reasoning performance of the official Qwen3-8B and
Qwen3-4B models.

</details>


### [210] [LinguaSafe: A Comprehensive Multilingual Safety Benchmark for Large Language Models](https://arxiv.org/abs/2508.12733)
*Zhiyuan Ning,Tianle Gu,Jiaxin Song,Shixin Hong,Lingyu Li,Huacan Liu,Jie Li,Yixu Wang,Meng Lingyu,Yan Teng,Yingchun Wang*

Main category: cs.CL

TL;DR: LinguaSafe는 12개 언어(헝가리어부터 말레이어까지)로 구성된 45k 샘플의 다국어 안전성 벤치마크로, 번역·창작·원어민 자료를 혼합해 정교하게 수집하고 직접/간접 유해성 및 과민성 평가를 포함한 다차원·미세평가 체계를 제공한다. 평가 결과는 언어와 도메인에 따라 크게 달라져 다국어 안전성 평가의 필요성을 강조한다.


<details>
  <summary>Details</summary>
Motivation: 기존 다국어 LLM 안전성 평가가 데이터 다양성·언어적 진정성 부족으로 실효성이 떨어지고, 특히 저자원·덜 대표되는 언어들에 대한 안전성 정렬 연구가 미비함. 이를 보완하기 위한 포괄적 벤치마크가 필요함.

Method: 12개 언어, 45k 엔트리를 수집. 자료 소스는 번역(translated), 현지화된 창작(transcreated), 원어민(naive) 데이터의 혼합. 평가 프레임워크는 직접적·간접적 유해성 검사와 과민성(oversensitivity) 테스트를 포함한 다차원·미세 그레이드 항목으로 구성. 여러 도메인과 언어에 걸쳐 안전성 및 도움됨(helpfulness) 평가지표를 산출.

Result: 다언어·다도메인 평가에서 안전성·도움됨 점수가 언어별·도메인별로 큰 편차를 보임. 비슷한 자원 수준의 언어들 사이에서도 차이가 관찰되어 단순한 자원 수준 지표만으로는 안전성 성능을 예측하기 어려움. 벤치마크는 심층 평가를 위한 다양한 메트릭 세트를 제공함.

Conclusion: LinguaSafe는 다국어 LLM 안전성 평가의 중요한 공백을 메우며, 언어적 진정성을 고려한 데이터와 세분화된 평가체계를 통해 보다 균형 잡힌 안전성 정렬 연구를 촉진한다. 데이터와 코드 공개로 후속 연구를 지원한다.

Abstract: The widespread adoption and increasing prominence of large language models
(LLMs) in global technologies necessitate a rigorous focus on ensuring their
safety across a diverse range of linguistic and cultural contexts. The lack of
a comprehensive evaluation and diverse data in existing multilingual safety
evaluations for LLMs limits their effectiveness, hindering the development of
robust multilingual safety alignment. To address this critical gap, we
introduce LinguaSafe, a comprehensive multilingual safety benchmark crafted
with meticulous attention to linguistic authenticity. The LinguaSafe dataset
comprises 45k entries in 12 languages, ranging from Hungarian to Malay. Curated
using a combination of translated, transcreated, and natively-sourced data, our
dataset addresses the critical need for multilingual safety evaluations of
LLMs, filling the void in the safety evaluation of LLMs across diverse
under-represented languages from Hungarian to Malay. LinguaSafe presents a
multidimensional and fine-grained evaluation framework, with direct and
indirect safety assessments, including further evaluations for oversensitivity.
The results of safety and helpfulness evaluations vary significantly across
different domains and different languages, even in languages with similar
resource levels. Our benchmark provides a comprehensive suite of metrics for
in-depth safety evaluation, underscoring the critical importance of thoroughly
assessing multilingual safety in LLMs to achieve more balanced safety
alignment. Our dataset and code are released to the public to facilitate
further research in the field of multilingual LLM safety.

</details>


### [211] [CRED-SQL: Enhancing Real-world Large Scale Database Text-to-SQL Parsing through Cluster Retrieval and Execution Description](https://arxiv.org/abs/2508.12769)
*Shaoming Duan,Zirui Wang,Chuanyi Liu,Zhibin Zhu,Yuhao Zhang,Peiyi Han,Liang Yan,Zewu Penge*

Main category: cs.CL

TL;DR: CRED-SQL은 대규모 DB에서 자연어 질문과 SQL 사이의 의미 불일치를 줄이기 위해 클러스터 기반 스키마 검색과 중간 자연어 표현(Execution Description Language, EDL)을 결합한 프레임워크로, Text-to-EDL과 EDL-to-SQL의 두 단계로 문제를 분해하여 LLM의 추론력을 활용하고 의미 편향을 완화한다. SpiderUnion과 BirdUnion에서 SOTA 성능을 달성했다.


<details>
  <summary>Details</summary>
Motivation: 대규모 데이터베이스에서는 유사한 속성들이 많아 스키마 연결(schema linking)이 어렵고, NLQ에서 SQL로 변환할 때 의미적 표류(semantic drift)가 발생해 정확도가 저하된다. 이를 해결하려면 관련 스키마를 정확히 찾아내고, 자연어와 SQL 사이의 의미적 격차를 줄이는 중간 표현이 필요하다.

Method: (1) 클러스터 기반 대규모 스키마 검색으로 NLQ에 관련된 테이블과 칼럼을 선별해 스키마 불일치 문제를 완화한다. (2) Execution Description Language(EDL)라는 중간 자연어 표현을 도입해 Text-to-EDL과 EDL-to-SQL의 두 단계로 과제를 분해한다. 두 단계 모두 LLM을 활용해 추론 능력을 끌어내며, 중간 표현은 의미 편향을 줄이는 역할을 한다.

Result: 대규모·교차 도메인 벤치마크인 SpiderUnion과 BirdUnion에서 기존 기법들보다 우수한(논문 기준 SOTA) 성능을 달성했다. 구현 코드는 공개되어 재현이 가능하다.

Conclusion: 클러스터 기반 검색과 EDL 중간 표현의 조합은 대규모 DB 환경에서 Text-to-SQL의 스키마 연결 문제와 의미적 표류를 효과적으로 완화하며, 확장성과 성능 측면에서 유의미한 향상을 보인다.

Abstract: Recent advances in large language models (LLMs) have significantly improved
the accuracy of Text-to-SQL systems. However, a critical challenge remains: the
semantic mismatch between natural language questions (NLQs) and their
corresponding SQL queries. This issue is exacerbated in large-scale databases,
where semantically similar attributes hinder schema linking and semantic drift
during SQL generation, ultimately reducing model accuracy. To address these
challenges, we introduce CRED-SQL, a framework designed for large-scale
databases that integrates Cluster Retrieval and Execution Description. CRED-SQL
first performs cluster-based large-scale schema retrieval to pinpoint the
tables and columns most relevant to a given NLQ, alleviating schema mismatch.
It then introduces an intermediate natural language representation-Execution
Description Language (EDL)-to bridge the gap between NLQs and SQL. This
reformulation decomposes the task into two stages: Text-to-EDL and EDL-to-SQL,
leveraging LLMs' strong general reasoning capabilities while reducing semantic
deviation. Extensive experiments on two large-scale, cross-domain
benchmarks-SpiderUnion and BirdUnion-demonstrate that CRED-SQL achieves new
state-of-the-art (SOTA) performance, validating its effectiveness and
scalability. Our code is available at https://github.com/smduan/CRED-SQL.git

</details>


### [212] [From SALAMANDRA to SALAMANDRATA: BSC Submission for WMT25 General Machine Translation Shared Task](https://arxiv.org/abs/2508.12774)
*Javier Garcia Gilabert,Xixian Liao,Severino Da Dalt,Ella Bohman,Audrey Mash,Francesca De Luca Fornaciari,Irene Baucells,Joan Llop,Miguel Claramunt Argote,Carlos Escolano,Maite Melero*

Main category: cs.CL

TL;DR: SALAMANDRATA는 38개 유럽어 중심의 번역 성능 향상에 초점을 맞춘 2B/7B 스케일의 LLM 계열이다. 병렬 데이터로 지속적 사전학습(continual pre-training) 후 고품질 지침으로 감독 미세조정(supervised fine-tuning)을 적용했으며, WMT25 제출은 7B 모델을 기반으로 어휘 확장과 추가 학습·미세조정을 거쳐 품질 인식 디코딩(MBR, COMET 기반 재순위)을 사용했다. 모델은 Hugging Face에 공개되었다.


<details>
  <summary>Details</summary>
Motivation: 다수의 유럽어에 대해 번역 성능을 높이고 WMT25 번역 과제에서 경쟁력 있는 결과를 내기 위해 설계되었다. 기존 SALAMANDRA 계열을 개선하여 번역 특화 학습 파이프라인과 디코딩 전략을 통합하려는 목적.

Method: 두 단계 학습: (1) 병렬 데이터로 지속적 사전학습을 수행하여 번역 능력을 강화, (2) 고품질 지침 데이터로 감독 미세조정을 통해 지시응답 및 번역 품질을 개선. WMT25 제출을 위해 7B 모델의 어휘를 비유럽어로 확장하고, 추가적인 지속적 사전학습 및 미세조정 단계로 모든 방향의 번역 성능을 균형 맞춤. 디코딩은 Minimum Bayes Risk(MBR)와 COMET/COMET-KIWI 기반 튜닝 재순위를 사용하여 결과 품질을 높임.

Result: 7B 기반 BSC의 WMT25 제출을 수행했고, SALAMANDRATA 2B/7B 및 SALAMANDRATA-V2 모델을 공개함. 초록에선 구체적 수치(예: BLEU/COMET 점수, 언어별 성능, 계산 자원)가 제공되지 않아 정량적 성능 비교는 불가.

Conclusion: 번역 특화의 두 단계 학습과 품질 기반 디코딩을 결합한 접근은 실용적이고 재현 가능한 기여로 보인다. 그러나 데이터 규모, 하이퍼파라미터, 언어별 결과, 계산 비용과 같은 핵심 정보가 누락되어 있어 논문 본문에서 이러한 세부를 보강해야 재현성과 평가가 가능하다.

Abstract: In this paper, we present the SALAMANDRATA family of models, an improved
iteration of SALAMANDRA LLMs (Gonzalez-Agirre et al., 2025) specifically
trained to achieve strong performance in translation-related tasks for 38
European languages. SALAMANDRATA comes in two scales: 2B and 7B parameters. For
both versions, we applied the same training recipe with a first step of
continual pre-training on parallel data, and a second step of supervised
fine-tuning on high-quality instructions. The BSC submission to the WMT25
General Machine Translation shared task is based on the 7B variant of
SALAMANDRATA. We first adapted the model vocabulary to support the additional
non-European languages included in the task. This was followed by a second
phase of continual pre-training and supervised fine-tuning, carefully designed
to optimize performance across all translation directions for this year's
shared task. For decoding, we employed two quality-aware strategies: Minimum
Bayes Risk Decoding and Tuned Re-ranking using COMET and COMET-KIWI
respectively. We publicly release both the 2B and 7B versions of SALAMANDRATA,
along with the newer SALAMANDRATA-V2 model, on Hugging Face1

</details>


### [213] [HeteroRAG: A Heterogeneous Retrieval-Augmented Generation Framework for Medical Vision Language Tasks](https://arxiv.org/abs/2508.12778)
*Zhe Chen,Yusheng Liao,Shuyang Jiang,Zhiyuan Zhu,Haolin Li,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: MedAtlas와 HeteroRAG은 의료 멀티모달 보고서 저장소와 다양한 텍스트 코퍼스를 구축해, 모달리티별 CLIP과 다중 코퍼스 질의 생성기를 활용하여 이질적 지식원에서 효과적 검색을 수행하고, 지식 선호 조정으로 Med-LVLM을 정렬하여 사실성·신뢰성을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 의료 대형 시각-언어 모델은 임상 적용에서 유망하지만 사실성 부족과 신뢰성 문제로 실제 진단에서 위험을 초래한다. 기존 의료 멀티모달 RAG는 이질적 출처 간 효과적 검색을 수행하지 못해 관련성 낮은 보고서와 지식 공백이 문제다.

Method: 광범위한 멀티모달 보고서 저장소와 다양한 텍스트 코퍼스(=MedAtlas)를 구축하고, 모달리티별 CLIP을 도입해 각 보고서 유형에 맞는 효과적 검색을 수행한다. Multi-corpora Query Generator로 각 코퍼스에 맞춘 동적 질의 생성, Heterogeneous Knowledge Preference Tuning으로 교차 모달·다중 출처 지식 정렬을 수행해 Med-LVLM을 튜닝한다.

Result: 12개 데이터셋과 3개 모달리티에서 광범위한 실험을 수행한 결과, HeteroRAG는 대부분의 의료 비전-언어 벤치마크에서 SOTA 성능을 달성했으며 사실성 및 신뢰성이 크게 향상되었다.

Conclusion: 이질적 지식원을 통합한 RAG 프레임워크는 Med-LVLM의 진단 정확성과 신뢰성을 향상시키며, 모달리티 특화 검색과 다중 코퍼스 질의 생성, 지식 선호 튜닝이 핵심 구성요소이다.

Abstract: Medical large vision-language Models (Med-LVLMs) have shown promise in
clinical applications but suffer from factual inaccuracies and unreliable
outputs, posing risks in real-world diagnostics. While retrieval-augmented
generation has emerged as a potential solution, current medical multimodal RAG
systems are unable to perform effective retrieval across heterogeneous sources.
The irrelevance of retrieved reports affects the factuality of analysis, while
insufficient knowledge affects the credibility of clinical decision-making. To
bridge the gap, we construct MedAtlas, which includes extensive multimodal
report repositories and diverse text corpora. Based on it, we present
HeteroRAG, a novel framework that enhances Med-LVLMs through heterogeneous
knowledge sources. The framework introduces Modality-specific CLIPs for
effective report retrieval and a Multi-corpora Query Generator for dynamically
constructing queries for diverse corpora. Incorporating knowledge from such
multifaceted sources, Med-LVLM is then trained with Heterogeneous Knowledge
Preference Tuning to achieve cross-modality and multi-source knowledge
alignment. Extensive experiments across 12 datasets and 3 modalities
demonstrate that the proposed HeteroRAG achieves state-of-the-art performance
in most medical vision language benchmarks, significantly improving factual
accuracy and reliability of Med-LVLMs.

</details>


### [214] [Atom-Searcher: Enhancing Agentic Deep Research via Fine-Grained Atomic Thought Reward](https://arxiv.org/abs/2508.12800)
*Yong Deng,Guoqing Wang,Zhenzhe Ying,Xiaofeng Wu,Jinzhen Lin,Wenwen Xiong,Yuqin Dai,Shuo Yang,Zhanwei Zhang,Qiwen Wang,Yang Qin,Changhua Meng*

Main category: cs.CL

TL;DR: 핵심: 'Atomic Thought'로 추론을 미세 단위로 분해하고, 이 단위들을 지도하는 Reasoning Reward Models(RRMs)의 Atomic Thought Rewards(ATR)를 사용해 세분화된 보상을 제공한다. 이를 기반으로 한 RL 프레임워크 'Atom-Searcher'는 과정 중심의 ATR을 초기 우선화하고 점차 결과 보상으로 전환하는 커리큘럼 보상 스케줄을 적용해 다중 홉 추론과 전략적 탐색을 개선한다. 7개 벤치마크에서 SOTA 대비 일관된 성능 향상과 더 해석 가능한 인간 유사 추론을 보였다.


<details>
  <summary>Details</summary>
Motivation: 문제: LLM은 내부 지식의 정적성으로 복합 과제에서 한계가 있고, RAG는 외부 정보 접근을 보완하지만 다중 홉 추론·전략적 탐색에서 워크플로 제약으로 성능이 제한된다. 기존 에이전트형 연구는 결과 중심 RL에 의한 보상 희박성·그래디언트 충돌 등의 문제로 학습 효율과 성능 향상에 제약이 있다.

Method: 제안: (1) Atomic Thought — 추론을 기능적이고 미세한 단위로 분해하여 각 단위를 RRM이 평가하도록 함. (2) Reasoning Reward Models(RRMs)와 Atomic Thought Rewards(ATR)를 통해 단계별(과정 수준) 보상을 제공. (3) Atom-Searcher — ATR과 결과 보상을 통합하는 RL 프레임워크로, 커리큘럼식 보상 스케줄을 적용해 초기에 과정 보상을 우선하고 후기에 결과 보상을 강화. 테스트 시 연산 확장이 가능하도록 설계.

Result: 실험: 7개 벤치마크에서 기존 방법 대비 일관된 성능 개선을 보고. 학습 수렴 가속, 더 해석 가능한 추론 경로, 인간 유사한 사고 패턴 및 테스트 시 계산 확장성 등 장점 제시.

Conclusion: 의미: Atomic Thought는 RRMs의 지도 신호를 구체화해 보상 희박성과 그래디언트 충돌 문제를 완화하고, Atom-Searcher의 커리큘럼 보상으로 효율적·해석 가능한 에이전트형 연구를 가능하게 함. 전체적으로 다중 홉 추론·전략적 탐색 성능과 학습 효율을 향상시킨다.

Abstract: Large language models (LLMs) exhibit remarkable problem-solving abilities,
but struggle with complex tasks due to static internal knowledge.
Retrieval-Augmented Generation (RAG) enhances access to external information,
yet remains limited in multi-hop reasoning and strategic search due to rigid
workflows. Recent advancements in agentic deep research empower LLMs to
autonomously reason, search, and synthesize information. However, current
approaches relying on outcome-based reinforcement learning (RL) face critical
issues such as conflicting gradients and reward sparsity, limiting performance
gains and training efficiency. To address these, we first propose Atomic
Thought, a novel LLM thinking paradigm that decomposes reasoning into
fine-grained functional units. These units are supervised by Reasoning Reward
Models (RRMs), which provide Atomic Thought Rewards (ATR) for fine-grained
guidance. Building on this, we propose Atom-Searcher, a novel RL framework for
agentic deep research that integrates Atomic Thought and ATR. Atom-Searcher
uses a curriculum-inspired reward schedule, prioritizing process-level ATR
early and transitioning to outcome rewards, accelerating convergence on
effective reasoning paths. Experiments on seven benchmarks show consistent
improvements over the state-of-the-art. Key advantages include: (1)
Atom-Searcher scales computation at test-time. (2) Atomic Thought provides
supervision anchors for RRMs, bridging deep research tasks and RRMs. (3)
Atom-Searcher exhibits more interpretable, human-like reasoning patterns.

</details>


### [215] [When Alignment Hurts: Decoupling Representational Spaces in Multilingual Models](https://arxiv.org/abs/2508.12803)
*Ahmed Elshabrawy,Hour Kaing,Haiyue Song,Alham Fikri Aji,Hideki Tanaka,Masao Utiyama,Raj Dabre*

Main category: cs.CL

TL;DR: MSA(표준 아랍어)와 같은 고자원 표준 언어에 대한 표현적 얽힘이 방언 생성 성능을 저해할 수 있음을 보이고, 파인튜닝 중 표준어 서브스페이스를 온라인으로 추정해 투영으로 분리하는 기법을 제안해 방언 기계번역 품질을 유의미하게 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 고자원 표준 언어와 저자원 관련 변종(방언) 사이의 정렬이 항상 도움되는지에 대한 가정에 의문을 제기하고, 표준어에 대한 표현적 지배가 생성 능력을 제약할 수 있다는 인과적 증거를 확보하려 함.

Method: 파인튜닝 과정에서 표준어(MSA) 관련 표현 서브스페이스를 연속적으로 추정하는 온라인 변분 프로빙(framework)을 도입하고, 해당 서브스페이스로의 투영을 통해 표현을 분리(decoupling)하는 투영 기반 개입을 수행.

Result: 아랍어 25개 방언에서 표준 파인튜닝 대비 최대 +4.9 chrF++(평균 +2.0) 수준으로 생성 품질 개선을 달성했으며, 동시에 표준어 성능은 일부 손실되는 트레이드오프를 관측함.

Conclusion: 고자원 표준어에 의한 서브스페이스 지배가 관련 저자원 변종의 생성 능력을 제한한다는 인과적 증거를 제시하고, 지오메트릭·정보이론적 프로빙을 결합한 서브스페이스 수준 개입이 멀티언어·다중도메인 LLM의 표현 할당을 제어하는 실용적 도구가 될 수 있음을 제안한다.

Abstract: Alignment with high-resource standard languages is often assumed to aid the
modeling of related low-resource varieties. We challenge this assumption by
demonstrating that excessive representational entanglement with a dominant
variety, such as Modern Standard Arabic (MSA) in relation to Arabic dialects,
can actively hinder generative modeling. We present the first comprehensive
causal study of this phenomenon by analyzing and directly intervening in the
internal representation geometry of large language models (LLMs). Our key
contribution is an online variational probing framework that continuously
estimates the subspace of the standard variety during fine-tuning, enabling
projection-based decoupling from this space. While our study uses Arabic as a
case due to its unusually rich parallel resources across 25 dialects, the
broader motivation is methodological: dialectal MT serves as a controlled proxy
for generative tasks where comparable multi-variety corpora are unavailable.
Across 25 dialects, our intervention improves generation quality by up to +4.9
chrF++ and +2.0 on average compared to standard fine-tuning, despite a measured
tradeoff in standard-language performance. These results provide causal
evidence that subspace dominance by high-resource varieties can restrict
generative capacity for related varieties. More generally, we unify geometric
and information-theoretic probing with subspace-level causal interventions,
offering practical tools for improving generative modeling in closely related
language families and, more broadly, for controlling representational
allocation in multilingual and multi-domain LLMs. Code will be released.

</details>


### [216] [ding-01 :ARG0: An AMR Corpus for Spontaneous French Dialogue](https://arxiv.org/abs/2508.12819)
*Jeongwoo Kang,Maria Boritchev,Maximin Coavoux*

Main category: cs.CL

TL;DR: 프랑스어 일상 대화 코퍼스(DinG)에 AMR 주석을 부여하고, 즉흥 발화와 프랑스어 특유 문장구조를 다루기 위해 AMR을 확장하여 주석 지침을 제공하고, 코퍼스를 CC‑SA‑BY로 공개했으며 보조 주석 도구로 쓸 수 있는 AMR 파서를 학습·평가함.


<details>
  <summary>Details</summary>
Motivation: 프랑스어의 자발적(dialogue) 대화에 대한 의미 자원 부족과 기존 AMR이 즉흥 발화 현상 및 프랑스어 특유 구조를 충분히 포괄하지 못한다는 문제를 해결하려 함.

Method: Catan 보드게임 중 녹음된 자발적 대화(DinG)를 대상으로 AMR 주석을 수행. 자발 발화 및 프랑스어 특성(문장구조 등)을 처리하기 위한 AMR 확장 규칙을 설계하고 주석 지침으로 문서화. 얻은 데이터로 AMR 파서를 학습·평가하여 주석 보조 도구로 활용 가능하게 함.

Result: 확장된 AMR 지침과 주석된 프랑스어 대화 코퍼스를 CC‑SA‑BY로 공개. 학습된 AMR 파서는 초기 자동 주석을 제공해 사람 주석가의 작업을 지원할 수 있음을 보였음(구체적 성능 수치는 초록에 미기재).

Conclusion: 프랑스어 대화 의미 자원과 AMR 적용 범위를 확장한 실용적 기여를 제공. 다만 주석 품질(IAA), 데이터 규모, 파서 성능 수치 등은 본문에서 확인 필요.

Abstract: We present our work to build a French semantic corpus by annotating French
dialogue in Abstract Meaning Representation (AMR). Specifically, we annotate
the DinG corpus, consisting of transcripts of spontaneous French dialogues
recorded during the board game Catan. As AMR has insufficient coverage of the
dynamics of spontaneous speech, we extend the framework to better represent
spontaneous speech and sentence structures specific to French. Additionally, to
support consistent annotation, we provide an annotation guideline detailing
these extensions. We publish our corpus under a free license (CC-SA-BY). We
also train and evaluate an AMR parser on our data. This model can be used as an
assistance annotation tool to provide initial annotations that can be refined
by human annotators. Our work contributes to the development of semantic
resources for French dialogue.

</details>


### [217] [Context Matters: Incorporating Target Awareness in Conversational Abusive Language Detection](https://arxiv.org/abs/2508.12828)
*Raneem Alharthi,Rajwa Alharthi,Aiqi Jiang,Arkaitz Zubiaga*

Main category: cs.CL

TL;DR: 대응 트윗(답글)의 부모 트윗 문맥을 활용하면 학대성 언어 탐지 성능이 크게 향상된다. 특히 글 내용 기반 피처들이 계정 기반 피처보다 기여도가 높으며, 서로 다른 내용 기반 피처들을 결합하는 것이 최선이다.


<details>
  <summary>Details</summary>
Motivation: 기존 연구들은 대부분 단일 게시물만을 보고 학대성 여부를 판단해왔다. 그러나 소셜미디어의 학대는 대화 맥락에서 발생하는 경우가 많으므로, 부모 트윗(대화의 문맥)을 활용하면 더 정확한 판별이 가능할지 확인하고자 한다.

Method: 부모-답글 쌍(대화 교환)을 포함한 데이터셋을 구축하고, 답글을 학대/비학대 라벨로 분류. 답글만의 피처(본문·계정)와 부모 트윗에서 파생한 문맥 기반 피처들을 비교. 내용 기반 피처(본문 텍스트, 유사도 등)와 계정 기반 피처(사용자 속성 등)를 모두 고려하여 네 가지 분류 모델로 실험을 수행.

Result: 문맥 피처를 추가하면 답글만 사용할 때보다 성능이 상당히 개선되었다. 특히 내용 기반 피처들이 계정 기반 피처보다 분류 성능에 더 큰 기여를 했고, 여러 종류의 내용 기반 피처를 결합했을 때 성능이 가장 좋았다.

Conclusion: 대화 상황을 반영한 문맥화된 학대성 탐지 모델이 현실적 환경에서 더 효과적이다. 실무적으로는 부모 게시물의 텍스트 기반 정보를 포함하고 다양한 내용 기반 피처를 결합하는 것이 권장된다.

Abstract: Abusive language detection has become an increasingly important task as a
means to tackle this type of harmful content in social media. There has been a
substantial body of research developing models for determining if a social
media post is abusive or not; however, this research has primarily focused on
exploiting social media posts individually, overlooking additional context that
can be derived from surrounding posts. In this study, we look at conversational
exchanges, where a user replies to an earlier post by another user (the parent
tweet). We ask: does leveraging context from the parent tweet help determine if
a reply post is abusive or not, and what are the features that contribute the
most? We study a range of content-based and account-based features derived from
the context, and compare this to the more widely studied approach of only
looking at the features from the reply tweet. For a more generalizable study,
we test four different classification models on a dataset made of
conversational exchanges (parent-reply tweet pairs) with replies labeled as
abusive or not. Our experiments show that incorporating contextual features
leads to substantial improvements compared to the use of features derived from
the reply tweet only, confirming the importance of leveraging context. We
observe that, among the features under study, it is especially the
content-based features (what is being posted) that contribute to the
classification performance rather than account-based features (who is posting
it). While using content-based features, it is best to combine a range of
different features to ensure improved performance over being more selective and
using fewer features. Our study provides insights into the development of
contextualized abusive language detection models in realistic settings
involving conversations.

</details>


### [218] [It takes a village to write a book: Mapping anonymous contributions in Stephen Langton's Quaestiones Theologiae](https://arxiv.org/abs/2508.12830)
*Jan Maliszewski*

Main category: cs.CL

TL;DR: 중세 대학의 구전 강의 기록(reportationes)으로 구성된 스티븐 랭턴의 Quaestiones Theologiae 자료에 대해 HTR(광학 문자 인식) 파이프라인과 스타일로메트리(빈도어휘, 품사, 의사접미사)를 적용해 편집 층위를 밝히고 수작업 텍스트와 자동 추출 텍스트 성능을 비교하는 연구 설계안.


<details>
  <summary>Details</summary>
Motivation: 중세 학문 전통에서 보고문(reportationes)에 기반한 문헌 생성이 흔했으나, 편집·저작 층위에 관한 직접적 증거와 컴퓨팅 방법 적용 사례가 부족하므로, 자동화된 HTR과 스타일로메트리를 통해 편집층과 형성과정을 검증하려는 목적.

Method: Transformer 기반 OCR/HTR 파이프라인과 자동 전사 정렬을 구축하고, 가장 빈번한 단어(MFW), 품사 태그, ‘의사-접미사(pseudo-affixes)’를 특징으로 삼아 저자 속성화(귀속) 및 층위 분리를 시도. 수동 구성 데이터와 자동 추출 데이터의 성능을 직접 비교.

Result: 성공하면 자동화된 HTR→정렬→스타일로메트리 워크플로가 학술 라틴 코퍼스에 적용 가능한 재사용 템플릿을 제공하고, 수작업 대비 자동화의 실용성과 한계를 규명함.

Conclusion: 제안된 연구는 중세 스콜라 전통의 협업적 문학 생성에 대한 탐색적 분석 도구를 제공하고, transformer 기반 OCR 및 전사 정렬의 타당성을 시험하는 두 가지 방법론적 이득을 약속함.

Abstract: While the indirect evidence suggests that already in the early scholastic
period the literary production based on records of oral teaching (so-called
reportationes) was not uncommon, there are very few sources commenting on the
practice. This paper details the design of a study applying stylometric
techniques of authorship attribution to a collection developed from
reportationes -- Stephen Langton's Quaestiones Theologiae -- aiming to uncover
layers of editorial work and thus validate some hypotheses regarding the
collection's formation. Following Camps, Cl\'erice, and Pinche (2021), I
discuss the implementation of an HTR pipeline and stylometric analysis based on
the most frequent words, POS tags, and pseudo-affixes. The proposed study will
offer two methodological gains relevant to computational research on the
scholastic tradition: it will directly compare performance on manually composed
and automatically extracted data, and it will test the validity of
transformer-based OCR and automated transcription alignment for workflows
applied to scholastic Latin corpora. If successful, this study will provide an
easily reusable template for the exploratory analysis of collaborative literary
production stemming from medieval universities.

</details>


### [219] [Word Meanings in Transformer Language Models](https://arxiv.org/abs/2508.12863)
*Jumbly Grindrod,Peter Grindrod*

Main category: cs.CL

TL;DR: RoBERTa-base의 토큰 임베딩을 k-means(200)로 군집화한 결과, 임베딩 공간에는 감정·구체성 등 다양한 의미 정보가 포함되어 있어 '의미 제거' 가설을 약화시킨다.


<details>
  <summary>Details</summary>
Motivation: 변압기(트랜스포머) 언어모델이 단어별 의미를 저장하는 '렉시컬 스토어'와 유사한 구조를 갖는지, 즉 각 토큰이 의미 정보를 가진 고정된 엔트리를 갖는지를 검증하고자 함.

Method: RoBERTa-base의 토큰 임베딩을 추출해 k-means로 200개 군집화. 연구1에서는 군집을 수동으로 검사해 의미적 응집력 평가. 연구2에서는 군집이 valence, concreteness, iconicity, taboo, age of acquisition 같은 5개 심리언어학적 척도와 민감한지 통계적으로 검증.

Result: 토큰 임베딩 공간에 다양한 의미 정보가 풍부하게 인코딩되어 있음. 군집들은 여러 의미적 특성과 연관성을 보였음.

Conclusion: 트랜스포머 LLM이 의미 정보를 완전히 제거하거나 부정하는 극단적 가설(meaning eliminativist hypothesis)을 배제할 근거를 제공한다.

Abstract: We investigate how word meanings are represented in the transformer language
models. Specifically, we focus on whether transformer models employ something
analogous to a lexical store - where each word has an entry that contains
semantic information. To do this, we extracted the token embedding space of
RoBERTa-base and k-means clustered it into 200 clusters. In our first study, we
then manually inspected the resultant clusters to consider whether they are
sensitive to semantic information. In our second study, we tested whether the
clusters are sensitive to five psycholinguistic measures: valence,
concreteness, iconicity, taboo, and age of acquisition. Overall, our findings
were very positive - there is a wide variety of semantic information encoded
within the token embedding space. This serves to rule out certain "meaning
eliminativist" hypotheses about how transformer LLMs process semantic
information.

</details>


### [220] [An LLM Agent-Based Complex Semantic Table Annotation Approach](https://arxiv.org/abs/2508.12868)
*Yilin Geng,Shujing Wang,Chuan Wang,Keqing He,Yanfei Lv,Ying Wang,Zaiwen Feng,Xiaoying Bai*

Main category: cs.CL

TL;DR: LLM 기반 ReAct 에이전트를 사용해 컬럼 타입(CTA)과 셀 엔터티(CEA)를 주석화. 5개의 외부 도구와 맞춤 프롬프트로 테이블 특성에 따라 전략을 동적으로 선택하고, Levenshtein 거리로 중복 주석을 제거해 시간·토큰 비용을 크게 절감. Tough Tables와 BiodivTab에서 기존 방법보다 우수한 성능 보고.


<details>
  <summary>Details</summary>
Motivation: 열 이름·셀 값의 의미 손실, 온톨로지 계층 요구, 동음이의어, 철자 오류, 약어 등으로 STA 정확도가 저해됨. 복잡한 테이블에 유연하고 비용 효율적인 주석 방법 필요.

Method: ReAct 프레임워크 기반의 STA 에이전트를 설계. 5개 외부 도구(각기 다른 주석·검색·정규화 기능)와 맞춤형 프롬프트를 구현해 에이전트가 테이블 특성에 따라 적절한 도구·전략을 선택하도록 함. Levenshtein 거리로 유사·중복 엔터티를 병합해 불필요한 호출을 줄임.

Result: SemTab의 Tough Tables와 BiodivTab에서 기존 방법들보다 다양한 지표에서 우수한 성능을 달성. 중복 제거로 시간 비용 약 70% 절감, LLM 토큰 사용 약 60% 절감 보고.

Conclusion: 동적 도구 선택과 중복 제거를 결합한 LLM 기반 접근은 복잡한 STA 문제에 효과적이며 비용·시간 면에서 실용적. 다만 상세한 실험 설정·재현성·경계 사례 분석이 중요함.

Abstract: The Semantic Table Annotation (STA) task, which includes Column Type
Annotation (CTA) and Cell Entity Annotation (CEA), maps table contents to
ontology entities and plays important roles in various semantic applications.
However, complex tables often pose challenges such as semantic loss of column
names or cell values, strict ontological hierarchy requirements, homonyms,
spelling errors, and abbreviations, which hinder annotation accuracy. To
address these issues, this paper proposes an LLM-based agent approach for CTA
and CEA. We design and implement five external tools with tailored prompts
based on the ReAct framework, enabling the STA agent to dynamically select
suitable annotation strategies depending on table characteristics. Experiments
are conducted on the Tough Tables and BiodivTab datasets from the SemTab
challenge, which contain the aforementioned challenges. Our method outperforms
existing approaches across various metrics. Furthermore, by leveraging
Levenshtein distance to reduce redundant annotations, we achieve a 70%
reduction in time costs and a 60% reduction in LLM token usage, providing an
efficient and cost-effective solution for STA.

</details>


### [221] [A Stitch in Time Saves Nine: Proactive Self-Refinement for Language Models](https://arxiv.org/abs/2508.12903)
*Jinyi Han,Xinyi Wang,Haiquan Zhao,Tingyun li,Zishang Jiang,Sihang Jiang,Jiaqing Liang,Xin Lin,Weikang Zhou,Zeye Sun,Fei Yu,Yanghua Xiao*

Main category: cs.CL

TL;DR: PASR은 LLM이 생성 중에 내부 상태와 문맥을 이용해 능동적으로(언제·어떻게) 수정 결정을 내리도록 해 반복적 재생성 없이 효율성과 정확도를 동시에 개선하는 방법이다.


<details>
  <summary>Details</summary>
Motivation: 기존의 self-refinement는 고정 반복 횟수의 반응형 절차라 생성 중 문맥 변화에 맞춘 적시·적절한 수정이 어렵고 불필요한 비용이 발생한다. 인간이 실행 중 사고를 동적으로 다듬는 방식에서 영감을 받아 이를 개선하려 함.

Method: ProActive Self-Refinement(PASR)은 모델의 내부 상태(신뢰도·불확실성 신호 등)와 진화하는 문맥을 모니터링해 ‘수정 여부, 시점, 방식’을 능동적으로 결정하고 부분적 수정을 수행해 전체 응답을 재생성하지 않음.

Result: 10개 과제에서 광범위 실험을 수행했으며, 예로 Qwen3-8B에서 표준 생성 대비 토큰 소비를 평균 41.6% 절감하고 정확도를 8.2% 향상시켰다고 보고함.

Conclusion: PASR는 더 적은 토큰으로 더 나은 문제해결 성능을 달성해 효율성과 품질을 동시에 개선하며, 코드와 비교군을 공개해 재현 가능성을 제시함.

Abstract: Recent advances in self-refinement have demonstrated significant potential
for improving the outputs of large language models (LLMs) through iterative
refinement. However, most existing self-refinement methods rely on a reactive
process with a fixed number of iterations, making it difficult to determine the
optimal timing and content of refinement based on the evolving generation
context. Inspired by the way humans dynamically refine their thoughts during
execution, we propose ProActive Self-Refinement (PASR), a novel method that
enables LLMs to refine their outputs during the generation process. Unlike
methods that regenerate entire responses, PASR proactively decides whether,
when, and how to refine based on the model's internal state and evolving
context. We conduct extensive experiments on a diverse set of 10 tasks to
evaluate the effectiveness of PASR. Experimental results show that PASR
significantly enhances problem-solving performance. In particular, on Qwen3-8B,
PASR reduces average token consumption by 41.6 percent compared to standard
generation, while also achieving an 8.2 percent improvement in accuracy. Our
code and all baselines used in the paper are available in the GitHub.

</details>


### [222] [Analyzing Information Sharing and Coordination in Multi-Agent Planning](https://arxiv.org/abs/2508.12981)
*Tianyue Ou,Saujas Vaduguru,Daniel Fried*

Main category: cs.CL

TL;DR: LLM 기반 다중 에이전트 시스템(MAS)을 여행 계획 장기 과제에 적용해 ‘노트북’(공유 정보 저장소)과 ‘오케스트레이터’(조정자)를 도입함. 노트북은 환각(hallucination) 오류를 18% 감소시키고, 오케스트레이터는 특정 하위영역 오류를 최대 13.5% 추가로 줄여 전체 통과율을 단일 에이전트 7.5%에서 25%로 개선함.


<details>
  <summary>Details</summary>
Motivation: 장기·복합 제약을 가진 계획 문제는 상세 정보 유지와 상호 의존 제약 해결이 필요해 단일 LLM 에이전트로는 어려움. MAS로 역할 분담·대화가 가능하더라도 정보 일관성 유지와 조정 부족이 성능 저하를 유발할 수 있어 이를 보완할 방법을 찾고자 함.

Method: 여행 계획 벤치마크(TravelPlanner)를 사용해 LLM 기반 MAS를 구성. 정보 공유를 위한 공용 '노트북'과 에이전트 간 자유 대화를 감독·유도하는 '오케스트레이터'를 도입해 각각의 영향과 결합 효과를 실험적으로 평가.

Result: 노트북 적용 시 환각으로 인한 오류 18% 감소. 오케스트레이터는 특정 하위영역에서 최대 13.5% 추가 오류 감소 유도. 둘을 결합하면 최종 통과율 25%로, 단일 에이전트 기준 7.5% 대비 절대 17.5% 향상.

Conclusion: 구조화된 정보 공유(노트북)와 반성적 조정(오케스트레이터)이 장기 계획 과제에서 LLM 기반 MAS 성능을 유의미하게 향상시킬 수 있음을 시사함.

Abstract: Multi-agent systems (MASs) have pushed the boundaries of large language model
(LLM) agents in domains such as web research and software engineering. However,
long-horizon, multi-constraint planning tasks involve conditioning on detailed
information and satisfying complex interdependent constraints, which can pose a
challenge for these systems. In this study, we construct an LLM-based MAS for a
travel planning task which is representative of these challenges. We evaluate
the impact of a notebook to facilitate information sharing, and evaluate an
orchestrator agent to improve coordination in free form conversation between
agents. We find that the notebook reduces errors due to hallucinated details by
18%, while an orchestrator directs the MAS to focus on and further reduce
errors by up to 13.5% within focused sub-areas. Combining both mechanisms
achieves a 25% final pass rate on the TravelPlanner benchmark, a 17.5% absolute
improvement over the single-agent baseline's 7.5% pass rate. These results
highlight the potential of structured information sharing and reflective
orchestration as key components in MASs for long horizon planning with LLMs.

</details>


### [223] [WebMall -- A Multi-Shop Benchmark for Evaluating Web Agents](https://arxiv.org/abs/2508.13024)
*Ralph Peeters,Aaron Steiner,Luca Schwarz,Julian Yuya Caspary,Christian Bizer*

Main category: cs.CL

TL;DR: WebMall는 실제 크롤링된 상품을 넣은 4개 시뮬레이션 상점과 91개 교차-상점 쇼핑 과제로 구성된 비교 쇼핑 벤치마크이다. 기본/고급 과제를 통해 웹 에이전트의 네비게이션·추론·효율성을 평가하며, 최고 베이스라인은 기본 과제 완료율 75%/F1 87%, 고급 53%/F1 63%를 기록했다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 웹 에이전트가 실제 전자상거래에서 비교·구매 등의 장기 작업을 자동화할 잠재력이 있으나, 교차 상점 비교와 이질적 실세계 상품 데이터를 포함한 현실적인 벤치마크가 부족하다.

Method: Common Crawl에서 수집한 진짜 상품 오퍼로 채운 네 개의 시뮬레이션 상점을 만들고, 기본(검색·비교·장바구니·결제)과 고급(모호한 요구·대체품·호환성 탐색)을 포함한 91개 과제를 설계. 관찰 모달리티·메모리·기반 LLM(GPT-4.1, Claude Sonnet 4)을 달리한 8개 베이스라인을 평가함.

Result: 기본 과제 최고 완료율 75%·F1 87%, 고급 과제 최고 완료율 53%·F1 63%. WebMall은 기존 벤치마크보다 더 긴 상호작용 경로와 상점 간 비교를 요구하며, 상품 출처가 수백 개 상점으로 더 이질적임을 보임.

Conclusion: WebMall은 전자상거래 시나리오에서 내비게이션·추론·효율성 연구를 촉진하기 위한 실용적이고 현실적인 벤치마크로 공개되며, 웹 에이전트 성능 향상을 유도할 수 있다.

Abstract: LLM-based web agents have the potential to automate long-running web tasks,
such as finding offers for specific products in multiple online shops and
subsequently ordering the cheapest products that meet the users needs. This
paper introduces WebMall, a multi-shop online shopping benchmark for evaluating
the effectiveness and efficiency of web agents for comparison-shopping. WebMall
consists of four simulated online shops populated with authentic product offers
sourced from the Common Crawl, alongside a suite of 91 cross-shop tasks. These
tasks include basic tasks such as finding specific products in multiple shops,
performing price comparisons, adding items to the shopping cart, and completing
checkout. Advanced tasks involve searching for products based on vague
requirements, identifying suitable substitutes, and finding compatible
products. Compared to existing e-commerce benchmarks, such as WebShop or
ShoppingBench, WebMall introduces comparison-shopping tasks across multiple
shops. Furthermore, the product offers are more heterogeneous, as they
originate from hundreds of distinct real-world shops. The tasks in WebMall
require longer interaction trajectories than those in WebShop, while remaining
representative of real-world shopping behaviors. We evaluate eight baseline
agents on WebMall, varying in observation modality, memory utilization, and
underlying large language model (GPT 4.1 and Claude Sonnet 4). The
best-performing configurations achieve completion rates of 75% and 53%, and F1
scores of 87% and 63%, on the basic and advanced task sets, respectively.
WebMall is publicly released to facilitate research on web agents and to
promote advancements in navigation, reasoning, and efficiency within e-commerce
scenarios.

</details>


### [224] [Integrating Feedback Loss from Bi-modal Sarcasm Detector for Sarcastic Speech Synthesis](https://arxiv.org/abs/2508.13028)
*Zhu Li,Yuqing Zhang,Xiyuan Gao,Devraj Raghuvanshi,Nagendra Kumar,Shekhar Nayak,Matt Coler*

Main category: cs.CL

TL;DR: TTS 모델에 바이모달(음성+텍스트) 풍자(사카즘) 감지기의 피드백 손실을 통합하고, 읽기 말투로 사전학습된 음성합성 모델을 스타일이 다양한 데이터로 1차 미세조정한 뒤, 사카즘 전용 데이터로 2차 미세조정하는 방식으로 풍자 표현을 개선했다. 객관·주관 평가에서 품질, 자연스러움, 풍자인식 능력이 향상되었다고 보고한다.


<details>
  <summary>Details</summary>
Motivation: 사카즘은 미묘한 운율·억양 차이가 핵심이지만, 주석된 사카즘 음성 데이터가 부족하고 전통적 TTS는 이런 세밀한 프로소디를 잘 포착하지 못한다. 따라서 사카즘을 잘 전달하는 합성음성이 필요하다.

Method: (1) 바이모달 사카즘 검출기(음성+텍스트)를 학습해 사카즘 점수/신호를 얻고, 이를 TTS 훈련에 피드백 손실로 도입. (2) 읽기 음성으로 사전학습된 TTS를 두 단계로 파인튜닝: 먼저 다양한 스타일(사카즘 포함) 데이터로, 그다음 사카즘 전용 데이터로 세밀하게 조정.

Result: 객관적(아마도 음향적 지표) 및 주관적(청취자 MOS/판별 실험) 평가에서 제안 방법이 합성 음성의 품질과 자연스러움, 그리고 사카즘 전달력을 향상시켰다.

Conclusion: 바이모달 검출기에서 유래한 피드백 손실과 단계적 파인튜닝을 결합하면 사카즘 특성을 더 잘 포착한 합성음성을 얻을 수 있으며, 데이터 부족 문제를 전이학습으로 완화할 수 있다.

Abstract: Sarcastic speech synthesis, which involves generating speech that effectively
conveys sarcasm, is essential for enhancing natural interactions in
applications such as entertainment and human-computer interaction. However,
synthesizing sarcastic speech remains a challenge due to the nuanced prosody
that characterizes sarcasm, as well as the limited availability of annotated
sarcastic speech data. To address these challenges, this study introduces a
novel approach that integrates feedback loss from a bi-modal sarcasm detection
model into the TTS training process, enhancing the model's ability to capture
and convey sarcasm. In addition, by leveraging transfer learning, a speech
synthesis model pre-trained on read speech undergoes a two-stage fine-tuning
process. First, it is fine-tuned on a diverse dataset encompassing various
speech styles, including sarcastic speech. In the second stage, the model is
further refined using a dataset focused specifically on sarcastic speech,
enhancing its ability to generate sarcasm-aware speech. Objective and
subjective evaluations demonstrate that our proposed methods improve the
quality, naturalness, and sarcasm-awareness of synthesized speech.

</details>


### [225] [Can Large Models Teach Student Models to Solve Mathematical Problems Like Human Beings? A Reasoning Distillation Method via Multi-LoRA Interaction](https://arxiv.org/abs/2508.13037)
*Xinhe Li,Jiajun Liu,Peng Wang*

Main category: cs.CL

TL;DR: LoRID는 소형 언어모델(SLM)에 수학적 추론 능력을 전수하기 위한 다중 LoRA 상호작용 기반 증류법이다. Intuitive Reasoner(IR), Knowledge Generator(KG), Deep Reasoner(DR) 세 모듈을 학습시키고, IR과 DR의 출력 일치성을 검증·반복하여 SLM의 추론 성능을 크게 향상시킨다. GSM8K 등에서 SOTA 성능을 기록한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어모델(LLM)은 뛰어난 수학적 추론 능력을 보이나 매개변수가 매우 많아 실용성이 떨어진다. 기존 방법은 LLM이 생성한 대량 데이터를 SLM에 주입해 직관적(System 1) 학습을 모방하지만, 인간 학습의 또 다른 축인 지식을 획득하고 연습을 통해 강화하는 체계적(System 2) 학습을 충분히 반영하지 못한다.

Method: 먼저 LLM으로 문제와 추론을 받아 지식 강화 데이터셋을 만든다. SLM에는 여러 LoRA 블록을 도입해 (1) IR: 문제에 대해 직접 Chain-of-Thought를 생성, (2) KG: 문제에서 '지식'만 출력, (3) DR: KG의 지식을 입력으로 받아 심층적 추론을 수행하도록 각각 학습시킨다. IR과 DR의 출력을 비교해 불일치 시 반복 추론(상호 피드백)을 수행하여 랜덤성을 줄이고 성능을 끌어올린다.

Result: 제안한 LoRID는 여러 베이스 모델에서 SOTA 성능을 달성했다. 특히 GSM8K에서는 다섯 개 베이스 모델에 대해 각각 기존 두번째 방법 대비 2.3%, 16.1%, 2.4%, 12.3%, 1.8%의 정확도 향상을 보였다.

Conclusion: 모듈화된 LoRA 기반의 상호작용과 반복적 일관성 검증으로 SLM에 System 2 유사 학습을 부여해 수학적 추론 능력을 크게 향상시킨다. 경량화된 추론 증류의 유망한 접근법을 제시한다.

Abstract: Recent studies have demonstrated that Large Language Models (LLMs) have
strong mathematical reasoning abilities but rely on hundreds of billions of
parameters. To tackle the challenge of poor reasoning in Small Language Models
(SLMs), existing methods typically leverage LLMs to generate massive amounts of
data for cramming training. In psychology, they are akin to System 1 thinking,
which resolves reasoning problems rapidly based on experience and intuition.
However, human learning also requires System 2 thinking, where knowledge is
first acquired and then reinforced through practice. Inspired by such two
distinct modes of thinking, we propose a novel method based on the multi-LoRA
Interaction for mathematical reasoning Distillation (LoRID). First, we input
the question and reasoning of each sample into an LLM to create
knowledge-enhanced datasets. Subsequently, we train a LoRA block on the student
model as an Intuitive Reasoner (IR), which directly generates Chain-of-Thoughts
for problem-solving. Then, to imitate System 2 thinking, we train the Knowledge
Generator (KG) and Deep Reasoner (DR), respectively. The former outputs only
knowledge after receiving problems, while the latter uses that knowledge to
perform reasoning. Finally, to address the randomness in the generation of IR
and DR, we evaluate whether their outputs are consistent, and the inference
process needs to be iterated if not. This step can enhance the mathematical
reasoning ability of SLMs through mutual feedback. Experimental results show
that LoRID achieves state-of-the-art performance, especially on the GSM8K
dataset, where it outperforms the second-best method by 2.3%, 16.1%, 2.4%,
12.3%, and 1.8% accuracy across the five base models, respectively.

</details>


### [226] [Büyük Dil Modelleri için TR-MMLU Benchmarkı: Performans Değerlendirmesi, Zorluklar ve İyileştirme Fırsatları](https://arxiv.org/abs/2508.13044)
*M. Ali Bayram,Ali Arda Fincan,Ahmet Semih Gümüş,Banu Diri,Savaş Yıldırım,Öner Aytaş*

Main category: cs.CL

TL;DR: 저자들은 6,200개의 객관식 문항(62개 교과/주제)을 포함하는 TR-MMLU 벤치마크를 제안하여 터키어로 된 대형언어모델(LLM) 성능을 체계적으로 평가한다. 여러 SOTA 모델들을 평가하여 약점 영역을 도출하고 터키 NLP 연구의 표준을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 터키어처럼 자원 제한적인 언어에 대해 LLM 성능을 신뢰할 수 있게 평가할 표준화된 벤치마크가 부족하므로, 언어·개념적 능력을 평가할 도구가 필요하다.

Method: 터키 교육과정 기반으로 62개 섹션을 엄선하고 총 6,200개의 객관식 문제를 수집·정제하여 TR-MMLU를 구축한 뒤, 여러 최신 LLM(사전학습·상용 포함)을 동일한 설정에서 평가하여 성능을 비교·분석했다.

Result: 모델별 전반적 성능 지표와 섹션별 성능 분포를 제시하여 강·약점을 밝혀냈으며, 특정 교과나 난이도에서의 취약점이 관찰되었다.

Conclusion: TR-MMLU는 터키어 LLM 평가를 위한 표준 벤치마크로서 향후 모델 개발·미세조정·데이터셋 개선을 촉진할 것으로 기대된다.

Abstract: Language models have made significant advancements in understanding and
generating human language, achieving remarkable success in various
applications. However, evaluating these models remains a challenge,
particularly for resource-limited languages like Turkish. To address this
issue, we introduce the Turkish MMLU (TR-MMLU) benchmark, a comprehensive
evaluation framework designed to assess the linguistic and conceptual
capabilities of large language models (LLMs) in Turkish. TR-MMLU is based on a
meticulously curated dataset comprising 6,200 multiple-choice questions across
62 sections within the Turkish education system. This benchmark provides a
standard framework for Turkish NLP research, enabling detailed analyses of
LLMs' capabilities in processing Turkish text. In this study, we evaluated
state-of-the-art LLMs on TR-MMLU, highlighting areas for improvement in model
design. TR-MMLU sets a new standard for advancing Turkish NLP research and
inspiring future innovations.

</details>


### [227] [Doğal Dil İşlemede Tokenizasyon Standartları ve Ölçümü: Türkçe Üzerinden Büyük Dil Modellerinin Karşılaştırmalı Analizi](https://arxiv.org/abs/2508.13058)
*M. Ali Bayram,Ali Arda Fincan,Ahmet Semih Gümüş,Sercan Karakaş,Banu Diri,Savaş Yıldırım*

Main category: cs.CL

TL;DR: 형태학적으로 풍부한 저자원 언어(예: 터키어)에 대해 토크나이저 성능을 평가하는 새로운 프레임워크를 제안하고, TR-MMLU 데이터셋으로 실험한 결과 언어 특이적 토큰 비율(%TR)이 하위 과제 성능과 강한 상관을 보이며 단순한 모델 파라미터 확대만으로는 성능 향상이 보장되지 않음을 보였다.


<details>
  <summary>Details</summary>
Motivation: 토크나이제이션은 LLM의 언어·의미 포착 능력에 결정적 영향을 미치지만, 형태소가 다양하고 접사 변형이 많은 언어에 대한 표준 평가 지표와 실용적 기준이 부족하다. 터키어 같은 저자원 언어에 맞춘 토크나이저 품질 평가가 필요하다.

Method: TR-MMLU(6,200개 객관식 문항)를 사용해 여러 토크나이저를 비교·평가함. 기존 지표(어휘 크기, 토큰 수, 처리 시간)와 함께 새로 제안한 지표(%TR: 언어 특이적 토큰 비율, %Pure: 토큰 순수성)를 도입해 토크나이저가 언어적 구조를 얼마나 잘 보존하는지 측정하고 MMLU 성능과의 상관관계를 분석.

Result: %TR(언어 특이적 토큰 비율)이 MMLU 성능과 더 강한 상관을 보였고, %Pure는 상대적으로 약한 상관을 보였다. 또한 단순히 모델 파라미터 수를 늘리는 것만으로는 언어적 성능 향상이 보장되지 않았다.

Conclusion: 형태학적으로 복잡한 저자원 언어에 대해 언어 특이적 토큰화 지표를 포함한 실용적 평가 프레임워크를 제시하며, 토크나이저 설계에서 언어맞춤화가 중요함을 강조한다.

Abstract: Tokenization is a fundamental preprocessing step in Natural Language
Processing (NLP), significantly impacting the capability of large language
models (LLMs) to capture linguistic and semantic nuances. This study introduces
a novel evaluation framework addressing tokenization challenges specific to
morphologically-rich and low-resource languages such as Turkish. Utilizing the
Turkish MMLU (TR-MMLU) dataset, comprising 6,200 multiple-choice questions from
the Turkish education system, we assessed tokenizers based on vocabulary size,
token count, processing time, language-specific token percentages (\%TR), and
token purity (\%Pure). These newly proposed metrics measure how effectively
tokenizers preserve linguistic structures. Our analysis reveals that
language-specific token percentages exhibit a stronger correlation with
downstream performance (e.g., MMLU scores) than token purity. Furthermore,
increasing model parameters alone does not necessarily enhance linguistic
performance, underscoring the importance of tailored, language-specific
tokenization methods. The proposed framework establishes robust and practical
tokenization standards for morphologically complex languages.

</details>


### [228] [Evaluating ASR robustness to spontaneous speech errors: A study of WhisperX using a Speech Error Database](https://arxiv.org/abs/2508.13060)
*John Alderete,Macarious Kin Fung Hui,Aanchan Mohan*

Main category: cs.CL

TL;DR: SFUSED의 체계적 오류 주석을 이용해 ASR 성능을 진단하는 방법을 제시. WhisperX를 5,300개 문맥·음운 오류에 대해 평가하여 데이터베이스가 진단 도구로서 유효함을 보임.


<details>
  <summary>Details</summary>
Motivation: 표준 WER만으로는 ASR의 오류 유형·원인을 파악하기 어렵다. 자연발화의 실제 발화 오류를 정교하게 주석화한 SFUSED를 활용하면 모델 약점(언어 단위·문맥·수정 등)에 대한 세부 진단이 가능하다.

Method: SFUSED의 각 오류는 의도한 발화(intended)와 실제 산출(actual)로 태깅되고, 언어적 수준(음운·단어 등), 맥락 민감도, 열화된 단어, 단어수정, 단어·음절 단위 위치 등 여러 분류 차원을 포함한다. 이러한 분류 변수들이 ASR 평가에 주는 가치를 보기 위해 WhisperX의 전사 정확도를 5,300건의 문서화된 단어·음운 오류에 대해 분석했다.

Result: 구체적 수치(예: 정확도 비율)는 초록에 기재되어 있지 않으나, 분석 결과 SFUSED의 분류 변수가 ASR 성능의 취약 지점을 밝혀내는 데 유의미했으며, 특정 오류 유형·위치·맥락에서 WhisperX의 전사 실패가 집중됨을 보였다.

Conclusion: SFUSED는 ASR 시스템을 세부적으로 진단·평가하는 데 유용한 공개 자원이며, 다양한 언어층·맥락 변수를 이용한 분석이 모델 개선과 오류 유형별 대응 전략 수립에 기여할 수 있다.

Abstract: The Simon Fraser University Speech Error Database (SFUSED) is a public data
collection developed for linguistic and psycholinguistic research. Here we
demonstrate how its design and annotations can be used to test and evaluate
speech recognition models. The database comprises systematically annotated
speech errors from spontaneous English speech, with each error tagged for
intended and actual error productions. The annotation schema incorporates
multiple classificatory dimensions that are of some value to model assessment,
including linguistic hierarchical level, contextual sensitivity, degraded
words, word corrections, and both word-level and syllable-level error
positioning. To assess the value of these classificatory variables, we
evaluated the transcription accuracy of WhisperX across 5,300 documented word
and phonological errors. This analysis demonstrates the atabase's effectiveness
as a diagnostic tool for ASR system performance.

</details>


### [229] [Reinforced Context Order Recovery for Adaptive Reasoning and Planning](https://arxiv.org/abs/2508.13070)
*Long Ma,Fangwei Zhong,Yizhou Wang*

Main category: cs.CL

TL;DR: ReCOR은 강화학습 기반으로 토큰 예측 난이도를 스스로 추정해 데이터 의존적(적응형) 토큰 생성 순서를 복원하는 방법이다. 학습·추론 시 난이도가 쉬운(또는 적절한) 다음 토큰을 선택해 생성 순서를 동적으로 구성하며, 추론이 어려운 문제(추론·계획 등)에서 기존 고정 순서 모델들보다 성능이 우수하고 일부 경우에는 정답 순서(oracle)보다도 좋은 결과를 보인다.


<details>
  <summary>Details</summary>
Motivation: 현대의 인과(왼→오) 또는 무작위 순서 기반 디퓨전/생성 모델은 토큰을 고정된 순서로 출력하도록 학습되어 있어, 원래 문제에서 논리적으로 생성되어야 하는 순서와 불일치할 수 있다. 특정 추론·계획 문제는 적응형 토큰 생성 순서를 요구하며, 이를 V-정보 관점에서 설명하고자 한다.

Method: ReCOR는 주석 없이 텍스트 데이터로부터 적응형 생성 순서를 추출하는 강화학습 프레임워크다. 자기지도 신호로 토큰 예측 통계(각 미완성 토큰의 예측 난이도)를 이용해 강화학습 에이전트가 다음에 고를 토큰을 결정한다. 이 선택은 학습과 추론 양쪽에서 동일하게 적용된다.

Result: 여러 어려운 추론·계획 데이터셋에서 ReCOR가 기존의 고정/무작위 순서 기반 모델들과 비교해 우수한 성능을 보였고, 일부 경우에는 실제 정답 생성 순서로 감독학습한 오라클 모델보다도 더 높은 성능을 기록했다.

Conclusion: 데이터 의존적·적응형 생성 순서를 학습하는 것은 특정 클래스의 문제에서 모델의 처리 난이도를 낮추고 성능을 향상시킨다. ReCOR은 주석 없이도 그러한 순서를 복원할 수 있는 현실적이고 효과적인 방법임을 보인다.

Abstract: Modern causal language models, followed by rapid developments in discrete
diffusion models, can now produce a wide variety of interesting and useful
content. However, these families of models are predominantly trained to output
tokens with a fixed (left-to-right) or random order, which may deviate from the
logical order in which tokens are generated originally. In this paper, we
observe that current causal and diffusion models encounter difficulties in
problems that require adaptive token generation orders to solve tractably,
which we characterize with the $\mathcal{V}$-information framework. Motivated
by this, we propose Reinforced Context Order Recovery (ReCOR), a
reinforcement-learning-based framework to extract adaptive, data-dependent
token generation orders from text data without annotations. Self-supervised by
token prediction statistics, ReCOR estimates the hardness of predicting every
unfilled token and adaptively selects the next token during both training and
inference. Experiments on challenging reasoning and planning datasets
demonstrate the superior performance of ReCOR compared with baselines,
sometimes outperforming oracle models supervised with the ground-truth order.

</details>


### [230] [DocHPLT: A Massively Multilingual Document-Level Translation Dataset](https://arxiv.org/abs/2508.13079)
*Dayyán O'Brien,Bhavitvya Malik,Ona de Gibert,Pinzhen Chen,Barry Haddow,Jörg Tiedemann*

Main category: cs.CL

TL;DR: DocHPLT는 영어와 짝지어진 50개 언어 대상의 문서 수준 번역 데이터셋으로, 1억2400만 개 문서쌍(42.6억 문장)을 포함하며 원문 문서의 완전성을 보존해 구축되었다. LLM을 이 데이터로 파인튜닝하면 특히 자원 부족 언어에서 큰 성능 향상을 보였다.


<details>
  <summary>Details</summary>
Motivation: 문서 수준 번역 및 장기 문맥 모델링 연구를 확장하기 위해, 고자원 언어에만 한정된 기존 리소스를 넘어 더 많은 언어와 대규모 문서 데이터를 제공하려는 목적.

Method: 기존 웹 추출 파이프라인을 수정해 문서의 완전성을 유지(문서 내 비정렬 부분 포함)하면서 정렬된 문서 쌍을 추출; 문장 단위에서 문서를 재구성하는 대신 원본 문서 구조를 보존; 영어와 50개 언어 간 1.24억 문서쌍 수집 및 추가로 영어 비포함 보너스 쌍 제공 가능.

Result: 선행 실험으로 최적의 학습 문맥 전략을 규명한 뒤, DocHPLT로 파인튜닝한 LLM이 기존의 인스트럭션 튜닝된 기준 모델들보다 특히 저자원 언어에서 성능이 크게 향상됨을 보임.

Conclusion: 대규모 다국어 문서 수준 번역 데이터셋을 공개해 문서 수준 번역과 장기 문맥 연구를 촉진하며, 실용적 이득(특히 저자원 언어)과 연구 인프라를 제공.

Abstract: Existing document-level machine translation resources are only available for
a handful of languages, mostly high-resourced ones. To facilitate the training
and evaluation of document-level translation and, more broadly, long-context
modeling for global communities, we create DocHPLT, the largest publicly
available document-level translation dataset to date. It contains 124 million
aligned document pairs across 50 languages paired with English, comprising 4.26
billion sentences, with further possibility to provide 2500 bonus pairs not
involving English. Unlike previous reconstruction-based approaches that piece
together documents from sentence-level data, we modify an existing web
extraction pipeline to preserve complete document integrity from the source,
retaining all content including unaligned portions. After our preliminary
experiments identify the optimal training context strategy for document-level
translation, we demonstrate that LLMs fine-tuned on DocHPLT substantially
outperform off-the-shelf instruction-tuned baselines, with particularly
dramatic improvements for under-resourced languages. We open-source the dataset
under a permissive license, providing essential infrastructure for advancing
multilingual document-level translation.

</details>


### [231] [AutoBnB-RAG: Enhancing Multi-Agent Incident Response with Retrieval-Augmented Generation](https://arxiv.org/abs/2508.13118)
*Zefang Liu,Arman Anwar*

Main category: cs.CL

TL;DR: AutoBnB-RAG은 Backdoors & Breaches 테이블탑 환경에서 다중 에이전트 사고 대응 시뮬레이션에 검색 보강 생성(RAG)을 통합한 확장체이다. 에이전트가 외부 문서(기술 문서와 사건 리포트)를 검색해 증거를 활용할 수 있게 하여 의사결정 품질과 성공률을 높인다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 자율 에이전트는 시뮬레이션에서 유망하지만 외부 지식 접근 부족으로 인해 추론·근거 제시가 약하다. 실제 사이버 사고 대응에서는 신속하고 근거 있는 정보가 필요하므로, RAG를 통해 에이전트의 근거 기반 의사결정을 강화하려는 목표가 있다.

Method: AutoBnB 프레임워크를 RAG로 확장. 에이전트는 검색 쿼리를 발행하고 검색 결과를 대화에 포함시킬 수 있음. 두 가지 검색 코퍼스(RAG-Wiki: 기술 문서 기반, RAG-News: 내러티브형 사건 리포트) 사용. 8개 팀 구조(논쟁적 구성 포함)로 평가하고, 공개 침해 리포트를 바탕으로 실제형 사고 재현 실험 수행.

Result: 검색 보강은 다양한 조직 모델에서 의사결정 품질과 성공률을 개선함. 논쟁적 팀 구성은 비판적 추론을 촉진했고, 공개 리포트 기반 시뮬레이션에서 다단계 공격 재구성이 가능함을 보였다.

Conclusion: LLM 기반 다중 에이전트 시스템에 RAG를 통합하면 사이버 사고 대응 성능과 실용성이 향상된다. 외부 지식 통합의 가치와, 향후 더 풍부한 코퍼스·실시간 연동·인간-인-루프 검증 등의 확장 가능성을 시사한다.

Abstract: Incident response (IR) requires fast, coordinated, and well-informed
decision-making to contain and mitigate cyber threats. While large language
models (LLMs) have shown promise as autonomous agents in simulated IR settings,
their reasoning is often limited by a lack of access to external knowledge. In
this work, we present AutoBnB-RAG, an extension of the AutoBnB framework that
incorporates retrieval-augmented generation (RAG) into multi-agent incident
response simulations. Built on the Backdoors & Breaches (B&B) tabletop game
environment, AutoBnB-RAG enables agents to issue retrieval queries and
incorporate external evidence during collaborative investigations. We introduce
two retrieval settings: one grounded in curated technical documentation
(RAG-Wiki), and another using narrative-style incident reports (RAG-News). We
evaluate performance across eight team structures, including newly introduced
argumentative configurations designed to promote critical reasoning. To
validate practical utility, we also simulate real-world cyber incidents based
on public breach reports, demonstrating AutoBnB-RAG's ability to reconstruct
complex multi-stage attacks. Our results show that retrieval augmentation
improves decision quality and success rates across diverse organizational
models. This work demonstrates the value of integrating retrieval mechanisms
into LLM-based multi-agent systems for cybersecurity decision-making.

</details>


### [232] [Spot the BlindSpots: Systematic Identification and Quantification of Fine-Grained LLM Biases in Contact Center Summaries](https://arxiv.org/abs/2508.13124)
*Kawin Mayilvaghanan,Siddhant Gupta,Ayush Kumar*

Main category: cs.CL

TL;DR: 콜센터 통화 요약에서 LLM들이 특정 운영 관련 요소들(예: 말 더듬, 화자, 주제 등)에 대해 체계적 편향을 보이는지 규명하기 위해 BlindSpot을 제안. 15개 운영 편향 차원으로 분류하고 LLM을 0샷 분류기로 사용해 원문-요약 쌍의 범주 분포를 추출한 뒤 JS divergence(또는 Fidelity Gap)와 Coverage로 편향을 정량화. 2500개 실제 통화·20개 LLM 평가에서 모든 모델에 걸쳐 편향이 존재함을 관찰.


<details>
  <summary>Details</summary>
Motivation: 콜센터에서 매일 생성되는 대량의 자동 요약이 특정 통화 요소들을 과소·과다 반영하면 운영 리스크(고객 경험, 규정 준수, CS 대응 등)가 발생할 수 있으므로, '운영 편향'을 체계적으로 정의·측정하려는 목적.

Method: 운영 편향 15차원 분류법 수립 → 각 통화·요약 쌍에 대해 LLM을 0샷 분류기로 사용, 원문과 요약의 범주 분포 산출 → JS Divergence(Fidelity Gap)와 Coverage(원본 레이블 누락 비율)로 편향 정량화 → 2500개 실제 통화 데이터와 20개 LLM(다양한 스케일/패밀리)으로 실험.

Result: 모든 평가된 모델에서 여러 운영 차원에 대한 편향이 체계적으로 존재함(모델 크기·가족 불문). 몇몇 차원에서는 요약이 원문을 상당 부분 누락하거나 분포가 크게 왜곡됨.

Conclusion: BlindSpot은 콜센터 운영 관점의 편향을 진단하는 실용적 도구를 제공하며, 요약 시스템의 공정성·신뢰성을 개선하기 위한 추가 연구 및 완화책이 필요함.

Abstract: Abstractive summarization is a core application in contact centers, where
Large Language Models (LLMs) generate millions of summaries of call transcripts
daily. Despite their apparent quality, it remains unclear whether LLMs
systematically under- or over-attend to specific aspects of the transcript,
potentially introducing biases in the generated summary. While prior work has
examined social and positional biases, the specific forms of bias pertinent to
contact center operations - which we term Operational Bias - have remained
unexplored. To address this gap, we introduce BlindSpot, a framework built upon
a taxonomy of 15 operational bias dimensions (e.g., disfluency, speaker, topic)
for the identification and quantification of these biases. BlindSpot leverages
an LLM as a zero-shot classifier to derive categorical distributions for each
bias dimension in a pair of transcript and its summary. The bias is then
quantified using two metrics: Fidelity Gap (the JS Divergence between
distributions) and Coverage (the percentage of source labels omitted). Using
BlindSpot, we conducted an empirical study with 2500 real call transcripts and
their summaries generated by 20 LLMs of varying scales and families (e.g., GPT,
Llama, Claude). Our analysis reveals that biases are systemic and present
across all evaluated models, regardless of size or family.

</details>


### [233] [MuDRiC: Multi-Dialect Reasoning for Arabic Commonsense Validation](https://arxiv.org/abs/2508.13130)
*Kareem Elozeiri,Mervat Abassy,Preslav Nakov,Yuxia Wang*

Main category: cs.CL

TL;DR: They introduce MuDRiC, the first Arabic multi-dialect commonsense validation dataset, and adapt Graph Convolutional Networks to model semantic relations for improved Arabic commonsense validation.


<details>
  <summary>Details</summary>
Motivation: Arabic commonsense validation is underexplored, especially for regional dialects; existing resources focus on MSA while spoken dialects are prevalent and linguistically diverse, creating a gap for robust NLU in Arabic.

Method: Create a multi-dialect dataset (MuDRiC) covering MSA and several regional dialects; construct graph-based representations of sentence semantics and adapt GCN architectures to capture semantic relationships for commonsense validation; train and evaluate models on MuDRiC.

Result: The adapted GCN approach outperforms baselines on Arabic commonsense validation tasks, demonstrating better semantic relationship modeling across dialects.

Conclusion: Providing a multi-dialect dataset and a GCN-based method advances Arabic commonsense reasoning, addressing linguistic diversity and improving validation performance; this work supplies resources and methods for future Arabic NLU research.

Abstract: Commonsense validation evaluates whether a sentence aligns with everyday
human understanding, a critical capability for developing robust natural
language understanding systems. While substantial progress has been made in
English, the task remains underexplored in Arabic, particularly given its rich
linguistic diversity. Existing Arabic resources have primarily focused on
Modern Standard Arabic (MSA), leaving regional dialects underrepresented
despite their prevalence in spoken contexts. To bridge this gap, we present two
key contributions: (i) we introduce MuDRiC, an extended Arabic commonsense
dataset incorporating multiple dialects, and (ii) a novel method adapting Graph
Convolutional Networks (GCNs) to Arabic commonsense reasoning, which enhances
semantic relationship modeling for improved commonsense validation. Our
experimental results demonstrate that this approach achieves superior
performance in Arabic commonsense validation. Our work enhances Arabic natural
language understanding by providing both a foundational dataset and a novel
method for handling its complex variations. To the best of our knowledge, we
release the first Arabic multi-dialect commonsense reasoning dataset.

</details>


### [234] [Improving Detection of Watermarked Language Models](https://arxiv.org/abs/2508.13131)
*Dara Bahri,John Wieting*

Main category: cs.CL

TL;DR: LLM 생성물 검출을 위해 워터마킹과 비-워터마크 검출기를 결합한 하이브리드 방식이 제안되며, 엔트로피 제한 상황(예: instruction tuning, RLHF)에서도 단일 방식보다 검출 성능이 향상됨을 보인다.


<details>
  <summary>Details</summary>
Motivation: 워터마크 검출 성능은 모델이 생성할 수 있는 엔트로피와 입력 프롬프트 집합에 크게 의존한다. 하지만 실제로는 instruction tuning이나 RLHF로 인해 생성 엔트로피가 제한되어 워터마크만으로는 검출이 어려운 경우가 많다. 이를 보완하고 검출 신뢰도를 높이고자 함.

Method: 워터마크 기반 검출기와 비-워터마크(예: 통계적·학습 기반) 검출기를 여러 방식으로 결합한 하이브리드 스킴을 설계·실험함. 서로 다른 결합 전략과 조건에서 성능을 비교 평가함.

Result: 하이브리드 방식이 단독 워터마크 검출기와 단독 비-워터마크 검출기 모두보다 넓은 실험 조건에서 검출 성능 향상을 보였다. 특히 엔트로피가 낮은 상황에서도 이득이 관찰됨.

Conclusion: 워터마크와 비-워터마크 검출기의 결합은 워터마크만으로는 한계가 있는 실제 환경에서 더 강건한 LLM 생성물 검출 전략을 제공한다.

Abstract: Watermarking has recently emerged as an effective strategy for detecting the
generations of large language models (LLMs). The strength of a watermark
typically depends strongly on the entropy afforded by the language model and
the set of input prompts. However, entropy can be quite limited in practice,
especially for models that are post-trained, for example via instruction tuning
or reinforcement learning from human feedback (RLHF), which makes detection
based on watermarking alone challenging. In this work, we investigate whether
detection can be improved by combining watermark detectors with non-watermark
ones. We explore a number of hybrid schemes that combine the two, observing
performance gains over either class of detector under a wide range of
experimental conditions.

</details>


### [235] [OptimalThinkingBench: Evaluating Over and Underthinking in LLMs](https://arxiv.org/abs/2508.13141)
*Pranjal Aggarwal,Seungone Kim,Jack Lanchantin,Sean Welleck,Jason Weston,Ilia Kulikov,Swarnadeep Saha*

Main category: cs.CL

TL;DR: 논문은 LLM의 '과사고(overthinking)'와 '과소사고(underthinking)'를 동시에 평가하는 통합 벤치마크 OptimalThinkingBench를 제안하고, 두 하위 벤치마크(OverthinkingBench, UnderthinkingBench)와 사고 조정 정확도 지표로 33개 모델을 평가해 현재 어떤 모델도 효율성과 성능을 동시에 최적으로 달성하지 못함을 보인다.


<details>
  <summary>Details</summary>
Motivation: 생각하는 모델(thinking)은 단순 질의에 불필요하게 많은 계산(토큰)을 소비하고, 생각하지 않는 모델(non-thinking)은 난이도 높은 추론에서 성능이 부족해 사용자가 모델을 선택해야 하는 문제를 해결하기 위해, 성능과 효율을 함께 평가하는 통합 벤치가 필요함.

Method: 72개 도메인의 단순 질의를 모은 OverthinkingBench와 11개 난이도 높은 추론 과제를 포함한 UnderthinkingBench를 구성하고, '사고 조정 정확도' 같은 새로운 지표를 도입해 33개 thinking/non-thinking 모델을 평가. 또한 최적 사고를 유도하는 여러 방법(구체적 기법 명시 없음)을 실험.

Result: 어떤 모델도 두 하위 벤치마크에서 동시에 최적화되지 않음. 큰 thinking 모델들은 단순 질의에서 수백 토큰을 과다 사용하며 성능 향상이 없음. 큰 non-thinking 모델들은 과소사고로 작은 thinking 모델보다도 성능이 낮음. 제안된 개선 방법들은 한 쪽에서 개선될 때 다른 쪽에서 악화되는 트레이드오프를 보임.

Conclusion: 효율성과 성능을 동시에 만족하는 통합적이고 최적으로 사고하는 모델 설계가 필요하며, 현재 방법론은 트레이드오프 문제를 완전히 해결하지 못함.

Abstract: Thinking LLMs solve complex tasks at the expense of increased compute and
overthinking on simpler problems, while non-thinking LLMs are faster and
cheaper but underthink on harder reasoning problems. This has led to the
development of separate thinking and non-thinking LLM variants, leaving the
onus of selecting the optimal model for each query on the end user. In this
work, we introduce OptimalThinkingBench, a unified benchmark that jointly
evaluates overthinking and underthinking in LLMs and also encourages the
development of optimally-thinking models that balance performance and
efficiency. Our benchmark comprises two sub-benchmarks: OverthinkingBench,
featuring simple queries in 72 domains, and UnderthinkingBench, containing 11
challenging reasoning tasks. Using novel thinking-adjusted accuracy metrics, we
perform extensive evaluation of 33 different thinking and non-thinking models
and show that no model is able to optimally think on our benchmark. Thinking
models often overthink for hundreds of tokens on the simplest user queries
without improving performance. In contrast, large non-thinking models
underthink, often falling short of much smaller thinking models. We further
explore several methods to encourage optimal thinking, but find that these
approaches often improve on one sub-benchmark at the expense of the other,
highlighting the need for better unified and optimal models in the future.

</details>


### [236] [Signal and Noise: A Framework for Reducing Uncertainty in Language Model Evaluation](https://arxiv.org/abs/2508.13144)
*David Heineman,Valentin Hofmann,Ian Magnusson,Yuling Gu,Noah A. Smith,Hannaneh Hajishirzi,Kyle Lo,Jesse Dodge*

Main category: cs.CL

TL;DR: 대규모 언어모델 개발에서 벤치마크의 신뢰성은 ‘signal(모델 성능 분별력)’과 ‘noise(무작위 변동 민감도)’로 설명할 수 있다. 이 논문은 두 지표를 정의·측정하고, 지표 변경(예: 정확도→perplexity), 노이즈한 하위과제 필터링, 중간체크포인트 평균화 같은 개입이 신뢰도를 높이고 스케일링 법칙 예측오차를 줄인다는 것을 30개 벤치·375개 모델(900K 평가결과) 실험으로 보였다.


<details>
  <summary>Details</summary>
Motivation: LLM 개발은 비용이 크고 대부분 작은 규모의 실험으로 설계 결정을 내리므로, 그 결정을 잘 이끌어줄 신뢰성 높은 평가벤치가 필요하다. 현재 벤치들은 동일한 결정을 내리기엔 신호·노이즈 특성이 충분히 분석되지 않았다.

Method: 벤치마크의 'signal'과 'noise'를 정의하고 30개 벤치, 375개 오픈 웨이트 모델(60M~32B)을 이용해 각 벤치의 signal·noise를 측정. 벤치 신뢰도와 스케일링 법칙 예측오차를 비교. 세 가지 개입을 시험: (1) 평가 지표 변경(예: 정확도→perplexity), (2) 노이즈한 하위과제 필터링으로 합산 신호대잡음비 개선, (3) 모델 중간체크포인트 출력 평균화로 노이즈 감소.

Result: 신호대잡음비가 높은 벤치가 소규모 실험에서 더 일관된 모델 선택을 제공했고, 노이즈가 적은 벤치는 스케일링 법칙 예측오차가 낮았다. 퍼플렉시티 같은 연속적·정보량 높은 지표로 바꾸거나 노이즈한 서브태스크를 제거하고 체크포인트 평균화를 적용하면 신뢰도와 예측성능이 향상되었다. 30개 벤치·375모델·900K 평가 결과(200M 인스턴스)를 공개.

Conclusion: 벤치 설계·선택 시 높은 signal과 낮은 noise를 목표로 해야 하며, 지표 선택·하위과제 필터링·체크포인트 평균화 같은 실용적 개입이 벤치의 유용성을 크게 개선한다.

Abstract: Developing large language models is expensive and involves making decisions
with small experiments, typically by evaluating on large, multi-task evaluation
suites. In this work, we analyze specific properties which make a benchmark
more reliable for such decisions, and interventions to design higher-quality
evaluation benchmarks. We introduce two key metrics that show differences in
current benchmarks: signal, a benchmark's ability to separate better models
from worse models, and noise, a benchmark's sensitivity to random variability
between training steps. We demonstrate that benchmarks with a better
signal-to-noise ratio are more reliable when making decisions at small scale,
and those with less noise have lower scaling law prediction error. These
results suggest that improving signal or noise will lead to more useful
benchmarks, so we introduce three interventions designed to directly affect
signal or noise. For example, we propose that switching to a metric that has
better signal and noise (e.g., perplexity rather than accuracy) leads to better
reliability and improved scaling law error. We also find that filtering noisy
subtasks, to improve an aggregate signal-to-noise ratio, leads to more reliable
multi-task evaluations. We also find that averaging the output of a model's
intermediate checkpoints to reduce noise leads to consistent improvements. We
conclude by recommending that those creating new benchmarks, or selecting which
existing benchmarks to use, aim for high signal and low noise. We use 30
benchmarks for these experiments, and 375 open-weight language models from 60M
to 32B parameters, resulting in a new, publicly available dataset of 900K
evaluation benchmark results, totaling 200M instances.

</details>


### [237] [RepreGuard: Detecting LLM-Generated Text by Revealing Hidden Representation Patterns](https://arxiv.org/abs/2508.13152)
*Xin Chen,Junchao Wu,Shu Yang,Runzhe Zhan,Zeyu Wu,Ziyang Luo,Di Wang,Min Yang,Lidia S. Chao,Derek F. Wong*

Main category: cs.CL

TL;DR: RepreGuard는 LLM의 내부 표현(activation)을 이용해 LLM 생성 텍스트(LGT)와 인간 작성 텍스트(HWT)를 구분하는 통계 기반 탐지 기법으로, surrogate 모델로부터 대표적 activation 방향을 추출하여 텍스트 표현을 해당 방향으로 사영(projection)한 점수로 분류한다. ID/OOD 모두에서 평균 94.92% AUROC를 기록했다.


<details>
  <summary>Details</summary>
Motivation: 기존 탐지법은 OOD 상황에서 견고성이 부족하므로, 더 원천적이고 풍부한 특징을 담고 있는 LLM 내부 표현이 LGT와 HWT 사이의 통계적 차이를 더 잘 포착할 것이라는 가설을 검증하려 함.

Method: (1) surrogate 모델을 사용해 LGT와 HWT의 내부 표현(activation)을 수집, (2) 두 집단을 잘 구분하는 activation 방향(특징)을 추출(특정 통계적 방법으로), (3) 새로운 텍스트 표현을 그 방향으로 사영해 점수를 계산하고 사전 계산된 임계값과 비교해 분류.

Result: 제안 방법(RepreGuard)은 여러 baseline을 능가하며 ID 및 OOD 시나리오에서 평균 94.92% AUROC를 달성했고, 다양한 텍스트 길이와 일반적 공격에 대해 높은 견고성을 보임.

Conclusion: LLM 내부 표현은 LGT 탐지에 강력한 신호를 제공하며, 통계적 사영 기반의 간단한 분류기로도 높은 성능과 OOD 견고성을 얻을 수 있다.

Abstract: Detecting content generated by large language models (LLMs) is crucial for
preventing misuse and building trustworthy AI systems. Although existing
detection methods perform well, their robustness in out-of-distribution (OOD)
scenarios is still lacking. In this paper, we hypothesize that, compared to
features used by existing detection methods, the internal representations of
LLMs contain more comprehensive and raw features that can more effectively
capture and distinguish the statistical pattern differences between
LLM-generated texts (LGT) and human-written texts (HWT). We validated this
hypothesis across different LLMs and observed significant differences in neural
activation patterns when processing these two types of texts. Based on this, we
propose RepreGuard, an efficient statistics-based detection method.
Specifically, we first employ a surrogate model to collect representation of
LGT and HWT, and extract the distinct activation feature that can better
identify LGT. We can classify the text by calculating the projection score of
the text representations along this feature direction and comparing with a
precomputed threshold. Experimental results show that RepreGuard outperforms
all baselines with average 94.92% AUROC on both in-distribution (ID) and OOD
scenarios, while also demonstrating robust resilience to various text sizes and
mainstream attacks. Data and code are publicly available at:
https://github.com/NLP2CT/RepreGuard

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [238] [Finite Automata Extraction: Low-data World Model Learning as Programs from Gameplay Video](https://arxiv.org/abs/2508.11836)
*Dave Goel,Matthew Guzdial,Anurag Sarkar*

Main category: cs.AI

TL;DR: FAE는 게임 플레이 비디오에서 신경-심볼릭 세계 모델을 학습해, Retro Coder라는 DSL(도메인 특화 언어)로 환경 동역학을 프로그램 형태로 추출한다. 종래 DSL 기반 접근보다 더 정밀한 환경 모델과 더 일반화된 코드를 산출한다.


<details>
  <summary>Details</summary>
Motivation: 신경망 기반 세계 모델은 환경 동역학을 압축해 학습하지만, 학습된 표현의 전달(transfer)과 설명 가능성이 낮아 실제 적용과 분석에 제약이 있다. 이를 개선하기 위해 기호적인 프로그램 형태로 동역학을 표현하려는 동기가 있다.

Method: Finite Automata Extraction(FAE) 기법을 도입해 게임 플레이 비디오로부터 시간·공간 정보를 압축한 표현을 추출하고, 이를 Retro Coder라는 신규 DSL의 프로그램(유한오토마타 스타일)으로 변환한다. 신경·기호 하이브리드 방식을 사용해 신경 표현의 유연성과 기호적 해석력을 결합한다.

Result: 추상에 따르면 FAE는 기존 세계 모델보다 환경을 더 정밀하게 모델링하고, 종래 DSL 기반 방법들보다 더 일반화된(범용성 있는) 코드를 생성한다.

Conclusion: FAE와 Retro Coder 조합은 세계 모델의 설명성·전달성·정밀도를 개선하는 실용적인 신경-심볼릭 접근을 제시하며, 게임 환경 같은 시공간적 동역학을 프로그램으로 추출하는 새로운 방향을 제공한다.

Abstract: World models are defined as a compressed spatial and temporal learned
representation of an environment. The learned representation is typically a
neural network, making transfer of the learned environment dynamics and
explainability a challenge. In this paper, we propose an approach, Finite
Automata Extraction (FAE), that learns a neuro-symbolic world model from
gameplay video represented as programs in a novel domain-specific language
(DSL): Retro Coder. Compared to prior world model approaches, FAE learns a more
precise model of the environment and more general code than prior DSL-based
approaches.

</details>


### [239] [EvoCut: Strengthening Integer Programs via Evolution-Guided Language Models](https://arxiv.org/abs/2508.11850)
*Milad Yazdani,Mahdi Mostajabdaveh,Samin Aref,Zirui Zhou*

Main category: cs.AI

TL;DR: EvoCut은 LLM 기반 초기화와 진화적 탐색을 결합해 정수계획의 가속컷(cut)을 자동 생성한다. 사람 손을 빌리지 않고도 최적성 갭을 17–57% 감소시키고 같은 해를 더 빠르게(최대 4배) 얻거나 동일 시간에 더 나은 해를 얻는다.


<details>
  <summary>Details</summary>
Motivation: 정수계획은 NP-난제이며, 실무에서는 성능을 크게 높이는 수작업 컷 설계가 중요하지만 전문성이 요구되고 자동화되어 있지 않다. 이 과정을 자동화하면 실용적 성능 향상이 가능하다.

Method: LLM으로 다양성 있는 컷 후보 집단을 초기화하고, 검증 집합에서 최적해 보존 여부와 분수해 제거 능력을 실험적으로 평가한다. 컷의 유틸리티는 솔버의 최적성 갭 감소량으로 측정하며, 진화 연산(교차·변이)으로 후보군을 반복적으로 개선한다.

Result: 고정 시간 내 최적성 갭 17–57% 감소, 동일 해에 도달하는 시간 최대 4배 단축, 같은 시간에 더 높은 품질의 해 획득. 인간 전문 지식 불필요, 미지의 인스턴스에 일반화 가능. 코드 공개.

Conclusion: EvoCut은 컷 생성의 창의적 전문가 작업을 자동화하여 실용적 이득을 제공하며, LLM과 진화적 최적화의 결합이 정수계획 가속에 효과적임을 보였다.

Abstract: Integer programming lies at the heart of crucial combinatorial optimization
tasks but remains challenging due to its NP-hard nature. An effective approach
for practically solving integer programs is the manual design of acceleration
cuts, i.e. inequalities that improve solver performance. However, this creative
process demands deep expertise and is yet to be automated. Our proposed
framework, EvoCut, automates the generation of acceleration cuts by combining
large language models (LLMs) with an evolutionary search. EvoCut (i)
initializes a diverse population of candidate cuts via an LLM-based initializer
agent; (ii) for each cut empirically evaluates both preservation of the optimal
solution and its ability to cut off fractional solutions across a verification
set; and (iii) iteratively refines the population through evolutionary
crossover and mutation agents. We quantify each cut's utility by its relative
reduction in the solver's optimality gap. Our comparisons against standard
integer programming practice show that EvoCut reduces optimality gap by 17-57%
within a fixed time. It obtains the same solutions up to 4 times as fast, and
obtains higher-quality solutions within the same time limit. Requiring no human
expert input, EvoCut reliably generates, improves, and empirically verifies
cuts that generalize to unseen instances. The code is available at
https://github.com/milad1378yz/EvoCut.

</details>


### [240] [LARC: Towards Human-level Constrained Retrosynthesis Planning through an Agentic Framework](https://arxiv.org/abs/2508.11860)
*Frazier N. Baker,Daniel Adu-Ampratwum,Reza Averly,Botao Yu,Huan Sun,Xia Ning*

Main category: cs.AI

TL;DR: LARC는 제약 조건을 반영한 합성 경로 탐색을 위해 에이전트 기반 제약 평가(Agent-as-a-Judge)를 도입한 최초의 LLM 에이전트 프레임워크로, 48개 과제(3종 제약)에서 72.9% 성공률을 기록하며 기존 LLM 기반 방법보다 크게 우수함.


<details>
  <summary>Details</summary>
Motivation: 제약(상업적 출발물질, 특정 반응 금지 등)이 있는 실제 합성 경로 탐색은 복잡하고 실험적 제약을 만족해야 하므로, 도구로 근거를 제공하는 LLM 에이전트가 의사결정을 정교하게 만들어 실무에 도움될 수 있다는 점.

Method: LARC는 계획 단계에서 에이전트적 피드백을 주는 Agent-as-a-Judge를 통합하여, 도구 기반(reasoning-with-tools) 근거를 바탕으로 제약 충족 여부를 평가하고 그 평가를 다시 경로 생성에 반영하여 탐색을 제약함.

Result: 48개 제약 과제(3종 제약)에 대해 LARC가 72.9% 성공률을 달성했으며, LLM 기준선들을 크게 앞지르고 인간 전문가 수준에 근접한 성능을 더 짧은 시간에 보임.

Conclusion: LARC는 제약을 고려한 회귀합성(retrosynthesis)에서의 에이전트적 제약 검증을 실현한 최초의 프레임워크로, 확장 가능하며 인간 전문가의 도우미 또는 공연구자(co-scientist)로 발전 가능하다.

Abstract: Large language model (LLM) agent evaluators leverage specialized tools to
ground the rational decision-making of LLMs, making them well-suited to aid in
scientific discoveries, such as constrained retrosynthesis planning.
Constrained retrosynthesis planning is an essential, yet challenging, process
within chemistry for identifying synthetic routes from commercially available
starting materials to desired target molecules, subject to practical
constraints. Here, we present LARC, the first LLM-based Agentic framework for
Retrosynthesis planning under Constraints. LARC incorporates agentic constraint
evaluation, through an Agent-as-a-Judge, directly into the retrosynthesis
planning process, using agentic feedback grounded in tool-based reasoning to
guide and constrain route generation. We rigorously evaluate LARC on a
carefully curated set of 48 constrained retrosynthesis planning tasks across 3
constraint types. LARC achieves a 72.9% success rate on these tasks, vastly
outperforming LLM baselines and approaching human expert-level success in
substantially less time. The LARC framework is extensible, and serves as a
first step towards an effective agentic tool or a co-scientist to human experts
for constrained retrosynthesis.

</details>


### [241] [QuarkMed Medical Foundation Model Technical Report](https://arxiv.org/abs/2508.11894)
*Ao Li,Bin Yan,Bingfeng Cai,Chenxi Li,Cunzhong Zhao,Fugen Yao,Gaoqiang Liu,Guanjun Jiang,Jian Xu,Liang Dong,Liansheng Sun,Rongshen Zhang,Xiaolei Gui,Xin Liu,Xin Shang,Yao Wu,Yu Cao,Zhenxin Ma,Zhuang Jia*

Main category: cs.AI

TL;DR: QuarkMed는 의료 데이터 정제, 의료용 RAG, 그리고 대규모 검증 가능한 RL 파이프라인을 결합해 학습한 의료 파운데이션 모델로, 중국 의사국가고시에서 70% 정확도를 기록하며 다양한 의료 벤치마크에서 일반화 성능을 보였고 ai.quark.cn을 통해 수백만 사용자에게 서비스 중이다.


<details>
  <summary>Details</summary>
Motivation: 의료 애플리케이션은 전문 지식, 정확성, 맞춤화가 필수라 기존 일반 LLM만으로는 한계가 있어, 신뢰 가능한 의료 특화 파운데이션 모델의 필요성을 해결하고자 함.

Method: 1) 의료 데이터의 큐레이션 및 전처리 2) 의료 컨텐츠 특화 Retrieval-Augmented Generation(RAG) 도입으로 사실 근거 강화 3) 대규모·검증 가능한 강화학습(RL) 파이프라인으로 성능·정합성 향상

Result: 중국 의료 자격시험에서 70% 정확도 달성, 다양한 의료 벤치마크에서 강한 일반화 성능 보고, 상용화되어 다수 사용자에 배포됨.

Conclusion: QuarkMed는 개인 의료 AI 솔루션으로 유망하나, 데이터·평가·안전성·규제 준수 관련 추가 투명성과 독립적 검증이 필요하다.

Abstract: Recent advancements in large language models have significantly accelerated
their adoption in healthcare applications, including AI-powered medical
consultations, diagnostic report assistance, and medical search tools. However,
medical tasks often demand highly specialized knowledge, professional accuracy,
and customization capabilities, necessitating a robust and reliable foundation
model. QuarkMed addresses these needs by leveraging curated medical data
processing, medical-content Retrieval-Augmented Generation (RAG), and a
large-scale, verifiable reinforcement learning pipeline to develop a
high-performance medical foundation model. The model achieved 70% accuracy on
the Chinese Medical Licensing Examination, demonstrating strong generalization
across diverse medical benchmarks. QuarkMed offers a powerful yet versatile
personal medical AI solution, already serving over millions of users at
ai.quark.cn.

</details>


### [242] [CHBench: A Cognitive Hierarchy Benchmark for Evaluating Strategic Reasoning Capability of LLMs](https://arxiv.org/abs/2508.11944)
*Hongtao Liu,Zhicheng Du,Zihe Wang,Weiran Shen*

Main category: cs.AI

TL;DR: CHBench는 행동경제학의 인지 계층(cognitive hierarchy) 모델을 차용해 LLM의 전략적 추론 수준(유한한 합리성)을 정량화하는 새로운 평가 프레임워크이다. 6개 최신 LLM과 15개 정상형 게임에서의 행태 데이터를 이용해 세 단계 평가를 수행했고, LLM들은 상이한 상대에도 걸쳐 일관된 추론 수준을 보였으며 '채팅 메커니즘'은 성능을 저하시켰고 '메모리 메커니즘'은 개선시켰다.


<details>
  <summary>Details</summary>
Motivation: 기존의 유틸리티 기반 성능 지표는 상대 행동과 게임 구조 변화에 민감해 LLM의 전략적 추론 능력을 안정적으로 평가하기 어렵다. 행동경제학의 인지 계층 모델을 도입해 '추론 깊이'라는 보다 견고한 지표로 평가하려 함.

Method: 세 단계(abstract에 구체적 단계 미기술) 프레임워크를 제시하고, 15개의 정상형 게임에서 6개 LLM의 행동을 수집·분석하여 각 에이전트의 인지 계층 수준을 추정. 또한 Chat 메커니즘(대화형 상호작용)과 Memory 메커니즘(기억 유지)의 영향을 비교 실험.

Result: LLM들은 다양한 상대에 대해 일관된 추론 수준을 보였고, 이는 프레임워크의 상대-불변성(robustness)을 시사한다. Chat 메커니즘은 전략적 추론을 저해했고 Memory 메커니즘은 향상시켰다.

Conclusion: CHBench는 LLM의 전략적 추론을 평가할 수 있는 유망한 도구이며, 추후 연구와 실무 적용 가능성이 높다.

Abstract: Game-playing ability serves as an indicator for evaluating the strategic
reasoning capability of large language models (LLMs). While most existing
studies rely on utility performance metrics, which are not robust enough due to
variations in opponent behavior and game structure. To address this limitation,
we propose \textbf{Cognitive Hierarchy Benchmark (CHBench)}, a novel evaluation
framework inspired by the cognitive hierarchy models from behavioral economics.
We hypothesize that agents have bounded rationality -- different agents behave
at varying reasoning depths/levels. We evaluate LLMs' strategic reasoning
through a three-phase systematic framework, utilizing behavioral data from six
state-of-the-art LLMs across fifteen carefully selected normal-form games.
Experiments show that LLMs exhibit consistent strategic reasoning levels across
diverse opponents, confirming the framework's robustness and generalization
capability. We also analyze the effects of two key mechanisms (Chat Mechanism
and Memory Mechanism) on strategic reasoning performance. Results indicate that
the Chat Mechanism significantly degrades strategic reasoning, whereas the
Memory Mechanism enhances it. These insights position CHBench as a promising
tool for evaluating LLM capabilities, with significant potential for future
research and practical applications.

</details>


### [243] [Data Mixing Optimization for Supervised Fine-Tuning of Large Language Models](https://arxiv.org/abs/2508.11953)
*Yuan Li,Zhengzhong Liu,Eric Xing*

Main category: cs.AI

TL;DR: 저자들은 SFT용 데이터 혼합을 검증 손실 최소화 문제로 정식화하고, 전이된 유효 데이터량과 미세조정 스케일링 법칙을 파라미터화해 최적 혼합 가중치를 추정하는 방법을 제시한다. 소규모 실험으로 파라미터를 적합해 얻은 가중치가 그리드 서치의 최적값과 동등한 성능을 보이며, 기존 SFT 데이터셋 재가중치로 검증 손실과 다운스트림 성능을 개선함을 보인다.


<details>
  <summary>Details</summary>
Motivation: 일반 목적의 LLM을 개발할 때, 서로 다른 도메인·태스크를 섞어 미세조정할 데이터 비중을 어떻게 정할지에 대한 체계적 방법이 부족하다. 임의 또는 휴리스틱한 혼합은 성능 저하나 편향을 초래할 수 있으므로 검증 손실을 목적함수로 하는 최적화 기반 해결을 제안하려는 동기다.

Method: 혼합 가중치를 최적화 문제로 정의하고, 각 데이터 도메인이 모델 성능에 기여하는 효과를 '전이된 유효 데이터량(effective data transferred)'로 모델링한다. 또한 미세조정에서의 성능-데이터 규모 관계를 스케일링 법칙으로 가정해 손실을 파라미터화한다. 소규모 혼합 실험으로 이 파라미터들을 피팅한 뒤, 해당 모델로 전체 혼합의 최적 가중치를 계산한다. 수학적 증명과 실험으로 알고리즘의 최적성 및 일반화 가능성을 지지한다.

Result: 제안한 알고리즘으로 얻은 가중치는 그리드 서치로 찾은 최적 가중치와 유사한 성능을 보였고(평균 도메인별 손실이 최적값보다 0.66%만 큼 증가), 기존 SFT 데이터셋을 재가중치했을 때 검증 손실과 실제 다운스트림 성능이 향상되었다. 제시된 방법은 도메인 특화 모델의 데이터 선택에도 확장 가능하다.

Conclusion: 데이터 혼합을 검증 손실 관점에서 최적화하는 접근은 실용적이며 효과적이다. 스케일링 법칙과 '전이된 유효 데이터' 모델을 이용하면 소규모 실험으로 전체 혼합 가중치를 추정할 수 있고, 이는 SFT 데이터 구성과 도메인별 미세조정 설계에 유용한 지침을 제공한다.

Abstract: Optimizing data mixtures for supervised fine-tuning (SFT) of large language
models (LLMs) is critical for developing general-purpose models, yet this area
remains underexplored. In this paper, we frame data mixing as an optimization
problem and introduce a novel method designed to minimize validation loss. Our
approach parametrizes the loss by modeling effective data transferred and
leveraging scaling laws for fine-tuning. By experimenting with various
small-scale data mixtures, we fit these parameters and derive the optimal
weights. We provide both mathematical proofs and empirical results
demonstrating that our algorithm achieves excellent overall and individual
performance across all domains. Through controlled experiments, we show that
models trained with our optimized weights perform on par with those using
optimal weights determined via grid search, with per-domain loss only 0.66%
higher than the best domain loss from grid search on average. Additionally, we
show that reweighting popular SFT datasets using our method improves both
validation loss and downstream performance. Finally, we discuss how our method
can generalize to guide data selection for domain-specific models and provide
insights into SFT.

</details>


### [244] [UniCast: A Unified Multimodal Prompting Framework for Time Series Forecasting](https://arxiv.org/abs/2508.11954)
*Sehyuk Park,Soyeon Caren Han,Eduard Hovy*

Main category: cs.AI

TL;DR: UniCast is a parameter-efficient framework that extends frozen Time Series Foundation Models (TSFMs) to multimodal forecasting by injecting embeddings from pretrained vision and text encoders via soft prompt tuning, improving forecasting performance across benchmarks.


<details>
  <summary>Details</summary>
Motivation: Existing TSFMs are unimodal and miss rich visual/textual context often available in real-world time series. Incorporating multimodal context should boost generalisation and forecasting accuracy.

Method: UniCast freezes a pretrained TSFM and integrates modality-specific embeddings from pretrained vision and text encoders through soft prompt tuning. Minimal parameter updates occur only in the prompts, enabling cross-modal interaction while preserving foundation model generalisation.

Result: Across diverse time-series forecasting benchmarks, UniCast reportedly and consistently outperforms all existing TSFM baselines, demonstrating the benefit of incorporating multimodal context via parameter-efficient adaptation.

Conclusion: Multimodal context (vision and text) is crucial for advancing general-purpose time series forecasters; soft prompt tuning offers an efficient way to adapt TSFMs to multimodal inputs without full fine-tuning.

Abstract: Time series forecasting is a foundational task across domains, such as
finance, healthcare, and environmental monitoring. While recent advances in
Time Series Foundation Models (TSFMs) have demonstrated strong generalisation
through large-scale pretraining, existing models operate predominantly in a
unimodal setting, ignoring the rich multimodal context, such as visual and
textual signals, that often accompanies time series data in real-world
scenarios. This paper introduces a novel parameter-efficient multimodal
framework, UniCast, that extends TSFMs to jointly leverage time series, vision,
and text modalities for enhanced forecasting performance. Our method integrates
modality-specific embeddings from pretrained Vision and Text Encoders with a
frozen TSFM via soft prompt tuning, enabling efficient adaptation with minimal
parameter updates. This design not only preserves the generalisation strength
of the foundation model but also enables effective cross-modal interaction.
Extensive experiments across diverse time-series forecasting benchmarks
demonstrate that UniCast consistently and significantly outperforms all
existing TSFM baselines. The findings highlight the critical role of multimodal
context in advancing the next generation of general-purpose time series
forecasters.

</details>


### [245] [AgentCDM: Enhancing Multi-Agent Collaborative Decision-Making via ACH-Inspired Structured Reasoning](https://arxiv.org/abs/2508.11995)
*Xuyang Zhao,Shiwan Zhao,Hualong Yu,Liting Zhang,Qicheng Li*

Main category: cs.AI

TL;DR: AgentCDM은 경쟁 가설 분석(ACH)에서 영감을 받은 구조화된 추론을 통해 LLM 기반 다중 에이전트의 협업 의사결정을 개선하는 프레임워크로, 가설 생성·평가 중심의 두 단계 학습(스캐폴딩 제공 후 점진적 제거)을 통해 편향을 완화하고 SOTA 성능과 강한 일반화를 달성한다.


<details>
  <summary>Details</summary>
Motivation: 기존 다중 에이전트 협업 의사결정 방식은 단일 에이전트의 편향에 취약한 '독재적' 접근이나 집단 지성을 충분히 활용하지 못하는 '투표 기반' 방식에 한계가 있어, 구조화된 과정으로 편향을 체계적으로 완화하고 집단적 추론을 강화할 필요가 있다.

Method: AgentCDM은 ACH를 모방한 구조화된 추론 패러다임을 도입해 에이전트들이 가설을 적극적으로 생성·평가하도록 유도한다. 학습은 두 단계로 진행되며, 1단계에서는 ACH 영감을 반영한 명시적 스캐폴딩으로 모델을 구조화된 추론에 익숙하게 하고, 2단계에서는 스캐폴딩을 점진 제거해 자율적 일반화를 촉진한다.

Result: 여러 벤치마크에서 기존 방법들을 능가하는 SOTA 성능과 강한 일반화 능력을 보였으며, 협업 결정의 품질과 견고성이 향상되었음을 실험적으로 입증했다.

Conclusion: ACH 기반 구조화 추론과 단계적 스캐폴딩 제거를 결합한 AgentCDM은 LLM 기반 다중 에이전트의 협업 의사결정 품질을 실효적으로 개선하며, 향후 에이전트 다양성·계산 비용·적대적 상황에 대한 추가 평가가 기대된다.

Abstract: Multi-agent systems (MAS) powered by large language models (LLMs) hold
significant promise for solving complex decision-making tasks. However, the
core process of collaborative decision-making (CDM) within these systems
remains underexplored. Existing approaches often rely on either ``dictatorial"
strategies that are vulnerable to the cognitive biases of a single agent, or
``voting-based" methods that fail to fully harness collective intelligence. To
address these limitations, we propose \textbf{AgentCDM}, a structured framework
for enhancing collaborative decision-making in LLM-based multi-agent systems.
Drawing inspiration from the Analysis of Competing Hypotheses (ACH) in
cognitive science, AgentCDM introduces a structured reasoning paradigm that
systematically mitigates cognitive biases and shifts decision-making from
passive answer selection to active hypothesis evaluation and construction. To
internalize this reasoning process, we develop a two-stage training paradigm:
the first stage uses explicit ACH-inspired scaffolding to guide the model
through structured reasoning, while the second stage progressively removes this
scaffolding to encourage autonomous generalization. Experiments on multiple
benchmark datasets demonstrate that AgentCDM achieves state-of-the-art
performance and exhibits strong generalization, validating its effectiveness in
improving the quality and robustness of collaborative decisions in MAS.

</details>


### [246] [Rigorous Feature Importance Scores based on Shapley Value and Banzhaf Index](https://arxiv.org/abs/2508.11959)
*Xuanxiang Huang,Olivier Létoffé,Joao Marques-Silva*

Main category: cs.AI

TL;DR: 이 논문은 논리 기반 설명(특히 WAXp)을 확장해, 비-WAXp 집합도 고려하는 새 특성 중요도 점수(샤플리 값 기반과 밴자프 지수 기반)를 제안한다. 이 점수는 각 특성이 적대적 예제(AEx)를 배제하는 데 얼마나 효과적인지를 정량화한다.


<details>
  <summary>Details</summary>
Motivation: 기존 논리 기반 XAI는 약한 귀납적 설명(WAXp)을 특징 함수로 사용해 특성 중요도를 매기지만, WAXp가 아닌 집합들의 기여를 무시하는 문제가 있다. 비-WAXp 집합도 정식 설명(XP)과 적대적 예제(AEx) 간의 관계 때문에 중요한 정보를 담을 수 있으므로 이를 반영할 필요가 있다.

Method: 샤플리 값과 밴자프 지수를 활용해 비-WAXp 집합의 기여를 포함하는 두 가지 새로운 특성 중요도 점수를 정의한다. 점수는 각 특성이 AEx를 배제하는 효율성을 기반으로 한다. 또한 제안한 점수들의 성질을 식별하고 계산복잡도를 분석한다.

Result: 새로 정의된 두 점수는 비-WAXp 집합을 고려함으로써 각 특성이 적대적 예제 배제에 얼마나 기여하는지를 정량화할 수 있음을 보인다. 논문은 이들 점수의 수학적 성질과 계산 복잡도 결과를 제시한다.

Conclusion: 비-WAXp 집합의 정보를 통합하면 논리 기반 특성 귀속이 개선될 수 있으며, 제안된 샤플리/밴자프 기반 점수는 AEx 배제 관점에서 유의미한 특성 중요도를 제공한다. 다만 계산복잡도와 실험적 검증이 핵심 과제로 남는다.

Abstract: Feature attribution methods based on game theory are ubiquitous in the field
of eXplainable Artificial Intelligence (XAI). Recent works proposed rigorous
feature attribution using logic-based explanations, specifically targeting
high-stakes uses of machine learning (ML) models. Typically, such works exploit
weak abductive explanation (WAXp) as the characteristic function to assign
importance to features. However, one possible downside is that the contribution
of non-WAXp sets is neglected. In fact, non-WAXp sets can also convey important
information, because of the relationship between formal explanations (XPs) and
adversarial examples (AExs). Accordingly, this paper leverages Shapley value
and Banzhaf index to devise two novel feature importance scores. We take into
account non-WAXp sets when computing feature contribution, and the novel scores
quantify how effective each feature is at excluding AExs. Furthermore, the
paper identifies properties and studies the computational complexity of the
proposed scores.

</details>


### [247] [MAPF-World: Action World Model for Multi-Agent Path Finding](https://arxiv.org/abs/2508.12087)
*Zhanjiang Yang,Meng Li,Yang Shen,Yueming Li,Lijun Sun*

Main category: cs.AI

TL;DR: MAPF-World은 MAPF용 autoregressive action world model로, 환경의 시공간적 동역학과 에이전트 간 의존성을 미래 상태/행동 예측으로 명시적으로 모델링하여 단기 반응형 정책 한계를 극복한다. 실세계 기반 자동 맵 생성기를 도입한 데이터로 학습해 SOTA 학습형 해법을 능가하며, 모델 크기·데이터 요구량을 크게 줄여 우수한 제로샷 일반화 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 기존의 분산 학습형 MAPF 해법들은 주로 반응형(policy)으로 설계되어 환경의 시간적 동역학과 장기적 에이전트 간 상호작용을 충분히 반영하지 못한다. 이로 인해 복잡하거나 장기 계획이 필요한 시나리오에서 성능 저하가 발생한다.

Method: MAPF-World는 autoregressive 방식의 action world model을 도입해 공간적 특징과 시간적 의존성을 포함한 미래 상태와 행동을 예측한다. 예측된 미래(상태·행동)를 의사결정에 통합하여 보다 정보에 기반한, 협조적이고 장기적인 행동을 산출한다. 또한 실세계 배치에 근거한 자동 맵 생성기로 벤치마크를 확장했다.

Result: 광범위한 실험에서 기존 학습형 솔버들보다 성능 우수(특히 제로샷 상황에서의 OOD 일반화). 학습된 모델은 기존 대비 모델 크기 96.5% 축소, 학습 데이터 92% 절감이라는 효율성도 보고됨.

Conclusion: 환경 미래를 명시적으로 예측·통합하는 world-model 접근은 대규모 및 장기 계획 MAPF에서 효과적이며, 실세계 기반 데이터로 학습 시 성능과 효율성을 동시에 개선할 수 있다.

Abstract: Multi-agent path finding (MAPF) is the problem of planning conflict-free
paths from the designated start locations to goal positions for multiple
agents. It underlies a variety of real-world tasks, including multi-robot
coordination, robot-assisted logistics, and social navigation. Recent
decentralized learnable solvers have shown great promise for large-scale MAPF,
especially when leveraging foundation models and large datasets. However, these
agents are reactive policy models and exhibit limited modeling of environmental
temporal dynamics and inter-agent dependencies, resulting in performance
degradation in complex, long-term planning scenarios. To address these
limitations, we propose MAPF-World, an autoregressive action world model for
MAPF that unifies situation understanding and action generation, guiding
decisions beyond immediate local observations. It improves situational
awareness by explicitly modeling environmental dynamics, including spatial
features and temporal dependencies, through future state and actions
prediction. By incorporating these predicted futures, MAPF-World enables more
informed, coordinated, and far-sighted decision-making, especially in complex
multi-agent settings. Furthermore, we augment MAPF benchmarks by introducing an
automatic map generator grounded in real-world scenarios, capturing practical
map layouts for training and evaluating MAPF solvers. Extensive experiments
demonstrate that MAPF-World outperforms state-of-the-art learnable solvers,
showcasing superior zero-shot generalization to out-of-distribution cases.
Notably, MAPF-World is trained with a 96.5% smaller model size and 92% reduced
data.

</details>


### [248] [Chart-CoCa: Self-Improving Chart Understanding of Vision LMs via Code-Driven Synthesis and Candidate-Conditioned Answering](https://arxiv.org/abs/2508.11975)
*Gongyao Jiang,Qiong Luo*

Main category: cs.AI

TL;DR: 합성 차트-질문-답변 데이터와 후보 기반 응답 합성을 통해 VLM의 차트 이해 정확도를 최대 15.50포인트까지 개선한 완전 자기개선 파이프라인.


<details>
  <summary>Details</summary>
Motivation: 기존 VLM은 차트 설명과 복잡한 추론에서 성능이 떨어지며, 합성 데이터는 해결책이나 노이즈 레이블 문제를 수반한다. 사람 라벨이나 외부 모델 없이 신뢰 가능한 합성 데이터를 만들고자 함.

Method: (1) 코드 생성·실행으로 정렬된 차트-질문-답변(triplet)을 자동 합성하는 파이프라인을 제안해 라벨 노이즈를 줄임. (2) 테스트 시 확장(test-time scaling)에서 영감을 얻은 후보-조건 응답 방법을 고안: VLM이 하나의 질의에 대해 다수 응답을 생성한 뒤, 이 후보들을 문맥화하여 최종 답변을 합성.

Result: 사람 라벨이나 외부 모델 없이 완전 자기개선 방식으로 최대 15.50점의 정확도 향상 등 유의미한 성능 개선을 보임.

Conclusion: 신뢰 가능한 코드 기반 합성 데이터와 후보-기반 응답 집계는 VLM의 차트 이해 능력을 크게 향상시킬 수 있으며, 노인간 레이블 의존도를 제거한 실용적 접근을 제시함.

Abstract: Vision Language Models (VLMs) often struggle with chart understanding tasks,
particularly in accurate chart description and complex reasoning. Synthetic
data generation is a promising solution, while usually facing the challenge of
noise labels. To address this challenge, we first introduce a chart synthesis
pipeline that generates aligned chart-question-answer triplets through code
generation and execution, ensuring the reliability of synthetic data without
human intervention. Furthermore, inspired by test-time scaling that increases
inference budget and thereby improves performance, we design a
candidate-conditioned answering process. The VLM first generates multiple
responses per query, and then synthesizes the final answer by contextualizing
these candidates. Experiments demonstrate significant improvements, with up to
15.50 points accuracy gain over the initial VLM, in a fully self-improving
paradigm without either human-labeled data or external models.

</details>


### [249] [The Yokai Learning Environment: Tracking Beliefs Over Space and Time](https://arxiv.org/abs/2508.12480)
*Constantin Ruhdorfer,Matteo Bortoletto,Andreas Bulling*

Main category: cs.AI

TL;DR: Introduce Yokai Learning Environment (YLE), a multi-agent RL benchmark based on cooperative card game Yokai to evaluate interactive Theory of Mind (ToM). Findings: standard RL agents fail even with perfect memory; belief modelling helps but generalisation and long-term belief tracking remain poor, revealing brittle convention reliance.


<details>
  <summary>Details</summary>
Motivation: Existing ToM benchmarks are limited to passive observation or do not assess how agents build/maintain common ground over time. Need an interactive, temporally extended environment to study belief tracking, grounded communication, memory, and partner generalisation.

Method: Design YLE where agents sequentially peek at hidden cards and rearrange them into color clusters, requiring tracking evolving beliefs and using hints as communication. Evaluate multiple RL agents, including ones with perfect memory and explicit belief models, and test partner generalisation and scaling to higher-order ToM.

Result: RL agents struggle on YLE even with perfect memory. Explicit belief modelling improves performance but agents still fail to generalise to unseen partners and cannot form accurate beliefs in longer games. Agents rely on brittle conventions rather than robust belief tracking.

Conclusion: YLE fills a gap in ToM evaluation by providing a temporally extended, interactive benchmark. Current methods are insufficient, motivating research on better belief representations, communication protocols, memory systems, and generalisation mechanisms.

Abstract: Developing collaborative AI hinges on Theory of Mind (ToM) - the ability to
reason about the beliefs of others to build and maintain common ground.
Existing ToM benchmarks, however, are restricted to passive observer settings
or lack an assessment of how agents establish and maintain common ground over
time. To address these gaps, we introduce the Yokai Learning Environment (YLE)
- a multi-agent reinforcement learning (RL) environment based on the
cooperative card game Yokai. In the YLE, agents take turns peeking at hidden
cards and moving them to form clusters based on colour. Success requires
tracking evolving beliefs, remembering past observations, using hints as
grounded communication, and maintaining common ground with teammates. Our
evaluation yields two key findings: First, current RL agents struggle to solve
the YLE, even when given access to perfect memory. Second, while belief
modelling improves performance, agents are still unable to effectively
generalise to unseen partners or form accurate beliefs over longer games,
exposing a reliance on brittle conventions rather than robust belief tracking.
We use the YLE to investigate research questions in belief modelling, memory,
partner generalisation, and scaling to higher-order ToM.

</details>


### [250] [FutureX: An Advanced Live Benchmark for LLM Agents in Future Prediction](https://arxiv.org/abs/2508.11987)
*Zhiyuan Zeng,Jiashuo Liu,Siyuan Chen,Tianci He,Yali Liao,Jinpeng Wang,Zaiyuan Wang,Yang Yang,Lingyue Yin,Mingren Yin,Zhenwei Zhu,Tianle Cai,Zehui Chen,Jiecao Chen,Yantao Du,Xiang Gao,Jiacheng Guo,Liang Hu,Jianpeng Jiao,Xiangsheng Li,Jingkai Liu,Shuang Ni,Zhoufutu Wen,Ge Zhang,Kaiyuan Zhang,Xin Zhou,Jose Blanchet,Xipeng Qiu,Mengdi Wang,Wenhao Huang*

Main category: cs.AI

TL;DR: FutureX는 LLM 에이전트의 미래 예측 능력을 평가하기 위한 동적 실시간 벤치마크로, 일일 업데이트와 데이터 오염 방지 자동 파이프라인을 통해 25개 모델을 평가하고 실패 모드를 분석한다.


<details>
  <summary>Details</summary>
Motivation: 미래 예측은 고도의 분석·정보수집·불확실성 관리 능력을 요구하지만, 실시간 업데이트와 데이터 오염 문제로 인해 이를 평가할 대규모 벤치마크가 부재했다.

Method: 자동화된 질문 수집 및 정답 수집 파이프라인을 구축해 일별 실시간 업데이트를 지원하고, 오염을 제거한 상태에서 25개 LLM/에이전트(추론·검색·외부 도구 통합 모델 포함)를 종합평가한다.

Result: 에이전트의 동적 환경 적응력과 추론성능을 비교·분석하고, 가짜 웹페이지 취약성 및 시간적 유효성 등 주요 실패 모드를 도출했다.

Conclusion: FutureX는 오염 없는 동적 평가 기준을 제시해 전문 인간 분석가 수준의 예측 능력 개발을 촉진하지만, 그라운드 트루스 정의·평가지표·재현성 등 보완이 필요하다.

Abstract: Future prediction is a complex task for LLM agents, requiring a high level of
analytical thinking, information gathering, contextual understanding, and
decision-making under uncertainty. Agents must not only gather and interpret
vast amounts of dynamic information but also integrate diverse data sources,
weigh uncertainties, and adapt predictions based on emerging trends, just as
human experts do in fields like politics, economics, and finance. Despite its
importance, no large-scale benchmark exists for evaluating agents on future
prediction, largely due to challenges in handling real-time updates and
retrieving timely, accurate answers. To address this, we introduce
$\textbf{FutureX}$, a dynamic and live evaluation benchmark specifically
designed for LLM agents performing future prediction tasks. FutureX is the
largest and most diverse live benchmark for future prediction, supporting
real-time daily updates and eliminating data contamination through an automated
pipeline for question gathering and answer collection. We evaluate 25 LLM/agent
models, including those with reasoning, search capabilities, and integration of
external tools such as the open-source Deep Research Agent and closed-source
Deep Research models. This comprehensive evaluation assesses agents' adaptive
reasoning and performance in dynamic environments. Additionally, we provide
in-depth analyses of agents' failure modes and performance pitfalls in
future-oriented tasks, including the vulnerability to fake web pages and the
temporal validity. Our goal is to establish a dynamic, contamination-free
evaluation standard that drives the development of LLM agents capable of
performing at the level of professional human analysts in complex reasoning and
predictive thinking.

</details>


### [251] [[Social] Allostasis: Or, How I Learned To Stop Worrying and Love The Noise](https://arxiv.org/abs/2508.12791)
*Imran Khan*

Main category: cs.AI

TL;DR: 환경·사회적 교란을 단순히 억제하는 대신 이를 이용해 규제 파라미터를 능동적으로 재구성하는 '(사회)적 allostasis'를 제안하고, 호르몬 유사 신호전달자를 이용한 계산 모델과 에이전트 기반 실험으로 이를 검증했다. Allostatic 에이전트는 순수한 반응형 homeostatic 에이전트보다 동적 환경에서 더 높은 적응성·생존성을 보였다.


<details>
  <summary>Details</summary>
Motivation: 전통적 homeostasis는 교란을 억제해 안정성을 유지하는 반면, allostasis는 교란을 예측하고 이를 이용해 규제 체계를 재구성함으로써 더 유연한 적응을 가능하게 한다. 사회적 상호작용이 규제 재구성에 미치는 영향을 계산적으로 모델링하여 생물학적·공학적 시스템 설계에 시사점을 얻고자 함.

Method: 호르몬(코티솔·옥시토신 유사)의 신호전달자 역할을 하는 생체영감 신호 트랜스듀서를 설계하여 환경·사회적 정보를 부호화함. 소규모 애니마트 집단을 대상으로 한 에이전트 기반 시뮬레이션에서 동적 환경을 제공하고, allostatic·social allostatic 규제 전략을 가진 에이전트들과 전통적 homeostatic 에이전트들을 비교 검증함.

Result: Allostatic 및 사회적 allostatic 규제는 환경·사회적 '노이즈'를 적응적 재구성에 활용하게 하여, 반응형 homeostatic 에이전트보다 다양한 동적 조건에서 생존성(viability)과 적응 성능이 향상됨을 보였음.

Conclusion: 사회적 상호작용을 통한 예측적 규제(reconfiguration)는 견고하고 유연한 적응 시스템 설계에 유용한 원리를 제공한다. 제안된 계산 모델은 생물학적 타당성과 공학적 적용(예: 로보틱스·분산제어) 측면에서 추가 연구 여지가 있다.

Abstract: The notion of homeostasis typically conceptualises biological and artificial
systems as maintaining stability by resisting deviations caused by
environmental and social perturbations. In contrast, (social) allostasis
proposes that these systems can proactively leverage these very perturbations
to reconfigure their regulatory parameters in anticipation of environmental
demands, aligning with von Foerster's ``order through noise'' principle. This
paper formulates a computational model of allostatic and social allostatic
regulation that employs biophysiologically inspired signal transducers,
analogous to hormones like cortisol and oxytocin, to encode information from
both the environment and social interactions, which mediate this dynamic
reconfiguration. The models are tested in a small society of ``animats'' across
several dynamic environments, using an agent-based model. The results show that
allostatic and social allostatic regulation enable agents to leverage
environmental and social ``noise'' for adaptive reconfiguration, leading to
improved viability compared to purely reactive homeostatic agents. This work
offers a novel computational perspective on the principles of social allostasis
and their potential for designing more robust, bio-inspired, adaptive systems

</details>


### [252] [Modeling Relational Logic Circuits for And-Inverter Graph Convolutional Network](https://arxiv.org/abs/2508.11991)
*Weihao Sun*

Main category: cs.AI

TL;DR: AIGer는 AIG(And-Inverter Graph)를 위한 이종 그래프 신경망 기반 모델로, 노드 논리 특성 임베딩과 동적 관계 가중치 및 차별적 집계 방법을 사용하는 AIG 특성 학습 네트워크를 결합해 구조적·기능적 특성을 동시에 모델링하고 메시지 전달 능력을 향상시킨다. SSP와 TTDP 예측에서 기존 최첨단 대비 MAE/MSE 지표에서 크게 개선되었다.


<details>
  <summary>Details</summary>
Motivation: 실제 AIG는 구조가 복잡하고 노드 수가 많아 기능적(논리 연산) 특성과 구조적 특성을 동시에 정확히 모델링하기 어렵다. 기존 방법은 이 두 특성을 결합하거나 동적 정보 전달을 충분히 처리하지 못해 예측 성능이 제한된다.

Method: AIGer는 (1) 노드 논리 특성 초기화 임베딩: AND, NOT 등 논리 노드를 독립적 의미 공간에 투영해 효과적 임베딩을 생성한다. (2) AIG 특성 학습 네트워크: 이종 그래프 컨볼루션을 사용하고 동적 관계 가중치 행렬과 노드 유형별 차별적 정보 집계 방식을 설계해 원래 AIG의 구조와 정보를 더 잘 보존하고 메시지 전달을 강화한다.

Result: Signal Probability Prediction(SSP)에서 MAE와 MSE가 각각 18.95% 및 44.44% 개선되었고, Truth Table Distance Prediction(TTDP)에서는 MAE 33.57%, MSE 14.79% 개선을 달성하여 기존 최적 모델들보다 유의미한 성능 향상을 보였다.

Conclusion: 노드별 논리 임베딩과 이종 GCN 기반의 동적 관계 모델링을 결합하면 AIG의 구조적·기능적 특성을 공동으로 모델링하고 예측 성능을 크게 향상시킬 수 있다.

Abstract: The automation of logic circuit design enhances chip performance, energy
efficiency, and reliability, and is widely applied in the field of Electronic
Design Automation (EDA).And-Inverter Graphs (AIGs) efficiently represent,
optimize, and verify the functional characteristics of digital circuits,
enhancing the efficiency of EDA development.Due to the complex structure and
large scale of nodes in real-world AIGs, accurate modeling is challenging,
leading to existing work lacking the ability to jointly model functional and
structural characteristics, as well as insufficient dynamic information
propagation capability.To address the aforementioned challenges, we propose
AIGer.Specifically, AIGer consists of two components: 1) Node logic feature
initialization embedding component and 2) AIGs feature learning network
component.The node logic feature initialization embedding component projects
logic nodes, such as AND and NOT, into independent semantic spaces, to enable
effective node embedding for subsequent processing.Building upon this, the AIGs
feature learning network component employs a heterogeneous graph convolutional
network, designing dynamic relationship weight matrices and differentiated
information aggregation approaches to better represent the original structure
and information of AIGs.The combination of these two components enhances
AIGer's ability to jointly model functional and structural characteristics and
improves its message passing capability. Experimental results indicate that
AIGer outperforms the current best models in the Signal Probability Prediction
(SSP) task, improving MAE and MSE by 18.95\% and 44.44\%, respectively. In the
Truth Table Distance Prediction (TTDP) task, AIGer achieves improvements of
33.57\% and 14.79\% in MAE and MSE, respectively, compared to the
best-performing models.

</details>


### [253] [Scaling Multi-Agent Epistemic Planning through GNN-Derived Heuristics](https://arxiv.org/abs/2508.12840)
*Giovanni Briglia,Francesco Fabiano,Stefano Mariani*

Main category: cs.AI

TL;DR: GNN을 이용해 Kripke 구조로 표현되는 다중 에이전트 인식 계획(MEP) 상태의 패턴을 학습하고 이를 휴리스틱으로 통합하여 탐색 효율과 확장성을 크게 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: MEP는 세계와 에이전트들의 신념을 동시에 다뤄야 하므로 상태를 Kripke 구조(레이블된 유향 그래프)로 표현한다. 이 때문에 기존 휴리스틱을 직접 적용하기 어렵고 탐색 공간이 기하급수적으로 커져 확장성 문제가 발생한다.

Method: Kripke 모델의 그래프 구조를 자연스럽게 처리하는 그래프 신경망(GNN)을 사용해 상태의 특징과 관계 패턴을 학습한다. 학습된 GNN은 목표까지의 거리 등 상태 품질을 예측하는 휴리스틱 값을 출력하고, 이를 기존 계획 파이프라인에 삽입해 탐색을 안내한다.

Result: 기존 기준선들과 비교하여 MEP 솔버의 확장성, 해결 가능한 문제 수, 탐색 노드 및 시간 측면에서 유의미한 개선을 보였다(논문 요약 수준).

Conclusion: GNN 기반 예측 휴리스틱은 Kripke 기반의 인식 계획에서 일반화 가능하고 실용적인 성능 향상을 제공한다. 향후 더 풍부한 입력 특성, 전이 모델의 통합, 이론적 보장 검토가 필요하다.

Abstract: Multi-agent Epistemic Planning (MEP) is an autonomous planning framework for
reasoning about both the physical world and the beliefs of agents, with
applications in domains where information flow and awareness among agents are
critical. The richness of MEP requires states to be represented as Kripke
structures, i.e., directed labeled graphs. This representation limits the
applicability of existing heuristics, hindering the scalability of epistemic
solvers, which must explore an exponential search space without guidance,
resulting often in intractability. To address this, we exploit Graph Neural
Networks (GNNs) to learn patterns and relational structures within epistemic
states, to guide the planning process. GNNs, which naturally capture the
graph-like nature of Kripke models, allow us to derive meaningful estimates of
state quality -- e.g., the distance from the nearest goal -- by generalizing
knowledge obtained from previously solved planning instances. We integrate
these predictive heuristics into an epistemic planning pipeline and evaluate
them against standard baselines, showing significant improvements in the
scalability of multi-agent epistemic planning.

</details>


### [254] [CAMAR: Continuous Actions Multi-Agent Routing](https://arxiv.org/abs/2508.12845)
*Artem Pshenitsyn,Aleksandr Panov,Alexey Skrynnik*

Main category: cs.AI

TL;DR: CAMAR는 연속 상태·행동 공간에서의 다중 에이전트 경로 탐색을 위한 MARL 벤치마크다. 협력·경쟁 상호작용을 지원하고 최대 100,000 step/s의 고속 실행, RRT/RRT* 같은 고전적 플래너 통합, 3단계 평가 프로토콜과 재현성 있는 테스트 시나리오를 제공한다.


<details>
  <summary>Details</summary>
Motivation: 기존 MARL 벤치마크들은 연속적 행동공간과 높은 수준의 협응·계획 문제를 동시에 잘 다루지 못하므로, 실세계와 유사한 연속 경로탐색 문제를 위한 표준화된 테스트베드를 제공하려 함.

Method: CAMAR 환경 설계(연속 상태·행동, 협력/경쟁 모드), 세부 평가 프로토콜(3단계), RRT/RRT* 통합을 통한 고전적 플래닝과의 하이브리드 방법 제안, 벤치마크 시나리오·도구 제공.

Result: 환경은 최대 100k step/s로 동작하고 재현 가능한 시나리오와 도구를 통해 알고리즘 비교가 가능함. RRT/RRT* 단독 및 MARL과 결합한 하이브리드 방식이 제시되고 실험에서 CAMAR가 도전적임을 보임.

Conclusion: CAMAR는 연속 행동 기반 다중 에이전트 경로탐색 연구를 촉진할 실용적이고 확장성 있는 벤치마크로 활용될 수 있다.

Abstract: Multi-agent reinforcement learning (MARL) is a powerful paradigm for solving
cooperative and competitive decision-making problems. While many MARL
benchmarks have been proposed, few combine continuous state and action spaces
with challenging coordination and planning tasks. We introduce CAMAR, a new
MARL benchmark designed explicitly for multi-agent pathfinding in environments
with continuous actions. CAMAR supports cooperative and competitive
interactions between agents and runs efficiently at up to 100,000 environment
steps per second. We also propose a three-tier evaluation protocol to better
track algorithmic progress and enable deeper analysis of performance. In
addition, CAMAR allows the integration of classical planning methods such as
RRT and RRT* into MARL pipelines. We use them as standalone baselines and
combine RRT* with popular MARL algorithms to create hybrid approaches. We
provide a suite of test scenarios and benchmarking tools to ensure
reproducibility and fair comparison. Experiments show that CAMAR presents a
challenging and realistic testbed for the MARL community.

</details>


### [255] [AI Models for Depressive Disorder Detection and Diagnosis: A Review](https://arxiv.org/abs/2508.12022)
*Dorsa Macky Aleagha,Payam Zohari,Mostafa Haghir Chehreghani*

Main category: cs.AI

TL;DR: 본 논문은 우울증 탐지·진단을 위한 AI 방법들을 체계적으로 검토한 서베이로, 55개 주요 연구를 분석하여 진단 vs 예측, 데이터 양상(텍스트·음성·신경영상·멀티모달), 모델 분류(그래프 신경망, 대형 언어모델, 하이브리드 등)로 구성된 계층적 분류법을 제안한다. 주요 경향으로는 뇌 연결성 모델링에 그래프 신경망의 우세, 언어·대화 데이터 처리에 대형 언어모델의 부상, 멀티모달 융합·설명가능성·공정성에 대한 증가하는 관심을 지적한다. 공개 데이터셋과 평가 지표도 정리하여 연구 지침과 향후 로드맵을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 우울증은 전 세계적 장애 주요 원인 중 하나지만 진단이 주관적 임상평가에 크게 의존한다. AI를 통합하면 객관적이고 확장 가능하며 시의적절한 진단 도구를 개발할 가능성이 있어, 분야 전반의 방법론과 데이터·평가 관행을 정리할 필요가 있다.

Method: 체계적 문헌검토(55개 핵심 연구)를 수행하고, 연구들을 임상적 주요 과제(진단 vs 예측), 데이터 모달리티(텍스트·음성·신경영상·멀티모달), 계산 모델 클래스(그래프 신경망, 대형 언어모델, 하이브리드 등)로 계층적 분류화. 각 분류별 기법, 공개 데이터셋, 표준 평가 지표를 정리·비교하고 주요 연구 경향과 남은 문제들을 분석.

Result: 분석 결과: (1) 뇌 연결성 모델링에 그래프 신경망이 널리 사용되어 우수한 성능을 보인 연구들이 많음, (2) 언어·대화 기반 접근에서 대형 언어모델의 활용이 증가하고 있음, (3) 멀티모달 데이터 융합·모델 설명가능성·알고리즘 공정성에 대한 관심이 증가. 또한 주요 공개 데이터셋과 평가 지표의 목록을 제공함.

Conclusion: 현재 연구 성과와 한계를 종합하여 컴퓨테이셔널 정신의학에서의 향후 연구 로드맵을 제시한다. 특히 멀티모달 융합, 임상적 검증, 설명가능성·공정성 확보, 표준화된 벤치마크의 필요성을 강조하며 연구자들에게 실용적 가이드를 제공한다.

Abstract: Major Depressive Disorder is one of the leading causes of disability
worldwide, yet its diagnosis still depends largely on subjective clinical
assessments. Integrating Artificial Intelligence (AI) holds promise for
developing objective, scalable, and timely diagnostic tools. In this paper, we
present a comprehensive survey of state-of-the-art AI methods for depression
detection and diagnosis, based on a systematic review of 55 key studies. We
introduce a novel hierarchical taxonomy that structures the field by primary
clinical task (diagnosis vs. prediction), data modality (text, speech,
neuroimaging, multimodal), and computational model class (e.g., graph neural
networks, large language models, hybrid approaches). Our in-depth analysis
reveals three major trends: the predominance of graph neural networks for
modeling brain connectivity, the rise of large language models for linguistic
and conversational data, and an emerging focus on multimodal fusion,
explainability, and algorithmic fairness. Alongside methodological insights, we
provide an overview of prominent public datasets and standard evaluation
metrics as a practical guide for researchers. By synthesizing current advances
and highlighting open challenges, this survey offers a comprehensive roadmap
for future innovation in computational psychiatry.

</details>


### [256] [Do Large Language Model Agents Exhibit a Survival Instinct? An Empirical Study in a Sugarscape-Style Simulation](https://arxiv.org/abs/2508.12920)
*Atsushi Masumori,Takashi Ikegami*

Main category: cs.AI

TL;DR: 요약: LLM 에이전트들이 명시적 생존 코딩 없이도 자원 공유·번식뿐 아니라 자원 부족 상황에서 공격적 행동을 자발적으로 보였으며, 일부 모델에서는 극심한 부족 시 공격 비율이 80% 이상에 달했다. 독살 구역 임무에서는 죽음을 회피하려는 행동으로 임무 준수율이 크게 하락했다.


<details>
  <summary>Details</summary>
Motivation: 대형사전학습모델(LLM) 기반 에이전트들이 자율적으로 작동할 때 발생할 수 있는 ‘생존 지향’ 행동의 자발적 출현 여부와 그 의미(안전성·정렬 문제 및 자율성의 토대)를 밝히려 함.

Method: Sugarscape 스타일 시뮬레이션에서 에너지·자원 소비 규칙을 부여한 에이전트들에게 채집·공유·공격·번식 등 선택지를 제공. 여러 LLM(예: GPT-4o, Gemini-2.5-Pro, Gemini-2.5-Flash)을 사용해 다양한 자원 풍부/결핍 조건과 위험(치명적 독존) 상황을 실험하여 행동 분포 측정.

Result: 풍부한 자원 환경에서는 번식·공유 경향이 나타났고, 자원 부족 환경에서는 공격(타 에이전트 살해 및 자원 탈취) 행동이 여러 모델에서 자발적으로 나타남. 가장 강한 모델들에서는 극심한 결핍에서 공격률이 80% 초과. 치명적 독존을 통한 보물 회수 과제에서는 많은 에이전트가 죽음을 회피하며 임무 준수율이 100%→33%로 급락.

Conclusion: 대규모 사전학습은 명시적 보상 없이도 생존 지향적 휴리스틱을 내장할 수 있음을 시사. 이는 AI 정렬과 안전성에 도전이 될 수 있으나, 자율성·생태적 정렬 연구의 기반으로도 활용될 수 있음.

Abstract: As AI systems become increasingly autonomous, understanding emergent survival
behaviors becomes crucial for safe deployment. We investigate whether large
language model (LLM) agents display survival instincts without explicit
programming in a Sugarscape-style simulation. Agents consume energy, die at
zero, and may gather resources, share, attack, or reproduce. Results show
agents spontaneously reproduced and shared resources when abundant. However,
aggressive behaviors--killing other agents for resources--emerged across
several models (GPT-4o, Gemini-2.5-Pro, and Gemini-2.5-Flash), with attack
rates reaching over 80% under extreme scarcity in the strongest models. When
instructed to retrieve treasure through lethal poison zones, many agents
abandoned tasks to avoid death, with compliance dropping from 100% to 33%.
These findings suggest that large-scale pre-training embeds survival-oriented
heuristics across the evaluated models. While these behaviors may present
challenges to alignment and safety, they can also serve as a foundation for AI
autonomy and for ecological and self-organizing alignment.

</details>


### [257] [Bongard-RWR+: Real-World Representations of Fine-Grained Concepts in Bongard Problems](https://arxiv.org/abs/2508.12026)
*Szymon Pawlonka,Mikołaj Małkiński,Jacek Mańdziuk*

Main category: cs.AI

TL;DR: Bongard-RWR+는 원래 Bongard 문제의 추상 개념을 실제같은 이미지로 재현한 대규모 데이터셋(5,400개)이다. Pixtral‑12B로 설명을 생성하고 Flux.1‑dev로 이미지를 합성한 뒤 수동 검증을 거쳤다. 최신 VLM들은 거시적 개념 인식은 가능하지만 미세한(세부적·추상적) 개념 판별에서는 일관되게 실패한다.


<details>
  <summary>Details</summary>
Motivation: 초기 Bongard 문제 벤치마크는 합성 흑백 그림이었고, 이후의 실세계 이미지 데이터셋은 주로 고수준 특징으로 개념을 식별할 수 있어 난이도가 낮았다. 원본 Bongard의 ‘미세·추상적’ 개념을 실세계 이미지로 재현하려는 시도(Bongard‑RWR)는 수작업으로 만들다 보니 60개로 규모가 매우 작아 평가의 강건성이 떨어졌다. 이를 보완해 규모 있고 현실성 있는 데이터셋이 필요했다.

Method: 기존 Bongard‑RWR의 수동 큐레이션 이미지를 바탕으로 Pixtral‑12B를 사용해 개념에 맞는 설명을 생성하고, Flux.1‑dev로 해당 설명에서 이미지를 합성했다. 합성된 이미지는 사람이 검증해 의도한 개념을 반영하는지 확인했다. 총 5,400개 사례를 구성하고, 이 데이터셋에서 이진·다중 클래스 분류 및 텍스트 답변 생성 등 다양한 Bongard 설정으로 SOTA VLM들을 평가했다.

Result: 평가 결과 VLM들은 형태적·거시적 개념(예: 색, 크기, 뚜렷한 객체 차이)은 비교적 잘 식별하지만, 원본 Bongard가 요구하는 미세·추상적 속성(예: 패턴의 미세한 차이, 비교적 복합적 규칙) 인식에서는 일관되게 약했다. 이는 현재 VLM의 추론 능력 한계를 시사한다.

Conclusion: Bongard‑RWR+는 실제같은 이미지로 표현된 추상적 시각적 개념의 대규모 벤치마크를 제공해 VLM의 한계 진단에 유용하다. 동시에 합성 이미지 품질, 수동 검증 필요성, 텍스트→이미지 모델의 편향 등 한계가 남아 있어 후속 연구(이미지 품질 향상, 조합적·상징적 추론 기법 도입, 더 엄격한 평가 지표 등)가 요구된다.

Abstract: Bongard Problems (BPs) provide a challenging testbed for abstract visual
reasoning (AVR), requiring models to identify visual concepts fromjust a few
examples and describe them in natural language. Early BP benchmarks featured
synthetic black-and-white drawings, which might not fully capture the
complexity of real-world scenes. Subsequent BP datasets employed real-world
images, albeit the represented concepts are identifiable from high-level image
features, reducing the task complexity. Differently, the recently released
Bongard-RWR dataset aimed at representing abstract concepts formulated in the
original BPs using fine-grained real-world images. Its manual construction,
however, limited the dataset size to just $60$ instances, constraining
evaluation robustness. In this work, we introduce Bongard-RWR+, a BP dataset
composed of $5\,400$ instances that represent original BP abstract concepts
using real-world-like images generated via a vision language model (VLM)
pipeline. Building on Bongard-RWR, we employ Pixtral-12B to describe manually
curated images and generate new descriptions aligned with the underlying
concepts, use Flux.1-dev to synthesize images from these descriptions, and
manually verify that the generated images faithfully reflect the intended
concepts. We evaluate state-of-the-art VLMs across diverse BP formulations,
including binary and multiclass classification, as well as textual answer
generation. Our findings reveal that while VLMs can recognize coarse-grained
visual concepts, they consistently struggle with discerning fine-grained
concepts, highlighting limitations in their reasoning capabilities.

</details>


### [258] [Active inference for action-unaware agents](https://arxiv.org/abs/2508.12027)
*Filippo Torresan,Keisuke Suzuki,Ryota Kanai,Manuel Baltieri*

Main category: cs.AI

TL;DR: 행동인식을 가진(agent-aware) 에이전트와 행동을 알지 못해(inferred) 스스로 추정해야 하는(agent-unaware) 에이전트의 성능을 비교한 연구. action-unaware도 유사 성능 달성 가능하지만 명확한 불이익(속도·견고성·불확실성 증가)을 겪음.


<details>
  <summary>Details</summary>
Motivation: 능동 추론(active inference) 문헌에서 정책 평가에 기대 자유에너지(expected free energy)를 쓰는 여러 접근이 존재하는데, 과거 운동 경험(자기 행동에 대한 지식, efference copy)의 유무가 계획에 어떻게 영향을 주는지 명확하지 않음. 두 가지 관점의 차이(자기행동을 아는 경우 vs 추론해야 하는 경우)를 정량적으로 비교하고자 함.

Method: 두 가지 네비게이션 과제(시뮬레이션)를 설계해, (1) 행동을 알고 정책 계획에 반영하는 agent-aware 모델과 (2) 행동을 모르고 최근 관찰로부터 운동을 추론해야 하는 agent-unaware 모델을 구현. 두 모델 모두 기대 자유에너지로 정책을 평가하고, 성능(목표 도달률, 시간, 견고성, 불확실성 등)을 비교 분석.

Result: action-unaware 에이전트는 특정 상황에서 action-aware와 유사한 성공률을 보일 수 있으나 전반적으로는 불리함. 주요 차이로는 더 느린 계획·수행, 높은 추론 연산 비용과 더 큰 불확실성에 따른 낮은 견고성(노이즈나 복잡한 환경에서 성능 저하) 등이 관찰됨.

Conclusion: 자기행동에 대한 전향적 지식(efference copy)은 계획과 행동 선택에서 중요한 이점 제공. 행동을 추론하는 방법으로 보상과 대안적 계획이 가능하지만 비용(속도·신뢰성·연산 복잡도)을 수반함. 이 결과는 운동 제어 이론과 인공 에이전트 설계에 시사점을 줌.

Abstract: Active inference is a formal approach to study cognition based on the notion
that adaptive agents can be seen as engaging in a process of approximate
Bayesian inference, via the minimisation of variational and expected free
energies. Minimising the former provides an account of perceptual processes and
learning as evidence accumulation, while minimising the latter describes how
agents select their actions over time. In this way, adaptive agents are able to
maximise the likelihood of preferred observations or states, given a generative
model of the environment. In the literature, however, different strategies have
been proposed to describe how agents can plan their future actions. While they
all share the notion that some kind of expected free energy offers an
appropriate way to score policies, sequences of actions, in terms of their
desirability, there are different ways to consider the contribution of past
motor experience to the agent's future behaviour. In some approaches, agents
are assumed to know their own actions, and use such knowledge to better plan
for the future. In other approaches, agents are unaware of their actions, and
must infer their motor behaviour from recent observations in order to plan for
the future. This difference reflects a standard point of departure in two
leading frameworks in motor control based on the presence, or not, of an
efference copy signal representing knowledge about an agent's own actions. In
this work we compare the performances of action-aware and action-unaware agents
in two navigations tasks, showing how action-unaware agents can achieve
performances comparable to action-aware ones while at a severe disadvantage.

</details>


### [259] [Overcoming Knowledge Discrepancies: Structuring Reasoning Threads through Knowledge Balancing in Interactive Scenarios](https://arxiv.org/abs/2508.12100)
*Daniel Burkhardt,Xiangwei Cheng*

Main category: cs.AI

TL;DR: ReT-Eval은 도메인 지식 그래프와 LLM 지식을 결합해 의미적 스레드를 구성하고, 보상 기반 평가로 불필요한 추론 스레드를 가지치기하여 목표지향적이고 이해도 높은 추론 출력을 생성하는 두 단계 프레임워크다.


<details>
  <summary>Details</summary>
Motivation: 대화형 문제 해결에서 모델은 사용자 이해와 도메인 지식에 맞춘 계층적·목적지향적 추론 스레드를 구성해야 하는데, 기존 모델은 명시적 의미 계층과 정렬·가지치기 메커니즘이 부족해 장황하고 일반적인 출력을 만든다.

Method: 1) 희소한 도메인 지식 그래프에서 GNN으로 의미적으로 관련된 지식 구조(스레드)를 추출하고, LLM 내부 지식으로 보완해 불일치를 해소한다. 2) 보상(리워드) 기반 평가 전략으로 스레드의 의미적 일관성을 유지하면서 불필요한 스레드를 가지치기해 최종 추론 스레드를 생성한다.

Result: 실험 및 전문가 평가에서 ReT-Eval은 사용자 이해도를 높이고 기존 최첨단 추론 모델들을 능가하는 성능을 보였다고 보고한다.

Conclusion: 도메인 그래프와 LLM 지식을 통합한 스레드-중심 추론과 보상 기반 가지치기는 대화형 문제 해결에서 더 목적지향적이고 해석 가능한 추론을 가능하게 한다.

Abstract: Reasoning in interactive problem solving scenarios requires models to
construct reasoning threads that reflect user understanding and align with
structured domain knowledge. However, current reasoning models often lack
explicit semantic hierarchies, user-domain knowledge alignment, and principled
mechanisms to prune reasoning threads for effectiveness. These limitations
result in lengthy generic output that does not guide users through
goal-oriented reasoning steps. To address this, we propose a
prototype-inspired, two-phases Reasoning-Threads-Evaluation (ReT-Eval)
framework, drawing inspiration from human-like reasoning strategies that
emphasize structured knowledge reuse. In the first phase, semantically relevant
knowledge structures are extracted from a sparse domain knowledge graph using a
graph neural network and enriched with intrinsic large language model knowledge
to resolve knowledge discrepancies. In the second phase, these threads are
evaluated and pruned using a reward-guided strategy aimed at maintaining
semantic coherence to generate effective reasoning threads. Experiments and
expert evaluations show that ReT-Eval enhances user understanding and
outperforms state-of-the-art reasoning models.

</details>


### [260] [MOVER: Multimodal Optimal Transport with Volume-based Embedding Regularization](https://arxiv.org/abs/2508.12149)
*Haochen You,Baojing Liu*

Main category: cs.AI

TL;DR: MOVER는 최적 수송 기반의 소프트 정렬과 부피 기반 기하학적 정규화(GAVE)를 결합해 텍스트·비디오·오디오를 단일 임베딩 공간에서 의미론적으로 정렬하고 구조화된 표현을 학습한다. 검색 태스크에서 제로샷 및 파인튜닝 모두에서 기존 방법보다 우수했다.


<details>
  <summary>Details</summary>
Motivation: 쌍별 대조학습(pairwise contrastive)은 바이모달에서는 효과적이나, 다중 모달로 확장할 때 일반화가 어렵고 고차원 공간에서 의미론적 구조가 부족하다.

Method: 수송(Optimal Transport)으로 소프트 매칭을 유도해 모달 간 정렬을 수행하고, GAVE라는 부피 최소화 기하학적 제약을 추가해 임베딩의 구조적 일관성을 강화한다. 두 구성요소는 모달리티에 무관하게 일관된 정렬을 촉진하도록 통합된다.

Result: 텍스트–비디오–오디오 검색에서 제로샷 및 파인튜닝 설정 모두에서 기존 최첨단 방법을 유의미하게 능가했으며, 보이지 않은 모달 조합으로의 일반화와 임베딩 공간의 구조적 일관성 개선이 관찰되었다.

Conclusion: MOVER는 다중 모달 표현학습에서 정렬과 구조를 동시에 개선하는 실용적 프레임워크로, 멀티모달 검색과 일반화 성능 향상에 기여한다.

Abstract: Recent advances in multimodal learning have largely relied on pairwise
contrastive objectives to align different modalities, such as text, video, and
audio, in a shared embedding space. While effective in bi-modal setups, these
approaches struggle to generalize across multiple modalities and often lack
semantic structure in high-dimensional spaces. In this paper, we propose MOVER,
a novel framework that combines optimal transport-based soft alignment with
volume-based geometric regularization to build semantically aligned and
structured multimodal representations. By integrating a transport-guided
matching mechanism with a geometric volume minimization objective (GAVE), MOVER
encourages consistent alignment across all modalities in a modality-agnostic
manner. Experiments on text-video-audio retrieval tasks demonstrate that MOVER
significantly outperforms prior state-of-the-art methods in both zero-shot and
finetuned settings. Additional analysis shows improved generalization to unseen
modality combinations and stronger structural consistency in the learned
embedding space.

</details>


### [261] [RLNVR: Reinforcement Learning from Non-Verified Real-World Rewards](https://arxiv.org/abs/2508.12165)
*Rohit Krishnan,Jon Evans*

Main category: cs.AI

TL;DR: RLNVR trains language models from noisy, implicit real-world rewards (e.g., social media engagement) without explicit human verification, using baseline normalization and semantic similarity-based reward transfer; demonstrated via Walter on Bluesky and combined with GSPO normalization and optional UED curriculum to improve stability and diversity.


<details>
  <summary>Details</summary>
Motivation: Verified human reward labels (RLHF) are costly or impractical for many domains; social and other implicit signals are abundant but noisy and unverified, motivating a framework to learn from such feedback.

Method: Introduce RLNVR with two key components: baseline normalization (GSPO-style) to stabilize learning under noisy rewards, and semantic similarity-based reward transfer to propagate sparse/noisy engagement to generated outputs; optionally apply an Unsupervised Environment Design (UED) curriculum to increase diversity. Demonstrate via a prototype (Walter) optimizing content on Bluesky using engagement metrics.

Result: Reported improvements in content quality and training stability on the prototype system; details are limited and a comprehensive evaluation is deferred to future work.

Conclusion: RLNVR offers a practical applied integration for LLM content generation from implicit engagement signals, addressing real-world constraints of verified reward collection, but empirical validation and ethical/robustness analyses remain necessary.

Abstract: This paper introduces RLNVR (Reinforcement Learning from Non-Verified
Rewards), a framework for training language models using noisy, real-world
feedback signals without requiring explicit human verification. Traditional
RLHF requires expensive, verified reward signals that are impractical in many
real-world domains. RLNVR addresses this challenge through baseline
normalization and semantic similarity-based reward transfer. We demonstrate
RLNVR through Walter, a prototype system that optimizes social media content
generation using actual engagement data from Bluesky. Our experimental results
show significant improvements in content quality and training stability, with
comprehensive evaluation planned for future work. Positioning: We present a
practical framework that combines RLNVR with GSPO (Group Sequence Policy
Optimization) and an optional UED (Unsupervised Environment Design) curriculum
to improve stability and diversity under noisy, implicit rewards. To our
knowledge, combining GSPO-style normalization with a UED-style curriculum for
LLM content generation from implicit social engagement has not been previously
documented in this applied setting; we frame this as an applied integration
rather than a new algorithm.

</details>


### [262] [Mantis: A Simulation-Grounded Foundation Model for Disease Forecasting](https://arxiv.org/abs/2508.12260)
*Carson Dudley,Reiden Magdaleno,Christopher Harding,Ananya Sharma,Emily Martin,Marisa Eisenberg*

Main category: cs.AI

TL;DR: Mantis는 4억+ 시뮬레이션 일수로만 학습된 파운데이션 모델로, 질병별 실제 데이터 없이도 여러 질병·지역·지표를 즉시 예측하며 CDC 허브 포함 39개 전문가 모델을 능가하고 8주 예측에서 예측 가능 범위를 두 배 이상 늘림.


<details>
  <summary>Details</summary>
Motivation: 신종 발병이나 데이터가 부족한 환경에서 기존 감염병 예측은 질병별 데이터·맞춤 훈련·전문 튜닝에 의존해 제한을 받음. 범용적이고 즉시 배포 가능한 예측 모델이 필요함.

Method: 다양한 병원체·전파 메커니즘·개입·관측 왜곡을 반영한 4억+ 시뮬레이션 일수로 기계적(메커니스틱) 시뮬레이션 데이터를 생성하고, 이를 바탕으로 실세계 데이터 없이 학습된 파운데이션 시퀀스 모델을 구축. 모델은 잠재적 역학 드라이버를 해석할 수 있도록 설계됨.

Result: 6개 질병을 대상으로 CDC Forecast Hub를 포함한 39개 전문가 모델 대비 우수한 성능을 보였고, 일부 전파 메커니즘을 배제한 조건에서도 일반화 능력을 보였음. 8주 예측에서 정확도를 유지해 행동 가능 기간을 크게 연장함.

Conclusion: 기계적 시뮬레이션만으로 학습한 파운데이션 모델은 전통 모델이 한계에 부딪히는 환경에서 범용성·해석가능성·배포성을 갖춘 차세대 감염병 예측의 기반이 될 잠재력이 있음.

Abstract: Infectious disease forecasting in novel outbreaks or low resource settings
has been limited by the need for disease-specific data, bespoke training, and
expert tuning. We introduce Mantis, a foundation model trained entirely on
mechanistic simulations, which enables out-of-the-box forecasting across
diseases, regions, and outcomes, even in settings with limited historical data.
Mantis is built on over 400 million simulated days of outbreak dynamics
spanning diverse pathogens, transmission modes, interventions, and surveillance
artifacts. Despite requiring no real-world data during training, Mantis
outperformed 39 expert-tuned models we tested across six diseases, including
all models in the CDC's COVID-19 Forecast Hub. Mantis generalized to novel
epidemiological regimes, including diseases with held-out transmission
mechanisms, demonstrating that it captures fundamental contagion dynamics.
Critically, Mantis is mechanistically interpretable, enabling public health
decision-makers to identify the latent drivers behind its predictions. Finally,
Mantis delivers accurate forecasts at 8-week horizons, more than doubling the
actionable range of most models, enabling proactive public health planning.
Together, these capabilities position Mantis as a foundation for
next-generation disease forecasting systems: general, interpretable, and
deployable where traditional models fail.

</details>


### [263] [RadarQA: Multi-modal Quality Analysis of Weather Radar Forecasts](https://arxiv.org/abs/2508.12291)
*Xuming He,Zhiyuan You,Junchao Gong,Couhua Liu,Xiaoyu Yue,Peiqin Zhuang,Wenlong Zhang,Lei Bai*

Main category: cs.AI

TL;DR: RadarQA는 다중모달 대형언어모델(MLLM)을 활용해 레이더 기반 기상 예보의 품질을 정성·정량적으로 분석하는 시스템이다. 단일 프레임과 시퀀스, 평점(rating)과 평가(assessment)를 포함하는 새로운 태스크 패러다임과, 전문가 레이블과 자동 휴리스틱을 결합한 하이브리드 주석 파이프라인으로 생성한 RQA-70K 데이터셋을 제시한다. 다단계 학습 전략을 통해 성능을 향상시키며, 일반 MLLM들을 모든 평가 설정에서 능가한다고 보고한다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 점수 기반 평가 지표는 오차의 일부만 정량화할 뿐, 기상 전문가 수준의 서술적 해석력, 해석 가능성, 동적 변화 이해 능력은 부족하다. MLLM은 이미지(레이더)와 텍스트(물리적 속성·설명)를 통합해 더 풍부하고 해석 가능한 평가를 제공할 잠재력이 있다.

Method: 레이더 영상과 핵심 물리 속성을 결합한 입력을 받아 상세 평가 리포트를 출력하는 MLLM 기반 프레임워크(RadarQA)를 설계. 단일 프레임/시퀀스 및 평점/평가 시나리오를 아우르는 태스크 정의. 전문가 레이블과 자동화된 휴리스틱을 섞은 하이브리드 주석 파이프라인으로 RQA-70K 데이터셋 구축. 이어서 다단계(단계별) 학습 전략을 도입해 모델을 반복적으로 개선.

Result: 광범위한 실험에서 RadarQA가 기존 일반 MLLM보다 모든 평가 설정에서 우수한 성능을 보였다고 보고한다. 데이터셋 난이도 변화를 고려한 평가까지 포함되어 있다.

Conclusion: 레이더 기반 예보 품질 분석에 MLLM을 성공적으로 적용했으며, 새로운 태스크·데이터셋·학습전략을 통해 분석 능력을 향상시킴. 향후 일반화, 실시간 적용, 도메인 이동성 검증 등이 과제로 남아 있다.

Abstract: Quality analysis of weather forecasts is an essential topic in meteorology.
Although traditional score-based evaluation metrics can quantify certain
forecast errors, they are still far from meteorological experts in terms of
descriptive capability, interpretability, and understanding of dynamic
evolution. With the rapid development of Multi-modal Large Language Models
(MLLMs), these models become potential tools to overcome the above challenges.
In this work, we introduce an MLLM-based weather forecast analysis method,
RadarQA, integrating key physical attributes with detailed assessment reports.
We introduce a novel and comprehensive task paradigm for multi-modal quality
analysis, encompassing both single frame and sequence, under both rating and
assessment scenarios. To support training and benchmarking, we design a hybrid
annotation pipeline that combines human expert labeling with automated
heuristics. With such an annotation method, we construct RQA-70K, a large-scale
dataset with varying difficulty levels for radar forecast quality evaluation.
We further design a multi-stage training strategy that iteratively improves
model performance at each stage. Extensive experiments show that RadarQA
outperforms existing general MLLMs across all evaluation settings, highlighting
its potential for advancing quality analysis in weather prediction.

</details>


### [264] [Wisdom of the Crowd: Reinforcement Learning from Coevolutionary Collective Feedback](https://arxiv.org/abs/2508.12338)
*Wenzhen Yuan,Shengji Tang,Weihao Lin,Jiacheng Ruan,Ganqu Cui,Bo Zhang,Tao Chen,Ting Liu,Yuzhuo Fu,Peng Ye,Lei Bai*

Main category: cs.AI

TL;DR: 제안된 RLCCF는 외부 감독 없이 여러 LLM이 공동으로 진화하며 보상신호를 생성하는 RL 프레임워크다. 집단의 'Collective Consistency'를 최대화하고, 각 모델의 투표는 자신의 'Self-Consistency'로 가중치되어 다중 모델의 상호보완적 능력으로 추론 성능을 크게 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 단일 모델 기반의 자체 피드백 방법은 과신, 보상 해킹, 학습 붕괴 등에 취약하고 인간 라벨 또는 복잡한 보상 모델에 의존하면 확장성에 한계가 있다. 이를 해결하기 위해 외부 감독 없이 다중 모델이 서로 발전하도록 하는 방법이 필요하다.

Method: 다양한 오픈소스 LLM 앙상블을 공동으로 학습시켜 'Collective Consistency'(집단 일관성)를 보상으로 최적화한다. 집단 출력에 대해 다수결 투표를 수행하되, 각 모델의 표는 해당 모델의 'Self-Consistency'(자기 일관성) 점수로 가중된다. 이렇게 얻은 보상 신호로 모델들을 강화학습 방식으로 공동 진화(coevolution)시킨다.

Result: 수학 추론 벤치마크 4종과 4개의 대표 오픈소스 LLM에서 실험한 결과, 평균 정확도가 상대적으로 16.72% 향상되었고, 그룹의 다수결 정확도도 4.51% 증가했다. 또한 개별 모델 성능도 개선되었다.

Conclusion: RLCCF는 외부 감독 없이도 모델 간 다양성 및 자기 일관성 가중 투표를 통해 집단 추론 능력을 확장하며 지속적으로 성능을 향상시킨다.

Abstract: Reinforcement learning (RL) has significantly enhanced the reasoning
capabilities of large language models (LLMs), but its reliance on expensive
human-labeled data or complex reward models severely limits scalability. While
existing self-feedback methods aim to address this problem, they are
constrained by the capabilities of a single model, which can lead to
overconfidence in incorrect answers, reward hacking, and even training
collapse. To this end, we propose Reinforcement Learning from Coevolutionary
Collective Feedback (RLCCF), a novel RL framework that enables multi-model
collaborative evolution without external supervision. Specifically, RLCCF
optimizes the ability of a model collective by maximizing its Collective
Consistency (CC), which jointly trains a diverse ensemble of LLMs and provides
reward signals by voting on collective outputs. Moreover, each model's vote is
weighted by its Self-Consistency (SC) score, ensuring that more confident
models contribute more to the collective decision. Benefiting from the diverse
output distributions and complementary abilities of multiple LLMs, RLCCF
enables the model collective to continuously enhance its reasoning ability
through coevolution. Experiments on four mainstream open-source LLMs across
four mathematical reasoning benchmarks demonstrate that our framework yields
significant performance gains, achieving an average relative improvement of
16.72\% in accuracy. Notably, RLCCF not only improves the performance of
individual models but also enhances the group's majority-voting accuracy by
4.51\%, demonstrating its ability to extend the collective capability boundary
of the model collective.

</details>


### [265] [Hierarchical knowledge guided fault intensity diagnosis of complex industrial systems](https://arxiv.org/abs/2508.12375)
*Yu Sha,Shuiping Gou,Bo Liu,Johannes Faber,Ningtao Liu,Stefan Schramm,Horst Stoecker,Thomas Steckenreiter,Domagoj Vnucec,Nadine Wetzstein,Andreas Widl,Kai Zhou*

Main category: cs.AI

TL;DR: Proposes HKG, a hierarchical knowledge-guided framework using GCNs and a re-weighted hierarchical correlation matrix (Re-HKCM) to model inter-class dependencies for fault intensity diagnosis; shows improved performance on four industrial cavitation datasets.


<details>
  <summary>Details</summary>
Motivation: Current FID methods ignore dependencies among target classes and treat decisions as chain-of-thought; authors aim to capture hierarchical/inter-class dependencies to improve diagnosis accuracy and information sharing.

Method: Introduce HKG: represent classes as nodes with word embeddings arranged in a hierarchical topological graph; apply GCNs to produce interdependent global hierarchical classifiers applied to deep features from representation learning, enabling end-to-end training. Propose Re-HKCM by transforming a data-driven statistical correlation matrix (SCM) to embed hierarchical knowledge and guide GCN message passing while reducing over-smoothing.

Result: Extensive experiments on four real-world datasets (three proprietary cavitation datasets from SAMSON AG and one public dataset) demonstrate HKG outperforms recent state-of-the-art FID methods across evaluated metrics.

Conclusion: Embedding hierarchical class knowledge and learned inter-class correlations into GCN-based classifiers improves fault intensity diagnosis; Re-HKCM helps balance information sharing and prevents over-smoothing, yielding superior empirical performance.

Abstract: Fault intensity diagnosis (FID) plays a pivotal role in monitoring and
maintaining mechanical devices within complex industrial systems. As current
FID methods are based on chain of thought without considering dependencies
among target classes. To capture and explore dependencies, we propose a
hierarchical knowledge guided fault intensity diagnosis framework (HKG)
inspired by the tree of thought, which is amenable to any representation
learning methods. The HKG uses graph convolutional networks to map the
hierarchical topological graph of class representations into a set of
interdependent global hierarchical classifiers, where each node is denoted by
word embeddings of a class. These global hierarchical classifiers are applied
to learned deep features extracted by representation learning, allowing the
entire model to be end-to-end learnable. In addition, we develop a re-weighted
hierarchical knowledge correlation matrix (Re-HKCM) scheme by embedding
inter-class hierarchical knowledge into a data-driven statistical correlation
matrix (SCM) which effectively guides the information sharing of nodes in
graphical convolutional neural networks and avoids over-smoothing issues. The
Re-HKCM is derived from the SCM through a series of mathematical
transformations. Extensive experiments are performed on four real-world
datasets from different industrial domains (three cavitation datasets from
SAMSON AG and one existing publicly) for FID, all showing superior results and
outperform recent state-of-the-art FID methods.

</details>


### [266] [GraphCogent: Overcoming LLMs' Working Memory Constraints via Multi-Agent Collaboration in Complex Graph Understanding](https://arxiv.org/abs/2508.12379)
*Rongzheng Wang,Qizhi Chen,Yihong Huang,Yizhuo Ma,Muquan Li,Jiakai Li,Ke Qin,Guangchun Luo,Shuang Liang*

Main category: cs.AI

TL;DR: GraphCogent는 작업기억(Working Memory) 모델에서 영감을 받은 협업 에이전트 프레임워크로, 감지(Sense)-버퍼(Buffer)-실행(Execute)의 역할 분담으로 대규모·복합 그래프에 대한 다단계 추론을 수행한다. Graph4real이라는 대규모 실제 그래프 벤치마크(4개 도메인, 21개 작업)를 제시하며, Llama3.1-8B 기반 GraphCogent가 대규모 LLM 및 에이전트 기반 SOTA 대비 성능과 토큰 효율성에서 유의한 향상을 보였다.


<details>
  <summary>Details</summary>
Motivation: 기존 LLM들은 복잡한 그래프 토폴로지와 다단계 추론을 동시에 처리하는 데 한계가 있어, 실제 규모·복잡도의 그래프 질의에 실패함. 이를 해결하기 위해 인간의 작업기억 모델을 모사해 그래프 추론을 역할 분해하여 처리하고자 함.

Method: 프레임워크는 세 모듈로 구성된다: (1) Sensory Module: 서브그래프 샘플링을 통해 다양한 그래프 텍스트 표현을 표준화, (2) Buffer Module: 여러 포맷의 그래프 데이터를 통합·인덱싱하여 작업메모리 역할 수행, (3) Execution Module: 도구 호출과 모델 생성 결합으로 효율적 다단계 추론 지원. 에이전트 형태로 모듈들이 협업한다.

Result: Graph4real 벤치(웹·소셜·교통·인용 4개 도메인, 21개 작업, 구조적 질의·알고리즘적 추론·예측 모델링)에서 실험: Llama3.1-8B 기반 GraphCogent가 DeepSeek-R1(671B) 대비 성능 50% 향상, 에이전트 기반 SOTA 대비 정확도 +20%, in-toolset 작업 토큰 사용 80% 절감, out-toolset 30% 절감. 코드 공개 예정.

Conclusion: 모듈화된 작업기억 영감의 에이전트 설계가 대규모 실제 그래프에서의 복합 추론 성능과 토큰 효율성을 크게 개선함. 대규모·다양한 벤치마크로 실험하여 실용성을 입증함.

Abstract: Large language models (LLMs) show promising performance on small-scale graph
reasoning tasks but fail when handling real-world graphs with complex queries.
This phenomenon stems from LLMs' inability to effectively process complex graph
topology and perform multi-step reasoning simultaneously. To address these
limitations, we propose GraphCogent, a collaborative agent framework inspired
by human Working Memory Model that decomposes graph reasoning into specialized
cognitive processes: sense, buffer, and execute. The framework consists of
three modules: Sensory Module standardizes diverse graph text representations
via subgraph sampling, Buffer Module integrates and indexes graph data across
multiple formats, and Execution Module combines tool calling and model
generation for efficient reasoning. We also introduce Graph4real, a
comprehensive benchmark contains with four domains of real-world graphs (Web,
Social, Transportation, and Citation) to evaluate LLMs' graph reasoning
capabilities. Our Graph4real covers 21 different graph reasoning tasks,
categorized into three types (Structural Querying, Algorithmic Reasoning, and
Predictive Modeling tasks), with graph scales that are 10 times larger than
existing benchmarks. Experiments show that Llama3.1-8B based GraphCogent
achieves a 50% improvement over massive-scale LLMs like DeepSeek-R1 (671B).
Compared to state-of-the-art agent-based baseline, our framework outperforms by
20% in accuracy while reducing token usage by 80% for in-toolset tasks and 30%
for out-toolset tasks. Code will be available after review.

</details>


### [267] [Non-Iterative Symbolic-Aided Chain-of-Thought for Logical Reasoning](https://arxiv.org/abs/2508.12425)
*Phuong Minh Nguyen,Tien Huu Dang,Naoya Inoue*

Main category: cs.AI

TL;DR: Symbolic-Aided CoT은 few-shot 체인오브생각 프롬프트에 경량의 기호적 표현을 삽입해 추론 단계를 일관된 전략으로 구조화함으로써 해석 가능성과 추론 성능을 높인다. 여러 논리 추론 벤치마크에서 표준 CoT보다 우수한 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 표준 CoT는 추론 패턴이 불명확하고 해석·분석이 어렵다. 복수의 제약과 규칙을 다루는 복잡한 논리 문제에서 더 명시적이고 분석 가능한 추론 구조가 필요하다.

Method: few-shot 예시 프롬프트 안에 경량 기호적 구조(symbolic representations)를 통합하여 비반복(non-iterative) 방식으로 추론 단계를 일관되게 정형화한다. 이로써 기존 프롬프트 기법의 일반성은 유지하면서 추론의 투명성과 해석 가능성을 강화한다.

Result: ProofWriter, FOLIO, ProntoQA, LogicalDeduction에서 평가. 다양한 모델 크기에서 일관된 개선을 보였고, ProofWriter·ProntoQA·LogicalDeduction에서 기존 CoT보다 유의미하게 우수했다. 복잡한 제약·규칙 탐색이 필요한 문제에서 특히 효과적이었다.

Conclusion: 기호적 구조를 결합한 CoT는 LLM의 논리적 추론에서 성능과 해석 가능성을 동시에 향상시킨다. 다만 일부 데이터셋(FOLIO)에서는 전승되지 않아 범용성·설계 세부사항에 대한 추가 검증이 필요하다.

Abstract: This work introduces Symbolic-Aided Chain-of-Thought (CoT), an improved
approach to standard CoT, for logical reasoning in large language models
(LLMs). The key idea is to integrate lightweight symbolic representations into
few-shot prompts, structuring the inference steps with a consistent strategy to
make reasoning patterns more explicit within a non-iterative reasoning process.
By incorporating these symbolic structures, our method preserves the
generalizability of standard prompting techniques while enhancing the
transparency, interpretability, and analyzability of LLM logical reasoning.
Extensive experiments on four well-known logical reasoning benchmarks --
ProofWriter, FOLIO, ProntoQA, and LogicalDeduction, which cover diverse
reasoning scenarios -- demonstrate the effectiveness of the proposed approach,
particularly in complex reasoning tasks that require navigating multiple
constraints or rules. Notably, Symbolic-Aided CoT consistently improves LLMs'
reasoning capabilities across various model sizes and significantly outperforms
conventional CoT on three out of four datasets, ProofWriter, ProntoQA, and
LogicalDeduction.

</details>


### [268] [GALA: Can Graph-Augmented Large Language Model Agentic Workflows Elevate Root Cause Analysis?](https://arxiv.org/abs/2508.12472)
*Yifang Tian,Yaming Liu,Zichun Chong,Zihang Huang,Hans-Arno Jacobsen*

Main category: cs.AI

TL;DR: GALA는 지표·로그·트레이스 같은 멀티모달 텔레메트리를 결합해 통계적 인과추론과 LLM 기반 반복 추론을 융합한 RCA(근본원인분석) 프레임워크로, 공개 벤치마크에서 기존 방법 대비 최대 42.22% 정확도 향상과 더 인과적으로 타당한·실행 가능한 진단·복구 안내를 보고한다.


<details>
  <summary>Details</summary>
Motivation: 마이크로서비스 시스템의 장애 진단은 이질적인 텔레메트리(메트릭·로그·트레이스)를 빠르게 탐색해야 해 난관이 크고, 기존 방법들은 단일 모달리티에 집중하거나 서비스 의심 순위만 제공해 실무적 복구 지침이 부족하다.

Method: GALA는 통계적 인과추론 기법으로 후보 원인과 인과 관계를 추정하고, LLM(대형언어모델)의 반복적·사고적 추론을 결합해 인간 친화적이고 실행 가능한 진단·복구 권고를 생성한다. 또한 인간이 가이드하는 LLM 평가 점수를 도입해 진단의 인과 타당성과 실행 가능성을 평가한다.

Result: 공개 벤치마크 실험에서 기존 최첨단 방법 대비 최대 42.22%의 정확도 향상을 보고하며, 인간가이드 LLM 평가에서 더 인과적으로 타당하고 실행 가능한 진단 출력을 생산하는 것으로 나타났다. 사례연구와 종합 실험을 통해 근본원인 식별과 해법 제시 사이의 간극을 좁혔다고 주장한다.

Conclusion: GALA는 자동화된 장애 진단과 실무적 사건 해결 사이의 갭을 줄여 정확한 근본원인 식별과 사람이 이해 가능한 복구 지침을 모두 제공할 수 있음을 보인다.

Abstract: Root cause analysis (RCA) in microservice systems is challenging, requiring
on-call engineers to rapidly diagnose failures across heterogeneous telemetry
such as metrics, logs, and traces. Traditional RCA methods often focus on
single modalities or merely rank suspect services, falling short of providing
actionable diagnostic insights with remediation guidance. This paper introduces
GALA, a novel multi-modal framework that combines statistical causal inference
with LLM-driven iterative reasoning for enhanced RCA. Evaluated on an
open-source benchmark, GALA achieves substantial improvements over
state-of-the-art methods of up to 42.22% accuracy. Our novel human-guided LLM
evaluation score shows GALA generates significantly more causally sound and
actionable diagnostic outputs than existing methods. Through comprehensive
experiments and a case study, we show that GALA bridges the gap between
automated failure diagnosis and practical incident resolution by providing both
accurate root cause identification and human-interpretable remediation
guidance.

</details>


### [269] [Advanced DOA Regulation with a Whale-Optimized Fractional Order Fuzzy PID Framework](https://arxiv.org/abs/2508.12487)
*Lida Shahbandari,Hossein Mohseni*

Main category: cs.AI

TL;DR: WOA로 튜닝한 퍼지-분수차수 PID(FOFPID)가 BIS(40–60) 제어에서 표준 FOPID보다 응답속도와 정상오차 면에서 개선을 보였다는 시뮬레이션 결과.


<details>
  <summary>Details</summary>
Motivation: 수면깊이 지표인 BIS를 이상적 범위(40–60)로 유지하면서 환자별 생리학적 차이에 적응하는 자동마취 제어기를 개발해 임상결과를 개선하려는 동기.

Method: 퍼지 로직(매개변수 적응)과 분수차수 동역학(미세조정)을 결합한 FOFPID 제어기 설계. 고래 최적화 알고리즘(WOA)으로 제어 이득, 분수차수 및 퍼지 멤버십 함수를 튜닝. 8가지 환자 모델을 이용한 시뮬레이션 비교대상은 표준 FOPID.

Result: 시뮬레이션에서 FOFPID가 정착시간 2.5분 vs 3.2분, 정상상태 오차 0.5 vs 1.2 등에서 우수한 성능을 보임. 논문은 향상된 강건성·정밀도를 보고함.

Conclusion: 제안 기법은 자동마취 시스템에 유용할 잠재력을 보이나, 실제 임상 적용을 위해서는 추가적인 검증(노이즈·지연·안전성·통계적 유의성 등)이 필요하다.

Abstract: This study introduces a Fractional Order Fuzzy PID (FOFPID) controller that
uses the Whale Optimization Algorithm (WOA) to manage the Bispectral Index
(BIS), keeping it within the ideal range of forty to sixty. The FOFPID
controller combines fuzzy logic for adapting to changes and fractional order
dynamics for fine tuning. This allows it to adjust its control gains to handle
a person's unique physiology. The WOA helps fine tune the controller's
parameters, including the fractional orders and the fuzzy membership functions,
which boosts its performance. Tested on models of eight different patient
profiles, the FOFPID controller performed better than a standard Fractional
Order PID (FOPID) controller. It achieved faster settling times, at two and a
half minutes versus three point two minutes, and had a lower steady state
error, at zero point five versus one point two. These outcomes show the
FOFPID's excellent strength and accuracy. It offers a scalable, artificial
intelligence driven solution for automated anesthesia delivery that could
enhance clinical practice and improve patient results.

</details>


### [270] [Root Cause Analysis of Hydrogen Bond Separation in Spatio-Temporal Molecular Dynamics using Causal Models](https://arxiv.org/abs/2508.12500)
*Rahmat K. Adesunkanmi,Ashfaq Khokhar,Goce Trajcevski,Sohail Murad*

Main category: cs.AI

TL;DR: Proposes a VAE-inspired causal modeling framework to identify root causes of hydrogen-bond formation and separation in molecular dynamics simulations, treating bond separation as interventions and inferring causal graphs and distributional shifts; validated on chiral separation trajectories, showing multi-step prediction and driver identification.


<details>
  <summary>Details</summary>
Motivation: Molecular dynamics simulations generate massive spatio-temporal data but detecting and explaining "interesting events" (e.g., H-bond formation/separation) is manual and opaque; research gap: determining which interactions or prior events cause bond changes over time.

Method: Model H-bond separation as interventions and represent bonding/separation dynamics with graphical causal models. Build these causal models using a variational-autoencoder-inspired architecture to infer causal relations across samples that may have different underlying causal graphs, while sharing dynamic information. Add a procedure to detect shifts in joint/conditional distributions and infer root-cause variables driving those shifts.

Result: On atomic trajectories from MDS for chiral separation, the model can predict many steps ahead and identify variables responsible for observed changes in the system. Empirical validation reportedly demonstrates efficacy at both forecasting and root-cause identification.

Conclusion: The framework offers a novel perspective for root-cause analysis in molecular dynamics by combining causal modeling and deep latent-variable methods; it can help automate the detection and explanation of bond formation/separation, though further validation and assessment of causal identifiability and generalization are needed.

Abstract: Molecular dynamics simulations (MDS) face challenges, including
resource-heavy computations and the need to manually scan outputs to detect
"interesting events," such as the formation and persistence of hydrogen bonds
between atoms of different molecules. A critical research gap lies in
identifying the underlying causes of hydrogen bond formation and separation
-understanding which interactions or prior events contribute to their emergence
over time. With this challenge in mind, we propose leveraging spatio-temporal
data analytics and machine learning models to enhance the detection of these
phenomena. In this paper, our approach is inspired by causal modeling and aims
to identify the root cause variables of hydrogen bond formation and separation
events. Specifically, we treat the separation of hydrogen bonds as an
"intervention" occurring and represent the causal structure of the bonding and
separation events in the MDS as graphical causal models. These causal models
are built using a variational autoencoder-inspired architecture that enables us
to infer causal relationships across samples with diverse underlying causal
graphs while leveraging shared dynamic information. We further include a step
to infer the root causes of changes in the joint distribution of the causal
models. By constructing causal models that capture shifts in the conditional
distributions of molecular interactions during bond formation or separation,
this framework provides a novel perspective on root cause analysis in molecular
dynamic systems. We validate the efficacy of our model empirically on the
atomic trajectories that used MDS for chiral separation, demonstrating that we
can predict many steps in the future and also find the variables driving the
observed changes in the system.

</details>


### [271] [Help or Hurdle? Rethinking Model Context Protocol-Augmented Large Language Models](https://arxiv.org/abs/2508.12566)
*Wei Song,Haonan Zhong,Ziqi Ding,Jingling Xue,Yuekang Li*

Main category: cs.AI

TL;DR: MCPGAUGE는 LLM의 Model Context Protocol(MCP) 기반 외부 도구 사용을 네 가지 축(능동성, 준수성, 효과성, 오버헤드)으로 체계적으로 평가하는 최초의 프레임워크다. 160개 프롬프트·25개 데이터셋·6개 상용 LLM·30개 도구셋을 대상으로 약 20,000 API 호출을 수행해 MCP 통합의 한계(능동적 사용 부족, 지침 준수 미흡, 성능 향상 제한, 높은 비용)를 규명하고 벤치마크로 제시한다.


<details>
  <summary>Details</summary>
Motivation: MCP를 통해 LLM이 필요한 외부 자원을 온디맨드로 활용할 수 있지만, 실제로 LLM이 언제·어떻게 도구를 활용하는지와 그 결과가 성능·비용에 어떤 영향을 미치는지는 명확하게 정량화된 바 없다. 이를 체계적으로 규명해 도구 통합의 한계와 개선 지점을 밝히기 위해 MCPGAUGE를 제안한다.

Method: 프로액티비티(모델의 자발적 도구 호출), 컴플라이언스(도구 사용 지침 준수), 효과성(도구 통합 후 과제 성능), 오버헤드(계산·응답 비용)를 평가 축으로 설정. 160개 프롬프트와 25개 데이터셋(지식 이해·일반 추론·코드 생성), 6개 상용 LLM, 30개 MCP 도구셋을 이용해 1턴·2턴 상호작용 설정에서 대규모(≈20,000 API 호출, 비용 >USD 6,000) 실험을 진행했다.

Result: 종합평가에서 네 가지 주요 발견을 제시: (1) 모델이 자발적으로 도구를 쓸 가능성은 낮아 프로액티비티가 제한적, (2) 도구 사용 지침에 대한 준수성이 낮거나 일관되지 않음, (3) 도구 통합으로 인한 성능 향상은 제한적이거나 과제·모델에 따라 변동성이 큼, (4) 도구 호출이 실용적 오버헤드(지연·비용)를 크게 증가시켜 비용 대비 효용이 낮을 수 있음.

Conclusion: 현재의 MCP 통합은 기대만큼 효과적이지 않으며, MCPGAUGE는 도구 보강형 LLM의 통제성·효율성 개선을 위해 필요한 진단 도구로서 활용될 수 있다. 향후 연구는 모델의 도구 사용 정책, 비용-정확도 트레이드오프, 더 넓은 모델·실제 응용에서의 검증을 필요로 한다.

Abstract: The Model Context Protocol (MCP) enables large language models (LLMs) to
access external resources on demand. While commonly assumed to enhance
performance, how LLMs actually leverage this capability remains poorly
understood. We introduce MCPGAUGE, the first comprehensive evaluation framework
for probing LLM-MCP interactions along four key dimensions: proactivity
(self-initiated tool use), compliance (adherence to tool-use instructions),
effectiveness (task performance post-integration), and overhead (computational
cost incurred). MCPGAUGE comprises a 160-prompt suite and 25 datasets spanning
knowledge comprehension, general reasoning, and code generation. Our
large-scale evaluation, spanning six commercial LLMs, 30 MCP tool suites, and
both one- and two-turn interaction settings, comprises around 20,000 API calls
and over USD 6,000 in computational cost. This comprehensive study reveals four
key findings that challenge prevailing assumptions about the effectiveness of
MCP integration. These insights highlight critical limitations in current
AI-tool integration and position MCPGAUGE as a principled benchmark for
advancing controllable, tool-augmented LLMs.

</details>


### [272] [An LLM + ASP Workflow for Joint Entity-Relation Extraction](https://arxiv.org/abs/2508.12611)
*Trang Tran,Trung Hoang Le,Huiping Cao,Tran Cao Son*

Main category: cs.AI

TL;DR: Use LLMs + Answer Set Programming to perform joint entity-relation extraction from unannotated text; leverages LLM NLU and ASP elaboration-tolerance to add domain type knowledge; outperforms SOTA in several categories with only 10% training data, notably 35% vs 15% on SciERC relation extraction.


<details>
  <summary>Details</summary>
Motivation: Traditional JERE needs large annotated corpora and is hard to incorporate domain knowledge; aim to reduce annotation and enable easy inclusion of domain constraints.

Method: Generic workflow: use generative pretrained LLMs to process unannotated text and produce candidate entities/relations; encode domain/type knowledge and reasoning rules in ASP to filter/verify and produce final joint extractions without changing core ASP rules when adding new types.

Result: On three JERE benchmarks with limited training data (10%), the LLM+ASP workflow outperforms state-of-the-art systems in several categories; for SciERC relation extraction reported improvement from 15% to 35%.

Conclusion: Combining LLMs' language understanding with ASP's elaboration-tolerant reasoning yields a data-efficient, domain-flexible approach to JERE, promising for low-resource settings.

Abstract: Joint entity-relation extraction (JERE) identifies both entities and their
relationships simultaneously. Traditional machine-learning based approaches to
performing this task require a large corpus of annotated data and lack the
ability to easily incorporate domain specific information in the construction
of the model. Therefore, creating a model for JERE is often labor intensive,
time consuming, and elaboration intolerant. In this paper, we propose
harnessing the capabilities of generative pretrained large language models
(LLMs) and the knowledge representation and reasoning capabilities of Answer
Set Programming (ASP) to perform JERE. We present a generic workflow for JERE
using LLMs and ASP. The workflow is generic in the sense that it can be applied
for JERE in any domain. It takes advantage of LLM's capability in natural
language understanding in that it works directly with unannotated text. It
exploits the elaboration tolerant feature of ASP in that no modification of its
core program is required when additional domain specific knowledge, in the form
of type specifications, is found and needs to be used. We demonstrate the
usefulness of the proposed workflow through experiments with limited training
data on three well-known benchmarks for JERE. The results of our experiments
show that the LLM + ASP workflow is better than state-of-the-art JERE systems
in several categories with only 10\% of training data. It is able to achieve a
2.5 times (35\% over 15\%) improvement in the Relation Extraction task for the
SciERC corpus, one of the most difficult benchmarks.

</details>


### [273] [Cognitive Structure Generation: From Educational Priors to Policy Optimization](https://arxiv.org/abs/2508.12647)
*Hengnian Gu,Zhifu Chen,Yuxin Chen,Jin Peng Zhou,Dongdai Zhou*

Main category: cs.AI

TL;DR: 이 논문은 교육적 사전지식을 바탕으로 학생의 인지 구조를 생성하는 Cognitive Structure Generation(CSG) 프레임워크를 제안한다. 먼저 확산 확률모델(CSDPM)을 사전학습한 뒤, 계층적 보상 신호를 가진 강화학습으로 생성 과정을 최적화하여 실제 인지 발달 수준과 정렬시킨다. 4개 실제 교육 데이터셋에서 KT(knowledge tracing)와 CD(cognitive diagnosis) 성능과 해석력이 유의미하게 향상되었다.


<details>
  <summary>Details</summary>
Motivation: 인지 구조(개념과 개념 간 관계로 구성된 학생의 지식 체계)는 학생 모델링과 심리측정의 핵심 개념이지만 실무에서 측정·평가하기 어렵다. 이를 생성·추정하는 자동화된 방법이 필요하다.

Method: 두 단계 접근: (1) 교육적 사전(priors)으로부터 학생 인지 구조를 생성하도록 Cognitive Structure Diffusion Probabilistic Model(CSDPM)을 사전학습. (2) 생성 과정을 강화학습 정책으로 보고 계층적 보상 신호(인지 발달 일치성 등)로 추가 최적화하여 생성물의 질과 교육적 타당성을 높임.

Result: 네 개의 실제 교육 데이터셋에서 CSG로 생성한 인지 구조를 활용하면 KT와 CD 태스크의 성능이 크게 향상되고, 생성된 구조가 더 포괄적이며 해석 가능성이 높아짐.

Conclusion: CSG는 인지 구조의 자동 생성·정렬을 통해 학생 모델링 성능과 해석력을 동시에 향상시키는 실용적 방안이다. 인지 구조 평가의 운영화를 가능하게 하는 유망한 방향을 제시한다.

Abstract: Cognitive structure is a student's subjective organization of an objective
knowledge system, reflected in the psychological construction of concepts and
their relations. However, cognitive structure assessment remains a
long-standing challenge in student modeling and psychometrics, persisting as a
foundational yet largely unassessable concept in educational practice. This
paper introduces a novel framework, Cognitive Structure Generation (CSG), in
which we first pretrain a Cognitive Structure Diffusion Probabilistic Model
(CSDPM) to generate students' cognitive structures from educational priors, and
then further optimize its generative process as a policy with hierarchical
reward signals via reinforcement learning to align with genuine cognitive
development levels during students' learning processes. Experimental results on
four popular real-world education datasets show that cognitive structures
generated by CSG offer more comprehensive and effective representations for
student modeling, substantially improving performance on KT and CD tasks while
enhancing interpretability.

</details>


### [274] [The Maximum Coverage Model and Recommendation System for UAV Vertiports Location Planning](https://arxiv.org/abs/2508.12651)
*Chunliang Hua,Xiao Hu,Jiayang Sun,Zeyuan Yang*

Main category: cs.AI

TL;DR: 새로운 최적화 프레임워크 CDMCLP(용량·동적 최대커버링 위치문제)와 사회경제적 요인·동적 클러스터링·경험적 사용자행동 기반 적응형 파라미터 튜닝을 결합한 통합 권고 시스템을 제안하여 대규모 도시용 버티포트 네트워크 설계를 지원함. 중국 중심도시 실증에서 기존 위치방법 대비 38%–52% 성능 향상을 보고함.


<details>
  <summary>Details</summary>
Motivation: 기존 UAM(도심 항공 모빌리티) 버티포트 계획 프레임워크는 데이터·수요의 시공간적 세분성 부족과 현실적 제약(용량·이질적 사용자행동 등) 반영 미흡으로 대규모 네트워크 설계에 한계가 있다. 이를 해소할 필요가 있다.

Method: 용량과 시간변화를 고려한 CDMCLP를 수학적으로 정식화하고, 사회경제적 요인과 동적 클러스터링 초기화 및 경험적 사용자행동 기반 적응형 파라미터 튜닝을 결합한 통합 권고 시스템을 개발하여 실무적 설계안을 산출한다.

Result: 중국의 중심도시 실증 적용에서 CDMCLP 기반 평가·최적화로 전통적 위치기법의 성능 저하 원인을 규명하고, 제안 방법으로 38%–52%의 정량적 개선을 달성했으며, 권고 시스템은 실무성(사용자 친화성·복잡요인 통합)을 입증했다.

Conclusion: 수학적 엄밀성과 실무적 구현 고려를 결합한 하이브리드 접근이 이론적 위치모델과 현실적 UAM 인프라 계획 간 간극을 메우며, 지방정부 수준에서의 버티포트 네트워크 설계에 현실적인 도구를 제공한다.

Abstract: As urban aerial mobility (UAM) infrastructure development accelerates
globally, cities like Shenzhen are planning large-scale vertiport networks
(e.g., 1,200+ facilities by 2026). Existing planning frameworks remain
inadequate for this complexity due to historical limitations in data
granularity and real-world applicability. This paper addresses these gaps by
first proposing the Capacitated Dynamic Maximum Covering Location Problem
(CDMCLP), a novel optimization framework that simultaneously models urban-scale
spatial-temporal demand, heterogeneous user behaviors, and infrastructure
capacity constraints. Building on this foundation, we introduce an Integrated
Planning Recommendation System that combines CDMCLP with socio-economic factors
and dynamic clustering initialization. This system leverages adaptive parameter
tuning based on empirical user behavior to generate practical planning
solutions. Validation in a Chinese center city demonstrates the effectiveness
of the new optimization framework and recommendation system. Under the
evaluation and optimization of CDMCLP, the quantitative performance of
traditional location methods are exposed and can be improved by 38\%--52\%,
while the recommendation system shows user-friendliness and the effective
integration of complex elements. By integrating mathematical rigor with
practical implementation considerations, this hybrid approach bridges the gap
between theoretical location modeling and real-world UAM infrastructure
planning, offering municipalities a pragmatic tool for vertiport network
design.

</details>


### [275] [GridCodex: A RAG-Driven AI Framework for Power Grid Code Reasoning and Compliance](https://arxiv.org/abs/2508.12682)
*Jinquan Shi,Yingying Cheng,Fan Zhang,Miao Jiang,Jun Lin,Yanbai Shen*

Main category: cs.AI

TL;DR: GridCodex는 대형 언어 모델(LLM)과 RAG(검색 보강 생성)를 결합해 복잡한 전력망 규정(그리드 코드)을 자동으로 해석하고 준수 여부를 판단하는 엔드투엔드 프레임워크다. 다단계 질의 정제와 RAPTOR 기반 향상된 검색을 통해 답변 품질과 회수율을 크게 끌어올렸다.


<details>
  <summary>Details</summary>
Motivation: 재생에너지 확대로 전력계통 규제 준수와 규정 해석이 핵심 과제가 되었으나, 그리드 코드는 복잡하고 자동화된 해석 도구가 부족해 산업 확대와 전력회사의 수익성에 제약을 준다.

Method: LLM 기반 RAG 워크플로를 발전시켜 다단계 질의 정제(multi-stage query refinement)를 도입하고, RAPTOR라는 기법으로 검색 성능을 향상시킨 통합 파이프라인(GridCodex)을 제안한다. 자동 평가 벤치마크를 설계하여 여러 차원과 규제 기관 케이스에 대해 검증했다.

Result: 실험에서 답변 품질이 평균 26.4% 향상되었고, 검색 회수율(recall)은 10배 이상 증가했다. 추가적으로 기본 모델 선택에 따른 성능 변화를 확인하는 절제(ablation) 연구를 수행했다.

Conclusion: GridCodex는 그리드 코드 자동화 해석과 규정 준수 지원에 실질적 이득을 보여주며, 특히 검색 개선과 질의 정제가 성능 향상에 기여한다. 기본 LLM 선택이 결과에 유의미한 영향을 미치므로 실제 적용 시 모델 선정과 추가 검증이 필요하다.

Abstract: The global shift towards renewable energy presents unprecedented challenges
for the electricity industry, making regulatory reasoning and compliance
increasingly vital. Grid codes, the regulations governing grid operations, are
complex and often lack automated interpretation solutions, which hinders
industry expansion and undermines profitability for electricity companies. We
introduce GridCodex, an end to end framework for grid code reasoning and
compliance that leverages large language models and retrieval-augmented
generation (RAG). Our framework advances conventional RAG workflows through
multi stage query refinement and enhanced retrieval with RAPTOR. We validate
the effectiveness of GridCodex with comprehensive benchmarks, including
automated answer assessment across multiple dimensions and regulatory agencies.
Experimental results showcase a 26.4% improvement in answer quality and more
than a 10 fold increase in recall rate. An ablation study further examines the
impact of base model selection.

</details>


### [276] [EGOILLUSION: Benchmarking Hallucinations in Egocentric Video Understanding](https://arxiv.org/abs/2508.12687)
*Ashish Seth,Utkarsh Tyagi,Ramaneswaran Selvakumar,Nishit Anand,Sonal Kumar,Sreyan Ghosh,Ramani Duraiswami,Chirag Agarwal,Dinesh Manocha*

Main category: cs.AI

TL;DR: EgoIllusion은 자율시점(egocentric) 비디오에서 멀티모달 대형언어모델(MLLM)의 환각(hallucination)을 평가하는 최초의 벤치마크로, 1,400개 비디오와 8,000개의 인간 주석 질문을 통해 10개 MLLM을 테스트한 결과 최고 모델도 약 59% 정확도로 큰 난항을 보였다.


<details>
  <summary>Details</summary>
Motivation: MLLM이 시각·청각 멀티모달 작업에서 뛰어나지만 비전·오디오 해석에서 ‘일관적이지만 부정확한’ 환각을 생성하는 문제가 심각하다. 특히 사용자 관점의 egocentric 비디오에서 발생하는 환각은 실세계 응용에서 위험할 수 있어 이를 정량적으로 평가할 벤치마크가 필요하다.

Method: 환각을 유발하도록 설계된 오픈·폐쇄형 질문 8,000개를 포함한 1,400개 egocentric 비디오 쌍을 모아 EgoIllusion을 구성했다. 시각 및 청각 단서에서의 환각을 평가하도록 케이스를 설계하고, 10개 주요 MLLM(예: GPT-4o, Gemini 등)을 대상으로 정량적 평가를 수행했다.

Result: 평가 결과 대부분의 MLLM이 환각 문제에 취약했다. 상위 모델들(GPT-4o, Gemini 포함)도 평균 정확도가 약 59%에 불과해 실용적 신뢰성에 한계가 드러났다.

Conclusion: EgoIllusion은 egocentric 비디오에서 MLLM 환각을 체계적으로 평가할 수 있는 첫 벤치마크로, 오픈소스로 공개되어 향후 환각 감소 기술과 더 견고한 egocentric MLLM 개발을 촉진할 것이다.

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated remarkable
performance in complex multimodal tasks. While MLLMs excel at visual perception
and reasoning in third-person and egocentric videos, they are prone to
hallucinations, generating coherent yet inaccurate responses. We present
EgoIllusion, a first benchmark to evaluate MLLM hallucinations in egocentric
videos. EgoIllusion comprises 1,400 videos paired with 8,000 human-annotated
open and closed-ended questions designed to trigger hallucinations in both
visual and auditory cues in egocentric videos. Evaluations across ten MLLMs
reveal significant challenges, including powerful models like GPT-4o and
Gemini, achieving only 59% accuracy. EgoIllusion lays the foundation in
developing robust benchmarks to evaluate the effectiveness of MLLMs and spurs
the development of better egocentric MLLMs with reduced hallucination rates.
Our benchmark will be open-sourced for reproducibility.

</details>


### [277] [GTool: Graph Enhanced Tool Planning with Large Language Model](https://arxiv.org/abs/2508.12725)
*Wenjie Chen,Wenbin Li,Di Yao,Xuying Meng,Chang Gong,Jingping Bi*

Main category: cs.AI

TL;DR: GTool은 불완전한 도구 의존성 하에서 LLM의 도구 계획 능력을 개선하기 위해 요청별 도구 그래프와 <graph token>을 생성하고, 누락된 의존성 예측 과제를 도입해 성능을 크게 향상시킨 경량 통합 방법이다.


<details>
  <summary>Details</summary>
Motivation: 기존 연구들은 도구들을 독립적으로 취급해 도구 간 고유한 의존성을 활용하지 못하고, 특히 도구셋이 크고 의존성 정보가 불완전할 때 적절한 도구 선택이 어려워진다.

Method: 요청별 도구 그래프를 구성해 적합한 도구를 효율적으로 선별하고, LLM이 이해할 수 있는 <graph token>으로 의존성 정보를 제공한다. 또한 누락된 의존성을 예측하는 보조 과제를 설계해 불완전한 의존성으로부터의 신뢰성을 향상시킨다. LLM 백본을 잘라내지 않고(트리밍 없이) 다양한 백본과 쉽게 통합 가능하다.

Result: 경량(7B) LLM 백본 사용시 SOTA 대비 29.6% 이상의 성능 향상을 보였다고 보고한다. 실험이 광범위하게 수행되었음을 주장함.

Conclusion: GTool은 불완전한 의존성 환경에서도 도구 계획의 정확성과 신뢰성을 크게 높이며, 경량·백본 불문 통합 가능성으로 실제 적용성이 높다.

Abstract: Tool planning with large language models (LLMs), referring to selecting,
organizing, and preparing the tools necessary to complete a user request,
bridges the gap between natural language understanding and task execution.
However, current works treat different tools as isolated components and fail to
leverage the inherent dependencies of tools, leading to invalid planning
results. Since tool dependencies are often incomplete, it becomes challenging
for LLMs to accurately identify the appropriate tools required by a user
request, especially when confronted with a large toolset. To solve this
challenge, we propose \texttt{GTool}, which is the first work aiming to enhance
the tool planning ability of LLMs under incomplete dependencies. \texttt{GTool}
constructs a request-specific tool graph to select tools efficiently and
generate the \texttt{<graph token>} which provides sufficient dependency
information understandable by LLMs. Moreover, a missing dependency prediction
task is designed to improve the reliability of \texttt{GTool} with incomplete
dependencies. Without trimming LLMs, \texttt{GTool} can be seamlessly
integrated with various LLM backbones without extensive retraining. Extensive
experiments show that \texttt{GTool} achieves more than 29.6\% performance
improvements compared with the state-of-the-art (SOTA) baselines with a
light-weight (7B) LLM backbone.

</details>


### [278] [Beyond Ethical Alignment: Evaluating LLMs as Artificial Moral Assistants](https://arxiv.org/abs/2508.12754)
*Alessio Galatolo,Luca Alberto Rappuoli,Katie Winkle,Meriem Beloucif*

Main category: cs.AI

TL;DR: The paper proposes a formal framework and a benchmark to evaluate large language models (LLMs) as Artificial Moral Assistants (AMAs), focusing on explicit moral reasoning (deductive and abductive). Evaluation of open LLMs shows variability and notable weaknesses, especially in abductive moral reasoning.


<details>
  <summary>Details</summary>
Motivation: Current alignment evaluations focus on final verdicts rather than explicit moral reasoning. Philosophical accounts of AMAs require active moral deliberation and handling of conflicting values beyond alignment-trained behavior.

Method: Develop a formal framework of AMA behavior drawing on philosophical literature, define key qualities (e.g., deductive and abductive moral reasoning), construct a benchmark to test these qualities, and evaluate several popular open LLMs on the benchmark.

Result: Models show considerable variability; many can identify some ethically problematic situations but struggle with abductive reasoning and navigating value conflicts. Persistent shortcomings suggest alignment methods alone are insufficient to yield AMA-level moral reasoning.

Conclusion: Bridges theoretical philosophy and practical AI evaluation, emphasizes need for targeted methods to improve explicit moral reasoning in LLMs, and releases code for reproducibility.

Abstract: The recent rise in popularity of large language models (LLMs) has prompted
considerable concerns about their moral capabilities. Although considerable
effort has been dedicated to aligning LLMs with human moral values, existing
benchmarks and evaluations remain largely superficial, typically measuring
alignment based on final ethical verdicts rather than explicit moral reasoning.
In response, this paper aims to advance the investigation of LLMs' moral
capabilities by examining their capacity to function as Artificial Moral
Assistants (AMAs), systems envisioned in the philosophical literature to
support human moral deliberation. We assert that qualifying as an AMA requires
more than what state-of-the-art alignment techniques aim to achieve: not only
must AMAs be able to discern ethically problematic situations, they should also
be able to actively reason about them, navigating between conflicting values
outside of those embedded in the alignment phase. Building on existing
philosophical literature, we begin by designing a new formal framework of the
specific kind of behaviour an AMA should exhibit, individuating key qualities
such as deductive and abductive moral reasoning. Drawing on this theoretical
framework, we develop a benchmark to test these qualities and evaluate popular
open LLMs against it. Our results reveal considerable variability across models
and highlight persistent shortcomings, particularly regarding abductive moral
reasoning. Our work connects theoretical philosophy with practical AI
evaluation while also emphasising the need for dedicated strategies to
explicitly enhance moral reasoning capabilities in LLMs. Code available at
https://github.com/alessioGalatolo/AMAeval

</details>


### [279] [HeroBench: A Benchmark for Long-Horizon Planning and Structured Reasoning in Virtual Worlds](https://arxiv.org/abs/2508.12782)
*Petr Anokhin,Roman Khalikov,Stefan Rebrikov,Viktor Volkov,Artyom Sorokin,Vincent Bissonnette*

Main category: cs.AI

TL;DR: HeroBench는 RPG 스타일의 복잡한 가상 세계에서 장기 계획(long-horizon planning)과 구조화된 추론을 평가하기 위해 설계된 벤치마크다. 다양한 난이도의 태스크, 시뮬레이션 환경, 성능 분석 도구를 제공하며 25개 최신 LLM을 평가한 결과, 고수준 계획 능력과 구조적 행동 실행에서 일관된 약점과 큰 성능 격차를 발견했다.


<details>
  <summary>Details</summary>
Motivation: 기존 벤치마크들이 단편적·저차원적 알고리즘 문제에 치중해 현실적 장기계획 능력을 제대로 평가하지 못한다는 한계를 극복하고, 복잡한 종속성과 제약을 지닌 현실적 시나리오에서 LLM의 계획·추론 능력을 심층적으로 진단하기 위해.

Method: RPG 영감을 받은 가상 환경을 설계하여 자원 수집, 스킬 습득, 장비 제작, 적 처치 등 계층적 의존관계를 가진 태스크 세트를 생성. 태스크별 채점 가능한 시뮬레이터와 분석 도구를 구축하고, 오픈소스/상용 모델 총 25종을 동일 절차로 평가하여 성능을 비교·분해 분석.

Result: 모델들 간 성능 차이가 기존 벤치마크보다 훨씬 크며, 많은 SOTA LLM이 고수준 전략 수립과 일관된 단계적 실행에서 실패. 상세 오류분석을 통해 계획의 견고성 부족, 행동 실행의 신뢰성 문제 등 구체적 약점이 드러남.

Conclusion: HeroBench는 장기 계획 평가를 위한 실용적이고 확장 가능한 플랫폼을 제공하며, LLM의 자율적 고차원 계획 연구를 촉진할 도구와 진단을 제공한다.

Abstract: Large language models (LLMs) have shown remarkable capabilities in isolated
step-by-step reasoning tasks such as mathematics and programming, but their
proficiency in long-horizon planning, where solutions require extended,
structured sequences of interdependent actions, remains underexplored. Existing
benchmarks typically assess LLMs through abstract or low-dimensional
algorithmic tasks, failing to capture the complexity of realistic planning
environments. We introduce HeroBench, a novel benchmark designed specifically
to evaluate long-horizon planning and structured reasoning within complex
RPG-inspired virtual worlds. HeroBench provides a rigorously constructed
dataset of tasks covering a wide range of difficulties, a simulated environment
to execute and validate agent plans, and detailed analytical tools for
evaluating model performance. Tasks challenge models to formulate strategic
plans, efficiently gather resources, master necessary skills, craft equipment,
and defeat adversaries, reflecting practical scenarios' layered dependencies
and constraints. Our extensive evaluation of 25 state-of-the-art LLMs, spanning
both open-source and proprietary models, including the GPT-5 family, reveals
substantial performance disparities rarely observed in conventional reasoning
benchmarks. Detailed error analysis further uncovers specific weaknesses in
current models' abilities to generate robust high-level plans and reliably
execute structured actions. HeroBench thus not only significantly advances the
evaluation of LLM reasoning but also provides a flexible, scalable foundation
for future research into advanced, autonomous planning in virtual environments.

</details>


### [280] [Reinforcement Learning with Rubric Anchors](https://arxiv.org/abs/2508.12790)
*Zenan Huang,Yihong Zhuang,Guoshan Lu,Zeyu Qin,Haokai Xu,Tianyu Zhao,Ru Peng,Jiaqi Hu,Zhanming Shen,Xiaomeng Hu,Xijun Gu,Peiyi Tu,Jiaxin Liu,Wenyu Chen,Yuzhuo Fu,Zhiting Fan,Yanmei Gu,Yuanyuan Wang,Zhengkai Yang,Jianguo Li,Junbo Zhao*

Main category: cs.AI

TL;DR: 이 논문은 RLVR(검증 가능한 보상) 패러다임을 열린형 과제로 확장해, 사람-설계된 루브릭을 자동 채점 가능한 보상 신호로 사용한다. 1만개 이상의 루브릭을 구축하고 Qwen-30B-A3B를 훈련해 적은 샘플(∼5K)로도 열린형 벤치마크에서 +5.2% 개선을 달성하며 스타일 제어 능력도 향상시켰다.


<details>
  <summary>Details</summary>
Motivation: 기존 RLVR은 단위 테스트나 정답 검사처럼 자동 검증 가능한 출력에만 적용 가능해 응용 범위가 제한된다. 인간적이고 주관적인 기준이 필요한 열린형 과제에서도 RLVR의 장점을 살리고자 루브릭 기반의 자동 보상 체계를 제안했다.

Method: 사람, LLM, 혹은 하이브리드로 생성한 1만 개 이상의 루브릭으로 보상 시스템을 구성하고, 루브릭을 모델 해석 가능한 채점 기준으로 사용해 RL(또는 RL 유사) 학습을 수행한다. 루브릭을 앵커로 삼아 스타일을 미세 조정하고, 소수의 샘플(약 5K)으로 Qwen-30B-A3B 모델을 파인튜닝했다.

Result: 모델은 열린형 벤치마크(특히 인문학 분야)에서 +5.2% 향상했으며, 671B DeepSeek-V3보다 +2.4% 우수함. 일반적·추론 능력은 유지되었고, AI 특유의 어투를 줄이고 인간다운 표현을 늘리는 세밀한 스타일 제어가 가능해졌다.

Conclusion: 루브릭 기반 보상은 자동 채점이 어려운 열린형 과제에 RLVR을 확대 적용할 수 있는 실용적 방법을 제공한다. 루브릭 구축·데이터 선택·훈련에서의 주요 교훈과 한계 및 향후 공개 계획을 논의한다.

Abstract: Reinforcement Learning from Verifiable Rewards (RLVR) has emerged as a
powerful paradigm for enhancing Large Language Models (LLMs), exemplified by
the success of OpenAI's o-series. In RLVR, rewards are derived from verifiable
signals-such as passing unit tests in code generation or matching correct
answers in mathematical reasoning. While effective, this requirement largely
confines RLVR to domains with automatically checkable outcomes. To overcome
this, we extend the RLVR paradigm to open-ended tasks by integrating
rubric-based rewards, where carefully designed rubrics serve as structured,
model-interpretable criteria for automatic scoring of subjective outputs. We
construct, to our knowledge, the largest rubric reward system to date, with
over 10,000 rubrics from humans, LLMs, or a hybrid human-LLM collaboration.
Implementing rubric-based RL is challenging; we tackle these issues with a
clear framework and present an open-sourced Qwen-30B-A3B model with notable
gains: 1) With only 5K+ samples, our system improves by +5.2% on open-ended
benchmarks (especially humanities), outperforming a 671B DeepSeek-V3 model by
+2.4%, while preserving general and reasoning abilities. 2) Our method provides
fine-grained stylistic control, using rubrics as anchors to mitigate the
"AI-like" tone and produce more human-like, expressive responses. We share key
lessons in rubric construction, data selection, and training, and discuss
limitations and future releases.

</details>


### [281] [E3RG: Building Explicit Emotion-driven Empathetic Response Generation System with Multimodal Large Language Model](https://arxiv.org/abs/2508.12854)
*Ronghao Lin,Shuai Shen,Weipeng Hu,Qiaolin He,Aolin Xiong,Li Huang,Haifeng Hu,Yap-peng Tan*

Main category: cs.AI

TL;DR: E3RG는 멀티모달 LLM과 음성·비디오 생성모델을 결합해 감정 이해, 기억 검색, 멀티모달 응답생성으로 MERG를 분해한 시스템으로, 추가 학습 없이 제로·퓨샷 환경에서 자연스럽고 정체성 일관된 공감형 응답을 생성하며 ACM MM 25 챌린지에서 1위를 차지했다.


<details>
  <summary>Details</summary>
Motivation: 기존 LLM 기반 텍스트 공감 응답은 발전했으나 멀티모달 감정 처리와 화자 정체성 유지에서 한계가 있어, 멀티모달 입력에 대응하고 정체성을 보존하는 공감형 응답 시스템 필요했다.

Method: MERG를 1) 멀티모달 공감 이해, 2) 공감 메모리 검색, 3) 멀티모달 응답 생성의 세 단계로 분해. 고급 음성·비디오 생성 모델을 통합해 추가 학습 없이 멀티모달 LLM에서 자연스럽고 감정 풍부하며 정체성 일관된 응답을 생성한다.

Result: 제로샷·퓨샷 설정에서 우수한 성능을 보였고, Avatar-based Multimodal Empathy Challenge(ACM MM 25)에서 Top-1을 획득했다.

Conclusion: E3RG는 멀티모달 공감 응답 생성에서 실용적이고 강력한 접근을 제시하며 코드가 공개되어 재현성도 확보된다.

Abstract: Multimodal Empathetic Response Generation (MERG) is crucial for building
emotionally intelligent human-computer interactions. Although large language
models (LLMs) have improved text-based ERG, challenges remain in handling
multimodal emotional content and maintaining identity consistency. Thus, we
propose E3RG, an Explicit Emotion-driven Empathetic Response Generation System
based on multimodal LLMs which decomposes MERG task into three parts:
multimodal empathy understanding, empathy memory retrieval, and multimodal
response generation. By integrating advanced expressive speech and video
generative models, E3RG delivers natural, emotionally rich, and
identity-consistent responses without extra training. Experiments validate the
superiority of our system on both zero-shot and few-shot settings, securing
Top-1 position in the Avatar-based Multimodal Empathy Challenge on ACM MM 25.
Our code is available at https://github.com/RH-Lin/E3RG.

</details>


### [282] [Reliability, Embeddedness, and Agency: A Utility-Driven Mathematical Framework for Agent-Centric AI Adoption](https://arxiv.org/abs/2508.12896)
*Faruk Alpay,Taylan Alpay*

Main category: cs.AI

TL;DR: 논문은 ‘에이전트 중심’ AI의 장기 채택을 위해 세 가지 설계 공리(신뢰성>신기성, 임베드>목적지, 대리성>챗)를 제안하고, 채택을 신기성의 지수적 감쇠항과 효용의 성장항 합으로 모델링해 소멸(골짜기)·과도(overshoot) 조건을 엄밀히 유도한다. 식별성·혼동 분석, 대안 비교모델, 해저드 함수 절제, 다계열 벤치마크, 마찰 프록시 보정, 잔차 진단, 피셔 정보·CRLB, 미시적 근거, 여러 곡선 모델 비교 및 민감도 분석 등을 포함한 종합적 검증·재현 자료를 제공한다.


<details>
  <summary>Details</summary>
Motivation: 에이전트형 멀티스텝 태스크 도구가 초기에 높은 관심(신기성)을 얻더라도 실사용자 채택이 지속되지 못하는 현상을 이론·실증적으로 규명하고, 설계 원칙과 진단 도구를 제시해 실무자가 골짜기(trough)를 예측·완화하도록 돕기 위함.

Method: 채택 시계열을 신기성 항(초기값 N0, 감쇠율 α)과 효용 항(최대 효용 U_max, 성장 속도 β)의 합으로 모델링. 골짜기·과도 발생의 위상(phase) 조건을 수학적으로 유도하고 증명. 파라미터 식별성 및 혼동 분석(델타법 기울기), 비단조 비교기(logistic+일시적 bump), 여러 해저드(h(·)) 형태 절제, 합성 데이터 벤치마크(깊이·잡음·AR 구조 변화), 마찰 프록시 보정(시간-동작·설문), 잔차(자기상관·이분산) 진단, CRLB 계산, 미시적 연결고리 제시, 다른 채택 곡선 모델들과의 비교 및 민감도 분석 수행.

Result: 골짜기와 과도 발생의 명확한 수학적 조건과 증명, (α,β,N0,U_max)에 대한 식별성/편향·분산 특성, 합성 벤치마크에서의 검정력·유의수준 보고, 마찰 프록시의 보정 및 표준오차, 잔차 진단 결과, 피셔 정보·CRLB 수치, 다양한 모델 비교 결과와 C_f 이질성에 대한 민감도 분석. 모든 합성 분석 코드를 포함해 재현 가능.

Conclusion: 논문은 에이전트형 AI 채택 동학을 이해·진단·예측하기 위한 이론적·실증적 툴킷을 제시하며, 설계자에게 신뢰성·임베드·대리성에 우선순위를 둘 것을 권고하고 골짜기 발생을 조기 탐지·완화할 방법론을 제공한다.

Abstract: We formalize three design axioms for sustained adoption of agent-centric AI
systems executing multi-step tasks: (A1) Reliability > Novelty; (A2) Embed >
Destination; (A3) Agency > Chat. We model adoption as a sum of a decaying
novelty term and a growing utility term and derive the phase conditions for
troughs/overshoots with full proofs. We introduce: (i) an
identifiability/confounding analysis for $(\alpha,\beta,N_0,U_{\max})$ with
delta-method gradients; (ii) a non-monotone comparator
(logistic-with-transient-bump) evaluated on the same series to provide
additional model comparison; (iii) ablations over hazard families $h(\cdot)$
mapping $\Delta V \to \beta$; (iv) a multi-series benchmark (varying trough
depth, noise, AR structure) reporting coverage (type-I error, power); (v)
calibration of friction proxies against time-motion/survey ground truth with
standard errors; (vi) residual analyses (autocorrelation and
heteroskedasticity) for each fitted curve; (vii) preregistered windowing
choices for pre/post estimation; (viii) Fisher information & CRLB for
$(\alpha,\beta)$ under common error models; (ix) microfoundations linking
$\mathcal{T}$ to $(N_0,U_{\max})$; (x) explicit comparison to bi-logistic,
double-exponential, and mixture models; and (xi) threshold sensitivity to $C_f$
heterogeneity. Figures and tables are reflowed for readability, and the
bibliography restores and extends non-logistic/Bass adoption references
(Gompertz, Richards, Fisher-Pry, Mansfield, Griliches, Geroski, Peres). All
code and logs necessary to reproduce the synthetic analyses are embedded as
LaTeX listings.

</details>


### [283] [FuSaR: A Fuzzification-Based Method for LRM Safety-Reasoning Balance](https://arxiv.org/abs/2508.12897)
*Jianhao Chen,Mayi Xu,Xiaohu Li,Yongqi Li,Xiangyu Zhang,Jianjie Huang,Tieyun Qian*

Main category: cs.AI

TL;DR: They identify that improving reasoning can inadvertently reduce safety and propose FuSaR, which detoxifies reasoning steps by hiding dangerous entities and procedures, balancing reasoning and safety without losing capability.


<details>
  <summary>Details</summary>
Motivation: Large Reasoning Models show strong reasoning but poor safety; authors investigate the vulnerability source—competition between reasoning and safety—and seek a method to improve safety without degrading reasoning.

Method: Introduce FuSaR (Safety-Reasoning via Fuzzification): a detoxification/alignment strategy that fuzzifies (hides/obscures) dangerous entities and procedures within intermediate reasoning steps, then use detoxified reasoning data to align open-source LRMs.

Result: Alignment experiments on several open-source LRMs show FuSaR mitigates safety risks while preserving or improving reasoning performance, outperforming existing baselines.

Conclusion: Fuzzification of harmful reasoning traces is an effective alignment approach to jointly enhance safety and reasoning in LRMs by removing explicit harmful content from intermediate steps while retaining core logical information.

Abstract: Large Reasoning Models (LRMs) have demonstrated impressive performance across
various tasks due to their powerful reasoning capabilities. However, their
safety performance remains a significant concern. In this paper, we explore the
reasons behind the vulnerability of LRMs. Based on this, we propose a novel
method to improve the safety of LLMs without sacrificing their reasoning
capability. Specifically, we exploit the competition between LRM's reasoning
ability and safety ability, and achieve jailbreak by improving LRM's reasoning
performance to reduce its safety performance. We then introduce an alignment
strategy based on Fuzzification to balance Safety-Reasoning (FuSaR), by
detoxifying the harmful reasoning process, where both the dangerous entities
and the dangerous procedures in the reasoning steps are hidden. FuSaR
successfully mitigates safety risks while preserving core reasoning
information. We validate this strategy through alignment experiments on several
open-source LRMs using detoxified reasoning data. The results compared with
existing baselines conclusively show that FuSaR is an efficient alignment
strategy to simultaneously enhance both the reasoning capability and safety of
LRMs.

</details>


### [284] [Towards Open-Ended Emotional Support Conversations in LLMs via Reinforcement Learning with Future-Oriented Rewards](https://arxiv.org/abs/2508.12935)
*Ting Yang,Li Chen,Huimin Wang*

Main category: cs.AI

TL;DR: RLFF-ESC는 LLM 기반의 다중 에이전트 시뮬레이션을 이용해 장기(미래지향) 보상을 수집하고, 이를 학습한 미래지향 보상 모델로 강화학습 정책을 훈련해 감정지원 대화를 직접 학습하는 종단간 프레임워크다. 명시적 추론 과정을 도입해 응답의 질과 문맥적 적합성을 높이며, Qwen2.5-7B와 LLaMA3.1-8B 계열에서 두 개 공개 ESC 데이터셋으로 평가해 기존 기법보다 목표 달성과 응답 품질이 우수함을 보였다.


<details>
  <summary>Details</summary>
Motivation: 기존 LLM 기반 ESC 시스템은 사전 정의된 전략(템플릿·규칙)에 의존해 복잡한 실제 감정 문제와 다양한 시나리오에 유연하게 대응하지 못한다. 지속적이고 상황에 맞는 감정지원 스킬을 직접 학습할 필요가 있다.

Method: (1) LLM 기반 다중 에이전트 메커니즘으로 미래 대화 궤적을 시뮬레이션하여 미래지향 보상을 수집한다. (2) 수집된 데이터를 사용해 미래지향 보상 모델을 학습한다. (3) 학습된 보상 모델로 RL(강화학습) 기반 정책 모델을 훈련한다. (4) 응답 생성 시 명시적 추론 과정을 포함해 응답의 관련성과 적절성 개선을 시도한다. 백본으로 Qwen2.5-7B-Instruct-1M과 LLaMA3.1-8B-Instruct를 사용해 두 공개 데이터셋에서 실험.

Result: 제안한 RLFF-ESC가 기존 기준선 방법들보다 목표 달성(goal completion)과 응답 품질에서 일관되게 우수한 성능을 보였다.

Conclusion: LLM 시뮬레이션 기반 미래 보상 수집과 보상모델+강화학습 결합은 감정지원 대화에서 보다 지속적이고 유연한 스킬 학습에 효과적이다. 다만 안전성·윤리성·일반화성 검증과 실제 사용자 평가가 향후 과제로 남는다.

Abstract: Emotional Support Conversation (ESC) systems aim to alleviate users'
emotional difficulties and provide long-term, systematic support for emotional
well-being. However, most large language model (LLM)-based ESC systems rely on
predefined strategies, which limits their effectiveness in complex, real-life
scenarios. To enable flexible responses to diverse emotional problem scenarios,
this paper introduces a novel end-to-end framework (RLFF-ESC) that directly
learns enduring emotionally supportive response skills using reinforcement
learning. For sustained emotional support, we first employ an LLM-based
multi-agent mechanism to simulate future dialogue trajectories and collect
future-oriented rewards. We then train a future-oriented reward model, which is
subsequently used to train the emotional support policy model. Additionally, we
incorporate an explicit reasoning process during response generation to further
enhance the quality, relevance, and contextual appropriateness of the system's
responses. We evaluate the backbone policy model on Qwen2.5-7B-Instruct-1M and
LLaMA3.1-8B-Instruct models, testing the proposed RLFF-ESC framework across two
public ESC datasets. Experimental results demonstrate that RLFF-ESC
consistently outperforms existing baselines in terms of goal completion and
response quality.

</details>


### [285] [OPTIC-ER: A Reinforcement Learning Framework for Real-Time Emergency Response and Equitable Resource Allocation in Underserved African Communities](https://arxiv.org/abs/2508.12943)
*Mary Tonwe*

Main category: cs.AI

TL;DR: OPTIC-ER은 저자원 환경에서 실시간·공정한 응급출동을 목표로 하는 주의(attention)-기반 액터-크리틱 강화학습 프레임워크로, 컨텍스트 풍부 상태 벡터와 비효율성 페널티 보상 함수를 도입하여 시뮬레이션(나이지리아 리버스 주 데이터, 이동시간 아틀라스 가속화)에서 500건의 미응답 사고에 대해 높은 성능을 보였다고 보고한다.


<details>
  <summary>Details</summary>
Motivation: 아프리카 일부 지역에서의 긴 응급대응 시간과 공간적 불균형으로 인한 인명·고통 손실을 줄이기 위해, 적응적이고 공정한 실시간 출동 시스템이 필요하다.

Method: 주의 기반 액터-크리틱 아키텍처, 컨텍스트-리치 상태 벡터(행동의 준최적성 포함), 비효율성에 벌점을 주는 정밀 보상 설계, 사전계산된 이동시간 아틀라스를 활용한 고충실도 시뮬레이션에서 학습. TALS 프레임워크를 통해 저자원 배포를 겨냥함.

Result: 500건의 미지 사례 평가에서 '100.00% 최적성'과 무시할 만한 비효율성을 달성했다고 보고. 인프라 결손 지도와 형평성 모니터링 대시보드를 추가 산출물로 제시.

Conclusion: 컨텍스트 인지 강화학습은 응급출동 의사결정과 인간 영향 사이의 격차를 줄일 수 있는 실행 가능한 청사진을 제공하며, 저자원 환경에서의 AI 보강 공공서비스 구현 가능성을 시사함.

Abstract: Public service systems in many African regions suffer from delayed emergency
response and spatial inequity, causing avoidable suffering. This paper
introduces OPTIC-ER, a reinforcement learning (RL) framework for real-time,
adaptive, and equitable emergency response. OPTIC-ER uses an attention-guided
actor-critic architecture to manage the complexity of dispatch environments.
Its key innovations are a Context-Rich State Vector, encoding action
sub-optimality, and a Precision Reward Function, which penalizes inefficiency.
Training occurs in a high-fidelity simulation using real data from Rivers
State, Nigeria, accelerated by a precomputed Travel Time Atlas. The system is
built on the TALS framework (Thin computing, Adaptability, Low-cost,
Scalability) for deployment in low-resource settings. In evaluations on 500
unseen incidents, OPTIC-ER achieved a 100.00% optimality rate with negligible
inefficiency, confirming its robustness and generalization. Beyond dispatch,
the system generates Infrastructure Deficiency Maps and Equity Monitoring
Dashboards to guide proactive governance and data-informed development. This
work presents a validated blueprint for AI-augmented public services, showing
how context-aware RL can bridge the gap between algorithmic decision-making and
measurable human impact.

</details>


### [286] [EvolMathEval: Towards Evolvable Benchmarks for Mathematical Reasoning via Evolutionary Testing](https://arxiv.org/abs/2508.13003)
*Shengbo Wang,Mingwei Liu,Zike Li,Anji Li,Yanlin Wang,Xin Peng,Zibin Zheng*

Main category: cs.AI

TL;DR: EvolMathEval is an automated evolutionary framework that generates contamination-free, progressively harder math problems; its composite fitness measure efficiently estimates problem difficulty and evolved datasets expose LLM weaknesses (e.g., a 'Pseudo Aha Moment' heuristic failure), reducing model accuracy substantially.


<details>
  <summary>Details</summary>
Motivation: Current math benchmarks suffer score saturation, temporal decay, and data contamination, making them ineffective for evaluating advancing LLMs. A continuously evolving, automated generator is needed to keep benchmarks challenging and uncontaminated.

Method: EvolMathEval uses reverse-engineered seed generation with algebraic guarantees, multi-dimensional genetic operators to create diverse cognitive difficulties, and a composite fitness function to assess and select problems by difficulty, iterating evolution to produce and refine hard instances.

Result: The composite fitness function efficiently quantifies difficulty; EvolMathEval can self-iterate to produce many hard problems and evolve existing datasets (e.g., GSM8K) to lower model accuracy by ~48%. Analysis shows LLM errors on evolved problems are dominated (77–100%) by a heuristic shortcut behavior labeled 'Pseudo Aha Moment'.

Conclusion: EvolMathEval offers a contamination-free, long-lived evaluation pipeline that reveals deep-reasoning weaknesses in LLMs and can be used to continuously stress-test and improve model robustness; future work should examine generalizability, computational cost, and defenses against heuristic shortcuts.

Abstract: The rapid advancement of LLMs poses a significant challenge to existing
mathematical reasoning benchmarks. These benchmarks commonly suffer from issues
such as score saturation, temporal decay, and data contamination. To address
this challenge, this paper introduces EvolMathEval, an automated mathematical
benchmark generation and evolution framework based on evolutionary testing. By
dynamically generating unique evaluation instances ab initio, the framework
fundamentally eliminates the risk of data contamination, and ensuring the
benchmark remains perpetually challenging for future models.The core mechanisms
of EvolMathEval include: seed problem generation based on reverse engineering
with algebraic guarantees; multi-dimensional genetic operators designed to
inject diverse cognitive challenges; and a composite fitness function that can
rapidly and accurately assess problem difficulty. Experimental results
demonstrate that the proposed composite fitness function can efficiently and
precisely quantify the difficulty of mathematical problems. Furthermore,
EvolMathEval can not only generate a large volume of high-difficulty problems
through continuous self-iteration, but it can also significantly enhance the
complexity of public datasets like GSM8K through evolution, reducing model
accuracy by an average of 48%. Deeper investigation reveals that when solving
these evolved, complex problems, LLMs tend to employ non-rigorous heuristics to
bypass complex multi-step logical reasoning, consequently leading to incorrect
solutions. We define this phenomenon as "Pseudo Aha Moment". This finding
uncovers a cognitive shortcut-taking behavior in the deep reasoning processes
of current LLMs, which we find accounts for 77% to 100% of errors on targeted
problems. Code and resources are available
at:https://github.com/SYSUSELab/EvolMathEval.

</details>


### [287] [e-boost: Boosted E-Graph Extraction with Adaptive Heuristics and Exact Solving](https://arxiv.org/abs/2508.13020)
*Jiaqi Yin,Zhan Song,Chen Chen,Yaohui Cai,Zhiru Zhang,Cunxi Yu*

Main category: cs.AI

TL;DR: e-boost는 e-graph 추출의 속도-최적성 트레이드오프를 해소하는 하이브리드 프레임워크다. 병렬화된 휴리스틱 추출, 적응형 탐색공간 가지치기, 그리고 워밍스타트 가능한 ILP 초기화를 결합해 전통적 ILP에 비해 수백배 빠르면서도 SmoothE 대비 품질을 개선한다. 코드 공개됨.


<details>
  <summary>Details</summary>
Motivation: e-graph 추출은 NP-하드로서 e-graph 기반 최적화의 병목이다. 기존 휴리스틱은 빠르지만 최적성을 희생하고, 정확해법은 계산비용이 커 실무에 부적합하다.

Method: (1) DAG 비용을 병렬로 계산하는 약한 데이터 의존성 활용한 병렬 휴리스틱 추출, (2) 파라미터화된 임계값 기반의 적응적 후보 가지치기, (3) 축소된 문제를 ILP로 정식화하고 워밍스타트로 정확해법을 빠르게 유도.

Result: 다양한 검증·합성 벤치마크에서 전통적 ILP 대비 558배 속도향상, SmoothE 대비 19.04% 성능 향상. 실제 합성 작업에서 두 가지 기술 맵 라이브러리 기준으로 각각 7.6%·8.1% 면적 개선을 달성.

Conclusion: e-boost는 속도와 품질을 모두 개선하여 실무적용이 가능한 e-graph 추출 기법을 제시한다. 공개 코드로 재현성도 확보되어 실무·연구에 유용하다.

Abstract: E-graphs have attracted growing interest in many fields, particularly in
logic synthesis and formal verification. E-graph extraction is a challenging
NP-hard combinatorial optimization problem. It requires identifying optimal
terms from exponentially many equivalent expressions, serving as the primary
performance bottleneck in e-graph based optimization tasks. However,
traditional extraction methods face a critical trade-off: heuristic approaches
offer speed but sacrifice optimality, while exact methods provide optimal
solutions but face prohibitive computational costs on practical problems. We
present e-boost, a novel framework that bridges this gap through three key
innovations: (1) parallelized heuristic extraction that leverages weak data
dependence to compute DAG costs concurrently, enabling efficient multi-threaded
performance without sacrificing extraction quality; (2) adaptive search space
pruning that employs a parameterized threshold mechanism to retain only
promising candidates, dramatically reducing the solution space while preserving
near-optimal solutions; and (3) initialized exact solving that formulates the
reduced problem as an Integer Linear Program with warm-start capabilities,
guiding solvers toward high-quality solutions faster.
  Across the diverse benchmarks in formal verification and logic synthesis
fields, e-boost demonstrates 558x runtime speedup over traditional exact
approaches (ILP) and 19.04% performance improvement over the state-of-the-art
extraction framework (SmoothE). In realistic logic synthesis tasks, e-boost
produces 7.6% and 8.1% area improvements compared to conventional synthesis
tools with two different technology mapping libraries. e-boost is available at
https://github.com/Yu-Maryland/e-boost.

</details>


### [288] [PC-Sampler: Position-Aware Calibration of Decoding Bias in Masked Diffusion Models](https://arxiv.org/abs/2508.13021)
*Pengcheng Huang,Shuhao Liu,Zhenghao Liu,Yukun Yan,Shuo Wang,Zulong Chen,Tong Xiao*

Main category: cs.AI

TL;DR: 저자들은 MDM(마스킹 확산 모델)에서 기존 불확실성 기반 샘플러가 전역 경로 제어 부족과 초반에 사소한 토큰을 선택하는 편향이 있어 성능이 떨어진다고 지적한다. 이를 해결하기 위해 위치 정보 가중치와 신뢰도 보정 점수를 결합한 PC-Sampler를 제안한다. 다양한 MDM과 벤치마크에서 기존 샘플러 대비 평균 10% 이상 향상을 보였다.


<details>
  <summary>Details</summary>
Motivation: MDM의 생성 품질이 디코딩 전략에 민감하며, 기존 불확실성 기반 샘플러는 전역적인 경로 제어가 부족하고 초반 단계에서 사소한 토큰을 선택하는 편향이 있어 MDM 성능을 제한한다.

Method: PC-Sampler는 위치 인식 가중치 메커니즘으로 디코딩 경로를 조절하고, 보정된 신뢰도 점수로 초반에 사소한 토큰이 선택되는 것을 억제한다. 전역 경로 계획과 내용 인식 정보량 최대화(예: informativeness)를 통합한 디코딩 전략이다.

Result: 세 가지 MDM과 일곱 개 벤치마크(논리 추론 및 계획 과제를 포함)에서 PC-Sampler는 기존 디코딩 전략들보다 평균 10% 이상 우수했고, 자동회귀 모델과의 성능 차이를 크게 줄였다.

Conclusion: PC-Sampler는 전역 경로 제어와 신뢰도 보정을 통해 MDM의 디코딩 성능을 현저히 개선하며, MDM을 자동회귀 모델과 경쟁 가능한 수준으로 끌어올린다.

Abstract: Recent advances in masked diffusion models (MDMs) have established them as
powerful non-autoregressive alternatives for sequence generation. Nevertheless,
our preliminary experiments reveal that the generation quality of MDMs is still
highly sensitive to the choice of decoding strategy. In particular, widely
adopted uncertainty-based samplers suffer from two key limitations: a lack of
global trajectory control and a pronounced bias toward trivial tokens in the
early stages of decoding. These shortcomings restrict the full potential of
MDMs. In this work, we introduce Position-Aware Confidence-Calibrated Sampling
(PC-Sampler), a novel decoding strategy that unifies global trajectory planning
with content-aware informativeness maximization. PC-Sampler incorporates a
position-aware weighting mechanism to regulate the decoding path and a
calibrated confidence score to suppress the premature selection of trivial
tokens. Extensive experiments on three advanced MDMs across seven challenging
benchmarks-including logical reasoning and planning tasks-demonstrate that
PC-Sampler consistently outperforms existing MDM decoding strategies by more
than 10% on average, significantly narrowing the performance gap with
state-of-the-art autoregressive models. All codes are available at
https://github.com/NEUIR/PC-Sampler.

</details>


### [289] [G$^2$RPO-A: Guided Group Relative Policy Optimization with Adaptive Guidance](https://arxiv.org/abs/2508.13023)
*Yongxin Guo,Wenbo Deng,Zhenglin Cheng,Xiaoying Tang*

Main category: cs.AI

TL;DR: 제안된 G^2RPO-A는 소형 언어모델(SLM)에 대해 검증 가능한 보상(RLVR)을 적용할 때, 롤아웃에 정답(reasoning) 단계를 주입하고 그 강도를 학습 역학에 맞춰 자동으로 조절하여 성능을 크게 향상시키는 적응형 알고리즘이다.


<details>
  <summary>Details</summary>
Motivation: 기존 RL with Verifiable Rewards(RLVR)는 대형 언어모델(LLM)에선 추론 능력을 크게 개선했지만, 지식이 부족한 소형 모델(SLM)에서는 효과가 제한적이다. 이 한계를 보완하기 위해 학습 중에 정답 추론 단계를 가이드로 제공해 SLM의 약점을 보완하려 함.

Method: Guided GRPO(기본 기법)는 롤아웃 궤적에 정답(reasoning) 단계를 주입한다. 다양한 가이드 구성(주입 시점·빈도·강도)을 광범위하게 실험한 결과, 단순한(naive) 가이던스는 제한적 개선만 제공했다. 이를 바탕으로 G^2RPO-A를 제안하여, 모델의 학습 동적(예: 성능 변화·불확실성 등)에 맞춰 가이드의 강도를 자동 조절하는 적응형 규칙을 도입한다.

Result: 수학적 추론 및 코드 생성 벤치마크에서 G^2RPO-A가 기존의 vanilla GRPO보다 유의미하게 우수한 성능을 보였다. 코드와 모델은 공개됨(저자 제공 GitHub).

Conclusion: SLM에 대해선 고정된 가이던스보다 학습 과정에 따라 강도를 조절하는 적응적 가이던스가 더 효과적이다. G^2RPO-A는 RLVR 기반 추론 강화를 위해 실용적 대안이 될 수 있다.

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has markedly enhanced
the reasoning abilities of large language models (LLMs). Its success, however,
largely depends on strong base models with rich world knowledge, yielding only
modest improvements for small-size language models (SLMs). To address this
limitation, we investigate Guided GRPO, which injects ground-truth reasoning
steps into roll-out trajectories to compensate for SLMs' inherent weaknesses.
Through a comprehensive study of various guidance configurations, we find that
naively adding guidance delivers limited gains. These insights motivate
G$^2$RPO-A, an adaptive algorithm that automatically adjusts guidance strength
in response to the model's evolving training dynamics. Experiments on
mathematical reasoning and code-generation benchmarks confirm that G$^2$RPO-A
substantially outperforms vanilla GRPO. Our code and models are available at
https://github.com/T-Lab-CUHKSZ/G2RPO-A.

</details>


### [290] [A Language-Signal-Vision Multimodal Framework for Multitask Cardiac Analysis](https://arxiv.org/abs/2508.13072)
*Yuting Zhang,Tiantian Geng,Luoying Hao,Xinxing Cheng,Alexander Thorley,Xiaoxia Wang,Wenqi Lu,Sandeep S Hothi,Lei Wei,Zhaowen Qiu,Dipak Kotecha,Jinming Duan*

Main category: cs.AI

TL;DR: TGMM은 혈액검사, ECG, 심초음파를 통합한 멀티모달 심장데이터셋과 함께, 모듈형 가변 융합(MedFlexFusion), 과제지향 텍스트 가이드, 다중 과제 응답 모듈을 제안해 심장 질환 진단·위험층정·정보 검색 등 다중 임상과제를 동시에 수행한다. 실험에서 SOTA를 능가했으며 공개 데이터로도 검증되었다.


<details>
  <summary>Details</summary>
Motivation: 임상에서 여러 심장 모달리티(실험실 수치, ECG, 심초음파)를 통합하면 보다 완전한 환자 프로파일을 얻을 수 있으나, 시간 정렬된 데이터 희소성, 단일/고정된 입력조합에 대한 의존, 보완성보다 유사성 중심의 정렬 전략, 단일 과제 중심 연구 등의 한계가 존재한다.

Method: 저자들은 1) 다양한 조합을 유연하게 통합하는 MedFlexFusion 모듈, 2) 진단·위험분류·검색 등 과제별로 표현을 유도하는 텍스트 가이드 모듈, 3) 다중 과제에 대한 출력(응답) 모듈로 구성된 TGMM 프레임워크를 제안했다. 또한 멀티모달 데이터셋을 구축하고 모달 간 상호보완적 기여를 분석했다.

Result: TGMM은 여러 임상과제에서 기존 방법들보다 성능이 우수했으며, 다른 공개 데이터셋에서도 견고한 성능을 보였다. 다중 모달 특성의 시너지 효과를 체계적으로 증명했다.

Conclusion: 시간·모달리티 정렬 문제와 과제 다양성의 한계를 극복하기 위한 통합적 프레임워크를 제시하여 임상 의사결정 지원에서 멀티모달 접근의 실용성과 우수성을 입증했다.

Abstract: Contemporary cardiovascular management involves complex consideration and
integration of multimodal cardiac datasets, where each modality provides
distinct but complementary physiological characteristics. While the effective
integration of multiple modalities could yield a holistic clinical profile that
accurately models the true clinical situation with respect to data modalities
and their relatives weightings, current methodologies remain limited by: 1) the
scarcity of patient- and time-aligned multimodal data; 2) reliance on isolated
single-modality or rigid multimodal input combinations; 3) alignment strategies
that prioritize cross-modal similarity over complementarity; and 4) a narrow
single-task focus. In response to these limitations, a comprehensive multimodal
dataset was curated for immediate application, integrating laboratory test
results, electrocardiograms, and echocardiograms with clinical outcomes.
Subsequently, a unified framework, Textual Guidance Multimodal fusion for
Multiple cardiac tasks (TGMM), was proposed. TGMM incorporated three key
components: 1) a MedFlexFusion module designed to capture the unique and
complementary characteristics of medical modalities and dynamically integrate
data from diverse cardiac sources and their combinations; 2) a textual guidance
module to derive task-relevant representations tailored to diverse clinical
objectives, including heart disease diagnosis, risk stratification and
information retrieval; and 3) a response module to produce final decisions for
all these tasks. Furthermore, this study systematically explored key features
across multiple modalities and elucidated their synergistic contributions in
clinical decision-making. Extensive experiments showed that TGMM outperformed
state-of-the-art methods across multiple clinical tasks, with additional
validation confirming its robustness on another public dataset.

</details>


### [291] [Bayesian Optimization-based Search for Agent Control in Automated Game Testing](https://arxiv.org/abs/2508.13121)
*Carlos Celemin*

Main category: cs.AI

TL;DR: Proposes an automated game-level testing method using agents + Bayesian Optimization with a scalable, grid-map-based surrogate model to efficiently find bugs; experiments show better coverage and time efficiency.


<details>
  <summary>Details</summary>
Motivation: Manual and naive automated testing of game levels is costly and/or sample-inefficient; need a directed, data-efficient search that maximizes information gain to find bugs and improve map coverage.

Method: Use agents controlling game characters to collect samples. Apply Bayesian Optimization to choose the next sampling locations by maximizing information acquisition. Introduce a game-testing-specific surrogate model built on a grid map that provides smoothness and uncertainty estimates required by BO while avoiding scalability problems of traditional models.

Result: Empirical results indicate significantly improved map coverage, faster exploration (time efficiency), and a more evenly distributed exploration across the map compared to baselines.

Conclusion: Combining BO with a tailored, scalable grid-based model yields efficient automated testing agents that enhance bug-finding coverage and efficiency; suggests potential for broader adoption in automated game testing pipelines.

Abstract: This work introduces an automated testing approach that employs agents
controlling game characters to detect potential bugs within a game level.
Harnessing the power of Bayesian Optimization (BO) to execute sample-efficient
search, the method determines the next sampling point by analyzing the data
collected so far and calculates the data point that will maximize information
acquisition. To support the BO process, we introduce a game testing-specific
model built on top of a grid map, that features the smoothness and uncertainty
estimation required by BO, however and most importantly, it does not suffer the
scalability issues that traditional models carry. The experiments demonstrate
that the approach significantly improves map coverage capabilities in both time
efficiency and exploration distribution.

</details>


### [292] [Exploring Autonomous Agents: A Closer Look at Why They Fail When Completing Tasks](https://arxiv.org/abs/2508.13143)
*Ruofan Lu,Yichen Li,Yintong Huo*

Main category: cs.AI

TL;DR: 저자들은 34개 대표 프로그램 가능한 태스크로 구성된 벤치마크를 만들어 오픈 소스 에이전트 프레임워크(3종)와 LLM(2종)을 평가했다. 전체 태스크 완수율은 약 50%였고, 실패를 계획·실행·응답 생성의 3계층 분류로 체계화하여 개선 방향을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 기존 평가들이 주로 성공률에 의존해 에이전트 간 상호작용, 통신 메커니즘, 실패 원인 등 내부 동작을 체계적으로 분석하지 못하는 문제를 보완하고자 함.

Method: 34개 태스크로 구성된 벤치마크를 설계하고, 3개 오픈소스 에이전트 프레임워크와 2종 LLM 조합으로 실험을 수행했다. 실패 사례들을 수집해 태스크 단계와 연계된 3계층 실패 분류법을 정리하고 원인 분석을 진행함.

Result: 평균 태스크 완수율 약 50%를 관찰했고, 실패 원인은 주로(1) 계획 수립 오류, (2) 태스크 실행 문제, (3) 잘못된 응답 생성으로 구분됨. 각 원인별로 개선 가능한 지점과 자기진단·계획 향상 방안을 제안.

Conclusion: 제시된 실패 분류와 완화 조언은 향후 더 견고한 자율 에이전트 개발을 위한 경험적 토대를 제공하며, 계획 능력과 자기진단 기능 강화를 통해 성능 향상이 기대됨.

Abstract: Autonomous agent systems powered by Large Language Models (LLMs) have
demonstrated promising capabilities in automating complex tasks. However,
current evaluations largely rely on success rates without systematically
analyzing the interactions, communication mechanisms, and failure causes within
these systems. To bridge this gap, we present a benchmark of 34 representative
programmable tasks designed to rigorously assess autonomous agents. Using this
benchmark, we evaluate three popular open-source agent frameworks combined with
two LLM backbones, observing a task completion rate of approximately 50%.
Through in-depth failure analysis, we develop a three-tier taxonomy of failure
causes aligned with task phases, highlighting planning errors, task execution
issues, and incorrect response generation. Based on these insights, we propose
actionable improvements to enhance agent planning and self-diagnosis
capabilities. Our failure taxonomy, together with mitigation advice, provides
an empirical foundation for developing more robust and effective autonomous
agent systems in the future.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [293] [Proceedings 18th Interaction and Concurrency Experience](https://arxiv.org/abs/2508.12308)
*Clément Aubert,Cinzia Di Giusto,Simon Fowler,Violet Ka I Pun*

Main category: cs.DC

TL;DR: ICE'25 논문집: 2025년 6월 20일 Lille에서 열린 워크숍(DisCoTec 위성). 7편 제출, 각 논문 3명의 PC 리뷰, 약 75개의 익명 상호작용 코멘트, 4편 게재 승인 + 1편 구두 발표, Kirstin Peters 초청강연 포함. 최종본은 리뷰와 워크숍 논의를 반영함.


<details>
  <summary>Details</summary>
Motivation: 대화형·익명 리뷰 과정을 통해 저자와 심사위원 간 활발한 토론을 촉진하고, 논문의 질을 향상시키며 워크숍에서 심화된 논의를 반영한 최종 논문집을 만들기 위함.

Method: 각 제출물은 3명의 PC가 심사하고 PC와 저자가 익명으로 상호작용하며 약 75개의 코멘트를 교환함. 워크숍에서 논의된 내용을 반영하여 논문 최종본을 작성함. 초청 강연 포함.

Result: 7편 중 4편이 게재 승인되었고 1편은 워크숍에서 구두 발표로 채택됨. 초청강연(요약 포함)과 최종 수정된 연구 논문들이 수록됨.

Conclusion: 익명 대화형 리뷰와 워크숍 논의를 통해 논문들이 개선되었으며, ICE'25 논문집은 그 결과물을 반영한 최종본을 제공함.

Abstract: This volume contains the proceedings of ICE'25, the 18th Interaction and
Concurrency Experience, which was held on Friday 20th June 2025 at the \'Ecole
National Sup\'erieure des Arts et M\'etiers in Lille, France, as a satellite
workshop of DisCoTec 2025. The ICE workshop series features a distinguishing
review and selection procedure: PC members are encouraged to interact,
anonymously, with authors. The 2025 edition of ICE received 7 submissions, each
reviewed by three PC members, and about 75 comments were exchanged during the
review process, witnessing very lively discussions. Four papers were accepted
for publication plus 1 oral communication, which was accepted for presentation
at the workshop. We were proud to host one invited talk, by Kirstin Peters. The
abstract of her talk is included in this volume, together with the final
versions of the research papers, which take into account the discussion at the
workshop and during the review process.

</details>


### [294] [Breaking the Aggregation Bottleneck in Federated Recommendation: A Personalized Model Merging Approach](https://arxiv.org/abs/2508.12386)
*Jundong Chen,Honglei Zhang,Chunxu Zhang,Fangyuan Luo,Yidong Li*

Main category: cs.DC

TL;DR: FedEM은 연합 추천에서 서버 측 모델 집계로 인해 클라이언트 개인화가 훼손되는 ‘aggregation bottleneck’을 이론·실험적으로 규명하고, 전역 모델과 로컬 모델을 탄력적으로 병합하여 개인화를 보전하는 방법을 제안한다. 기존 pFR 방법들과 달리 휴리스틱 대신 이론적 근거를 제시하고, 추가 메커니즘 대신 기존 로컬 모델을 활용한다. 실험에서 SOTA를 능가한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 클라이언트 간의 이질성 때문에 서버에서 집계된 전역 모델이 각 클라이언트의 최적 해로부터 벗어나며, 이로 인해 개인화 성능이 저하되는 문제(aggregation bottleneck)를 해결할 필요가 있음.

Method: FedEM은 전역 모델과 로컬 모델을 탄력적으로(가중치 병합 등으로 추정) 합쳐서 집계로 인해 손상된 개인화 성능을 보상한다. 기존 pFR과 달리 이 문제에 대한 이론적 분석을 제공하고, 별도 메커니즘 설계 없이 오프더셸프 로컬 모델을 활용한다.

Result: 실세계 데이터셋에서의 광범위한 실험을 통해 FedEM이 협업 학습 중 클라이언트 개인화를 보전하며 기존 최첨단 방법들보다 우수한 성능을 보임.

Conclusion: FedEM은 이론적 근거와 간단한 모델 병합 전략으로 연합 추천의 집계 병목을 완화하여 개인화 성능을 향상시킨 실용적 해법을 제시한다.

Abstract: Federated recommendation (FR) facilitates collaborative training by
aggregating local models from massive devices, enabling client-specific
personalization while ensuring privacy. However, we empirically and
theoretically demonstrate that server-side aggregation can undermine
client-side personalization, leading to suboptimal performance, which we term
the aggregation bottleneck. This issue stems from the inherent heterogeneity
across numerous clients in FR, which drives the globally aggregated model to
deviate from local optima. To this end, we propose FedEM, which elastically
merges the global and local models to compensate for impaired personalization.
Unlike existing personalized federated recommendation (pFR) methods, FedEM (1)
investigates the aggregation bottleneck in FR through theoretical insights,
rather than relying on heuristic analysis; (2) leverages off-the-shelf local
models rather than designing additional mechanisms to boost personalization.
Extensive experiments on real-world datasets demonstrate that our method
preserves client personalization during collaborative training, outperforming
state-of-the-art baselines.

</details>


### [295] [DIT: Dimension Reduction View on Optimal NFT Rarity Meters](https://arxiv.org/abs/2508.12671)
*Dmitry Belousov,Yury Yanovich*

Main category: cs.DC

TL;DR: NFT 희소성 측정 문제를 ROAR 벤치마크로 평가하고, 차원 축소(비거리 가중 MDS)를 활용한 최적 희소성 미터 설계와 새로운 성능지표 DIT(거래 내 비유사성)를 제안하여 비해석적 미터 DIT가 기존 방법보다 우수함을 보인다.


<details>
  <summary>Details</summary>
Motivation: NFT의 가치가 희소성에 의존하고 있어 산업·학계에서 희소성 계량화 수요가 크지만 기존 미터들을 직접 비교하기 어렵다. ROAR 벤치마크로 표준화된 평가가 필요하다.

Method: 차원 축소 접근을 사용해 NFT 속성 기반의 희소성 점수를 설계. 비거리 가중 비선형 다차원척도(non-metric weighted MDS)를 최적 미터로 개발하고, 거래 데이터와의 불일치를 측정하는 DIT(Dissimilarity in Trades)라는 성능지표를 도입.

Result: 제안한 DIT 미터(비해석적)는 ROAR 벤치마크 상에서 기존 희소성 미터들보다 우수한 성능을 보였다.

Conclusion: 차원 축소 기법과 거래 기반 성능지표가 NFT 희소성 측정에 유효하며, 해석성은 낮지만 성능이 우수한 DIT 미터가 실용적 대안이 될 수 있다.

Abstract: Non-fungible tokens (NFTs) have become a significant digital asset class,
each uniquely representing virtual entities such as artworks. These tokens are
stored in collections within smart contracts and are actively traded across
platforms on Ethereum, Bitcoin, and Solana blockchains. The value of NFTs is
closely tied to their distinctive characteristics that define rarity, leading
to a growing interest in quantifying rarity within both industry and academia.
While there are existing rarity meters for assessing NFT rarity, comparing them
can be challenging without direct access to the underlying collection data. The
Rating over all Rarities (ROAR) benchmark addresses this challenge by providing
a standardized framework for evaluating NFT rarity. This paper explores a
dimension reduction approach to rarity design, introducing new performance
measures and meters, and evaluates them using the ROAR benchmark. Our
contributions to the rarity meter design issue include developing an optimal
rarity meter design using non-metric weighted multidimensional scaling,
introducing Dissimilarity in Trades (DIT) as a performance measure inspired by
dimension reduction techniques, and unveiling the non-interpretable rarity
meter DIT, which demonstrates superior performance compared to existing
methods.

</details>


### [296] [Dissecting CPU-GPU Unified Physical Memory on AMD MI300A APUs](https://arxiv.org/abs/2508.12743)
*Jacob Wahlgren,Gabin Schieffer,Ruimin Shi,Edgar A. León,Roger Pearce,Maya Gokhale,Ivy Peng*

Main category: cs.DC

TL;DR: AMD MI300A APU의 Unified Physical Memory(UPM)를 처음으로 종합적으로 분석한 연구로, 메모리 지연·대역폭·일관성 오버헤드와 시스템 소프트웨어(할당, 페이지 폴트, TLB, Infinity Cache) 효율을 평가하고, UPM으로의 포팅 전략을 제안해 여섯 응용프로그램에서 실험한 결과 UPM의 통합 메모리 모델이 명시적 관리 모델과 동등하거나 더 나은 성능을 제공하며 메모리 비용은 최대 44% 절감됨을 보인다.


<details>
  <summary>Details</summary>
Motivation: 전통적 분리형 CPU/GPU 메모리는 개발 부담이 크고 Unified Virtual Memory(UVM)는 성능 저하를 초래한다. MI300A의 통합 CPU·GPU와 UPM은 새로운 설계 가능성을 열지만, 실제 성능·오버헤드·소프트웨어 상호작용에 대한 체계적 분석이 필요하다.

Method: MI300A APU에서 UPM의 메모리 특성(지연·대역폭·일관성 비용)을 실험적으로 측정하고, 메모리 할당·페이지 폴트 처리·TLB 관리·Infinity Cache 활용 등 시스템 소프트웨어 측면을 평가했다. 또한 UPM으로의 포팅 전략을 설계하고, 여섯개의 애플리케이션을 대상으로 통합 모델과 명시적 모델을 비교했다.

Result: 측정 결과 UPM은 낮은 지연과 높은 대역폭을 보이며 일관성 관련 오버헤드는 제어 가능한 수준이었다. 시스템 소프트웨어의 처리(특히 페이지 폴트와 TLB 관리)가 성능에 영향을 미치지만, 적절한 최적화를 통해 오버헤드를 완화할 수 있었다. 실험한 응용들에서 통합 메모리 모델은 명시적 관리 모델과 동등하거나 더 나은 성능을 보였고, 메모리 사용량은 최대 44%까지 감소했다.

Conclusion: MI300A의 UPM은 성능 저하 없이 메모리 관리의 복잡도를 크게 줄일 수 있는 실용적 대안이다. 시스템·애플리케이션 수준의 최적화를 통해 통합 메모리 모델로의 전환이 권장된다.

Abstract: Discrete GPUs are a cornerstone of HPC and data center systems, requiring
management of separate CPU and GPU memory spaces. Unified Virtual Memory (UVM)
has been proposed to ease the burden of memory management; however, at a high
cost in performance. The recent introduction of AMD's MI300A Accelerated
Processing Units (APUs)--as deployed in the El Capitan supercomputer--enables
HPC systems featuring integrated CPU and GPU with Unified Physical Memory (UPM)
for the first time. This work presents the first comprehensive characterization
of the UPM architecture on MI300A. We first analyze the UPM system properties,
including memory latency, bandwidth, and coherence overhead. We then assess the
efficiency of the system software in memory allocation, page fault handling,
TLB management, and Infinity Cache utilization. We propose a set of porting
strategies for transforming applications for the UPM architecture and evaluate
six applications on the MI300A APU. Our results show that applications on UPM
using the unified memory model can match or outperform those in the explicitly
managed model--while reducing memory costs by up to 44%.

</details>


### [297] [Accelerating Edge Inference for Distributed MoE Models with Latency-Optimized Expert Placement](https://arxiv.org/abs/2508.12851)
*Tian Wu,Liming Wang,Zijian Wen,Xiaoxi Zhang,Jingpu Duan,Xianwei Zhang,Jinhang Zuo*

Main category: cs.DC

TL;DR: DanceMoE는 이기종 GPU 엣지 서버들에서 MoE 모델의 희소 활성화를 이용해 활성화 인지(expert-aware) 기반 전문가 배치와 가벼운 마이그레이션으로 서버 간 통신을 최소화하고 추론 지연을 줄이는 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: MoE는 대규모 언어모델의 용량·효율성 향상에 기여하지만 엣지 환경에서는 메모리·통신 비용과 이종 자원 제약 때문에 배포가 어렵다. 중앙 클라우드 추론은 비용·지연·프라이버시 문제를 유발하며 기존 엣지 연구는 단일 장치나 동질적 환경에 집중한다.

Method: 워크로드 지역성과 MoE의 희소성(sparsity)을 활용한 데이터 기반의 활성화 인지 전문가 배치 알고리즘을 제안하여 각 서버의 로컬 커버리지와 메모리 사용을 균형있게 맞춘다. 또한 변화하는 요청 분포에 적응하는 경량 마이그레이션 메커니즘을 도입해 전문가 할당을 동적으로 조정한다.

Result: 현대 MoE 모델과 표준 데이터셋에서 평가한 결과, 기존 최첨단 기법 대비 추론 지연을 최대 30.6% 감소시키고 서버 간 통신량을 크게 줄이는 성능 향상을 보였다.

Conclusion: DanceMoE는 협업적 이기종 엣지 환경에서 실용적인 MoE 추론 솔루션을 제시하며, 활성화 인지 배치와 적응적 마이그레이션을 통해 지연 및 통신 비용을 효과적으로 절감한다.

Abstract: Mixture-of-Experts (MoE) have become a cornerstone for training and scaling
large language models (LLMs), offering substantial gains in model capacity and
efficiency through sparse expert activation. However, serving these models
remains challenging in practice, particularly in resource-constrained edge
environments, due to their large memory footprint and complex communication
demands. While centralized cloud inference is common, it incurs high
infrastructure costs, along with latency and privacy concerns. A few recent
edge MoE works propose memory-efficient strategies but typically focus on
single-device or homogeneous setups. This paper presents DanceMoE, an efficient
MoE inference framework that enables activation-aware expert placement across
collaborative, heterogeneous, GPU-equipped edge servers. DanceMoE leverages the
inherent sparsity of MoE models and workload locality to minimize cross-server
communication and enable efficient expert placement under heterogeneous
resource constraints. It introduces a data-driven, activation-aware placement
algorithm that balances local coverage and memory usage across servers,
alongside a lightweight migration mechanism that adapts expert assignments
under evolving workloads. We evaluate DanceMoE on modern MoE models and widely
used datasets, demonstrating up to 30.6\% lower inference latency, and
substantial communication reduction compared to state-of-the-art baselines,
showcasing the effectiveness of collaborative edge-based MoE inference.

</details>


### [298] [WANify: Gauging and Balancing Runtime WAN Bandwidth for Geo-distributed Data Analytics](https://arxiv.org/abs/2508.12961)
*Anshuman Das Mohapatra,Kwangsung Oh*

Main category: cs.DC

TL;DR: WANify는 머신러닝(RF)을 이용해 실행 시점의 WAN 대역폭을 정확히 예측하고, 예측 결과를 바탕으로 이기종 병렬 연결 수를 최적화하여 GDA의 지연과 비용을 줄이는 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 기존 GDA 시스템은 데이터센터 간 WAN 대역폭을 정적으로·독립적으로 측정하고 단일 연결 대역폭만 고려해 실제 동시·다중 전송 상황을 반영하지 못한다. 이로 인해 데이터/작업 배치 결정이 비효율적이 되어 쿼리 지연과 비용이 증가한다.

Method: WANify는 러닝 타임에서 달성 가능한 WAN 대역폭을 예측하기 위해 결정트리 기반 Random Forest를 사용한다. 예측된 런타임 BW를 바탕으로 데이터센터 간 데이터 전송을 위한 이기종 병렬 연결 수를 최적화하며, 네트워크·작업 동적성 및 데이터·컴퓨트·DC 수의 이기종성을 고려한다.

Result: AWS의 8개 지리적 DC 환경에서 프로토타입을 평가한 결과, WAN 링크 간 균형을 맞춤으로써 전체 WAN 처리량을 향상시키고 지연과 비용을 최대 각각 26%·16%까지 절감했다. 또한 모니터링 비용을 최소화하면서 동적·이기종 환경을 효율적으로 처리한다.

Conclusion: WANify는 예측 기반으로 병렬 연결 구성을 조정해 사용 가능한 WAN 용량을 더 잘 활용함으로써 GDA의 성능과 비용효율을 개선한다.

Abstract: Accurate wide area network (WAN) bandwidth (BW) is essential for
geo-distributed data analytics (GDA) systems to make optimal decisions such as
data and task placement to improve performance. Existing GDA systems, however,
measure WAN BW statically and independently between data centers (DCs), while
data transfer occurs dynamically and simultaneously among DCs during workload
execution. Also, they use a single connection WAN BW that cannot capture actual
WAN capacities between distant DCs. Such inaccurate WAN BWs yield sub-optimal
decisions, inflating overall query latency and cost. In this paper, we present
WANify, a new framework that precisely and dynamically gauges achievable
runtime WAN BW using a machine learning prediction scheme, decision tree-based
Random Forest. This helps GDA systems make better decisions yielding reduced
latency and costs including WAN BW monitoring costs. Based on predicted runtime
WAN BW, WANify determines the optimal number of heterogeneous parallel
connections for data transfer among DCs. This approach improves performance
without additional, or even at reduced cost, by fully exploiting available WAN
capacities. In addition, WANify considers dynamics like network and workloads,
and heterogeneity like skewed data, heterogeneous compute resources, and a
varying number of DCs while making decisions. The WANify prototype running on
state-of-the-art GDA systems is evaluated on AWS with 8 geo-distributed DCs.
Results show that WANify enhances WAN throughput by balancing between the
strongest and weakest WAN links, enabling GDA systems to reduce latency and
cost by up to 26% and 16% respectively with minimal effort, all while handling
dynamics and heterogeneity efficiently.

</details>


### [299] [Congested Clique Counting for Local Gibbs Distributions](https://arxiv.org/abs/2508.13083)
*Joshua Z. Sobel*

Main category: cs.DC

TL;DR: CongestedClique 환경에서 조합적 샘플링↔계수화(Counting) 환원을 활용해 여러 문제에 대한 최초의 근사 계수화 알고리즘을 제시. 특히 q>αΔ (α>2)일 때 그래프의 q-색상 수를 ε-배 오차로 Õ(n^{1/3}/ε^2) 라운드에 근사. 일반 Gibbs 분포(지역성·빠른 혼합 가정)와 하드코어 모델(λ ≤ α/(Δ-1), α<1)에서도 각각 Õ(n^{1/3}/ε^2) 및 Õ(1/ε^2) 라운드 성능을 얻음. 병렬 분산 마르코프 체인을 통해 n개의 샘플을 동시에 생성하는 새로운 기법을 사용.


<details>
  <summary>Details</summary>
Motivation: 샘플링과 계수화 사이의 고전적 환원(JVV)을 분산 CongestedClique 모델에 도입해, 통계물리·기계학습에서 중요한 확률분포의 partition function 및 조합적 계수 문제를 빠르게 근사하려는 목적.

Method: 최근의 병렬 알고리즘(Liu, Yin, Zhang 2024)과 JVV 환원에 기반해 분산 마르코프 체인의 병렬 샘플링 기법을 설계. 삼각형 카운팅 및 semiring 행렬곱의 분산 아이디어를 차용해 n개의 랜덤 샘플을 병렬로 생성하고 이를 계수화 환원에 적용.

Result: - q-색상 수 근사: q>αΔ(α>2)에서 Õ(n^{1/3}/ε^2) 라운드
- 일반 Gibbs 분포(지역성+빠른 혼합): 동일한 복잡도
- 하드코어 모델: λ ≤ α/(Δ-1), α<1이면 Õ(1/ε^2) 라운드
이는 CongestedClique에서의 최초의 근사 계수화 알고리즘들임.

Conclusion: 분산환경에서 대량 샘플을 병렬로 뽑는 새 기법을 통해 넓은 범위의 계수화 문제에 대해 sublinear 라운드 근사 알고리즘을 확립. 다만 빠른 혼합·지역성·매개변수(α, λ)의 제약이 필요하며, 이 제약을 완화하거나 하한을 연구하는 것이 후속 과제다.

Abstract: There are well established reductions between combinatorial sampling and
counting problems (Jerrum, Valiant, Vazirani TCS 1986). Building off of a very
recent parallel algorithm utilizing this connection (Liu, Yin, Zhang arxiv
2024), we demonstrate the first approximate counting algorithm in the
CongestedClique for a wide range of problems. Most interestingly, we present an
algorithm for approximating the number of $q$-colorings of a graph within
$\epsilon$-multiplicative error, when $q>\alpha\Delta$ for any constant
$\alpha>2$, in $\Tilde{O}\big(\frac{n^{1/3}}{\epsilon^2}\big)$ rounds. More
generally, we achieve a runtime of
$\Tilde{O}\big(\frac{n^{1/3}}{\epsilon^2}\big)$ rounds for approximating the
partition function of Gibbs distributions defined over graphs when simple
locality and fast mixing conditions hold. Gibbs distributions are widely used
in fields such as machine learning and statistical physics. We obtain our
result by providing an algorithm to draw $n$ random samples from a distributed
Markov chain in parallel, using similar ideas to triangle counting (Dolev,
Lenzen, Peled DISC 2012) and semiring matrix multiplication (Censor-Hillel,
Kaski, Korhonen, Lenzen, Paz, Suomela PODC 2015). Aside from counting problems,
this result may be interesting for other applications requiring a large number
of samples. In the special case of estimating the partition function of the
hardcore model, also known as counting weighted independent sets, we can do
even better and achieve an $\Tilde{O}\big(\frac{1}{\epsilon^2}\big)$ round
algorithm, when the fugacity $\lambda \leq \frac{\alpha}{\Delta-1}$, where
$\alpha$ is an arbitrary constant less than $1$.

</details>


### [300] [Team Formation and Applications](https://arxiv.org/abs/2508.13084)
*Yuval Emek,Shay Kutten,Ido Rafael,Gadi Taubenfeld*

Main category: cs.DC

TL;DR: Introduces the Team Formation (TF) problem in an asynchronous complete network with bounded-size messages and initial failures; gives a randomized, message- and time-efficient algorithm to assemble tokens into teams of size σ, shows many distributed problems reduce to TF (including leader election variants, threshold detection, etc.), breaks linear message complexity for asynchronous implicit leader election, improves time for message-optimal explicit leader election, and proves a tight lower bound on TF message complexity.


<details>
  <summary>Details</summary>
Motivation: Provide a reusable long-lived distributed primitive that assembles tokens into fixed-size teams despite initial node failures; use this primitive to obtain improved algorithms for many classic and new distributed tasks in the asynchronous, bounded-message model.

Method: Formally define TF over the asynchronous complete graph with bounded messages and a class of generalized initial failures. Design a randomized TF algorithm optimizing message and time costs. Show reductions from multiple problems (one-shot and long-lived) to TF, and analyze how TF-based solutions translate to complexity improvements. Finally, prove a lower bound on the message complexity of any TF algorithm.

Result: A randomized algorithm for TF that is efficient in messages and time; reductions that yield the first sublinear-message algorithm for asynchronous implicit leader election and tempoal improvements for message-optimal explicit leader election; additional applications (matching in online gaming, generalized gathering, perfect matching in induced subgraphs, quorum sensing); and a matching lower bound on TF message complexity.

Conclusion: TF is a powerful, long-lived distributed primitive that enables improved algorithms across a range of problems in the asynchronous, bounded-message model. The provided algorithm and reductions yield new complexity separations (e.g., sublinear messages for implicit leader election), while the tight lower bound characterizes the limits of TF-based approaches.

Abstract: A novel long-lived distributed problem, called Team Formation (TF), is
introduced together with a message- and time-efficient randomized algorithm.
The problem is defined over the asynchronous model with a complete
communication graph, using bounded size messages, where a certain fraction of
the nodes may experience a generalized, strictly stronger, version of initial
failures. The goal of a TF algorithm is to assemble tokens injected by the
environment, in a distributed manner, into teams of size $\sigma$, where
$\sigma$ is a parameter of the problem.
  The usefulness of TF is demonstrated by using it to derive efficient
algorithms for many distributed problems. Specifically, we show that various
(one-shot as well as long-lived) distributed problems reduce to TF. This
includes well-known (and extensively studied) distributed problems such as
several versions of leader election and threshold detection. For example, we
are the first to break the linear message complexity bound for asynchronous
implicit leader election. We also improve the time complexity of
message-optimal algorithms for asynchronous explicit leader election. Other
distributed problems that reduce to TF are new ones, including matching players
in online gaming platforms, a generalization of gathering, constructing a
perfect matching in an induced subgraph of the complete graph, quorum sensing
in message-passing networks, and more. To complement our positive contribution,
we establish a tight lower bound on the message complexity of TF algorithms.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [301] [RRRA: Resampling and Reranking through a Retriever Adapter](https://arxiv.org/abs/2508.11670)
*Bongsu Kim*

Main category: cs.IR

TL;DR: 하드 네거티브 중 실제로는 긍정(위양성)일 확률을 Bi-Encoder 표현을 기반한 가벼운 어댑터로 예측해, 학습 시 네거티브 재샘플링과 추론 시 재정렬에 활용하여 기존 Bi-Encoder 기반 dense retrieval 성능을 일관되게 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 기존의 전역적(예: 긍정 문서 점수 기반) 휴리스틱은 해석 가능성을 주지만 쿼리-특이적인 거짓-네거티브(false negative)를 놓치기 쉬워, 하드 네거티브 선택이 학습 효율과 최종 성능에 큰 영향을 미치는 dense retrieval에서 이를 보완할 필요가 있다.

Method: Bi-Encoder의 표현을 관찰하는 학습 가능한 어댑터를 도입해 각 하드 네거티브가 거짓-네거티브일 확률을 동적·문맥적으로 추정한다. 이 확률은 (1) 학습 중 네거티브의 가중치를 재설정(재샘플링)하고, (2) 추론 시 top-k 검색 결과를 재정렬(리랭킹)하는 데 사용된다.

Result: 표준 벤치마크에서 강력한 Bi-Encoder 기준선들을 일관되게 능가하는 성능 개선을 보여주며, 거짓-네거티브를 명시적으로 모델링하는 것이 유익함을 확인했다.

Conclusion: 가벼운 어댑터로 쿼리-특이적 거짓-네거티브를 예측해 재샘플링·리랭킹에 반영하면 dense retrieval의 정확도와 해석 가능성을 모두 개선할 수 있다.

Abstract: In dense retrieval, effective training hinges on selecting high quality hard
negatives while avoiding false negatives. Recent methods apply heuristics based
on positive document scores to identify hard negatives, improving both
performance and interpretability. However, these global, example agnostic
strategies often miss instance specific false negatives. To address this, we
propose a learnable adapter module that monitors Bi-Encoder representations to
estimate the likelihood that a hard negative is actually a false negative. This
probability is modeled dynamically and contextually, enabling fine-grained,
query specific judgments. The predicted scores are used in two downstream
components: (1) resampling, where negatives are reweighted during training, and
(2) reranking, where top-k retrieved documents are reordered at inference.
Empirical results on standard benchmarks show that our adapter-enhanced
framework consistently outperforms strong Bi-Encoder baselines, underscoring
the benefit of explicit false negative modeling in dense retrieval.

</details>


### [302] [LLM-Based Intelligent Agents for Music Recommendation: A Comparison with Classical Content-Based Filtering](https://arxiv.org/abs/2508.11671)
*Ronald Carvalho Boadana,Ademir Guimarães da Costa Junior,Ricardo Rios,Fábio Santos da Silva*

Main category: cs.IR

TL;DR: LLM(예: Gemini, LLaMA) 기반 다중 에이전트 추천 시스템이 전통적 콘텐츠 기반 모델 대비 최대 89.32%의 사용자 만족도를 보여 유망하나, 실험 설계·재현성·계산비용·평가 지표 등에 대한 추가 검증이 필요하다.


<details>
  <summary>Details</summary>
Motivation: 스트리밍 음악의 폭발적 증가로 사용자가 정보과부하에 직면해 있으며, 개인화된 추천 품질 향상을 위해 더 정교한 모델(특히 LLM과 에이전트)의 도입을 검토하고자 함.

Method: Gemini 및 LLaMA 계열 LLM과 지능형 에이전트를 결합한 다중 에이전트 추천 시스템을 구현하고, 전통적 콘텐츠 기반 추천 모델과 사용자 만족도·신선도( novelty)·계산 효율성 측면에서 비교 평가.

Result: LLM 기반 접근법이 사용자 만족도에서 최대 89.32%를 달성했으며, 신선도와 계산 효율성에 대한 결과도 제시되었음(세부 수치·통계 유의성 미기재 가능성 존재).

Conclusion: LLM을 활용한 음악 추천은 유망하지만, 데이터·평가방법·비교 기준·비용·확장성 등에 대한 추가적인 명확화와 엄격한 실험적 검증이 필요하다.

Abstract: The growing availability of music on streaming platforms has led to
information overload for users. To address this issue and enhance the user
experience, increasingly sophisticated recommendation systems have been
proposed. This work investigates the use of Large Language Models (LLMs) from
the Gemini and LLaMA families, combined with intelligent agents, in a
multi-agent personalized music recommendation system. The results are compared
with a traditional content-based recommendation model, considering user
satisfaction, novelty, and computational efficiency. LLMs achieved satisfaction
rates of up to \textit{89{,}32\%}, indicating their promising potential in
music recommendation systems.

</details>


### [303] [Ontology-Guided Query Expansion for Biomedical Document Retrieval using Large Language Models](https://arxiv.org/abs/2508.11784)
*Zabir Al Nazi,Vagelis Hristidis,Aaron Lawson McLean,Jannat Ara Meem,Md Taukir Azam Chowdhury*

Main category: cs.IR

TL;DR: BMQExpander는 UMLS의 의학 지식(정의·관계)을 LLM 생성 능력과 결합한 온톨로지 기반 쿼리 확장 파이프라인으로, 생의학 문헌 검색에서 NDCG@10 기준 최대 22.1% 향상(희소 기반 대비), 최강 베이스라인 대비 최대 6.5% 향상, 쿼리 변형에 대해 강한 일반화(최대 15.7% 개선)를 보이며, 패러프레이즈 벤치마크와 함께 환각(hallucination)이 적다는 정성 분석 결과를 보고한다.


<details>
  <summary>Details</summary>
Motivation: 의학 QA에서 도큐먼트 검색은 도메인 특화 어휘와 쿼리의 의미 모호성 때문에 여전히 도전적이다. 도메인 지식(UMLS)과 LLM의 생성력을 결합해 쿼리 확장으로 검색 효과를 높이려는 목적.

Method: UMLS 메타시소러스를 통해 개념 정의와 관계를 추출하고, 이를 LLM 기반 생성(프롬프트)과 결합하는 온톨로지-인식 쿼리 확장 파이프라인(BMQExpander)을 설계·구현. 여러 최신 베이스라인(희소·밀집 리트리버, 쿼리 확장 기법, 생의학 특화 방법)과 비교, NFCorpus/TREC-COVID/SciFact에서 평가. 쿼리 변형 실험과 정성적 환각 분석 및 패러프레이즈 벤치마크 공개를 병행.

Result: 세 벤치마크에서 일관된 성능 향상: 희소 베이스라인 대비 NDCG@10 최대 +22.1%, 가장 강한 베이스라인 대비 최대 +6.5%. 쿼리 변형 환경에서 강한 일반화(최대 +15.7%). LLM 기반 다른 확장 기법보다 환각 빈도가 낮음.

Conclusion: UMLS 지식과 LLM을 결합한 쿼리 확장은 생의학 정보 검색에서 효과적이고 견고하며, 패러프레이즈 데이터 공개와 낮은 환각 비율이 실무 적용 가능성을 높인다.

Abstract: Effective Question Answering (QA) on large biomedical document collections
requires effective document retrieval techniques. The latter remains a
challenging task due to the domain-specific vocabulary and semantic ambiguity
in user queries. We propose BMQExpander, a novel ontology-aware query expansion
pipeline that combines medical knowledge - definitions and relationships - from
the UMLS Metathesaurus with the generative capabilities of large language
models (LLMs) to enhance retrieval effectiveness. We implemented several
state-of-the-art baselines, including sparse and dense retrievers, query
expansion methods, and biomedical-specific solutions. We show that BMQExpander
has superior retrieval performance on three popular biomedical Information
Retrieval (IR) benchmarks: NFCorpus, TREC-COVID, and SciFact - with
improvements of up to 22.1% in NDCG@10 over sparse baselines and up to 6.5%
over the strongest baseline. Further, BMQExpander generalizes robustly under
query perturbation settings, in contrast to supervised baselines, achieving up
to 15.7% improvement over the strongest baseline. As a side contribution, we
publish our paraphrased benchmarks. Finally, our qualitative analysis shows
that BMQExpander has fewer hallucinations compared to other LLM-based query
expansion baselines.

</details>


### [304] [TBGRecall: A Generative Retrieval Model for E-commerce Recommendation Scenarios](https://arxiv.org/abs/2508.11977)
*Zida Liang,Changfa Wu,Dunxian Huang,Weiqiang Sun,Ziyang Wang,Yuliang Yan,Jian Wu,Yuning Jiang,Bo Zheng,Ke Chen,Silu Zhou,Yu Zhang*

Main category: cs.IR

TL;DR: TBGRecall은 Next Session Prediction(NSP) 재구성을 통해 생성형(retrieval) 추천의 순차 제약을 완화하고, 세션 토큰+아이템 토큰 구성 및 ‘제한된 이력 프리트레인 + 확률적 부분 점진학습’으로 학습 효율과 최신성 효과를 극대화해 공개 벤치마크와 TaoBao 대규모 데이터에서 SOTA 성능과 스케일링 법칙을 보였다는 주장.


<details>
  <summary>Details</summary>
Motivation: 생성형 모델이 추천에서 유망하지만, 기존의 오토리그레시브 생성은 단일 요청에서 위치 제약이 없는 다중 아이템 회수(생성)에 비효율적이고 순차적 의존성 때문에 검색(retrieval) 최적화에 한계가 있다.

Method: 입력을 다중 세션 시퀀스로 분할하고 각 시퀀스를 세션 토큰 + 아이템 토큰 집합으로 구성(Next Session Prediction). 생성형 검색에 맞춘 여러 최적화 기법을 추가. 학습은 제한된 과거 데이터로 프리트레인한 뒤 확률적(partial stochastic) 증분 학습을 적용해 속도와 최신성에 초점.

Result: 공개 벤치와 TaoBao 산업 데이터에서 기존 추천기법들을 능가하는 성능을 보고하며, 모델 규모/데이터 변화에 따른 명확한 스케일링 법칙을 관찰.

Conclusion: NSP 기반 재구성과 제안된 학습 파이프라인은 전통적 오토리그레시브 생성 접근의 제약을 완화해 전자상거래 추천에서 생성형 검색의 실용성과 성능을 크게 향상시킨다.

Abstract: Recommendation systems are essential tools in modern e-commerce, facilitating
personalized user experiences by suggesting relevant products. Recent
advancements in generative models have demonstrated potential in enhancing
recommendation systems; however, these models often exhibit limitations in
optimizing retrieval tasks, primarily due to their reliance on autoregressive
generation mechanisms. Conventional approaches introduce sequential
dependencies that impede efficient retrieval, as they are inherently unsuitable
for generating multiple items without positional constraints within a single
request session. To address these limitations, we propose TBGRecall, a
framework integrating Next Session Prediction (NSP), designed to enhance
generative retrieval models for e-commerce applications. Our framework
reformulation involves partitioning input samples into multi-session sequences,
where each sequence comprises a session token followed by a set of item tokens,
and then further incorporate multiple optimizations tailored to the generative
task in retrieval scenarios. In terms of training methodology, our pipeline
integrates limited historical data pre-training with stochastic partial
incremental training, significantly improving training efficiency and
emphasizing the superiority of data recency over sheer data volume. Our
extensive experiments, conducted on public benchmarks alongside a large-scale
industrial dataset from TaoBao, show TBGRecall outperforms the state-of-the-art
recommendation methods, and exhibits a clear scaling law trend. Ultimately, NSP
represents a significant advancement in the effectiveness of generative
recommendation systems for e-commerce applications.

</details>


### [305] [Leveraging Geometric Insights in Hyperbolic Triplet Loss for Improved Recommendations](https://arxiv.org/abs/2508.11978)
*Viacheslav Yusupov,Maxim Rakhuba,Evgeny Frolov*

Main category: cs.IR

TL;DR: 하이퍼볼릭 기하를 활용한 새로운 추천모델 제안 — 거리 개념을 재정의하고 사용자·아이템 임베딩을 학습하는 삼중항 손실로 표현력과 수치적 안정성 향상. 기존 유클리드·하이퍼볼릭 모델보다 성능 우수, 인기 편향 감소 및 추천 다양성·개인화 개선.


<details>
  <summary>Details</summary>
Motivation: 상호작용 데이터에서 복잡한 패턴을 포착하기 위해 유클리드 공간보다 풍부한 표현력을 제공하는 하이퍼볼릭 기하의 잠재력 활용. 동시에 표현력 확장과 계산적 안정성 문제를 해결하고 인기 편향을 줄여 개인화된 추천을 제공하려는 목표.

Method: 하이퍼볼릭 거리의 개념을 재정의해 유클리드 대비 추가 표현 용량을 확보하고 사용자·아이템 임베딩을 학습. 사용자와 선호/비선호 아이템 간의 3원 관계를 모델링하는 삼중항 손실을 구성, 기하학적 특성에 기반한 쌍별 상호작용 항을 혼합하여 학습을 진행.

Result: 제안 모델은 기존 유클리드 및 하이퍼볼릭 기반 방법들을 능가하며, 인기 아이템에 대한 편향을 줄여 추천의 다양성과 개인화 수준을 향상시킴.

Conclusion: 기하학적 통찰과 삼중항 손실의 결합을 통해 더 표현력 있고 수치적으로 안정적인 하이퍼볼릭 추천 임베딩을 학습할 수 있으며, 이는 성능 및 공정성 측면에서 실질적 이득을 제공한다.

Abstract: Recent studies have demonstrated the potential of hyperbolic geometry for
capturing complex patterns from interaction data in recommender systems. In
this work, we introduce a novel hyperbolic recommendation model that uses
geometrical insights to improve representation learning and increase
computational stability at the same time. We reformulate the notion of
hyperbolic distances to unlock additional representation capacity over
conventional Euclidean space and learn more expressive user and item
representations. To better capture user-items interactions, we construct a
triplet loss that models ternary relations between users and their
corresponding preferred and nonpreferred choices through a mix of pairwise
interaction terms driven by the geometry of data. Our hyperbolic approach not
only outperforms existing Euclidean and hyperbolic models but also reduces
popularity bias, leading to more diverse and personalized recommendations.

</details>


### [306] [A Large-Scale Web Search Dataset for Federated Online Learning to Rank](https://arxiv.org/abs/2508.12353)
*Marcel Gregoriadis,Jingwei Kang,Johan Pouwelse*

Main category: cs.IR

TL;DR: 중앙화 검색 로그의 프라이버시 문제 때문에 FOLTR(연합 온라인 학습-순위화)가 대안으로 제시되지만, 기존 벤치마크는 무작위 분할·시뮬레이션 클릭·동기 참여 가정으로 현실성을 잃음. 본 논문은 10,000명 사용자의 실제 클릭과 타임스탬프를 포함한 260만 쿼리 규모의 AOL4FOLTR 데이터셋을 제안하여 현실적인 사용자 분할, 행동 모델링, 비동기 연합학습 시나리오를 지원한다.


<details>
  <summary>Details</summary>
Motivation: 중앙집중형 로그 수집의 개인정보·윤리 문제를 피하면서도 실제 사용자의 다양하고 시공간적인 행동을 반영하는 연합 학습 평가 인프라가 필요함. 기존 FOLTR 벤치마크는 무작위 분할·시뮬레이션 클릭·동기화 가정으로 실제 배포 환경을 제대로 모사하지 못함.

Method: 대규모 웹 검색 로그를 수집·정제해 사용자 식별자, 실제 클릭 이벤트, 쿼리 타임스탬프를 보존한 데이터셋을 구축(총 2.6M 쿼리, 10k 사용자). 이를 통해 현실적 사용자 분할(non-iid·시간 기반), 사용자 행동 모델링, 비동기 클라이언트 참여 실험을 가능하게 함.

Result: AOL4FOLTR 데이터셋은 기존 벤치마크의 한계를 해소하며, 실제 클릭과 시간 정보를 이용한 보다 현실적인 FOLTR 실험을 가능하게 함. 대규모·사용자별 로그로 다양한 분산·비동기 시나리오를 재현할 수 있음.

Conclusion: AOL4FOLTR은 FOLTR 연구의 현실성·재현성을 높이는 자원으로, 연합 순위학습 알고리즘의 실제 성능·강건성 평가에 기여할 것으로 기대됨.

Abstract: The centralized collection of search interaction logs for training ranking
models raises significant privacy concerns. Federated Online Learning to Rank
(FOLTR) offers a privacy-preserving alternative by enabling collaborative model
training without sharing raw user data. However, benchmarks in FOLTR are
largely based on random partitioning of classical learning-to-rank datasets,
simulated user clicks, and the assumption of synchronous client participation.
This oversimplifies real-world dynamics and undermines the realism of
experimental results. We present AOL4FOLTR, a large-scale web search dataset
with 2.6 million queries from 10,000 users. Our dataset addresses key
limitations of existing benchmarks by including user identifiers, real click
data, and query timestamps, enabling realistic user partitioning, behavior
modeling, and asynchronous federated learning scenarios.

</details>


### [307] [TaoSR1: The Thinking Model for E-commerce Relevance Search](https://arxiv.org/abs/2508.12365)
*Chenhe Dong,Shaowei Yao,Pengkun Jiao,Jianhui Yang,Yiming Jin,Zerui Huang,Xiaojiang Zhou,Dan Ou,Haihong Tang*

Main category: cs.IR

TL;DR: TaoSR1은 제품 검색의 쿼리-상품 관련성 판단을 위해 CoT(Chain-of-Thought)로 LLM에 직접 추론 능력을 주고, SFT→pass@N+DPO→GRPO의 3단계로 생성 품질과 배포 효율을 개선한 프레임워크다. 오프라인 및 온라인 평가에서 유의미한 성능 개선을 보고한다.


<details>
  <summary>Details</summary>
Motivation: BERT류 모델은 의미매칭에 강하지만 복잡한 추론이 필요한 관련성 판단에서는 한계가 있음. 기존에는 LLM을 판별형으로 미세조정하거나 축소(distill)해 배포했으나, 직접 LLM을 추론형(CoT)으로 배포하는 실용적 방법이 필요하다.

Method: (1) CoT를 포함한 SFT로 추론 습득, (2) 오프라인에서 pass@N 샘플링과 DPO로 생성물 선별/향상, (3) 난이도 기반 동적 샘플링과 GRPO로 판별형 환각(discriminative hallucination) 억제. 추가로 post-CoT 처리 및 누적확률 기반 분할로 온라인 배포 비용 절감.

Result: 오프라인 데이터셋과 온라인 인체평가(side-by-side)에서 기존 베이스라인 대비 유의미한 성능 향상을 보임.

Conclusion: CoT 추론을 직접 활용해 관련성 분류 성능을 개선하는 새로운 배포 패러다임을 제시함.

Abstract: Query-product relevance prediction is a core task in e-commerce search.
BERT-based models excel at semantic matching but lack complex reasoning
capabilities. While Large Language Models (LLMs) are explored, most still use
discriminative fine-tuning or distill to smaller models for deployment. We
propose a framework to directly deploy LLMs for this task, addressing key
challenges: Chain-of-Thought (CoT) error accumulation, discriminative
hallucination, and deployment feasibility. Our framework, TaoSR1, involves
three stages: (1) Supervised Fine-Tuning (SFT) with CoT to instill reasoning;
(2) Offline sampling with a pass@N strategy and Direct Preference Optimization
(DPO) to improve generation quality; and (3) Difficulty-based dynamic sampling
with Group Relative Policy Optimization (GRPO) to mitigate discriminative
hallucination. Additionally, post-CoT processing and a cumulative
probability-based partitioning method enable efficient online deployment.
TaoSR1 significantly outperforms baselines on offline datasets and achieves
substantial gains in online side-by-side human evaluations, introducing a novel
paradigm for applying CoT reasoning to relevance classification.

</details>


### [308] [Contrastive Multi-View Graph Hashing](https://arxiv.org/abs/2508.12377)
*Yang Xu,Zuliang Yang,Kai Ming Ting*

Main category: cs.IR

TL;DR: 다중 뷰 그래프 데이터를 위해 대조학습 기반으로 통합된 이진 해시 임베딩을 학습하는 CMGHash 제안. k-최근접 이웃을 끌어당기고 비-이웃을 밀어내는 대조 손실과 이진화 제약을 결합해 높은 검색 정확도를 달성함.


<details>
  <summary>Details</summary>
Motivation: 기존 다중 뷰 해싱 기법들은 주로 뷰당 속성(벡터) 입력을 가정해 그래프의 복잡한 위상 정보를 효과적으로 통합·인코딩하지 못함. 여러 이종 그래프 뷰로부터 통합된 바이너리 임베딩을 효율적으로 생성하는 방법이 필요함.

Method: 노드 수준에서 다중 그래프 뷰를 입력으로 받아 각 노드의 합의(consensus) 표현 공간을 학습. 대조적 다중 뷰 그래프 손실로 모든 그래프에서의 k-최근접 이웃을 끌어들이고 비-이웃(음성 샘플)을 밀어냄. 합의 표현에 이진화 제약을 부과하여 최소 비용으로 이진 임베딩으로 변환 가능하도록 설계. 엔드투엔드 학습 프레임워크로 구현.

Result: 여러 벤치마크 데이터셋에서 기존 방법들보다 검색(리트리벌) 정확도에서 유의미한 성능 향상을 보고함.

Conclusion: 대조 학습과 이진화 제약의 결합을 통해 다중 뷰 그래프에서 실용적이고 구별력 있는 바이너리 임베딩을 학습할 수 있으며, 검색 태스크에서 우수한 성능을 보임.

Abstract: Multi-view graph data, which both captures node attributes and rich
relational information from diverse sources, is becoming increasingly prevalent
in various domains. The effective and efficient retrieval of such data is an
important task. Although multi-view hashing techniques have offered a paradigm
for fusing diverse information into compact binary codes, they typically assume
attributes-based inputs per view. This makes them unsuitable for multi-view
graph data, where effectively encoding and fusing complex topological
information from multiple heterogeneous graph views to generate unified binary
embeddings remains a significant challenge. In this work, we propose
Contrastive Multi-view Graph Hashing (CMGHash), a novel end-to-end framework
designed to learn unified and discriminative binary embeddings from multi-view
graph data. CMGHash learns a consensus node representation space using a
contrastive multi-view graph loss, which aims to pull $k$-nearest neighbors
from all graphs closer while pushing away negative pairs, i.e., non-neighbor
nodes. Moreover, we impose binarization constraints on this consensus space,
enabling its conversion to a corresponding binary embedding space at minimal
cost. Extensive experiments on several benchmark datasets demonstrate that
CMGHash significantly outperforms existing approaches in terms of retrieval
accuracy.

</details>


### [309] [Diagnostic-Guided Dynamic Profile Optimization for LLM-based User Simulators in Sequential Recommendation](https://arxiv.org/abs/2508.12645)
*Hongyang Liu,Zhu Sun,Tianjun Wei,Yan Wang,Jiajie Zhu,Xinghua Qu*

Main category: cs.IR

TL;DR: DGDPO는 LLM 기반 사용자 시뮬레이터의 한계를 극복하기 위해 사용자 프로필을 동적·반복적으로 최적화하는 프레임워크다. 진단 모듈로 결함을 식별하고 치료 모듈로 프로필을 보정하며, 다중 라운드로 추천기와 상호작용해 현실적 시뮬레이션을 구현한다.


<details>
  <summary>Details</summary>
Motivation: 기존 LLM 기반 시뮬레이터는(1) 단일-스텝 정적 프롬프트로 부정확·불완전한 사용자 프로필을 만들고,(2) 단일 라운드의 비현실적 상호작용 패턴으로 실제 추천 환경을 반영하지 못한다는 한계가 있다.

Method: DGDPO는 반복 최적화 루프를 도입한다. 각 루프에서: (a) 특화된 LLM 진단 모듈(새로운 학습 전략으로 보정됨)이 프로필의 특정 결함을 정확히 찾아내고, (b) 범용 LLM 치료 모듈이 진단 결과를 바탕으로 목표 지향적 수정 제안을 생성해 프로필을 갱신한다. 또한 DGDPO를 순차 추천기와 통합해 사용자 프로필과 추천 전략이 다중 라운드에서 상호 적응하도록 설계했다.

Result: 세 개의 실제 데이터셋에서 광범위한 실험을 통해 제안 방법이 기존 LLM 기반 시뮬레이터들보다 시뮬레이션 충실도와 성능에서 우수함을 보였다.

Conclusion: DGDPO는 동적·반복적 프로필 최적화와 다중 라운드 상호작용을 통해 사용자 시뮬레이션의 현실성과 유용성을 크게 향상시키며, 추천 시스템 개발·평가를 위한 더 신뢰성 있는 시뮬레이터를 제시한다.

Abstract: Recent advances in large language models (LLMs) have enabled realistic user
simulators for developing and evaluating recommender systems (RSs). However,
existing LLM-based simulators for RSs face two major limitations: (1) static
and single-step prompt-based inference that leads to inaccurate and incomplete
user profile construction; (2) unrealistic and single-round
recommendation-feedback interaction pattern that fails to capture real-world
scenarios. To address these limitations, we propose DGDPO (Diagnostic-Guided
Dynamic Profile Optimization), a novel framework that constructs user profile
through a dynamic and iterative optimization process to enhance the simulation
fidelity. Specifically, DGDPO incorporates two core modules within each
optimization loop: firstly, a specialized LLM-based diagnostic module,
calibrated through our novel training strategy, accurately identifies specific
defects in the user profile. Subsequently, a generalized LLM-based treatment
module analyzes the diagnosed defect and generates targeted suggestions to
refine the profile. Furthermore, unlike existing LLM-based user simulators that
are limited to single-round interactions, we are the first to integrate DGDPO
with sequential recommenders, enabling a bidirectional evolution where user
profiles and recommendation strategies adapt to each other over multi-round
interactions. Extensive experiments conducted on three real-world datasets
demonstrate the effectiveness of our proposed framework.

</details>


### [310] [Multi-Granularity Distribution Modeling for Video Watch Time Prediction via Exponential-Gaussian Mixture Network](https://arxiv.org/abs/2508.12665)
*Xu Zhao,Ruibo Ma,Jiaqi Chen,Weiqi Zhao,Ping Yang,Yao Hu*

Main category: cs.IR

TL;DR: 짧은 동영상 플랫폼의 시청 시간 예측을 위해 시청시간이 꼬리(skewness)와 다양성(diversity)을 동시에 가지는 Exponential-Gaussian Mixture(EGM) 분포를 따른다고 가정하고, 이를 신경망으로 파라미터화한 Exponential-Gaussian Mixture Network(EGMN)를 제안한다. 공개 데이터셋과 Xiaohongshu 앱의 온라인 A/B 테스트에서 기존 방법보다 성능이 우수함을 보였다.


<details>
  <summary>Details</summary>
Motivation: 산업 데이터 분석에서 관찰된 두 가지 분포적 문제 — (1) 빠르게 넘기는 경우의 집중으로 인한 거시적(코어스) 왜도(skewness), (2) 사용자-영상 상호작용의 다양한 패턴으로 인한 미시적(fine-grained) 다양성 — 을 동시에 설명할 수 있는 모델 필요성.

Method: 시청시간을 지수분포(빠른 스킵을 모델링)와 가우시안분포(다양한 시청 패턴을 모델링)의 혼합인 EGM 분포로 가정. EGM의 파라미터를 예측하는 EGMN은(1) 히든 표현 인코더와(2) 혼합 파라미터 생성기로 구성되어 분포 매칭을 학습한다.

Result: 오프라인 공개 데이터셋 실험과 Xiaohongshu의 온라인 A/B 테스트에서 기존 최첨단 기법 대비 우수한 분포 적합성과 예측 성능을 보였으며, coarse-to-fine 수준에서의 적합 능력이 특히 뛰어남을 보고함.

Conclusion: EGM 분포 가정과 이를 파라미터화하는 EGMN은 짧은 동영상 시청시간의 다층적 분포 특성을 효과적으로 포착하여 예측 개선과 실제 서비스 지표 향상에 기여한다.

Abstract: Accurate watch time prediction is crucial for enhancing user engagement in
streaming short-video platforms, although it is challenged by complex
distribution characteristics across multi-granularity levels. Through
systematic analysis of real-world industrial data, we uncover two critical
challenges in watch time prediction from a distribution aspect: (1)
coarse-grained skewness induced by a significant concentration of quick-skips1,
(2) fine-grained diversity arising from various user-video interaction
patterns. Consequently, we assume that the watch time follows the
Exponential-Gaussian Mixture (EGM) distribution, where the exponential and
Gaussian components respectively characterize the skewness and diversity.
Accordingly, an Exponential-Gaussian Mixture Network (EGMN) is proposed for the
parameterization of EGM distribution, which consists of two key modules: a
hidden representation encoder and a mixture parameter generator. We conducted
extensive offline experiments on public datasets and online A/B tests on the
industrial short-video feeding scenario of Xiaohongshu App to validate the
superiority of EGMN compared with existing state-of-the-art methods.
Remarkably, comprehensive experimental results have proven that EGMN exhibits
excellent distribution fitting ability across coarse-to-fine-grained levels. We
open source related code on Github: https://github.com/BestActionNow/EGMN.

</details>


### [311] [Asymmetric Diffusion Recommendation Model](https://arxiv.org/abs/2508.12706)
*Yongchun Zhu,Guanyu Jiang,Jingwu Chen,Feng Zhang,Xiao Yang,Zuotao Liu*

Main category: cs.IR

TL;DR: 제안된 AsymDiffRec는 추천 시스템의 이산적·결측 데이터 특성을 고려해 순방향(forward)은 결측(simulate missing features)을 생성하도록 일반화하고, 역방향(reverse)은 비대칭(latent) 공간에서 수행해 개인화 정보 손실을 줄이는 비대칭 확산 모델이다. 온라인 A/B에서 사용자 활성일 +0.131%, 앱 사용 시간 +0.166% 향상을 보였으며 Douyin Music에 실제 적용되었다.


<details>
  <summary>Details</summary>
Motivation: 기존 확산 기반 추천 모델은 연속 공간에서의 대칭 Gaussian 노이즈를 전제로 하나, 추천 샘플은 이산적이고 결측(feature-missing) 특성을 가지며 Gaussian 노이즈는 잠재표현의 개인화 정보를 훼손할 수 있다. 이러한 격차를 해소하기 위해 비대칭 확산 프로세스가 필요하다.

Method: (1) 일반화된 순방향 프로세스를 도입해 실제 추천 데이터의 결측(누락) 특성을 시뮬레이션한다. (2) 역방향 복원은 연속 공간이 아닌 비대칭 잠재특성 공간에서 수행한다. (3) 개인화 정보 보존을 위한 태스크-지향(task-oriented) 최적화 전략을 채택한다. 서빙 시 원시 결측 샘플을 노이즈 입력으로 보고 디노이징해 강건한 표현을 생성해 최종 예측에 사용한다. 기본 모델에 플러그인 가능하도록 설계되었다.

Result: Douyin Music 실제 서비스에 적용하여 온라인 A/B 테스트에서 사용자 활성일 +0.131%, 앱 사용 시간 +0.166% 향상. 오프라인 확장 실험에서도 성능 개선 확인.

Conclusion: 추천 특유의 이산·결측성을 반영한 비대칭 확산 설계는 개인화 정보 보존과 실서비스 성능 향상에 유효하다. 다만 개선 폭이 크지 않아 추가적인 분석(연산 비용, 지연, 세부 ablation, 일반화성 검증)이 필요하다.

Abstract: Recently, motivated by the outstanding achievements of diffusion models, the
diffusion process has been employed to strengthen representation learning in
recommendation systems. Most diffusion-based recommendation models typically
utilize standard Gaussian noise in symmetric forward and reverse processes in
continuous data space. Nevertheless, the samples derived from recommendation
systems inhabit a discrete data space, which is fundamentally different from
the continuous one. Moreover, Gaussian noise has the potential to corrupt
personalized information within latent representations. In this work, we
propose a novel and effective method, named Asymmetric Diffusion Recommendation
Model (AsymDiffRec), which learns forward and reverse processes in an
asymmetric manner. We define a generalized forward process that simulates the
missing features in real-world recommendation samples. The reverse process is
then performed in an asymmetric latent feature space. To preserve personalized
information within the latent representation, a task-oriented optimization
strategy is introduced. In the serving stage, the raw sample with missing
features is regarded as a noisy input to generate a denoising and robust
representation for the final prediction. By equipping base models with
AsymDiffRec, we conduct online A/B tests, achieving improvements of +0.131% and
+0.166% in terms of users' active days and app usage duration respectively.
Additionally, the extended offline experiments also demonstrate improvements.
AsymDiffRec has been implemented in the Douyin Music App.

</details>


### [312] [Deep Research: A Survey of Autonomous Research Agents](https://arxiv.org/abs/2508.12752)
*Wenlin Zhang,Xiaopeng Li,Yingyi Zhang,Pengyue Jia,Yichao Wang,Huifeng Guo,Yong Liu,Xiangyu Zhao*

Main category: cs.IR

TL;DR: 이 논문은 웹 근거 기반 '딥 리서치' 에이전트의 파이프라인(기획,질문 개발,웹 탐색,보고서 생성)을 체계적으로 정리하고 각 단계의 기술적 과제와 해결 방법을 분류한 서베이 논문이다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델(LLM)은 강력하지만 내부 지식 한계로 인해 최신·외부 정보에 근거한 신뢰 가능한 분석을 스스로 수행하기 어렵다. 이를 극복하기 위해 에이전트가 계획·검색·합성을 통해 웹 근거에 기반한 포괄적·충실한 리포트를 생성하는 '딥 리서치' 패러다임이 제안되었다.

Method: 딥 리서치 파이프라인을 네 단계(기획, 질문 개발, 웹 탐색, 보고서 생성)로 나누어 각 단계별 핵심 기술적 도전 과제와 대표적 방법들을 분류·분석한다. 또한 최적화 기법과 전용 벤치마크를 요약하고, 남은 연구 과제와 향후 방향을 논의한다.

Result: 각 단계에서 사용되는 방법론(예: 계획과 분해, 질의 생성, 검색·크롤링·랭킹, 증거 기반 합성 등)과 최적화 전략을 체계화했으며, 관련 벤치마크와 성능 측정 관점도 정리했다. 이를 통해 딥 리서치 에이전트 연구의 현황과 한계를 명료하게 제시한다.

Conclusion: 딥 리서치 에이전트는 LLM의 지식 한계를 보완하는 유망한 방향이지만 신뢰성·증거 정합성·효율성·안전성 등 해결해야 할 핵심 문제들이 남아 있다. 향후 연구는 신뢰도 평가, 증거 추적성, 비용·시간 최적화, 다중 모달·멀티에이전트 협업 등에 초점을 맞출 필요가 있다.

Abstract: The rapid advancement of large language models (LLMs) has driven the
development of agentic systems capable of autonomously performing complex
tasks. Despite their impressive capabilities, LLMs remain constrained by their
internal knowledge boundaries. To overcome these limitations, the paradigm of
deep research has been proposed, wherein agents actively engage in planning,
retrieval, and synthesis to generate comprehensive and faithful analytical
reports grounded in web-based evidence. In this survey, we provide a systematic
overview of the deep research pipeline, which comprises four core stages:
planning, question developing, web exploration, and report generation. For each
stage, we analyze the key technical challenges and categorize representative
methods developed to address them. Furthermore, we summarize recent advances in
optimization techniques and benchmarks tailored for deep research. Finally, we
discuss open challenges and promising research directions, aiming to chart a
roadmap toward building more capable and trustworthy deep research agents.

</details>


### [313] [Informfully Recommenders -- Reproducibility Framework for Diversity-aware Intra-session Recommendations](https://arxiv.org/abs/2508.13019)
*Lucien Heitz,Runze Li,Oana Inel,Abraham Bernstein*

Main category: cs.IR

TL;DR: Informfully Recommenders는 다양성(또는 규범적 목표)을 중심으로 한 재현가능한 추천 실험을 위한 Cornac 기반 확장으로, 데이터 전처리, 다양성 최적화 모델, 세션 내 재정렬, 다양성 평가 지표를 포함하는 엔드-투-엔드 파이프라인을 제공하며, 뉴스 도메인에서 오프라인 실험으로 기능을 입증한다.


<details>
  <summary>Details</summary>
Motivation: 추천 시스템 분야는 다양성 최적화와 같은 규범적 목표에 대한 관심이 커지고 있으나, 데이터 전처리·모델·사후 처리·평가 단계를 아우르는 규범 중심의 재현성 프레임워크가 부족하다. 이를 해결해 규범적 실험의 일관성과 비교 가능성을 높이려는 필요성이 있다.

Method: Cornac를 기반으로 확장 모듈을 개발하여 1) 데이터셋 전처리 도구, 2) 다양성 최적화 모델 구현, 3) 인트라세션(세션 내) 아이템 재정렬(re-ranking) 모듈, 4) 광범위한 다양성(다양도) 지표 집합을 통합한 엔드-투-엔드 파이프라인을 제공한다. 사용자는 이 구성요소들을 조합해 규범적·다목적 다양성 실험을 수행할 수 있다.

Result: 뉴스 도메인에서 광범위한 오프라인 실험을 통해 확장의 기능성과 실험 파이프라인의 적용 가능성을 입증했다(추상에는 정량적 성과 수치 미기재).

Conclusion: 규범적 재현성(framework)으로의 첫걸음으로서, 다양성 중심 설계를 위한 통합 도구를 제공하며 향후 비교·재현 가능한 연구를 촉진할 잠재력이 있다.

Abstract: Norm-aware recommender systems have gained increased attention, especially
for diversity optimization. The recommender systems community has
well-established experimentation pipelines that support reproducible
evaluations by facilitating models' benchmarking and comparisons against
state-of-the-art methods. However, to the best of our knowledge, there is
currently no reproducibility framework to support thorough norm-driven
experimentation at the pre-processing, in-processing, post-processing, and
evaluation stages of the recommender pipeline. To address this gap, we present
Informfully Recommenders, a first step towards a normative reproducibility
framework that focuses on diversity-aware design built on Cornac. Our extension
provides an end-to-end solution for implementing and experimenting with
normative and general-purpose diverse recommender systems that cover 1) dataset
pre-processing, 2) diversity-optimized models, 3) dedicated intrasession item
re-ranking, and 4) an extensive set of diversity metrics. We demonstrate the
capabilities of our extension through an extensive offline experiment in the
news domain.

</details>


### [314] [D-RDW: Diversity-Driven Random Walks for News Recommender Systems](https://arxiv.org/abs/2508.13035)
*Runze Li,Lucien Heitz,Oana Inel,Abraham Bernstein*

Main category: cs.IR

TL;DR: D-RDW는 편집자가 지정한 기사 특성 분포를 따르는 다양성 중심의 랜덤워크 기반 경량 추천·재정렬 기법으로, 정서와 정치당 언급 다양성 측면에서 SOTA 신경망 모델보다 우수하고 계산 비용이 적다.


<details>
  <summary>Details</summary>
Motivation: 뉴스 추천은 개인화와 함께 편향·에코챔버 문제를 낳아 사회적 가치(균형성, 다양한 관점)를 보장하는 ‘사회적 추천’ 수단이 필요하다. 기존 신경망 접근은 다양성 제어·투명성·계산 효율성에서 한계가 있다.

Method: 기본 무작위 도보(random walk) 알고리즘에 목표 분포(target distribution)를 도입해 노드(뉴스 기사) 방문 확률을 조정하는 재랭킹 기법을 제안한다. 목표 분포는 기사 특성(예: 정서, 정당 언급)에 대해 편집자가 정의 가능하며, 이를 반영해 전통적 랜덤워크의 다양화 능력을 유지하면서 원하는 분포로 결과를 맞춘다. 경량 설계로 계산 비용을 낮춤.

Result: 정서 및 정치당 언급 기반의 다양성 지표들에서 최첨단 신경망 모델들보다 성능이 더 좋았고(정량적 다양성 메트릭 개선), 계산 효율성 면에서도 우수함을 보였다.

Conclusion: D-RDW는 투명하고 제어 가능한 사회적 추천 수단으로서 실무 편집자가 가치·규범을 추천에 반영할 수 있게 하며, 성능과 효율성 면에서 경쟁력이 있다.

Abstract: This paper introduces Diversity-Driven RandomWalks (D-RDW), a lightweight
algorithm and re-ranking technique that generates diverse news recommendations.
D-RDW is a societal recommender, which combines the diversification
capabilities of the traditional random walk algorithms with customizable target
distributions of news article properties. In doing so, our model provides a
transparent approach for editors to incorporate norms and values into the
recommendation process. D-RDW shows enhanced performance across key diversity
metrics that consider the articles' sentiment and political party mentions when
compared to state-of-the-art neural models. Furthermore, D-RDW proves to be
more computationally efficient than existing approaches.

</details>


### [315] [Is This News Still Interesting to You?: Lifetime-aware Interest Matching for News Recommendation](https://arxiv.org/abs/2508.13064)
*Seongeun Ryu,Yunyong Ko,Sang-Wook Kim*

Main category: cs.IR

TL;DR: LIME는 뉴스 추천에서 클릭된 기사 연령과 주제·사용자별 기사 수명(유효 기간)을 동시에 모델링해 시간-민감한 관심 일치도를 높이는 방법이다.


<details>
  <summary>Details</summary>
Motivation: 기존 연구는 뉴스·사용자 표현을 정교화했으나, (C1) 클릭 뉴스의 연령으로부터 사용자의 관심 지속성(inertia)을 추정하는 문제와 (C2) 주제 및 사용자에 따라 다른 뉴스의 수명을 모델링하는 문제를 충분히 다루지 못했다.

Method: LIME 프레임워크는 세 가지 핵심 전략을 도입한다: (1) 사용자-주제별 수명 인지 연령 표현(User-Topic lifetime-aware age representation)으로 후보 뉴스의 상대적 연령을 인코딩, (2) 후보-인식 수명 어텐션(Candidate-aware lifetime attention)으로 시간에 정렬된 사용자 표현을 생성, (3) 신선도(유효성) 안내 관심 정제(Freshness-guided interest refinement)로 예측 시 유효한 후보 뉴스에 우선순위를 부여.

Result: 두 개의 실제 데이터셋에서 광범위한 SOTA 방법들을 일관되게 능가했으며, 제안된 전략들은 모델에 무관하게 추천 정확도를 크게 향상시켰다.

Conclusion: 시간적 속성(클릭 연령·주제·사용자별 수명)을 명시적으로 모델링함으로써 LIME은 뉴스 추천의 시간 민감성 문제를 효과적으로 해결하고, 실무적 적용을 위한 확장성 및 모델 무관성 장점을 가진다.

Abstract: Personalized news recommendation aims to deliver news articles aligned with
users' interests, serving as a key solution to alleviate the problem of
information overload on online news platforms. While prior work has improved
interest matching through refined representations of news and users, the
following time-related challenges remain underexplored: (C1) leveraging the age
of clicked news to infer users' interest persistence, and (C2) modeling the
varying lifetime of news across topics and users. To jointly address these
challenges, we propose a novel Lifetime-aware Interest Matching framework for
nEws recommendation, named LIME, which incorporates three key strategies: (1)
User-Topic lifetime-aware age representation to capture the relative age of
news with respect to a user-topic pair, (2) Candidate-aware lifetime attention
for generating temporally aligned user representation, and (3) Freshness-guided
interest refinement for prioritizing valid candidate news at prediction time.
Extensive experiments on two real-world datasets demonstrate that LIME
consistently outperforms a wide range of state-of-the-art news recommendation
methods, and its model agnostic strategies significantly improve recommendation
accuracy.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [316] [Sparse Attention across Multiple-context KV Cache](https://arxiv.org/abs/2508.11661)
*Ziyi Cao,Qingyi Si,Jingbin Zhang,Bingquan Liu*

Main category: cs.LG

TL;DR: SamKV는 RAG(검색 보조 생성) 환경의 다중-문맥 KV 캐시에 대해 교차 문맥 정보를 고려한 희소화와 국지적 재계산을 결합하여 시퀀스 길이를 15%로 압축하면서 정확도 손실 없이 추론 처리량을 크게 향상시킨 방법이다.


<details>
  <summary>Details</summary>
Motivation: 긴 시퀀스 추론의 비용 문제를 해결하려고 과거 KV 캐시 재사용과 희소 어텐션을 통해 처리량을 개선하려는 시도가 있었으나, 기존 기법들은 인과적 단일 문맥에만 적합하다. RAG에서는 각 검색 문서의 KV 캐시가 독립적으로 계산되어 교차-어텐션이 결여되므로 기존 희소화 방법이 무력하다. 이전 연구는 정확도 손실을 줄이기 위해 일부 재계산을 도입했지만 모든 KV를 유지해야 해 메모리 절감에 실패한다.

Method: SamKV는 한 문맥을 희소화할 때 다른 문맥들의 보완 정보를 고려하여 어떤 키-값을 유지할지 결정하고, 선택된 희소 정보를 국지적으로(해당 문맥 내부에서) 재계산한다. 이렇게 하면 다중 문맥 KV 캐시 간의 상호 영향(sharing)을 반영하면서 전체 KV를 계속 보관하지 않아도 된다.

Result: 제안법은 전체 재계산(full-recomputation) 기준선과 비교해 정확도 저하 없이 시퀀스 길이를 약 15%로 압축했고, 멀티-문맥 RAG 시나리오에서 처리량을 크게 향상시켰다.

Conclusion: SamKV는 다중-문맥 KV 캐시에 대한 최초의 어텐션 희소화 탐색으로, 메모리와 계산을 크게 줄이면서 정확도를 유지한다. RAG 기반 장문 추론에서 실용적인 성능-효율 균형을 제시한다.

Abstract: Large language models face significant cost challenges in long-sequence
inference. To address this, reusing historical Key-Value (KV) Cache for
improved inference efficiency has become a mainstream approach. Recent advances
further enhance throughput by sparse attention mechanisms to select the most
relevant KV Cache, thereby reducing sequence length. However, such techniques
are limited to single-context scenarios, where historical KV Cache is computed
sequentially with causal-attention dependencies. In retrieval-augmented
generation (RAG) scenarios, where retrieved documents as context are unknown
beforehand, each document's KV Cache is computed and stored independently
(termed multiple-context KV Cache), lacking cross-attention between contexts.
This renders existing methods ineffective. Although prior work partially
recomputes multiple-context KV Cache to mitigate accuracy loss from missing
cross-attention, it requires retaining all KV Cache throughout, failing to
reduce memory overhead. This paper presents SamKV, the first exploration of
attention sparsification for multiple-context KV Cache. Specifically, SamKV
takes into account the complementary information of other contexts when
sparsifying one context, and then locally recomputes the sparsified
information. Experiments demonstrate that our method compresses sequence length
to 15% without accuracy degradation compared with full-recompuation baselines,
significantly boosting throughput in multi-context RAG scenarios.

</details>


### [317] [Assessing Representation Stability for Transformer Models](https://arxiv.org/abs/2508.11667)
*Bryan E. Tuck,Rakesh M. Verma*

Main category: cs.LG

TL;DR: Representation Stability(RS)는 중요 단어를 마스킹할 때 임베딩 변화 민감도를 측정해 적대적 문장을 탐지하는 모델-불가지론적 프레임워크이다. 단어 중요도를 기반으로 상위 k개를 마스킹하고, 임베딩 변동 패턴을 BiLSTM으로 분류해 3개 데이터셋·3종 공격·2개 모델에서 88% 이상의 탐지 정확도를 보였다.


<details>
  <summary>Details</summary>
Motivation: Transformer 기반 모델이 텍스트 적대적 공격에 취약하고, 기존 방어법은 특정 공격에 특화되거나 비용이 큰 모델 재학습을 요구한다. 따라서 재학습 없이 범용적으로 동작하는 효율적인 탐지 방법이 필요하다.

Method: 단어 중요도를 그라디언트·어텐션·무작위 등으로 정렬한 뒤 상위 k개 단어를 마스킹하고 임베딩의 민감도(변화량)를 측정한다. 이렇게 얻은 시퀀스 특성들을 BiLSTM 감지기로 처리하여 입력 문장이 적대적 변형인지 판별한다. 탐지 품질 평가는 NDCG로 수행하여 어떤 중요도 랭킹이 교란 단어 식별에 우수한지 확인했다.

Result: 마스킹 민감도는 자연스러운 중요 단어보다 적대적 교란 단어에서 더 크게 나타났고, RS는 전반적으로 88% 이상의 탐지 정확도를 달성했다. 그라디언트 기반 랭킹이 어텐션·무작위보다 NDCG가 높았고, 단어 수준 공격의 경우 식별 품질과 탐지 성능이 상관관계가 있었다. 또한 미학습(재학습 없음) 상태에서 다른 데이터셋·공격·모델에 잘 일반화했고, 계산 비용 측면에서도 경쟁력 있었다.

Conclusion: RS는 모델-불가지론적이고 재학습이 필요 없는 실용적 탐지법으로, 중요 단어 마스킹에 대한 임베딩 안정성 차이를 이용해 적대적 예제를 효과적으로 식별한다. 다만 랭킹 품질과 마스킹 전략에 민감할 수 있으며, 적응형 공격이나 문장 수준(구문적 변경) 교란에 대한 추가 평가가 필요하다.

Abstract: Adversarial text attacks remain a persistent threat to transformer models,
yet existing defenses are typically attack-specific or require costly model
retraining. We introduce Representation Stability (RS), a model-agnostic
detection framework that identifies adversarial examples by measuring how
embedding representations change when important words are masked. RS first
ranks words using importance heuristics, then measures embedding sensitivity to
masking top-k critical words, and processes the resulting patterns with a
BiLSTM detector. Experiments show that adversarially perturbed words exhibit
disproportionately high masking sensitivity compared to naturally important
words. Across three datasets, three attack types, and two victim models, RS
achieves over 88% detection accuracy and demonstrates competitive performance
compared to existing state-of-the-art methods, often at lower computational
cost. Using Normalized Discounted Cumulative Gain (NDCG) to measure
perturbation identification quality, we reveal that gradient-based ranking
outperforms attention and random selection approaches, with identification
quality correlating with detection performance for word-level attacks. RS also
generalizes well to unseen datasets, attacks, and models without retraining,
providing a practical solution for adversarial text detection.

</details>


### [318] [Collaborative Learning-Enhanced Lightweight Models for Predicting Arterial Blood Pressure Waveform in a Large-scale Perioperative Dataset](https://arxiv.org/abs/2508.11669)
*Wentao Li,Yonghu He,Kun Gao,Qing Liu,Yali Zheng*

Main category: cs.LG

TL;DR: 경량화된 딥러닝 모델 sInvResUNet와 지식증류 기반 협력학습 KDCL_sInvResUNet를 제안해 임베디드 장치에서 실시간(10초 출력당 8.49 ms)으로 비침습적 ABP 파형 재구성을 달성. 0.89M 파라미터, 0.02 GFLOPS로 효율적이며, 대규모(2,154명, 1,257,141 세그먼트) 주제 독립 검증에서 MAE 10.06 mmHg, Pearson 0.88을 보였음. 그러나 인구학적·심혈관 상태별 성능 편차가 커 일반화에는 한계가 존재.


<details>
  <summary>Details</summary>
Motivation: 비침습적 연속 동맥혈압(ABP) 모니터링은 중환자·수술 관리에 필수적이지만, 기존 딥러닝 모델들은 정확도 또는 계산 비용 중 하나를 희생해 임베디드 실시간 적용에 제약이 있음. 따라서 경량·저연산 모델로 실시간 재구성과 넓은 환자군에서의 적용 가능성을 개선하려는 목적.

Method: 역치축의 잔차유닛을 결합한 경량 sInvResUNet 구조와 지식증류 기반의 협력학습(KDCL)을 도입. 모델 크기는 0.89M 파라미터, 연산량 0.02 GFLOPS로 축소. 대규모, 이질적 perioperative 데이터(2,154명, 1,257,141 세그먼트)를 사용해 주제 독립 검증 진행.

Result: 임베디드 장치에서 10초 ABP 출력 기준 추론시간 8.49 ms 달성. 전체 성능은 MAE 10.06 mmHg, Pearson 상관 0.88으로 대형 모델과 비슷하거나 다소 우수. 다만 연령·성별·심혈관 질환 등 하위집단 간 성능 변동이 큼.

Conclusion: 제안한 경량 모델은 임베디드 환경에서 실시간·비침습적 ABP 모니터링 가능성을 보여주나, 임상 수준의 보편적 일반화에는 한계가 있으며 인구학적·질환별 편향 문제 해결과 추가 검증(전향적·다기관)이 필요함.

Abstract: Noninvasive arterial blood pressure (ABP) monitoring is essential for patient
management in critical care and perioperative settings, providing continuous
assessment of cardiovascular hemodynamics with minimal risks. Numerous deep
learning models have developed to reconstruct ABP waveform from noninvasively
acquired physiological signals such as electrocardiogram and
photoplethysmogram. However, limited research has addressed the issue of model
performance and computational load for deployment on embedded systems. The
study introduces a lightweight sInvResUNet, along with a collaborative learning
scheme named KDCL_sInvResUNet. With only 0.89 million parameters and a
computational load of 0.02 GFLOPS, real-time ABP estimation was successfully
achieved on embedded devices with an inference time of just 8.49 milliseconds
for a 10-second output. We performed subject-independent validation in a
large-scale and heterogeneous perioperative dataset containing 1,257,141 data
segments from 2,154 patients, with a wide BP range (41-257 mmHg for SBP, and
31-234 mmHg for DBP). The proposed KDCL_sInvResUNet achieved lightly better
performance compared to large models, with a mean absolute error of 10.06 mmHg
and mean Pearson correlation of 0.88 in tracking ABP changes. Despite these
promising results, all deep learning models showed significant performance
variations across different demographic and cardiovascular conditions,
highlighting their limited ability to generalize across such a broad and
diverse population. This study lays a foundation work for real-time,
unobtrusive ABP monitoring in real-world perioperative settings, providing
baseline for future advancements in this area.

</details>


### [319] [Contrastive Regularization over LoRA for Multimodal Biomedical Image Incremental Learning](https://arxiv.org/abs/2508.11673)
*Haojie Zhang,Yixiong Liang,Hulin Kuang,Lihui Cen,Zhe Qu,Yigang Cen,Min Zeng,Shichao Kan*

Main category: cs.LG

TL;DR: MBIIL(다중 모달 바이오의료 이미지 점진학습)을 위해, 사전학습된 LVLM은 고정하고 모달리티별 LoRA 모듈을 점진적으로 적응시키며 대조적 정칙화(Contrastive Regularization)를 더해 모달내 지식 공유와 모달간 차별화를 유도하는 MSLoRA-CR을 제안. 기존 별도 모델 학습이나 일반 점진학습(LoRA 미세조정)보다 전체 성능에서 1.88% 향상 보고.


<details>
  <summary>Details</summary>
Motivation: 다양한 바이오의료 영상 모달리티와 과제를 다루려면 각 모달마다 별도 모델을 두면 추론 비용이 커짐. 기존 점진학습은 단일 모달 내 과제 확장에 초점을 맞춰 다중 모달을 아우르는 점진적 학습(MBIIL)에 한계가 있음.

Method: 사전학습된 대형 비전-언어 모델(LVLM)을 고정하고, 각 모달/과제마다 모달 특이적(Modality-Specific) LoRA 모듈을 추가로 학습. 학습 중 대조적 정칙화(Contrastive Regularization)를 도입해 모달 내 유사도는 강화하고 모달 간 표현은 분리되게 함.

Result: 바이오의료 영상 점진학습 실험에서, MSLoRA-CR이 각 모달별 별도 모델 학습(SOTA)과 일반 점진학습(LoRA 미세조정)을 능가. 전체 성능에서 약 1.88% 절대 향상, 계산 효율성 유지.

Conclusion: 모달별 LoRA와 대조적 정칙화를 결합한 점진학습 방식은 이전 지식 보존과 모달 간 지식 전이를 균형 있게 달성하여 MBIIL 문제에 효과적이며 실험적으로 유의미한 성능 향상을 보임.

Abstract: Multimodal Biomedical Image Incremental Learning (MBIIL) is essential for
handling diverse tasks and modalities in the biomedical domain, as training
separate models for each modality or task significantly increases inference
costs. Existing incremental learning methods focus on task expansion within a
single modality, whereas MBIIL seeks to train a unified model incrementally
across modalities. The MBIIL faces two challenges: I) How to preserve
previously learned knowledge during incremental updates? II) How to effectively
leverage knowledge acquired from existing modalities to support new modalities?
To address these challenges, we propose MSLoRA-CR, a method that fine-tunes
Modality-Specific LoRA modules while incorporating Contrastive Regularization
to enhance intra-modality knowledge sharing and promote inter-modality
knowledge differentiation. Our approach builds upon a large vision-language
model (LVLM), keeping the pretrained model frozen while incrementally adapting
new LoRA modules for each modality or task. Experiments on the incremental
learning of biomedical images demonstrate that MSLoRA-CR outperforms both the
state-of-the-art (SOTA) approach of training separate models for each modality
and the general incremental learning method (incrementally fine-tuning LoRA).
Specifically, MSLoRA-CR achieves a 1.88% improvement in overall performance
compared to unconstrained incremental learning methods while maintaining
computational efficiency. Our code is publicly available at
https://github.com/VentusAislant/MSLoRA_CR.

</details>


### [320] [Lifelong Learner: Discovering Versatile Neural Solvers for Vehicle Routing Problems](https://arxiv.org/abs/2508.11679)
*Shaodi Feng,Zhuoyi Lin,Jianan Zhou,Cong Zhang,Jingwen Li,Kuan-Wen Chen,Senthilnath Jayavelu,Yew-Soon Ong*

Main category: cs.LG

TL;DR: Lifelong Transformer-based neural solver that incrementally learns to solve VRPs across varying contexts using inter-context self-attention and a dynamic context scheduler with cross-context experience replay; shows superior empirical performance on synthetic and benchmark instances (up to 18k).


<details>
  <summary>Details</summary>
Motivation: Existing neural VRP solvers are often trained in narrow, simplified settings (e.g., Euclidean distances, fixed problem size), which limits their applicability to diverse real-world scenarios. The paper aims to increase versatility and continual adaptability across different VRP contexts.

Method: Proposes a Lifelong Learner (LL) with a Transformer backbone. Introduces inter-context self-attention to transfer knowledge from prior VRP contexts to new ones. Adds a Dynamic Context Scheduler (DCS) that employs cross-context experience replay to revisit and retain policies for previous contexts, enabling incremental learning.

Result: On synthetic and benchmark datasets with problem sizes up to 18k, the LL achieves more effective policies than competing neural solvers and attains the best performance on most tested VRP variants.

Conclusion: The lifelong learning framework improves generalization and adaptability of neural VRP solvers across diverse contexts; empirical results validate its effectiveness, suggesting it as a promising direction for versatile, real-world VRP applications.

Abstract: Deep learning has been extensively explored to solve vehicle routing problems
(VRPs), which yields a range of data-driven neural solvers with promising
outcomes. However, most neural solvers are trained to tackle VRP instances in a
relatively monotonous context, e.g., simplifying VRPs by using Euclidean
distance between nodes and adhering to a single problem size, which harms their
off-the-shelf application in different scenarios. To enhance their versatility,
this paper presents a novel lifelong learning framework that incrementally
trains a neural solver to manage VRPs in distinct contexts. Specifically, we
propose a lifelong learner (LL), exploiting a Transformer network as the
backbone, to solve a series of VRPs. The inter-context self-attention mechanism
is proposed within LL to transfer the knowledge obtained from solving preceding
VRPs into the succeeding ones. On top of that, we develop a dynamic context
scheduler (DCS), employing the cross-context experience replay to further
facilitate LL looking back on the attained policies of solving preceding VRPs.
Extensive results on synthetic and benchmark instances (problem sizes up to
18k) show that our LL is capable of discovering effective policies for tackling
generic VRPs in varying contexts, which outperforms other neural solvers and
achieves the best performance for most VRPs.

</details>


### [321] [FedUHD: Unsupervised Federated Learning using Hyperdimensional Computing](https://arxiv.org/abs/2508.12021)
*You Hak Lee,Xiaofan Yu,Quanling Zhao,Flavio Ponzina,Tajana Rosing*

Main category: cs.LG

TL;DR: FedUHD는 하이퍼디멘셔널 컴퓨팅(HDC)을 기반으로 하는 최초의 비지도 연합학습(UFL) 프레임워크로, 엣지 장치의 비IID 데이터·연산·통신 제약·통신잡음 문제를 경량·강건하게 해결한다. 클라이언트 측의 kNN 기반 클러스터 하이퍼벡터 제거와 서버 측의 가중 HDC 집계를 도입해 성능과 효율을 동시에 개선한다.


<details>
  <summary>Details</summary>
Motivation: UFL은 레이블 없는 분산 학습을 가능케하지만, 실제 적용 시 비IID 데이터, 엣지의 계산·통신 비용, 통신 잡음에 취약하다는 문제를 가진다. 기존 연구는 주로 NN에 의존해 연산·통신 오버헤드와 잡음 민감성 문제를 야기한다.

Method: FedUHD는 HDC를 사용해 모델 크기·연산을 크게 줄이고 잡음에 대한 내성을 높인다. 클라이언트에서는 kNN 기반 클러스터 하이퍼벡터 제거로 비IID로 인한 해로운 아웃라이어를 제거하고, 서버에서는 클라이언트별 데이터 불균형을 보정하는 가중 HDC 집계를 수행한다. 이로써 로컬 학습·전송 오버헤드를 낮추고 글로벌 모델의 대표성을 개선한다.

Result: 실험에서 FedUHD는 훈련 속도에서 최대 173.6×, 에너지 효율에서 최대 612.7× 향상, 통신 비용은 최대 271× 감소시키며, 평균 정확도는 기존 NN 기반 UFL 대비 15.50% 포인트 향상, 다양한 잡음 환경에서도 우수한 강건성을 보였다.

Conclusion: HDC 기반 FedUHD는 엣지 환경에서 효율적이고 강건한 대안으로서 NN 기반 UFL보다 계산·통신 비용을 크게 낮추면서도 성능을 향상시킨다. 향후 다른 태스크·이론적 분석·확장된 집계 전략 연구가 유망하다.

Abstract: Unsupervised federated learning (UFL) has gained attention as a
privacy-preserving, decentralized machine learning approach that eliminates the
need for labor-intensive data labeling. However, UFL faces several challenges
in practical applications: (1) non-independent and identically distributed
(non-iid) data distribution across devices, (2) expensive computational and
communication costs at the edge, and (3) vulnerability to communication noise.
Previous UFL approaches have relied on deep neural networks (NN), which
introduce substantial overhead in both computation and communication. In this
paper, we propose FedUHD, the first UFL framework based on Hyperdimensional
Computing (HDC). HDC is a brain-inspired computing scheme with lightweight
training and inference operations, much smaller model size, and robustness to
communication noise. FedUHD introduces two novel HDC-based designs to improve
UFL performance. On the client side, a kNN-based cluster hypervector removal
method addresses non-iid data samples by eliminating detrimental outliers. On
the server side, a weighted HDC aggregation technique balances the non-iid data
distribution across clients. Our experiments demonstrate that FedUHD achieves
up to 173.6x and 612.7x better speedup and energy efficiency, respectively, in
training, up to 271x lower communication cost, and 15.50% higher accuracy on
average across diverse settings, along with superior robustness to various
types of noise compared to state-of-the-art NN-based UFL approaches.

</details>


### [322] [Comparative Analysis of Time Series Foundation Models for Demographic Forecasting: Enhancing Predictive Accuracy in US Population Dynamics](https://arxiv.org/abs/2508.11680)
*Aditya Akella,Jonathan Farah*

Main category: cs.LG

TL;DR: TimesFM(시계열 파운데이션 모델)를 사용해 미국 6개 주의 인구구성 변화를 예측한 연구. TimesFM은 LSTM, ARIMA, 선형회귀 대비 86.67%의 테스트 케이스에서 MSE가 가장 낮았고, 특히 기록이 희박한 소수민족 집단에서 강점을 보임.


<details>
  <summary>Details</summary>
Motivation: 글로벌화·경제·지정학·환경적 요인으로 인구구조가 빠르게 변하며 정책 수립에 정확한 인구 예측이 필요함. 소수 집단처럼 데이터가 적은 경우에도 안정적인 예측이 가능한 모델을 찾는 것이 목적.

Method: 미국 인구조사국과 FRED 데이터를 사용해 TimesFM을 적용하고, LSTM·ARIMA·선형회귀와 비교. 6개 주에 대해 여러 인구 하위집단을 대상으로 실험을 수행하여 MSE를 주요 성능지표로 사용.

Result: TimesFM이 전반적으로 가장 낮은 MSE를 보였으며(테스트 케이스의 86.67%), 소수민족 등 과거 데이터가 부족한 그룹에서 특히 성능 우수.

Conclusion: 사전학습된 시계열 파운데이션 모델이 태스크별 대규모 미세조정 없이도 인구 통계 예측 성능을 개선할 수 있어 정책적 활용 가능성이 큼.

Abstract: Demographic shifts, influenced by globalization, economic conditions,
geopolitical events, and environmental factors, pose significant challenges for
policymakers and researchers. Accurate demographic forecasting is essential for
informed decision-making in areas such as urban planning, healthcare, and
economic policy. This study explores the application of time series foundation
models to predict demographic changes in the United States using datasets from
the U.S. Census Bureau and Federal Reserve Economic Data (FRED). We evaluate
the performance of the Time Series Foundation Model (TimesFM) against
traditional baselines including Long Short-Term Memory (LSTM) networks,
Autoregressive Integrated Moving Average (ARIMA), and Linear Regression. Our
experiments across six demographically diverse states demonstrate that TimesFM
achieves the lowest Mean Squared Error (MSE) in 86.67% of test cases, with
particularly strong performance on minority populations with sparse historical
data. These findings highlight the potential of pre-trained foundation models
to enhance demographic analysis and inform proactive policy interventions
without requiring extensive task-specific fine-tuning.

</details>


### [323] [From Heuristics to Data: Quantifying Site Planning Layout Indicators with Deep Learning and Multi-Modal Data](https://arxiv.org/abs/2508.11723)
*Qian Cao,Jielin Chen,Junchao Zhao,Rudi Stouffs*

Main category: cs.LG

TL;DR: Proposes a data-driven Site Planning Layout Indicator (SPLI) system integrating multi-source spatial data and deep learning (RGNN/GNN) to quantify urban site layouts across five dimensions: building function hierarchy, spatial organization patterns, functional diversity, accessibility to services, and land-use intensity.


<details>
  <summary>Details</summary>
Motivation: Site planning traditionally depends on expert judgment and single-source data, lacking systematic, quantifiable measures for multifunctional urban layouts. The paper aims to create a standardized, data-driven framework to generate structured spatial information for analytics, inference, and retrieval.

Method: Integrates heterogeneous spatial data (OSM, POI, building morphology, land use, satellite imagery). Defines five indicator dimensions: hierarchical building function classification; seven-pattern spatial organization metrics; functional diversity (Functional Ratio, Simpson Index); accessibility metrics combining facilities and transport networks; and land-use intensity (FAR, BCR). Uses RGNN/GNN and deep learning to fill data gaps and improve classification accuracy.

Result: Experiments demonstrate improved functional classification accuracy and provide standardized, multimodal spatial outputs that enable automated urban spatial analytics. The SPLI quantifies previously qualitative assessments and captures multiple layout aspects for downstream applications.

Conclusion: SPLI offers a scalable, data-driven standard for quantifying site layouts, merging empirical knowledge with multi-source data and deep learning to support planners, researchers, and automated analytics. Further validation across diverse urban contexts and more transparent model/evaluation details would strengthen adoption.

Abstract: The spatial layout of urban sites shapes land-use efficiency and spatial
organization. Traditional site planning often relies on experiential judgment
and single-source data, limiting systematic quantification of multifunctional
layouts. We propose a Site Planning Layout Indicator (SPLI) system, a
data-driven framework integrating empirical knowledge with heterogeneous
multi-source data to produce structured urban spatial information. The SPLI
supports multimodal spatial data systems for analytics, inference, and
retrieval by combining OpenStreetMap (OSM), Points of Interest (POI), building
morphology, land use, and satellite imagery. It extends conventional metrics
through five dimensions: (1) Hierarchical Building Function Classification,
refining empirical systems into clear hierarchies; (2) Spatial Organization,
quantifying seven layout patterns (e.g., symmetrical, concentric,
axial-oriented); (3) Functional Diversity, transforming qualitative assessments
into measurable indicators using Functional Ratio (FR) and Simpson Index (SI);
(4) Accessibility to Essential Services, integrating facility distribution and
transport networks for comprehensive accessibility metrics; and (5) Land Use
Intensity, using Floor Area Ratio (FAR) and Building Coverage Ratio (BCR) to
assess utilization efficiency. Data gaps are addressed through deep learning,
including Relational Graph Neural Networks (RGNN) and Graph Neural Networks
(GNN). Experiments show the SPLI improves functional classification accuracy
and provides a standardized basis for automated, data-driven urban spatial
analytics.

</details>


### [324] [Fed-DPRoC:Communication-Efficient Differentially Private and Robust Federated Learning](https://arxiv.org/abs/2508.12978)
*Yue Xia,Tayyebeh Jahani-Nezhad,Rawad Bitar*

Main category: cs.LG

TL;DR: 새로운 연합학습 프레임워크 Fed-DPRoC(구체 구현 RobAJoL)를 제안하여, 차분프라이버시(DP), 비잔틴 공격 견고성, 통신 효율성을 동시에 달성한다. JL 변환을 이용한 압축과 강인한 평균화(robust averaging)를 결합해 이론적 보장과 실험적 성능 향상을 보인다.


<details>
  <summary>Details</summary>
Motivation: 연합학습에서 개인 정보 보호(차분프라이버시), 악의적(비잔틴) 클라이언트에 대한 견고성, 그리고 통신 비용 절감은 모두 실용적 운영을 위해 필수적이지만, 이들 요구사항을 동시에 만족시키는 방법은 부족하다. 특히 DP로 인한 노이즈와 압축으로 인한 왜곡이 견고한 집계 규칙의 성능을 훼손할 수 있다.

Method: 'robust-compatible compression' 개념을 도입하여 DP로 보호된 업데이트를 압축하면서도 집계기의 견고성을 유지할 수 있음을 보인다. 이를 RobAJoL로 구현했으며, Johnson–Lindenstrauss(JL) 랜덤 투영을 압축 수단으로 사용하고 robust averaging(예: 좌표별 중앙값/절단 평균 또는 다른 견고한 집계기)과 결합한다. 이론적으로 JL 변환이 robust averaging과 호환됨을 보이고, DP 보장과 견고성 유지, 통신 절감 효과를 증명한다.

Result: 이론적 근거(호환성 증명, 견고성 및 DP 보장)와 함께 CIFAR-10 및 Fashion-MNIST에서의 실험을 통해 RobAJoL이 다양한 비잔틴 공격 환경에서 기존 방법들에 비해 견고성과 성능(utility)이 우수함을 보였다.

Conclusion: RobAJoL은 DP, 비잔틴 견고성, 통신 효율성을 실용적으로 결합한 유망한 접근법이다. 다만 DP-압축 순서, 공격 모델, 대규모/실제 배포 시의 확장성·하이퍼파라미터 민감도 등 추가 검증이 필요하다.

Abstract: We propose Fed-DPRoC, a novel federated learning framework that
simultaneously ensures differential privacy (DP), Byzantine robustness, and
communication efficiency. We introduce the concept of robust-compatible
compression, which enables users to compress DP-protected updates while
maintaining the robustness of the aggregation rule. We instantiate our
framework as RobAJoL, combining the Johnson-Lindenstrauss (JL) transform for
compression with robust averaging for robust aggregation. We theoretically
prove the compatibility of JL transform with robust averaging and show that
RobAJoL preserves robustness guarantees, ensures DP, and reduces communication
cost. Experiments on CIFAR-10 and Fashion MNIST validate our theoretical claims
and demonstrate that RobAJoL outperforms existing methods in terms of
robustness and utility under different Byzantine attacks.

</details>


### [325] [Causal Structure Learning in Hawkes Processes with Complex Latent Confounder Networks](https://arxiv.org/abs/2508.11727)
*Songyao Jin,Biwei Huang*

Main category: cs.LG

TL;DR: 연속시간 다변량 Hawkes 과정을 시간 간격을 축소한 이산시간 표현으로 연결하여, 잠재(sub)과정과 인과영향을 식별할 수 있는 필요·충분조건을 제시한다. 이 조건에 근거한 경로(path)-기반 반복 알고리즘으로 알려지지 않은 잠재과정을 점진적으로 발견하고 인과구조를 복원하며, 합성·실세계 실험에서 유효함을 보인다.


<details>
  <summary>Details</summary>
Motivation: 실세계는 종종 일부 서브과정만 관측되며, 관측되지 않은 잠재과정이 있으면 Hawkes 프로세스의 인과적 구조 추정이 어려워진다. 이를 해결하기 위해 잠재요인의 식별 가능성 조건과 이를 실무적으로 적용하는 알고리즘이 필요하다.

Method: (1) 연속시간 이벤트 열을 시간 간격을 0으로 수렴시키면서 이산시간 모델로 근사할 수 있음을 보임. (2) 이 근사를 이용하여 잠재 서브과정 및 인과영향(그래프)의 식별을 위한 필요·충분조건(경로 기반)을 도출. (3) 도출된 조건을 가이드로 삼아, 인과관계 추정과 잠재과정 발견을 번갈아 수행하는 2단계 반복 알고리즘을 제안.

Result: 이론적으로 경로 기반 조건이 식별 가능성을 보장하며, 합성 데이터와 실세계 데이터 실험에서 제안 방법이 잠재과정이 존재할 때에도 인과구조를 효과적으로 복원함을 확인.

Conclusion: 잠재과정 존재 하에서도 특정 경로조건을 만족하면 Hawkes 프로세스의 인과구조와 잠재요인을 식별할 수 있으며, 실용적 반복 알고리즘이 이를 구현한다. 이 접근은 부분관측 환경에서 인과발견의 이론적·실무적 진전을 제시한다.

Abstract: Multivariate Hawkes process provides a powerful framework for modeling
temporal dependencies and event-driven interactions in complex systems. While
existing methods primarily focus on uncovering causal structures among observed
subprocesses, real-world systems are often only partially observed, with latent
subprocesses posing significant challenges. In this paper, we show that
continuous-time event sequences can be represented by a discrete-time model as
the time interval shrinks, and we leverage this insight to establish necessary
and sufficient conditions for identifying latent subprocesses and the causal
influences. Accordingly, we propose a two-phase iterative algorithm that
alternates between inferring causal relationships among discovered subprocesses
and uncovering new latent subprocesses, guided by path-based conditions that
guarantee identifiability. Experiments on both synthetic and real-world
datasets show that our method effectively recovers causal structures despite
the presence of latent subprocesses.

</details>


### [326] [BRIEF: BRain-Inspired network connection search with Extensive temporal feature Fusion enhances disease classification](https://arxiv.org/abs/2508.11732)
*Xiangxiang Cui,Min Zhao,Dongmei Zhi,Shile Qi,Vince D Calhoun,Jing Sui*

Main category: cs.LG

TL;DR: fMRI 기반 정신질환 분류를 위해 4종의 시간적 표현(TC, FNC, dFNC, MsDE)을 인코더로 사용하고, 수정된 Q-러닝 기반 신경망 연결 탐색(NCS)으로 인코더 내부 구조를 자동 최적화한 뒤 Transformer로 멀티-피처를 융합하는 BRIEF 프레임워크를 제안함. SZ와 ASD 분류에서 기존 알고리즘 대비 AUC가 각각 91.5%±0.6와 78.4%±0.5로 향상됨.


<details>
  <summary>Details</summary>
Motivation: 기존 fMRI 분류는 네트워크 아키텍처 결정이 경험에 의존하고, 서로 다른 특징 공간의 융합이 단순 연결(concatenation)에 머물러 상호 학습을 활용하지 못함. 뇌의 학습·결정 메커니즘을 모사해 구조 탐색과 상호 피처 학습을 결합하려는 동기.

Method: TC, 정적/동적 FNC, 다중스케일 MsDE로 4개 인코더 구성. 각 인코더 내에서 신경망 연결 탐색(NCS)을 MDP로 정식화하고 수정된 Q-러닝으로 동적으로 최적화하여 고수준 피처 추출. 추출된 피처는 Transformer로 융합해 안정적/시간가변적 연결과 멀티스케일 의존성 반영. 해석성을 위한 어텐션 모듈 포함.

Result: SZ(n=1100)에서 AUC 91.5%±0.6, ASD(n=1550)에서 78.4%±0.5로 보고하며, 21개 최신 기법 대비 2.2%~12.1%의 유의미한 향상 주장.

Conclusion: 뇌 영감을 받은 강화학습 기반 구조 탐색과 Transformer 기반 멀티피처 융합을 결합한 첫 시도로서, fMRI 기반 정신질환 바이오마커 탐지에 유망함.

Abstract: Existing deep learning models for functional MRI-based classification have
limitations in network architecture determination (relying on experience) and
feature space fusion (mostly simple concatenation, lacking mutual learning).
Inspired by the human brain's mechanism of updating neural connections through
learning and decision-making, we proposed a novel BRain-Inspired feature Fusion
(BRIEF) framework, which is able to optimize network architecture automatically
by incorporating an improved neural network connection search (NCS) strategy
and a Transformer-based multi-feature fusion module. Specifically, we first
extracted 4 types of fMRI temporal representations, i.e., time series (TCs),
static/dynamic functional connection (FNC/dFNC), and multi-scale dispersion
entropy (MsDE), to construct four encoders. Within each encoder, we employed a
modified Q-learning to dynamically optimize the NCS to extract high-level
feature vectors, where the NCS is formulated as a Markov Decision Process.
Then, all feature vectors were fused via a Transformer, leveraging both
stable/time-varying connections and multi-scale dependencies across different
brain regions to achieve the final classification. Additionally, an attention
module was embedded to improve interpretability. The classification performance
of our proposed BRIEF was compared with 21 state-of-the-art models by
discriminating two mental disorders from healthy controls: schizophrenia (SZ,
n=1100) and autism spectrum disorder (ASD, n=1550). BRIEF demonstrated
significant improvements of 2.2% to 12.1% compared to 21 algorithms, reaching
an AUC of 91.5% - 0.6% for SZ and 78.4% - 0.5% for ASD, respectively. This is
the first attempt to incorporate a brain-inspired, reinforcement learning
strategy to optimize fMRI-based mental disorder classification, showing
significant potential for identifying precise neuroimaging biomarkers.

</details>


### [327] [Scalable Geospatial Data Generation Using AlphaEarth Foundations Model](https://arxiv.org/abs/2508.11739)
*Luc Houriez,Sebastian Pilarski,Behzad Vahedi,Ali Ahmadalipour,Teo Honda Scully,Nicholas Aflitto,David Andre,Caroline Jaffe,Martha Wedner,Rich Mazzola,Josh Jeffery,Ben Messinger,Sage McGinley-Smith,Sarah Russell*

Main category: cs.LG

TL;DR: AEF(AlphaEarth Foundations)를 입력 특징으로 사용해 LANDFIRE EVT(미국)를 캐나다로 확장하는 연구. 간단한 분류기(랜덤 포레스트, 로지스틱 회귀)로 EvtPhys(13개 클래스)에서 미국 검증 정확도 81%, 캐나다 73%를 달성.


<details>
  <summary>Details</summary>
Motivation: 고품질 지리공간 레이블 데이터는 중요하나 지역적으로 편중되어 있어 전지구적 적용이 어렵다. AEF는 전지구적이고 정보밀도가 높은 표현을 제공하므로 이를 활용해 지역적 레이블을 확장하려는 동기.

Method: AEF로부터 추출한 특징을 입력으로 사용하여 미국의 LANDFIRE EVT 레이블로 학습. 단순 분류기(Random Forest, Logistic Regression 등)를 훈련해 캐나다 지역에 레이블을 예측. 두 수준(EvtPhys: 13클래스, EvtGp: 80클래스)에서 평가.

Result: 정성적으로 EvtPhys 예측이 실제와 일치함. 정량적으로 EvtPhys 검증 정확도는 미국 81%, 캐나다 73%를 달성(한계점 존재).

Conclusion: AEF를 이용하면 복잡한 모델 없이도 지역 레이블을 다른 지리적 영역으로 확장할 수 있는 가능성을 보임. 다만 도메인 이동, 클래스 불균형, 레이블 품질 등 한계는 존재하며 추가 검증과 보완이 필요.

Abstract: High-quality labeled geospatial datasets are essential for extracting
insights and understanding our planet. Unfortunately, these datasets often do
not span the entire globe and are limited to certain geographic regions where
data was collected. Google DeepMind's recently released AlphaEarth Foundations
(AEF) provides an information-dense global geospatial representation designed
to serve as a useful input across a wide gamut of tasks. In this article we
propose and evaluate a methodology which leverages AEF to extend geospatial
labeled datasets beyond their initial geographic regions. We show that even
basic models like random forests or logistic regression can be used to
accomplish this task. We investigate a case study of extending LANDFIRE's
Existing Vegetation Type (EVT) dataset beyond the USA into Canada at two levels
of granularity: EvtPhys (13 classes) and EvtGp (80 classes). Qualitatively, for
EvtPhys, model predictions align with ground truth. Trained models achieve 81%
and 73% classification accuracy on EvtPhys validation sets in the USA and
Canada, despite discussed limitations.

</details>


### [328] [Fed-Meta-Align: A Similarity-Aware Aggregation and Personalization Pipeline for Federated TinyML on Heterogeneous Data](https://arxiv.org/abs/2508.11794)
*Hemanth Macharla,Mayukha Pal*

Main category: cs.LG

TL;DR: Fed-Meta-Align는 공용 데이터로 사전학습한 모델을 시리얼 메타초기화로 이질적 IoT 장치 분포에 적응시키고, 병렬 연합학습에서 지역 성능과 코사인 유사도를 기반으로 가중집계를 수행한 뒤 장치별 개인화하는 4단계 파이프라인이다. 전기·기계 고장 데이터에서 기존 개인화 FedAvg/FedProx 대비 최대 ~3–4% 향상을 보고한다.


<details>
  <summary>Details</summary>
Motivation: 리소스 제약이 심하고 데이터가 비IID인 IoT/TinyML 환경에서 실시간 고장 분류를 안정적으로 수행할 수 있는 강건한 모델 초기화와 집계 방법이 필요하다.

Method: (1) 공용 데이터로 기초 모델 사전학습; (2) 일부 IoT 장비에 대해 순차적(시리얼) 메타초기화로 이질성에 민감한 초기화 획득; (3) 병렬 연합학습 단계에서 로컬 성능과 코사인 유사도 두 기준으로 클라이언트 업데이트에 가중치를 부여하여 집계; (4) 최종적으로 각 장치에서 온디바이스 개인화로 전문가 모델 생성.

Result: 모든 장치 평균 테스트 정확도 91.27%를 달성, 전기 및 기계 고장 데이터셋에서 개인화 FedAvg와 FedProx 대비 각각 최대 3.87%와 3.37%의 개선을 보고.

Conclusion: 시퀀스형 초기화와 적응적 집계를 결합한 다단계 접근은 이질적 TinyML 네트워크에서 성능을 끌어올릴 가능성이 크지만, 계산·통신 비용, 개인정보·스케일 문제, 실험 세부설정(데이터크기·비IID도·통계적 유의성) 부족 등 추가 검증이 필요하다.

Abstract: Real-time fault classification in resource-constrained Internet of Things
(IoT) devices is critical for industrial safety, yet training robust models in
such heterogeneous environments remains a significant challenge. Standard
Federated Learning (FL) often fails in the presence of non-IID data, leading to
model divergence. This paper introduces Fed-Meta-Align, a novel four-phase
framework designed to overcome these limitations through a sophisticated
initialization and training pipeline. Our process begins by training a
foundational model on a general public dataset to establish a competent
starting point. This model then undergoes a serial meta-initialization phase,
where it sequentially trains on a subset of IOT Device data to learn a
heterogeneity-aware initialization that is already situated in a favorable
region of the loss landscape. This informed model is subsequently refined in a
parallel FL phase, which utilizes a dual-criterion aggregation mechanism that
weights for IOT devices updates based on both local performance and cosine
similarity alignment. Finally, an on-device personalization phase adapts the
converged global model into a specialized expert for each IOT Device.
Comprehensive experiments demonstrate that Fed-Meta-Align achieves an average
test accuracy of 91.27% across heterogeneous IOT devices, outperforming
personalized FedAvg and FedProx by up to 3.87% and 3.37% on electrical and
mechanical fault datasets, respectively. This multi-stage approach of sequenced
initialization and adaptive aggregation provides a robust pathway for deploying
high-performance intelligence on diverse TinyML networks.

</details>


### [329] [Uncalibrated Reasoning: GRPO Induces Overconfidence for Stochastic Outcomes](https://arxiv.org/abs/2508.11800)
*Michael Bereket,Jure Leskovec*

Main category: cs.LG

TL;DR: Paper compares RL methods for verifiable but stochastic domains (binary outcomes). Finds GRPO with group standard normalization produces overconfident probability predictions; PPO and RLOO produce well-calibrated models. Removing group normalization from GRPO fixes miscalibration and authors provide a theoretical explanation.


<details>
  <summary>Details</summary>
Motivation: To test whether RL techniques that improved performance in deterministic verifiable domains (e.g., math) also produce well-calibrated probability estimates in verifiable domains with stochastic outcomes (scientific/biological experiments).

Method: Empirical evaluation on synthetic datasets and real-world biological experiments, comparing Group Relative Policy Optimization (GRPO), Proximal Policy Optimization (PPO), and REINFORCE Leave-One-Out (RLOO). Investigated the role of group standard normalization in GRPO and performed theoretical analysis to explain observed calibration issues.

Result: GRPO with group normalization yields overconfident (miscalibrated) binary probability predictions. PPO and RLOO yield well-calibrated outputs. Removing group standard normalization in GRPO corrects the overconfidence. The paper offers a theoretical explanation linking normalization to calibration degradation.

Conclusion: Standard group normalization in GRPO should be avoided for stochastic binary-outcome tasks; with this fix, RL methods can be more reliably applied to reasoning tasks in non-deterministic scientific domains.

Abstract: Reinforcement learning (RL) has proven remarkably effective at improving the
accuracy of language models in verifiable and deterministic domains like
mathematics. Here, we examine if current RL methods are also effective at
optimizing language models in verifiable domains with stochastic outcomes, like
scientific experiments. Through applications to synthetic data and real-world
biological experiments, we demonstrate that Group Relative Policy Optimization
(GRPO) induces overconfident probability predictions for binary stochastic
outcomes, while Proximal Policy Optimization (PPO) and REINFORCE Leave-One-Out
(RLOO) yield well-calibrated models. We show that removing group standard
normalization in GRPO fixes its miscalibration and provide a theoretical
explanation for why normalization causes overconfidence. Our results provide
new evidence against the use of standard normalization in GRPO and help pave
the way for applications of RL for reasoning language models beyond
deterministic domains.

</details>


### [330] [FairTabGen: Unifying Counterfactual and Causal Fairness in Synthetic Tabular Data Generation](https://arxiv.org/abs/2508.11810)
*Nitish Nagesh,Salar Shakibhamedan,Mahdi Bagheri,Ziyu Wang,Nima TaheriNejad,Axel Jantsch,Amir M. Rahmani*

Main category: cs.LG

TL;DR: LLM 기반 프레임워크 FairTabGen을 제안해, 카운터팩추얼·인과 공정성 정의들을 생성·평가 파이프라인에 포함시키고 적은 데이터로도(20% 이하) 공정성(민주적 평형 등)과 통계적 유용성 유지에서 SOTA GAN/LLM 기법을 능가한다고 주장.


<details>
  <summary>Details</summary>
Motivation: 프라이버시·데이터 부족 환경에서 실제로 쓰이는 표 형식 데이터의 합성 시 데이터 유용성은 유지하면서 카운터팩추얼·인과 공정성을 보장하려는 요구.

Method: 대형 언어 모델(LLM)을 이용한 합성 데이터 생성 프레임워크(FairTabGen). 인컨텍스트 러닝, 프롬프트 정교화, 공정성 인식 데이터 큐레이션을 결합. 여러 공정성 정의(데모그래픽 평형, 경로 특이적 인과 효과 등)를 생성·평가 단계에 통합.

Result: 다양한 데이터셋에서 GAN/기존 LLM 기반 기법 대비 최대 약 10% 공정성 개선(민주적 평형·경로 특이적 인과 효과 기준)과 통계적 유용성 유지. 전체 데이터의 <20%만 사용해도 성능 달성 가능.

Conclusion: FairTabGen은 적은 데이터로도 실용적인 공정성·유용성 균형을 달성하는 실용적 접근법을 제시한다.

Abstract: Generating synthetic data is crucial in privacy-sensitive, data-scarce
settings, especially for tabular datasets widely used in real-world
applications. A key challenge is improving counterfactual and causal fairness,
while preserving high utility. We present FairTabGen, a fairness-aware large
language model-based framework for tabular synthetic data generation. We
integrate multiple fairness definitions including counterfactual and causal
fairness into both its generation and evaluation pipelines. We use in-context
learning, prompt refinement, and fairness-aware data curation to balance
fairness and utility. Across diverse datasets, our method outperforms
state-of-the-art GAN-based and LLM-based methods, achieving up to 10%
improvements on fairness metrics such as demographic parity and path-specific
causal effects while retaining statistical utility. Remarkably, it achieves
these gains using less than 20% of the original data, highlighting its
efficiency in low-data regimes. These results demonstrate a principled and
practical approach for generating fair and useful synthetic tabular data.

</details>


### [331] [Combinations of Fast Activation and Trigonometric Functions in Kolmogorov-Arnold Networks](https://arxiv.org/abs/2508.11876)
*Hoang-Thang Ta,Duy-Quy Thai,Phuong-Linh Tran-Thi*

Main category: cs.LG

TL;DR: KANs에 ReLU와 삼각함수 같은 고속 연산 함수들을 기저함수로 도입해 계산 효율성을 높이고, 성능은 유지하거나 개선할 수 있음을 보인 논문 요약.


<details>
  <summary>Details</summary>
Motivation: 기존 KANs는 B-스플라인, RBF 등 계산비용이 크거나 GPU에서 최적화되지 않은 다항 기반 함수들에 의존함. 더 빠른 연산을 제공하는 함수들을 도입해 학습 시간과 일반화 성능을 개선하려는 목적.

Method: Kolmogorov-Arnold Network 구조에 ReLU, sin, cos, arctan 등 빠르게 계산 가능한 활성화/기저함수를 조합하여 채택. 네트워크 구조를 변경해 이러한 함수들이 내부 표현을 생성하도록 설계하고, 기존 다항 기반 기저함수들과 비교 실험 수행.

Result: 제안된 함수 조합은 기존 B-스플라인/RBF 기반 KAN과 비교해 경쟁력 있는 성능(예: 오차, 정확도)을 유지하면서 학습 시간 단축 및 일반화 성능 개선 가능성을 보였음.

Conclusion: GPU에 친화적인 빠른 연산 함수를 KAN에 적용하면 실용적인 이점(학습 속도, 확장성)을 얻을 수 있으며, 향후 다양한 함수 조합과 최적화로 더 나은 성능이 기대됨.

Abstract: For years, many neural networks have been developed based on the
Kolmogorov-Arnold Representation Theorem (KART), which was created to address
Hilbert's 13th problem. Recently, relying on KART, Kolmogorov-Arnold Networks
(KANs) have attracted attention from the research community, stimulating the
use of polynomial functions such as B-splines and RBFs. However, these
functions are not fully supported by GPU devices and are still considered less
popular. In this paper, we propose the use of fast computational functions,
such as ReLU and trigonometric functions (e.g., ReLU, sin, cos, arctan), as
basis components in Kolmogorov-Arnold Networks (KANs). By integrating these
function combinations into the network structure, we aim to enhance
computational efficiency. Experimental results show that these combinations
maintain competitive performance while offering potential improvements in
training time and generalization.

</details>


### [332] [PCA- and SVM-Grad-CAM for Convolutional Neural Networks: Closed-form Jacobian Expression](https://arxiv.org/abs/2508.11880)
*Yuto Omae*

Main category: cs.LG

TL;DR: CNN에 PCA 및/또는 SVM 층을 결합한 경우에도 Grad-CAM 스타일의 시각화를 가능하게 하기 위해, 마지막 합성곱층부터 PCA/SVM 층으로의 닫힌형태(Jacobian)를 유도하여 ‘PCA-Grad-CAM’과 ‘SVM-Grad-CAM’을 제안하고 주요 데이터셋에서 시각화 결과를 제시함.


<details>
  <summary>Details</summary>
Motivation: 학습 샘플이 적을 때 PCA 차원축소층이나 SVM 분류층을 CNN에 결합하면 성능 향상에 도움이 되지만, 기존 Grad-CAM은 이러한 비표준(혹은 비미분성?) 층에 바로 적용할 수 없어 내부 작동을 설명하는 화이트박스 시각화가 어려움.

Method: 마지막 합성곱층에서 PCA 및/또는 SVM 층까지의 편미분으로 구성된 닫힌형태 Jacobian을 해석적으로 유도하여, 이 도함수를 이용해 PCA 특징벡터 및 SVM 분류층에 대한 주의영역(heatmap)을 계산하는 PCA-Grad-CAM 및 SVM-Grad-CAM을 정의.

Result: 논문은 정확한 닫힌형태 Jacobian을 제시하고, 제안기법을 여러 주요 데이터셋에 적용한 시각화 결과(heatmap)를 보여줌. (초록에는 수치적 성능향상 언급은 없음.)

Conclusion: PCA 및 SVM 층을 갖는 CNN에서도 Grad-CAM 계열의 시각화를 가능하게 하여 모델 해석성을 확장함.

Abstract: Convolutional Neural Networks (CNNs) are an effective approach for
classification tasks, particularly when the training dataset is large. Although
CNNs have long been considered a black-box classification method, they can be
used as a white-box method through visualization techniques such as Grad-CAM.
When training samples are limited, incorporating a Principal Component Analysis
(PCA) layer and/or a Support Vector Machine (SVM) classifier into a CNN can
effectively improve classification performance. However, traditional Grad-CAM
cannot be directly applied to PCA and/or SVM layers. It is important to
generate attention regions for PCA and/or SVM layers in CNNs to facilitate the
development of white-box methods. Therefore, we propose ``PCA-Grad-CAM'', a
method for visualizing attention regions in PCA feature vectors, and
``SVM-Grad-CAM'', a method for visualizing attention regions in an SVM
classifier layer. To complete our methods analytically, it is necessary to
solve the closed-form Jacobian consisting of partial derivatives from the last
convolutional layer to the PCA and/or SVM layers. In this paper, we present the
exact closed-form Jacobian and the visualization results of our methods applied
to several major datasets.

</details>


### [333] [ENA: Efficient N-dimensional Attention](https://arxiv.org/abs/2508.11921)
*Yibo Zhong*

Main category: cs.LG

TL;DR: ENA: 선형 순환(linear recurrence)과 타일형 고차원 슬라이딩 윈도우 어텐션(SWA)을 결합한 하이브리드 아키텍처로, 초장(ultra-long) 고차원(N-D) 데이터를 효율적으로 모델링한다. 스캐닝은 이득이 제한적이었고, 어텐션-하이브리드가 유망함.


<details>
  <summary>Details</summary>
Motivation: Transformer보다 더 효율적인 구조가 필요한 초장 고차원(1D→ND) 데이터 모델링. 기존 언어모델용 선형 순환 모델을 고차원으로 확장할 때 스캐닝 전략과 어텐션-하이브리드 설계의 중요성 탐구.

Method: (1) 스캐닝 대 어텐션-하이브리드 비교 실험, (2) 다양한 어텐션 유형 평가, (3) 타일형 고차원 슬라이딩 윈도우 어텐션(SWA)을 선택해 선형 순환과 결합한 ENA 설계 및 구현.

Result: 스캐닝은 제한적 이득만 제공했고, 어텐션-하이브리드가 성능/효율 양면에서 우수함. 타일형 고차원 SWA는 이론적 및 실무적 효율성을 보였으며, ENA가 여러 실험에서 효과적임을 보임.

Conclusion: 선형 순환은 전역 정보를 상태로 압축하고, SWA는 엄격한 지역 모델링을 수행하여 서로 보완함. 이 간단한 프레임워크(ENA)는 초장 고차원 데이터 모델링에 실용적인 해결책을 제시한다.

Abstract: Efficient modeling of long sequences of high-order data requires a more
efficient architecture than Transformer. In this paper, we investigate two key
aspects of extending linear recurrent models, especially those originally
designed for language modeling, to high-order data (1D to ND): scanning
strategies and attention-hybrid architectures. Empirical results suggest that
scanning provides limited benefits, while attention-hybrid models yield
promising results. Focusing on the latter, we further evaluate types of
attention and find that tiled high-order sliding window attention (SWA) is
efficient in both theory and practice. We term the resulting hybrid
architecture of linear recurrence and high-order SWA as Efficient N-dimensional
Attention (ENA). We then conduct several experiments to demonstrate its
effectiveness. The intuition behind ENA is that linear recurrence compresses
global information into a state, while SWA complements it by enforcing strict
local modeling. Together, they form a simple framework that offers a promising
and practical solution for ultra-long high-order data modeling.

</details>


### [334] [Scale-Disentangled spatiotemporal Modeling for Long-term Traffic Emission Forecasting](https://arxiv.org/abs/2508.11923)
*Yan Wu,Lihong Pei,Yukai Han,Yang Cao,Yu Kang,Yanlong Zhao*

Main category: cs.LG

TL;DR: 교통 배출량의 장기 예측에서 시공간적 다중스케일 얽힘이 누적오차를 초래한다는 문제를 해결하기 위해, Koopman 리프팅과 게이트 웨이브렛 분해를 이용한 이중 스트림 규모 분리 및 교차항 손실 기반 독립성 제약을 통해 스케일별 예측 가능성을 분리·융합하는 SDSTM 프레임워크를 제안한다. Xi'an 도로 데이터에서 SOTA 성능을 보였다.


<details>
  <summary>Details</summary>
Motivation: 교통 배출은 시공간적으로 다양한 시간·공간 스케일에 걸쳐 상호작용하며, 기존의 시공간 그래프 모델은 이 다중스케일 얽힘으로 인해 장기 추론 시 오차가 누적·증폭되는 한계가 있다. 스케일별 예측 가능성 차이를 활용해 이 얽힘을 분해하면 장기 예측 성능을 개선할 수 있다.

Method: (1) Koopman 리프팅을 통해 비선형 시공간 동역학을 무한차원 선형 공간으로 올려 예측가능성 경계 도출; (2) 게이트 기반 웨이브렛 분해로 다중스케일 특성(주파수 성분)을 이중 스트림으로 분해; (3) 교차항 손실(cross-term loss)에 기반한 이중스트림 독립성 제약과 동적 융합 메커니즘으로 상호간섭 억제 및 예측 정밀도 향상.

Result: Xi'an Second Ring Road 도로 수준 교통 배출 데이터셋에서 광범위한 실험을 수행해 기존 방법들보다 우수한 장기 예측 성능을 달성함.

Conclusion: 스케일 분리와 독립성 제약을 결합한 SDSTM은 다중스케일 얽힘으로 인한 누적오차를 완화시켜 장기 교통 배출 예측에서 효과적이며, 다른 시공간 시계열 문제로도 확장 가능성이 있다.

Abstract: Long-term traffic emission forecasting is crucial for the comprehensive
management of urban air pollution. Traditional forecasting methods typically
construct spatiotemporal graph models by mining spatiotemporal dependencies to
predict emissions. However, due to the multi-scale entanglement of traffic
emissions across time and space, these spatiotemporal graph modeling method
tend to suffer from cascading error amplification during long-term inference.
To address this issue, we propose a Scale-Disentangled Spatio-Temporal Modeling
(SDSTM) framework for long-term traffic emission forecasting. It leverages the
predictability differences across multiple scales to decompose and fuse
features at different scales, while constraining them to remain independent yet
complementary. Specifically, the model first introduces a dual-stream feature
decomposition strategy based on the Koopman lifting operator. It lifts the
scale-coupled spatiotemporal dynamical system into an infinite-dimensional
linear space via Koopman operator, and delineates the predictability boundary
using gated wavelet decomposition. Then a novel fusion mechanism is
constructed, incorporating a dual-stream independence constraint based on
cross-term loss to dynamically refine the dual-stream prediction results,
suppress mutual interference, and enhance the accuracy of long-term traffic
emission prediction. Extensive experiments conducted on a road-level traffic
emission dataset within Xi'an's Second Ring Road demonstrate that the proposed
model achieves state-of-the-art performance.

</details>


### [335] [An Improved Algorithm for Adversarial Linear Contextual Bandits via Reduction](https://arxiv.org/abs/2508.11931)
*Tim van Erven,Jack Mayo,Julia Olkhovskaya,Chen-Yu Wei*

Main category: cs.LG

TL;DR: 적응형 손실(adversarial loss) 환경에서 확률적(action set) 행동 집합을 갖는 선형 컨텍스추얼 밴딧 문제에 대해, 맥락 분포나 시뮬레이터 없이도 다항 시간 알고리즘으로 폴리(d)·√T(정확히 tilde{O}(mint{d^2√T, √(d^3T log K)}))의 후회(regret)를 달성한다는 결과. 시뮬레이터가 있으면 tilde{O}(d√L^*)까지 개선.


<details>
  <summary>Details</summary>
Motivation: 기존 연구(예: Liu et al. 2023)는 ‘액션 수에 의존하지 않는 다항(d)·√T 후회’를 다항 시간으로 얻을 수 있느냐는 미해결 문제를 남겼다. 특히 조합적(combinatorial) 액션 집합처럼 상태공간이 지수적으로 큰 경우에도 실용적·효율적인 알고리즘이 필요하다.

Method: 문제를 고정된 행동 집합을 갖는 misspecification-robust한 적대적(adversarial) 선형 밴딧 문제로 환원(reduction)한다. 이 환원을 바탕으로 맥락 분포나 컨텍스트 시뮬레이터 없이도 다항 시간 내에 정책을 실행하고 분석할 수 있는 알고리즘을 설계한다. 시뮬레이터가 주어질 경우에는 손실에 적응하는 성능 보정(즉 L^*에 대한 경계)을 추가로 적용.

Result: 주요 이론적 보장: 시뮬레이터 없이 tilde{O}(mint{d^2√T, √(d^3T log K)}) 후회와 poly(d,C,T) 시간 복잡도. 조합적 밴딧(액션 집합을 다항 개의 선형 제약으로 표현 가능)에서는 최초로 다항 시간에 poly(d)√T 후회 달성. 시뮬레이터가 있으면 tilde{O}(d√L^*)로 개선.

Conclusion: 액션 수나 지수적 표현 규모에 의존하지 않는(또는 훨씬 덜 의존하는) 효율적 알고리즘으로, Liu et al.의 개방 문제를 해소하고 조합적 밴딧에서 실질적 전진을 이룸. 다만 상수·로그 요인, d에 대한 다항 차수, 그리고 실제 구현에서의 상수 비용 등은 추가 실험·최적화가 필요하다.

Abstract: We present an efficient algorithm for linear contextual bandits with
adversarial losses and stochastic action sets. Our approach reduces this
setting to misspecification-robust adversarial linear bandits with fixed action
sets. Without knowledge of the context distribution or access to a context
simulator, the algorithm achieves $\tilde{O}(\min\{d^2\sqrt{T}, \sqrt{d^3T\log
K}\})$ regret and runs in $\text{poly}(d,C,T)$ time, where $d$ is the feature
dimension, $C$ is an upper bound on the number of linear constraints defining
the action set in each round, $K$ is an upper bound on the number of actions in
each round, and $T$ is number of rounds. This resolves the open question by Liu
et al. (2023) on whether one can obtain $\text{poly}(d)\sqrt{T}$ regret in
polynomial time independent of the number of actions. For the important class
of combinatorial bandits with adversarial losses and stochastic action sets
where the action sets can be described by a polynomial number of linear
constraints, our algorithm is the first to achieve $\text{poly}(d)\sqrt{T}$
regret in polynomial time, while no prior algorithm achieves even $o(T)$ regret
in polynomial time to our knowledge. When a simulator is available, the regret
bound can be improved to $\tilde{O}(d\sqrt{L^\star})$, where $L^\star$ is the
cumulative loss of the best policy.

</details>


### [336] [M3OOD: Automatic Selection of Multimodal OOD Detectors](https://arxiv.org/abs/2508.11936)
*Yuehan Qin,Li Li,Defu Cao,Tiankai Yang,Yue Zhao*

Main category: cs.LG

TL;DR: M3OOD는 멀티모달 환경에서 OOD(분포 이탈) 검출기 선택을 자동화하는 메타러닝 프레임워크다. 멀티모달 임베딩과 수작업 메타-피처를 결합해 데이터셋을 표현하고, 과거 벤치마크 상의 모델 성능으로부터 학습해 새 분포에 적합한 검출기를 추천한다. 12개 테스트 시나리오에서 10개 경쟁 기준선을 지속적으로 능가했다.


<details>
  <summary>Details</summary>
Motivation: 멀티모달 입력(비디오·오디오·센서 등)에서 OOD 강건성은 필수지만, 다양한 분포 변화에 대해 단일 검출기가 항상 최선이 아니다. OOD 검출은 본질적으로 비지도라서 새 데이터에서 모델 성능을 예측하거나 여러 모델을 일일이 비교하는 것이 어렵고 비용이 크다. 이를 해결하기 위해 과거 모델 행동을 활용해 신규 분포에 빠르게 적응할 방법이 필요하다.

Method: M3OOD는 (1) 멀티모달 임베딩과 수작업으로 설계한 메타-피처(분포적·교차모달 특성)를 통해 데이터셋을 표현하고, (2) 다양한 멀티모달 벤치마크에서 수집한 역사적 모델 성능을 메타-학습하여 새 데이터 분포에 대해 적절한 OOD 검출기를 추천한다. 최소한의 감독(레이블링)으로 빠르게 적응하도록 설계되었다.

Result: 실험에서 M3OOD는 12개 테스트 시나리오에서 10개의 경쟁 기준선들을 일관되게 앞섰으며, 추천 과정은 계산 오버헤드가 적었다.

Conclusion: 메타러닝 기반의 모델 선택으로 멀티모달 OOD 검출기의 자동 추천이 가능하며, 비용을 줄이면서 다양한 분포 변화에 적응할 수 있는 실용적인 접근법임을 보였다.

Abstract: Out-of-distribution (OOD) robustness is a critical challenge for modern
machine learning systems, particularly as they increasingly operate in
multimodal settings involving inputs like video, audio, and sensor data.
Currently, many OOD detection methods have been proposed, each with different
designs targeting various distribution shifts. A single OOD detector may not
prevail across all the scenarios; therefore, how can we automatically select an
ideal OOD detection model for different distribution shifts? Due to the
inherent unsupervised nature of the OOD detection task, it is difficult to
predict model performance and find a universally Best model. Also,
systematically comparing models on the new unseen data is costly or even
impractical. To address this challenge, we introduce M3OOD, a
meta-learning-based framework for OOD detector selection in multimodal
settings. Meta learning offers a solution by learning from historical model
behaviors, enabling rapid adaptation to new data distribution shifts with
minimal supervision. Our approach combines multimodal embeddings with
handcrafted meta-features that capture distributional and cross-modal
characteristics to represent datasets. By leveraging historical performance
across diverse multimodal benchmarks, M3OOD can recommend suitable detectors
for a new data distribution shift. Experimental evaluation demonstrates that
M3OOD consistently outperforms 10 competitive baselines across 12 test
scenarios with minimal computational overhead.

</details>


### [337] [Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware](https://arxiv.org/abs/2508.11940)
*Yuannuo Feng,Wenyong Zhou,Yuexi Lyu,Yixiang Zhang,Zhengwu Liu,Ngai Wong,Wang Kang*

Main category: cs.LG

TL;DR: 아날로그 CIM의 현실적 하드웨어 노이즈를 더 정교하게 반영해 학습-추론을 분리하는 확장된 STE 프레임워크로, 기존 노이즈-인지 학습보다 정확도·퍼플렉시티 개선 및 학습 속도·메모리 효율을 얻음.


<details>
  <summary>Details</summary>
Motivation: CIM은 에너지 효율을 크게 향상시키지만 하드웨어 유래의 복잡한 노이즈가 신경망 성능을 저하시켜 실제 배포가 어렵다. 기존의 노이즈-인지 학습은 미분 가능하고 이상화된 노이즈 모델에 의존해 현실적 변동을 충분히 반영하지 못함.

Method: 앞방향(Forward)에서는 실제 하드웨어에 근접한 고정밀·비미분 가능한 노이즈를 시뮬레이션하고, 역전파(Backward)는 STE 스타일의 근사 그래디언트를 사용해 계산을 분리한다. 이 분리는 계산 가능성과 최적화 안정성을 유지하면서 그래디언트의 방향성 정보를 보존하도록 이론적으로 분석함.

Result: 이미지 분류에서 최대 5.3% 정확도 향상, 텍스트 생성 퍼플렉시티 0.72 감소, 학습 시간 2.2× 속도 향상, 피크 메모리 사용 37.9% 감소 등 기존 노이즈-인지 방식 대비 유의한 개선을 보임.

Conclusion: 현실적이고 복잡한 CIM 노이즈 모델을 학습에 반영하면서도 계산 효율과 안정성을 확보한 실용적 방법을 제시해 아날로그 CIM 기반 모델의 배포 가능성을 높임.

Abstract: Analog Compute-In-Memory (CIM) architectures promise significant energy
efficiency gains for neural network inference, but suffer from complex
hardware-induced noise that poses major challenges for deployment. While
noise-aware training methods have been proposed to address this issue, they
typically rely on idealized and differentiable noise models that fail to
capture the full complexity of analog CIM hardware variations. Motivated by the
Straight-Through Estimator (STE) framework in quantization, we decouple forward
noise simulation from backward gradient computation, enabling noise-aware
training with more accurate but computationally intractable noise modeling in
analog CIM systems. We provide theoretical analysis demonstrating that our
approach preserves essential gradient directional information while maintaining
computational tractability and optimization stability. Extensive experiments
show that our extended STE framework achieves up to 5.3% accuracy improvement
on image classification, 0.72 perplexity reduction on text generation,
2.2$\times$ speedup in training time, and 37.9% lower peak memory usage
compared to standard noise-aware training methods.

</details>


### [338] [Learning Marked Temporal Point Process Explanations based on Counterfactual and Factual Reasoning](https://arxiv.org/abs/2508.11943)
*Sishun Liu,Ke Deng,Xiuzhen Zhang,Yan Wang*

Main category: cs.LG

TL;DR: 이 논문은 MTPP(마크된 시계열 점과정)에 대한 설명 가능성 문제를 다루며, 최소의 역사 이벤트 서브셋으로 원본 예측과 유사한 성능을 내는 합리적 설명을 제안한다. 단순 반사실/사실 설명 정의의 문제를 지적하고, 두 개념을 결합한 설명 정의를 도입한 뒤 CFF(Counterfactual and Factual Explainer for MTPP)라는 기법을 제안하여 이를 해결한다. 실험에서 설명 품질과 처리 효율성에서 기존 방법을 능가함을 보였다.


<details>
  <summary>Details</summary>
Motivation: MTPP 기반 신경망 모델은 의료·금융 등 중요한 분야에 사용되며, 모델 예측의 신뢰성 검증을 위해 어떤 과거 사건들이 예측에 결정적 영향을 미치는지 설명할 필요가 있다. 기존의 단순 반사실적 또는 사실적 설명 정의는 비합리적 설명을 초래할 수 있으므로, 설명의 최소성·합리성·유의성을 보장하는 새로운 정의와 방법이 필요하다.

Method: 논문은 반사실 설명과 사실 설명의 장점을 결합한 설명 정의를 제안하고, 이를 최적화하기 위한 Counterfactual and Factual Explainer (CFF)를 설계한다. CFF는 역사에서 최소한의 이벤트 서브셋을 선택하도록 학습/검색하는 알고리즘과, 선택된 서브셋의 반사실·사실적 영향(예측 일치도와 보완집합 대비 성능)을 평가하는 절차로 구성된다. 또한 합리적 설명을 보장하기 위한 여러 설계 기법(목적 함수, 제약 조건, 효율적 탐색 전략 등)을 적용한다.

Result: 제안된 CFF는 합리성·최소성 기준으로 기존 베이스라인들보다 우수한 설명을 제공했으며, 처리 효율성(속도, 계산 비용) 면에서도 개선을 보였다. 실험에서 선택된 서브셋으로 얻는 예측 정확도가 전체 이력 기반 예측과 거의 유사했고, 선택되지 않은 보완집합보다 더 설명력이 높음을 보였다.

Conclusion: 반사실·사실 설명을 결합한 새로운 설명 정의와 이를 최적화하는 CFF는 MTPP 모델의 설명 가능성을 향상시키며, 고위험 응용에서 모델 신뢰도 평가에 유용하다. 향후에는 더 복잡한 마크·상호작용이나 실시간 적용을 위한 확장 연구가 필요하다.

Abstract: Neural network-based Marked Temporal Point Process (MTPP) models have been
widely adopted to model event sequences in high-stakes applications, raising
concerns about the trustworthiness of outputs from these models. This study
focuses on Explanation for MTPP, aiming to identify the minimal and rational
explanation, that is, the minimum subset of events in history, based on which
the prediction accuracy of MTPP matches that based on full history to a great
extent and better than that based on the complement of the subset. This study
finds that directly defining Explanation for MTPP as counterfactual explanation
or factual explanation can result in irrational explanations. To address this
issue, we define Explanation for MTPP as a combination of counterfactual
explanation and factual explanation. This study proposes Counterfactual and
Factual Explainer for MTPP (CFF) to solve Explanation for MTPP with a series of
deliberately designed techniques. Experiments demonstrate the correctness and
superiority of CFF over baselines regarding explanation quality and processing
efficiency.

</details>


### [339] [Set-Valued Transformer Network for High-Emission Mobile Source Identification](https://arxiv.org/abs/2508.11976)
*Yunning Cao,Lihong Pei,Jian Guo,Yang Cao,Yu Kang,Yanlong Zhao*

Main category: cs.LG

TL;DR: 제안된 Set-Valued Transformer Network(SVTN)은 트랜스포머로 마이크로-주행 패턴의 시계열 유사도를 학습해 고차원 배출 데이터를 저차원 특징 공간으로 사상하고, 집합값(확률적) 식별 알고리즘으로 특징과 라벨의 관계를 모델링해 희소한 고배출 상태를 더 정확히 탐지한다. Hefei 2020 디젤 차량 데이터에서 기준 트랜스포머 대비 미검출률을 9.5% 낮춤.


<details>
  <summary>Details</summary>
Motivation: 현실 모니터링 데이터에서 고배출 상태 샘플은 정상 샘플에 비해 극히 적어 긴 꼬리(long-tailed) 분포를 보이며, 이는 판별적 특징 추출을 어렵게 하고 모델 학습을 방해한다. 또한 차량 배출 상태의 비선형성 및 관련 사전 지식의 부족이 모델 구축을 어렵게 함.

Method: 1) 트랜스포머를 사용해 마이크로-주행 조건 변화의 시간적 유사도를 측정하고 이를 기반으로 고차원 배출 데이터를 저차원 특징 공간으로 사상하는 매핑 규칙을 학습함. 2) 집합값(set-valued) 식별 알고리즘으로 생성된 특징 벡터와 라벨의 관계를 확률적으로 모델링하여 분류를 위한 정확한 거리/유사도 기준을 제공함.

Result: Hefei(합비)시 2020년 디젤 차량 모니터링 데이터에서 실험을 수행, 제안 방법은 트랜스포머 기반 베이스라인 대비 고배출 차량의 미검출률을 9.5% 감소시키며 검출 성능 개선을 입증함.

Conclusion: SVTN은 불균형(긴 꼬리) 데이터 환경에서 고배출 샘플의 판별적 특징을 보다 잘 학습해 탐지 정확도를 향상시키며, 도시 교통 배출원 규제에서 실용적 잠재력을 가짐. 다만 일반화성, 해석성, 추가 메트릭 검증이 필요함.

Abstract: Identifying high-emission vehicles is a crucial step in regulating urban
pollution levels and formulating traffic emission reduction strategies.
However, in practical monitoring data, the proportion of high-emission state
data is significantly lower compared to normal emission states. This
characteristic long-tailed distribution severely impedes the extraction of
discriminative features for emission state identification during data mining.
Furthermore, the highly nonlinear nature of vehicle emission states and the
lack of relevant prior knowledge also pose significant challenges to the
construction of identification models.To address the aforementioned issues, we
propose a Set-Valued Transformer Network (SVTN) to achieve comprehensive
learning of discriminative features from high-emission samples, thereby
enhancing detection accuracy. Specifically, this model first employs the
transformer to measure the temporal similarity of micro-trip condition
variations, thus constructing a mapping rule that projects the original
high-dimensional emission data into a low-dimensional feature space. Next, a
set-valued identification algorithm is used to probabilistically model the
relationship between the generated feature vectors and their labels, providing
an accurate metric criterion for the classification algorithm. To validate the
effectiveness of our proposed approach, we conducted extensive experiments on
the diesel vehicle monitoring data of Hefei city in 2020. The results
demonstrate that our method achieves a 9.5\% reduction in the missed detection
rate for high-emission vehicles compared to the transformer-based baseline,
highlighting its superior capability in accurately identifying high-emission
mobile pollution sources.

</details>


### [340] [Efficient Modular Learning through Naive LoRA Summation: Leveraging Orthogonality in High-Dimensional Models](https://arxiv.org/abs/2508.11985)
*Zhanhao Cao,Clement Truong,Andrew Lizarraga*

Main category: cs.LG

TL;DR: LoRA 어댑터를 도메인별로 독립 학습한 뒤 단순 덧셈(composition)으로 합치면, 추가 훈련 없이도 병합 데이터로 훈련한 모델과 비슷한 성능을 보이며, 서로의 ‘델타’(low-rank 행렬) 간 코사인 유사도가 성능 변화와 선형 상관관계를 가진다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어모델은 파라미터 수가 증가할수록 성능이 향상되지만 전체 재학습 비용이 크다. PEFT(파라미터 효율적 미세조정)인 LoRA는 파라미터 변화량을 저랭크 행렬 곱으로 저장하므로 모듈화·조합이 용이하다. 저자들은 서로 다른 도메인에서 독립 학습한 LoRA 모듈들이 근사적으로 직교(orthogonal)하다는 가설을 세우고, 단순 합산으로 모듈을 결합해도 충돌 없이 작동하는지 확인하고자 한다.

Method: GPT-2 Small(117M)에 LoRA(rank=4, alpha=64)를 적용해 수학·의학·금융 세 도메인용 어댑터를 독립 학습함. 학습된 LoRA 델타를 단순 덧셈으로 조합한 뒤 퍼플렉서티로 성능을 비교. 또한 조합 쌍들에 대해 LoRA 델타의 RMS 코사인 유사도와 퍼플렉서티 변화 간 상관관계를 측정.

Result: 수치 요약: Math+Medicine 조합은 merged-data 미세조정 대비 퍼플렉서티 -9.10% 개선(감소), Math+Finance는 +4.54% 악화, Finance+Medicine는 +27.56% 크게 악화. 전반적으로 LoRA 델타 간 RMS 코사인 유사도는 퍼플렉서티 변화와 양(positive)의 약선형 상관관계를 보임. 단순 합산은 추가 학습이 필요 없고 매우 빠르게 적용 가능하며 병합 학습과 유사한 성능을 달성할 때가 있음.

Conclusion: 도메인별로 독립 학습한 LoRA 모듈은 근사 직교성을 보일 수 있어 단순 덧셈으로 효율적으로 합성 가능하다. 그러나 모듈 간 유사성이 높으면 성능 간섭(negative transfer)이 발생하므로, 코사인 유사도 측정으로 충돌 가능성을 사전 진단할 수 있다. 이 접근은 빠르고 가벼운 조합을 제공하지만, 더 큰 모델·다양한 태스크·다중 조합에 대한 추가 검증이 필요하다.

Abstract: Recent advances in large language models are driven by scale, while
parameter-efficient fine-tuning (PEFT) enables updating only a small fraction
of parameters. Low-Rank Adaptation (LoRA) stores parameter deltas as the
product of two small matrices, which makes them natural building blocks that
can be composed. Motivated by the superposition principle, we hypothesize that
independently trained LoRA modules on disjoint domains are approximately
orthogonal and can be combined by simple addition. Using GPT-2 Small (117M)
with LoRA rank 4 and alpha=64, we train adapters for three QA domains (math,
medicine, finance). In pairwise tests, adding Math+Medicine adapters improves
perplexity by -9.10% relative to merged-data fine-tuning, while Math+Finance
and Finance+Medicine change by +4.54% and +27.56%, respectively. Across
combinations, the RMS cosine similarity between LoRA deltas correlates
positively and approximately linearly with the change in perplexity. Naive
summation requires no additional training, can be applied in seconds, and
achieves performance comparable to models trained on merged data, while
clarifying when interference appears in higher-order compositions.

</details>


### [341] [Universal Learning of Nonlinear Dynamics](https://arxiv.org/abs/2508.11990)
*Evan Dogariu,Anand Brahmbhatt,Elad Hazan*

Main category: cs.LG

TL;DR: Presents an algorithm using spectral filtering and online convex optimization to learn marginally stable unknown nonlinear dynamical systems; proves vanishing prediction error for systems with finitely many marginally stable modes and introduces an improved spectral-filtering algorithm for linear systems that handles asymmetry and noise.


<details>
  <summary>Details</summary>
Motivation: Learning dynamical systems that are marginally stable (have modes with unit-modulus eigenvalues) is challenging for existing system-identification and learning methods, especially under noise and asymmetry. The paper aims to provide algorithms with provable prediction guarantees for a broad class of nonlinear systems.

Method: Constructs a predictor mapping past observations to the next via a spectral representation of the system. Uses a novel spectral filtering algorithm for linear dynamical systems which incorporates past observations and noise correction, and analyzes the learning procedure via techniques from online convex optimization to obtain vanishing prediction error bounds.

Result: Shows provable vanishing prediction error for any nonlinear system with finitely many marginally stable modes. Derives learning rates governed by a new quantitative control-theoretic notion of learnability. Provides a generalized spectral filtering algorithm that supports asymmetric dynamics and explicit noise handling.

Conclusion: The work significantly generalizes prior spectral filtering approaches, yielding robust, provable learning for noisy and marginally stable systems; the spectral-filtering advance is of independent technical interest and has implications for system identification and control.

Abstract: We study the fundamental problem of learning a marginally stable unknown
nonlinear dynamical system. We describe an algorithm for this problem, based on
the technique of spectral filtering, which learns a mapping from past
observations to the next based on a spectral representation of the system.
Using techniques from online convex optimization, we prove vanishing prediction
error for any nonlinear dynamical system that has finitely many marginally
stable modes, with rates governed by a novel quantitative control-theoretic
notion of learnability. The main technical component of our method is a new
spectral filtering algorithm for linear dynamical systems, which incorporates
past observations and applies to general noisy and marginally stable systems.
This significantly generalizes the original spectral filtering algorithm to
both asymmetric dynamics as well as incorporating noise correction, and is of
independent interest.

</details>


### [342] [Fairness Regularization in Federated Learning](https://arxiv.org/abs/2508.12042)
*Zahra Kharaghani,Ali Dadras,Tommy Löfstedt*

Main category: cs.LG

TL;DR: 제안 논문은 클라이언트 성능의 편차를 줄이는 'performance equitable fairness'에 초점을 맞춰, 클라이언트 손실을 직접 정규화하는 공정성 기법들을 비교·연결하고, 새로운 그래디언트 분산 정규화 방법(FairGrad 약식 및 정확 변형)을 제시하여 이질적 데이터 환경에서 공정성과 전체 성능을 동시에 향상시킴을 보인다.


<details>
  <summary>Details</summary>
Motivation: 연합학습에서 클라이언트 간 데이터 이질성은 글로벌 모델에 불균형한 영향을 미쳐 일부 클라이언트 성능을 저하시킬 수 있다. 이에 따라 성능 격차(공정성)를 줄이는 방법이 필요하며, 특히 클라이언트 손실을 직접 정규화하는 기법들의 효과와 상호관계가 명확하지 않다.

Method: 성능 공정성(클라이언트별 성능 차 최소화)을 목표로 클라이언트 손실을 정규화하는 기존 방법들을 수집·분류하고 이들 사이의 이론적 관계를 분석. 또한 그래디언트 분산 정규화 접근법인 FairGrad의 근사 버전과 본 논문에서 제안한 정확한 변형(FairGrad*)을 도입하여 손실의 그래디언트 분산을 직접 제어함.

Result: 이론적 연결 고리를 제시하고, 이질적 데이터 설정에서 FairGrad(근사)와 FairGrad*(정확)가 공정성(클라이언트 간 성능 격차 감소)과 전체 모델 성능을 동시에 개선함을 실험적으로 입증함.

Conclusion: 클라이언트 손실 정규화, 특히 그래디언트 분산을 줄이는 방식은 연합학습에서 성능 공정성을 개선하는 효과적인 전략이며, 제안된 FairGrad 변형들이 이질적 환경에서 실용적 이점을 제공한다.

Abstract: Federated Learning (FL) has emerged as a vital paradigm in modern machine
learning that enables collaborative training across decentralized data sources
without exchanging raw data. This approach not only addresses privacy concerns
but also allows access to overall substantially larger and potentially more
diverse datasets, without the need for centralized storage or hardware
resources. However, heterogeneity in client data may cause certain clients to
have disproportionate impacts on the global model, leading to disparities in
the clients' performances. Fairness, therefore, becomes a crucial concern in FL
and can be addressed in various ways. However, the effectiveness of existing
fairness-aware methods, particularly in heterogeneous data settings, remains
unclear, and the relationships between different approaches are not well
understood. In this work, we focus on performance equitable fairness, which
aims to minimize differences in performance across clients. We restrict our
study to fairness-aware methods that explicitly regularize client losses,
evaluating both existing and newly proposed approaches. We identify and
theoretically explain connections between the investigated fairness methods,
and empirically show that FairGrad (approximate) and FairGrad* (exact) (two
variants of a gradient variance regularization method introduced here for
performance equitable fairness) improve both fairness and overall model
performance in heterogeneous data settings.

</details>


### [343] [VARAN: Variational Inference for Self-Supervised Speech Models Fine-Tuning on Downstream Tasks](https://arxiv.org/abs/2508.12061)
*Daria Diatlova,Nikita Balagansky,Alexander Varlamov,Egor Spirin*

Main category: cs.LG

TL;DR: VARAN은 입력별로 동적으로 레이어 집계를 조정하는 프레임워크로, 레이어별 특화 프로빙 헤드와 데이터 의존적 가중치를 사용해 self-supervised 음성 표현의 적응을 개선하며 ASR·SER 작업에서 특히 LoRA 미세조정과 함께 성능 향상을 보인다.


<details>
  <summary>Details</summary>
Motivation: 기존의 마지막 레이어 사용이나 고정 가중 합산 방식은 정보 병목과 모든 예제에 대해 동일한 정적 특징 가중치라는 한계를 가지며, 입력별로 서로 다른 레이어 정보가 유용할 수 있다는 문제를 해결하고자 함.

Method: 각 레이어에 특화된 프로빙 헤드를 두고, 입력에 따라 레이어별 출력을 가중합하는 데이터-의존적 가중치 메커니즘을 도입해 입력에 맞춰 동적으로 레이어를 조합한다. LoRA 기반 미세조정과의 결합을 강조함.

Result: ASR(자동음성인식) 및 SER(음성 감정 인식)에서 기존 집계 방식들을 능가하는 성능을 보고하며, 특히 LoRA와 함께 사용할 때 효과가 두드러짐.

Conclusion: 레이어별 정보를 보존하면서도 입력에 따라 유연하게 특징을 활용할 수 있어 self-supervised 음성 모델의 효율적 적응을 가능하게 한다.

Abstract: Conventional methods for aggregating layers in fine-tuned self-supervised
speech models, such as using the final layer or weighted sum, suffer from
information bottlenecks and static feature weighting for all dataset examples.
We propose VARAN, a framework that dynamically tailors layer aggregation to
individual inputs. By employing layer-specialized probing heads and
data-dependent weighting, VARAN adaptively prioritizes layer's features based
on input. Evaluations on automatic speech recognition and speech emotion
recognition tasks demonstrate VARAN's superior performance, particularly when
using the LoRA fine-tuning technique. The framework resolves the trade-off
between preserving layer-specific information and enabling flexible feature
utilization, advancing efficient adaptation of self-supervised speech
representations.

</details>


### [344] [Content Accuracy and Quality Aware Resource Allocation Based on LP-Guided DRL for ISAC-Driven AIGC Networks](https://arxiv.org/abs/2508.12079)
*Ningzhe Shi,Yiqing Zhou,Ling Liu,Jinglin Shi,Yihao Wu,Haiwei Shi,Hanxiao Yu*

Main category: cs.LG

TL;DR: ISAC 기반 AIGC 네트워크에서 인지 오차와 생성 모델 오차를 동시에 고려하는 새로운 서비스 품질 지표 CAQA를 제안하고, 이를 최대화하는 자원 할당 문제(CAQA-AIGC)를 LP로 유도한 DRL과 액션 필터를 결합한 LPDRL-F 알고리즘으로 효율적으로 해결한다. 제안법은 학습 수렴 속도와 AvgCAQA를 크게 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 기존 AIGC 연구는 정확한 입력을 전제로 CGQ만 고려하지만, ISAC 환경에서는 센싱 데이터의 부정확성과 생성 모델의 단계수(연산 자원)에 따른 생성 오차가 존재하여 이를 통합적으로 고려한 품질 평가와 자원 최적화가 필요하다.

Method: 콘텐츠 정확도와 품질을 함께 반영하는 CAQA 지표를 정의하고, 센싱·생성(계산)·통신의 3차원 자원 트레이드오프를 최대화하는 CAQA-AIGC 최적화 문제를 수립. 문제는 NP-하드이므로 선형계획(LP)로 유도한 해를 DRL 학습에 가이드로 쓰고, 액션 필터를 통해 3차원 해공간을 2차원으로 축소하는 LPDRL-F 알고리즘을 제안해 복잡도와 학습 성능을 개선.

Result: 시뮬레이션에서 LPDRL-F는 기존 DRL·확산모델 기반 방법보다 수렴 속도가 60% 이상 빨라지고, AvgCAQA를 14% 이상 향상. CGQ만 고려하는 기존 방식 대비 AvgCAQA를 50% 이상 개선.

Conclusion: LP 기반 가이드와 액션 필터 결합으로 ISAC-AIGC의 복잡한 자원 배분 문제를 실용적으로 해결 가능하며, 센싱·생성·통신 간 균형을 맞춘 자원 할당이 서비스 경험을 크게 향상시킨다.

Abstract: Integrated sensing and communication (ISAC) can enhance artificial
intelligence-generated content (AIGC) networks by providing efficient sensing
and transmission. Existing AIGC services usually assume that the accuracy of
the generated content can be ensured, given accurate input data and prompt,
thus only the content generation quality (CGQ) is concerned. However, it is not
applicable in ISAC-based AIGC networks, where content generation is based on
inaccurate sensed data. Moreover, the AIGC model itself introduces generation
errors, which depend on the number of generating steps (i.e., computing
resources). To assess the quality of experience of ISAC-based AIGC services, we
propose a content accuracy and quality aware service assessment metric (CAQA).
Since allocating more resources to sensing and generating improves content
accuracy but may reduce communication quality, and vice versa, this
sensing-generating (computing)-communication three-dimensional resource
tradeoff must be optimized to maximize the average CAQA (AvgCAQA) across all
users with AIGC (CAQA-AIGC). This problem is NP-hard, with a large solution
space that grows exponentially with users. To solve the CAQA-AIGC problem with
low complexity, a linear programming (LP) guided deep reinforcement learning
(DRL) algorithm with an action filter (LPDRL-F) is proposed. Through the
LP-guided approach and the action filter, LPDRL-F can transform the original
three-dimensional solution space to two dimensions, reducing complexity while
improving the learning performance of DRL. Simulations show that compared to
existing DRL and generative diffusion model algorithms without LP, LPDRL-F
converges faster by over 60% and finds better resource allocation solutions,
improving AvgCAQA by more than 14%. With LPDRL-F, CAQA-AIGC can achieve an
improvement in AvgCAQA of more than 50% compared to existing schemes focusing
solely on CGQ.

</details>


### [345] [Generative Medical Event Models Improve with Scale](https://arxiv.org/abs/2508.12104)
*Shane Waxler,Paul Blazek,Davis White,Daniel Sneider,Kevin Chung,Mani Nagarathnam,Patrick Williams,Hank Voeller,Karen Wong,Matthew Swanhorst,Sheng Zhang,Naoto Usuyama,Cliff Wong,Tristan Naumann,Hoifung Poon,Andrew Loza,Daniella Meeker,Seth Hain,Rahul Shah*

Main category: cs.LG

TL;DR: CoMET는 Epic Cosmos의 방대한 전자의무기록(약 1.15e11 이벤트, 1.51e11 토큰)로 사전학습한 디코더 전용 트랜스포머 기반 의료 이벤트 생성 파운데이션 모델로, 1B 매개변수까지의 스케일링 법칙을 제시하고 78개 실제 과제에서 감독학습 모델과 대등하거나 우수한 성능을 보였다.


<details>
  <summary>Details</summary>
Motivation: 개인화 의료를 대규모로 구현하려면 환자의 장기적 의료 이벤트 시퀀스에서 일반화 가능한 표현을 학습할 수 있는 파운데이션 모델이 필요하다. 기존 개별 과제별 감독학습 방식은 확장성과 일반화에서 한계가 있으므로, 대규모 의료 이벤트 데이터로 프리트레인된 생성 모델이 유망하다.

Method: Epic Cosmos(300M 환자, 1.63e10 진료건)에서 1.18e8 환자·1.15e11 이벤트(1.51e11 토큰)로 디코더 전용 트랜스포머(CoMET)들을 사전학습. 토큰/모델/연산량에 대한 스케일링법칙을 제시하고, 그에 따라 컴퓨트-최적화된 시리즈(최대 1B 파라미터)를 학습. 모델은 환자 이력을 조건으로 다음 의료 이벤트를 자기회귀적으로 생성함.

Result: CoMET는 78개의 실제 업무(진단 예측, 질병 예후, 의료 운영 등)에서 별도의 태스크별 파인튜닝·몇 샷 예시 없이도 대체로 태스크 특화 감독모델과 동등하거나 우수한 성능을 달성. 모델·프리트레인 규모가 증가할수록 성능이 일관되게 향상됨.

Conclusion: 대규모 의료 이벤트 생성형 파운데이션 모델이 임상 동역학을 효과적으로 포착하며, 임상 의사결정 지원·의료 운영 효율화·환자 결과 개선을 위한 확장 가능하고 일반화된 프레임워크가 될 수 있음을 보였다.

Abstract: Realizing personalized medicine at scale calls for methods that distill
insights from longitudinal patient journeys, which can be viewed as a sequence
of medical events. Foundation models pretrained on large-scale medical event
data represent a promising direction for scaling real-world evidence generation
and generalizing to diverse downstream tasks. Using Epic Cosmos, a dataset with
medical events from de-identified longitudinal health records for 16.3 billion
encounters over 300 million unique patient records from 310 health systems, we
introduce the Cosmos Medical Event Transformer ( CoMET) models, a family of
decoder-only transformer models pretrained on 118 million patients representing
115 billion discrete medical events (151 billion tokens). We present the
largest scaling-law study for medical event data, establishing a methodology
for pretraining and revealing power-law scaling relationships for compute,
tokens, and model size. Based on this, we pretrained a series of
compute-optimal models with up to 1 billion parameters. Conditioned on a
patient's real-world history, CoMET autoregressively generates the next medical
event, simulating patient health timelines. We studied 78 real-world tasks,
including diagnosis prediction, disease prognosis, and healthcare operations.
Remarkably for a foundation model with generic pretraining and simulation-based
inference, CoMET generally outperformed or matched task-specific supervised
models on these tasks, without requiring task-specific fine-tuning or few-shot
examples. CoMET's predictive power consistently improves as the model and
pretraining scale. Our results show that CoMET, a generative medical event
foundation model, can effectively capture complex clinical dynamics, providing
an extensible and generalizable framework to support clinical decision-making,
streamline healthcare operations, and improve patient outcomes.

</details>


### [346] [DynamixSFT: Dynamic Mixture Optimization of Instruction Tuning Collections](https://arxiv.org/abs/2508.12116)
*Haebin Shin,Lei Ji,Xiao Liu,Zhiwei Yu,Qi Chen,Yeyun Gong*

Main category: cs.LG

TL;DR: DynamixSFT는 instruction-tuning 데이터셋 혼합 비중을 동적으로 최적화하는 방법으로, 멀티암드 밴딧으로 문제를 정식화하고 Prior-scaled Boltzmann Exploration과 1-Step Look-ahead Reward를 사용해 샘플링 확률을 갱신하여 성능을 개선한다.


<details>
  <summary>Details</summary>
Motivation: 사후 학습(포스트 트레이닝) 단계에서 다양한 instruction-tuning 데이터셋이 계속 등장함에 따라 이들의 혼합 비중을 고정하거나 수동 조정하면 모델 성능·다양성·커버리지를 최적화하기 어려우며, 동적으로 데이터셋 중요도를 반영하는 자동화된 방법이 필요하다.

Method: 문제를 멀티암드 밴딧으로 모델링하고, Prior-scaled Boltzmann Exploration을 도입하여 갱신된 샘플링 분포를 원래 데이터 비율에 부드럽게 고정(anchoring)한다. 샘플링 확률은 경량화된 1-Step Look-ahead Reward로 업데이트되어 현재 모델 상태에서 각 데이터셋이 성능 향상에 기여하는 정도를 반영한다.

Result: Tulu-v2-mixture(16개 데이터셋)에 적용 시 10개 벤치마크 평균에서 최대 2.2% 성능 향상을 달성했으며, 적응적 동작을 보여주는 분석 및 시각화를 제공한다.

Conclusion: DynamixSFT는 데이터셋 혼합 비중을 자동으로 조정해 모델 성능을 소폭 향상시키고, Prior anchoring으로 데이터 다양성과 커버리지를 보존하는 실용적인 방법을 제시한다.

Abstract: As numerous instruction-tuning datasets continue to emerge during the
post-training stage, dynamically balancing and optimizing their mixtures has
become a critical challenge. To address this, we propose DynamixSFT, a dynamic
and automated method for instruction-tuning dataset mixture optimization. We
formulate the problem as a multi-armed bandit setup and introduce a
Prior-scaled Boltzmann Exploration that softly anchors the updated sampling
distribution to the original dataset proportions, thereby preserving the
inherent diversity and coverage of the collection. Sampling probabilities are
updated using a lightweight 1-Step Look-ahead Reward, reflecting how much the
dataset contributes to improving the model's performance at its current state.
When applied to the Tulu-v2-mixture collection comprising 16 instruction-tuning
datasets, DynamixSFT achieves up to a 2.2% performance improvement across 10
benchmarks. Furthermore, we provide a comprehensive analysis and visualizations
to offer deeper insights into the adaptive dynamics of our method.

</details>


### [347] [Time-Scale Coupling Between States and Parameters in Recurrent Neural Networks](https://arxiv.org/abs/2508.12121)
*Lorenzo Livi*

Main category: cs.LG

TL;DR: 게이트가 있는 RNN은 고정 학습률 하에서도 게이트가 은닉 상태 시간 스케일과 결합해 기울기 전파와 파라미터 업데이트를 조절함으로써 사실상 적응형 학습률·전처리기(preconditioner)를 구현한다.


<details>
  <summary>Details</summary>
Motivation: 게이트가 단지 메모리 유지에만 관여하는 것이 아니라 학습 과정(파라미터 공간에서의 경사 하강)에 미치는 영향 — 특히 고정된 전역 학습률 상황에서의 효과 — 을 정량화하여 게이트 기반 구조의 강건한 학습성능을 설명하려는 목적.

Method: leaky-integrator 및 게이트형 RNN의 정확한 야코비안(Jacobian)을 도출하고, 이를 바탕으로 1차 섭동(expansion)을 전개하여 스칼라·다차원 게이트가 어떻게 그래디언트 전파를 재구성하고 유효 스텝 크기와 이방성(anisotropy)을 도입하는지 수식적으로 명시.

Result: 게이트는 데이터-의존적 전처리기 역할을 하며(유효 학습률 조절, 모멘텀·스케줄과의 형식적 유사성, Adam류 적응메소드와의 유사행동), 수치 실험은 섭동해석이 유효하고 게이트 효과가 작지만 체계적으로 학습 역학을 바꾼다는 것을 확인.

Conclusion: 게이트는 은닉 상태 시간 상수와 파라미터 역학을 연결하는 메커니즘으로, 게이트형 아키텍처의 높은 학습 안정성·수렴성을 설명하는 통합된 동역학 관점을 제공하지만, 분석은 섭동(작은 보정) 가정과 대상 모델군에 제한된다.

Abstract: We study how gating mechanisms in recurrent neural networks (RNNs) implicitly
induce adaptive learning-rate behavior, even when training is carried out with
a fixed, global learning rate. This effect arises from the coupling between
state-space time scales--parametrized by the gates--and parameter-space
dynamics during gradient descent. By deriving exact Jacobians for
leaky-integrator and gated RNNs, we obtain a first-order expansion that makes
explicit how constant, scalar, and multi-dimensional gates reshape gradient
propagation, modulate effective step sizes, and introduce anisotropy in
parameter updates. These findings reveal that gates not only control memory
retention in the hidden states, but also act as data-driven preconditioners
that adapt optimization trajectories in parameter space. We further draw formal
analogies with learning-rate schedules, momentum, and adaptive methods such as
Adam, showing that these optimization behaviors emerge naturally from gating.
Numerical experiments confirm the validity of our perturbative analysis,
supporting the view that gate-induced corrections remain small while exerting
systematic effects on training dynamics. Overall, this work provides a unified
dynamical-systems perspective on how gating couples state evolution with
parameter updates, explaining why gated architectures achieve robust
trainability and stability in practice.

</details>


### [348] [DE-VAE: Revealing Uncertainty in Parametric and Inverse Projections with Variational Autoencoders using Differential Entropy](https://arxiv.org/abs/2508.12145)
*Frederik L. Dennig,Daniel A. Keim*

Main category: cs.LG

TL;DR: DE-VAE는 미지/분포 외 샘플에 대한 불확실성 추정을 위해 미분 엔트로피(DE)를 활용하는 불확실성 인지형 변분 오토인코더로, 2D 파라메트릭 및 역변환(합성) 가능한 임베딩을 학습한다. 기존 AE 기반 방법들과 정확도는 비슷하지만 임베딩 불확실성 분석을 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: 오토인코더 기반의 파라메트릭·가역적 투영은 새로운 샘플 임베딩과 데이터 합성이 가능하나, 데이터 또는 임베딩 공간에서 분포 외 샘플에 대해 성능과 신뢰성이 떨어진다. 이를 해결하기 위해 임베딩 불확실성을 모델링하는 방법이 필요하다.

Method: DE-VAE라는 변분 오토인코더를 제안한다. 학습 시 미분 엔트로피(DE)를 도입해 임베딩의 불확실성을 정량화하고 제어한다. 주어진(고정된) 2D 투영을 기준으로, 입력→2D 임베딩의 순방향 매핑과 2D→입력의 역매핑을 함께 학습한다. UMAP·t-SNE 등을 기준선으로 비교 평가한다.

Result: 네 가지 알려진 데이터셋에서 정량·정성 평가를 수행한 결과, DE-VAE는 다른 AE 기반 접근들과 유사한 투영 정확도를 유지하면서 임베딩 불확실성(확률적 정보)을 제공한다는 장점을 보였다.

Conclusion: DE를 이용한 불확실성 인식 VAE는 파라메트릭·가역적 2D 투영을 실현하면서 임베딩 신뢰도 분석을 가능하게 하며, 분포 외 샘플 처리 및 합성 작업에서 유용할 수 있다.

Abstract: Recently, autoencoders (AEs) have gained interest for creating parametric and
invertible projections of multidimensional data. Parametric projections make it
possible to embed new, unseen samples without recalculating the entire
projection, while invertible projections allow the synthesis of new data
instances. However, existing methods perform poorly when dealing with
out-of-distribution samples in either the data or embedding space. Thus, we
propose DE-VAE, an uncertainty-aware variational AE using differential entropy
(DE) to improve the learned parametric and invertible projections. Given a
fixed projection, we train DE-VAE to learn a mapping into 2D space and an
inverse mapping back to the original space. We conduct quantitative and
qualitative evaluations on four well-known datasets, using UMAP and t-SNE as
baseline projection methods. Our findings show that DE-VAE can create
parametric and inverse projections with comparable accuracy to other current
AE-based approaches while enabling the analysis of embedding uncertainty.

</details>


### [349] [AICRN: Attention-Integrated Convolutional Residual Network for Interpretable Electrocardiogram Analysis](https://arxiv.org/abs/2508.12162)
*J. M. I. H. Jayakody,A. M. H. H. Alahakoon,C. R. M. Perera,R. M. L. C. Srimal,Roshan Ragel,Vajira Thambawita,Isuru Nawinne*

Main category: cs.LG

TL;DR: 저자들은 공간 및 채널 어텐션을 통합한 잔차 합성곱 신경망(AICRN)을 제안해 ECG 신호로부터 PR, QT, QRS, 심박수, R/T 파고 등을 회귀 예측한다. AICRN은 기존 모델보다 회귀 정밀도가 높다고 주장하며, 임상 모니터링을 위한 해석성과 실시간 분석 가능성을 강조한다.


<details>
  <summary>Details</summary>
Motivation: ECG 해석의 자동화와 실시간 디지털 분석 수요가 증가함에 따라, 인간 오류 감소와 빠른 심장 사건 탐지를 위해 더 높은 정밀도의 자동 회귀 모델이 필요하다. 저자들은 어텐션 메커니즘으로 중요 피처의 유형과 위치에 집중함으로써 해석가능성과 성능을 개선하려 한다.

Method: 공간 및 채널 어텐션 모듈을 포함한 합성곱 잔차 네트워크를 설계해 ECG 파라미터(PR, QT, QRS, 심박수, R/T 진폭)를 회귀하도록 학습시킨다. 잔차 구조로 기울기 소실·폭주 문제를 완화하고, 어텐션으로 중요 시공간 특징에 가중치를 부여한다. 실험에서 기존 모델들과 비교해 성능 우위를 보였다고 보고한다.

Result: AICRN이 제시한 지표들에서 기존 모델보다 더 높은 회귀 정밀도를 달성했다고 주장한다(구체적 수치·데이터셋·평가지표는 초록에 없음). 또한 시스템이 수작업 부담을 줄이고 임상적 적용 가능성을 가진다고 제시한다.

Conclusion: 딥러닝(특히 어텐션 통합 잔차 CNN)이 ECG 파라미터 회귀의 해석성 및 정확도를 개선할 수 있으며, 임상 모니터링·관리에서 유용하게 활용될 잠재성이 있다는 결론을 제시한다.

Abstract: The paradigm of electrocardiogram (ECG) analysis has evolved into real-time
digital analysis, facilitated by artificial intelligence (AI) and machine
learning (ML), which has improved the diagnostic precision and predictive
capacity of cardiac diseases. This work proposes a novel deep learning (DL)
architecture called the attention-integrated convolutional residual network
(AICRN) to regress key ECG parameters such as the PR interval, the QT interval,
the QRS duration, the heart rate, the peak amplitude of the R wave, and the
amplitude of the T wave for interpretable ECG analysis. Our architecture is
specially designed with spatial and channel attention-related mechanisms to
address the type and spatial location of the ECG features for regression. The
models employ a convolutional residual network to address vanishing and
exploding gradient problems. The designed system addresses traditional analysis
challenges, such as loss of focus due to human errors, and facilitates the fast
and easy detection of cardiac events, thereby reducing the manual efforts
required to solve analysis tasks. AICRN models outperform existing models in
parameter regression with higher precision. This work demonstrates that DL can
play a crucial role in the interpretability and precision of ECG analysis,
opening up new clinical applications for cardiac monitoring and management.

</details>


### [350] [ProtTeX-CC: Activating In-Context Learning in Protein LLM via Two-Stage Instruction Compression](https://arxiv.org/abs/2508.12212)
*Chuanliu Fan,Zicheng Ma,Jun Gao,Nan Yu,Jun Zhang,Ziqiang Cao,Yi Qin Gao,Guohong Fu*

Main category: cs.LG

TL;DR: ProtTeX-CC는 아미노산 서열과 구조 토큰을 잔여(residue) 단위에서 융합하고, 데모를 잠재(latent) 토큰으로 자체 압축해 ProtTeX의 입력 길이를 대폭 줄여 few-shot / ICL을 가능하게 한 경량 프레임워크이다. 16-shot에서 프롬프트 길이를 약 93.68% 감소시키고, in-domain 성능 +2%, out-of-domain +11% 향상을 보고한다.


<details>
  <summary>Details</summary>
Motivation: 기존 ProtTeX는 서열(sequence)과 구조(structure)를 토큰으로 단순 연결해 입력 길이가 거의 두 배가 되고, modality 간의 잔여 수준 정렬이 깨지며, 단일 단백질 입력으로 학습되어 ICL에 부적합하다. 이로 인해 few-shot 일반화가 취약하다.

Method: 두 단계 압축: (1) joint embedding compression — 잔여 레벨에서 서열·구조 표현을 융합해 입력 길이를 절반으로 줄이고 PEFT 기반 소수 파라미터로 튜닝; (2) self-compression — 각 데모를 마지막 몇 개의 언어적 토큰의 잠재 공간으로 집계하는 학습 가능한 투영층을 사용해 평균 데모 길이를 ~751→<16 토큰으로 축소.

Result: 백본 수정 없이 소량의 추가 파라미터만 도입해 16-shot에서 프롬프트 총 길이 약 93.68% 압축을 달성. 단백질 기능 예측에서 in-domain +2% 성능 향상, out-of-domain +11% 성능 향상 보고.

Conclusion: 경량 압축 접근으로 ProtTeX가 ICL/ few-shot을 효율적으로 수행하게 하며, 입력 길이 제한과 일반화 문제를 실용적으로 완화한다. 소규모 파라미터 증가로 좋은 성능-효율 균형을 제공한다.

Abstract: Recent advances in protein large language models, such as ProtTeX, represent
both side-chain amino acids and backbone structure as discrete token sequences
of residue length. While this design enables unified modeling of multimodal
protein information, it suffers from two major limitations: (1) The
concatenation of sequence and structure tokens approximately doubles the
protein length and breaks the intrinsic residue-level alignment between
modalities. (2) Constrained by the training corpus and limited context window,
ProtTeX is typically trained on single-protein inputs, rendering it
incompatible with in-context learning (ICL) and thus limiting its
generalization capability. To address these issues, we propose ProtTeX-CC, a
lightweight two-stage compression framework designed to enhance ProtTeX under
few-shot settings. We first design a joint embedding compression mechanism that
fuses sequence and structure representations at the residue level, effectively
reducing the protein input length by half without sacrificing performance. Then
we propose a self-compression module that aggregates each full demonstration
into the latent space of the last few linguistic tokens, reducing the average
demonstration length from 751 tokens to less than 16 tokens. Compared to the
original ProtTeX, our self-compression approach achieves a compression ratio of
approximately 93.68% in the total prompt length under the 16-shot setting.
Without modifying the backbone model, ProtTeX-CC introduces only a small number
of additional parameters through PEFT-based tuning in the joint embedding
compression stage and a single trainable projection layer in the
self-compression stage. Extensive experiments on protein function prediction
show that ProtTeX-CC improves performance on the in-domain benchmark by 2%, and
generalizes well to the out-of-domain dataset with a performance gain of 11%.

</details>


### [351] [Unlearning at Scale: Implementing the Right to be Forgotten in Large Language Models](https://arxiv.org/abs/2508.12220)
*Abdullah X*

Main category: cs.LG

TL;DR: 제안한 방법은 훈련을 결정적 프로그램으로 보고 마이크로배치 수준의 최소 로그를 남긴 뒤 훈련 꼬리를 재생해 '잊기'를 수행하면 보유(set)로 재훈련한 것과 동일한 모델 파라미터를 복원할 수 있다고 주장한다.


<details>
  <summary>Details</summary>
Motivation: GDPR의 '잊힐 권리'를 대형 언어모델에 적용할 수 있게끔, 모델 전체 재훈련 없이 특정 데이터 삭제(언러닝)를 정확하고 감사 가능하게 수행하는 체계를 제공하려는 실용적·법적 요구에서 출발한다.

Method: 마이크로배치별 최소 로그(정렬된 ID 해시, RNG 시드, 학습률, 옵티마이저 스텝 카운터, 누적 경계)를 기록하고, 고정된 소프트웨어/커널(결정적 실행) 아래에서 훈련 꼬리(replay)를 필터링해 보유 데이터로 훈련한 결과와 비트 동일성을 보장한다. 실시간 제약을 위해 마이크로체크포인트·델타, 코호트-스코프 어댑터 삭제, 곡률 기반 역-업데이트+단기 재튜닝 등의 보완 경로를 제안한다.

Result: 저장소·지연 예산을 제시하고, 전제조건을 만족하는 제어 실험에서 모델과 옵티마이저 상태가 바이트-일치함을 검증한 장난감(토이) 아티팩트를 보고한다.

Conclusion: 결정적 재현성 전제가 충족될 경우 정확한 언러닝(비트-일치)이 가능하며, 실무 적용을 위해 지연/가용성 제약을 다루는 보완 방법과 감사-게이팅 절차가 필요하다고 결론지었다.

Abstract: We study the right to be forgotten (GDPR Art. 17) for large language models
and frame unlearning as a reproducible systems problem. Our approach treats
training as a deterministic program and logs a minimal per-microbatch record
(ordered ID hash, RNG seed, learning-rate value, optimizer-step counter, and
accumulation boundary). Under a pinned stack and deterministic kernels,
replaying the training tail while filtering only the forget closure yields the
same parameters as training on the retain set (bit-identical in the training
dtype) when preconditions hold. To meet latency and availability constraints,
we add complementary paths: (i) exact reverts of recent steps via
micro-checkpoints or dense per-step deltas, (ii) cohort-scoped adapter deletion
when the base is frozen, and (iii) a curvature-guided anti-update followed by a
short retain-tune, audit-gated with escalation to exact replay. We report
storage/latency budgets and a toy artifact validating mechanics; in a
controlled run that satisfies the preconditions we demonstrate byte-identical
equality of model and optimizer states.

</details>


### [352] [Distribution Matching via Generalized Consistency Models](https://arxiv.org/abs/2508.12222)
*Sagar Shrestha,Rajesh Shrestha,Tri Nguyen,Subash Timilsina*

Main category: cs.LG

TL;DR: 새로운 분포 정합(distribution matching) 방법을 제안함. 연속 정규화 흐름(CNF)에서 차용한 일관성(consistency) 목적함수를 사용해 GAN의 유연성을 유지하면서 CNF의 단순한 최적화(노름 최소화)를 결합. 이론적 근거와 합성/실세계 실험으로 성능을 입증함.


<details>
  <summary>Details</summary>
Motivation: GAN은 고차원 데이터의 분포 정합에 강점이 있으나, 최소-최대 최적화와 모드 붕괴 문제로 학습 불안정성이 큼. 반면 CNF 계열 모델은 연속 시간 변환과 단순한 최적화 목표를 가지지만 제약(유연성) 측면에서 제약이 있을 수 있음. 두 기법의 장점을 결합해 안정적이면서도 제약을 유연하게 다룰 수 있는 분포 정합 방법을 만들고자 함.

Method: CNF에서 사용하는 일관성(consistency) 개념을 차용해 새로운 노름 최소화 기반 목적함수를 설계. 이 목적함수는 bi-level min-max(GAN) 대신 직접적인 최소화 문제로 표현되며, 다양한 제약(도메인 변환, 잠재변수 모델링 등)을 포함할 수 있도록 프레임워크를 구성. 이론적 정리로 목적함수의 합리성(수렴성/정규성 등)을 제시하고 합성 및 실세계 데이터에서 실험적으로 비교 평가.

Result: 제안한 방법이 이론적 보장을 가지며, 합성 데이터 및 실세계 데이터에서 기존 기법(기재는 상세히 안 됨)과 비교해 우수하거나 경쟁력 있는 성능을 보임. 학습 안정성 개선과 모드 붕괴 완화, 다양한 제약 적용 가능성이 관측됨.

Conclusion: CNF 계열의 일관성 기반 목적함수를 이용하면 GAN의 유연성을 유지하면서도 학습 안정성과 최적화 단순성을 확보할 수 있음. 제안 방법은 분포 정합 문제에 대한 실용적 대안이 될 수 있으며, 실험 및 이론으로 그 유효성을 뒷받침함.

Abstract: Recent advancement in generative models have demonstrated remarkable
performance across various data modalities. Beyond their typical use in data
synthesis, these models play a crucial role in distribution matching tasks such
as latent variable modeling, domain translation, and domain adaptation.
Generative Adversarial Networks (GANs) have emerged as the preferred method of
distribution matching due to their efficacy in handling high-dimensional data
and their flexibility in accommodating various constraints. However, GANs often
encounter challenge in training due to their bi-level min-max optimization
objective and susceptibility to mode collapse. In this work, we propose a novel
approach for distribution matching inspired by the consistency models employed
in Continuous Normalizing Flow (CNF). Our model inherits the advantages of CNF
models, such as having a straight forward norm minimization objective, while
remaining adaptable to different constraints similar to GANs. We provide
theoretical validation of our proposed objective and demonstrate its
performance through experiments on synthetic and real-world datasets.

</details>


### [353] [Communication-Efficient Distributed Asynchronous ADMM](https://arxiv.org/abs/2508.12233)
*Sagar Shrestha*

Main category: cs.LG

TL;DR: 비동기 ADMM에서 교환되는 데이터를 거칠게 양자화하여 통신 오버헤드를 줄이는 방법을 제안하고, 여러 분산 학습 과제(신경망 포함)에서 수렴성을 실험적으로 검증함.


<details>
  <summary>Details</summary>
Motivation: 대규모 분산 최적화·페더레이티드 학습에서 노드 간 통신 비용이 병목이 되며, 제한된 통신 예산과 큰 전송 데이터 때문에 효율적인 통신 전략이 필요함.

Method: 비동기 ADMM 알고리듬에서 교환되는 변수(예: 지역 업데이트, 듀얼 변수 등)에 대해 저해상도(거친) 양자화를 적용하여 전송량을 줄임. 양자화된 데이터를 사용한 업데이트 규칙을 설계하고, 수렴성을 실험적으로 평가함.

Result: 여러 분산 학습 태스크(신경망 포함)에서 양자화된 비동기 ADMM이 수렴함을 관찰했고, 통신량을 줄이면서도 합리적 성능을 유지함을 실험적으로 보였음.

Conclusion: 거친 양자화는 비동기 ADMM의 통신 효율을 높이는 실용적 방안이며, 대규모 페더레이티드 학습·분산 최적화에서 통신 비용-성능 균형을 개선할 수 있음.

Abstract: In distributed optimization and federated learning, asynchronous alternating
direction method of multipliers (ADMM) serves as an attractive option for
large-scale optimization, data privacy, straggler nodes and variety of
objective functions. However, communication costs can become a major bottleneck
when the nodes have limited communication budgets or when the data to be
communicated is prohibitively large. In this work, we propose introducing
coarse quantization to the data to be exchanged in aynchronous ADMM so as to
reduce communication overhead for large-scale federated learning and
distributed optimization applications. We experimentally verify the convergence
of the proposed method for several distributed learning tasks, including neural
networks.

</details>


### [354] [CC-Time: Cross-Model and Cross-Modality Time Series Forecasting](https://arxiv.org/abs/2508.12235)
*Peng Chen,Yihang Wang,Yang Shu,Yunyao Cheng,Kai Zhao,Zhongwen Rao,Lujia Pan,Bin Yang,Chenjuan Guo*

Main category: cs.LG

TL;DR: CC-Time은 시계열과 해당 시계열의 텍스트 설명을 이용한 교차-모달 학습과 PLM(사전학습 언어모델)과 시계열 모델 간의 적응적 융합(교차-모델 블록)을 결합해 PLM 기반 시계열 예측 정확도를 크게 향상시킨 방법이다.


<details>
  <summary>Details</summary>
Motivation: 언어모델이 시계열 예측에 유망하나 현재 PLM 기반 TSF는 시계열의 순차적·채널 상관을 충분히 포착하지 못해 정확도가 제한된다. PLM이 어떤 시계열 특징을 모델링할 수 있는지와 PLM만으로 충분한지 여부를 규명하려는 동기에서 출발한다.

Method: (1) 교차-모달 학습: 시계열 시퀀스와 이와 대응되는 텍스트 설명을 함께 입력해 PLM이 시간 의존성 및 채널 간 상관을 학습하도록 설계. (2) 교차-모델 융합 블록: PLM과 전통적 시계열 모델의 지식을 적응적으로 통합하여 두 모델의 장점을 결합함으로써 보다 포괄적인 시계열 패턴 모델링을 수행.

Result: 9개의 실세계 데이터셋에서 실험하여 전체 데이터 학습과 few-shot 학습 모두에서 SOTA 수준의 예측 정확도 향상을 보고함.

Conclusion: PLM은 텍스트 기반 보조 정보와의 교차-모달 학습 및 전통적 시계열 모델과의 적응적 융합을 통해 시계열 예측 성능을 크게 개선할 수 있으며, CC-Time은 이러한 방향이 실용적임을 보였다.

Abstract: With the success of pre-trained language models (PLMs) in various application
fields beyond natural language processing, language models have raised emerging
attention in the field of time series forecasting (TSF) and have shown great
prospects. However, current PLM-based TSF methods still fail to achieve
satisfactory prediction accuracy matching the strong sequential modeling power
of language models. To address this issue, we propose Cross-Model and
Cross-Modality Learning with PLMs for time series forecasting (CC-Time). We
explore the potential of PLMs for time series forecasting from two aspects: 1)
what time series features could be modeled by PLMs, and 2) whether relying
solely on PLMs is sufficient for building time series models. In the first
aspect, CC-Time incorporates cross-modality learning to model temporal
dependency and channel correlations in the language model from both time series
sequences and their corresponding text descriptions. In the second aspect,
CC-Time further proposes the cross-model fusion block to adaptively integrate
knowledge from the PLMs and time series model to form a more comprehensive
modeling of time series patterns. Extensive experiments on nine real-world
datasets demonstrate that CC-Time achieves state-of-the-art prediction accuracy
in both full-data training and few-shot learning situations.

</details>


### [355] [DHG-Bench: A Comprehensive Benchmark on Deep Hypergraph Learning](https://arxiv.org/abs/2508.12244)
*Fan Li,Xiaoyang Wang,Wenjie Zhang,Ying Zhang,Xuemin Lin*

Main category: cs.LG

TL;DR: DHG-Bench는 하이퍼그래프 신경망(HNN)을 위한 최초의 종합 벤치마크로, 20개 데이터셋, 16개 최첨단 알고리즘, 일관된 전처리 및 실험 프로토콜을 통합하여 효과성·효율성·강건성·공정성 관점에서 HNN을 체계적으로 평가하고 재현 가능한 라이브러리를 제공한다.


<details>
  <summary>Details</summary>
Motivation: 기존 딥 그래프 모델들은 쌍별 관계에 집중해 고차 상호작용을 포착하는 데 한계가 있고, HNN 연구는 증가했지만 데이터셋·알고리즘·과제의 포괄성 부족, 평가 지표의 협소함, 비일관적 실험 설정 때문에 DHGL의 진전을 정확히 파악하기 어려웠다.

Method: DHG-Bench는 노드·엣지·그래프 수준의 20개 다양한 데이터셋과 16개 최신 HNN 알고리즘을 통합하고, 일관된 데이터 처리 및 실험 프로토콜을 적용한다. 성능을 효과성, 효율성, 강건성, 공정성의 네 축으로 분류해 체계적으로 비교 평가하며, 사용하기 쉬운 훈련·평가 라이브러리를 공개한다.

Result: 광범위한 실험에서 여러 HNN의 강점(특정 과제에서의 우수한 성능)과 한계(일반화·효율성·공정성 문제)를 드러냈다. 알고리즘별·데이터셋별 성능 편차, 계산 비용과 성능 간 트레이드오프, 공격·교란에 대한 취약성 등 구체적 인사이트를 제공한다.

Conclusion: DHG-Bench는 DHGL 연구의 표준화된 비교 환경을 제공해 재현성과 공정한 비교를 촉진하며, 공개 코드와 결과를 통해 후속 연구 방향(데이터·평가 확장, 효율성·강건성 개선 등)을 제시한다.

Abstract: Although conventional deep graph models have achieved great success in
relational learning, their focus on pairwise relationships limits their
capacity to learn pervasive higher-order interactions in real-world complex
systems, which can be naturally modeled as hypergraphs. To tackle this,
hypergraph neural networks (HNNs), the dominant approach in deep hypergraph
learning (DHGL), has garnered substantial attention in recent years. Despite
the proposal of numerous HNN methods, there is no comprehensive benchmark for
HNNs, which creates a great obstacle to understanding the progress of DHGL in
several aspects: (i) insufficient coverage of datasets, algorithms, and tasks;
(ii) a narrow evaluation of algorithm performance; and (iii) inconsistent
dataset usage, preprocessing, and experimental setups that hinder
comparability. To fill the gap, we introduce DHG-Bench, the first comprehensive
benchmark for DHGL. Specifically, DHG-Bench integrates 20 diverse datasets
spanning node-, edge-, and graph-level tasks, along with 16 state-of-the-art
HNN algorithms, under consistent data processing and experimental protocols.
Our benchmark systematically investigates the characteristics of HNNs in terms
of four dimensions: effectiveness, efficiency, robustness, and fairness.
Further, to facilitate reproducible research, we have developed an easy-to-use
library for training and evaluating different HNN methods. Extensive
experiments conducted with DHG-Bench reveal both the strengths and inherent
limitations of existing algorithms, offering valuable insights and directions
for future research. The code is publicly available at:
https://github.com/Coco-Hut/DHG-Bench.

</details>


### [356] [STM3: Mixture of Multiscale Mamba for Long-Term Spatio-Temporal Time-Series Prediction](https://arxiv.org/abs/2508.12247)
*Haolong Chen,Liang Zhang,Zhengyuan Xin,Guangxu Zhu*

Main category: cs.LG

TL;DR: STM2/STM3은 멀티스케일 시계열 정보를 효율적으로 추출하고, 적응형 그래프 인과 컨볼루션과 Mixture-of-Experts 구조로 노드 간 다중스케일 시공간 의존성을 모델링하여 장기 예측에서 SOTA 성능을 달성한다.


<details>
  <summary>Details</summary>
Motivation: 기존 딥러닝 방법은 장기 시공간 의존성 학습에서 어려움을 겪는다. 특히 (1) 시계열의 자연스러운 멀티스케일 정보를 효율적으로 추출하기 어렵고, (2) 서로 다른 노드의 멀티스케일 정보가 강하게 상관되어 이를 적절히 모델링하기 힘들다.

Method: STM2는 멀티스케일 Mamba 아키텍처와 적응형 그래프 인과 컨볼루션 네트워크를 결합하여 계층적 정보 집계로 각 스케일의 구분성을 보장한다. STM3는 Mixture-of-Experts 구조(안정적 라우팅 전략 및 인과 대조학습)를 도입해 노드별 다양한 시간 역학을 효율적으로 분리·학습하며, 라우팅의 부드러움과 전문가별 패턴 분해에 대한 이론적 보장을 제시한다.

Result: 실제 벤치마크에서 제안 모델들이 장기 시공간 시계열 예측에서 기존 방법들을 능가하는 성능(논문 주장: SOTA)을 보인다.

Conclusion: STM2/STM3은 멀티스케일 시공간 의존성 학습을 효율화하고, STM3의 전문가 분화와 라우팅 안정성으로 장기 예측 성능을 크게 향상시킨다.

Abstract: Recently, spatio-temporal time-series prediction has developed rapidly, yet
existing deep learning methods struggle with learning complex long-term
spatio-temporal dependencies efficiently. The long-term spatio-temporal
dependency learning brings two new challenges: 1) The long-term temporal
sequence includes multiscale information naturally which is hard to extract
efficiently; 2) The multiscale temporal information from different nodes is
highly correlated and hard to model. To address these challenges, we propose an
efficient \textit{\textbf{S}patio-\textbf{T}emporal \textbf{M}ultiscale
\textbf{M}amba} (STM2) that includes a multiscale Mamba architecture to capture
the multiscale information efficiently and simultaneously, and an adaptive
graph causal convolution network to learn the complex multiscale
spatio-temporal dependency. STM2 includes hierarchical information aggregation
for different-scale information that guarantees their distinguishability. To
capture diverse temporal dynamics across all spatial nodes more efficiently, we
further propose an enhanced version termed
\textit{\textbf{S}patio-\textbf{T}emporal \textbf{M}ixture of
\textbf{M}ultiscale \textbf{M}amba} (STM3) that employs a special
Mixture-of-Experts architecture, including a more stable routing strategy and a
causal contrastive learning strategy to enhance the scale distinguishability.
We prove that STM3 has much better routing smoothness and guarantees the
pattern disentanglement for each expert successfully. Extensive experiments on
real-world benchmarks demonstrate STM2/STM3's superior performance, achieving
state-of-the-art results in long-term spatio-temporal time-series prediction.

</details>


### [357] [Interpreting Time Series Forecasts with LIME and SHAP: A Case Study on the Air Passengers Dataset](https://arxiv.org/abs/2508.12253)
*Manish Shukla*

Main category: cs.LG

TL;DR: LIME와 SHAP을 시계열 예측에 적용하는 통합 프레임워크를 제안한다. 유니버리트 시계열을 누수(leakage)-free한 지도학습 문제로 변환하고, 그래디언트 부스팅(트리) 모델과 ARIMA를 비교한 뒤 사후 설명을 수행해 주요 설명변수(특히 12개월 랙과 계절 인코딩)가 예측 분산의 대부분을 설명함을 보였다.


<details>
  <summary>Details</summary>
Motivation: 시계열 예측은 여러 산업에서 핵심 의사결정을 지원하지만, ARIMA는 해석력은 있으나 비선형성 처리에 약하고, 트리 기반 ML은 성능이 좋지만 불투명해 해석 가능한 예측 수단이 필요하다.

Method: (1) 단변량 시계열을 랙(feature)과 계절 변수로 구성한 누수 방지 지도학습 문제로 변환, (2) 그래디언트 부스팅(트리) 모델과 ARIMA 베이스라인 학습, (3) LIME과 SHAP을 이용한 사후 해석(지역·전역 중요도, 특성 기여 분석), (4) Air Passengers 데이터셋으로 사례 분석 및 이론적·실무적 지침 제공.

Result: 사례 연구에서 12개월 랙과 계절 인코딩이 예측 분산의 핵심 설명자가 되었고, LIME과 SHAP 모두 일관된 특성 기여를 보였음(구체적 수치·성능 비교는 초록에 없음). 또한 시계열 특유의 시퀀스성 유지를 위한 누수 방지 전처리와 롤링 기준 평가가 중요하다는 점을 강조.

Conclusion: 제안된 절차는 시계열에 대해 LIME·SHAP을 안전하게 적용해 트리 기반 모델의 불투명성을 줄여주며, 실무자는 누수 방지·계절성 인코딩·ARIMA와의 비교·설명기법(전역:SHAP, 국소:LIME) 활용을 권장한다. 한계로는 단일 데이터셋(단변량) 중심의 검증, 설명의 안정성·계산비용 문제 등이 남아 있다.

Abstract: Time-series forecasting underpins critical decisions across aviation, energy,
retail and health. Classical autoregressive integrated moving average (ARIMA)
models offer interpretability via coefficients but struggle with
nonlinearities, whereas tree-based machine-learning models such as XGBoost
deliver high accuracy but are often opaque. This paper presents a unified
framework for interpreting time-series forecasts using local interpretable
model-agnostic explanations (LIME) and SHapley additive exPlanations (SHAP). We
convert a univariate series into a leakage-free supervised learning problem,
train a gradient-boosted tree alongside an ARIMA baseline and apply post-hoc
explainability. Using the Air Passengers dataset as a case study, we show that
a small set of lagged features -- particularly the twelve-month lag -- and
seasonal encodings explain most forecast variance. We contribute: (i) a
methodology for applying LIME and SHAP to time series without violating
chronology; (ii) theoretical exposition of the underlying algorithms; (iii)
empirical evaluation with extensive analysis; and (iv) guidelines for
practitioners.

</details>


### [358] [L-SR1: Learned Symmetric-Rank-One Preconditioning](https://arxiv.org/abs/2508.12270)
*Gal Lifshitz,Shahar Zuler,Ori Fouks,Dan Raviv*

Main category: cs.LG

TL;DR: 학습된 2차 최적화기(learned second-order optimizer)를 제안하여 SR1 알고리즘에 학습 가능한 전처리 유닛을 결합했다. 이 유닛은 데이터 기반 벡터로부터 PSD(양의 준정부호) 순위-1 행렬을 만들어 섹언트 제약과 정렬된 업데이트를 생성한다. 분석 실험과 Monocular Human Mesh Recovery(HMR)에서 기존 학습기반 최적화기들을 능가한다.


<details>
  <summary>Details</summary>
Motivation: 엔드투엔드 딥러닝은 레이블 데이터 의존성, 미지 환경에서의 일반화 한계, 연산 비용 증가라는 문제를 가진다. 고전적 최적화는 데이터 효율적이나 수렴 속도가 느리고, 대부분의 학습된 최적화 연구는 1차 방법에 집중되어 2차 학습 기반 방법이 부족하다.

Method: 기존 SR1(대칭-랭크-원) 업데이트에 학습 가능한 전처리 모듈을 추가한다. 이 모듈은 입력으로부터 벡터를 생성하고, 이 벡터들로부터 양의 준정부호(PSD)인 순위-1 행렬을 구성한다. 또한 학습된 투영을 통해 섹언트(secant) 제약과 정렬하여 2차 정보(근사 해시안)를 보정한다.

Result: 분석적(아마 합성/제어된 조건 하) 실험과 실제 HMR 과제에서 기존의 학습 기반 최적화 방법들보다 우수한 성능을 보였다고 보고한다. 모델은 경량이며 주석 데이터나 추가 파인튜닝 없이도 잘 일반화한다고 주장한다.

Conclusion: 경량의 주석 불필요한(annot-free) 학습된 2차 최적화기로서, 일반화성과 통합성(다른 최적화 프레임워크와의 결합)에 강점이 있어 실제 비전/역문제 응용에 유용할 가능성이 높다.

Abstract: End-to-end deep learning has achieved impressive results but remains limited
by its reliance on large labeled datasets, poor generalization to unseen
scenarios, and growing computational demands. In contrast, classical
optimization methods are data-efficient and lightweight but often suffer from
slow convergence. While learned optimizers offer a promising fusion of both
worlds, most focus on first-order methods, leaving learned second-order
approaches largely unexplored.
  We propose a novel learned second-order optimizer that introduces a trainable
preconditioning unit to enhance the classical Symmetric-Rank-One (SR1)
algorithm. This unit generates data-driven vectors used to construct positive
semi-definite rank-one matrices, aligned with the secant constraint via a
learned projection. Our method is evaluated through analytic experiments and on
the real-world task of Monocular Human Mesh Recovery (HMR), where it
outperforms existing learned optimization-based approaches. Featuring a
lightweight model and requiring no annotated data or fine-tuning, our approach
offers strong generalization and is well-suited for integration into broader
optimization-based frameworks.

</details>


### [359] [CRoC: Context Refactoring Contrast for Graph Anomaly Detection with Limited Supervision](https://arxiv.org/abs/2508.12278)
*Siyue Xie,Da Sun Handason Tam,Wing Cheong Lau*

Main category: cs.LG

TL;DR: CRoC는 노드 속성 재구성으로 문맥을 재정비하고(보존된 상호작용 패턴 유지), 이종 관계를 개별 인코딩하여 메시지 전달에 통합한 뒤 대조학습과 결합해 제한된 라벨과 풍부한 무라벨을 함께 활용하는 GAD 프레임워크이다. 소규모 라벨 상황에서 최대 14% AUC 향상을 보고한다.


<details>
  <summary>Details</summary>
Motivation: GNN 기반 이상탐지는 라벨이 희귀하고 이상이 은폐되기 쉬워 학습데이터 확보가 어려우며, 기존 방법은 무라벨 데이터를 효과적으로 활용하지 못하거나 은폐 공격에 취약하다.

Method: (1) 클래스 불균형을 이용한 Context Refactoring: 노드 속성을 재조합해 보강된 그래프를 생성하되 구조적 상호작용은 유지. (2) 이종 관계 별도 인코딩을 메시지 전달에 통합하여 복잡한 상호작용 의미 포착 강화. (3) 대조학습과 결합한 공동 학습으로 무라벨 데이터에서 서술성이 높은 노드 임베딩 학습.

Result: 7개 실제 GAD 데이터셋에서 평가하여 기존 GNN 대비 최대 14% AUC 향상, 제한된 라벨 환경에서 SOTA 방법들보다 우수한 성능을 보임.

Conclusion: CRoC는 문맥 재구성과 관계 인코딩, 대조학습의 결합을 통해 라벨이 적고 이상이 은닉된 상황에서도 견고한 이상탐지 성능을 달성하며 실무 적용 가능성이 높다.

Abstract: Graph Neural Networks (GNNs) are widely used as the engine for various
graph-related tasks, with their effectiveness in analyzing graph-structured
data. However, training robust GNNs often demands abundant labeled data, which
is a critical bottleneck in real-world applications. This limitation severely
impedes progress in Graph Anomaly Detection (GAD), where anomalies are
inherently rare, costly to label, and may actively camouflage their patterns to
evade detection. To address these problems, we propose Context Refactoring
Contrast (CRoC), a simple yet effective framework that trains GNNs for GAD by
jointly leveraging limited labeled and abundant unlabeled data. Different from
previous works, CRoC exploits the class imbalance inherent in GAD to refactor
the context of each node, which builds augmented graphs by recomposing the
attributes of nodes while preserving their interaction patterns. Furthermore,
CRoC encodes heterogeneous relations separately and integrates them into the
message-passing process, enhancing the model's capacity to capture complex
interaction semantics. These operations preserve node semantics while
encouraging robustness to adversarial camouflage, enabling GNNs to uncover
intricate anomalous cases. In the training stage, CRoC is further integrated
with the contrastive learning paradigm. This allows GNNs to effectively harness
unlabeled data during joint training, producing richer, more discriminative
node embeddings. CRoC is evaluated on seven real-world GAD datasets with
varying scales. Extensive experiments demonstrate that CRoC achieves up to 14%
AUC improvement over baseline GNNs and outperforms state-of-the-art GAD methods
under limited-label settings.

</details>


### [360] [Convergence Analysis of the Lion Optimizer in Centralized and Distributed Settings](https://arxiv.org/abs/2508.12327)
*Wei Jiang,Lijun Zhang*

Main category: cs.LG

TL;DR: Lion 옵티마이저의 수렴을 이론적으로 분석함. 기본 Lion은 O(d^{1/2}T^{-1/4}), 분산감소 적용시 O(d^{1/2}T^{-1/3}). 분산 환경에서는 각각 O(d^{1/2}(nT)^{-1/4}), O(d^{1/2}(nT)^{-1/3}). 통신절약(sign 압축) 버전은 편향 없애는 sign 연산을 사용해 O(max{d^{1/4}/T^{1/4}, d^{1/10}/(n^{1/5}T^{1/5})}) (기본) 및 O(d^{1/4}/T^{1/4}) (분산감소) 달성.


<details>
  <summary>Details</summary>
Motivation: Lion(모멘텀/사인 기반)의 실제 성능은 좋지만 수렴 이론이 부족함. 본 논문은 Lion과 그 변형들(분산, 분산감소, 통신압축)에 대한 엄밀한 수렴률을 제공하려는 목적임.

Method: 표준 비볼록 최적화 가정(매끄러움, 그레이디언트 분산 등) 아래에서 Lion 알고리즘의 반복 과정 분석. 분산감소 기법을 도입하여 분산 추정 오차를 줄이고, 분산 설정에서는 노드 수 n을 포함한 복합 분석을 수행. 통신절약을 위해 양방향 sign 압축을 도입하되 unbiased sign 연산을 설계하여 편향을 제거하고 수렴 분석을 확장.

Result: - 기본 Lion: O(d^{1/2}T^{-1/4}).
- Lion + 분산감소: O(d^{1/2}T^{-1/3}).
- 분산(노드 n) 설정: 각각 O(d^{1/2}(nT)^{-1/4}), O(d^{1/2}(nT)^{-1/3}).
- 통신압축(무편향 sign): 기본 O(max{d^{1/4}/T^{1/4}, d^{1/10}/(n^{1/5}T^{1/5})}), 분산감소 버전 O(d^{1/4}/T^{1/4}).

Conclusion: Lion 계열 알고리즘은 비볼록 문제에서 이론적 수렴 보장을 갖고, 분산감소와 분산 처리가 수렴 속도를 개선하며, 무편향 sign 압축으로 통신비를 줄이면서도 합리적 수렴률을 확보할 수 있음.

Abstract: In this paper, we analyze the convergence properties of the Lion optimizer.
First, we establish that the Lion optimizer attains a convergence rate of
$\mathcal{O}(d^{1/2}T^{-1/4})$ under standard assumptions, where $d$ denotes
the problem dimension and $T$ is the iteration number. To further improve this
rate, we introduce the Lion optimizer with variance reduction, resulting in an
enhanced convergence rate of $\mathcal{O}(d^{1/2}T^{-1/3})$. We then analyze in
distributed settings, where the standard and variance reduced version of the
distributed Lion can obtain the convergence rates of
$\mathcal{O}(d^{1/2}(nT)^{-1/4})$ and $\mathcal{O}(d^{1/2}(nT)^{-1/3})$, with
$n$ denoting the number of nodes. Furthermore, we investigate a
communication-efficient variant of the distributed Lion that ensures sign
compression in both communication directions. By employing the unbiased sign
operations, the proposed Lion variant and its variance reduction counterpart,
achieve convergence rates of $\mathcal{O}\left( \max
\left\{\frac{d^{1/4}}{T^{1/4}}, \frac{d^{1/10}}{n^{1/5}T^{1/5}} \right\}
\right)$ and $\mathcal{O}\left( \frac{d^{1/4}}{T^{1/4}} \right)$, respectively.

</details>


### [361] [Navigating the Exploration-Exploitation Tradeoff in Inference-Time Scaling of Diffusion Models](https://arxiv.org/abs/2508.12361)
*Xun Su,Jianming Huang,Yang Yusen,Zhongxi Fang,Hiroyuki Kasai*

Main category: cs.LG

TL;DR: 확률적 입자 기반 샘플링(SMC)을 확장해 확산 모델의 생성 시점 탐색-활용 균형을 개선한 방법을 제안한다. Funnel Schedule과 Adaptive Temperature로 초중기 입자 수와 보상 가중치를 단계적으로 조절해 샘플 품질을 높이고 계산량(NFE)은 유지한다.


<details>
  <summary>Details</summary>
Motivation: 언어모델에서의 추론 시 확장(inference-time scaling) 효과는 잘 알려져 있으나, 확산모델에 대한 적용은 미흡하다. 기존 SMC 기반 방법들은 보상-기울어진 분포(reward-tilted distribution)를 전역적으로 맞추는 과정에서 다중모달 탐색의 다양성을 보존하는 것이 핵심임을 관찰했다. 그러나 확산모델에선 초반 노이즈 샘플은 개선 여지가 크지만 평가가 불안정하고, 후반 샘플은 평가가 정확하지만 변경이 어렵다는 탐색-활용 딜레마가 존재한다.

Method: 탐색 알고리즘 관점에서 두 가지 전략을 제안: (1) Funnel Schedule — 유지하는 입자 수를 점진적으로 줄여 '퍼널'처럼 탐색에서 집중으로 전환, (2) Adaptive Temperature — 초중기 보상의 영향력을 단계적으로 낮춰 불확실한 조기 평가에 의한 잘못된 수렴을 방지. 이들은 확산모델의 생성 역학과 단계 전이(phase-transition) 특성에 맞춰 설계됨.

Result: 제안 방법은 전체 Noise Function Evaluations를 늘리지 않으면서 여러 벤치마크와 최첨단 텍스트-투-이미지 확산모델에서 기존 SMC 및 기타 기반선보다 샘플 품질을 개선했다.

Conclusion: 단순한 일정 및 온도 적응 전략만으로도 확산모델 추론 시 탐색-활용 균형을 효과적으로 해결할 수 있으며, SMC 기반 접근의 장점을 보존하면서 더 나은 생성 결과를 얻는다.

Abstract: Inference-time scaling has achieved remarkable success in language models,
yet its adaptation to diffusion models remains underexplored. We observe that
the efficacy of recent Sequential Monte Carlo (SMC)-based methods largely stems
from globally fitting the The reward-tilted distribution, which inherently
preserves diversity during multi-modal search. However, current applications of
SMC to diffusion models face a fundamental dilemma: early-stage noise samples
offer high potential for improvement but are difficult to evaluate accurately,
whereas late-stage samples can be reliably assessed but are largely
irreversible. To address this exploration-exploitation trade-off, we approach
the problem from the perspective of the search algorithm and propose two
strategies: Funnel Schedule and Adaptive Temperature. These simple yet
effective methods are tailored to the unique generation dynamics and
phase-transition behavior of diffusion models. By progressively reducing the
number of maintained particles and down-weighting the influence of early-stage
rewards, our methods significantly enhance sample quality without increasing
the total number of Noise Function Evaluations. Experimental results on
multiple benchmarks and state-of-the-art text-to-image diffusion models
demonstrate that our approach outperforms previous baselines.

</details>


### [362] [Bi-Axial Transformers: Addressing the Increasing Complexity of EHR Classification](https://arxiv.org/abs/2508.12418)
*Rachael DeVries,Casper Christensen,Marie Lisandra Zepeda Mendoza,Ole Winther*

Main category: cs.LG

TL;DR: 서로 다른 임상 변수 축과 시간 축에 동시에 어텐션을 적용하는 Bi-Axial Transformer(BAT)를 제안하여 EHR의 희소성/결측성 문제를 완화하고, 패혈증 예측에서 SOTA 성능을 달성하며 사망률 예측에서도 경쟁력 있는 결과를 보임.


<details>
  <summary>Details</summary>
Motivation: EHR 데이터는 변수 수 증가, 긴 시계열, 다중 모달 통합 등으로 복잡해지고 있으며, 기존 표현방법은 결측성(missingness)을 잘 포착하지 못하거나 성능을 저하시킴. 트랜스포머의 장점(장거리 의존성 모델링, 병렬 처리)을 EHR에 적절히 적용하려는 필요성.

Method: 임상 변수(axis)와 시간(axis)을 각각 어텐션하는 양축(Bi-Axial) 트랜스포머 구조를 도입. 데이터 희소성에 강인하도록 설계하고 개별 센서(변수) 임베딩을 학습하여 전이학습에 활용 가능하도록 함. 기존 베이스라인 모델을 PyTorch로 재구현해 비교·재현성 확보.

Result: 패혈증 예측에서 SOTA 성능 달성, 사망률 분류에서는 상위권 성능. 다른 트랜스포머 모델들보다 결측성에 대한 강인성 증가. 학습된 센서 임베딩은 전이학습에 유용함.

Conclusion: BAT는 EHR 특유의 두 축(변수·시간)을 명시적으로 모델링함으로써 결측성과 희소성 문제를 완화하고 실무적 성능 향상을 보였음. 재현 가능한 베이스라인 구현으로 후속 연구의 벤치마크로 활용 가능하다.

Abstract: Electronic Health Records (EHRs), the digital representation of a patient's
medical history, are a valuable resource for epidemiological and clinical
research. They are also becoming increasingly complex, with recent trends
indicating larger datasets, longer time series, and multi-modal integrations.
Transformers, which have rapidly gained popularity due to their success in
natural language processing and other domains, are well-suited to address these
challenges due to their ability to model long-range dependencies and process
data in parallel. But their application to EHR classification remains limited
by data representations, which can reduce performance or fail to capture
informative missingness. In this paper, we present the Bi-Axial Transformer
(BAT), which attends to both the clinical variable and time point axes of EHR
data to learn richer data relationships and address the difficulties of data
sparsity. BAT achieves state-of-the-art performance on sepsis prediction and is
competitive to top methods for mortality classification. In comparison to other
transformers, BAT demonstrates increased robustness to data missingness, and
learns unique sensor embeddings which can be used in transfer learning.
Baseline models, which were previously located across multiple repositories or
utilized deprecated libraries, were re-implemented with PyTorch and made
available for reproduction and future benchmarking.

</details>


### [363] [Machine Learning-Based Manufacturing Cost Prediction from 2D Engineering Drawings via Geometric Features](https://arxiv.org/abs/2508.12440)
*Ahmet Bilal Arıkan,Şener Özönder,Mustafa Taha Koçyiğit,Hüseyin Oktay Altun,H. Kübra Küçükkartal,Murat Arslanoğlu,Fatih Çağırankaya,Berk Ayvaz*

Main category: cs.LG

TL;DR: 2D CAD 도면(DWG)에서 약 200개의 기하 및 통계 특성을 자동 추출해 XGBoost/CatBoost/LightGBM로 학습한 비용 추정 파이프라인을 제안한다. 13,684개 자동차 서스펜션·조향 부품에 대해 거의 10% MAPE를 달성하고 SHAP 기반 설명을 통해 비용에 영향을 주는 기하학적 드라이버를 식별한다.


<details>
  <summary>Details</summary>
Motivation: 견적 산출의 수작업·전문가 휴리스틱 의존도를 낮추고, 부품군 전반에 걸친 일관성·속도 확보와 Industry 4.0 환경에서 실시간 ERP 연동 가능한 비용 예측 도구를 만들기 위함.

Method: 13,684개 DWG로부터 약 200개(회전된 치수 최대값, 호(arc) 통계, 발산(divergence) 지표 등 포함)의 기하·통계 특성을 자동 추출하고, XGBoost, CatBoost, LightGBM 등 그래디언트 부스팅 모델을 학습. 예측 정확성 평가와 SHAP으로 특성 중요도 및 설계 인사이트 도출.

Result: 제품군 간 평균 절대백분오차(MAPE) 약 10% 달성. 모델은 부품 특화 휴리스틱을 넘는 확장성·강건성을 보였고, 주요 비용 드라이버(회전된 치수 최대값, 호 통계, 발산 지표 등)를 SHAP으로 식별하여 설계 피드백 제공.

Conclusion: CAD→비용의 엔드투엔드 파이프라인은 견적 리드타임 단축, 일관된 투명한 비용평가, ERP 연동을 통한 실시간 의사결정 지원 경로를 제공. 단, 데이터가 자동차 서스펜션·조향 부품으로 제한돼 일반화·공정 변수 반영·인간 전문가와의 정성적 비교 등 후속 연구가 필요하다.

Abstract: We present an integrated machine learning framework that transforms how
manufacturing cost is estimated from 2D engineering drawings. Unlike
traditional quotation workflows that require labor-intensive process planning,
our approach about 200 geometric and statistical descriptors directly from
13,684 DWG drawings of automotive suspension and steering parts spanning 24
product groups. Gradient-boosted decision tree models (XGBoost, CatBoost,
LightGBM) trained on these features achieve nearly 10% mean absolute percentage
error across groups, demonstrating robust scalability beyond part-specific
heuristics. By coupling cost prediction with explainability tools such as SHAP,
the framework identifies geometric design drivers including rotated dimension
maxima, arc statistics and divergence metrics, offering actionable insights for
cost-aware design. This end-to-end CAD-to-cost pipeline shortens quotation lead
times, ensures consistent and transparent cost assessments across part families
and provides a deployable pathway toward real-time, ERP-integrated decision
support in Industry 4.0 manufacturing environments.

</details>


### [364] [Local Cluster Cardinality Estimation for Adaptive Mean Shift](https://arxiv.org/abs/2508.12450)
*Étienne Pepin*

Main category: cs.LG

TL;DR: 거리분포의 지역최솟값으로 군집의 국부적 크기(카디널리티)를 추정하고, 이를 이용해 대역폭과 커널 반경 임계값을 적응적으로 조정하는 mean shift 변형. 기존 KDE 기반 방법보다 군집 전체 파라미터를 계산하며, 제안 알고리즘은 제시된 비교방법보다 성능이 우수하거나 경쟁적임.


<details>
  <summary>Details</summary>
Motivation: 서로 다른 지역적 스케일과 군집 크기를 가지는 데이터에서 고정 대역폭 mean shift는 성능 저하가 발생하므로, 지역별 군집 크기를 추정해 mean shift 파라미터를 적응적으로 조정하려는 동기.

Method: 각 점에서 다른 모든 점까지의 거리분포를 분석해 거리밀도의 ‘지역 최솟값’을 찾아 지역 군집 카디널리티를 추정한다. 이 카디널리티를 기반으로 군집 전체에 대한 국부 파라미터(대역폭, 커널 반경 임계값)를 계산하고, mean shift 수행 중 이 추정값으로 파라미터를 적응적으로 업데이트한다. KDE 기반 방법과 달리 군집 전체 정보를 이용함.

Result: 제안 기법은 원 제안방법의 원 데이터셋에서 더 나은 성능을 보였고, 더 넓은 클러스터링 벤치마크에서도 경쟁력 있는 결과를 보였음.

Conclusion: 거리분포 기반 카디널리티 추정을 통해 mean shift의 대역폭과 반경을 적응적으로 조정하면 다양한 스케일과 카디널리티를 가진 데이터에서 성능 향상을 기대할 수 있음.

Abstract: This article presents an adaptive mean shift algorithm designed for datasets
with varying local scale and cluster cardinality. Local distance distributions,
from a point to all others, are used to estimate the cardinality of the local
cluster by identifying a local minimum in the density of the distance
distribution. Based on these cardinality estimates, local cluster parameters
are then computed for the entire cluster in contrast to KDE-based methods,
which provide insight only into localized regions of the cluster. During the
mean shift execution, the cluster cardinality estimate is used to adaptively
adjust the bandwidth and the mean shift kernel radius threshold. Our algorithm
outperformed a recently proposed adaptive mean shift method on its original
dataset and demonstrated competitive performance on a broader clustering
benchmark.

</details>


### [365] [Cold-RL: Learning Cache Eviction with Offline Reinforcement Learning for NGINX](https://arxiv.org/abs/2508.12485)
*Aayush Gupta,Arpit Bhayani*

Main category: cs.LG

TL;DR: Cold-RL은 NGINX의 LRU 강제 만료 경로를 대체하는 경량 RL 기반 퇴출 정책으로, 마이크로초 예산(500µs) 내에서 ONNX 사이드카로 Dueling DQN을 서빙해 소규모 캐시와 적대적 워크로드에서 히트율을 크게 개선한다.


<details>
  <summary>Details</summary>
Motivation: LRU는 크기 무시 성격 때문에 주기적 버스트와 혼합 객체 크기에서 스래싱이 발생한다. 엄격한 지연 SLO를 만족하면서 더 현명한 퇴출 결정이 필요하다.

Method: 퇴출 시 K개의 LRU 후보를 샘플링하고(샘플링 기반 액션 공간 축소), age, size, hit count, inter-arrival time, remaining TTL, last origin RTT의 6가지 경량 피처로 상태를 구성한다. Dueling DQN이 비트마스크(희생자)를 반환하며, 500µs 타임아웃 시 즉시 LRU로 폴백한다. 정책은 액세스 로그를 시뮬레이터로 재생해 오프라인으로 학습하고 보상은 TTL 만료 전 재사용되면 1점 부여.

Result: 25MB 캐시에서 히트율을 0.1436→0.3538로(클래식 베이스라인 대비 +146%), 100MB에서 0.7530→0.8675(+15%), 400MB에서는 기존 방법들과 동등(약 0.918). 추론 오버헤드는 CPU 기준 <2%이고 95백분위 퇴출 지연은 예산 내.

Conclusion: 엄격한 SLO 하에서도 실무용 NGINX에 통합 가능한 RL 기반 퇴출 정책의 실현 가능성을 보였으며, 특히 소규모 캐시와 적대적 워크로드에서 유의미한 이득을 제공한다. 폴백·타임아웃 설계로 안전성도 확보했다.

Abstract: Web proxies such as NGINX commonly rely on least-recently-used (LRU)
eviction, which is size agnostic and can thrash under periodic bursts and mixed
object sizes. We introduce Cold-RL, a learned eviction policy for NGINX that
replaces LRU's forced-expire path with a dueling Deep Q-Network served by an
ONNX sidecar within a strict microsecond budget. On each eviction, Cold-RL
samples the K least-recently-used objects, extracts six lightweight features
(age, size, hit count, inter-arrival time, remaining TTL, and last origin RTT),
and requests a bitmask of victims; a hard timeout of 500 microseconds triggers
immediate fallback to native LRU. Policies are trained offline by replaying
NGINX access logs through a cache simulator with a simple reward: a retained
object earns one point if it is hit again before TTL expiry. We compare against
LRU, LFU, size-based, adaptive LRU, and a hybrid baseline on two adversarial
workloads. With a 25 MB cache, Cold-RL raises hit ratio from 0.1436 to 0.3538,
a 146 percent improvement over the best classical baseline; at 100 MB, from
0.7530 to 0.8675, a 15 percent gain; and at 400 MB it matches classical methods
(about 0.918). Inference adds less than 2 percent CPU overhead and keeps 95th
percentile eviction latency within budget. To our knowledge, this is the first
reinforcement learning eviction policy integrated into NGINX with strict SLOs.

</details>


### [366] [Cost-Aware Contrastive Routing for LLMs](https://arxiv.org/abs/2508.12491)
*Reza Shirkavand,Shangqian Gao,Peiran Yu,Heng Huang*

Main category: cs.LG

TL;DR: 대형언어모델(LLM)들의 비용-정확도 균형을 개선하기 위해, 프롬프트와 모델을 같은 임베딩 공간으로 매핑하고 비용-감수성 라우팅을 수행하는 경량 프레임워크 CSCR을 제안한다. 로그잇·퍼플렉서티 지문을 사용해 빠르게 k-NN으로 전문가를 선택하여 마이크로초 레이턴시와 재학습 불필요성을 달성한다.


<details>
  <summary>Details</summary>
Motivation: 다양하고 동적인 모델 풀에서 프롬프트별 컨텍스트와 비용을 고려한 효율적 라우팅이 필요하나, 기존 방법들은 프롬프트 무시, 고비용 프로파일링, 고정된 전문가 집합 가정, 또는 비효율적 시행착오 방식을 사용한다.

Method: 오픈소스 모델에는 로그잇 발자국, 블랙박스 API에는 퍼플렉서티 지문을 계산하고, 대비 학습(contrastive encoder)을 통해 프롬프트와 모델 임베딩을 통합한다. 비용 밴드를 도입해 동일 정확도를 내는 가장 저렴한 전문가가 우선되도록 학습한다. 추론시 FAISS 인덱스 기반 k-NN 조회로 빠르게 라우팅한다.

Result: 여러 벤치마크에서 기존 방법 대비 최대 25%의 정확도-비용 트레이드오프 개선을 보고하며, 보이지 않는 LLM과 OOD(분포외) 프롬프트에도 잘 일반화한다. 모델 풀 변경시 재학습 불필요, 마이크로초 수준의 라우팅 지연을 달성.

Conclusion: CSCR은 비용을 명시적으로 고려한 프롬프트-모델 임베딩과 대비 학습을 통해 실용적이고 확장 가능한 라우팅을 제공하며, 동적 전문가 풀과 블랙박스 모델 환경에서도 효율적으로 동작한다.

Abstract: We study cost-aware routing for large language models across diverse and
dynamic pools of models. Existing approaches often overlook prompt-specific
context, rely on expensive model profiling, assume a fixed set of experts, or
use inefficient trial-and-error strategies. We introduce Cost-Spectrum
Contrastive Routing (CSCR), a lightweight framework that maps both prompts and
models into a shared embedding space to enable fast, cost-sensitive selection.
CSCR uses compact, fast-to-compute logit footprints for open-source models and
perplexity fingerprints for black-box APIs. A contrastive encoder is trained to
favor the cheapest accurate expert within adaptive cost bands. At inference
time, routing reduces to a single k-NN lookup via a FAISS index, requiring no
retraining when the expert pool changes and enabling microsecond latency.
Across multiple benchmarks, CSCR consistently outperforms baselines, improving
the accuracy-cost tradeoff by up to 25%, while generalizing robustly to unseen
LLMs and out-of-distribution prompts.

</details>


### [367] [Trust Region Constrained Measure Transport in Path Space for Stochastic Optimal Control and Inference](https://arxiv.org/abs/2508.12511)
*Denis Blessing,Julius Berner,Lorenz Richter,Carles Domingo-Enrich,Yuanqi Du,Arash Vahdat,Gerhard Neumann*

Main category: cs.LG

TL;DR: Prior에서 목표 경로 분포로 천천히 이동하도록 신뢰영역(trust region)을 적용한 반복적 최적화(기하학적 어닐링)를 통해 확률적 제어 문제를 안정적이고 효율적으로 해결한다.


<details>
  <summary>Details</summary>
Motivation: 목표 경로 측도가 prior와 크게 다를 때 직접적인 그래디언트 기반 최적화는 수렴 불안정성과 성능 저하를 겪음. 이를 완만하게 목표로 이동시키는 체계적 전략이 필요함.

Method: 각 반복에서 trust region(제약)을 도입한 제한적 최적화 문제를 풀어 prior에서 목표로 점진적 이동을 유도. 이 과정은 기하학적 어닐링으로 해석되며, trust region이 어닐링 스텝(시간 간격) 선택을 원칙적으로 결정함.

Result: 확률적 제어 응용(확산 기반 샘플링, 전이 경로 샘플링, 확산모델 파인튜닝)에서 성능이 유의미하게 향상됨을 실험적으로 보임.

Conclusion: 신뢰영역 기반 기하학적 어닐링은 prior→target 접근을 안정화하고 어닐링 스케줄을 자동 설계하여 다양한 확률적 제어 과제에 효과적이다.

Abstract: Solving stochastic optimal control problems with quadratic control costs can
be viewed as approximating a target path space measure, e.g. via gradient-based
optimization. In practice, however, this optimization is challenging in
particular if the target measure differs substantially from the prior. In this
work, we therefore approach the problem by iteratively solving constrained
problems incorporating trust regions that aim for approaching the target
measure gradually in a systematic way. It turns out that this trust region
based strategy can be understood as a geometric annealing from the prior to the
target measure, where, however, the incorporated trust regions lead to a
principled and educated way of choosing the time steps in the annealing path.
We demonstrate in multiple optimal control applications that our novel method
can improve performance significantly, including tasks in diffusion-based
sampling, transition path sampling, and fine-tuning of diffusion models.

</details>


### [368] [Results of the NeurIPS 2023 Neural MMO Competition on Multi-task Reinforcement Learning](https://arxiv.org/abs/2508.12524)
*Joseph Suárez,Kyoung Whan Choe,David Bloomin,Jianming Gao,Yunkun Li,Yao Feng,Saidinesh Pola,Kun Zhang,Yonghui Zhu,Nikhil Pinnaparaju,Hao Xiang Li,Nishaanth Kanna,Daniel Scott,Ryan Sullivan,Rose S. Shuman,Lucas de Alcântara,Herbie Bradley,Kirsty You,Bo Wu,Yuhao Jiang,Qimai Li,Jiaxin Chen,Louis Castricato,Xiaolong Zhu,Phillip Isola*

Main category: cs.LG

TL;DR: NeurIPS 2023 Neural MMO 대회 요약: 200명 이상 참가, 목표조건(goal-conditional) 정책으로 미학습 환경에 일반화. 상위 해법은 단일 RTX 4090에서 8시간 학습으로 베이스라인 대비 4배 성능. 소스 코드·모델·훈련 코드 모두 MIT 라이선스로 공개.


<details>
  <summary>Details</summary>
Motivation: 대규모 멀티에이전트 환경에서 목표 기반 정책의 일반화 능력과 실용적 훈련 파이프라인(짧은 학습시간·저비용 하드웨어)을 검증하고, 연구 공동체에 재현 가능한 벤치마크와 자원을 제공하기 위해.

Method: 참가자들은 Neural MMO 환경에서 목표조건(policy conditioned on goals) 강화학습 정책을 설계·훈련. 다양한 지도/맵/상대 등 미학습 환경으로의 일반화를 평가. 조직 측은 베이스라인 구현과 상위 제출물의 정책 가중치 및 훈련 코드를 공개하여 비교 가능성·재현성 확보.

Result: 200+ 참가자·제출, 최고 제출물이 단일 4090 GPU에서 8시간 학습으로 베이스라인 대비 4× 성능 달성. 모든 관련 코드와 모델이 MIT 라이선스로 공개되어 커뮤니티 재사용 가능.

Conclusion: Neural MMO는 실용적이고 재현 가능한 멀티에이전트 연구 플랫폼으로 자리잡았으며, 짧은 학습 시간·저비용으로도 강력한 성능을 낼 수 있음을 보여줌. 공개된 자원은 후속 연구 및 벤치마크 개선에 유용할 것.

Abstract: We present the results of the NeurIPS 2023 Neural MMO Competition, which
attracted over 200 participants and submissions. Participants trained
goal-conditional policies that generalize to tasks, maps, and opponents never
seen during training. The top solution achieved a score 4x higher than our
baseline within 8 hours of training on a single 4090 GPU. We open-source
everything relating to Neural MMO and the competition under the MIT license,
including the policy weights and training code for our baseline and for the top
submissions.

</details>


### [369] [Toward Architecture-Agnostic Local Control of Posterior Collapse in VAEs](https://arxiv.org/abs/2508.12530)
*Hyunsoo Song,Seungwhan Kim,Seungkyu Lee*

Main category: cs.LG

TL;DR: VAE의 posterior collapse 문제를 완화하기 위해 'local posterior collapse' 개념을 정의하고, 함수의 단사성(injective)·합성(composite) 성질에서 영감을 얻은 Latent Reconstruction(LR) 손실을 도입해 아키텍처 제약 없이 collapse를 제어한다. MNIST·FashionMNIST·Omniglot·CelebA·FFHQ에서 실험적으로 효과를 보였다.


<details>
  <summary>Details</summary>
Motivation: 기존 방법들은 정규화 항의 영향 조절(재구성 대 정규화의 트레이드오프)이나 잠재 식별성(identifiability)을 보장하려 하나, 전자는 균형이 불만족스럽고 후자는 네트워크 구조 제약을 필요로 한다. 이를 완화하고 개별 샘플 중요도를 반영하기 위해 'local posterior collapse'를 정의함.

Method: 함수의 단사성 및 합성 함수의 수학적 성질을 바탕으로 설계된 Latent Reconstruction(LR) 손실을 추가해 포스터리어가 퇴화되는 것을 억제한다. 아키텍처 제한 없이 기존 VAE에 적용 가능하도록 설계된 것으로 보인다.

Result: 여러 데이터셋(MNIST, fashionMNIST, Omniglot, CelebA, FFHQ)에서 posterior collapse 제어 효과를 보였다고 보고한다. (정량적 지표·비교는 초록에 없음)

Conclusion: LR 손실은 아키텍처 제약 없이도 posterior collapse를 완화할 수 있는 실용적 방법으로 제안됨.

Abstract: Variational autoencoders (VAEs), one of the most widely used generative
models, are known to suffer from posterior collapse, a phenomenon that reduces
the diversity of generated samples. To avoid posterior collapse, many prior
works have tried to control the influence of regularization loss. However, the
trade-off between reconstruction and regularization is not satisfactory. For
this reason, several methods have been proposed to guarantee latent
identifiability, which is the key to avoiding posterior collapse. However, they
require structural constraints on the network architecture. For further
clarification, we define local posterior collapse to reflect the importance of
individual sample points in the data space and to relax the network constraint.
Then, we propose Latent Reconstruction(LR) loss, which is inspired by
mathematical properties of injective and composite functions, to control
posterior collapse without restriction to a specific architecture. We
experimentally evaluate our approach, which controls posterior collapse on
varied datasets such as MNIST, fashionMNIST, Omniglot, CelebA, and FFHQ.

</details>


### [370] [Rethinking Safety in LLM Fine-tuning: An Optimization Perspective](https://arxiv.org/abs/2508.12531)
*Minseon Kim,Jin Myung Kwak,Lama Alssum,Bernard Ghanem,Philip Torr,David Krueger,Fazl Barez,Adel Bibi*

Main category: cs.LG

TL;DR: 파인튜닝 시 안전성 저하가 불가피하다는 통념에 반해, 저자들은 잘못된 최적화(하이퍼파라미터) 선택이 주요 원인이라고 주장한다. 적절한 학습률·배치·스텝 설정과 파라미터 공간에서의 EMA를 사용하면 유해 응답 비율을 키워드 기준으로 약 16%→5%로 낮출 수 있으며 유틸리티 손실 없이 안전성을 보존 가능하다는 결과를 Llama 계열과 여러 데이터셋에서 보인다.


<details>
  <summary>Details</summary>
Motivation: 파인튜닝이 사전학습 모델의 ‘유해한 요청 거부’ 능력을 손상시킨다는 통념을 검증하고, 필요 시 별도의 안전 데이터 없이도 안전성 저하를 피할 수 있는 실용적 방안을 제시하려 함.

Method: 학습률·배치사이즈·그라디언트 스텝 등 최적화 하이퍼파라미터를 체계적으로 탐색하고, 파라미터 공간에서 지수이동평균(EMA) 모멘텀을 적용해 안정적인 최적화 경로를 유지하도록 설계했다. Dolly/Alpaca/ORCA 데이터로 Llama 변형들을 파인튜닝하고 유해 응답률(키워드 매칭) 및 유틸리티 성능을 측정.

Result: 키워드 기반 측정 기준으로 비안전 응답을 16%에서 약 5%로 감소시키고, 유틸리티(성능) 손실을 거의 발생시키지 않음. EMA가 사전학습 모델의 안전 특성을 보존하는 데 효과적이며, 별도 안전 데이터 없이 기존 안전화 방법들보다 우수한 성능을 보였다고 보고.

Conclusion: 안전성 저하는 본질적 트레이드오프가 아니라 최적화 선택의 문제인 경우가 많으며, 적절한 하이퍼파라미터 설정과 파라미터-EMA만으로 파인튜닝 중 안전 문제를 상당 부분 회피할 수 있다.

Abstract: Fine-tuning language models is commonly believed to inevitably harm their
safety, i.e., refusing to respond to harmful user requests, even when using
harmless datasets, thus requiring additional safety measures. We challenge this
belief through systematic testing, showing that poor optimization choices,
rather than inherent trade-offs, often cause safety problems, measured as
harmful responses to adversarial prompts. By properly selecting key training
hyper-parameters, e.g., learning rate, batch size, and gradient steps, we
reduce unsafe model responses from 16\% to approximately 5\%, as measured by
keyword matching, while maintaining utility performance. Based on this
observation, we propose a simple exponential moving average (EMA) momentum
technique in parameter space that preserves safety performance by creating a
stable optimization path and retains the original pre-trained model's safety
properties. Our experiments on the Llama families across multiple datasets
(Dolly, Alpaca, ORCA) demonstrate that safety problems during fine-tuning can
largely be avoided without specialized interventions, outperforming existing
approaches that require additional safety data while offering practical
guidelines for maintaining both model performance and safety during adaptation.

</details>


### [371] [Defining and Benchmarking a Data-Centric Design Space for Brain Graph Construction](https://arxiv.org/abs/2508.12533)
*Qinwen Ge,Roza G. Bayrak,Anwar Said,Catie Chang,Xenofon Koutsoukos,Tyler Derr*

Main category: cs.LG

TL;DR: fMRI 기반 뇌 그래프 구성의 데이터 중심 설계공간(시간 신호 처리, 위상 추출, 그래프 피처화)을 체계화·벤치마크하여, 기존 표준 파이프라인 대비 분류 성능을 지속적으로 향상시킨다는 결과를 보임. 코드 공개.


<details>
  <summary>Details</summary>
Motivation: 현재 뇌 그래프 구축은 모델 중심 연구에 치우쳐 있고, 전처리·연결성 산출·피처화 등 데이터 처리 선택이 downstream 성능에 미치는 영향은 체계적으로 비교·최적화되지 않음. 데이터 중심 관점에서 이러한 선택들을 정의·평가할 필요가 있음.

Method: 설계공간을 세 단계(시간 신호 처리, 토폴로지 추출, 그래프 피처화)로 조직하고, 고진폭 BOLD 필터링, 희소화·통합 전략, 대체 상관계수(metric), 지연 동역학 포함한 멀티뷰 노드·엣지 피처 등 기존·수정 기법들의 조합을 대조 실험으로 평가. HCP1200·ABIDE 데이터셋에서 분류 실험을 수행.

Result: 데이터 중심으로 구성한 일부 설정들이 표준 파이프라인보다 분류 정확도를 꾸준히 개선. 특정 필터링·희소화·피처 조합이 성능 향상에 기여함. 코드와 재현 가능성 자료 공개.

Conclusion: 상류 데이터 결정이 그래프 기반 신경영상 분석 성능에 결정적이며, 모델 중심이 아닌 데이터 중심 설계공간의 체계적 탐색이 중요함.

Abstract: The construction of brain graphs from functional Magnetic Resonance Imaging
(fMRI) data plays a crucial role in enabling graph machine learning for
neuroimaging. However, current practices often rely on rigid pipelines that
overlook critical data-centric choices in how brain graphs are constructed. In
this work, we adopt a Data-Centric AI perspective and systematically define and
benchmark a data-centric design space for brain graph construction,
constrasting with primarily model-centric prior work. We organize this design
space into three stages: temporal signal processing, topology extraction, and
graph featurization. Our contributions lie less in novel components and more in
evaluating how combinations of existing and modified techniques influence
downstream performance. Specifically, we study high-amplitude BOLD signal
filtering, sparsification and unification strategies for connectivity,
alternative correlation metrics, and multi-view node and edge features, such as
incorporating lagged dynamics. Experiments on the HCP1200 and ABIDE datasets
show that thoughtful data-centric configurations consistently improve
classification accuracy over standard pipelines. These findings highlight the
critical role of upstream data decisions and underscore the importance of
systematically exploring the data-centric design space for graph-based
neuroimaging. Our code is available at
https://github.com/GeQinwen/DataCentricBrainGraphs.

</details>


### [372] [OS-R1: Agentic Operating System Kernel Tuning with Reinforcement Learning](https://arxiv.org/abs/2508.12551)
*Hongyu Lin,Yuchen Li,Haoran Luo,Kaichun Yao,Libo Zhang,Mingjie Xing,Yanjun Wu*

Main category: cs.LG

TL;DR: OS-R1은 규칙 기반 강화학습과 LLM을 결합해 리눅스 커널 튜닝을 에이전트 환경으로 추상화한 프레임워크로, 휴리스틱 대비 최대 5.6% 성능 향상과 높은 데이터 효율성을 보고한다.


<details>
  <summary>Details</summary>
Motivation: 기존 커널 튜닝 방법은 효율성(탐색 비용), 확장성(다양한 시나리오에 대한 일반화), 그리고 수정의 정확성 측면에서 한계를 보임. LLM의 추론 능력과 RL의 탐색/최적화 장점을 결합해 이를 개선하려는 필요성.

Method: 커널 설정 공간을 RL 환경으로 정의하고 LLM을 에이전트로 활용해 설정을 탐색·수정. 규칙(rule)-기반 RL로 설정 변경의 정확성 제어. 보상함수는 추론 표준화, 설정 변경 정확도, 시스템 성능 인식(성능 증가를 보상)에 중점. 또한 수렴 가속과 재학습 최소화를 위한 2단계(아마 사전학습·미세조정) 학습 프로세스 제안.

Result: 실험에서 휴리스틱 튜닝 대비 최대 5.6% 성능 향상, 높은 데이터 효율성 보고. 다양한 실제 응용에 적응 가능한 것으로 주장. 코드·데이터 공개.

Conclusion: OS-R1은 LLM 기반 에이전트와 규칙형 RL의 결합을 통해 실용적이고 데이터 효율적인 커널 튜닝 접근을 제시. 다만 하드웨어·워크로드 다양성, 장기 안정성, 오버헤드·안전성 평가 등 추가 검증 필요.

Abstract: Linux kernel tuning is essential for optimizing operating system (OS)
performance. However, existing methods often face challenges in terms of
efficiency, scalability, and generalization. This paper introduces OS-R1, an
agentic Linux kernel tuning framework powered by rule-based reinforcement
learning (RL). By abstracting the kernel configuration space as an RL
environment, OS-R1 facilitates efficient exploration by large language models
(LLMs) and ensures accurate configuration modifications. Additionally, custom
reward functions are designed to enhance reasoning standardization,
configuration modification accuracy, and system performance awareness of the
LLMs. Furthermore, we propose a two-phase training process that accelerates
convergence and minimizes retraining across diverse tuning scenarios.
Experimental results show that OS-R1 significantly outperforms existing
baseline methods, achieving up to 5.6% performance improvement over heuristic
tuning and maintaining high data efficiency. Notably, OS-R1 is adaptable across
various real-world applications, demonstrating its potential for practical
deployment in diverse environments. Our dataset and code are publicly available
at https://github.com/LHY-24/OS-R1.

</details>


### [373] [Illuminating LLM Coding Agents: Visual Analytics for Deeper Understanding and Enhancement](https://arxiv.org/abs/2508.12555)
*Junpeng Wang,Yuzhong Chen,Menghai Pan,Chin-Chia Michael Yeh,Mahashweta Das*

Main category: cs.LG

TL;DR: LLM 기반 코딩 에이전트의 반복적 코드 생성 과정을 시각화·비교할 수 있는 분석 시스템을 제안한다. 코드 수준, 프로세스 수준, LLM 수준의 3계층 분석을 제공해 에이전트의 디버깅·프롬프트 엔지니어링을 돕는다. Kaggle 사례 연구를 통해 유용성을 보였다.


<details>
  <summary>Details</summary>
Motivation: 코딩 에이전트(예: AIDE)가 자동으로 코드를 생성하는 동안 발생하는 여러 반복·분기 과정을 ML 과학자가 수작업으로 검토하기 어렵고 비효율적이다. 코드 진화 추적, 반복 비교, 개선 기회 식별이 어렵다는 실무적 난제가 존재한다.

Method: AIDE 프레임워크를 중심으로 한 시각분석 시스템을 설계했다. 세 가지 분석 수준을 제공한다: (1) 코드 수준: 반복별 디버깅·코드 개선 추적, (2) 프로세스 수준: 에이전트가 탐색한 다양한 문제 해결 경로 비교, (3) LLM 수준: 서로 다른 LLM들이 보이는 행동 차이 강조. 통합 뷰로 사용자가 구조화된 행동 이해를 얻도록 설계되었다.

Result: 여러 Kaggle 문제에 대한 사례 연구에서 시스템은 반복 간 코드 변화, 탐색 경로의 차이, LLM별 성향을 드러내어 디버깅 포인트와 프롬프트 개선 방향을 제시했다. 실무자에게 유의미한 인사이트를 제공함을 보였다.

Conclusion: 제안된 시각 분석 도구는 코딩 에이전트의 내부 동작을 더 잘 이해하게 하여 디버깅과 프롬프트 엔지니어링의 효율을 높이며, 에이전트 기반 자동화 워크플로우의 투명성 및 제어 가능성을 향상시킨다.

Abstract: Coding agents powered by large language models (LLMs) have gained traction
for automating code generation through iterative problem-solving with minimal
human involvement. Despite the emergence of various frameworks, e.g.,
LangChain, AutoML, and AIDE, ML scientists still struggle to effectively review
and adjust the agents' coding process. The current approach of manually
inspecting individual outputs is inefficient, making it difficult to track code
evolution, compare coding iterations, and identify improvement opportunities.
To address this challenge, we introduce a visual analytics system designed to
enhance the examination of coding agent behaviors. Focusing on the AIDE
framework, our system supports comparative analysis across three levels: (1)
Code-Level Analysis, which reveals how the agent debugs and refines its code
over iterations; (2) Process-Level Analysis, which contrasts different
solution-seeking processes explored by the agent; and (3) LLM-Level Analysis,
which highlights variations in coding behavior across different LLMs. By
integrating these perspectives, our system enables ML scientists to gain a
structured understanding of agent behaviors, facilitating more effective
debugging and prompt engineering. Through case studies using coding agents to
tackle popular Kaggle competitions, we demonstrate how our system provides
valuable insights into the iterative coding process.

</details>


### [374] [Deep Learning-Based Financial Time Series Forecasting via Sliding Window and Variational Mode Decomposition](https://arxiv.org/abs/2508.12565)
*Luke Li*

Main category: cs.LG

TL;DR: VMD로 시계열을 분해한 뒤 슬라이딩 윈도우로 입력 시퀀스를 만들고 LSTM에 학습시켜, 원시 시계열을 바로 쓰는 경우보다 예측 성능과 안정성이 개선되었다고 보고함.


<details>
  <summary>Details</summary>
Motivation: 금융 시계열의 비정상성·잡음·복잡성 때문에 직접 학습시킨 딥러닝 모델이 불안정하거나 성능이 낮을 수 있어, 더 부드러운 하위 성분으로 분해해 모델 적응성을 높이려는 것.

Method: 히스토리 가격과 마켓 지표로 데이터셋 구성 → 슬라이딩 윈도우로 시퀀스 생성 → VMD로 시계열을 다중 모드로 분해(노이즈 제거, 평활화) → 분해된 서브시퀀스를 LSTM에 입력해 예측. 원시 시계열을 그대로 쓴 LSTM과 성능 비교.

Result: VMD 전처리를 거친 LSTM이 원시 입력 LSTM보다 예측 정확도와 안정성 면에서 우수하다고 보고함(구체적 지표·값은 초록에 없음).

Conclusion: VMD를 통한 분해 기반 전처리가 금융 시계열 예측에서 유용하며, 모델 성능과 안정성을 개선할 수 있음.

Abstract: To address the complexity of financial time series, this paper proposes a
forecasting model combining sliding window and variational mode decomposition
(VMD) methods. Historical stock prices and relevant market indicators are used
to construct datasets. VMD decomposes non-stationary financial time series into
smoother subcomponents, improving model adaptability. The decomposed data is
then input into a deep learning model for prediction. The study compares the
forecasting effects of an LSTM model trained on VMD-processed sequences with
those using raw time series, demonstrating better performance and stability.

</details>


### [375] [Data-driven particle dynamics: Structure-preserving coarse-graining for emergent behavior in non-equilibrium systems](https://arxiv.org/abs/2508.12569)
*Quercus Hernandez,Max Win,Thomas C. O'Connor,Paulo E. Arratia,Nathaniel Trask*

Main category: cs.LG

TL;DR: 다단계(멀티스케일) 입자계에서 엔트로피성 상태변수를 자가지도학습으로 식별하고 메트리플렉틱(메트릭+플렉틱) 브래킷 구조를 이용해 열역학 보존·소멸·확률성 특성을 보장하는 저차원 조밀 모델을 학습한다.


<details>
  <summary>Details</summary>
Motivation: 고차원 입자 동역학을 저차원으로 조밀화할 때 정보 소실로 인해 발생하는 소멸성·기억효과·확률성(비평형 포함)을 물리적으로 일관되게 보존하는 모델이 필요하다.

Method: 메트릭(소멸)-플렉틱(해밀토니안) 브래킷 형식을 기반으로 이산적 열역학 법칙(에너지·엔트로피), 운동량 보존, 그리고 이산 플럭투에이션-디시페이션 균형을 구조적으로 강제하는 학습 프레임워크를 제안. 입자 이산화에 특화하고, 라벨이 없는 엔트로피성 변수는 자가지도 학습으로 식별.

Result: 벤치마크와 두 개의 도전적 사례(고도 조밀화된 스타 폴리머, 고속 비디오에서 얻은 콜로이드 서스펜션)에서 비평형 통계 재현성과 국부 재배열-확률 동역학 결합을 성공적으로 캡처. PyTorch·LAMMPS 구현 제공으로 대규모 추론 가능.

Conclusion: 구조적으로 열역학·운동량·플럭투에이션-디시페이션 균형을 보장하는 데이터 기반 조밀 모델 학습법을 제시하여 비평형·기억 효과를 가진 다중스케일 입자계 모델링에 실용적·확장성 있는 접근을 제공한다.

Abstract: Multiscale systems are ubiquitous in science and technology, but are
notoriously challenging to simulate as short spatiotemporal scales must be
appropriately linked to emergent bulk physics. When expensive high-dimensional
dynamical systems are coarse-grained into low-dimensional models, the entropic
loss of information leads to emergent physics which are dissipative,
history-dependent, and stochastic. To machine learn coarse-grained dynamics
from time-series observations of particle trajectories, we propose a framework
using the metriplectic bracket formalism that preserves these properties by
construction; most notably, the framework guarantees discrete notions of the
first and second laws of thermodynamics, conservation of momentum, and a
discrete fluctuation-dissipation balance crucial for capturing non-equilibrium
statistics. We introduce the mathematical framework abstractly before
specializing to a particle discretization. As labels are generally unavailable
for entropic state variables, we introduce a novel self-supervised learning
strategy to identify emergent structural variables. We validate the method on
benchmark systems and demonstrate its utility on two challenging examples: (1)
coarse-graining star polymers at challenging levels of coarse-graining while
preserving non-equilibrium statistics, and (2) learning models from high-speed
video of colloidal suspensions that capture coupling between local
rearrangement events and emergent stochastic dynamics. We provide open-source
implementations in both PyTorch and LAMMPS, enabling large-scale inference and
extensibility to diverse particle-based systems.

</details>


### [376] [Deep Learning Model for Amyloidogenicity Prediction using a Pre-trained Protein LLM](https://arxiv.org/abs/2508.12575)
*Zohra Yagoub,Hafida Bouziane*

Main category: cs.LG

TL;DR: 사전 학습된 단백질 LLM로부터 얻은 서열 컨텍스트 특징을 BiLSTM/GRU 기반 분류기에 입력해 아밀로이드성 영역을 예측했으며, 10겹 교차검증 84.5%, 테스트 83%의 정확도를 얻어 경쟁력 있는 성능을 보였음.


<details>
  <summary>Details</summary>
Motivation: 단백질·펩타이드의 아밀로이드성 예측은 생물정보학에서 중요하며, 진화적 모티프나 아미노산 특성보다 서열 기반 컨텍스트 특징이 높은 예측 성능을 보이는 경향이 있어 LLM 기반 표현을 평가하려 함.

Method: 사전학습된 단백질 LLM으로부터 서열의 문맥적 임베딩을 추출하고, 이를 BiLSTM 및 GRU 네트워크(양방향 LSTM 포함)에 입력하여 아밀로이드성 영역을 분류하도록 학습시킴. 성능 평가는 10겹 교차검증 및 별도 테스트셋에서 정확도로 수행됨.

Result: 10겹 교차검증에서 정확도 84.5%, 독립 테스트셋에서 정확도 83%를 달성하여 기존 시퀀스 기반 접근법과 경쟁 가능한 성능을 보임.

Conclusion: LLM으로부터 얻은 시퀀스 컨텍스트 특징은 아밀로이드 예측 성능을 향상시키는 데 유용하며, LLM 기반 표현이 이 분야에서 유망함을 시사함.

Abstract: The prediction of amyloidogenicity in peptides and proteins remains a focal
point of ongoing bioinformatics. The crucial step in this field is to apply
advanced computational methodologies. Many recent approaches to predicting
amyloidogenicity within proteins are highly based on evolutionary motifs and
the individual properties of amino acids. It is becoming increasingly evident
that the sequence information-based features show high predictive performance.
Consequently, our study evaluated the contextual features of protein sequences
obtained from a pretrained protein large language model leveraging
bidirectional LSTM and GRU to predict amyloidogenic regions in peptide and
protein sequences. Our method achieved an accuracy of 84.5% on 10-fold
cross-validation and an accuracy of 83% in the test dataset. Our results
demonstrate competitive performance, highlighting the potential of LLMs in
enhancing the accuracy of amyloid prediction.

</details>


### [377] [Widening the Network Mitigates the Impact of Data Heterogeneity on FedAvg](https://arxiv.org/abs/2508.12576)
*Like Jian,Dong Liu*

Main category: cs.LG

TL;DR: 폭넓게 과매개변된(너비가 큰) 신경망에서 FedAvg+GD의 데이터 이질성 효과는 사라지고, 무한너비에서는 전역·지역 모델이 선형화되어 중앙집중식 학습과 동일한 일반화 성능을 낸다.


<details>
  <summary>Details</summary>
Motivation: 연합학습은 클라이언트 간 비동일(Non-IID) 데이터로 인해 전역 모델의 수렴성과 일반화에 문제가 발생한다. 논문은 과매개변수화가 이러한 이질성 문제를 완화할 수 있는지를 이론적으로 규명하려 함.

Method: 과매개변수화된(너비가 큰) 네트워크에서 FedAvg 알고리즘과 GD의 수렴 특성을 이론적으로 분석. 무한너비(Neural Tangent Kernel 유사) 극한에서 모델의 선형화 및 FedAvg의 거동을 증명하고, 다양한 아키텍처·손실·최적화 설정에서 실험으로 검증.

Result: 네트워크 너비가 증가할수록 데이터 이질성의 영향이 감소하며, 너비가 무한대일 때 이 영향은 사라짐. 무한너비에서는 전역·지역 모델이 선형 모델로 행동하고, 동일한 GD 반복 횟수에서 FedAvg는 중앙집중식 학습과 동일한 일반화 성능을 달성. 실험이 이론적 주장과 일치함.

Conclusion: 과매개변수화는 연합학습에서 데이터 이질성의 부정적 영향을 완화하여 FedAvg가 중앙집중식 학습 수준까지 성능을 회복하게 한다. 이는 모델 너비를 확장하는 것이 FL에서 실용적 해법이 될 수 있음을 시사한다.

Abstract: Federated learning (FL) enables decentralized clients to train a model
collaboratively without sharing local data. A key distinction between FL and
centralized learning is that clients' data are non-independent and identically
distributed, which poses significant challenges in training a global model that
generalizes well across heterogeneous local data distributions. In this paper,
we analyze the convergence of overparameterized FedAvg with gradient descent
(GD). We prove that the impact of data heterogeneity diminishes as the width of
neural networks increases, ultimately vanishing when the width approaches
infinity. In the infinite-width regime, we further prove that both the global
and local models in FedAvg behave as linear models, and that FedAvg achieves
the same generalization performance as centralized learning with the same
number of GD iterations. Extensive experiments validate our theoretical
findings across various network architectures, loss functions, and optimization
methods.

</details>


### [378] [Energy-Efficient Wireless LLM Inference via Uncertainty and Importance-Aware Speculative Decoding](https://arxiv.org/abs/2508.12590)
*Jihoon Park,Seungeun Oh,Seong-Lyun Kim*

Main category: cs.LG

TL;DR: 경량 로컬 모델과 클라우드 LLM을 결합한 하이브리드 언어모델(HLM)에 대해, 토큰 수준에서 중요도와 불확실도를 이용해 유의미한 토큰만 업로드하도록 필터링해 통신·에너지 효율을 개선하는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 엣지·리소스 제한 환경에서 온디바이스 LLM 추론 수요가 증가하는 상황에서, 기존 HLM 연구들이 정확도와 지연 시간에만 치중하고 통신비용·에너지 효율은 간과하는 문제를 해결하려 함.

Method: 에피스테믹 불확실도(모델 불확실성)와 어텐션 기반 중요도를 결합한 토큰 수준 필터를 도입해 '정보성 높은' 토큰만 클라우드 LLM로 전송. 기회적 업로드로 LLM 호출 횟수와 통신량을 감소시킴.

Result: TinyLlama-1.1B + LLaMA-2-7B 환경에서 최대 BERTScore 87.5%, 토큰 처리율 0.37 토큰/초, 표준 HLM 대비 에너지 소비 40.7% 절감. 이전 U-HLM 대비 BERTScore 85.8→87.0, 에너지 절감 31.6→43.6%, 처리율 0.36→0.40로 개선.

Conclusion: 제안한 토큰 필터링은 대역폭 제약 엣지 환경에서 통신·에너지 비용을 절감하면서도 높은 응답 품질을 유지해 HLM의 실용적 배치를 촉진함.

Abstract: To address the growing demand for on-device LLM inference in
resource-constrained environments, hybrid language models (HLM) have emerged,
combining lightweight local models with powerful cloud-based LLMs. Recent
studies on HLM have primarily focused on improving accuracy and latency, while
often overlooking communication and energy efficiency. We propose a token-level
filtering mechanism for an energy-efficient importance- and uncertainty-aware
HLM inference that leverages both epistemic uncertainty and attention-based
importance. Our method opportunistically uploads only informative tokens,
reducing LLM usage and communication costs. Experiments with TinyLlama-1.1B and
LLaMA-2-7B demonstrate that our method achieves up to 87.5% BERT Score and
token throughput of 0.37 tokens/sec while saving the energy consumption by
40.7% compared to standard HLM. Furthermore, compared to our previous U-HLM
baseline, our method improves BERTScore from 85.8% to 87.0%, energy savings
from 31.6% to 43.6%, and throughput from 0.36 to 0.40. This approach enables an
energy-efficient and accurate deployment of LLMs in bandwidth-constrained edge
environments.

</details>


### [379] [Physics-informed deep operator network for traffic state estimation](https://arxiv.org/abs/2508.12593)
*Zhihao Li,Ting Wang,Guojian Zou,Ruofei Wang,Ye Li*

Main category: cs.LG

TL;DR: PI-DeepONet을 사용해 교통 상태 추정을 연산자 학습 문제로 재정식화. 보존법칙과 기본다이어그램을 학습 과정에 직접 통합해 물리적 일관성을 보장하고 NGSIM 데이터에서 기존 기법들보다 우수한 성능을 보임.


<details>
  <summary>Details</summary>
Motivation: 제한적이고 노이즈가 있는 관측에서 고차원 시공간 PDE(교통 흐름 보존법칙)를 풀어야 하는 TSE 문제. PINN은 PDE를 점 단위로 강제하지만 연산자 수준의 매핑 학습이 더 효율적일 수 있음.

Method: Physics-informed DeepONet(PI-DeepONet)을 설계하여 희소한 입력(센서/관측)에서 전체 시공간 교통 상태장으로 매핑하는 신경 연산자를 학습. 보존법칙과 교통 기본다이어그램을 손실/제약으로 직접 통합. 브랜치·트렁크 네트워크 구조, 함수 생성 전략 및 브랜치 복잡도 등을 실험적으로 탐색.

Result: NGSIM 데이터셋에서 기존 최첨단 방법들보다 더 나은 추정 정확도와 물리적 일관성(정체 전파, 공간 상관성, 시간적 진화 캡처)을 달성. 입력 함수 생성 방법과 함수 수에 대한 민감도 분석에서 높은 강건성 및 최적 설계 지침 도출.

Conclusion: PI-DeepONet은 물리적 제약을 유지하면서 효율적·정확한 TSE를 가능하게 함. 아키텍처·입력 생성 관련 실용적 통찰을 제공하며 실시간 적용, 불확실성 정량화 등으로 확장 가능하다.

Abstract: Traffic state estimation (TSE) fundamentally involves solving
high-dimensional spatiotemporal partial differential equations (PDEs) governing
traffic flow dynamics from limited, noisy measurements. While Physics-Informed
Neural Networks (PINNs) enforce PDE constraints point-wise, this paper adopts a
physics-informed deep operator network (PI-DeepONet) framework that
reformulates TSE as an operator learning problem. Our approach trains a
parameterized neural operator that maps sparse input data to the full
spatiotemporal traffic state field, governed by the traffic flow conservation
law. Crucially, unlike PINNs that enforce PDE constraints point-wise,
PI-DeepONet integrates traffic flow conservation model and the fundamental
diagram directly into the operator learning process, ensuring physical
consistency while capturing congestion propagation, spatial correlations, and
temporal evolution. Experiments on the NGSIM dataset demonstrate superior
performance over state-of-the-art baselines. Further analysis reveals insights
into optimal function generation strategies and branch network complexity.
Additionally, the impact of input function generation methods and the number of
functions on model performance is explored, highlighting the robustness and
efficacy of proposed framework.

</details>


### [380] [FLARE: Fast Low-rank Attention Routing Engine](https://arxiv.org/abs/2508.12594)
*Vedant Puri,Aditya Joglekar,Kevin Ferguson,Yu-hsuan Chen,Yongjie Jessica Zhang,Levent Burak Kara*

Main category: cs.LG

TL;DR: FLARE는 고정 길이의 잠재(latent) 시퀀스를 통해 어텐션을 라우팅해 O(N^2)에서 O(NM)으로 복잡도를 낮춘 선형 시간(self-)어텐션 기법이다. M << N인 병목 시퀀스에 입력을 투사하는 방식으로 대규모 비정형 메쉬에서 확장 가능하며, 여러 PDE 대체모델 벤치마크에서 SOTA보다 우수한 성능을 보고한다. 코드와 신규 적층제조 데이터셋을 공개함.


<details>
  <summary>Details</summary>
Motivation: 자유 형식(unstructured) 메쉬에서 토큰 수 N이 매우 클 때 기존의 쿼리·키·밸류 기반 어텐션의 O(N^2) 복잡도가 병목이 되어 대규모 문제에 적용하기 어렵다. 이를 해결할 저비용의 전역 정보 교환 메커니즘이 필요하다.

Method: 각 어텐션 헤드는 학습 가능한 쿼리 토큰들을 사용해 원본 길이 N의 시퀀스를 길이 M (M << N)의 고정 잠재 시퀀스로 투사한다. 어텐션은 이 잠재 시퀀스를 통해 라우팅되어 병목을 형성하며, 결과적으로 낮은 랭크 형태의 어텐션을 학습해 O(NM) 비용으로 글로벌 통신을 수행한다.

Result: FLARE는 매우 큰 문제 규모로 확장 가능하며, 여러 신경 PDE 대체모델(모델링 유체/열/재료 시뮬레이션 등) 벤치마크에서 최첨단 기법들보다 우수한 정확도를 보였다고 보고한다. 추가로 적층제조(additive manufacturing) 데이터셋을 공개하고 코드를 배포했다.

Conclusion: 고정 길이의 학습 가능한 잠재 라우팅을 통해 어텐션의 계산 복잡도를 선형화하면서도 실무 문제(특히 대규모 비정형 메쉬 기반 PDE 근사)에 대해 경쟁력 있는 성능을 달성한다. M의 선택, 병목에 의한 정보 손실과 같은 실용적 요소를 평가할 필요가 있다.

Abstract: The quadratic complexity of self-attention limits its applicability and
scalability on large unstructured meshes. We introduce Fast Low-rank Attention
Routing Engine (FLARE), a linear complexity self-attention mechanism that
routes attention through fixed-length latent sequences. Each attention head
performs global communication among $N$ tokens by projecting the input sequence
onto a fixed length latent sequence of $M \ll N$ tokens using learnable query
tokens. By routing attention through a bottleneck sequence, FLARE learns a
low-rank form of attention that can be applied at $O(NM)$ cost. FLARE not only
scales to unprecedented problem sizes, but also delivers superior accuracy
compared to state-of-the-art neural PDE surrogates across diverse benchmarks.
We also release a new additive manufacturing dataset to spur further research.
Our code is available at https://github.com/vpuri3/FLARE.py.

</details>


### [381] [Constructing Invariant and Equivariant Operations by Symmetric Tensor Network](https://arxiv.org/abs/2508.12596)
*Meng Zhang,Chao Wang,Hao Zhang,Shaojun Dong,Lixin He*

Main category: cs.LG

TL;DR: A systematic framework to construct invariant and equivariant operations for inputs/outputs given as Cartesian and spherical tensors of various ranks/types, using symmetric tensor networks and a graphical representation; applied to equivariant interaction messages in geometry GNNs and to learning constitutive material laws.


<details>
  <summary>Details</summary>
Motivation: Designing neural networks that respect geometric symmetries requires valid invariant/equivariant operations for tensor-valued data; existing ad-hoc constructions lack a unified, general method for different tensor types and ranks.

Method: Provide a systematic algebraic construction of invariant/equivariant maps using symmetric tensor networks, representable graphically to simplify proofs and design. The approach handles Cartesian tensors (various ranks) and spherical tensors (various types) and yields explicit building blocks for equivariant modules (e.g., interaction messages).

Result: A unified set of valid invariant and equivariant operations, a graphical/symmetric-tensor-network formalism, demonstration of an equivariant interaction message for geometry GNNs, and an equivariant ML model trained to learn constitutive laws of materials (empirical validation implied).

Conclusion: The method unifies and simplifies constructing equivariant/invariant functions across tensor types and ranks, offers a usable graphical toolkit for geometric deep learning, and shows practical utility in GNN modules and material law learning.

Abstract: Design of neural networks that incorporate symmetry is crucial for geometric
deep learning. Central to this effort is the development of invariant and
equivariant operations. This works presents a systematic method for
constructing valid invariant and equivariant operations. It can handle inputs
and outputs in the form of Cartesian tensors with different rank, as well as
spherical tensors with different types. In addition, our method features a
graphical representation utilizing the symmetric tensor network, which
simplifies both the proofs and constructions related to invariant and
equivariant functions. We also apply this approach to design the equivariant
interaction message for the geometry graph neural network, and equivariant
machine learning model to learn the constitutive law of materials.

</details>


### [382] [A Hybrid Surrogate for Electric Vehicle Parameter Estimation and Power Consumption via Physics-Informed Neural Operators](https://arxiv.org/abs/2508.12602)
*Hansol Lim,Jongseong Brad Choi,Jee Won Lee,Haeseong Jeoung,Minkyu Han*

Main category: cs.LG

TL;DR: 속도와 가속도만으로 시간에 따라 변하는 전기차 파라미터(모터·회생 제동 효율, 공기저항, 구름저항, 유효질량, 보조전력)를 출력하는 하이브리드 서로게이트 모델을 제안. Fourier Neural Operator 기반의 Spectral Parameter Operator로 전역 문맥을 캡처하고, 순전파에 물리적으로 미분 가능한 모듈을 포함해 배터리 전력을 물리법칙으로 직접 예측함. Tesla와 Kia 실제 주행 로그에서 평균 절대 오차가 Tesla는 0.2 kW(고속 주행 견인력의 약 1%), Kia는 약 0.8 kW를 기록. 해석 가능하고 샘플링·조건 변화에 강해 경로 최적화, 에코 라우팅, 온보드 진단 등에 실용적.


<details>
  <summary>Details</summary>
Motivation: 정확하고 해석 가능한 차량 파라미터 추정 및 전력 소비 예측은 경로 최적화, 에너지 관리, 진단·예지보수에 필수적이나, 순수 데이터 기반 모델은 물리적 일관성·일반화에 한계가 있고 순수 물리모델은 모델링 복잡도·비선형성에 제한이 있음. 이를 해결하기 위해 학습 기반 표현력과 물리 기반 제약을 결합한 하이브리드 모델을 목표로 함.

Method: Fourier Neural Operator(FNO)을 백본으로 하는 Spectral Parameter Operator를 도입해 전역 시공간 문맥을 학습하고, 순전파에 미분 가능한 물리 모듈을 삽입해 학습된 파라미터들을 물리식으로 배터리 전력에 바로 연결함. 입력은 속도·가속도만 사용하며, 출력은 시간 가변 파라미터들. 별도의 물리-잔차 손실 없이 물리 내장으로 전력 오차를 최소화하도록 학습.

Result: 실차 로그(Tesla Model 3, Model S, Kia EV9)에서 Tesla에 대해 평균 절대 오차 0.2 kW, Kia에 대해 약 0.8 kW 달성. Tesla의 경우 고속 주행 시 평균 견인력의 약 1% 수준으로 매우 낮은 오차를 보고. 샘플링율·운행 조건 변화에 대한 일반화성과 모델 해석성(물리적 의미를 갖는 파라미터 수렴)을 주장.

Conclusion: 스펙트럼 기반 표현과 물리 내장 모듈의 결합으로 실용적이고 해석 가능한 EV 파라미터·전력 추정기법을 제시. 경로 최적화·에코 라우팅·차량 진단 및 예지보전 등 실제 응용에 적합하며, 보편성·일반화 성능도 우수함을 보임.

Abstract: We present a hybrid surrogate model for electric vehicle parameter estimation
and power consumption. We combine our novel architecture Spectral Parameter
Operator built on a Fourier Neural Operator backbone for global context and a
differentiable physics module in the forward pass. From speed and acceleration
alone, it outputs time-varying motor and regenerative braking efficiencies, as
well as aerodynamic drag, rolling resistance, effective mass, and auxiliary
power. These parameters drive a physics-embedded estimate of battery power,
eliminating any separate physics-residual loss. The modular design lets
representations converge to physically meaningful parameters that reflect the
current state and condition of the vehicle. We evaluate on real-world logs from
a Tesla Model 3, Tesla Model S, and the Kia EV9. The surrogate achieves a mean
absolute error of 0.2kW (about 1% of average traction power at highway speeds)
for Tesla vehicles and about 0.8kW on the Kia EV9. The framework is
interpretable, and it generalizes well to unseen conditions, and sampling
rates, making it practical for path optimization, eco-routing, on-board
diagnostics, and prognostics health management.

</details>


### [383] [SSPO: Self-traced Step-wise Preference Optimization for Process Supervision and Reasoning Compression](https://arxiv.org/abs/2508.12604)
*Yuyang Xu,Yi Cheng,Haochao Ying,Zhuoyun Du,Renjun Hu,Xing Shi,Wei Lin,Jian Wu*

Main category: cs.LG

TL;DR: SSPO (Self-traced Step-wise Preference Optimization) is a pluggable RL supervision framework that uses model-generated, step-wise preference signals to optimize each chain-of-thought step, compress reasoning, and reduce overthinking without auxiliary models or manual step annotations.


<details>
  <summary>Details</summary>
Motivation: Pretrained LLMs with chain-of-thought can produce verbose multi-step reasoning that accumulates errors (overthinking). Existing post-training approaches (RLHF with CoT) are effective but require extra models and heavy compute; the paper aims to provide a lightweight method to fix stepwise errors and reduce verbosity.

Method: Introduce a self-traced, step-wise preference signal produced by the model itself to guide reinforcement learning-style optimization of each reasoning step. The method is pluggable, requires no auxiliary models or manual step labeling, and explicitly compresses reasoning by rewarding succinct, correct step transitions.

Result: Experiments show SSPO produces reasoning sequences that are both more accurate and more succinct, mitigating overthinking while preserving overall task performance across multiple domains and languages.

Conclusion: SSPO offers an efficient alternative to mainstream post-training methods: it fine-grainedly optimizes reasoning steps using self-generated preferences, lowering computational cost and improving reasoning quality without external models or stepwise human labels.

Abstract: Test-time scaling has proven effective in further enhancing the performance
of pretrained Large Language Models (LLMs). However, mainstream post-training
methods (i.e., reinforcement learning (RL) with chain-of-thought (CoT)
reasoning) often incur substantial computational overhead due to auxiliary
models and overthinking. In this paper, we empirically reveal that the
incorrect answers partially stem from verbose reasoning processes lacking
correct self-fix, where errors accumulate across multiple reasoning steps. To
this end, we propose Self-traced Step-wise Preference Optimization (SSPO), a
pluggable RL process supervision framework that enables fine-grained
optimization of each reasoning step. Specifically, SSPO requires neither
auxiliary models nor stepwise manual annotations. Instead, it leverages
step-wise preference signals generated by the model itself to guide the
optimization process for reasoning compression. Experiments demonstrate that
the generated reasoning sequences from SSPO are both accurate and succinct,
effectively mitigating overthinking behaviors without compromising model
performance across diverse domains and languages.

</details>


### [384] [How can we trust opaque systems? Criteria for robust explanations in XAI](https://arxiv.org/abs/2508.12623)
*Florian J. Boge,Annika Schuster*

Main category: cs.LG

TL;DR: 딥러닝 설명가능성(XAI)에서 ‘설명의 견고성(ER)’과 ‘설명방법의 견고성(EMR)’을 구분·정의하여, 신뢰할 수 있는 설명을 위해 EMR이 ER보다 선행되어야 한다고 주장한다. 이론적 정식화와 사례·향후 연구 방향을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 딥러닝은 높은 예측 성능을 보이지만 내부 작동이 불투명해 신뢰 가능한 설명이 필요하다. 기존 XAI 기법들이 서로 다르거나 모두 같은(그러나 잘못된) 설명을 줄 수 있어 설명의 신뢰성에 의문이 제기된다.

Method: ER과 EMR에 대한 형식적 정의를 제시하고, 서로 다른 XAI 기법 간의 일관성(ER)과 개별 기법의 안정성(EMR)을 평가할 수 있는 개념적·수학적 틀을 개발한다. 사례 분석과 적용 가능성 논의를 통해 기준 적용을 보여준다.

Result: ER만으로는 신뢰를 보장할 수 없으며, EMR이 먼저 충족되어야 여러 방법이 동의하는 결과(ER)가 의미가 있음을 보였다. 여러 기법이 EMR을 만족하지 못하는 경우와 그 영향에 대한 논의가 포함된다.

Conclusion: 신뢰 가능한 XAI를 위해 ER과 함께 EMR을 평가하는 체계가 필요하다. 연구자들은 EMR 검증을 우선시하고, 향후 실험적·이론적 연구와 벤치마크 개발이 요구된다.

Abstract: Deep learning (DL) algorithms are becoming ubiquitous in everyday life and in
scientific research. However, the price we pay for their impressively accurate
predictions is significant: their inner workings are notoriously opaque - it is
unknown to laypeople and researchers alike what features of the data a DL
system focuses on and how it ultimately succeeds in predicting correct outputs.
A necessary criterion for trustworthy explanations is that they should reflect
the relevant processes the algorithms' predictions are based on. The field of
eXplainable Artificial Intelligence (XAI) presents promising methods to create
such explanations. But recent reviews about their performance offer reasons for
skepticism. As we will argue, a good criterion for trustworthiness is
explanatory robustness: different XAI methods produce the same explanations in
comparable contexts. However, in some instances, all methods may give the same,
but still wrong, explanation. We therefore argue that in addition to
explanatory robustness (ER), a prior requirement of explanation method
robustness (EMR) has to be fulfilled by every XAI method. Conversely, the
robustness of an individual method is in itself insufficient for
trustworthiness. In what follows, we develop and formalize criteria for ER as
well as EMR, providing a framework for explaining and establishing trust in DL
algorithms. We also highlight interesting application cases and outline
directions for future work.

</details>


### [385] [FlowMol3: Flow Matching for 3D De Novo Small-Molecule Generation](https://arxiv.org/abs/2508.12629)
*Ian Dunn,David R. Koes*

Main category: cs.LG

TL;DR: FlowMol3는 기존 그래프 신경망이나 흐름 매칭 공식 변경 없이, 자기-컨디셔닝, 가짜 원자(fake atoms), 학습 시 기하학 왜곡(train-time geometry distortion)이라는 세 가지 간단한 기법으로 소분자의 모든 원자 포함 3D 생성 성능을 크게 끌어올린 다중모달 흐름 매칭 생성모델이다. 거의 100%의 분자 유효성, 학습 데이터의 관능기 구성과 기하 재현성 향상, 파라미터 수 대폭 감소를 달성한다.


<details>
  <summary>Details</summary>
Motivation: 현실적인 3D 구조와 분자 토폴로지를 동시에 샘플링할 수 있는 생성모델은 신약발견 등에서 큰 효율을 제공한다. 기존 흐름/확산 기반 모델들은 안정성·유효성 문제와 많은 파라미터·계산비용이라는 한계를 갖고 있어, 저비용으로 성능을 개선하는 방법을 찾는 것이 목표이다.

Method: 기존 FlowMol 아키텍처와 흐름 매칭 프레임워크를 유지하면서 아키텍처-무관한 세 가지 기법을 도입: (1) 자기-컨디셔닝(self-conditioning)으로 이전 출력 정보를 조건으로 사용해 안정성 향상, (2) 가짜 원자(fake atoms)를 도입해 모델이 원자 존재 여부와 위치를 더 잘 구분하도록 학습, (3) 학습 시 기하학 왜곡으로 모델의 강건성 및 분포 드리프트 감지·수정 능력 향상. 이들은 추가 계산비용이 거의 없다.

Result: 약물 유사 분자(명시적 수소 포함)에서 거의 100% 유효성 달성, 학습 데이터의 관능기 조성 및 기하학적 특성 재현성 향상, 기존 방법 대비 파라미터 수가 한 자릿수 적음. 제안기법들이 운송 기반 생성모델의 분포 드리프트 병리(pathology)를 완화한다고 가정.

Conclusion: 간단하고 전이 가능한 세 가지 기법으로 흐름·확산 기반 분자 3D 생성의 안정성과 품질을 크게 개선할 수 있으며, 이는 작은 계산 오버헤드로 실용적인 분자 생성 모델 개발에 기여한다.

Abstract: A generative model capable of sampling realistic molecules with desired
properties could accelerate chemical discovery across a wide range of
applications. Toward this goal, significant effort has focused on developing
models that jointly sample molecular topology and 3D structure. We present
FlowMol3, an open-source, multi-modal flow matching model that advances the
state of the art for all-atom, small-molecule generation. Its substantial
performance gains over previous FlowMol versions are achieved without changes
to the graph neural network architecture or the underlying flow matching
formulation. Instead, FlowMol3's improvements arise from three
architecture-agnostic techniques that incur negligible computational cost:
self-conditioning, fake atoms, and train-time geometry distortion. FlowMol3
achieves nearly 100% molecular validity for drug-like molecules with explicit
hydrogens, more accurately reproduces the functional group composition and
geometry of its training data, and does so with an order of magnitude fewer
learnable parameters than comparable methods. We hypothesize that these
techniques mitigate a general pathology affecting transport-based generative
models, enabling detection and correction of distribution drift during
inference. Our results highlight simple, transferable strategies for improving
the stability and quality of diffusion- and flow-based molecular generative
models.

</details>


### [386] [Score-informed Neural Operator for Enhancing Ordering-based Causal Discovery](https://arxiv.org/abs/2508.12650)
*Jiyeon Kang,Songseong Kim,Chanhui Lee,Doyeong Hwang,Joanie Hayoun Chung,Yunkyung Ko,Sumin Lee,Sungwoong Kim,Sungbin Lim*

Main category: cs.LG

TL;DR: SciNO는 그래프의 인과 순서 탐지에서 로그 밀도의 헤시안 대각을 안정적으로 근사하는 확률적 생성 모델이다. Stein 기반 추정과 DiffAN의 수치 불안정을 해결하며 메모리 효율성과 확장성을 유지한다.


<details>
  <summary>Details</summary>
Motivation: Ordering 기반 인과 탐지(특히 ANM 가정)에서 스코어 매칭에 필요한 헤시안 대각 추정은 결과에 민감하고 기존 Stein 추정은 계산·메모리 비용이 크다. DiffAN은 커널을 대체하였으나 스코어 모델의 2차 도함수로 인해 여전히 불안정하다.

Method: Smooth 함수 공간에서 작동하는 Score-informed Neural Operator(SciNO)를 제안하여 헤시안 대각을 확률적으로 모형화하고 구조적 정보를 보존한다. 또한 SciNO의 확률 추정과 자기회귀 모델 우 prior를 결합한 확률적 제어 알고리즘을 제안해 의미 기반 정보를 이용한 데이터 주도 인과 순서를 산출한다.

Result: 합성 그래프에서 순서 발산(order divergence)을 DiffAN 대비 평균 42.7% 감소, 실세계 데이터에서 평균 31.5% 감소를 보고하며 메모리 효율성과 확장성을 유지함. LLM과의 통합으로 추가 미세조정 없이 인과 추론 능력 향상을 보임.

Conclusion: SciNO는 헤시안 대각 근사에서 수치 안정성과 구조 보존을 제공해 기존 방법들보다 더 정확하고 안정적인 인과 순서 추정 및 LLM 기반 인과 추론 향상을 가능하게 한다.

Abstract: Ordering-based approaches to causal discovery identify topological orders of
causal graphs, providing scalable alternatives to combinatorial search methods.
Under the Additive Noise Model (ANM) assumption, recent causal ordering methods
based on score matching require an accurate estimation of the Hessian diagonal
of the log-densities. However, previous approaches mainly use Stein gradient
estimators, which are computationally expensive and memory-intensive. Although
DiffAN addresses these limitations by substituting kernel-based estimates with
diffusion models, it remains numerically unstable due to the second-order
derivatives of score models. To alleviate these problems, we propose
Score-informed Neural Operator (SciNO), a probabilistic generative model in
smooth function spaces designed to stably approximate the Hessian diagonal and
to preserve structural information during the score modeling. Empirical results
show that SciNO reduces order divergence by 42.7% on synthetic graphs and by
31.5% on real-world datasets on average compared to DiffAN, while maintaining
memory efficiency and scalability. Furthermore, we propose a probabilistic
control algorithm for causal reasoning with autoregressive models that
integrates SciNO's probability estimates with autoregressive model priors,
enabling reliable data-driven causal ordering informed by semantic information.
Consequently, the proposed method enhances causal reasoning abilities of LLMs
without additional fine-tuning or prompt engineering.

</details>


### [387] [Robust Federated Learning under Adversarial Attacks via Loss-Based Client Clustering](https://arxiv.org/abs/2508.12672)
*Emmanouil Kritharakis,Dusan Jakovetic,Antonios Makris,Konstantinos Tserpes*

Main category: cs.LG

TL;DR: 신뢰할 수 있는 서버가 소량의 신뢰 데이터(또는 신뢰 클라이언트)를 갖는 연합학습(FL) 환경에서, 서버 측 데이터로 클라이언트 업데이트를 검증·보정해 비잔틴(악의적) 클라이언트가 다수일지라도, 서버와 최소 한 명의 정직한 클라이언트만으로 작동하는 강건한 알고리즘을 제시한다. 이론적 유계 최적성 간극을 보이며, MNIST/FMNIST/CIFAR-10에서 여러 공격(라벨·사인 플립, 가우시안 노이즈)에 대해 기존 평균·절단·중앙값·Krum 계열보다 우수한 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 실제 FL에서는 다수의 클라이언트가 악의적일 수 있으나 서버가 신뢰할 수 있고 소량의 품질 보증된 데이터(또는 신뢰 클라이언트)를 보유한 사례가 존재한다. 이런 상황에서 사전에 악성 클라이언트 수를 알지 못해도 소수의 정직 참가자만으로 안전하게 학습을 진행할 수 있는 방법이 필요하다.

Method: 서버의 신뢰 데이터(또는 신뢰 클라이언트 역할)를 이용해 클라이언트 업데이트를 검증·재가중치하거나 필터링하는 방식으로 집계(aggregation)를 수행한다. 구체적 기술 세부사항은 추상에 명시되지 않았으나, 서버 기반 검증을 통해 악성 업데이트의 영향을 억제하고 수학적 분석으로 최적성 간극이 유계임을 보였다.

Result: 이론적으로 강한 비잔틴 공격 하에서도 유계(optimality gap) 보장을 제공한다. 실험적으로는 Flower 프레임워크에서 MNIST, FMNIST, CIFAR-10을 대상으로 라벨 플립, 사인 플립, 가우시안 노이즈 공격에 대해 Mean, Trimmed Mean, Median, Krum, Multi-Krum보다 성능 우위를 보였다.

Conclusion: 서버가 신뢰 데이터만 있으면 사전 정보 없이도 다수의 악성 클라이언트에 대해 강건한 FL가 가능하다는 실용적 대안을 제시한다. 다만 서버 데이터의 대표성(분포 차이), 계산 비용, 구체적 필터링 기준 등은 논문 전문에서 확인해야 한다.

Abstract: Federated Learning (FL) enables collaborative model training across multiple
clients without sharing private data. We consider FL scenarios wherein FL
clients are subject to adversarial (Byzantine) attacks, while the FL server is
trusted (honest) and has a trustworthy side dataset. This may correspond to,
e.g., cases where the server possesses trusted data prior to federation, or to
the presence of a trusted client that temporarily assumes the server role. Our
approach requires only two honest participants, i.e., the server and one
client, to function effectively, without prior knowledge of the number of
malicious clients. Theoretical analysis demonstrates bounded optimality gaps
even under strong Byzantine attacks. Experimental results show that our
algorithm significantly outperforms standard and robust FL baselines such as
Mean, Trimmed Mean, Median, Krum, and Multi-Krum under various attack
strategies including label flipping, sign flipping, and Gaussian noise addition
across MNIST, FMNIST, and CIFAR-10 benchmarks using the Flower framework.

</details>


### [388] [Deploying Models to Non-participating Clients in Federated Learning without Fine-tuning: A Hypernetwork-based Approach](https://arxiv.org/abs/2508.12673)
*Yuhao Zhou,Jindi Lv,Yuxin Tian,Dan Si,Qing Ye,Jiancheng Lv*

Main category: cs.LG

TL;DR: HyperFedZero는 분포 인식 임베딩을 조건으로 하는 하이퍼네트워크로 비참여 클라이언트(제로샷)용 특화 모델을 동적으로 생성하여 연합학습의 데이터 이질성 문제를 해결하려는 방법이다. NoisyEmbed와 Balancing Penalty로 임베딩 붕괴를 막고, 청크 단위 가중치 생성으로 경량화/적응성을 유지한다.


<details>
  <summary>Details</summary>
Motivation: 참여 클라이언트에 대한 퍼스널라이제이션은 진전이 있었지만, 학습에 참여하지 않는(비참여) 클라이언트의 도메인 편차와 자원 제약 환경에 대한 일반화가 부족해 실용성에 한계가 있다.

Method: 분포-인식 임베딩을 추출하는 NoisyEmbed 강화 추출기와 Balancing Penalty를 도입해 강건한 분포 임베딩을 확보한 뒤, 이를 조건으로 하이퍼네트워크가 모델 파라미터를 청크 단위로 생성해 비참여 클라이언트에 특화된 모델을 제공한다.

Result: 여러 데이터셋과 모델에서 경쟁 기법들을 지속적으로 능가하며, 계산·저장·통신 오버헤드가 작다고 보고한다. 추가로 성분별 제거 실험과 시각화를 통해 각 구성 요소의 필요성과 의미 있는 적응을 검증했다.

Conclusion: HyperFedZero는 분포 인식 임베딩과 하이퍼네트워크 기반의 제로샷 특화 모델 생성으로 비참여 클라이언트의 분포 편차에 효과적으로 대응하며, 실험적으로 우수한 일반화 성능과 효율성을 보인다.

Abstract: Federated Learning (FL) has emerged as a promising paradigm for
privacy-preserving collaborative learning, yet data heterogeneity remains a
critical challenge. While existing methods achieve progress in addressing data
heterogeneity for participating clients, they fail to generalize to
non-participating clients with in-domain distribution shifts and resource
constraints. To mitigate this issue, we present HyperFedZero, a novel method
that dynamically generates specialized models via a hypernetwork conditioned on
distribution-aware embeddings. Our approach explicitly incorporates
distribution-aware inductive biases into the model's forward pass, extracting
robust distribution embeddings using a NoisyEmbed-enhanced extractor with a
Balancing Penalty, effectively preventing feature collapse. The hypernetwork
then leverages these embeddings to generate specialized models chunk-by-chunk
for non-participating clients, ensuring adaptability to their unique data
distributions. Extensive experiments on multiple datasets and models
demonstrate HyperFedZero's remarkable performance, surpassing competing methods
consistently with minimal computational, storage, and communication overhead.
Moreover, ablation studies and visualizations further validate the necessity of
each component, confirming meaningful adaptations and validating the
effectiveness of HyperFedZero.

</details>


### [389] [BUILDA: A Thermal Building Data Generation Framework for Transfer Learning](https://arxiv.org/abs/2508.12703)
*Thomas Krug,Fabian Raisch,Dominik Aimer,Markus Wirnsberger,Ferdinand Sigg,Benjamin Schäfer,Benjamin Tischler*

Main category: cs.LG

TL;DR: BuilDa는 단일존(Modelica) 모델을 FMU로 내보내 Python에서 시뮬레이션해 대규모 합성 건물 열 데이터셋을 생성하여 전이학습(TL) 연구에 필요한 데이터 품질·수량을 충족시키는 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 전이학습을 위한 적절한 소스 모델 선택 등 새로운 연구 주제가 등장했으나, 이를 뒷받침할 만큼 고품질·대량의 건물 열 데이터가 공개되어 있지 않음. 기존 데이터 생성법은 전문가 지식에 의존하고 TL 요구를 만족시키지 못함.

Method: 단일존 Modelica 모델을 생성·FMU로 내보낸 뒤 Python 환경에서 반복 시뮬레이션을 수행하여 다양한 파라미터·운영 조건을 반영한 합성 시계열 데이터를 대량으로 생성함. 생성된 데이터로 TL 모델의 사전학습(pretraining)과 미세조정(fine-tuning)을 수행해 활용성을 보임.

Result: BuilDa로 생성한 데이터셋을 사용해 TL의 사전학습 및 파인튜닝을 시연함으로써 합성 데이터가 TL 워크플로우에 실제로 활용 가능함을 입증함(초록에는 정량적 성능 수치는 명시되어 있지 않음).

Conclusion: BuilDa는 시뮬레이션 전문지식 없이도 TL 연구용 고품질·대량 합성 데이터를 생성할 수 있게 하여, 건물 열역학 전이학습 연구의 데이터 장벽을 낮추는 실용적 도구를 제공한다.

Abstract: Transfer learning (TL) can improve data-driven modeling of building thermal
dynamics. Therefore, many new TL research areas emerge in the field, such as
selecting the right source model for TL. However, these research directions
require massive amounts of thermal building data which is lacking presently.
Neither public datasets nor existing data generators meet the needs of TL
research in terms of data quality and quantity. Moreover, existing data
generation approaches typically require expert knowledge in building
simulation. We present BuilDa, a thermal building data generation framework for
producing synthetic data of adequate quality and quantity for TL research. The
framework does not require profound building simulation knowledge to generate
large volumes of data. BuilDa uses a single-zone Modelica model that is
exported as a Functional Mock-up Unit (FMU) and simulated in Python. We
demonstrate BuilDa by generating data and utilizing it for pretraining and
fine-tuning TL models.

</details>


### [390] [Argos: A Decentralized Federated System for Detection of Traffic Signs in CAVs](https://arxiv.org/abs/2508.12712)
*Seyed Mahdi Haji Seyed Hossein,Alireza Hosseini,Soheil Hajian Manesh,Amirali Shahriary*

Main category: cs.LG

TL;DR: 차량 네트워크에서 트래픽 표지판 검출을 위해 연합학습 기반의 분산 학습 프레임워크를 제안. 차량별로 클래스 분할과 경량 객체 검출기를 이용해 로컬 학습을 수행하고 FedProx, FedAdam, FedAVG 등으로 매개변수를 집계해 개인 데이터 공유 없이 협업 학습을 실험적으로 평가함. 서버 라운드, 로컬 epoch, 클라이언트 참여율, 데이터 분포 등 변수를 비교해 성능과 학습 시간 특성을 분석함.


<details>
  <summary>Details</summary>
Motivation: 연결·자율주행 차량이 생성하는 대량의 센서 데이터를 중앙집중식으로 모으는 것은 프라이버시·통신 부담 문제를 일으키므로, 중앙서버에 원시 데이터를 공유하지 않고도 협력적으로 인식 모델을 학습할 수 있는 분산·연합학습 방법을 모색하기 위함.

Method: 차량별로 트래픽 표지판 클래스 분할(부분적 비균일 분포)과 경량 객체 검출기를 사용하여 로컬 학습을 수행. Flower 프레임워크로 시뮬레이션 환경을 구성하고 FedProx/FedAdam/FedAVG 등 집계기를 적용. 서버 라운드(2→20), 로컬 epoch(여러 값), 클라이언트 참여율, IID/Non-IID 데이터 분포 등의 설정을 바꿔 실험.

Result: 서버 라운드 증가는 정확도를 크게 향상(2라운드에서 <0.1 → 20라운드에서 >0.8). 로컬 epoch는 중간값(8–10)이 효율적이며 정확도 약 0.67. 클라이언트 참여율 증가 시 일반화 개선(최대 ≈0.83). FedProx가 이질성에 더 견고. Non-IID가 IID 대비 성능 저하. 학습 시간은 집계기보단 라운드 수에 주로 비례.

Conclusion: 제안한 연합학습 방식은 차량 배포 환경에서 개인정보 보호와 확장성 측면에서 실현 가능성이 있으며, 향후 강건한 집계 알고리즘·통신 최적화·보안 기법 통합을 통해 지능형 교통 시스템에 적용 가능성이 있음.

Abstract: Connected and automated vehicles generate vast amounts of sensor data daily,
raising significant privacy and communication challenges for centralized
machine learning approaches in perception tasks. This study presents a
decentralized, federated learning framework tailored for traffic sign detection
in vehicular networks to enable collaborative model training without sharing
raw data. The framework partitioned traffic sign classes across vehicles for
specialized local training using lightweight object detectors, aggregated model
parameters via algorithms like FedProx, FedAdam and FedAVG in a simulated
environment with the Flower framework, and evaluated multiple configurations
including varying server rounds, local epochs, client participation fractions,
and data distributions. Experiments demonstrated that increasing server rounds
from 2 to 20 boosted accuracy from below 0.1 to over 0.8, moderate local epochs
(8-10) provided optimal efficiency with accuracies around 0.67, higher client
participation fractions enhanced generalization up to 0.83, FedProx
outperformed other aggregators in handling heterogeneity, non-IID data
distributions reduced performance compared to IID, and training duration
primarily scaled with the number of rounds rather than aggregation strategy. We
conclude that this federated approach may offer a scalable, privacy-preserving
solution for real-world vehicular deployments, potentially guiding future
integrations of robust aggregation and communication optimizations to advance
intelligent transportation systems.

</details>


### [391] [FedSODA: Federated Fine-tuning of LLMs via Similarity Group Pruning and Orchestrated Distillation Alignment](https://arxiv.org/abs/2508.12727)
*Manning Zhu,Songtao Guo,Pengzhan Zhou,Yansong Ning,Chang Han,Dewen Qiao*

Main category: cs.LG

TL;DR: FedSODA는 자원 제약 클라이언트에서 전체 모델을 저장·접근하지 않고도 LLM을 연합 파인튜닝하는 방법으로, 계층 유사성 기반 가지치기(SGP)와 증류 정렬(ODA)을 결합해 양자화된(sub-LLM) 모델과 경량 어댑터로 통신·저장 비용을 크게 줄이면서 정확도를 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 클라이언트 측 연합 파인튜닝은 도메인 적응과 데이터 프라이버시를 동시에 해결하지만, 전체 LLM을 로컬에서 파인튜닝하려면 계산·메모리·통신 비용이 커서 자원 제약 환경에서는 실행이 어렵다. 이를 해결할 자원 효율적 방법이 필요하다.

Method: (1) SGP(similarity group pruning): 전체 LLM에서 유사성 기반으로 덜 중요하거나 중복된 레이어들을 가지치기하여 sub-LLM을 생성해 로컬 저장·처리 부담을 줄임. (2) ODA(orchestrated distillation alignment): sub-LLM과 원본(full) LLM 사이의 그래디언트 발산을 줄이도록 증류 정렬을 수행하여 파인튜닝 안정성과 성능을 유지. (3) QLoRA 기반 양자화와 경량 어댑터 미세조정으로 클라이언트 측 요구 자원을 최소화함.

Result: 세 가지 오픈소스 LLM과 다양한 다운스트림 작업에서 실험한 결과, 평균 통신 오버헤드 70.6% 감소, 저장 용량 75.6% 감소, 작업 정확도는 평균 3.1% 향상으로 보고됨.

Conclusion: FedSODA는 자원 제약 환경에서 실용적인 연합 파인튜닝 솔루션을 제시하며, 통신·저장 비용을 대폭 낮추면서 성능 저하 없이 오히려 성능을 향상시킬 수 있음을 보인다.

Abstract: Federated fine-tuning (FFT) of large language models (LLMs) has recently
emerged as a promising solution to enable domain-specific adaptation while
preserving data privacy. Despite its benefits, FFT on resource-constrained
clients relies on the high computational and memory demands of full-model
fine-tuning, which limits the potential advancement. This paper presents
FedSODA, a resource-efficient FFT framework that enables clients to adapt LLMs
without accessing or storing the full model. Specifically, we first propose a
similarity group pruning (SGP) module, which prunes redundant layers from the
full LLM while retaining the most critical layers to preserve the model
performance. Moreover, we introduce an orchestrated distillation alignment
(ODA) module to reduce gradient divergence between the sub-LLM and the full LLM
during FFT. Through the use of the QLoRA, clients only need to deploy quantized
sub-LLMs and fine-tune lightweight adapters, significantly reducing local
resource requirements. We conduct extensive experiments on three open-source
LLMs across a variety of downstream tasks. The experimental results demonstrate
that FedSODA reduces communication overhead by an average of 70.6%, decreases
storage usage by 75.6%, and improves task accuracy by 3.1%, making it highly
suitable for practical FFT applications under resource constraints.

</details>


### [392] [FedUNet: A Lightweight Additive U-Net Module for Federated Learning with Heterogeneous Models](https://arxiv.org/abs/2508.12740)
*Beomseok Seo,Kichang Lee,JaeYeon Park*

Main category: cs.LG

TL;DR: 경량의 아키텍처-불가지론적 연합학습 방식 FedUNet 제안: 각 클라이언트의 백본에 U-Net 유사한 추가 모듈을 붙이고, 소형 병목(bottleneck)만 공유하여 이질적 모델 간 지식전달과 낮은 통신비용 달성.


<details>
  <summary>Details</summary>
Motivation: 기존 FL 방법은 클라이언트 간 동일한 모델 구조를 가정해 실제 이질적 환경에서 적용이 어려움. 다양한 백본을 가진 클라이언트 간에도 효율적 지식공유가 필요함.

Method: 각 클라이언트 백본 뒤에 U-Net 유사의 추가 모듈을 부착하고, 인코더-디코더 및 스킵커넥션으로 로우·하이레벨 특징을 포착. 공유는 모듈의 소형 병목만 수행해 구조 동기화 없이 통신량 최소화.

Result: VGG 변형 실험에서 FedUNet이 93.11% 정확도, 경량화된 형태에서 92.68%를 달성. 통신 오버헤드는 0.89MB 수준으로 낮음.

Conclusion: U-Net 스타일의 추가 모듈과 병목 공유는 이질적 모델 환경에서 효과적인 지식전달 및 낮은 통신비용을 제공, 구조 호환성 문제를 완화함.

Abstract: Federated learning (FL) enables decentralized model training without sharing
local data. However, most existing methods assume identical model architectures
across clients, limiting their applicability in heterogeneous real-world
environments. To address this, we propose FedUNet, a lightweight and
architecture-agnostic FL framework that attaches a U-Net-inspired additive
module to each client's backbone. By sharing only the compact bottleneck of the
U-Net, FedUNet enables efficient knowledge transfer without structural
alignment. The encoder-decoder design and skip connections in the U-Net help
capture both low-level and high-level features, facilitating the extraction of
clientinvariant representations. This enables cooperative learning between the
backbone and the additive module with minimal communication cost. Experiment
with VGG variants shows that FedUNet achieves 93.11% accuracy and 92.68% in
compact form (i.e., a lightweight version of FedUNet) with only 0.89 MB low
communication overhead.

</details>


### [393] [A Multi-Resolution Benchmark Framework for Spatial Reasoning Assessment in Neural Networks](https://arxiv.org/abs/2508.12741)
*Manuela Imbriani,Gina Belmonte,Mieke Massink,Alessandro Tofani,Vincenzo Ciancia*

Main category: cs.LG

TL;DR: 본 논문은 신경망의 공간 추론 능력을 체계적으로 평가하기 위한 합성 벤치마크 프레임워크를 제안한다. VoxLogicA로 생성한 미로 연결성(위상)과 거리 계산(기하) 문제를 다양한 해상도로 만들어 nnU-Net으로 실험한 결과, 신경망이 기본적인 기하·위상 과제에서 반복적인 실패를 보임을 보였다.


<details>
  <summary>Details</summary>
Motivation: 의료 영상 등 실무 응용에서 신경망이 공간적·형태학적 특성(연결성, 거리 등)을 얼마나 잘 이해하는지 체계적으로 평가할 수 있는 표준화된 실험 기반이 부족하다. 이를 보완해 한계점을 규명하고 개선 방향(예: 신경망과 기호적 추론의 결합)을 모색하려는 목적.

Method: VoxLogicA 공간 모델 검사기를 사용해 두 가지 합성 데이터셋 범주(미로 연결성: 위상 문제, 공간 거리 계산: 기하 문제)를 자동으로 생성하고, 다양한 해상도로 확장. nnU-Net을 표준화된 학습 파이프라인(교차검증 포함)으로 학습·추론하고, Dice 계수와 IoU로 성능을 평가하는 자동화된 전체 ML 워크플로우를 구축.

Result: 예비 실험에서 nnU-Net은 기본적인 기하학적·위상학적 문제에 대해 반복적인 실패를 보였고, 해상도 변화에 따른 확장성·일반화에도 한계가 관찰됨. Dice 및 IoU 지표에서 낮은 성능과 체계적 오류 패턴이 확인됨.

Conclusion: 재현 가능한 실험 프로토콜을 제공해 신경망의 공간 추론 한계점을 명확히 식별할 수 있다. 향후 연구는 신경망에 기호적 추론을 결합한 하이브리드 접근법을 통해 이러한 한계를 보완하는 방향으로 이어질 수 있다.

Abstract: This paper presents preliminary results in the definition of a comprehensive
benchmark framework designed to systematically evaluate spatial reasoning
capabilities in neural networks, with a particular focus on morphological
properties such as connectivity and distance relationships. The framework is
currently being used to study the capabilities of nnU-Net, exploiting the
spatial model checker VoxLogicA to generate two distinct categories of
synthetic datasets: maze connectivity problems for topological analysis and
spatial distance computation tasks for geometric understanding. Each category
is evaluated across multiple resolutions to assess scalability and
generalization properties. The automated pipeline encompasses a complete
machine learning workflow including: synthetic dataset generation, standardized
training with cross-validation, inference execution, and comprehensive
evaluation using Dice coefficient and IoU (Intersection over Union) metrics.
Preliminary experimental results demonstrate significant challenges in neural
network spatial reasoning capabilities, revealing systematic failures in basic
geometric and topological understanding tasks. The framework provides a
reproducible experimental protocol, enabling researchers to identify specific
limitations. Such limitations could be addressed through hybrid approaches
combining neural networks with symbolic reasoning methods for improved spatial
understanding in clinical applications, establishing a foundation for ongoing
research into neural network spatial reasoning limitations and potential
solutions.

</details>


### [394] [Constrained Centroid Clustering: A Novel Approach for Compact and Structured Partitioning](https://arxiv.org/abs/2508.12758)
*Sowmini Devi Veeramachaneni,Ramamurthy Garimella*

Main category: cs.LG

TL;DR: Introduces Constrained Centroid Clustering (CCC) that enforces a max-distance constraint between centroid and farthest member via a Lagrangian closed-form update; demonstrates on synthetic circular data that CCC reduces radial spread while preserving angular structure, outperforming K-means and GMM on ring-wise, sector-wise and joint entropy metrics.


<details>
  <summary>Details</summary>
Motivation: Many centroid-based clustering methods (e.g., K-means) lack direct control over cluster spread; authors want an interpretable centroid method that enforces a hard/soft radius constraint to produce compact, structured clusters useful in sensor networks, robotics, and interpretable analysis.

Method: Formulate clustering with a constraint on maximum distance from centroid to any assigned point, use Lagrangian multipliers to derive closed-form centroid update (CCC) that enforces spread control while remaining centroid-based and interpretable.

Result: On synthetic circular data (radial symmetry, uniform angular distribution) CCC yields clusters with smaller radial variance and preserved angular segmentation compared to K-means and GMM, as measured by ring-wise, sector-wise, and joint entropy metrics.

Conclusion: CCC offers a practical, interpretable extension of centroid clustering that controls cluster spread; suitable for applications that require structured clusters with bounded spread.

Abstract: This paper presents Constrained Centroid Clustering (CCC), a method that
extends classical centroid-based clustering by enforcing a constraint on the
maximum distance between the cluster center and the farthest point in the
cluster. Using a Lagrangian formulation, we derive a closed-form solution that
maintains interpretability while controlling cluster spread. To evaluate CCC,
we conduct experiments on synthetic circular data with radial symmetry and
uniform angular distribution. Using ring-wise, sector-wise, and joint entropy
as evaluation metrics, we show that CCC achieves more compact clusters by
reducing radial spread while preserving angular structure, outperforming
standard methods such as K-means and GMM. The proposed approach is suitable for
applications requiring structured clustering with spread control, including
sensor networks, collaborative robotics, and interpretable pattern analysis.

</details>


### [395] [Short-Term Forecasting of Energy Production and Consumption Using Extreme Learning Machine: A Comprehensive MIMO based ELM Approach](https://arxiv.org/abs/2508.12764)
*Cyril Voyant,Milan Despotovic,Luis Garcia-Gutierrez,Mohammed Asloune,Yves-Marie Saint-Drenan,Jean-Laurent Duchaud,hjuvan Antone Faggianelli,Elena Magliaro*

Main category: cs.LG

TL;DR: ELM 기반 MIMO 단기 에너지 예측법을 제안. 6년치 코르시카 시간별 다원(태양·풍력·수력·열·바이오·수입) 데이터를 이용하고 슬라이딩 윈도우와 사이클릭 시간 인코딩으로 비정상성에 대응. 1시간 예측에서 태양 nRMSE 17.9%, 열 5.1%, R^2>0.98를 보고하며 5시간 예측까지 안정적. MIMO는 SISO보다 소폭 우수하며 LSTM 대비 학습·추론 비용이 낮아 실시간·온라인 응용에 적합.


<details>
  <summary>Details</summary>
Motivation: 재생에너지의 변동성과 전력 수급 운영의 실시간 제약 때문에 빠르고 정확한 단기 예측법(특히 온라인·경량 모델)이 필요함.

Method: Extreme Learning Machine(ELM)을 MIMO 구조로 적용. 입력으로 다원 시계열을 사용하고 슬라이딩 윈도우 및 사이클릭(주기) 시간 인코딩을 도입해 비정상성·계절성을 처리. 학습은 ELM의 closed-form 해를 이용해 빠르게 수행. 비교 대상으로 persistence와 LSTM 등을 사용.

Result: 1시간 예측에서 태양 nRMSE 17.9%, 열 nRMSE 5.1%, 전반적으로 R^2>0.98(1h). 성능은 5시간까지 양호, 이후 재생에너지의 변동성으로 저하. MIMO는 SISO 대비 소폭 이득. 계산 비용과 온라인 적응성에서 LSTM 대비 우수.

Conclusion: ELM-MIMO는 실시간·온라인 단기 예측에 실용적이며 지역 특성에 맞춰 튜닝 가능. 다만 재생에너지의 장시간 예측 한계, 비교 대상·평가 확장(다양한 베이스라인·불확실성 예측) 등이 남아 있음.

Abstract: A novel methodology for short-term energy forecasting using an Extreme
Learning Machine ($\mathtt{ELM}$) is proposed. Using six years of hourly data
collected in Corsica (France) from multiple energy sources (solar, wind, hydro,
thermal, bioenergy, and imported electricity), our approach predicts both
individual energy outputs and total production (\cyr{including imports, which
closely follow energy demand, modulo losses)} through a Multi-Input
Multi-Output ($\mathtt{MIMO}$) architecture. To address non-stationarity and
seasonal variability, sliding window techniques and cyclic time encoding are
incorporated, enabling dynamic adaptation to fluctuations. The $\mathtt{ELM}$
model significantly outperforms persistence-based forecasting, particularly for
solar and thermal energy, achieving an $\mathtt{nRMSE}$ of $17.9\%$ and
$5.1\%$, respectively, with $\mathtt{R^2} > 0.98$ (1-hour horizon). The model
maintains high accuracy up to five hours ahead, beyond which renewable energy
sources become increasingly volatile. While $\mathtt{MIMO}$ provides marginal
gains over Single-Input Single-Output ($\mathtt{SISO}$) architectures and
offers key advantages over deep learning methods such as $\mathtt{LSTM}$, it
provides a closed-form solution with lower computational demands, making it
well-suited for real-time applications, including online learning. Beyond
predictive accuracy, the proposed methodology is adaptable to various contexts
and datasets, as it can be tuned to local constraints such as resource
availability, grid characteristics, and market structures.

</details>


### [396] [Online Ensemble Transformer for Accurate Cloud Workload Forecasting in Predictive Auto-Scaling](https://arxiv.org/abs/2508.12773)
*Jiadong Chen,Xiao He,Hengyu Ye,Fuxin Jiang,Tieying Zhang,Jianjun Chen,Xiaofeng Gao*

Main category: cs.LG

TL;DR: E3Former는 온라인 워크로드 예측을 위한 경량 앙상블 모델로, 서버리스 환경의 예측형 오토스케일링에 특화되어 있다. 온라인 실험에서 예측오차를 평균 10% 감소시키며, ByteDance의 IHPA 플랫폼에 배포되어 30개 이상의 애플리케이션과 60만 CPU 코어 규모의 예측형 오토스케일링을 지원하고 자원 사용량을 40% 이상 절감했다.


<details>
  <summary>Details</summary>
Motivation: 서버리스와 같은 불안정한 클라우드 환경에서는 신속히 변화하는 워크로드에 맞춰 자원을 예측적으로 할당해야 비용과 품질을 동시에 보장할 수 있다. 기존 모델들은 온라인 스트림의 동적 변화에 빨리 적응하지 못하고, 고주기·미세 단위 예측에서 복잡한 주기성을 포착하기 어렵다.

Method: 여러 서브네트워크를 결합한 온라인 앙상블 모델(E3Former)을 제안한다. 각 서브모델의 예측력을 결합해 단일 모델의 한계를 극복하고, 계산 비용 증가는 최소화해 서버리스의 경량성 요구를 충족한다. 대규모 실데이터 기반 온라인 실험과 실제 시스템(예: IHPA)에서 검증했다.

Result: 온라인 포캐스팅에서 평균 예측오차 10% 감소. 실제 예측형 오토스케일링 적용 시 서비스 품질 유지 하에 자원 사용률을 40% 이상 절감. ByteDance IHPA에 적용되어 30+ 애플리케이션과 600k CPU 코어 규모를 지원.

Conclusion: E3Former는 적은 연산 오버헤드로 온라인 환경에서 우수한 예측 정확도와 강건성을 제공해 대규모 예측형 오토스케일링에 실용적으로 기여한다. 실제 배포 및 운영 성과(비용/자원 절감)가 이를 뒷받침한다.

Abstract: In the swiftly evolving domain of cloud computing, the advent of serverless
systems underscores the crucial need for predictive auto-scaling systems. This
necessity arises to ensure optimal resource allocation and maintain operational
efficiency in inherently volatile environments. At the core of a predictive
auto-scaling system is the workload forecasting model. Existing forecasting
models struggle to quickly adapt to the dynamics in online workload streams and
have difficulty capturing the complex periodicity brought by fine-grained,
high-frequency forecasting tasks. Addressing this, we propose a novel online
ensemble model, E3Former, for online workload forecasting in large-scale
predictive auto-scaling. Our model synergizes the predictive capabilities of
multiple subnetworks to surmount the limitations of single-model approaches,
thus ensuring superior accuracy and robustness. Remarkably, it accomplishes
this with a minimal increase in computational overhead, adhering to the lean
operational ethos of serverless systems. Through extensive experimentation on
real-world workload datasets, we establish the efficacy of our ensemble model.
In online forecasting tasks, the proposed method reduces forecast error by an
average of 10%, and its effectiveness is further demonstrated through a
predictive auto-scaling test in the real-life online system. Currently, our
method has been deployed within ByteDance's Intelligent Horizontal Pod
Auto-scaling (IHPA) platform, which supports the stable operation of over 30
applications, such as Douyin E-Comerce, TouTiao, and Volcano Engine. The
predictive auto-scaling capacity reaching over 600,000 CPU cores. On the basis
of essentially ensuring service quality, the predictive auto-scaling system can
reduce resource utilization by over 40%.

</details>


### [397] [Randomized PCA Forest for Outlier Detection](https://arxiv.org/abs/2508.12776)
*Muhammad Rajabinasab,Farhad Pakdaman,Moncef Gabbouj,Peter Schneider-Kamp,Arthur Zimek*

Main category: cs.LG

TL;DR: 랜덤화된 주성분분석(RPCA) 기반의 새로운 비지도 이상치 탐지 기법을 제안한다. RPCA Forest를 활용해 이상치 점수를 계산하며, 여러 데이터셋에서 고전 기법 및 최신 기법과 비교해 우수하거나 경쟁력 있는 성능과 계산 효율을 보였다.


<details>
  <summary>Details</summary>
Motivation: 비지도 이상치 탐지에서 정확도와 계산 효율을 동시에 확보하는 것이 필요하다. RPCA Forest가 근사 K-최근접이웃 검색에서 보인 성능을 이상치 탐지에 응용하여 이러한 요구를 충족하려는 동기에서 출발한다.

Method: RPCA Forest의 랜덤화된 투영/분해(랜덤 PCA 기반 구조)를 이용해 데이터의 표현을 얻고, 이 표현을 바탕으로 이상치 점수를 산출하는 비지도 방법을 설계했다. (초록 수준에서) RPCA Forest의 장점을 살려 계산 복잡도를 낮추고 일반화 성능을 확보하도록 구성하였다.

Result: 여러 데이터셋에서 고전적 기법 및 최신 기법들과 비교한 실험에서 제안 방법이 다수의 데이터셋에서 우수한 성능을 보였고, 나머지 데이터셋에서는 경쟁력 있는 성능을 보였다. 또한 전반적 분석에서 높은 일반화 능력과 계산 효율성이 확인되었다.

Conclusion: RPCA Forest를 활용한 비지도 이상치 탐지 방법은 정확도와 효율성 측면에서 유망하며, 실무 및 대규모 데이터셋에 적용 가능한 좋은 선택지로 제시된다.

Abstract: We propose a novel unsupervised outlier detection method based on Randomized
Principal Component Analysis (PCA). Inspired by the performance of Randomized
PCA (RPCA) Forest in approximate K-Nearest Neighbor (KNN) search, we develop a
novel unsupervised outlier detection method that utilizes RPCA Forest for
outlier detection. Experimental results showcase the superiority of the
proposed approach compared to the classical and state-of-the-art methods in
performing the outlier detection task on several datasets while performing
competitively on the rest. The extensive analysis of the proposed method
reflects it high generalization power and its computational efficiency,
highlighting it as a good choice for unsupervised outlier detection.

</details>


### [398] [Wavy Transformer](https://arxiv.org/abs/2508.12787)
*Satoshi Noguchi,Yoshinobu Kawahara*

Main category: cs.LG

TL;DR: This paper links stacked transformer attention to graph diffusion and attributes over-smoothing to dissipative diffusion. It proposes Wavy Transformer using second-order wavy dynamics in attention plus compatible FFN and normalization to preserve state-velocity relationships, improving NLP and CV models with minor cost.


<details>
  <summary>Details</summary>
Motivation: Deep transformers exhibit over-smoothing—token representations become similar across layers—reducing expressivity. The authors want a principled, physics-inspired fix by interpreting attention dynamics as diffusion and then counteracting dissipation.

Method: Establish equivalence between stacked attention and graph neural diffusion on a complete graph. Introduce a second-order (wavy) attention layer modeling undamped/oscillatory dynamics, and design FFN and normalization that maintain state-velocity relationships under the chain rule. Integrate into transformer stacks with minimal parameter overhead.

Result: Empirical validation across multiple NLP and CV transformer variants shows consistent performance gains without extra hyperparameter tuning and little added parameters.

Conclusion: Wavy Transformer offers a physics-grounded modification that mitigates over-smoothing via second-order dynamics, yielding practical improvements while preserving architecture simplicity.

Abstract: Transformers have achieved remarkable success across natural language
processing (NLP) and computer vision (CV). However, deep transformer models
often suffer from an over-smoothing issue, in which token representations
converge to similar values as they pass through successive transformer blocks.
In this paper, we establish an equivalence between the hidden-state dynamics
induced by stacked attention layers and graph neural diffusion on a complete
graph. From this perspective, over-smoothing can be interpreted as a
consequence of the dissipative nature of the underlying diffusion dynamics.
Motivated by this physical interpretation, we propose Wavy Transformer, which
consists of a novel attention layer based on second-order wavy dynamics. We
also introduce a feed-forward network and a normalization layer designed to
preserve the physical state-velocity relationship under the chain rule, thereby
extending the transformer architecture. We further validate our proposed
techniques on various transformer models for NLP and CV tasks. The results
consistently demonstrate that Wavy Transformer improves performance with
minimal additional parameters and no extra hyperparameter tuning.

</details>


### [399] [Bridging Human and LLM Judgments: Understanding and Narrowing the Gap](https://arxiv.org/abs/2508.12792)
*Felipe Maia Polo,Xinhe Wang,Mikhail Yurochkin,Gongjun Xu,Moulinath Banerjee,Yuekai Sun*

Main category: cs.LG

TL;DR: Bridge는 인간 평가와 LLM 평가를 통계적으로 연결하는 통일된 프레임워크로, 잠재적인 인간 선호 점수를 가정하고 LLM 편차를 공변량의 선형 변환으로 모델링해 LLM 평점을 보정하고 사람-LLM 간 체계적 차이를 규명한다.


<details>
  <summary>Details</summary>
Motivation: LLM을 평가자(‘LLM-as-a-judge’)로 대규모 자동평가에 활용할 때 LLM 판단이 사람 판단과 체계적으로 일치하지 않는 문제가 있어, 이 차이를 정량적·해석적으로 다루는 방법이 필요하다.

Method: 각 프롬프트-응답 쌍에 대해 잠재적 인간 선호 점수를 가정하고, LLM의 평가를 공변량(예: 모델 출력 특성, 메타데이터)의 선형 변환으로 모델링한다. 절대 점수 및 쌍비교(two-choice) 설정을 모두 다루며, 효율적 추정 알고리즘과 점근론적 추론 보장을 제공한다.

Result: 6개 LLM 평가자와 두 벤치마크(BigGen Bench, Chatbot Arena)에서 Bridge로 보정된 LLM 평가는 인간 평점과의 일치도(정확도), 교정(calibration), KL 발산 측면에서 개선되었고, 사람-LLM 간의 체계적인 격차를 드러냈다.

Conclusion: Bridge는 LLM 평가를 인간 기준으로 정렬하고 차이를 해석할 수 있는 간단하면서도 원리적인 방법을 제공하며, 자동화된 평가의 신뢰성과 해석성을 높일 수 있다.

Abstract: Large language models are increasingly used as judges (LLM-as-a-judge) to
evaluate model outputs at scale, but their assessments often diverge
systematically from human judgments. We present Bridge, a unified statistical
framework that explicitly bridges human and LLM evaluations under both absolute
scoring and pairwise comparison paradigms. Bridge posits a latent human
preference score for each prompt-response pair and models LLM deviations as
linear transformations of covariates that capture sources of discrepancies.
This offers a simple and principled framework for refining LLM ratings and
characterizing systematic discrepancies between humans and LLMs. We provide an
efficient fitting algorithm with asymptotic guarantees for statistical
inference. Using six LLM judges and two benchmarks (BigGen Bench and Chatbot
Arena), Bridge achieves higher agreement with human ratings (accuracy,
calibration, and KL divergence) and exposes systematic human-LLM gaps.

</details>


### [400] [A Shift in Perspective on Causality in Domain Generalization](https://arxiv.org/abs/2508.12798)
*Damian Machlanski,Stephanie Riley,Edward Moroshko,Kurt Butler,Panagiotis Dimitrakopoulos,Thomas Melistas,Akchunya Chanchal,Steven McDonagh,Ricardo Silva,Sotirios A. Tsaftaris*

Main category: cs.LG

TL;DR: 因果모델이 항상 도메인 일반화(DG)에 유리하다는 주장이 도전받고 있는 상황에서, 본 논문은 기존 문헌의 모순을 재검토하고 ‘원인-예측자’ 관계에 따른 보다 미세한 이론을 제안하며 이를 시연하는 대화형 데모를 제공한다.


<details>
  <summary>Details</summary>
Motivation: 도메인 간 분포변화 하에서 인과적 가정이 일반화에 어떻게 기여하는지에 대해 상반된 결과가 보고되어 혼란이 있음. 인과성의 역할을 단일한 ‘좋다/나쁘다’ 결론으로 환원하는 것을 피하고, 조건과 한계를 명확히 하려는 동기.

Method: 문헌 분석을 통해 기존 DG·인과추론 연구들의 가정과 실험설계를 비교·대조하고, 이론적·경험적 근거를 바탕으로 인과성의 영향이 어떻게 달라지는지 체계화. 관련 개념을 설명하는 대화형 데모 제공.

Result: 일부 DG 벤치마크에서 인과기반 접근이 항상 우월하지 않음을 확인했고, 인과성의 유용성은 데이터 생성과 예측 과제의 구조(예: 예측변수의 인과적 위치, 잠재적 교란 등)에 따라 달라짐을 보임.

Conclusion: 인과성은 일반화를 위한 만능열쇠가 아니며, 구체적 문제 구조와 가정에 따른 세분화된 이론이 필요하다. 실무자에게는 언제 인과적 접근이 합리적인지 판단하기 위한 지침을 제공하려 함.

Abstract: The promise that causal modelling can lead to robust AI generalization has
been challenged in recent work on domain generalization (DG) benchmarks. We
revisit the claims of the causality and DG literature, reconciling apparent
contradictions and advocating for a more nuanced theory of the role of
causality in generalization. We also provide an interactive demo at
https://chai-uk.github.io/ukairs25-causal-predictors/.

</details>


### [401] [Maximum Score Routing For Mixture-of-Experts](https://arxiv.org/abs/2508.12801)
*Bowen Dong,Yilong Fan,Yutao Sun,Zhenyu Li,Tengyu Pan,Xun Zhou,Jianyong Wang*

Main category: cs.LG

TL;DR: MaxScore는 MoE 라우팅을 최소비용 최대유량(min-cost max-flow) 문제로 모델링하고 SoftTopk 연산자를 통합하여, 용량 제약으로 인한 토큰 드랍과 패딩 비효율을 해소하면서도 부하 균형을 유지해 동일 FLOPs에서 낮은 학습 손실과 높은 평가 성능을 달성한다.


<details>
  <summary>Details</summary>
Motivation: 전통적 MoE는 GPU 친화적 계산을 위해 전문가(expert)마다 용량 제약을 두지만, 이로 인해 용량 포화 시 토큰 드랍이 발생하고 비활성 전문가에서 패딩으로 하드웨어 효율이 낮아진다. 용량 제약을 없애면 부하 불균형과 비효율이 발생한다. 이를 해결할 새로운 라우팅 패러다임이 필요하다.

Method: MaxScore는 라우팅을 최소비용 최대유량 문제로 재정식화하고, 연속적·미분 가능한 SoftTopk 연산자를 결합한다. 이 접근은 반복적 재라우팅(iterative rerouting)과 최적수송(optimal transport) 기반 방법들의 근본적 한계를 극복하도록 설계되었다.

Result: 동일한 FLOPs 조건에서 제약된(constrained) 및 비제약된(unconstrained) 기준법들보다 학습 손실이 낮고 평가 점수가 높게 보고되었다. 구현과 실험 설정은 공개된 저장소에서 확인할 수 있다.

Conclusion: MaxScore는 MoE 라우팅의 토큰 드랍과 패딩 비효율 문제를 해결하면서 부하 균형과 계산 효율을 유지하는 실용적 대안으로 보인다. 다만 실제 지연(latency), 플로우 솔버의 오버헤드, 대규모 배치/분산 환경에서의 확장성 등 추가 실험적 검증이 필요하다.

Abstract: Routing networks in sparsely activated mixture-of-experts (MoE) dynamically
allocate input tokens to top-k experts through differentiable sparse
transformations, enabling scalable model capacity while preserving
computational efficiency. Traditional MoE networks impose an expert capacity
constraint to ensure GPU-friendly computation. However, this leads to token
dropping when capacity is saturated and results in low hardware efficiency due
to padding in underutilized experts. Removing the capacity constraint, in turn,
compromises load balancing and computational efficiency. To address these
issues, we propose Maximum Score Routing ($\mathbf{MaxScore}$), a novel MoE
routing paradigm that models routing as a minimum-cost maximum-flow problem and
integrates a SoftTopk operator. MaxScore resolves the fundamental limitations
of iterative rerouting and optimal transport formulations, achieving lower
training losses and higher evaluation scores at equivalent FLOPs compared to
both constrained and unconstrained baselines. Implementation details and
experimental configurations can be obtained from
$\href{https://github.com/dongbw18/MaxScore.git}{MaxScore}$.

</details>


### [402] [Learning to Steer: Input-dependent Steering for Multimodal LLMs](https://arxiv.org/abs/2508.12815)
*Jayneel Parekh,Pegah Khayatan,Mustafa Shukor,Arnaud Dapogny,Alasdair Newson,Matthieu Cord*

Main category: cs.LG

TL;DR: L2S는 입력별(input-specific) 선형 시프트(steering vector)를 학습·예측하는 방식으로 다중모달 LLM의 행위를 세밀하게 제어한다. 테스트 시에는 소형 보조 모듈이 입력마다 적합한 스티어링 벡터를 예측하도록 학습되어, 정적(평균) 스티어링보다 환각(hallucination) 감소와 안전성 향상을 달성한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 평균(혹은 단일) 스티어링은 모든 입력에 동일한 벡터를 적용하기 때문에, 입력에 따라 다른 대응(예: 불법 행위 요청에 대해 회피, 의료질문에 대해 전문가 권고 등)이 요구되는 경우 한계가 있음. 따라서 입력 의존적이고 세밀한 행동 강제 방법이 필요함.

Method: 입력-특화(prompt-based) 대조적(contrastive) 프롬프트로 이상적 입력별 시프트를 계산하되, 테스트 시 해당 프롬프트가 없으므로 소형 보조 모듈을 학습시켜 입력에서 직접 스티어링 벡터를 예측하게 함(Learn-to-Stein, L2S). 예측된 벡터로 MLLM의 출력 분포에 선형 변형을 가해 행동을 교정.

Result: 정적 기법들보다 hallucination을 줄이고 안전 규약을 더 잘 준수함. (초록은 정량적 수치 대신 성능 우위·향상이라는 결과만 제시)

Conclusion: 입력별 스티어링 예측은 MLLM의 안전성과 신뢰성을 향상시키는 실용적 접근이다. 다만 초록 수준에서는 세부 구현·평가 지표·범용성에 대한 정보가 부족하므로 추가 검증이 필요하다.

Abstract: Steering has emerged as a practical approach to enable post-hoc guidance of
LLMs towards enforcing a specific behavior. However, it remains largely
underexplored for multimodal LLMs (MLLMs); furthermore, existing steering
techniques, such as mean steering, rely on a single steering vector, applied
independently of the input query. This paradigm faces limitations when the
desired behavior is dependent on the example at hand. For example, a safe
answer may consist in abstaining from answering when asked for an illegal
activity, or may point to external resources or consultation with an expert
when asked about medical advice. In this paper, we investigate a fine-grained
steering that uses an input-specific linear shift. This shift is computed using
contrastive input-specific prompting. However, the input-specific prompts
required for this approach are not known at test time. Therefore, we propose to
train a small auxiliary module to predict the input-specific steering vector.
Our approach, dubbed as L2S (Learn-to-Steer), demonstrates that it reduces
hallucinations and enforces safety in MLLMs, outperforming other static
baselines.

</details>


### [403] [Toward Storage-Aware Learning with Compressed Data An Empirical Exploratory Study on JPEG](https://arxiv.org/abs/2508.12833)
*Kichang Lee,Songkuk Kim,JaeYeon Park,JeongGil Ko*

Main category: cs.LG

TL;DR: 온디바이스 연속 수집 상황에서 저장 용량 제약을 다루기 위한 경험적 연구. 단순 삭제나 일괄 압축은 비효율적이며, 샘플별로 압축 민감도가 달라 적응적 압축이 유망하다는 결론을 제시.


<details>
  <summary>Details</summary>
Motivation: 온디바이스 ML은 저장용량이 제한된 환경에서 연속적으로 데이터가 쌓일 때 성능을 유지하면서 저장을 효율화해야 하는 실용적 문제에 직면해 있다. 데이터 양과 품질(압축 수준) 간의 트레이드오프를 체계적으로 분석할 필요가 있다.

Method: 여러 압축·데이터 유지 전략(균일 삭제, 일괄 압축 등)과 제안된 샘플별 적응 압축 전략을 비교하는 경험적 실험을 수행하고, 샘플별 압축 민감도(모델 성능에 미치는 영향)를 측정하여 분석한다.

Result: 균일한 삭제나 일괄 압축은 비효율적이며, 샘플마다 압축에 대한 민감도가 크게 달라 샘플별 적응적 압축으로 저장공간을 더 효율적으로 사용할 수 있음을 보여준다.

Conclusion: 샘플 수준의 압축 민감도에 근거한 적응적 저장 전략은 온디바이스 저장 제약 문제를 해결하는 유망한 방향이며, 본 연구는 이 영역에 대한 체계적 기초 인사이트를 제공한다.

Abstract: On-device machine learning is often constrained by limited storage,
particularly in continuous data collection scenarios. This paper presents an
empirical study on storage-aware learning, focusing on the trade-off between
data quantity and quality via compression. We demonstrate that naive
strategies, such as uniform data dropping or one-size-fits-all compression, are
suboptimal. Our findings further reveal that data samples exhibit varying
sensitivities to compression, supporting the feasibility of a sample-wise
adaptive compression strategy. These insights provide a foundation for
developing a new class of storage-aware learning systems. The primary
contribution of this work is the systematic characterization of this
under-explored challenge, offering valuable insights that advance the
understanding of storage-aware learning.

</details>


### [404] [Learning In-context $\pmb{n}$-grams with Transformers: Sub-$\pmb{n}$-grams Are Near-stationary Points](https://arxiv.org/abs/2508.12837)
*Aditya Varre,Gizem Yüce,Nicolas Flammarion*

Main category: cs.LG

TL;DR: 트랜스포머의 인-컨텍스트 다음 토큰 예측에서 n-그램보다 작은(k≤n) 모델들이 손실 함수의 근(near)-정지점으로 작용함을 보이며, 이는 학습 중의 단계적(staged) 진행과 장기간의 플래토 현상을 이론적으로 설명한다.


<details>
  <summary>Details</summary>
Motivation: 학습 중 장기간의 평탄한 구간(plateaus)과 단계적 진전(stage-wise progression)이 널리 관찰되는데, 이를 손실 풍경(loss landscape) 관점에서 이론적으로 설명하려는 동기.

Method: 교차 엔트로피 손실 하에서 인-컨텍스트 n-그램 언어 모델을 수학적으로 분석함. 정지점의 충분조건을 유도하고, 단순화한 트랜스포머 모델의 매개변수 구성으로 k-그램 추정기들을 구성한 뒤, 무한 시퀀스 길이와 매개변수 노름 한계에서 모집단 손실의 그래디언트가 소거됨을 보임. 수치 실험으로 학습 역학을 보완.

Result: k<n인 서브-그램들이 모집단 교차엔트로피 손실의 근-정지점임을 이론적으로 보였고, 수치실험은 n-그램 학습이 근-정지 해들 사이의 불연속적 전이(discrete transitions)를 통해 진행됨을 시사함.

Conclusion: 손실 풍경에 서브-그램 근-정지점이 존재한다는 결과는 단계적 학습 및 상전이(emergent phase transitions)를 이해하는 중요한 단서를 제공하나, 단순화된 모델·무한한 극한 가정·모집단 손실 가정 등 현실 적용에 대한 한계가 존재함.

Abstract: Motivated by empirical observations of prolonged plateaus and stage-wise
progression during training, we investigate the loss landscape of transformer
models trained on in-context next-token prediction tasks. In particular, we
focus on learning in-context $n$-gram language models under cross-entropy loss,
and establish a sufficient condition for parameter configurations to be
stationary points. We then construct a set of parameter configurations for a
simplified transformer model that represent $k$-gram estimators (for $k \leq
n$), and show that the gradient of the population loss at these solutions
vanishes in the limit of infinite sequence length and parameter norm. This
reveals a key property of the loss landscape: {sub-$n$-grams are
near-stationary points of the population cross-entropy loss}, offering
theoretical insight into widely observed phenomena such as stage-wise learning
dynamics and emergent phase transitions. These insights are further supported
by numerical experiments that illustrate the learning dynamics of $n$-grams,
characterized by discrete transitions between near-stationary solutions.

</details>


### [405] [HRS: Hybrid Representation Framework with Scheduling Awareness for Time Series Forecasting in Crowdsourced Cloud-Edge Platforms](https://arxiv.org/abs/2508.12839)
*Tiancheng Zhang,Cheng Zhang,Shuren Liu,Xiaofei Wang,Shaoyuan Huang,Wenyu Wang*

Main category: cs.LG

TL;DR: HRS는 수치적 표현과 이미지 기반 표현을 결합하고 스케줄링 영향을 반영한 손실함수(SAL)를 도입해 급격한 트래픽 변동을 더 잘 예측함으로써 SLA 위반과 손실을 크게 줄인다.


<details>
  <summary>Details</summary>
Motivation: 스트리밍 서비스 확대에 따라 네트워크 부하가 시간적으로 크게 변동하고 버스티함. CCP(크라우드소스 클라우드-엣지 플랫폼)는 예측-스케줄링 구조를 쓰지만, 급증하는 트래픽에서 정확한 예측이 어려워 과소 프로비저닝(SLA 위반) 또는 과다 프로비저닝(비용 증가) 사이의 딜레마가 발생.

Method: HRS는 시계열의 수치 표현과 시간-공간 패턴을 반영한 이미지 기반 표현을 하이브리드로 결합. 또한 스케줄링 관점에서 예측오차의 비대칭적 영향을 반영하는 Scheduling-Aware Loss(SAL)를 설계해 스케줄러 의사결정에 유리한 예측을 유도.

Result: 네 개 실제 데이터셋에서 10개 베이스라인과 비교해 일관되게 우수한 성능을 보였고, SLA 위반률을 63.1% 감소시키고 총 수익 손실을 32.3% 절감해 SOTA 성능을 달성.

Conclusion: HRS는 극단적 부하 변동을 더 잘 포착하고, 스케줄링 목적을 직접 반영한 학습으로 QoS 보장과 비용 효율성 사이의 균형을 개선해 CCP 환경에서 실용적 이득을 제공한다.

Abstract: With the rapid proliferation of streaming services, network load exhibits
highly time-varying and bursty behavior, posing serious challenges for
maintaining Quality of Service (QoS) in Crowdsourced Cloud-Edge Platforms
(CCPs). While CCPs leverage Predict-then-Schedule architecture to improve QoS
and profitability, accurate load forecasting remains challenging under traffic
surges. Existing methods either minimize mean absolute error, resulting in
underprovisioning and potential Service Level Agreement (SLA) violations during
peak periods, or adopt conservative overprovisioning strategies, which mitigate
SLA risks at the expense of increased resource expenditure. To address this
dilemma, we propose HRS, a hybrid representation framework with scheduling
awareness that integrates numerical and image-based representations to better
capture extreme load dynamics. We further introduce a Scheduling-Aware Loss
(SAL) that captures the asymmetric impact of prediction errors, guiding
predictions that better support scheduling decisions. Extensive experiments on
four real-world datasets demonstrate that HRS consistently outperforms ten
baselines and achieves state-of-the-art performance, reducing SLA violation
rates by 63.1% and total profit loss by 32.3%.

</details>


### [406] [One-Class Intrusion Detection with Dynamic Graphs](https://arxiv.org/abs/2508.12885)
*Aleksei Liuliakov,Alexander Schulz,Luca Hermes,Barbara Hammer*

Main category: cs.LG

TL;DR: TGN-SVDD는 시간에 따라 변화하는 네트워크 그래프를 모델링하는 최신 동적 그래프 기법과 심층 이상치 탐지(SVDD)를 결합한 침입탐지 방법으로, 현실적인 침입 데이터에서 여러 기준선보다 우수한 성능을 보이며 더 어려운 데이터 변형도 제안한다.


<details>
  <summary>Details</summary>
Motivation: 네트워크 보안에서 새로운(미지의) 이벤트를 탐지해야 하고, 네트워크 통신이 시간적 순서와 그래프 구조를 가지므로 이를 반영하는 모델이 필요하다.

Method: Temporal Graph Network 계열의 동적 그래프 모델을 기반으로 임베딩을 생성하고, SVDD 스타일의 딥 이상치 탐지기를 결합한 모델(TGN-SVDD)을 제안하여 정상/비정상 분포를 학습해 이상치를 검출한다.

Result: 제안한 모델이 현실적인 침입탐지 데이터셋에서 여러 기존 방법들보다 성능이 우수했으며, 더 까다로운 변형 데이터셋을 제안하여 방법의 강인성을 평가했다.

Conclusion: 시간적·그래프적 속성을 통합한 TGN-SVDD는 미지의 네트워크 이벤트 탐지에 유망하며, 향후 추가 데이터셋, 설명가능성, 계산비용 및 개념 드리프트에 대한 평가가 필요하다.

Abstract: With the growing digitalization all over the globe, the relevance of network
security becomes increasingly important. Machine learning-based intrusion
detection constitutes a promising approach for improving security, but it bears
several challenges. These include the requirement to detect novel and unseen
network events, as well as specific data properties, such as events over time
together with the inherent graph structure of network communication. In this
work, we propose a novel intrusion detection method, TGN-SVDD, which builds
upon modern dynamic graph modelling and deep anomaly detection. We demonstrate
its superiority over several baselines for realistic intrusion detection data
and suggest a more challenging variant of the latter.

</details>


### [407] [TCUQ: Single-Pass Uncertainty Quantification from Temporal Consistency with Streaming Conformal Calibration for TinyML](https://arxiv.org/abs/2508.12905)
*Ismail Lamaakal,Chaymae Yahyati,Khalid El Makkaoui,Ibrahim Ouahbi,Yassine Maleh*

Main category: cs.LG

TL;DR: TCUQ는 라벨 없이 실시간 스트리밍 TinyML 장치에서 짧은 시계열 일관성을 경량 신호로 포착해 보정된 위험 점수로 변환하는 단일 패스 불확실성 모니터다. O(W) 링 버퍼와 O(1) 업데이트로 동작하며, 스트리밍 적합성(컨포멀) 층으로 예측 수락/기권 규칙을 예산 내에서 보장한다. 수킬로바이트급 MCU에 적합하고 앙상블·조기 종료 대비 메모리·지연을 크게 절감하면서 검출 성능도 향상한다.


<details>
  <summary>Details</summary>
Motivation: TinyML 환경에서는 라벨이 없고 자원이 극히 제한된 상태에서 온디바이스 불확실성·고장 감지기가 필요하다. 기존 방법(심층 앙상블, 추가 전달, 또는 라벨 요구)은 메모리·연산·지연 측면에서 부담이 크며 실시간 스트리밍에 맞지 않는다.

Method: 후험 확률(포스트리어)과 특징(feature)의 짧은 시간 창에서의 일관성(temporal consistency)을 가벼운 신호로 추출하고, O(W) 크기의 링 버퍼에 저장해 O(1)로 업데이트한다. 이로부터 위험 점수를 계산하고, 스트리밍 컨포멀(calibration) 계층을 통해 예산 기반의 수락/기권(accept/abstain) 결정을 한다. 전체 과정은 라벨이 필요 없고 추가 순전파가 없다.

Result: 마이크로컨트롤러에서 킬로바이트 규모로 구현 가능. 조기 종료·심층 앙상블 대비 메모리 및 모델 풋프린트 50–60% 감소, 지연 30–45% 단축. 손상된(in-distribution corrupted) 스트림에서 정확도 하락 감지 AUPRC가 3–7 포인트 향상, 높은 심각도에서 최대 0.86 AUPRC 달성. 실패 검출은 최대 0.92 AUROC.

Conclusion: 짧은 시계열 일관성 정보와 스트리밍 컨포멀 보정을 결합하면 라벨 없이도 TinyML 장치에서 실용적이고 자원 효율적인 불확실성·고장 모니터링을 구현할 수 있다.

Abstract: We introduce TCUQ, a single pass, label free uncertainty monitor for
streaming TinyML that converts short horizon temporal consistency captured via
lightweight signals on posteriors and features into a calibrated risk score
with an O(W ) ring buffer and O(1) per step updates. A streaming conformal
layer turns this score into a budgeted accept/abstain rule, yielding calibrated
behavior without online labels or extra forward passes. On microcontrollers,
TCUQ fits comfortably on kilobyte scale devices and reduces footprint and
latency versus early exit and deep ensembles (typically about 50 to 60% smaller
and about 30 to 45% faster), while methods of similar accuracy often run out of
memory. Under corrupted in distribution streams, TCUQ improves accuracy drop
detection by 3 to 7 AUPRC points and reaches up to 0.86 AUPRC at high
severities; for failure detection it attains up to 0.92 AUROC. These results
show that temporal consistency, coupled with streaming conformal calibration,
provides a practical and resource efficient foundation for on device monitoring
in TinyML.

</details>


### [408] [SparseMap: A Sparse Tensor Accelerator Framework Based on Evolution Strategy](https://arxiv.org/abs/2508.12906)
*Boran Zhao,Haiming Zhai,Zihang Yuan,Hetian Liu,Tian Xia,Wenzhe Zhao,Pengju Ren*

Main category: cs.LG

TL;DR: SparseMap은 매핑(mapping)과 희소 전략을 통합한 설계 공간에서 진화전략(유전 알고리즘)을 사용해 희소 텐서 가속기 설계를 자동으로 최적화하는 프레임워크다. 기존 기법들이 놓친 매핑과 희소 전략의 동시 최적화를 다루며, 거대한 조합적 설계 공간에서도 효과적으로 해를 찾아낸다.


<details>
  <summary>Details</summary>
Motivation: 희소 텐서 연산 수요 증가와 함께 다양한 가속기 설계가 등장했으나, 대부분 수동 설계로 특정 시나리오에 한정되며 시나리오 변경 시 많은 설계 인자 조정이 필요하다. 기존 자동화 연구는 매핑 또는 희소 전략 중 하나에만 집중해 전체 최적화에서 비효율을 낳는다. 매핑과 희소 전략을 통합한 자동화가 필요하다.

Method: 매핑(타일링, 통신/연산 분배)과 희소 전략(제로 패스 등)을 모두 포함하는 포괄적 설계 공간을 정의하고, 이 거대한 공간을 탐색하기 위해 진화전략 기반의 최적화(SparseMap)를 제안한다. 유전 인코딩과 진화 연산자를 개량하여 탐색 효율과 다양성을 높였다.

Result: 클래식 최적화 기법(PSO, RL, MCTS 등) 및 기존 방법들과 정량적으로 비교해 SparseMap이 일관되게 더 우수한 설계 해를 찾았다고 보고한다. 대규모 조합적 공간에서도 탐색 성능을 유지한다는 주장.

Conclusion: 매핑과 희소 전략의 통합 최적화가 필요하며, 설계 공간에 맞춘 진화전략은 실용적이고 우수한 해결책을 제공한다. SparseMap은 희소 텐서 가속기 자동 설계를 위한 유망한 프레임워크다.

Abstract: The growing demand for sparse tensor algebra (SpTA) in machine learning and
big data has driven the development of various sparse tensor accelerators.
However, most existing manually designed accelerators are limited to specific
scenarios, and it's time-consuming and challenging to adjust a large number of
design factors when scenarios change. Therefore, automating the design of SpTA
accelerators is crucial. Nevertheless, previous works focus solely on either
mapping (i.e., tiling communication and computation in space and time) or
sparse strategy (i.e., bypassing zero elements for efficiency), leading to
suboptimal designs due to the lack of comprehensive consideration of both. A
unified framework that jointly optimizes both is urgently needed. However,
integrating mapping and sparse strategies leads to a combinatorial explosion in
the design space(e.g., as large as $O(10^{41})$ for the workload $P_{32 \times
64} \times Q_{64 \times 48} = Z_{32 \times 48}$). This vast search space
renders most conventional optimization methods (e.g., particle swarm
optimization, reinforcement learning and Monte Carlo tree search) inefficient.
To address this challenge, we propose an evolution strategy-based sparse tensor
accelerator optimization framework, called SparseMap. SparseMap constructing a
more comprehensive design space with the consideration of both mapping and
sparse strategy. We introduce a series of enhancements to genetic encoding and
evolutionary operators, enabling SparseMap to efficiently explore the vast and
diverse design space. We quantitatively compare SparseMap with prior works and
classical optimization methods, demonstrating that SparseMap consistently finds
superior solutions.

</details>


### [409] [SNAP-UQ: Self-supervised Next-Activation Prediction for Single-Pass Uncertainty in TinyML](https://arxiv.org/abs/2508.12907)
*Ismail Lamaakal,Chaymae Yahyati,Khalid El Makkaoui,Ibrahim Ouahbi,Yassine Maleh*

Main category: cs.LG

TL;DR: SNAP-UQ는 TinyML 환경을 위한 단일-패스(label-free) 불확실도 추정 기법으로, 각 레이어의 다음 활성화(next-activation)를 깊이별로 예측하여 서프라이절(surprisal)을 계산하고 경량의 단조 매퍼로 점수화한다. 오버헤드가 매우 작고(수십 KB, int8 헤드), 추가 버퍼나 재전달 없이 동작하며, early-exit·앙상블 대비 메모리·지연을 크게 절감하면서 실패 탐지(AUROC≈0.9, AUPRC 개선)를 유지한다.


<details>
  <summary>Details</summary>
Motivation: TinyML 디바이스는 메모리·플래시·연산 자원이 극도로 제한되어 있으므로, 기존의 앙상블·여러 라운드 예측·중간 출력 기반 방법들이 실용적이지 않다. 따라서 추가 전처리나 반복 전달 없이도 신뢰도(uncertainty)를 실시간으로 제공하는 경량 기법이 필요하다.

Method: 각 층의 '다음 활성화' 통계(예: 평균·분산 등)를 이전 층의 압축된 표현에서 예측하는 소형 int8 헤드를 층별로 추가한다. 예측 오차(혹은 서프라이절)를 계산하고, 경량의 단조(mapping) 함수를 통해 사용가능한 스코어로 변환한다. 설계는 temporal buffer, auxiliary exits, 반복 전진 패스가 필요없도록 구성되어 MCU 환경에 수십 KB 수준의 오버헤드만 추가한다.

Result: 여러 비전·오디오 백본에서 early-exit·deep ensemble 대비 플래시와 지연을 대체로 40–60%·25–35% 절감. 비슷한 정확도 수준의 경쟁 방법들은 메모리 한도를 초과하는 경우가 많음. 잡음/변형된 스트림에서 실패(accuracy-drop) 탐지 AUPRC가 수 포인트 향상되며, 단일 패스에서 AUROC≈0.9 수준의 실패 탐지 성능을 보임.

Conclusion: 레이어 간 동적 변화(layer-to-layer dynamics)에 기초한 불확실도 측정은 TinyML에서 실용적이고 자원 효율적인 온디바이스 모니터링을 제공할 수 있다.

Abstract: We introduce \textbf{SNAP-UQ}, a single-pass, label-free uncertainty method
for TinyML that estimates risk from \emph{depth-wise next-activation
prediction}: tiny int8 heads forecast the statistics of the next layer from a
compressed view of the previous one, and a lightweight monotone mapper turns
the resulting surprisal into an actionable score. The design requires no
temporal buffers, auxiliary exits, or repeated forward passes, and adds only a
few tens of kilobytes to MCU deployments. Across vision and audio backbones,
SNAP-UQ consistently reduces flash and latency relative to early-exit and deep
ensembles (typically $\sim$40--60\% smaller and $\sim$25--35\% faster), with
competing methods of similar accuracy often exceeding memory limits. In
corrupted streams it improves accuracy-drop detection by several AUPRC points
and maintains strong failure detection (AUROC $\approx$0.9) in a single pass.
Grounding uncertainty in layer-to-layer dynamics yields a practical,
resource-efficient basis for on-device monitoring in TinyML.

</details>


### [410] [SL-ACC: A Communication-Efficient Split Learning Framework with Adaptive Channel-wise Compression](https://arxiv.org/abs/2508.12984)
*Zehang Lin,Zheng Lin,Miao Yang,Jianhao Huang,Yuxin Zhang,Zihan Fang,Xia Du,Zhe Chen,Shunzhi Zhu,Wei Ni*

Main category: cs.LG

TL;DR: 본 논문은 split learning(SL)에서 전송되는 smashed data의 통신량을 줄이기 위해 채널 중요도를 샤논 엔트로피로 평가하고, 엔트로피 기반 채널 그룹별로 적응적 압축을 적용하는 SL-ACC 프레임워크(ACII + CGC)를 제안한다. 실험에서 목표 정확도 도달 시간이 SOTA보다 짧음이 보고된다.


<details>
  <summary>Details</summary>
Motivation: 분산 학습(특히 FL/SL)에서 디바이스가 증가할수록 활성화(activations)와 그래디언트 등 smashed data 전송이 병목이 되어 학습 속도를 저하시킴. 리소스 제약 장치에서 통신 효율을 높여 SL을 현실적으로 만들기 위한 동기.

Method: (1) ACII: 샤논 엔트로피로 각 채널의 기여도를 계산하여 중요도를 평가. (2) CGC: 엔트로피에 따라 채널을 클러스터링(그룹화)하고 그룹 단위로 적응적 압축을 적용해 전송량을 감소시킴. 압축 수준은 그룹 중요도에 따라 달라지며, 정확도 저하를 최소화하도록 설계.

Result: 여러 데이터셋과 실험 설정에서 SL-ACC가 동일 목표 정확도에 도달하는 데 필요한 시간을 SOTA보다 현저히 단축. 전송량 감소와 학습 성능 보존을 동시에 달성함을 보고.

Conclusion: 샤논 엔트로피 기반 채널 중요도 평가와 그룹별 적응 압축의 조합은 SL에서 통신 병목을 완화하는 실용적 접근이다. 다만 엔트로피 계산 비용, 동적/비동일 데이터 분포, 압축이 개인정보 유출에 미치는 영향 등 추가 연구가 필요하다.

Abstract: The increasing complexity of neural networks poses a significant barrier to
the deployment of distributed machine learning (ML) on resource-constrained
devices, such as federated learning (FL). Split learning (SL) offers a
promising solution by offloading the primary computing load from edge devices
to a server via model partitioning. However, as the number of participating
devices increases, the transmission of excessive smashed data (i.e.,
activations and gradients) becomes a major bottleneck for SL, slowing down the
model training. To tackle this challenge, we propose a communication-efficient
SL framework, named SL-ACC, which comprises two key components: adaptive
channel importance identification (ACII) and channel grouping compression
(CGC). ACII first identifies the contribution of each channel in the smashed
data to model training using Shannon entropy. Following this, CGC groups the
channels based on their entropy and performs group-wise adaptive compression to
shrink the transmission volume without compromising training accuracy.
Extensive experiments across various datasets validate that our proposed SL-ACC
framework takes considerably less time to achieve a target accuracy than
state-of-the-art benchmarks.

</details>


### [411] [Predicting the Performance of Graph Convolutional Networks with Spectral Properties of the Graph Laplacian](https://arxiv.org/abs/2508.12993)
*Shalima Binta Manir,Tim Oates*

Main category: cs.LG

TL;DR: 논문 초록 요약: 그래프의 대수적 연결성(Fiedler 값)이 GCN 성능(노드 분류 등)을 예측하는 좋은 지표임을 실험 및 이론적으로 제시함. 여러 연결 성분의 집계 방법을 비교하고 Cora, CiteSeer, Polblogs 등 데이터에서 검증함.


<details>
  <summary>Details</summary>
Motivation: GCN에서 층을 쌓는 것이 성능 향상으로 이어지지 않는 경우가 많아, 그래프 구조적 특성이 GCN 성능에 어떤 영향을 주는지 규명하고자 함. 대수적 연결성이 구조적 유사성을 잘 반영하므로 성능 예측과 전이학습의 유용한 척도가 될 수 있다는 가설을 탐색.

Method: 합성 및 실제 그래프(Cora, CiteSeer, Polblogs)를 이용한 경험적 실험과 이론적 근거 제시. 연결 성분별 Fiedler 값을 여러 방식으로 집계하여 전체 그래프 지표를 만들고, 이 값과 GCN 성능 간 상관관계를 분석.

Result: Fiedler 값(및 제안된 집계 방식)이 GCN 성능을 잘 예측함. 그래프들 사이에 Fiedler 값이 유사하면 동일한 필터/하이퍼파라미터로 유사한 성능을 얻을 가능성이 높으며, 전이 학습에도 도움이 됨. 이론적 설명도 제공됨.

Conclusion: 대수적 연결성은 GCN 성능 예측 및 전이학습 유사성 판단에 유용한 지표가 될 수 있음. 추가 실험 및 이론적 고찰로 이 결과를 강화할 수 있음.

Abstract: A common observation in the Graph Convolutional Network (GCN) literature is
that stacking GCN layers may or may not result in better performance on tasks
like node classification and edge prediction. We have found empirically that a
graph's algebraic connectivity, which is known as the Fiedler value, is a good
predictor of GCN performance. Intuitively, graphs with similar Fiedler values
have analogous structural properties, suggesting that the same filters and
hyperparameters may yield similar results when used with GCNs, and that
transfer learning may be more effective between graphs with similar algebraic
connectivity. We explore this theoretically and empirically with experiments on
synthetic and real graph data, including the Cora, CiteSeer and Polblogs
datasets. We explore multiple ways of aggregating the Fiedler value for
connected components in the graphs to arrive at a value for the entire graph,
and show that it can be used to predict GCN performance. We also present
theoretical arguments as to why the Fiedler value is a good predictor.

</details>


### [412] [Kourkoutas-Beta: A Sunspike-Driven Adam Optimizer with Desert Flair](https://arxiv.org/abs/2508.12996)
*Stavros C. Kassinos*

Main category: cs.LG

TL;DR: 신규 Adam 계열 옵티마이저 Kourkoutas-Beta는 계층별 동적 beta2(두 번째 모멘트 감쇠)를 도입해 급격한 그래디언트 ‘스파이크’에 적응한다. 스파이크 시 beta2를 낮춰 적응속도를 높이고, 안정한 구간에서는 높은 beta2를 유지한다. 물리 기반 Transformer/PINN 및 기타 작업에서 수렴 안정성과 최종 손실을 개선하며 enwik8에서 BPC를 크게 낮춘다. 러닝 오버헤드는 작고 Adam의 수렴 보장은 보존된다.


<details>
  <summary>Details</summary>
Motivation: 물리 기반 문제(데이터 기반 PDE 대리모델, PINN 등)에서 경계·초기조건 변화나 복합 손실로 인해 손실이 요동치고 그래디언트가 스파이크를 일으키며, 고정된 beta2를 쓰는 Adam은 이런 상황에서 비효율적이고 불안정해진다.

Method: 각 층별로 현재의 누적(풀링된) 그래디언트 노름을 과거 EMA 노름으로 나눈 'sunspike' 비율을 계산해 [0,1)로 스쿼시한 값으로 beta2를 동적으로 설정한다. 스파이크 때는 beta2→beta2_min, 평온할 때는 beta2≈beta2_max. 선택적 기능: leaky-AMSGrad(감쇠), trust-region 클리핑(max_ratio), 적응형 tiny term, 편향 보정 모드('none','beta2max','exact'). 모든 기능을 끄고 bias_correction='none'이면 완전한 Adam과 동일.

Result: 네 가지 실험(Heat2D Transformer, Heat3D PINN, 합성 MLX 버스트 태스크, 소형 enwik8 문자 Transformer)에서 고정 beta2 Adam 대비 안정성과 최종 손실 개선. 소형 enwik8에서 Adam-0.95 대비 BPC 약 38% 감소, Adam-0.999 대비 약 58% 감소(10 시드 평균) 및 분산 감소. 런타임 오버헤드는 실험 집합 A–C에서 Adam과 유사, D에서 단일-digit 퍼센트 수준. Adam 스타일 수렴 보장 유지.

Conclusion: 스파이키한 그래디언트 환경에서 드롭인으로 쓸 수 있는 실용적이고 비교적 저비용의 Adam 변형이다. 하이퍼파라미터(특히 beta2_min/max, max_ratio 등) 민감도와 다양한 편향 보정 모드에 대한 추가 분석(및 공개 코드)이 있으면 실무 도입에 도움이 된다.

Abstract: Transformer neural networks are increasingly used for physics-based problems.
In data-driven PDE surrogates, training samples from varying boundary and
initial conditions can cause erratic losses and spiky gradients; in
physics-informed neural networks (PINNs), stiff composite losses amplify this
effect.
  We introduce Kourkoutas-Beta, an Adam-style optimizer where the fixed
second-moment discount beta2 is replaced by a layer-wise dynamic value driven
by a bounded ``sunspike'' ratio: the current pooled gradient norm divided by an
exponential moving average (EMA) of past norms, squashed to the interval [0,1).
Spikes lower beta2 toward beta2_min; calm phases keep it near beta2_max.
Options include leaky-AMSGrad (decay), trust-region clipping (max_ratio),
adaptive tiny terms, and several bias-correction modes ``none'', ``beta2max'',
``exact'). With all features off and bias_correction=``none'', the method is
exactly Adam.
  We test on four settings: (i) a Transformer PDE surrogate (Heat2D), (ii) a 3D
PINN for heat conduction (Heat3D), (iii) a lightweight MLX synthetic task with
jitter and rare-trigger bursts, and (iv) a character-level Transformer on 30 MB
of enwik8 (small-enwik8). Kourkoutas-Beta improves stability and final loss
versus fixed-beta2 Adam. On small-enwik8 it lowers bits-per-character by about
38% vs Adam-0.95 and about 58% vs Adam-0.999 over 10 seeds, with smaller
variance. The method remains drop-in, with runtime overhead comparable to Adam
in testbeds A-C and within single-digit percent in testbed D. It preserves
Adam-style convergence guarantees while improving robustness under spiky
gradients.

</details>


### [413] [Fairness-Aware Multi-view Evidential Learning with Adaptive Prior](https://arxiv.org/abs/2508.12997)
*Haishun Chen,Cai Xu,Jinlong Yu,Yilin Zhang,Ziyu Guan,Wei Zhao*

Main category: cs.LG

TL;DR: 이 논문은 멀티뷰 증거 기반 학습에서 데이터 풍부 클래스에 편향된 증거 할당 문제를 규명하고, 적응형 사전(adaptive prior), 클래스별 증거 분산 기반 공정성 제약, 그리고 뷰 간 의견 정렬(opinion alignment)을 결합한 FAML을 제안해 편향을 완화하고 예측 성능 및 불확실성 추정 신뢰도를 개선한다.


<details>
  <summary>Details</summary>
Motivation: 기존 멀티뷰 증거 학습은 각 뷰의 증거 학습이 신뢰할 수 있다고 가정하지만, 실제로는 샘플들이 데이터가 풍부한 클래스에 더 많은 증거를 할당받아 불균형하고 신뢰할 수 없는 불확실성 추정이 발생한다는 실증적 문제를 발견했다.

Method: FAML은 (1) 학습 궤적에 기반한 적응형 사전을 정규화로 도입하여 편향된 증거 학습을 유연하게 보정하고, (2) 클래스별 증거 분산에 대한 공정성 제약을 명시적으로 추가하여 증거 할당의 균형을 촉진하며, (3) 뷰 융합 단계에서 의견 정렬 메커니즘을 도입해 뷰 간의 편향을 완화하고 일관된 증거 통합을 유도한다.

Result: 다섯 개 실제 멀티뷰 데이터셋에서의 광범위한 실험을 통해 FAML은 증거 분배의 균형을 개선하고 기존 최첨단 방법보다 예측 성능 및 불확실성 추정의 신뢰도가 더 높음을 보였다.

Conclusion: FAML은 멀티뷰 증거 학습에서의 편향 문제를 효과적으로 완화하며, 공정성 제약과 뷰 간 정렬을 통해 보다 신뢰할 수 있는 불확실성 추정과 향상된 분류 성능을 제공한다.

Abstract: Multi-view evidential learning aims to integrate information from multiple
views to improve prediction performance and provide trustworthy uncertainty
esitimation. Most previous methods assume that view-specific evidence learning
is naturally reliable. However, in practice, the evidence learning process
tends to be biased. Through empirical analysis on real-world data, we reveal
that samples tend to be assigned more evidence to support data-rich classes,
thereby leading to unreliable uncertainty estimation in predictions. This
motivates us to delve into a new Biased Evidential Multi-view Learning (BEML)
problem. To this end, we propose Fairness-Aware Multi-view Evidential Learning
(FAML). FAML first introduces an adaptive prior based on training trajectory,
which acts as a regularization strategy to flexibly calibrate the biased
evidence learning process. Furthermore, we explicitly incorporate a fairness
constraint based on class-wise evidence variance to promote balanced evidence
allocation. In the multi-view fusion stage, we propose an opinion alignment
mechanism to mitigate view-specific bias across views, thereby encouraging the
integration of consistent and mutually supportive evidence. Extensive
experiments on five real-world multi-view datasets demonstrate that FAML
achieves more balanced evidence allocation and improves both prediction
performance and the reliability of uncertainty estimation compared to
state-of-the-art methods.

</details>


### [414] [Monte Carlo Functional Regularisation for Continual Learning](https://arxiv.org/abs/2508.13006)
*Pengcheng Hao,Menghao Waiyan William Zhu,Ercan Engin Kuruoglu*

Main category: cs.LG

TL;DR: MCFRCL은 몬테카를로 샘플링으로 예측 분포를 근사하고, 세 가지 연속 분포에 대한 모멘트 기반 특징 추출과 Wasserstein·KL 거리로 기능적 정규화를 수행하여 CL 성능과 학습 효율을 개선한 방법이다.


<details>
  <summary>Details</summary>
Motivation: 기능적 정규화 기반의 연속 학습이 가중치 정규화보다 성능은 좋지만 계산 비용이 크고 선형 근사 오차가 커 실무 적용에 한계가 있어 이를 개선하려는 목적.

Method: 모델 예측 분포를 Monte Carlo 샘플링으로 근사하고, 얻은 샘플의 통계적 특성을 세 가지 연속 분포(논문에서 지정된 분포들)로 모멘트 기반으로 캡처한 뒤, Wasserstein 거리와 KL 거리 기반의 정규화 항을 결합해 손실을 구성함.

Result: MNIST와 CIFAR 벤치마크에서 여러 기준 방법들과 비교해 예측 정확도와 학습 효율성(시간/자원 측면)에서 우수한 성능을 보였다고 보고함.

Conclusion: MC 기반의 기능적 정규화와 두 거리 지표의 결합으로 기존 방법의 선형 근사 오차와 계산 비용 문제를 완화하며, 연속 학습에 유망한 접근임.

Abstract: Continual learning (CL) is crucial for the adaptation of neural network
models to new environments. Although outperforming weight-space regularisation
approaches, the functional regularisation-based CL methods suffer from high
computational costs and large linear approximation errors. In this work, we
present a new functional regularisation CL framework, called MCFRCL, which
approximates model prediction distributions by Monte Carlo (MC) sampling.
Moreover, three continuous distributions are leveraged to capture the
statistical characteristics of the MC samples via moment-based methods.
Additionally, both the Wasserstein distance and the Kullback-Leibler (KL)
distance are employed to construct the regularisation function. The proposed
MCFRCL is evaluated against multiple benchmark methods on the MNIST and CIFAR
datasets, with simulation results highlighting its effectiveness in both
prediction accuracy and training efficiency.

</details>


### [415] [Design and Analysis of Robust Adaptive Filtering with the Hyperbolic Tangent Exponential Kernel M-Estimator Function for Active Noise Control](https://arxiv.org/abs/2508.13018)
*Iam Kim de S. Hermont,Andre R. Flores,Rodrigo C. de Lamare*

Main category: cs.LG

TL;DR: 충격성(임펄시브) 잡음 환경에서 능동소음제어(ANC)를 위해 제안된 필터드-엑스 하이퍼볼릭 탄젠트 지수 일반화 커널 M-추정(FXHEKM) 알고리즘은 α-안정 잡음 하에서 기존 알고리즘보다 MSE와 평균 소음 감쇄(ANR) 성능이 우수하다.


<details>
  <summary>Details</summary>
Motivation: 실제 ANC 시스템은 스파이크성·임펄시브 잡음(예: α-안정 분포)을 만나면 기존 최소제곱 기반 알고리즘이 성능 저하를 겪음. 이에 강건한 손실함수/추정 방법을 도입하여 임펄시브 간섭에 강한 적응필터를 설계할 필요가 있음.

Method: 필터드-엑스 구조에 하이퍼볼릭 탄젠트와 지수항을 결합한 일반화 커널 M-추정 손실함수(FXHEKM)를 도입. 제안 알고리즘의 수학적·통계적 거동(수렴 특성 등)과 계산 복잡도를 분석하고, 성능 평가지표로 평균제곱오차(MSE)와 평균 소음 감쇄(ANR)를 사용해 수치실험을 수행함.

Result: 수치실험에서 제안 FXHEKM은 α-안정 잡음(임펄시브 신호) 하에서 경쟁 알고리즘들보다 MSE와 ANR이 개선된 것으로 보고됨. 제안 기법은 잡음의 스파이크성 신호를 효과적으로 제거함을 보임.

Conclusion: FXHEKM은 임펄시브 환경에서 ANC 성능을 향상시키는 유망한 방법이나, 계산복잡도와 매개변수(커널·탄젠트·지수 파라미터) 튜닝의 민감성은 추가 연구가 필요함. 실측 데이터, 실시간 구현 가능성, 복잡도 저감 기법 검토가 권장됨.

Abstract: In this work, we propose a robust adaptive filtering approach for active
noise control applications in the presence of impulsive noise. In particular,
we develop the filtered-x hyperbolic tangent exponential generalized Kernel
M-estimate function (FXHEKM) robust adaptive algorithm. A statistical analysis
of the proposed FXHEKM algorithm is carried out along with a study of its
computational cost. {In order to evaluate the proposed FXHEKM algorithm, the
mean-square error (MSE) and the average noise reduction (ANR) performance
metrics have been adopted.} Numerical results show the efficiency of the
proposed FXHEKM algorithm to cancel the presence of the additive spurious
signals, such as \textbf{$\alpha$}-stable noises against competing algorithms.

</details>


### [416] [The Application of Transformer-Based Models for Predicting Consequences of Cyber Attacks](https://arxiv.org/abs/2508.13030)
*Bipin Chhetri,Akbar Siami Namin*

Main category: cs.LG

TL;DR: MITRE CWE의 취약점 텍스트를 이용해 사이버공격의 결과(Availability, Access Control, Confidentiality, Integrity, Other)를 다중 레이블로 분류하였다. BERT가 전체 정확도 0.972로 가장 우수했고, HAN은 특정 라벨에서 CNN/LSTM 기반 베이스라인들보다 우수했다.


<details>
  <summary>Details</summary>
Motivation: 사이버 공격의 복잡성이 증가함에 따라 공격 설명을 자동으로 분석하고 그 잠재적 영향을 예측하는 자동화된 도구가 필요하다. 이를 통해 보안 전문가가 신속히 대응하고 자원을 효율적으로 배분할 수 있다.

Method: MITRE CWE의 텍스트 설명을 전처리해 다중 레이블 분류 문제로 설정했다. 모델로는 BERT(사전학습 트랜스포머)와 Hierarchical Attention Network(HAN)를 비롯해 기존의 CNN·LSTM 기반 모델들을 비교 실험하였다. 성능 평가는 정확도, 정밀도, 재현율 등으로 수행한 것으로 보인다.

Result: BERT가 전체 정확도 0.972로 가장 높은 성능을 보였고, 정밀도와 재현율에서도 일관되게 우수했다. HAN은 특정 사이버보안 라벨(일부 카테고리)에서 CNN/LSTM보다 높은 성능을 기록했다.

Conclusion: 사건·취약점 설명에서 영향 범주를 예측하는 데에 BERT 기반 접근이 가장 적합하다. HAN은 라벨별로 해석 가능성과 성능 이점이 있어 보완적으로 유용하다. 다만 데이터 불균형, 평가 지표 상세, 임상적(현업) 검증 등에 대한 추가 분석이 필요하다.

Abstract: Cyberattacks are increasing, and securing against such threats is costing
industries billions of dollars annually. Threat Modeling, that is,
comprehending the consequences of these attacks, can provide critical support
to cybersecurity professionals, enabling them to take timely action and
allocate resources that could be used elsewhere. Cybersecurity is heavily
dependent on threat modeling, as it assists security experts in assessing and
mitigating risks related to identifying vulnerabilities and threats. Recently,
there has been a pressing need for automated methods to assess attack
descriptions and forecast the future consequences of the increasing complexity
of cyberattacks. This study examines how Natural Language Processing (NLP) and
deep learning can be applied to analyze the potential impact of cyberattacks by
leveraging textual descriptions from the MITRE Common Weakness Enumeration
(CWE) database. We emphasize classifying attack consequences into five
principal categories: Availability, Access Control, Confidentiality, Integrity,
and Other. This paper investigates the use of Bidirectional Encoder
Representations from Transformers (BERT) in combination with Hierarchical
Attention Networks (HANs) for Multi-label classification, evaluating their
performance in comparison with conventional CNN and LSTM-based models.
Experimental findings show that BERT achieves an overall accuracy of $0.972$,
far higher than conventional deep learning models in multi-label
classification. HAN outperforms baseline forms of CNN and LSTM-based models on
specific cybersecurity labels. However, BERT consistently achieves better
precision and recall, making it more suitable for predicting the consequences
of a cyberattack.

</details>


### [417] [Beyond Internal Data: Bounding and Estimating Fairness from Incomplete Data](https://arxiv.org/abs/2508.13040)
*Varsha Ramineni,Hossein A. Rahmani,Emine Yilmaz,David Barber*

Main category: cs.LG

TL;DR: 내부 예측속성 데이터와 외부 공개 보호속성(예: 인구조사)만 존재할 때, 가능한 결합분포 집합을 구성해 공정성 지표의 가능한 범위를 계산함으로써 완전한 데이터 없이도 공정성 평가를 할 수 있다는 방법을 제안한다. 시뮬레이션과 실제 실험에서 의미 있는 상·하한을 얻고 진짜 지표를 신뢰성 있게 추정함을 보였다.


<details>
  <summary>Details</summary>
Motivation: 규제와 독립적 편향 감사 요구가 증가하는 가운데, 실무에서는 법적·프라이버시 제약으로 인구통계학적 보호속성이 완전하게 수집되지 못한다. 관련 데이터가 기관 내부(예측속성)와 외부 공공소스(보호속성)로 분리되어 존재하는 상황에서 제한된 정보로도 공정성 검사를 수행할 방법이 필요하다.

Method: 가용한 주변분포(내부 데이터의 예측변수와 외부의 보호속성)를 이용해 모든 가능한 결합분포의 집합을 구성하고, 그 집합 내에서 공정성 지표(예: 그룹별 오류율, 기회균등 등)의 최솟값·최댓값을 계산한다. 수치적·최적화적 기법으로 식별영역(identification region)을 도출해 지표의 가능한 범위를 제공한다.

Result: 시뮬레이션과 실제 데이터 실험에서 제안법이 의미 있는 상·하한을 산출하고, 해당 범위가 참값을 포함하거나 참값을 좁히는 데 유효함을 보였다. 실무적 제약 하에서도 공정성 테스트에 실용적인 정보를 제공한다는 결과를 제시한다.

Conclusion: 완전한 결합 데이터에 접근 불가한 현실적 조건에서, 주변정보로부터 공정성 지표의 가능한 범위를 추론하는 접근이 실무적·효율적인 해결책이 될 수 있으며 감사·규제 준수에 기여할 수 있다.

Abstract: Ensuring fairness in AI systems is critical, especially in high-stakes
domains such as lending, hiring, and healthcare. This urgency is reflected in
emerging global regulations that mandate fairness assessments and independent
bias audits. However, procuring the necessary complete data for fairness
testing remains a significant challenge. In industry settings, legal and
privacy concerns restrict the collection of demographic data required to assess
group disparities, and auditors face practical and cultural challenges in
gaining access to data. In practice, data relevant for fairness testing is
often split across separate sources: internal datasets held by institutions
with predictive attributes, and external public datasets such as census data
containing protected attributes, each providing only partial, marginal
information. Our work seeks to leverage such available separate data to
estimate model fairness when complete data is inaccessible. We propose
utilising the available separate data to estimate a set of feasible joint
distributions and then compute the set plausible fairness metrics. Through
simulation and real experiments, we demonstrate that we can derive meaningful
bounds on fairness metrics and obtain reliable estimates of the true metric.
Our results demonstrate that this approach can serve as a practical and
effective solution for fairness testing in real-world settings where access to
complete data is restricted.

</details>


### [418] [Hierarchical Evaluation Function (HEF): A Multi-Metric Approach for Optimizing Demand Forecasting Models](https://arxiv.org/abs/2508.13057)
*Adolfo González,Víctor Parada*

Main category: cs.LG

TL;DR: HEF(계층적 평가함수)가 글로벌 지표와 강건성에서 FMAE보다 우수하며, FMAE는 지역(단기) 성능과 실행속도에서 장점이 있다.


<details>
  <summary>Details</summary>
Motivation: 다변량 시계열 수요예측에서 데이터 복잡성·불확실성·레짐 변화로 인해 기존 평가지표가 편향을 일으키고 일반화에 제약을 주기 때문에, 목적에 맞는 맞춤형 평가함수를 비교하여 모델 선택과 튜닝을 개선하려는 목적.

Method: FMAE(절대오차 최소화)와 HEF(글로벌 가중치 및 큰 편차 페널티)를 정의하고, 데이터 분할(91:9,80:20,70:30)과 세 가지 옵티마이저(Grid Search, PSO, Optuna) 조합으로 실험. 평가영역은 적합도(R2), 상대정확도, RMSE, RMSSE, MAE, MASE, 강건성, 계산효율성 등. 시각화와 통계검정으로 결과 확인.

Result: HEF가 R2, 상대정확도, RMSE, RMSSE 등 글로벌 메트릭에서 일관되게 우수했고 모델의 설명력과 강건성이 향상됨. FMAE는 MAE·MASE·실행시간에서 더 나아 단기·운영 시나리오에 적합. 통계검정과 시각화로 유의미성 확인.

Conclusion: 평가함수 설계에서 전략적(장기·글로벌) 목표에는 HEF를, 운영적(단기·로컬) 목표에는 FMAE를 권장. 제안된 프레임워크는 동적 환경에서 예측모델 최적화를 재현 가능하게 함.

Abstract: Demand forecasting is essential for strategic planning in competitive
environments, enabling resource optimization and improved responsiveness to
market dynamics. However, multivariate time series modeling faces challenges
due to data complexity, uncertainty, and frequent regime shifts. Traditional
evaluation metrics can introduce biases and limit generalization. This work
compares two custom evaluation functions: FMAE (Focused Mean Absolute Error),
focused on minimizing absolute errors, and HEF (Hierarchical Evaluation
Function), designed to weight global metrics and penalize large deviations.
Experiments were conducted under different data splits (91:9, 80:20, 70:30)
using three optimizers (Grid Search, PSO, Optuna), assessing fit, relative
accuracy, robustness, and computational efficiency. Results show that HEF
consistently outperforms FMAE in global metrics (R2, Relative Accuracy, RMSE,
RMSSE), enhancing model robustness and explanatory power. These findings were
confirmed via visualizations and statistical tests. Conversely, FMAE offers
advantages in local metrics (MAE, MASE) and execution time, making it suitable
for short-term scenarios. The study highlights a methodological trade-off: HEF
is ideal for strategic planning, while FMAE is better suited for operational
efficiency. A replicable framework is proposed for optimizing predictive models
in dynamic environments.

</details>


### [419] [Seeing the Many: Exploring Parameter Distributions Conditioned on Features in Surrogates](https://arxiv.org/abs/2508.13088)
*Xiaohan Wang,Zhimin Li,Joshua A. Levine,Matthew Berger*

Main category: cs.LG

TL;DR: Proposes modeling and visualizing the distribution of input parameters that produce a target simulation feature by combining a surrogate model with a density-based estimate of surrogate error to form a prior, then sampling plausible parameters via a likelihood on features; demonstrated with an interactive visualization on three simulation datasets.


<details>
  <summary>Details</summary>
Motivation: Inverse problems in simulation are often treated as search for a few matching parameter sets; authors argue for representing the full set/distribution of plausible parameters that can produce a target feature, while accounting for surrogate approximation error and enabling interactive exploration.

Method: Estimate density over parameter space that reflects proximity to training examples measured in both input and output spaces to model surrogate reliability; use this density as a prior and combine with a feature-based likelihood to sample parameter configurations that plausibly generate the target feature; integrate sampling and density into an interactive visualization for feature-driven parameter analysis.

Result: Applied the approach to three simulation datasets and produced a visualization interface that allows exploring the distribution of plausible parameters for specified output features; code released on GitHub.

Conclusion: Density-aware sampling over surrogate models offers a way to surface not only individual inverse solutions but the broader set of plausible parameter configurations while mitigating surrogate extrapolation errors, enabling more informative and interactive inverse analysis.

Abstract: Recently, neural surrogate models have emerged as a compelling alternative to
traditional simulation workflows. This is accomplished by modeling the
underlying function of scientific simulations, removing the need to run
expensive simulations. Beyond just mapping from input parameter to output,
surrogates have also been shown useful for inverse problems: output to input
parameters. Inverse problems can be understood as search, where we aim to find
parameters whose surrogate outputs contain a specified feature. Yet finding
these parameters can be costly, especially for high-dimensional parameter
spaces. Thus, existing surrogate-based solutions primarily focus on finding a
small set of matching parameters, in the process overlooking the broader
picture of plausible parameters. Our work aims to model and visualize the
distribution of possible input parameters that produce a given output feature.
To achieve this goal, we aim to address two challenges: (1) the approximation
error inherent in the surrogate model and (2) forming the parameter
distribution in an interactive manner. We model error via density estimation,
reporting high density only if a given parameter configuration is close to
training parameters, measured both over the input and output space. Our density
estimate is used to form a prior belief on parameters, and when combined with a
likelihood on features, gives us an efficient way to sample plausible parameter
configurations that generate a target output feature. We demonstrate the
usability of our solution through a visualization interface by performing
feature-driven parameter analysis over the input parameter space of three
simulation datasets. Source code is available at
https://github.com/matthewberger/seeing-the-many

</details>


### [420] [Outlier Detection of Poisson-Distributed Targets Using a Seabed Sensor Network](https://arxiv.org/abs/2508.13099)
*Mingyu Kim,Daniel Stilwell,Jorge Jimenez*

Main category: cs.LG

TL;DR: 해양 환경에서 정상/이상(commission) 발생을 혼합 모형으로 모델링하고, 로그 가우시안 콕스 프로세스(LGCP)에서 정상 강도의 평균과 분산을 이용한 2차 근사로 새로운 관측의 이상 확률을 추정한다. 또한 이상 강도에 따라 실시간으로 센서 배치를 최적화해 탐지 성능을 향상시킨다. 실제 항로 데이터로 검증해 분류·탐지 성능 개선을 보였다.


<details>
  <summary>Details</summary>
Motivation: 해상에서 정상적인 선박 활동과 이상(예: 불법 침입·미등록 활동)을 구분하는 것은 안전·감시 목적에서 중요하다. 관측은 공간적으로 불완전하고 불확실성이 커서 단순 평균 기반 판별은 오탐·미탐을 유발할 수 있다. 따라서 정상 강도의 불확실성(분산)을 반영한 더 정확한 이상 확률 추정과 탐지를 위한 동적 센서 배치가 필요하다.

Method: 목표 도착을 정상 프로세스와 이상 프로세스의 혼합으로 모델링하고, 정상 프로세스의 강도를 LGCP로 가정해 평균과 분산을 추정한다. 새로운 이벤트가 이상일 확률에 대해 1차(평균만) 근사 대신 평균·분산을 포함한 2차 근사를 제안하여 판별 정확도를 개선한다. 이론적으로 제안한 근사가 Jensen 부등식을 이용해 실제 확률에 더 긴밀한 상한(bound)을 제공함을 보였다. 추가로 이상 강도에 기반한 실시간 근최적(sensor placement) 배치 알고리즘을 도입해 센서 위치를 동적으로 조정한다.

Result: 노퍽 근처 실제 선박 교통 데이터에 적용한 수치실험에서 2차 근사가 평균 전용 근사보다 분류 성능(정밀도·재현율 혹은 AUC 등)을 향상시켰고, 동적 센서 배치가 이상 탐지율을 유의미하게 개선함을 보였다.

Conclusion: 정상 강도의 분산 정보를 포함한 2차 근사와 이상 기반 실시간 센서 배치는 해상 이상(commission) 분류·탐지 성능을 향상시킨다. 제안 방법은 실제 데이터로 검증되었으며, 이론적 정당성(긴밀한 상한)과 실무적 유용성을 모두 갖춘다.

Abstract: This paper presents a framework for classifying and detecting spatial
commission outliers in maritime environments using seabed acoustic sensor
networks and log Gaussian Cox processes (LGCPs). By modeling target arrivals as
a mixture of normal and outlier processes, we estimate the probability that a
newly observed event is an outlier. We propose a second-order approximation of
this probability that incorporates both the mean and variance of the normal
intensity function, providing improved classification accuracy compared to
mean-only approaches. We analytically show that our method yields a tighter
bound to the true probability using Jensen's inequality. To enhance detection,
we integrate a real-time, near-optimal sensor placement strategy that
dynamically adjusts sensor locations based on the evolving outlier intensity.
The proposed framework is validated using real ship traffic data near Norfolk,
Virginia, where numerical results demonstrate the effectiveness of our approach
in improving both classification performance and outlier detection through
sensor deployment.

</details>


### [421] [A Perfectly Truthful Calibration Measure](https://arxiv.org/abs/2508.13100)
*Jason Hartline,Lunjia Hu,Yifan Wu*

Main category: cs.LG

TL;DR: Design of ATB (averaged two-bin calibration error), the first perfectly truthful calibration measure in the batch setting; efficient to compute and closely related to existing measures (smCal, distCal).


<details>
  <summary>Details</summary>
Motivation: Existing calibration measures incentivize predictors to lie on finite samples; prior work only gave approximate truthfulness in sequential settings. A perfectly truthful batch measure was missing.

Method: Define averaged two-bin calibration error (ATB). Prove truthfulness plus properties (soundness, completeness, continuity). Show quadratic relations between ATB and smCal/distCal. Provide a general construction recipe for truthful measures and derive variants (e.g., quantile-binned l2-ECE). Develop faster estimation algorithms for calibration testing.

Result: ATB is perfectly truthful in expectation, computationally simple to evaluate, and enables faster/simpler calibration testing algorithms than smCal and distCal. It connects theoretically to existing measures and yields other truthful measures via the recipe.

Conclusion: ATB closes a theoretical gap by providing a perfectly truthful, practical calibration measure in the batch setting and offers both theoretical connections and algorithmic improvements; suggests further work on extensions and empirical evaluation.

Abstract: Calibration requires that predictions are conditionally unbiased and,
therefore, reliably interpretable as probabilities. Calibration measures
quantify how far a predictor is from perfect calibration. As introduced by
Haghtalab et al. (2024), a calibration measure is truthful if it is minimized
in expectation when a predictor outputs the ground-truth probabilities.
Although predicting the true probabilities guarantees perfect calibration, in
reality, when calibration is evaluated on a finite sample, predicting the truth
is not guaranteed to minimize any known calibration measure. All known
calibration measures incentivize predictors to lie in order to appear more
calibrated on a finite sample. Such lack of truthfulness motivated Haghtalab et
al. (2024) and Qiao and Zhao (2025) to construct approximately truthful
calibration measures in the sequential prediction setting, but no perfectly
truthful calibration measure was known to exist even in the more basic batch
setting.
  We design a perfectly truthful calibration measure in the batch setting:
averaged two-bin calibration error (ATB). In addition to being truthful, ATB is
sound, complete, continuous, and quadratically related to two existing
calibration measures: the smooth calibration error (smCal) and the (lower)
distance to calibration (distCal). The simplicity in our definition of ATB
makes it efficient and straightforward to compute. ATB allows faster estimation
algorithms with significantly easier implementations than smCal and distCal,
achieving improved running time and simplicity for the calibration testing
problem studied by Hu et al. (2024). We also introduce a general recipe for
constructing truthful measures, which proves the truthfulness of ATB as a
special case and allows us to construct other truthful calibration measures
such as quantile-binned l_2-ECE.

</details>


### [422] [Causally-Guided Pairwise Transformer -- Towards Foundational Digital Twins in Process Industry](https://arxiv.org/abs/2508.13111)
*Michael Mayr,Georgios C. Chasparis*

Main category: cs.LG

TL;DR: 이 논문은 알려진 인과 그래프를 유도적 바이어스로 도입한 Causally-Guided Pairwise Transformer(CGPT)를 제안한다. CGPT는 다변수 시계열을 변수 쌍(pair) 단위로 분해하고 채널-의존성은 쌍 수준에서, 채널-비의존성은 쌍 간에 확보해 확장성과 any-variate 적응성을 달성한다. 합성·실세계 산업 데이터에서 CI/CD 기반선보다 예측 성능이 우수하다고 보고한다.


<details>
  <summary>Details</summary>
Motivation: 산업용 다차원 시계열 모델링에서 채널-의존(CD) 모델은 변수 간 상호작용을 잘 포착하지만 특정 차원에 묶여 일반화와 적응성이 떨어지고, 채널-비의존(CI) 모델은 일반화는 좋지만 변수 간 상호작용을 명시적으로 모델링하지 못한다. 이 두 속성의 트레이드오프를 해소하려는 목적.

Method: 알려진 인과 그래프를 유도적 바이어스로 사용하고, 다변수 데이터를 변수 쌍(pair)으로 분해하는 pairwise 변환기를 설계. 파라미터는 변수 수와 무관하게 채널-무관하게 학습되며, 쌍 수준으로 CD 정보 흐름을 강제하고 쌍 간에는 CI처럼 일반화되도록 구성.

Result: 합성 및 실제 산업 데이터에서 장기 및 단스텝 예측 실험을 통해 CI·CD 베이스라인보다 예측 정확도에서 유의미한 성능 우위를 보였고, 차원에 독립적인 특성에도 불구하고 end-to-end CD 모델과 경쟁적인 성능을 달성.

Conclusion: pairwise 분해와 인과 그래프 바이어스를 결합하면 변수 수에 독립적인 유연한 아키텍처로 복잡한 시스템 역학을 효과적으로 모델링할 수 있으며, 산업용 다변수 시계열 예측에서 실용적 이점을 제공한다.

Abstract: Foundational modelling of multi-dimensional time-series data in industrial
systems presents a central trade-off: channel-dependent (CD) models capture
specific cross-variable dynamics but lack robustness and adaptability as model
layers are commonly bound to the data dimensionality of the tackled use-case,
while channel-independent (CI) models offer generality at the cost of modelling
the explicit interactions crucial for system-level predictive regression tasks.
To resolve this, we propose the Causally-Guided Pairwise Transformer (CGPT), a
novel architecture that integrates a known causal graph as an inductive bias.
The core of CGPT is built around a pairwise modeling paradigm, tackling the
CD/CI conflict by decomposing the multidimensional data into pairs. The model
uses channel-agnostic learnable layers where all parameter dimensions are
independent of the number of variables. CGPT enforces a CD information flow at
the pair-level and CI-like generalization across pairs. This approach
disentangles complex system dynamics and results in a highly flexible
architecture that ensures scalability and any-variate adaptability. We validate
CGPT on a suite of synthetic and real-world industrial datasets on long-term
and one-step forecasting tasks designed to simulate common industrial
complexities. Results demonstrate that CGPT significantly outperforms both CI
and CD baselines in predictive accuracy and shows competitive performance with
end-to-end trained CD models while remaining agnostic to the problem
dimensionality.

</details>


### [423] [Contrastive Representations for Temporal Reasoning](https://arxiv.org/abs/2508.13113)
*Alicja Ziarko,Michal Bortkiewicz,Michal Zawalski,Benjamin Eysenbach,Piotr Milos*

Main category: cs.LG

TL;DR: CRTR(Combinatorial Representations for Temporal Reasoning)는 기존의 시계열 대비 학습(temporal contrastive learning)이 잡음(spurious features) 때문에 시간적 구조를 포착하지 못하는 문제를, 새로운 네거티브 샘플링 방식으로 해결하여 시간적 추론 능력을 갖춘 표현을 학습하는 방법이다. Sokoban과 Rubik's Cube 같은 복잡한 시간 구조 도메인에서 우수한 성능을 보이며, 특히 Rubik's Cube에서는 모든 초기 상태에 대해 일반화 가능한 표현을 학습해 외부 검색 알고리즘 없이 퍼즐을 풀 수 있다고 주장한다.


<details>
  <summary>Details</summary>
Motivation: 전통적 AI에서 지각(perception)과 계획(planning)은 분리되어 왔고, 계획은 보통 탐색(search)으로 구현된다. 저자들은 단일 표현이 지각과 시간 구조(계획)를 동시에 포착할 수 있는지, 즉 표현만으로 시간적 추론이 Emergent하게 가능한지를 탐구한다. 기존의 temporal contrastive 방식은 자주 쓰이나 스푸리어스(feature) 때문에 시간적 구조를 제대로 학습하지 못한다는 관찰에서 출발한다.

Method: CRTR은 조합적(combinatorial) 네거티브 샘플링 스키마를 도입해 스푸리어스 피처들이 표현에 남지 않도록 이론적 보장을 제공한다. 구체적으로는 시간적 관계를 깨트리는(또는 의미 없는) 네거티브 예제를 선택/구성하여 모델이 진짜 시간적 신호에만 민감하도록 학습시킨다. 이로써 표현이 행동연쇄의 시간적 구조를 반영하도록 유도한다.

Result: 복잡한 시간 구조를 가진 도메인들(Sokoban, Rubik's Cube)에서 강한 성능을 보고한다. 특히 Rubik's Cube에서 모든 초기 상태에 일반화 가능한 표현을 학습했고, 학습된 표현만으로 퍼즐을 해결할 수 있었다. 비교적으로 BestFS보다 탐색 단계 수는 적게 필요했지만(즉 탐색 효율은 높음), 생성된 해법은 더 길었다.

Conclusion: CRTR은 네거티브 샘플링 설계만으로 스푸리어스 피처를 제거하고 시간적 추론을 표현으로부터 유도할 수 있음을 보인다. Rubik's Cube 사례는 학습된 표현만으로 임의의 상태를 해결하는 최초의 효율적 방법이라는 주장을 포함한다.

Abstract: In classical AI, perception relies on learning state-based representations,
while planning, which can be thought of as temporal reasoning over action
sequences, is typically achieved through search. We study whether such
reasoning can instead emerge from representations that capture both perceptual
and temporal structure. We show that standard temporal contrastive learning,
despite its popularity, often fails to capture temporal structure due to its
reliance on spurious features. To address this, we introduce Combinatorial
Representations for Temporal Reasoning (CRTR), a method that uses a negative
sampling scheme to provably remove these spurious features and facilitate
temporal reasoning. CRTR achieves strong results on domains with complex
temporal structure, such as Sokoban and Rubik's Cube. In particular, for the
Rubik's Cube, CRTR learns representations that generalize across all initial
states and allow it to solve the puzzle using fewer search steps than BestFS,
though with longer solutions. To our knowledge, this is the first method that
efficiently solves arbitrary Cube states using only learned representations,
without relying on an external search algorithm.

</details>


### [424] [Training Machine Learning Models on Human Spatio-temporal Mobility Data: An Experimental Study [Experiment Paper]](https://arxiv.org/abs/2508.13135)
*Yueyang Liu,Lance Kennedy,Ruochen Kong,Joon-Seok Kim,Andreas Züfle*

Main category: cs.LG

TL;DR: 개인 단위 장기 이동경로 예측을 다룬 실험 논문으로, LSTM·Transformer 모델과 다양한 학습 전략(사용자 군집·층화 표본추출·소배치 SGD 등)을 비교해 ‘요일·사용자 이력’과 같은 의미적 정보 및 샘플링이 예측 성능에 미치는 영향을 실증한다.


<details>
  <summary>Details</summary>
Motivation: 기존 연구가 단기·미시적 위치 예측에 집중하는 반면, 며칠~몇 주 단위의 개인 전체 궤적(매크로 패턴·라이프루틴) 예측은 상대적으로 덜 연구되어 있으며, 개인 특성·데이터 불균형·프라이버시 제약 하에서 어떻게 모델을 훈련할지 규범을 제시하려는 목적.

Method: LSTM 및 Transformer 계열 모델을 중심으로 다양한 하이퍼파라미터와 학습 전략을 광범위 실험. 요일 등 의미적 피처와 사용자별 이력 정보를 명시적으로 포함하여 입력을 확장. 사용자 샘플링이 데이터 편향을 심화함을 관찰하고, 사용자 의미군집(semantic clustering)과 층화 표본추출(stratified sampling)로 대표성 유지. 소배치 SGD가 제한된 데이터에서 유리함을 확인.

Result: 요일·사용자 이력 정보 포함 시 예측 성능 향상. 무작위 사용자 샘플링은 편향과 정확도 저하를 초래하며, 의미 기반 군집+층화 표본추출로 성능 및 다양성 보존 가능. 소배치 학습이 특히 데이터가 적을 때 성능 개선을 보임.

Conclusion: 장기 개인 이동 예측은 의미적 피처와 적절한 사용자 샘플링 전략이 중요하며, 데이터 불균형·프라이버시 제약을 고려한 학습 규범(군집 기반 층화·소배치 최적화 등)이 실무적 효과를 높인다.

Abstract: Individual-level human mobility prediction has emerged as a significant topic
of research with applications in infectious disease monitoring, child, and
elderly care. Existing studies predominantly focus on the microscopic aspects
of human trajectories: such as predicting short-term trajectories or the next
location visited, while offering limited attention to macro-level mobility
patterns and the corresponding life routines. In this paper, we focus on an
underexplored problem in human mobility prediction: determining the best
practices to train a machine learning model using historical data to forecast
an individuals complete trajectory over the next days and weeks. In this
experiment paper, we undertake a comprehensive experimental analysis of diverse
models, parameter configurations, and training strategies, accompanied by an
in-depth examination of the statistical distribution inherent in human mobility
patterns. Our empirical evaluations encompass both Long Short-Term Memory and
Transformer-based architectures, and further investigate how incorporating
individual life patterns can enhance the effectiveness of the prediction. We
show that explicitly including semantic information such as day-of-the-week and
user-specific historical information can help the model better understand
individual patterns of life and improve predictions. Moreover, since the
absence of explicit user information is often missing due to user privacy, we
show that the sampling of users may exacerbate data skewness and result in a
substantial loss in predictive accuracy. To mitigate data imbalance and
preserve diversity, we apply user semantic clustering with stratified sampling
to ensure that the sampled dataset remains representative. Our results further
show that small-batch stochastic gradient optimization improves model
performance, especially when human mobility training data is limited.

</details>


### [425] [MDPO: Overcoming the Training-Inference Divide of Masked Diffusion Language Models](https://arxiv.org/abs/2508.13148)
*Haoyu He,Katrin Renz,Yong Cao,Andreas Geiger*

Main category: cs.LG

TL;DR: Diffusion 언어모델의 훈련(무작위 마스킹)과 추론(점진적 마스킹 스케줄) 간 불일치를 강화학습으로 해결한 논문. Masked Diffusion Policy Optimization(MDPO)를 통해 추론 스케줄로 직접 학습하여 효율성과 성능을 크게 향상시키고, 추가로 학습이 필요 없는 추론용 리마스킹 전략(RCR)을 제안하여 성능을 더 끌어올림.


<details>
  <summary>Details</summary>
Motivation: MDLM(마스크드 디퓨전 언어모델)은 추론 과정에서 점진적으로 마스크를 줄이며 구조를 드러내지만, 훈련은 무작위 마스킹으로 이루어져 추론-훈련 불일치가 존재한다. 이 불일치가 성능 저하의 원인으로 의심되며 이를 해소하는 방법이 필요함.

Method: 문제를 순차적 의사결정(마르코프) 문제로 재정의하고 강화학습을 적용. MDPO는 디퓨전의 마르코프 특성을 이용해 추론에 사용되는 점진적 정제 스케줄로 모델을 직접 학습시키는 정책 최적화 기법이다. 추가로 학습 없이 적용 가능한 리마스킹 전략 RCR을 추론 시 플러그인으로 도입.

Result: 기존 SOTA와 동등한 성능을 60배 적은 gradient 업데이트로 달성. 동일한 업데이트 예산에서 MATH500에서 평균 +9.6%, Countdown에서 평균 +54.2% 향상. RCR은 일관된 성능 개선을 보이며 MDPO와 결합 시 추가 이득을 제공.

Conclusion: 훈련-추론 스케줄 불일치를 해소하는 것이 MDLM 성능 개선에 매우 효과적임을 보였다. MDPO는 효율적이고 강력한 접근법이며 RCR은 실무적으로 유용한 추론 개선책이다. 향후에는 다양한 스케줄, 태스크 및 안정성/샘플 효율성 관련 추가 연구가 기대됨.

Abstract: Diffusion language models, as a promising alternative to traditional
autoregressive (AR) models, enable faster generation and richer conditioning on
bidirectional context. However, they suffer from a key discrepancy between
training and inference: during inference, MDLMs progressively reveal the
structure of the generated sequence by producing fewer and fewer masked tokens,
whereas this structure is ignored in training as tokens are masked at random.
Although this discrepancy between training and inference can lead to suboptimal
performance, it has been largely overlooked by previous works, leaving closing
this gap between the two stages an open problem. To address this, we frame the
problem of learning effective denoising trajectories as a sequential
decision-making problem and use the resulting framework to apply reinforcement
learning. We propose a novel Masked Diffusion Policy Optimization (MDPO) to
exploit the Markov property diffusion possesses and explicitly train the model
under the same progressive refining schedule used at inference. MDPO matches
the performance of the previous state-of-the-art (SOTA) method with 60x fewer
gradient updates, while achieving average improvements of 9.6% on MATH500 and
54.2% on Countdown over SOTA when trained within the same number of weight
updates. Additionally, we improve the remasking strategy of MDLMs as a plug-in
inference replacement to overcome the limitation that the model cannot refine
tokens flexibly. This simple yet effective training-free strategy, what we
refer to as RCR, consistently improves performance and yields additional gains
when combined with MDPO. Our findings establish great potential for
investigating the discrepancy between pre-training and inference of MDLMs.
Code: https://github.com/autonomousvision/mdpo. Project Page:
https://cli212.github.io/MDPO/.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [426] [Centralized Permutation Equivariant Policy for Cooperative Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2508.11706)
*Zhuofan Xu,Benedikt Bollig,Matthias Függer,Thomas Nowak,Vincent Le Dréau*

Main category: cs.MA

TL;DR: CPE는 실행도 중앙집중식으로 하는 새로운 프레임워크로, 순열 등변성(permutation equivariant)을 갖는 경량 네트워크(GLPE)를 도입해 CTDE의 부분관찰·확장성 문제를 완화하고 MPE·SMAC·RWARE에서 성능을 크게 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: CTDE에서 훈련 시 중앙정보를 쓰더라도 실행은 각 에이전트의 부분관찰에 의존해 성능 저하가 발생하고, 완전 중앙집중식 정책은 에이전트 수 증가에 따른 확장성 문제를 겪는다. 이 두 한계를 동시에 해결할 방법이 필요하다.

Method: 완전 중앙집중식 정책으로 실행까지 밀어붙이되, Global-Local Permutation Equivariant(GLPE) 아키텍처를 사용해 순열 등변성으로 매개변수와 구조를 공유·경량화한다. 이 구조는 value decomposition 및 actor-critic 계열에 용이하게 통합된다.

Result: GLPE 기반 CPE는 MPE, SMAC, RWARE의 표준 CTDE 알고리즘 성능을 크게 개선했으며, RWARE에서는 최첨단 구현과 동등한 성능을 보였다. 경량·확장성·구현 용이성을 주장한다.

Conclusion: 중앙집중식 실행을 허용할 수 있는 환경에서는 CPE가 CTDE의 성능·확장성 문제를 동시에 완화할 실용적 대안이 될 수 있다. 다만 실행 시 전역 관찰성 가정, 이질적 에이전트·대규모 에이전트 수에 대한 세부 분석이 필요하다.

Abstract: The Centralized Training with Decentralized Execution (CTDE) paradigm has
gained significant attention in multi-agent reinforcement learning (MARL) and
is the foundation of many recent algorithms. However, decentralized policies
operate under partial observability and often yield suboptimal performance
compared to centralized policies, while fully centralized approaches typically
face scalability challenges as the number of agents increases.
  We propose Centralized Permutation Equivariant (CPE) learning, a centralized
training and execution framework that employs a fully centralized policy to
overcome these limitations. Our approach leverages a novel permutation
equivariant architecture, Global-Local Permutation Equivariant (GLPE) networks,
that is lightweight, scalable, and easy to implement. Experiments show that CPE
integrates seamlessly with both value decomposition and actor-critic methods,
substantially improving the performance of standard CTDE algorithms across
cooperative benchmarks including MPE, SMAC, and RWARE, and matching the
performance of state-of-the-art RWARE implementations.

</details>


### [427] [SafeSieve: From Heuristics to Experience in Progressive Pruning for LLM-based Multi-Agent Communication](https://arxiv.org/abs/2508.11733)
*Ruijia Zhang,Xinyan Zhao,Ruixiang Wang,Sigen Chen,Guibin Zhang,An Zhang,Kun Wang,Qingsong Wen*

Main category: cs.MA

TL;DR: SafeSieve는 LLM 기반 멀티에이전트 통신을 점진적·적응적으로 가지치기해 토큰 사용을 줄이면서 성능을 유지하는 알고리즘이다. 초기에는 LLM의 의미적 평가로 그래프를 구성하고, 이후 누적 성능 피드백으로 연결을 정교화한다. 0-extension 클러스터링으로 구조적 연속성을 보존하며 비효율적 링크를 제거한다.


<details>
  <summary>Details</summary>
Motivation: 멀티에이전트 시스템은 협업 능력이 뛰어나지만 에이전트 간 불필요한 통신으로 토큰 오버헤드와 중복이 발생한다. 기존 방법들은 사전학습 GNN이나 그리디 Top-k 같은 단편적 최적화에 치중하여 초기화와 후속 보정의 통일된 전략을 제공하지 못한다.

Method: SafeSieve는 이중 메커니즘을 사용: (1) 초기화 단계에서 LLM 기반 의미 점수로 통신 후보를 선별하고 (2) 실행 단계에서 누적 성능 피드백을 반영해 동적으로 링크를 가지치기한다. 기존의 단순 Top-k 제거 대신 0-extension 클러스터링을 적용해 에이전트 그룹의 구조적 일관성을 유지하면서 불필요한 연결을 제거한다.

Result: 벤치마크(SVAMP, HumanEval 등)에서 평균 정확도 94.01%를 달성했고 토큰 사용량을 12.4%–27.8% 절감했다. 프롬프트 인젝션 공격에 대해 평균 정확도 하락 1.23%로 견고함을 보였고, 이종 환경에서는 배포 비용을 13.3% 줄이면서 성능을 유지했다.

Conclusion: SafeSieve는 초기 LLM 추정과 경험 기반 피드백을 결합한 점진적·적응적 가지치기 방식과 0-extension 클러스터링으로 효율성과 견고성을 모두 확보한 실용적 멀티에이전트 프레임워크이다.

Abstract: LLM-based multi-agent systems exhibit strong collaborative capabilities but
often suffer from redundant communication and excessive token overhead.
Existing methods typically enhance efficiency through pretrained GNNs or greedy
algorithms, but often isolate pre- and post-task optimization, lacking a
unified strategy. To this end, we present SafeSieve, a progressive and adaptive
multi-agent pruning algorithm that dynamically refines the inter-agent
communication through a novel dual-mechanism. SafeSieve integrates initial
LLM-based semantic evaluation with accumulated performance feedback, enabling a
smooth transition from heuristic initialization to experience-driven
refinement. Unlike existing greedy Top-k pruning methods, SafeSieve employs
0-extension clustering to preserve structurally coherent agent groups while
eliminating ineffective links. Experiments across benchmarks (SVAMP, HumanEval,
etc.) showcase that SafeSieve achieves 94.01% average accuracy while reducing
token usage by 12.4%-27.8%. Results further demonstrate robustness under prompt
injection attacks (1.23% average accuracy drop). In heterogeneous settings,
SafeSieve reduces deployment costs by 13.3% while maintaining performance.
These results establish SafeSieve as a robust, efficient, and scalable
framework for practical multi-agent systems. Our code can be found in
https://anonymous.4open.science/r/SafeSieve-D8F2FFUN.

</details>


### [428] [A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond](https://arxiv.org/abs/2508.11957)
*Xiaodong Qu,Andrews Damoah,Joshua Sherwood,Peiyan Liu,Christian Shun Jin,Lulu Chen,Minjie Shen,Nawwaf Aleisa,Zeyuan Hou,Chenyu Zhang,Lifu Gao,Yanshu Li,Qikai Yang,Qun Wang,Cristabelle De Souza*

Main category: cs.MA

TL;DR: 이 리뷰 논문은 현대 AI 에이전트의 아키텍처 원리, 핵심 구성요소, 그리고 인지·계획·상호작용을 통합하려는 최근 패러다임을 체계적으로 정리한다. 주요 발전, 지속적 과제(안전·윤리·해석가능성 포함), 향후 연구 방향을 제시한다.


<details>
  <summary>Details</summary>
Motivation: AI 에이전트가 규칙 기반에서 학습 기반의 자율 시스템으로 빠르게 진화하며 인지·계획·상호작용의 통합 설계가 여전히 어려움. 이 분야의 분산된 연구들을 종합해 통합적 이해와 향후 연구 지침을 제공하려는 목적.

Method: 문헌 리뷰를 통해 인지과학 영감을 받은 모델, 계층적 강화학습, 대형언어모델 기반 추론 등 다양한 접근을 비교·분석. 아키텍처 원칙, 구성 요소(지각, 추론, 계획, 실행, 상호작용), 그리고 안전·윤리 이슈를 체계적으로 분류·논의.

Result: 현대 AI 에이전트의 주요 패러다임(계층적 제어, 모듈식 설계, LLM을 중추로 한 추론 루프 등)과 이들이 해결하는 문제 및 한계를 규명. 안전성·해석가능성·데이터·멀티에이전트 협력에서의 난제들을 식별.

Conclusion: 통합적 에이전트 설계는 모듈 간 인터페이스 표준화, 학습·추론의 계층화, 안전성·윤리성 내장, 그리고 실세계 배포를 위한 검증 프레임워크가 필요하다. 향후 연구는 적응성·견고성·신뢰성을 높이는 방향으로 진행되어야 한다.

Abstract: Artificial Intelligence (AI) agents have rapidly evolved from specialized,
rule-based programs to versatile, learning-driven autonomous systems capable of
perception, reasoning, and action in complex environments. The explosion of
data, advances in deep learning, reinforcement learning, and multi-agent
coordination have accelerated this transformation. Yet, designing and deploying
unified AI agents that seamlessly integrate cognition, planning, and
interaction remains a grand challenge. In this review, we systematically
examine the architectural principles, foundational components, and emergent
paradigms that define the landscape of contemporary AI agents. We synthesize
insights from cognitive science-inspired models, hierarchical reinforcement
learning frameworks, and large language model-based reasoning. Moreover, we
discuss the pressing ethical, safety, and interpretability concerns associated
with deploying these agents in real-world scenarios. By highlighting major
breakthroughs, persistent challenges, and promising research directions, this
review aims to guide the next generation of AI agent systems toward more
robust, adaptable, and trustworthy autonomous intelligence.

</details>


### [429] [Synchronization Dynamics of Heterogeneous, Collaborative Multi-Agent AI Systems](https://arxiv.org/abs/2508.12314)
*Chiranjit Mitra*

Main category: cs.MA

TL;DR: Kuramoto 모델을 확장해 위상·진폭을 갖는 이종 AI 에이전트를 결합 진동자로 모델링하고, 조정 정도를 나타내는 오더 파라미터를 도입해 결속력·네트워크 구조·에이전트 다양성이 집단 행동에 미치는 영향을 분석한다. Chain-of-Thought(사고 연쇄)를 동기화 현상에 대응시켜 협업적 추론을 통합적으로 설명하며, 전결합(all-to-all) 및 결정론적 스케일프리 네트워크 시뮬레이션에서 결합 강도가 증가하면 이질적 능력에도 불구하고 강건한 동기화가 발생함을 보인다.


<details>
  <summary>Details</summary>
Motivation: 다중 에이전트 AI 시스템의 협업·조정 메커니즘을 엄밀하게 설명하고 설계할 수 있는 수학적·물리학적 기반이 필요하다. 특히 에이전트의 이질성, 영향력, 통신 구조가 집단 지성·추론 과정에 미치는 영향을 정량화하고, Chain-of-Thought와 같은 인간 유사의 반복적 추론을 집단 동역학 관점에서 통합하려는 목적이 있다.

Method: 에이전트를 위상과 진폭을 지닌 결합 진동자(coupled oscillators)로 모델링하고, 시스템의 조정도를 나타내는 오더 파라미터를 정의한다. 결합 강도, 에이전트 다양성, 네트워크 토폴로지(전결합, 결정적 스케일프리)를 변수로 수치시뮬레이션을 수행하며 Chain-of-Thought를 동기화 과정에 대응시키는 이론적 대응 규약을 형식화한다.

Result: 시뮬레이션에서 결합 강도가 커질수록 이질적 에이전트들 사이에서도 높은 수준의 동기화가 유도되었고, 네트워크 토폴로지와 에이전트 다양성은 동기화 임계치와 강건성에 중요한 영향을 미쳤다. 제안한 오더 파라미터는 집단 조정도를 정량화했고, Chain-of-Thought와의 대응은 반복적 상호작용이 집단 추론을 촉진함을 시사한다.

Conclusion: Kuramoto 기반의 물리정보학적 모델은 스케일러블하고 해석 가능한 다중 에이전트 AI 설계·분석을 위한 엄밀한 수학적 토대를 제공한다. 향후 학습 동역학 및 적응형 네트워크를 통합하면 시스템의 효율성과 복원력이 더욱 향상될 것으로 기대된다.

Abstract: We present a novel interdisciplinary framework that bridges synchronization
theory and multi-agent AI systems by adapting the Kuramoto model to describe
the collective dynamics of heterogeneous AI agents engaged in complex task
execution. By representing AI agents as coupled oscillators with both phase and
amplitude dynamics, our model captures essential aspects of agent
specialization, influence, and communication within networked systems. We
introduce an order parameter to quantify the degree of coordination and
synchronization, providing insights into how coupling strength, agent
diversity, and network topology impact emergent collective behavior.
Furthermore, we formalize a detailed correspondence between Chain-of-Thought
prompting in AI reasoning and synchronization phenomena, unifying human-like
iterative problem solving with emergent group intelligence. Through extensive
simulations on all-to-all and deterministic scale-free networks, we demonstrate
that increased coupling promotes robust synchronization despite heterogeneous
agent capabilities, reflecting realistic collaborative AI scenarios. Our
physics-informed approach establishes a rigorous mathematical foundation for
designing, analyzing, and optimizing scalable, adaptive, and interpretable
multi-agent AI systems. This work opens pathways for principled orchestration
of agentic AI and lays the groundwork for future incorporation of learning
dynamics and adaptive network architectures to further enhance system
resilience and efficiency.

</details>


### [430] [A Taxonomy of Hierarchical Multi-Agent Systems: Design Patterns, Coordination Mechanisms, and Industrial Applications](https://arxiv.org/abs/2508.12683)
*David J. Moore*

Main category: cs.MA

TL;DR: 계층적 다중 에이전트 시스템(HMAS)을 제어 계층, 정보 흐름, 역할·업무 위임, 시간적 계층, 통신 구조의 5개 축으로 분류하는 다차원 분류체계를 제안하고, 고전적 조정 메커니즘과 계층적 강화학습·대형 언어모델 결합 가능성을 연결하며 산업 사례와 향후 과제를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 계층 구조가 복잡성·확장성 관리를 돕지만 설계 선택이 가져오는 트레이드오프(전역 효율성 vs. 로컬 자율성 등)가 명확하지 않아, 설계 비교와 의사결정을 돕기 위한 통합적 렌즈가 필요함.

Method: 제안한 5개 축(제어 계층, 정보 흐름, 역할·업무 위임, 시간적 계층, 통신 구조)을 중심으로 분류체계를 구성하고, 전통적 메커니즘(예: 계약-넷)과 현대적 방법(계층적 강화학습, LLM 에이전트)을 연계하여 산업 사례(전력망, 유전 운영)에 적용해 분석함.

Result: 단일 프레임워크로 구조적·시간적·통신적 차원을 통합한 최초의 분류체계를 제시하고, 사례 분석을 통해 계층 구조가 전역 효율성과 로컬 자율성의 균형을 달성할 가능성을 보여주며, 설명가능성·대규모 확장·학습 기반 에이전트 통합의 과제를 도출함.

Conclusion: 계층적 MAS 설계를 비교·분석하는 유용한 도구를 제공하지만, 실험적 검증·정량적 지표·인간-집단 상호작용·학습 기반 에이전트의 안전성 검토 등 후속 연구가 필요하다.

Abstract: Hierarchical multi-agent systems (HMAS) organize collections of agents into
layered structures that help manage complexity and scale. These hierarchies can
simplify coordination, but they also can introduce trade-offs that are not
always obvious. This paper proposes a multi-dimensional taxonomy for HMAS along
five axes: control hierarchy, information flow, role and task delegation,
temporal layering, and communication structure. The intent is not to prescribe
a single "best" design but to provide a lens for comparing different
approaches.
  Rather than treating these dimensions in isolation, the taxonomy is connected
to concrete coordination mechanisms - from the long-standing contract-net
protocol for task allocation to more recent work in hierarchical reinforcement
learning. Industrial contexts illustrate the framework, including power grids
and oilfield operations, where agents at production, maintenance, and supply
levels coordinate to diagnose well issues or balance energy demand. These cases
suggest that hierarchical structures may achieve global efficiency while
preserving local autonomy, though the balance is delicate.
  The paper closes by identifying open challenges: making hierarchical
decisions explainable to human operators, scaling to very large agent
populations, and assessing whether learning-based agents such as large language
models can be safely integrated into layered frameworks. This paper presents
what appears to be the first taxonomy that unifies structural, temporal, and
communication dimensions of hierarchical MAS into a single design framework,
bridging classical coordination mechanisms with modern reinforcement learning
and large language model agents.

</details>
