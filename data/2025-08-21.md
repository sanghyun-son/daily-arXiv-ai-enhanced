<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 58]
- [cs.CL](#cs.CL) [Total: 39]
- [cs.IR](#cs.IR) [Total: 10]
- [cs.LG](#cs.LG) [Total: 45]
- [cs.AI](#cs.AI) [Total: 9]
- [cs.DC](#cs.DC) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [RynnEC: Bringing MLLMs into Embodied World](https://arxiv.org/abs/2508.14160)
*Ronghao Dang,Yuqian Yuan,Yunxuan Mao,Kehan Li,Jiangpin Liu,Zhikai Wang,Xin Li,Fan Wang,Deli Zhao*

Main category: cs.CV

TL;DR: RynnEC는 비전-언어 기반의 컴팩트한 비디오 멀티모달 LLM으로, 영역 인코더(region encoder)와 마스크 디코더(mask decoder)를 결합해 영역 수준의 비디오 상호작용을 지원한다. 에고센트릭 비디오에서 임베디드 인지 데이터를 생성하는 파이프라인과 RynnEC-Bench 벤치마크를 제시하며, 객체 속성 이해, 분할, 공간 추론에서 SOTA 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 임베디드 에이전트가 물리적 세계를 더 정밀하게 인지·상호작용하도록 하는 범용 인지 코어 개발을 목표로 한다. 특히 3D 주석 데이터 부족을 해결하고, 영역 중심(region-centric) 영상 처리로 세밀한 지각을 제공하려는 필요성에서 출발한다.

Method: 기존 범용 비전-언어 파운데이션 모델을 바탕으로 지역(Region) 인코더와 마스크 디코더를 결합한 아키텍처를 설계해 영역 수준의 비디오 인터랙션을 가능하게 함. 또한 에고센트릭(egocentric) 비디오 기반 파이프라인으로 임베디드 인지용 데이터를 합성/생성하고, 평가를 위한 RynnEC-Bench를 구성.

Result: 컴팩트한 구조에도 불구하고 객체 속성 이해, 객체 분할, 공간 추론 과제에서 최첨단 성능을 달성했다는 결과를 보고함. 코드·체크포인트·벤치마크를 공개하여 재현성과 확장성을 지원한다.

Conclusion: 영역 중심의 비디오 패러다임을 통해 임베디드 에이전트의 정밀한 지각 및 상호작용이 가능해지며, RynnEC와 RynnEC-Bench는 범용 인지 코어 발전과 다양한 임베디드 작업으로의 일반화에 기여할 것으로 기대된다.

Abstract: We introduce RynnEC, a video multimodal large language model designed for
embodied cognition. Built upon a general-purpose vision-language foundation
model, RynnEC incorporates a region encoder and a mask decoder, enabling
flexible region-level video interaction. Despite its compact architecture,
RynnEC achieves state-of-the-art performance in object property understanding,
object segmentation, and spatial reasoning. Conceptually, it offers a
region-centric video paradigm for the brain of embodied agents, providing
fine-grained perception of the physical world and enabling more precise
interactions. To mitigate the scarcity of annotated 3D datasets, we propose an
egocentric video based pipeline for generating embodied cognition data.
Furthermore, we introduce RynnEC-Bench, a region-centered benchmark for
evaluating embodied cognitive capabilities. We anticipate that RynnEC will
advance the development of general-purpose cognitive cores for embodied agents
and facilitate generalization across diverse embodied tasks. The code, model
checkpoints, and benchmark are available at:
https://github.com/alibaba-damo-academy/RynnEC

</details>


### [2] [Safety-Critical Learning for Long-Tail Events: The TUM Traffic Accident Dataset](https://arxiv.org/abs/2508.14567)
*Walter Zimmer,Ross Greer,Xingcheng Zhou,Rui Song,Marc Pavel,Daniel Lehmberg,Ahmed Ghita,Akshay Gopalkrishnan,Mohan Trivedi,Alois Knoll*

Main category: cs.CV

TL;DR: TUM Traffic Accident (TUMTraf-A)는 고속도로 실제 사고 비디오·라이다 데이터셋으로, 4대의 도로변 카메라와 라이다로 수집된 48,144 프레임에 대해 2D/3D 박스와 트랙 ID를 대규모로 주석함. 저자들은 규칙 기반과 학습 기반을 결합한 Accid3nD 사고 검출기를 제안하며 실험과 소거 연구로 방법의 견고함을 보임.


<details>
  <summary>Details</summary>
Motivation: 교통 네트워크의 안전성 향상 연구에도 불구하고 실제 고속도로 사고는 여전히 빈발하며, 이를 이해·분석할 수 있는 현실적인 고품질 데이터가 필요함.

Method: TUMTraf-A 데이터셋을 구성(4대 카메라+라이다, 10Hz 수집, OpenLABEL 포맷, 10개 객체 클래스)하고, 사고 검출을 위해 규칙 기반 로직과 학습 기반 모듈을 결합한 Accid3nD 모델을 제안. 데이터와 코드 공개.

Result: 데이터셋 규모: 48,144 프레임, 294,924개의 2D 박스, 93,012개의 3D 박스 및 트랙 ID. 제안한 Accid3nD는 데이터셋에서 실험과 소거 연구를 통해 견고함을 보였음.

Conclusion: TUMTraf-A는 고속도로 사고 연구(특히 비디오·라이다 기반 사고 감지/추적)를 위한 실세계 대규모 멀티센서 데이터셋이며, Accid3nD는 이 데이터에서 유의미한 성능을 보임. 데이터·모델·코드는 공개되어 후속 연구에 활용 가능.

Abstract: Even though a significant amount of work has been done to increase the safety
of transportation networks, accidents still occur regularly. They must be
understood as an unavoidable and sporadic outcome of traffic networks. We
present the TUM Traffic Accident (TUMTraf-A) dataset, a collection of
real-world highway accidents. It contains ten sequences of vehicle crashes at
high-speed driving with 294,924 labeled 2D and 93,012 labeled 3D boxes and
track IDs within 48,144 labeled frames recorded from four roadside cameras and
LiDARs at 10 Hz. The dataset contains ten object classes and is provided in the
OpenLABEL format. We propose Accid3nD, an accident detection model that
combines a rule-based approach with a learning-based one. Experiments and
ablation studies on our dataset show the robustness of our proposed method. The
dataset, model, and code are available on our project website:
https://tum-traffic-dataset.github.io/tumtraf-a.

</details>


### [3] [Federated Action Recognition for Smart Worker Assistance Using FastPose](https://arxiv.org/abs/2508.14113)
*Vinit Hegiste,Vidit Goyal,Tatjana Legler,Martin Ruskowski*

Main category: cs.CV

TL;DR: 연구는 산업 환경의 상체 동작을 골격(포즈) 기반으로 인식하기 위해 프라이버시를 보장하는 연합학습(FL) 프레임워크를 제안한다. LSTM 및 Transformer 기반 시계열 백본을 중앙집중식, 로컬, FedAvg, FedEnsemble 네 가지 학습 시나리오로 비교했고, FL 특히 FedEnsemble이 중앙집중식보다 일반화 성능을 크게 향상시킴을 보였다.


<details>
  <summary>Details</summary>
Motivation: 스마트 제조에서 작업자 행동을 실시간으로 정확히 인식하는 것은 중요하나, 산업 현장은 개인정보·프라이버시 제약이 커 중앙집중식 데이터 수집이 어렵다. 골격 기반 HAR는 조명·시점 변동에 강하지만 분산·프라이버시 환경에서의 성능·일반화 문제를 해결할 필요가 있다.

Method: 직접 수집한 5명의 참여자로부터 8가지 상체 제스처 골격 데이터셋을 만들고 FastPose(수정)를 사용해 관절 좌표를 추출했다. 두 가지 시계열 백본(LSTM, Transformer)을 각각 중앙집중식, 클라이언트별 로컬, FedAvg(가중치 연합 평균), FedEnsemble(연합 앙상블)으로 학습·평가했다. 평가에는 글로벌 테스트셋과 보지 않은 외부 클라이언트가 포함된다.

Result: 글로벌 테스트에서 FL Transformer는 중앙집중식보다 +12.4%p, FedEnsemble은 +16.3%p 향상되었다. 보지 않은 외부 클라이언트에서는 FL과 FedEnsemble이 중앙집중식 대비 각각 +52.6%p, +58.3%p의 큰 성능 개선을 보였다.

Conclusion: 연합학습은 개인정보를 보호하면서도 사용자 간 이질성(분산된 데이터)에 대한 일반화 성능을 크게 향상시켜, 이질적 산업 환경에서 확장 가능한 프라이버시 보존형 골격 기반 HAR의 실용적 해법임을 입증했다.

Abstract: In smart manufacturing environments, accurate and real-time recognition of
worker actions is essential for productivity, safety, and human-machine
collaboration. While skeleton-based human activity recognition (HAR) offers
robustness to lighting, viewpoint, and background variations, most existing
approaches rely on centralized datasets, which are impractical in
privacy-sensitive industrial scenarios. This paper presents a federated
learning (FL) framework for pose-based HAR using a custom skeletal dataset of
eight industrially relevant upper-body gestures, captured from five
participants and processed using a modified FastPose model. Two temporal
backbones, an LSTM and a Transformer encoder, are trained and evaluated under
four paradigms: centralized, local (per-client), FL with weighted federated
averaging (FedAvg), and federated ensemble learning (FedEnsemble). On the
global test set, the FL Transformer improves over centralized training by +12.4
percentage points, with FedEnsemble delivering a +16.3 percentage points gain.
On an unseen external client, FL and FedEnsemble exceed centralized accuracy by
+52.6 and +58.3 percentage points, respectively. These results demonstrate that
FL not only preserves privacy but also substantially enhances cross-user
generalization, establishing it as a practical solution for scalable,
privacy-aware HAR in heterogeneous industrial settings.

</details>


### [4] [LENS: Learning to Segment Anything with Unified Reinforced Reasoning](https://arxiv.org/abs/2508.14153)
*Lianghui Zhu,Bin Ouyang,Yuxuan Zhang,Tianheng Cheng,Rui Hu,Haocheng Shen,Longjin Ran,Xiaoxin Chen,Li Yu,Wenyu Liu,Xinggang Wang*

Main category: cs.CV

TL;DR: LENS는 텍스트 유도 이미지 분할에서 테스트 시 명시적인 체인-오브-생각(CoT) 추론을 강화하기 위해 개발된 강화학습 프레임워크로, 추론 과정과 마스크 분할을 종단간으로 공동 최적화한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 지도학습 기반 미세 튜닝 방법들은 테스트 시 CoT 추론을 명시적으로 사용하지 않아 미지의 프롬프트와 도메인으로 일반화가 제한된다.

Method: 문장-, 박스-, 세그먼트 수준의 통합된 강화학습 보상을 설계하여 모델이 정보성 있는 CoT 근거를 생성하면서 마스크 품질을 개선하도록 장려한다. 공개 30억 파라미터 비전-언어 모델(Qwen2.5-VL-3B-Instruct)을 사용해 학습했다.

Result: RefCOCO, RefCOCO+, RefCOCOg에서 평균 cIoU 81.2%를 달성했으며, 강력한 미세튜닝 방법인 GLaMM 대비 최대 5.6%p 향상했다.

Conclusion: RL 기반 CoT 추론은 텍스트 유도 분할의 강력한 사전 지식(prior)으로 작용하며, 보다 일반화 가능한 Segment Anything 계열 모델로 나아갈 현실적 경로를 제시한다.

Abstract: Text-prompted image segmentation enables fine-grained visual understanding
and is critical for applications such as human-computer interaction and
robotics. However, existing supervised fine-tuning methods typically ignore
explicit chain-of-thought (CoT) reasoning at test time, which limits their
ability to generalize to unseen prompts and domains. To address this issue, we
introduce LENS, a scalable reinforcement-learning framework that jointly
optimizes the reasoning process and segmentation in an end-to-end manner. We
propose unified reinforcement-learning rewards that span sentence-, box-, and
segment-level cues, encouraging the model to generate informative CoT
rationales while refining mask quality. Using a publicly available
3-billion-parameter vision-language model, i.e., Qwen2.5-VL-3B-Instruct, LENS
achieves an average cIoU of 81.2% on the RefCOCO, RefCOCO+, and RefCOCOg
benchmarks, outperforming the strong fine-tuned method, i.e., GLaMM, by up to
5.6%. These results demonstrate that RL-driven CoT reasoning serves as a robust
prior for text-prompted segmentation and offers a practical path toward more
generalizable Segment Anything models. Code is available at
https://github.com/hustvl/LENS.

</details>


### [5] [CLIPSym: Delving into Symmetry Detection with CLIP](https://arxiv.org/abs/2508.14197)
*Tinghan Yang,Md Ashiqur Rahman,Raymond A. Yeh*

Main category: cs.CV

TL;DR: CLIP의 이미지·언어 인코더와 회전-등변(de) 컨볼루션 기반 디코더 및 새로운 프롬프트 기법을 결합해 영상/이미지의 대칭(회전·반사)을 검출하는 방법을 제안한다. CLIP의 언어 신호를 활용한 성능 향상과 세 가지 데이터셋에서의 SOTA 달성을 보였다.


<details>
  <summary>Details</summary>
Motivation: 대칭은 컴퓨터 비전의 기본 기하학적 단서이나 정확한 검출이 어려움. CLIP 같은 비전-언어 사전학습 모델이 자연 이미지 설명에 담긴 대칭 단서를 제공할 수 있는지 탐구하려는 동기.

Method: CLIPSym: CLIP의 이미지·언어 인코더를 사용하고, Transformer와 G-Conv(군 합성곱)의 하이브리드로 구성된 회전-등변 디코더로 회전 및 반사 대칭을 예측. 언어 인코더를 효과적으로 활용하기 위해 Semantic-Aware Prompt Grouping(SAPG)이라는 프롬프트 집계 기법을 도입해 객체 기반 다양한 프롬프트를 통합.

Result: 세 개의 표준 대칭 검출 데이터셋(DENDI, SDRW, LDRS)에서 기존 최첨단 방법을 능가. CLIP 사전학습, 등변 디코더, SAPG의 기여를 확인하는 상세한 소거 연구 수행.

Conclusion: 비전-언어 사전학습 모델의 언어적 시맨틱스와 회전 등변 구조를 결합하면 대칭 검출 성능을 실질적으로 향상시킬 수 있음. 구현 코드 공개됨.

Abstract: Symmetry is one of the most fundamental geometric cues in computer vision,
and detecting it has been an ongoing challenge. With the recent advances in
vision-language models,~i.e., CLIP, we investigate whether a pre-trained CLIP
model can aid symmetry detection by leveraging the additional symmetry cues
found in the natural image descriptions. We propose CLIPSym, which leverages
CLIP's image and language encoders and a rotation-equivariant decoder based on
a hybrid of Transformer and $G$-Convolution to detect rotation and reflection
symmetries. To fully utilize CLIP's language encoder, we have developed a novel
prompting technique called Semantic-Aware Prompt Grouping (SAPG), which
aggregates a diverse set of frequent object-based prompts to better integrate
the semantic cues for symmetry detection. Empirically, we show that CLIPSym
outperforms the current state-of-the-art on three standard symmetry detection
datasets (DENDI, SDRW, and LDRS). Finally, we conduct detailed ablations
verifying the benefits of CLIP's pre-training, the proposed equivariant
decoder, and the SAPG technique. The code is available at
https://github.com/timyoung2333/CLIPSym.

</details>


### [6] [A Survey on Video Anomaly Detection via Deep Learning: Human, Vehicle, and Environment](https://arxiv.org/abs/2508.14203)
*Ghazal Alinezhad Noghre,Armin Danesh Pazho,Hamed Tabkhi*

Main category: cs.CV

TL;DR: 이 논문은 비디오 이상 탐지(VAD) 분야의 포괄적 서베이로, 다양한 감독 수준 및 온라인·능동·연속 학습 등 적응형 학습 방법을 포함하여 인적·차량·환경 중심의 세 가지 응용 분야별로 문헌을 체계적으로 정리하고 한계와 도전 과제를 제시한다.


<details>
  <summary>Details</summary>
Motivation: VAD 연구는 여러 분야와 학습 패러다임에 걸쳐 산발적으로 발전해 왔으나 통합적 관점과 응용별 정리가 부족하여 연구자들이 체계적으로 접근하기 어려움. 이를 해소하기 위해 서베이를 통해 문헌을 종합하고 개방 문제를 제시하려 함.

Method: 문헌 조사 및 분류: 감독 수준(비지도·약지도·지도 등), 적응형 학습(온라인, 능동, 연속 학습)으로 분류하고, 인간·차량·환경 중심의 응용 카테고리별로 방법론과 데이터셋 및 평가 지표를 분석함.

Result: 각 분류별 핵심 기여와 한계를 도출하고, 분야 전반에 걸친 공통된 문제(데이터 불균형, 일반화 어려움, 실시간성 등) 및 실무적 장애요인(라벨 부족, 배포 시 제약 등)을 정리함.

Conclusion: 서베이는 VAD 분야의 체계적 이해를 돕고, 연구자들이 향후 이론적 발전 및 실세계 적용을 위해 집중할 연구 방향과 해결해야 할 과제를 제시한다.

Abstract: Video Anomaly Detection (VAD) has emerged as a pivotal task in computer
vision, with broad relevance across multiple fields. Recent advances in deep
learning have driven significant progress in this area, yet the field remains
fragmented across domains and learning paradigms. This survey offers a
comprehensive perspective on VAD, systematically organizing the literature
across various supervision levels, as well as adaptive learning methods such as
online, active, and continual learning. We examine the state of VAD across
three major application categories: human-centric, vehicle-centric, and
environment-centric scenarios, each with distinct challenges and design
considerations. In doing so, we identify fundamental contributions and
limitations of current methodologies. By consolidating insights from subfields,
we aim to provide the community with a structured foundation for advancing both
theoretical understanding and real-world applicability of VAD systems. This
survey aims to support researchers by providing a useful reference, while also
drawing attention to the broader set of open challenges in anomaly detection,
including both fundamental research questions and practical obstacles to
real-world deployment.

</details>


### [7] [Directed-Tokens: A Robust Multi-Modality Alignment Approach to Large Language-Vision Models](https://arxiv.org/abs/2508.14264)
*Thanh-Dat Truong,Huu-Thien Tran,Tran Thai Son,Bhiksha Raj,Khoa Luu*

Main category: cs.CV

TL;DR: Introduce tasks that reconstruct image and text order during LMM pre-training/fine-tuning, plus a directed-token mechanism and Image-to-Response Guided loss, to improve cross-modal alignment, visual reasoning, and achieve SoTA on benchmarks.


<details>
  <summary>Details</summary>
Motivation: Existing LMMs still lack robustness and generalization due to imperfect alignment/correlation between visual and textual features; improving alignment should enhance reasoning and visual understanding.

Method: Add two shuffling-based tasks (image-order reconstruction and text-order reconstruction) to pre-training/fine-tuning; propose a directed-token approach to capture visual/textual knowledge for reconstructing visual input order; introduce Image-to-Response Guided loss to improve visual understanding in responses.

Result: Consistent SoTA performance over prior LMMs on academic task-oriented and instruction-following LMM benchmarks, with improved reasoning, visual understanding, and cross-modality alignment.

Conclusion: Simple shuffling-reconstruction objectives plus directed-token and image-to-response loss effectively strengthen robust visual-textual alignment and downstream performance for LMMs.

Abstract: Large multimodal models (LMMs) have gained impressive performance due to
their outstanding capability in various understanding tasks. However, these
models still suffer from some fundamental limitations related to robustness and
generalization due to the alignment and correlation between visual and textual
features. In this paper, we introduce a simple but efficient learning mechanism
for improving the robust alignment between visual and textual modalities by
solving shuffling problems. In particular, the proposed approach can improve
reasoning capability, visual understanding, and cross-modality alignment by
introducing two new tasks: reconstructing the image order and the text order
into the LMM's pre-training and fine-tuning phases. In addition, we propose a
new directed-token approach to capture visual and textual knowledge, enabling
the capability to reconstruct the correct order of visual inputs. Then, we
introduce a new Image-to-Response Guided loss to further improve the visual
understanding of the LMM in its responses. The proposed approach consistently
achieves state-of-the-art (SoTA) performance compared with prior LMMs on
academic task-oriented and instruction-following LMM benchmarks.

</details>


### [8] [GALA: Guided Attention with Language Alignment for Open Vocabulary Gaussian Splatting](https://arxiv.org/abs/2508.14278)
*Elena Alegret Regalado,Kunyi Li,Sen Wang,Siyun Liang,Michael Niemeyer,Stefano Gasperini,Nassir Navab,Federico Tombari*

Main category: cs.CV

TL;DR: GALA는 3D Gaussian Splatting(3DGS)을 기반으로 2D 이미지에서 언어-인지적(open-vocabulary) 3D 표현을 학습하는 프레임워크이다. 자기지도 대조학습으로 장면별 3D 인스턴스 피쳐 필드를 증류하고, 두 개의 학습 가능한 코드북을 가진 크로스-어텐션 모듈로 뷰-독립적 의미 임베딩을 생성해 2D/3D 오픈-보캐뷸러리 질의를 지원한다. 퍼-가우시안 고차원 피쳐 학습을 피해 메모리를 절감하며, 실험에서 2D와 3D 모두에서 우수한 오픈-보캐뷸러리 성능을 보였다.


<details>
  <summary>Details</summary>
Motivation: 기존 방법들은 2D 이미지만으로 세밀하고 언어에 민감한 3D 표현을 얻는 데 한계를 보이며, 특히 개방어휘(open-vocabulary) 수준의 2D↔3D 질의 대응이 어려움.

Method: 장면-특화 3D 인스턴스 피쳐 필드를 자기지도 대조학습으로 증류. 핵심은 두 개의 학습 가능한 코드북을 이용한 크로스-어텐션 모듈로, 이 모듈이 뷰-독립적인 의미 임베딩을 인코딩해 인스턴스 내부 유사성을 보장하고 2D/3D 오픈-보캐뷸러리 질의를 가능하게 함. 또한 각 가우시안마다 고차원 피쳐를 저장하지 않아 메모리 사용을 줄임. 3DGS(3D Gaussian Splatting)를 렌더링/표현 기반으로 사용.

Result: 실세계 데이터셋에서 광범위한 실험을 통해 2D와 3D 모두에서 뛰어난 오픈-보캐뷸러리 성능을 달성함을 보고.

Conclusion: GALA는 메모리 효율적인 코드북 기반 크로스-어텐션과 자기지도 증류를 통해 2D 이미지로부터 언어-연관 3D 표현을 효과적으로 학습하며, V-L(vision-language) 관점의 3D 이해 연구에 유용한 접근법임.

Abstract: 3D scene reconstruction and understanding have gained increasing popularity,
yet existing methods still struggle to capture fine-grained, language-aware 3D
representations from 2D images. In this paper, we present GALA, a novel
framework for open-vocabulary 3D scene understanding with 3D Gaussian Splatting
(3DGS). GALA distills a scene-specific 3D instance feature field via
self-supervised contrastive learning. To extend to generalized language feature
fields, we introduce the core contribution of GALA, a cross-attention module
with two learnable codebooks that encode view-independent semantic embeddings.
This design not only ensures intra-instance feature similarity but also
supports seamless 2D and 3D open-vocabulary queries. It reduces memory
consumption by avoiding per-Gaussian high-dimensional feature learning.
Extensive experiments on real-world datasets demonstrate GALA's remarkable
open-vocabulary performance on both 2D and 3D.

</details>


### [9] [Multi-Rationale Explainable Object Recognition via Contrastive Conditional Inference](https://arxiv.org/abs/2508.14280)
*Ali Rasekh,Sepehr Kazemi Ranjbar,Simon Gottschalk*

Main category: cs.CV

TL;DR: CLIP와 같은 비전-언어 모델을 이용한 설명 가능한 객체 인식을 위해 다중 근거(multi-rationale) 벤치마크를 제시하고, 근거(conditioning)를 효과적으로 반영하는 학습 불필요한 대비적 조건 추론(CCI) 프레임워크를 제안하여 제로샷에서 SOTA 성능을 달성함.


<details>
  <summary>Details</summary>
Motivation: 기존의 프롬프트 기반 접근은 CLIP의 텍스트 인코더 한계와 약한 설명 구조 조건화 문제를 가지며, 기존 데이터셋은 단일이거나 노이즈가 섞인 근거만 제공해 판별적 이미지 특징의 다양성을 반영하지 못함.

Method: 이미지 임베딩, 카테고리 레이블, 근거 간의 확률적 관계를 명시적으로 모델링하는 대비적 조건 추론(CCI) 프레임워크를 제안함. 학습 없이 근거에 대한 효과적 조건화를 가능하게 함.

Result: 다중 근거 설명 가능한 객체 인식 벤치마크에서 분류 정확도와 근거 품질 모두에서 SOTA 성능을 달성하고, 강한 제로샷 성능을 보임.

Conclusion: 다중 근거 어노테이션과 평가 지표를 포함한 벤치마크와 CCI 프레임워크를 통해 설명 가능한 객체 인식 평가의 완성도를 높였으며, 향후 모델 평가의 기준을 제시함.

Abstract: Explainable object recognition using vision-language models such as CLIP
involves predicting accurate category labels supported by rationales that
justify the decision-making process. Existing methods typically rely on
prompt-based conditioning, which suffers from limitations in CLIP's text
encoder and provides weak conditioning on explanatory structures. Additionally,
prior datasets are often restricted to single, and frequently noisy, rationales
that fail to capture the full diversity of discriminative image features. In
this work, we introduce a multi-rationale explainable object recognition
benchmark comprising datasets in which each image is annotated with multiple
ground-truth rationales, along with evaluation metrics designed to offer a more
comprehensive representation of the task. To overcome the limitations of
previous approaches, we propose a contrastive conditional inference (CCI)
framework that explicitly models the probabilistic relationships among image
embeddings, category labels, and rationales. Without requiring any training,
our framework enables more effective conditioning on rationales to predict
accurate object categories. Our approach achieves state-of-the-art results on
the multi-rationale explainable object recognition benchmark, including strong
zero-shot performance, and sets a new standard for both classification accuracy
and rationale quality. Together with the benchmark, this work provides a more
complete framework for evaluating future models in explainable object
recognition. The code will be made available online.

</details>


### [10] [Pixels to Play: A Foundation Model for 3D Gameplay](https://arxiv.org/abs/2508.14295)
*Yuguang Yue,Chris Green,Samuel Hunt,Irakli Salia,Wenzhe Shi,Jonathan J Hunt*

Main category: cs.CV

TL;DR: P2P0.1은 픽셀 입력만으로 다양한 3D 비디오 게임을 플레이하도록 학습된 행동 복제 기반의 기초 모델이다. 인간 플레이 시연과 공개 비디오(역동역학 모델로 행동 예측)를 병합해 학습하며, 디코더 전용 오토리그레시브 트랜스포머로 행동을 출력해 단일 소비자 GPU에서 저지연 실행을 목표로 한다.


<details>
  <summary>Details</summary>
Motivation: AI 팀원, 제어 가능한 NPC, 개인화된 라이브스트리머, 보조 테스터 등 실제 활용 사례를 위해, 플레이어가 이용하는 동일한 픽셀 스트림만으로 다양한 게임에 일반화되는 에이전트 필요성.

Method: 행동 복제(behavior cloning)를 사용해 학습. 계측된 인간 게임 플레이로 레이블된 시연을 수집하고, 공개된 무라벨 비디오에는 역동역학(inverse-dynamics) 모델로 행동을 추정해 보강. 디코더 전용 오토리그레시브 트랜스포머 모델을 사용해 대형 행동 공간을 처리하고 단일 GPU에서 저지연으로 동작하도록 설계.

Result: Roblox와 고전 MS-DOS 타이틀 등에서 인간과 유사한 플레이를 보이는 정성적 결과를 보고. 무라벨 데이터의 효과에 대한 소거 연구(ablations)를 제시. 텍스트 조건 제어 및 전문가 수준 제어 달성을 위한 스케일링 및 평가 단계의 로드맵을 제시.

Conclusion: 픽셀 기반 범용 게임 플레이를 향한 유망한 초기 기초 모델로, 무라벨 비디오 활용과 역동역학을 통한 행동 추정이 효과적임을 보였으나 아직 전문가 수준과 텍스트 조건 제어를 위해서는 추가적인 스케일링·평가가 필요하다.

Abstract: We introduce Pixels2Play-0.1 (P2P0.1), a foundation model that learns to play
a wide range of 3D video games with recognizable human-like behavior. Motivated
by emerging consumer and developer use cases - AI teammates, controllable NPCs,
personalized live-streamers, assistive testers - we argue that an agent must
rely on the same pixel stream available to players and generalize to new titles
with minimal game-specific engineering. P2P0.1 is trained end-to-end with
behavior cloning: labeled demonstrations collected from instrumented human
game-play are complemented by unlabeled public videos, to which we impute
actions via an inverse-dynamics model. A decoder-only transformer with
auto-regressive action output handles the large action space while remaining
latency-friendly on a single consumer GPU. We report qualitative results
showing competent play across simple Roblox and classic MS-DOS titles,
ablations on unlabeled data, and outline the scaling and evaluation steps
required to reach expert-level, text-conditioned control.

</details>


### [11] [MoVieDrive: Multi-Modal Multi-View Urban Scene Video Generation](https://arxiv.org/abs/2508.14327)
*Guile Wu,David Huang,Dongfeng Bai,Bingbing Liu*

Main category: cs.CV

TL;DR: 자율주행 도시 장면을 위한 다중 모달·다중 뷰 비디오 생성 논문으로, RGB뿐 아니라 깊이·시맨틱 맵 등 여러 모달을 하나의 통합 확산 트랜스포머로 생성해 고충실도·제어 가능한 비디오를 만들어 nuScenes에서 SOTA를 능가함.


<details>
  <summary>Details</summary>
Motivation: 기존 자율주행 비디오 생성은 주로 RGB에만 집중해 깊이/시맨틱 같은 다중 모달을 지원하지 못함. 다중 모델 사용은 배포 난이도 상승과 모달 간 보완 정보 활용 불가라는 문제를 가짐.

Method: 모달-공유 구성요소와 모달-특이 구성요소로 이루어진 통합 확산(transformer) 모델을 설계하고, 다양한 컨디셔닝 입력을 통해 장면 구조·콘텐츠 제어 신호를 인코딩해 다중 모달·다중 뷰 비디오를 생성함.

Result: 실험은 실제 자율주행 데이터셋 nuScenes에서 수행되었고, 제안 기법이 다중 모달·다중 뷰 도시 장면 비디오를 높은 충실도와 제어성으로 생성하여 기존 최신 방법들을 능가하는 성능을 보임.

Conclusion: 단일 통합 프레임워크로 여러 모달과 뷰를 동시에 생성함으로써 배포 효율을 높이고 모달 간 보완적 단서를 활용할 수 있게 함. 자율주행 장면의 다중 모달 비디오 합성에 실용적 진전을 제시함.

Abstract: Video generation has recently shown superiority in urban scene synthesis for
autonomous driving. Existing video generation approaches to autonomous driving
primarily focus on RGB video generation and lack the ability to support
multi-modal video generation. However, multi-modal data, such as depth maps and
semantic maps, are crucial for holistic urban scene understanding in autonomous
driving. Although it is feasible to use multiple models to generate different
modalities, this increases the difficulty of model deployment and does not
leverage complementary cues for multi-modal data generation. To address this
problem, in this work, we propose a novel multi-modal multi-view video
generation approach to autonomous driving. Specifically, we construct a unified
diffusion transformer model composed of modal-shared components and
modal-specific components. Then, we leverage diverse conditioning inputs to
encode controllable scene structure and content cues into the unified diffusion
model for multi-modal multi-view video generation. In this way, our approach is
capable of generating multi-modal multi-view driving scene videos in a unified
framework. Our experiments on the challenging real-world autonomous driving
dataset, nuScenes, show that our approach can generate multi-modal multi-view
urban scene videos with high fidelity and controllability, surpassing the
state-of-the-art methods.

</details>


### [12] [HandCraft: Dynamic Sign Generation for Synthetic Data Augmentation](https://arxiv.org/abs/2508.14345)
*Gaston Gustavo Rios*

Main category: cs.CV

TL;DR: The paper proposes a lightweight sign generation model based on CMLPe and a synthetic data pretraining strategy to address data scarcity in Sign Language Recognition (SLR). This approach improves recognition accuracy and achieves new state-of-the-art results on LSFB and DiSPLaY using Mamba-SL and Transformer-SL classifiers.


<details>
  <summary>Details</summary>
Motivation: SLR performance is limited by insufficient annotated training data; generating synthetic sign data and pretraining on it could improve recognition robustness and accuracy.

Method: Introduce a computationally efficient sign generation model based on CMLPe and use synthetic data pretraining. Evaluate by training Mamba-SL and Transformer-SL classifiers with synthetic pretraining and compare to traditional augmentation and baselines.

Result: Synthetic data pretraining consistently improves recognition accuracy, achieves new SOTA on LSFB and DiSPLaY, outperforms traditional augmentation in some cases, and provides complementary gains when combined with augmentation.

Conclusion: Lightweight sign generation plus synthetic data pretraining is an effective, computationally efficient strategy to mitigate data scarcity in SLR, democratizing synthetic data methods and delivering significant improvements across datasets.

Abstract: Sign Language Recognition (SLR) models face significant performance
limitations due to insufficient training data availability. In this article, we
address the challenge of limited data in SLR by introducing a novel and
lightweight sign generation model based on CMLPe. This model, coupled with a
synthetic data pretraining approach, consistently improves recognition
accuracy, establishing new state-of-the-art results for the LSFB and DiSPLaY
datasets using our Mamba-SL and Transformer-SL classifiers. Our findings reveal
that synthetic data pretraining outperforms traditional augmentation methods in
some cases and yields complementary benefits when implemented alongside them.
Our approach democratizes sign generation and synthetic data pretraining for
SLR by providing computationally efficient methods that achieve significant
performance improvements across diverse datasets.

</details>


### [13] [Taming Transformer for Emotion-Controllable Talking Face Generation](https://arxiv.org/abs/2508.14359)
*Ziqi Zhang,Cheng Deng*

Main category: cs.CV

TL;DR: This paper proposes a discrete, token-based method for emotion-controllable talking-face video generation: disentangle audio, quantize video to visual tokens, introduce an emotion-anchor (EA) representation, and use an autoregressive transformer to predict token sequences. Evaluated on MEAD, it shows qualitative and quantitative improvements.


<details>
  <summary>Details</summary>
Motivation: Existing methods struggle to (1) model multimodal relationships tied to specific emotions and (2) leverage those relationships to synthesize identity-preserving emotional videos. The paper aims to address these two challenges for emotion-controllable talking-face generation.

Method: Two pre-training strategies: (a) disentangle audio into independent components; (b) quantize videos into combinations of visual tokens. Introduce an emotion-anchor (EA) representation that embeds emotional information into visual tokens. Use an autoregressive transformer conditioned on inputs to model global distribution of visual tokens and predict index sequences to synthesize manipulated videos.

Result: On the MEAD dataset (emotion-conditioned videos from multiple emotional audios), the proposed method outperforms baselines in qualitative and quantitative evaluations for emotion-controllable talking-face generation.

Conclusion: A discrete-token pipeline combined with an emotion-anchor representation and autoregressive modeling effectively controls expressed emotion while preserving identity in talking-face generation. The approach leverages pretraining and tokenization to model multimodal emotion relationships.

Abstract: Talking face generation is a novel and challenging generation task, aiming at
synthesizing a vivid speaking-face video given a specific audio. To fulfill
emotion-controllable talking face generation, current methods need to overcome
two challenges: One is how to effectively model the multimodal relationship
related to the specific emotion, and the other is how to leverage this
relationship to synthesize identity preserving emotional videos. In this paper,
we propose a novel method to tackle the emotion-controllable talking face
generation task discretely. Specifically, we employ two pre-training strategies
to disentangle audio into independent components and quantize videos into
combinations of visual tokens. Subsequently, we propose the emotion-anchor (EA)
representation that integrates the emotional information into visual tokens.
Finally, we introduce an autoregressive transformer to model the global
distribution of the visual tokens under the given conditions and further
predict the index sequence for synthesizing the manipulated videos. We conduct
experiments on the MEAD dataset that controls the emotion of videos conditioned
on multiple emotional audios. Extensive experiments demonstrate the
superiorities of our method both qualitatively and quantitatively.

</details>


### [14] [FastTracker: Real-Time and Accurate Visual Tracking](https://arxiv.org/abs/2508.14370)
*Hamidreza Hashempoor,Yu Dong Hwang*

Main category: cs.CV

TL;DR: 본 논문은 보행자 중심의 전통적 MOT를 넘어 차량을 포함한 다중 객체 유형을 추적하기 위한 일반화된 프레임워크를 제안한다. 주요 요소는(1) 심한 가림 상황에서 정체성 보존을 돕는 가림 인식 재식별(occlusion-aware re-ID)과 (2) 차선·횡단보도·도로 경계 같은 장면 의미 prior를 활용한 도로 구조 인식 트랙릿 정제(tracklet refinement)이다. 또한 다양한 차량 클래스의 프레임 단위 추적 주석을 가진 새로운 벤치마크 데이터셋을 공개한다.


<details>
  <summary>Details</summary>
Motivation: 기존 MOT 시스템은 보행자 추적에 편중되어 다른 객체군(특히 차량)에 대한 일반화 성능이 부족하다. 복잡한 교통 장면에서 차량의 신원 보존과 궤적 연속성을 개선할 필요가 있다.

Method: (1) 가림 상황을 고려한 re-identification 모듈을 도입해 가려진 객체의 ID 유지 능력을 향상시키고, (2) 차선 방향·횡단보도·도로 경계 등의 시멘틱 장면 정보를 사용해 트랙릿을 정제함으로써 궤적의 정확성과 연속성을 개선한다. 이를 평가하기 위해 차량 중심의 새 데이터셋을 구축·공개했다.

Result: 새 데이터셋과 공개 벤치마크들에서 강건한 성능을 보였으며, 기존 벤치마크(MOT17, MOT20)에서도 HOTA 66.4, 65.7 등 경쟁력 있는 결과를 기록했다.

Conclusion: 제안한 프레임워크는 차량 중심의 복잡한 장면에서 ID 보존과 궤적 정밀도를 향상시키며, 다중 클래스 일반화 능력을 갖춘 추적 방법으로 유효하다. 코드와 데이터셋을 공개해 재현성과 확장성을 지원한다.

Abstract: Conventional multi-object tracking (MOT) systems are predominantly designed
for pedestrian tracking and often exhibit limited generalization to other
object categories. This paper presents a generalized tracking framework capable
of handling multiple object types, with a particular emphasis on vehicle
tracking in complex traffic scenes. The proposed method incorporates two key
components: (1) an occlusion-aware re-identification mechanism that enhances
identity preservation for heavily occluded objects, and (2) a
road-structure-aware tracklet refinement strategy that utilizes semantic scene
priors such as lane directions, crosswalks, and road boundaries to improve
trajectory continuity and accuracy. In addition, we introduce a new benchmark
dataset comprising diverse vehicle classes with frame-level tracking
annotations, specifically curated to support evaluation of vehicle-focused
tracking methods. Extensive experimental results demonstrate that the proposed
approach achieves robust performance on both the newly introduced dataset and
several public benchmarks, highlighting its effectiveness in general-purpose
object tracking. While our framework is designed for generalized multi-class
tracking, it also achieves strong performance on conventional benchmarks, with
HOTA scores of 66.4 on MOT17 and 65.7 on MOT20 test sets. Code and Benchmark
are available: github.com/Hamidreza-Hashempoor/FastTracker,
huggingface.co/datasets/Hamidreza-Hashemp/FastTracker-Benchmark.

</details>


### [15] [PB-IAD: Utilizing multimodal foundation models for semantic industrial anomaly detection in dynamic manufacturing environments](https://arxiv.org/abs/2508.14504)
*Bernd Hofmann,Albert Scheck,Joerg Franke,Patrick Bruendl*

Main category: cs.CV

TL;DR: PB-IAD는 GPT-4.1 같은 대형 기반 모델의 다중모달·추론 능력을 활용해 제조 이상 감지를 수행하는 프롬프트 기반 프레임워크로, 데이터 희소성·민첩성·도메인 사용자 중심 설계를 목표로 한다.


<details>
  <summary>Details</summary>
Motivation: 전통적 통계·데이터 기반 이상 탐지 방법은 레이블된 데이터 의존성과 동적 생산 환경에서의 유연성 부족 문제를 가짐. 기반 모델의 인지 능력을 활용하면 소량 데이터나 도메인 지식을 통한 빠른 적응이 가능할 것으로 기대됨.

Method: 사용자 입력을 효과적 시스템 프롬프트로 변환하는 전처리 모듈과 도메인별 프로세스 지식을 반복적으로 반영할 수 있는 프롬프트 템플릿을 설계하여 GPT-4.1 기반으로 이상 감지 작업을 수행. 다중 제작 시나리오와 두 가지 데이터 모달리티에서 평가하고, 의미적 지시문의 기여도를 보기 위한 소거실험 진행.

Result: PatchCore 등 최첨단 방법과 비교한 결과, 특히 데이터가 희소하거나 저샷 환경에서 의미적 지시문만으로도 우수한 성능을 보였음.

Conclusion: 프롬프트 중심의 사용자-도메인 통합 접근은 레이블이 부족한 제조 환경에서 기반 모델을 활용한 이상 감지에 유망하며, 도메인 전문가가 데이터 과학 지식 없이도 시스템을 맞춤화할 수 있게 함.

Abstract: The detection of anomalies in manufacturing processes is crucial to ensure
product quality and identify process deviations. Statistical and data-driven
approaches remain the standard in industrial anomaly detection, yet their
adaptability and usability are constrained by the dependence on extensive
annotated datasets and limited flexibility under dynamic production conditions.
Recent advances in the perception capabilities of foundation models provide
promising opportunities for their adaptation to this downstream task. This
paper presents PB-IAD (Prompt-based Industrial Anomaly Detection), a novel
framework that leverages the multimodal and reasoning capabilities of
foundation models for industrial anomaly detection. Specifically, PB-IAD
addresses three key requirements of dynamic production environments: data
sparsity, agile adaptability, and domain user centricity. In addition to the
anomaly detection, the framework includes a prompt template that is
specifically designed for iteratively implementing domain-specific process
knowledge, as well as a pre-processing module that translates domain user
inputs into effective system prompts. This user-centric design allows domain
experts to customise the system flexibly without requiring data science
expertise. The proposed framework is evaluated by utilizing GPT-4.1 across
three distinct manufacturing scenarios, two data modalities, and an ablation
study to systematically assess the contribution of semantic instructions.
Furthermore, PB-IAD is benchmarked to state-of-the-art methods for anomaly
detection such as PatchCore. The results demonstrate superior performance,
particularly in data-sparse scenarios and low-shot settings, achieved solely
through semantic instructions.

</details>


### [16] [CTA-Flux: Integrating Chinese Cultural Semantics into High-Quality English Text-to-Image Communities](https://arxiv.org/abs/2508.14405)
*Yue Gong,Shanyuan Liu,Liuzhuozheng Li,Jian Zhu,Bo Cheng,Liebucha Wu,Xiaoyu Wu,Yuhang Ma,Dawei Leng,Yuhui Yin*

Main category: cs.CV

TL;DR: CTA-Flux는 영어 중심으로 학습된 텍스트-투-이미지(Flux) 모델에 중국어 입력을 효과적으로 적응시키는 방법으로, MMDiT를 활용해 파라미터 규모를 줄이면서 중국어 의미와 문화적 요소를 보존해 고품질 이미지 생성을 달성한다.


<details>
  <summary>Details</summary>
Motivation: Flux 같은 강력한 TTI 모델은 영어 입력에서는 성능이 좋지만, 영어 편향 훈련 데이터로 인해 비영어(특히 중국어) 프롬프트 처리에서 의미·문화적 왜곡이 발생해 이미지 품질과 진정성이 떨어진다.

Method: 기존의 번역이나 전체 파인튜닝 대신 MultiModal Diffusion Transformer(MMDiT)를 이용해 Flux 백본을 직접 제어하는 어댑터(CTA-Flux)를 설계하여 파라미터를 줄이고 중국어 의미 통제력을 확보함. ControlNet 유사 접근보다 경량화되고 기존 플러그인(LoRA, IP-Adapter, ControlNet)과 호환성을 유지함.

Result: CTA-Flux는 중국어·영어 프롬프트를 지원하며, 실험에서 이미지 생성 품질, 시각적 사실성 및 중국어 의미 충실도에서 우수한 성능을 보였다.

Conclusion: 문화적·언어적 차이를 고려한 경량 어댑터로 대규모 재학습 없이도 영어 중심 TTI 모델의 다국어(중국어) 적응을 개선할 수 있으며, 기존 생태계와의 호환성을 유지한다.

Abstract: We proposed the Chinese Text Adapter-Flux (CTA-Flux). An adaptation method
fits the Chinese text inputs to Flux, a powerful text-to-image (TTI) generative
model initially trained on the English corpus. Despite the notable image
generation ability conditioned on English text inputs, Flux performs poorly
when processing non-English prompts, particularly due to linguistic and
cultural biases inherent in predominantly English-centric training datasets.
Existing approaches, such as translating non-English prompts into English or
finetuning models for bilingual mappings, inadequately address culturally
specific semantics, compromising image authenticity and quality. To address
this issue, we introduce a novel method to bridge Chinese semantic
understanding with compatibility in English-centric TTI model communities.
Existing approaches relying on ControlNet-like architectures typically require
a massive parameter scale and lack direct control over Chinese semantics. In
comparison, CTA-flux leverages MultiModal Diffusion Transformer (MMDiT) to
control the Flux backbone directly, significantly reducing the number of
parameters while enhancing the model's understanding of Chinese semantics. This
integration significantly improves the generation quality and cultural
authenticity without extensive retraining of the entire model, thus maintaining
compatibility with existing text-to-image plugins such as LoRA, IP-Adapter, and
ControlNet. Empirical evaluations demonstrate that CTA-flux supports Chinese
and English prompts and achieves superior image generation quality, visual
realism, and faithful depiction of Chinese semantics.

</details>


### [17] [MoCHA-former: Moiré-Conditioned Hybrid Adaptive Transformer for Video Demoiréing](https://arxiv.org/abs/2508.14423)
*Jeahun Sung,Changhyun Roh,Chanho Eom,Jihyong Oh*

Main category: cs.CV

TL;DR: MoCHA-former은 비디오에서 카메라-디스플레이 간의 색 필터/서브픽셀 주파수 앨리어싱으로 발생하는 모아레(moire) 패턴을 제거하기 위한 변환기 기반 모델이다. 모아레와 콘텐츠를 분리하는 DMAD와 대규모 구조·채널·시간적 변화를 다루는 STAD를 결합해 프레임 정렬 없이도 시간적 일관성을 유지하며 RAW 및 sRGB 비디오 데이터셋에서 기존 기법을 능가한다.


<details>
  <summary>Details</summary>
Motivation: 카메라의 CFA와 디스플레이 서브픽셀 간의 주파수 앨리어싱으로 인해 촬영한 스크린 이미지/비디오에 심각한 모아레 패턴이 발생한다. 기존 방법은 프레임 내에서 공간적으로 강도가 달라지는 아티팩트, 대규모 구조, 채널별 통계 차이, 프레임 간 급격한 시간적 변화 등을 충분히 처리하지 못한다.

Method: MoCHA-former는 두 구성요소로 이루어짐: (1) DMAD(Decoupled Moiré Adaptive Demoiréeing): Moiré Decoupling Block(MDB)과 Detail Decoupling Block(DDB)으로 모아레와 디테일을 분리하고 Moiré Conditioning Block(MCB)으로 모아레 적응형 특징을 생성. (2) STAD(Spatio-Temporal Adaptive Demoiréeing): window attention 기반의 Spatial Fusion Block(SFB)로 대규모 구조를 포착하고 Feature Channel Attention(FCA)로 RAW 프레임의 채널 의존성 모델링. 시간적 일관성은 명시적 정렬 모듈 없이 암묵적 프레임 정렬로 보장.

Result: RAW 및 sRGB 도메인을 포함한 두 비디오 데이터셋에서 PSNR, SSIM, LPIPS 등 주요 지표에서 기존 방법들보다 일관되게 우수한 성능을 보임. 정성·정량 분석을 통해 모아레 특성에 맞춘 설계의 이점을 입증.

Conclusion: 모아레 특성을 분리·조건화하고 공간·채널·시간 차원을 적응적으로 처리하는 설계를 통해 비디오 기반 모아레 제거 문제에서 성능 향상을 달성. 비디오 복원 및 관련 데이터셋 연구에 유용한 접근법을 제시.

Abstract: Recent advances in portable imaging have made camera-based screen capture
ubiquitous. Unfortunately, frequency aliasing between the camera's color filter
array (CFA) and the display's sub-pixels induces moir\'e patterns that severely
degrade captured photos and videos. Although various demoir\'eing models have
been proposed to remove such moir\'e patterns, these approaches still suffer
from several limitations: (i) spatially varying artifact strength within a
frame, (ii) large-scale and globally spreading structures, (iii)
channel-dependent statistics and (iv) rapid temporal fluctuations across
frames. We address these issues with the Moir\'e Conditioned Hybrid Adaptive
Transformer (MoCHA-former), which comprises two key components: Decoupled
Moir\'e Adaptive Demoir\'eing (DMAD) and Spatio-Temporal Adaptive Demoir\'eing
(STAD). DMAD separates moir\'e and content via a Moir\'e Decoupling Block (MDB)
and a Detail Decoupling Block (DDB), then produces moir\'e-adaptive features
using a Moir\'e Conditioning Block (MCB) for targeted restoration. STAD
introduces a Spatial Fusion Block (SFB) with window attention to capture
large-scale structures, and a Feature Channel Attention (FCA) to model channel
dependence in RAW frames. To ensure temporal consistency, MoCHA-former performs
implicit frame alignment without any explicit alignment module. We analyze
moir\'e characteristics through qualitative and quantitative studies, and
evaluate on two video datasets covering RAW and sRGB domains. MoCHA-former
consistently surpasses prior methods across PSNR, SSIM, and LPIPS.

</details>


### [18] [UST-SSM: Unified Spatio-Temporal State Space Models for Point Cloud Video Modeling](https://arxiv.org/abs/2508.14604)
*Peiming Li,Ziyi Wang,Yulin Yuan,Hong Liu,Xiangming Meng,Junsong Yuan,Mengyuan Liu*

Main category: cs.CV

TL;DR: 저자들은 점 구름 비디오의 비정렬된 시공간 특성 때문에 기존 Selective State Space Models(SSMs)을 직접 적용하기 어렵다고 보고, 이를 해결하기 위해 UST-SSM을 제안한다. 핵심은 프롬프트 기반 클러스터링으로 의미 기반 시퀀스를 구성하는 STSS, 4D 기하·모션 결손을 보완하는 STSA, 그리고 비앵커 프레임과 확장된 수용역을 이용해 시간적 상호작용을 강화하는 TIS이다. MSR-Action3D, NTU RGB+D, Synthia 4D에서 성능 향상을 확인했다.


<details>
  <summary>Details</summary>
Motivation: 점 구름 비디오는 조명·시점 변화에 강해 미세한 연속 행동 인식에 유리하지만, 점들의 시공간적 무질서 때문에 1D 시퀀스로 단순 펼쳤을 때 SSM의 일방향 모델링에 제약이 생긴다. 이를 해결해 SSM의 장점을 점 구름 비디오에 적용하려 함.

Method: UST-SSM을 제안. (1) STSS: 프롬프트 기반 클러스터링으로 무질서한 점들을 의미 기반 시퀀스로 재구성해 시공간상 먼 점들도 시퀀스 내에서 유효하게 활용, (2) STSA: 시공간 구조 특징을 집계해 4D 기하·모션 정보 손실 보완, (3) TIS: 비앵커 프레임 이용 및 넓은 수용역으로 미세한 시간적 의존성 강화. 이러한 구성으로 SSM을 점 구름 비디오에 맞게 확장함.

Result: MSR-Action3D, NTU RGB+D, Synthia 4D 데이터셋 실험에서 제안 기법이 성능을 개선함을 보고. 코드 공개(깃허브 링크 포함).

Conclusion: UST-SSM은 점 구름 비디오의 무질서한 시공간 구조를 재구성하고 보완하여 SSM 기반 시퀀스 모델링을 효과적으로 확장함으로써 행동 인식 성능을 향상시킨다.

Abstract: Point cloud videos capture dynamic 3D motion while reducing the effects of
lighting and viewpoint variations, making them highly effective for recognizing
subtle and continuous human actions. Although Selective State Space Models
(SSMs) have shown good performance in sequence modeling with linear complexity,
the spatio-temporal disorder of point cloud videos hinders their unidirectional
modeling when directly unfolding the point cloud video into a 1D sequence
through temporally sequential scanning. To address this challenge, we propose
the Unified Spatio-Temporal State Space Model (UST-SSM), which extends the
latest advancements in SSMs to point cloud videos. Specifically, we introduce
Spatial-Temporal Selection Scanning (STSS), which reorganizes unordered points
into semantic-aware sequences through prompt-guided clustering, thereby
enabling the effective utilization of points that are spatially and temporally
distant yet similar within the sequence. For missing 4D geometric and motion
details, Spatio-Temporal Structure Aggregation (STSA) aggregates
spatio-temporal features and compensates. To improve temporal interaction
within the sampled sequence, Temporal Interaction Sampling (TIS) enhances
fine-grained temporal dependencies through non-anchor frame utilization and
expanded receptive fields. Experimental results on the MSR-Action3D, NTU RGB+D,
and Synthia 4D datasets validate the effectiveness of our method. Our code is
available at https://github.com/wangzy01/UST-SSM.

</details>


### [19] [MUSE: Multi-Subject Unified Synthesis via Explicit Layout Semantic Expansion](https://arxiv.org/abs/2508.14440)
*Fei Peng,Junqiang Wu,Yan Li,Tingting Gao,Di Zhang,Huiyuan Fu*

Main category: cs.CV

TL;DR: Proposes MUSE, a framework for layout-controllable multi-subject image synthesis using concatenated cross-attention (CCA) and a progressive two-stage training, achieving zero-shot end-to-end generation with improved spatial accuracy and identity preservation.


<details>
  <summary>Details</summary>
Motivation: Existing text-to-image diffusion models excel at single-subject generation but struggle to simultaneously preserve multiple reference subject identities and place them precisely according to layout constraints in a single image; prior methods improve either layout control or subject fidelity but not both together.

Method: Introduce MUSE which employs concatenated cross-attention (CCA) to integrate layout specifications and textual guidance via semantic space expansion, enabling bidirectional alignment between spatial constraints and text. Also use a progressive two-stage training strategy that decomposes the LMS task into learnable sub-objectives for better optimization.

Result: Extensive experiments show MUSE delivers zero-shot end-to-end multi-subject generation with superior spatial accuracy and identity consistency compared to prior methods.

Conclusion: MUSE advances controllable image synthesis by jointly addressing spatial precision and identity preservation for multi-subject compositional generation; code and models are publicly available.

Abstract: Existing text-to-image diffusion models have demonstrated remarkable
capabilities in generating high-quality images guided by textual prompts.
However, achieving multi-subject compositional synthesis with precise spatial
control remains a significant challenge. In this work, we address the task of
layout-controllable multi-subject synthesis (LMS), which requires both faithful
reconstruction of reference subjects and their accurate placement in specified
regions within a unified image. While recent advancements have separately
improved layout control and subject synthesis, existing approaches struggle to
simultaneously satisfy the dual requirements of spatial precision and identity
preservation in this composite task. To bridge this gap, we propose MUSE, a
unified synthesis framework that employs concatenated cross-attention (CCA) to
seamlessly integrate layout specifications with textual guidance through
explicit semantic space expansion. The proposed CCA mechanism enables
bidirectional modality alignment between spatial constraints and textual
descriptions without interference. Furthermore, we design a progressive
two-stage training strategy that decomposes the LMS task into learnable
sub-objectives for effective optimization. Extensive experiments demonstrate
that MUSE achieves zero-shot end-to-end generation with superior spatial
accuracy and identity consistency compared to existing solutions, advancing the
frontier of controllable image synthesis. Our code and model are available at
https://github.com/pf0607/MUSE.

</details>


### [20] [Generalizable Engagement Estimation in Conversation via Domain Prompting and Parallel Attention](https://arxiv.org/abs/2508.14448)
*Yangche Yu,Yin Chen,Jia Li,Peng Jia,Yu Zhang,Li Dai,Zhenzhen Hu,Meng Wang,Richang Hong*

Main category: cs.CV

TL;DR: DAPA는 도메인 프롬프트와 병렬 교차주의(attention)로 대화형 참여도 추정의 일반화와 상호작용 동기화 문제를 해결한다.


<details>
  <summary>Details</summary>
Motivation: 현재 참여도 추정 시스템은 다양한 도메인 간 일반화가 약하고 참여자의 복잡한 상호작용 역학을 포착하기 어렵다.

Method: 도메인별 학습 가능한 벡터를 입력 앞에 붙이는 Domain Prompting과, 반응적(전향 BiLSTM)과 예측적(역방향 BiLSTM) 상태를 정렬하는 Parallel Cross-Attention 모듈을 도입.

Result: 여러 교차문화·교차언어 벤치마크에서 SoTA를 달성했으며, NoXi-J 테스트셋에서 강한 베이스라인 대비 CCC 0.45 절대 개선을 보였고 MultiMediate'25 챌린지에서 1위를 차지.

Conclusion: 도메인 정보를 명시적으로 도입하고 상호작용적 동기화를 모델링함으로써 대화형 참여도 추정의 일반화 성능을 크게 향상시킨다.

Abstract: Accurate engagement estimation is essential for adaptive human-computer
interaction systems, yet robust deployment is hindered by poor generalizability
across diverse domains and challenges in modeling complex interaction
dynamics.To tackle these issues, we propose DAPA (Domain-Adaptive Parallel
Attention), a novel framework for generalizable conversational engagement
modeling. DAPA introduces a Domain Prompting mechanism by prepending learnable
domain-specific vectors to the input, explicitly conditioning the model on the
data's origin to facilitate domain-aware adaptation while preserving
generalizable engagement representations. To capture interactional synchrony,
the framework also incorporates a Parallel Cross-Attention module that
explicitly aligns reactive (forward BiLSTM) and anticipatory (backward BiLSTM)
states between participants.Extensive experiments demonstrate that DAPA
establishes a new state-of-the-art performance on several cross-cultural and
cross-linguistic benchmarks, notably achieving an absolute improvement of 0.45
in Concordance Correlation Coefficient (CCC) over a strong baseline on the
NoXi-J test set. The superiority of our method was also confirmed by winning
the first place in the Multi-Domain Engagement Estimation Challenge at
MultiMediate'25.

</details>


### [21] [D^3-Talker: Dual-Branch Decoupled Deformation Fields for Few-Shot 3D Talking Head Synthesis](https://arxiv.org/abs/2508.14449)
*Yuhang Guo,Kaijun Deng,Siyang Song,Jindong Xie,Wenhui Ma,Linlin Shen*

Main category: cs.CV

TL;DR: 음성과 얼굴 운동 신호를 분리해 3D 가우시안 속성 필드를 통해 개인화된 입술 움직임을 생성하는 D^3-Talker를 제안한다. 적은 프레임만으로도 고품질 렌더링과 높은 오디오-입술 동기화를 달성한다.


<details>
  <summary>Details</summary>
Motivation: 기존 3D 토킹헤드 합성은 각 대상에 대해 긴 영상으로 모델을 처음부터 학습해야 하며, 오디오에 포함된 입술 동작과 무관한 정보 때문에 소수의 프레임으로는 현실적 입술 움직임을 예측하기 어렵다.

Method: 정적 3D 가우시안 속성 필드를 구성하고 오디오와 얼굴 모션 신호로 각각 두 개의 가우시안 변형 필드를 독립 제어해 일반 변형과 개인화된 변형을 분리한다. 사전학습 단계에서 유사성 대조 손실(similarity contrastive loss)을 도입해 분리를 강화하고, Coarse-to-Fine 모듈로 렌더링 결과의 흐릿함을 개선한다.

Result: 제한된 학습 데이터에서도 기존 최첨단 기법보다 고충실도 렌더링과 우수한 오디오-입술 동기화를 달성했다고 보고한다.

Conclusion: 오디오 및 얼굴 모션의 역할을 명확히 분리하고 대조학습과 정교화 모듈을 결합하여 적은 데이터 환경에서도 실용적인 3D 토킹헤드 합성을 가능하게 한다.

Abstract: A key challenge in 3D talking head synthesis lies in the reliance on a
long-duration talking head video to train a new model for each target identity
from scratch. Recent methods have attempted to address this issue by extracting
general features from audio through pre-training models. However, since audio
contains information irrelevant to lip motion, existing approaches typically
struggle to map the given audio to realistic lip behaviors in the target face
when trained on only a few frames, causing poor lip synchronization and talking
head image quality. This paper proposes D^3-Talker, a novel approach that
constructs a static 3D Gaussian attribute field and employs audio and Facial
Motion signals to independently control two distinct Gaussian attribute
deformation fields, effectively decoupling the predictions of general and
personalized deformations. We design a novel similarity contrastive loss
function during pre-training to achieve more thorough decoupling. Furthermore,
we integrate a Coarse-to-Fine module to refine the rendered images, alleviating
blurriness caused by head movements and enhancing overall image quality.
Extensive experiments demonstrate that D^3-Talker outperforms state-of-the-art
methods in both high-fidelity rendering and accurate audio-lip synchronization
with limited training data. Our code will be provided upon acceptance.

</details>


### [22] [Ouroboros: Single-step Diffusion Models for Cycle-consistent Forward and Inverse Rendering](https://arxiv.org/abs/2508.14461)
*Shanlin Sun,Yifan Wang,Hanwen Zhang,Yifeng Xiong,Qin Ren,Ruogu Fang,Xiaohui Xie,Chenyu You*

Main category: cs.CV

TL;DR: Ouroboros는 상호 보강하는 두 개의 단일 단계 확산 모델을 사용해 정방향(렌더링)과 역방향(역렌더링)을 처리하며, 사이클 일관성 기제를 도입해 장면의 고유 분해(intrinsic decomposition)를 실내외로 확장하고 비디오 분해로 무학습 전이를 지원해 속도와 일관성을 개선한다.


<details>
  <summary>Details</summary>
Motivation: 기존 다중 단계 확산 모델들은 정방향과 역방향 렌더링을 독립적으로 다뤄 순환 불일치(cycle inconsistency)와 느린 추론 속도 문제가 존재한다. 이를 해결해 일관성 있는 결과와 빠른 추론을 얻고자 함.

Method: Ouroboros 프레임워크는 서로를 보완하는 두 개의 단일 단계 확산(single-step diffusion) 모델로 구성된다. intrinsic decomposition을 실내 및 실외 장면으로 확장하고, 정방향과 역방향 출력 간의 정합성을 보장하는 사이클 일관성 메커니즘을 도입한다. 또한 학습 없이 비디오 분해로 전이하여 프레임 간 시간적 불일치를 줄인다.

Result: 다양한 장면에서 최첨단 성능을 달성했으며, 기존 확산 기반 방법들보다 추론 속도가 크게 향상되었다. 비디오 분해로의 무학습 전이 시에도 프레임별 고품질 역렌더링을 유지하면서 시간적 불일치를 감소시켰다.

Conclusion: 두 단일 단계 확산 모델의 상호 보강과 사이클 일관성 도입으로 렌더링-역렌더링 문제를 통합적으로 해결해 속도와 일관성을 동시에 개선했으며, 비디오로의 실용적 전이 가능성을 보였다.

Abstract: While multi-step diffusion models have advanced both forward and inverse
rendering, existing approaches often treat these problems independently,
leading to cycle inconsistency and slow inference speed. In this work, we
present Ouroboros, a framework composed of two single-step diffusion models
that handle forward and inverse rendering with mutual reinforcement. Our
approach extends intrinsic decomposition to both indoor and outdoor scenes and
introduces a cycle consistency mechanism that ensures coherence between forward
and inverse rendering outputs. Experimental results demonstrate
state-of-the-art performance across diverse scenes while achieving
substantially faster inference speed compared to other diffusion-based methods.
We also demonstrate that Ouroboros can transfer to video decomposition in a
training-free manner, reducing temporal inconsistency in video sequences while
maintaining high-quality per-frame inverse rendering.

</details>


### [23] [MF-LPR$^2$: Multi-Frame License Plate Image Restoration and Recognition using Optical Flow](https://arxiv.org/abs/2508.14797)
*Kihyun Na,Junseok Oh,Youngkwan Cho,Bumjin Kim,Sungmin Cho,Jinyoung Choi,Injung Kim*

Main category: cs.CV

TL;DR: 다중 프레임 정렬·집계를 통해 저화질·블러·글레어가 있는 대시캠 번호판 영상을 복원하고 인식하는 MF-LPR^2 프레임워크와 이를 평가하는 RLPR 데이터셋을 제안. 광류(Optical Flow) 기반 정렬과 오류 검출·보정 알고리즘으로 화질·인식 정확도를 개선함.


<details>
  <summary>Details</summary>
Motivation: 대시캠 영상의 번호판은 저해상도, 모션 블러, 글레어 등으로 인해 단일 이미지 복원·인식이 어렵고, 기존 사전학습 기반 생성 모델은 심각한 왜곡·아티팩트를 초래할 수 있음.

Method: 이웃 프레임을 정렬·집계하는 다중 프레임 복원·인식 프레임워크 MF-LPR^2를 제안. 최신 광류 추정기를 사용해 프레임을 정렬하고, 시공간 일관성을 활용해 잘못된 광류 추정을 검출·보정하는 필터링·정제 알고리즘을 설계하여 정렬 정확도를 높임.

Result: 새로운 RLPR 데이터셋(저화질 시퀀스와 고품질 의사 정답 200쌍)을 구축하여 평가. MF-LPR^2가 PSNR, SSIM, LPIPS에서 기존 8개 복원 모델을 큰 폭으로 상회. 인식 정확도는 86.44%로 단일 프레임 최고(14.04%) 및 다른 다중 프레임 최고(82.55%)를 능가. Ablation에서 필터링·정제 기법의 기여 확인.

Conclusion: 사전학습된 생성적 사전지식에 의존하지 않고 시공간 정보를 이용한 프레임 정렬·집계를 통해 실제 대시캠 환경에서 번호판 복원과 인식 성능을 크게 개선할 수 있음. RLPR 데이터셋은 실세계 조건 평가에 유용함.

Abstract: License plate recognition (LPR) is important for traffic law enforcement,
crime investigation, and surveillance. However, license plate areas in dash cam
images often suffer from low resolution, motion blur, and glare, which make
accurate recognition challenging. Existing generative models that rely on
pretrained priors cannot reliably restore such poor-quality images, frequently
introducing severe artifacts and distortions. To address this issue, we propose
a novel multi-frame license plate restoration and recognition framework,
MF-LPR$^2$, which addresses ambiguities in poor-quality images by aligning and
aggregating neighboring frames instead of relying on pretrained knowledge. To
achieve accurate frame alignment, we employ a state-of-the-art optical flow
estimator in conjunction with carefully designed algorithms that detect and
correct erroneous optical flow estimations by leveraging the spatio-temporal
consistency inherent in license plate image sequences. Our approach enhances
both image quality and recognition accuracy while preserving the evidential
content of the input images. In addition, we constructed a novel Realistic LPR
(RLPR) dataset to evaluate MF-LPR$^2$. The RLPR dataset contains 200 pairs of
low-quality license plate image sequences and high-quality pseudo ground-truth
images, reflecting the complexities of real-world scenarios. In experiments,
MF-LPR$^2$ outperformed eight recent restoration models in terms of PSNR, SSIM,
and LPIPS by significant margins. In recognition, MF-LPR$^2$ achieved an
accuracy of 86.44%, outperforming both the best single-frame LPR (14.04%) and
the multi-frame LPR (82.55%) among the eleven baseline models. The results of
ablation studies confirm that our filtering and refinement algorithms
significantly contribute to these improvements.

</details>


### [24] [DreamSwapV: Mask-guided Subject Swapping for Any Customized Video Editing](https://arxiv.org/abs/2508.14465)
*Weitao Wang,Zichen Wang,Hongdeng Shen,Yulei Lu,Xirui Fan,Suhui Wu,Jun Zhang,Haoqian Wang,Hao Zhang*

Main category: cs.CV

TL;DR: DreamSwapV는 사용자 지정 마스크와 참조 이미지로 비디오 내 모든 주체를 교체하는 마스크 안내형(subject-agnostic) end-to-end 프레임워크다. 다중 조건과 조건 융합 모듈, 적응형 마스크 전략, 2단계 데이터셋 구축·학습으로 기존 방법들을 능가하며 새로운 DreamSwapV-Benchmark와 VBench 지표에서 우수한 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 맞춤형 비디오 편집 수요 증가에서 주체 교체(subject swapping)는 핵심이지만, 기존 기법들은 좁은 도메인에 특화되거나 간접적/모호한 편집 수단에 의존해 최종 품질이 낮음. 더 일반적이고 정밀한 주체 교체 방법이 필요함.

Method: 마스크 기반의 주체-무관(end-to-end) 프레임워크 도입. 세부 안내를 위해 다중 조건을 도입하고 이를 효율적으로 통합하는 조건 융합 모듈을 제안. 다양한 크기·속성의 주체를 다루기 위한 적응형 마스크 전략을 설계. 또한 정교한 2단계(두 페이즈) 데이터셋 구성 및 학습 스킴을 사용.

Result: 제안한 DreamSwapV는 기존 교체 방법보다 높은 정교도와 문맥 상호작용 일관성을 보였으며, VBench 지표 및 새로 제시된 DreamSwapV-Benchmark에서 우수한 성능을 기록함.

Conclusion: DreamSwapV는 범용적이고 정밀한 비디오 주체 교체를 가능하게 하며, 새로운 벤치마크와 평가를 통해 실제 활용 가능성을 입증함.

Abstract: With the rapid progress of video generation, demand for customized video
editing is surging, where subject swapping constitutes a key component yet
remains under-explored. Prevailing swapping approaches either specialize in
narrow domains--such as human-body animation or hand-object interaction--or
rely on some indirect editing paradigm or ambiguous text prompts that
compromise final fidelity. In this paper, we propose DreamSwapV, a mask-guided,
subject-agnostic, end-to-end framework that swaps any subject in any video for
customization with a user-specified mask and reference image. To inject
fine-grained guidance, we introduce multiple conditions and a dedicated
condition fusion module that integrates them efficiently. In addition, an
adaptive mask strategy is designed to accommodate subjects of varying scales
and attributes, further improving interactions between the swapped subject and
its surrounding context. Through our elaborate two-phase dataset construction
and training scheme, our DreamSwapV outperforms existing methods, as validated
by comprehensive experiments on VBench indicators and our first introduced
DreamSwapV-Benchmark.

</details>


### [25] [DINOv3 with Test-Time Training for Medical Image Registration](https://arxiv.org/abs/2508.14809)
*Shansong Wang,Mojtaba Safari,Mingzhe Hu,Qiang Li,Chih-Wei Chang,Richard LJ Qiu,Xiaofeng Yang*

Main category: cs.CV

TL;DR: 학습이 필요 없는(test-time) 파이프라인으로, 동결된 DINOv3 기반 특징 공간에서 변형장을 최적화해 의료영상 정합을 수행하여 높은 정합 정확도와 규칙적 변형을 달성함.


<details>
  <summary>Details</summary>
Motivation: 학습 기반 의료영상 정합은 대량의 레이블된 학습 데이터가 필요해 임상 도입이 어려우므로, 추가 학습 없이 일반화 가능한 실용적 정합 방법을 제시하려 함.

Method: 사전학습된(frozen) DINOv3 인코더로 입력 영상을 특징 공간으로 투영한 뒤, 테스트 시점에서 변형장(디포메이션 필드)을 특징 공간에서 최적화하여 정합을 수행함(학습 단계 없음).

Result: Abdomen MR-CT: mean DSC 0.790, HD95 4.9±5.0, SDLogJ 0.08±0.02. ACDC cardiac MRI: mean DSC 0.769, HD95 4.8, SDLogJ 0.11. 전반적으로 초기 정렬 대비 성능 및 변형 규칙성 개선.

Conclusion: 기초(Foundation) 비전 특징 공간에서 테스트 시점 최적화를 수행하면 추가 학습 없이 실용적이고 일반화 가능한 임상 정합 솔루션을 제공할 수 있음.

Abstract: Prior medical image registration approaches, particularly learning-based
methods, often require large amounts of training data, which constrains
clinical adoption. To overcome this limitation, we propose a training-free
pipeline that relies on a frozen DINOv3 encoder and test-time optimization of
the deformation field in feature space. Across two representative benchmarks,
the method is accurate and yields regular deformations. On Abdomen MR-CT, it
attained the best mean Dice score (DSC) of 0.790 together with the lowest 95th
percentile Hausdorff Distance (HD95) of 4.9+-5.0 and the lowest standard
deviation of Log-Jacobian (SDLogJ) of 0.08+-0.02. On ACDC cardiac MRI, it
improves mean DSC to 0.769 and reduces SDLogJ to 0.11 and HD95 to 4.8, a marked
gain over the initial alignment. The results indicate that operating in a
compact foundation feature space at test time offers a practical and general
solution for clinical registration without additional training.

</details>


### [26] [LookOut: Real-World Humanoid Egocentric Navigation](https://arxiv.org/abs/2508.14466)
*Boxiao Pan,Adam W. Harley,C. Karen Liu,Leonidas J. Guibas*

Main category: cs.CV

TL;DR: Predict future sequence of 6D head poses (translations + rotations) from egocentric video; propose model using temporally aggregated 3D latent features; introduce Aria Navigation Dataset (AND) collected with Project Aria glasses (4 hours); experiments show human-like navigation behaviors and generalization to unseen environments.


<details>
  <summary>Details</summary>
Motivation: Collision-free future trajectory prediction from egocentric observations is crucial for humanoid robotics, VR/AR, and assistive navigation, but prior work lacks methods and real-world datasets for predicting sequences of 6D head poses and active head-turning behavior.

Method: Introduce a framework that reasons over temporally aggregated 3D latent features capturing geometric and semantic constraints for static and dynamic scene parts; predict both head translations and rotations to model active information-gathering behavior. Also develop a data collection pipeline using Project Aria glasses.

Result: Collected Aria Navigation Dataset (AND): 4 hours of real-world egocentric navigation recordings with diverse behaviors. Experiments demonstrate the model learns human-like behaviors (waiting, slowing, rerouting, looking for traffic) and generalizes to unseen environments.

Conclusion: Defines a new, challenging task and provides both a modeling approach and a real-world dataset that advance egocentric navigation and future pose prediction research.

Abstract: The ability to predict collision-free future trajectories from egocentric
observations is crucial in applications such as humanoid robotics, VR / AR, and
assistive navigation. In this work, we introduce the challenging problem of
predicting a sequence of future 6D head poses from an egocentric video. In
particular, we predict both head translations and rotations to learn the active
information-gathering behavior expressed through head-turning events. To solve
this task, we propose a framework that reasons over temporally aggregated 3D
latent features, which models the geometric and semantic constraints for both
the static and dynamic parts of the environment. Motivated by the lack of
training data in this space, we further contribute a data collection pipeline
using the Project Aria glasses, and present a dataset collected through this
approach. Our dataset, dubbed Aria Navigation Dataset (AND), consists of 4
hours of recording of users navigating in real-world scenarios. It includes
diverse situations and navigation behaviors, providing a valuable resource for
learning real-world egocentric navigation policies. Extensive experiments show
that our model learns human-like navigation behaviors such as waiting / slowing
down, rerouting, and looking around for traffic while generalizing to unseen
environments. Check out our project webpage at
https://sites.google.com/stanford.edu/lookout.

</details>


### [27] [Vivid-VR: Distilling Concepts from Text-to-Video Diffusion Transformer for Photorealistic Video Restoration](https://arxiv.org/abs/2508.14483)
*Haoran Bai,Xiaoxu Chen,Canqian Yang,Zongyao He,Sibin Deng,Ying Chen*

Main category: cs.CV

TL;DR: Vivid-VR은 T2V(텍스트-투-비디오) 기반의 생성적 비디오 복원 방법으로, ControlNet을 사용해 생성 과정의 콘텐츠 일관성을 보장한다. 기존의 제어 가능한 파이프라인은 다중모달 정렬의 제한으로 분포 변동(distribution drift)이 발생해 텍스처 현실감과 시간적 일관성이 저하되는 문제가 있었다. 이를 해결하기 위해 사전학습된 T2V 모델로부터 텍스트 개념을 합성한 학습 샘플을 생성해 개념을 증류하는 'concept distillation' 전략을 도입하고, 제어 아키텍처를 제안하여 입력 비디오의 열화(artifacts)를 필터링하는 control feature projector와 MLP 기반 매핑과 교차-어텐션을 결합한 이중 분기 ControlNet connector를 설계했다. 실험에서 합성 및 실제 벤치마크, AIGC 비디오에서 우수한 텍스처 현실감, 시각적 생동감, 시간적 일관성을 달성했다.


<details>
  <summary>Details</summary>
Motivation: 기존 T2V 기반 제어 가능한 복원 파이프라인은 멀티모달 정렬의 불완전성으로 분포 드리프트가 발생해 복원 품질(텍스처/detail 및 시간적 일관성)이 저하된다. 이를 극복해 텍스처 유지와 시간적 일관성을 확보하면서 제어성을 향상시키려는 목적이다.

Method: 사전학습된 T2V 모델을 이용해 텍스트 개념이 내재된 합성 학습 샘플을 만들고 이를 통해 개념을 증류(concept distillation)한다. 제어 아키텍처는 두 가지 핵심 요소로 구성된다: (1) 입력 비디오 라텐트의 열화 아티팩트를 걸러 생성 파이프라인 전파를 최소화하는 control feature projector, (2) MLP 기반 특징 매핑과 교차-어텐션을 결합한 이중-분기(ControlNet connector)로 동적 제어 특징 검색 및 적응적 제어 신호 조절을 수행한다.

Result: 합성 및 실제-world 벤치마크와 AIGC 비디오에서 기존 접근법보다 우수한 성능을 보였으며, 텍스처 현실감, 시각적 생동감, 시간적 일관성 측면에서 개선을 기록했다. 코드와 체크포인트를 공개했다.

Conclusion: Vivid-VR은 concept distillation과 제어 아키텍처 재설계를 통해 T2V 기반 복원에서 발생하는 분포 드리프트 문제를 완화하고, 콘텐츠 보존과 적응적 제어를 동시에 달성하여 복원 품질을 향상시킨 실용적 접근이다.

Abstract: We present Vivid-VR, a DiT-based generative video restoration method built
upon an advanced T2V foundation model, where ControlNet is leveraged to control
the generation process, ensuring content consistency. However, conventional
fine-tuning of such controllable pipelines frequently suffers from distribution
drift due to limitations in imperfect multimodal alignment, resulting in
compromised texture realism and temporal coherence. To tackle this challenge,
we propose a concept distillation training strategy that utilizes the
pretrained T2V model to synthesize training samples with embedded textual
concepts, thereby distilling its conceptual understanding to preserve texture
and temporal quality. To enhance generation controllability, we redesign the
control architecture with two key components: 1) a control feature projector
that filters degradation artifacts from input video latents to minimize their
propagation through the generation pipeline, and 2) a new ControlNet connector
employing a dual-branch design. This connector synergistically combines
MLP-based feature mapping with cross-attention mechanism for dynamic control
feature retrieval, enabling both content preservation and adaptive control
signal modulation. Extensive experiments show that Vivid-VR performs favorably
against existing approaches on both synthetic and real-world benchmarks, as
well as AIGC videos, achieving impressive texture realism, visual vividness,
and temporal consistency. The codes and checkpoints are publicly available at
https://github.com/csbhr/Vivid-VR.

</details>


### [28] [Virtual Community: An Open World for Humans, Robots, and Society](https://arxiv.org/abs/2508.14893)
*Qinhong Zhou,Hongxin Zhang,Xiangye Lin,Zheyuan Zhang,Yutian Chen,Wenjun Liu,Zunzhe Zhang,Sunli Chen,Lixing Fang,Qiushi Lyu,Xinyu Sun,Jincheng Yang,Zeyuan Wang,Bao Chi Dang,Zhehuan Chen,Daksha Ladia,Jiageng Liu,Chuang Gan*

Main category: cs.CV

TL;DR: Virtual Community는 실제 3D 장면 기반의 범세계 물리 엔진 위에서 사람, 로봇, 사회가 공존하는 대규모 오픈월드 시뮬레이션 플랫폼이다. 멀티에이전트 물리 시뮬레이터와 현실 정렬된 커뮤니티 생성 파이프라인을 제공하며, 커뮤니티 기획 및 로봇 협업 등 두 가지 도전과제를 제시해 다중 에이전트 추론·계획 및 이기종 로봇 협업의 난제를 연구하도록 설계되었다.


<details>
  <summary>Details</summary>
Motivation: AI와 로보틱스의 발전으로 인간과 로봇이 공동체에서 공존하게 될 가능성이 커짐에 따라, 대규모로 구현된 오픈월드 환경에서의 인간-로봇 사회적 지능과 상호작용을 연구할 플랫폼이 필요하다.

Method: (1) 오픈소스 멀티에이전트 물리 시뮬레이터 구현(로봇/인간/상호작용 지원). (2) 현실 정렬된 대규모 커뮤니티 생성 파이프라인 구축(광활한 야외 공간, 다양한 실내 장면, 다양한 외형의 에이전트). (3) 두 가지 평가 과제 설계: Community Planning Challenge(다중 에이전트 계획·추론) 및 Community Robot Challenge(이기종 로봇 협업). (4) 다양한 베이스라인을 과제에 적용해 성능 평가.

Result: 베이스라인 실험에서 고수준(open-world) 작업 계획과 저수준 협력 제어 모두에서 어려움이 나타났음을 보였으며, 플랫폼이 제시하는 문제들이 여전히 도전적임을 입증했다.

Conclusion: Virtual Community는 인간-로봇 공존과 대규모 사회적 지능 연구를 촉진할 오픈월드 시뮬레이션과 평가과제를 제공하며, 향후 관련 연구(계획·협업·사회적 상호작용) 활성화를 기대한다.

Abstract: The rapid progress in AI and Robotics may lead to a profound societal
transformation, as humans and robots begin to coexist within shared
communities, introducing both opportunities and challenges. To explore this
future, we present Virtual Community-an open-world platform for humans, robots,
and society-built on a universal physics engine and grounded in real-world 3D
scenes. With Virtual Community, we aim to study embodied social intelligence at
scale: 1) How robots can intelligently cooperate or compete; 2) How humans
develop social relations and build community; 3) More importantly, how
intelligent robots and humans can co-exist in an open world. To support these,
Virtual Community features: 1) An open-source multi-agent physics simulator
that supports robots, humans, and their interactions within a society; 2) A
large-scale, real-world aligned community generation pipeline, including vast
outdoor space, diverse indoor scenes, and a community of grounded agents with
rich characters and appearances. Leveraging Virtual Community, we propose two
novel challenges. The Community Planning Challenge evaluates multi-agent
reasoning and planning ability in open-world settings, such as cooperating to
help agents with daily activities and efficiently connecting other agents. The
Community Robot Challenge requires multiple heterogeneous robots to collaborate
in solving complex open-world tasks. We evaluate various baselines on these
tasks and demonstrate the challenges in both high-level open-world task
planning and low-level cooperation controls. We hope that Virtual Community
will unlock further study of human-robot coexistence within open-world
environments.

</details>


### [29] [SATURN: Autoregressive Image Generation Guided by Scene Graphs](https://arxiv.org/abs/2508.14502)
*Thanh-Nhan Vo,Trong-Thuan Nguyen,Tam V. Nguyen,Minh-Triet Tran*

Main category: cs.CV

TL;DR: SATURN은 장면 그래프를 중요도 순 토큰 시퀀스로 변환해 VAR-CLIP 기반의 동결된 CLIP-VQ-VAE 백본과 미세조정되는 VAR 트랜스포머만으로 그래프 구조를 해석해 고품질 장면 렌더링을 달성하는 경량 확장이다.


<details>
  <summary>Details</summary>
Motivation: 텍스트-투-이미지 모델은 사실적 렌더링은 우수하지만 복잡한 프롬프트에 내재된 객체 배치와 관계(레이아웃)를 정확히 반영하지 못한다. 장면 그래프는 구조적 사전 지식을 제공하지만 기존 그래프 기반 방법들은 GAN/확산 파이프라인 의존으로 최신 자기회귀 아키텍처 대비 속도와 화질에서 뒤처졌다.

Method: SATURN은 장면 그래프를 살리언스(중요도) 정렬 토큰 시퀀스로 변환하고, CLIP-VQ-VAE 백본을 동결한 채 VAR 트랜스포머만 미세조정한다. 별도 모듈이나 다단계 학습 없이 그래프 구조를 토큰 시퀀스로 주입함으로써 기존 VAR-CLIP 흐름을 확장한다.

Result: Visual Genome에서 FID를 56.45%에서 21.62%로 감소시키고 Inception Score를 16.03에서 24.78로 향상해 SG2IM, SGDiff 등 이전 방법들을 능가했다. 질적 분석에서도 객체 수 정확도와 공간 관계의 개선을 보였다.

Conclusion: SATURN은 구조적 인식(장면 그래프)과 최신 자기회귀 기반 렌더링 품질을 결합한 경량 솔루션으로, 추가 모듈이나 복잡한 학습 절차 없이 그래프 지시문을 효과적으로 활용한다.

Abstract: State-of-the-art text-to-image models excel at photorealistic rendering but
often struggle to capture the layout and object relationships implied by
complex prompts. Scene graphs provide a natural structural prior, yet previous
graph-guided approaches have typically relied on heavy GAN or diffusion
pipelines, which lag behind modern autoregressive architectures in both speed
and fidelity. We introduce SATURN (Structured Arrangement of Triplets for
Unified Rendering Networks), a lightweight extension to VAR-CLIP that
translates a scene graph into a salience-ordered token sequence, enabling a
frozen CLIP-VQ-VAE backbone to interpret graph structure while fine-tuning only
the VAR transformer. On the Visual Genome dataset, SATURN reduces FID from
56.45% to 21.62% and increases the Inception Score from 16.03 to 24.78,
outperforming prior methods such as SG2IM and SGDiff without requiring extra
modules or multi-stage training. Qualitative results further confirm
improvements in object count fidelity and spatial relation accuracy, showing
that SATURN effectively combines structural awareness with state-of-the-art
autoregressive fidelity.

</details>


### [30] [Adversarial Generation and Collaborative Evolution of Safety-Critical Scenarios for Autonomous Vehicles](https://arxiv.org/abs/2508.14527)
*Jiangfan Liu,Yongkang Guo,Fangzhi Zhong,Tianyuan Zhang,Zonglei Jing,Siyuan Liang,Jiakai Wang,Mingchuan Zhang,Aishan Liu,Xianglong Liu*

Main category: cs.CV

TL;DR: ScenGE는 대형 언어 모델과 시뮬레이터 제어 코드를 결합해 자율주행차의 안전 평가를 위해 현실적이고 적대적인 시나리오를 자동으로 생성·확장하는 프레임워크다. 메타-시나리오 생성으로 위협 행위를 유도한 뒤, 복잡한 교통 흐름을 통해 위협을 증폭시켜 더 많은 충돌 사례를 찾아낸다.


<details>
  <summary>Details</summary>
Motivation: 기존의 규칙 기반 또는 사전 정의된 위협 패턴은 사고의 다양하고 예기치 못한 실패 모드를 드러내지 못하므로, 보다 창의적이고 현실적인 적대적 시나리오 생성이 필요하다.

Method: ScenGE는 (1) Meta-Scenario Generation: 구조화된 주행 지식을 바탕으로 대형 언어 모델이 위협적이면서 그럴듯한 적대 행위를 유추하고 이를 실행 가능한 코드로 명세, (2) Complex Scenario Evolution: 배경 차량을 활용해 핵심 위협을 증폭시키고, adversarial collaborator graph로 주요 에이전트 궤적을 최적화하여 조향 공간 축소와 주요 가림(occlusion) 생성.

Result: 여러 강화학습 기반 자율주행 모델에 대해 SoTA 대비 평균 +31.96% 더 심각한 충돌 사례를 발견했고, 대형 모델 기반 AV 시스템과 다양한 시뮬레이터에서 적용 가능했으며, 제시한 시나리오로 적대적 학습 시 모델의 강인성이 향상됨. 실차 테스트와 인간 평가로 시나리오의 그럴듯함과 위협성을 검증.

Conclusion: LLM 기반의 메타-시나리오 생성과 시뮬레이터 내 복잡성 증폭 기법을 결합하면 기존 규칙 기반 방법보다 더 다양한·심각한 안전 위협을 발견할 수 있으며, 이는 AV 시스템의 안전성 평가 및 강인성 향상에 유용하다.

Abstract: The generation of safety-critical scenarios in simulation has become
increasingly crucial for safety evaluation in autonomous vehicles prior to road
deployment in society. However, current approaches largely rely on predefined
threat patterns or rule-based strategies, which limit their ability to expose
diverse and unforeseen failure modes. To overcome these, we propose ScenGE, a
framework that can generate plentiful safety-critical scenarios by reasoning
novel adversarial cases and then amplifying them with complex traffic flows.
Given a simple prompt of a benign scene, it first performs Meta-Scenario
Generation, where a large language model, grounded in structured driving
knowledge, infers an adversarial agent whose behavior poses a threat that is
both plausible and deliberately challenging. This meta-scenario is then
specified in executable code for precise in-simulator control. Subsequently,
Complex Scenario Evolution uses background vehicles to amplify the core threat
introduced by Meta-Scenario. It builds an adversarial collaborator graph to
identify key agent trajectories for optimization. These perturbations are
designed to simultaneously reduce the ego vehicle's maneuvering space and
create critical occlusions. Extensive experiments conducted on multiple
reinforcement learning based AV models show that ScenGE uncovers more severe
collision cases (+31.96%) on average than SoTA baselines. Additionally, our
ScenGE can be applied to large model based AV systems and deployed on different
simulators; we further observe that adversarial training on our scenarios
improves the model robustness. Finally, we validate our framework through
real-world vehicle tests and human evaluation, confirming that the generated
scenarios are both plausible and critical. We hope our paper can build up a
critical step towards building public trust and ensuring their safe deployment.

</details>


### [31] [WISE-FUSE: Efficient Whole Slide Image Encoding via Coarse-to-Fine Patch Selection with VLM and LLM Knowledge Fusion](https://arxiv.org/abs/2508.14537)
*Yonghan Shin,SeungKyu Kim,Won-Ki Jeong*

Main category: cs.CV

TL;DR: WISE-FUSE는 병리학 도메인 비전-언어 모델과 대형 언어 모델을 활용해 저해상도 패치와 클래스별 텍스트 설명의 유사도를 계산, 진단에 중요한 영역만 선택적으로 고해상도로 인코딩·텍스트 임베딩과 융합하여 WSI 인코딩 시간을 3배 이상 단축하면서 진단 성능을 유지하거나 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: WSI(Whole Slide Images)는 기가픽셀 규모로 인코딩 비용과 전처리·학습 시간이 매우 커서 실제 배포의 병목이 된다. 이를 줄이기 위한 선택적·효율적 인코딩 방법이 필요하다.

Method: 저해상도 패치와 클래스별 텍스트 설명 간 유사도를 병리 도메인 비전-언어 모델과 지식 증류로 계산해 세밀한 진단 특징을 보존한다. 유사도 기반으로 정보성 높은 소수의 영역을 선택해 불필요한 패치를 조기에 제거하고, 선택된 고해상도 패치만 인코딩한 뒤 텍스트 임베딩과 융합한다.

Result: WSI 인코딩 시간을 3배 이상 단축하면서 전체 패치 처리와 비교해 진단 성능이 동등하거나 더 우수함을 실험으로 보였다.

Conclusion: 진단 문맥을 보강하는 텍스트-비전 융합과 선택적 인코딩 전략으로 CPath의 확장성과 실무 적용성을 크게 개선한 실용적 접근이다.

Abstract: Whole slide images (WSIs) in computational pathology (CPath) pose a major
computational challenge due to their gigapixel scale, often requiring the
processing of tens to hundreds of thousands of high-resolution patches per
slide. This results in prohibitive encoding costs, with preprocessing and
training times extending to days or even weeks-making WSI encoding the most
significant bottleneck in real-world deployment. In this work, we propose
WISE-FUSE, an adaptive WSI encoding framework that leverages pathology-domain
vision-language models and large language models to address this challenge by
selectively processing diagnostically relevant regions. WISE-FUSE first
computes similarity scores between low-resolution patches and class-specific
textual descriptions using a knowledge distillation mechanism that preserves
fine-grained diagnostic features. Based on these similarity scores, we select a
small subset of informative regions for the target task, which quickly
eliminates irrelevant patches at the coarse level. The corresponding
high-resolution patches are then selectively encoded and fused with textual
embeddings to reinforce diagnostic context. Extensive experiments demonstrate
that WISE-FUSE reduces WSI encoding time by over threefold while achieving
diagnostic performance comparable to or surpassing that of exhaustive patch
processing, offering a scalable and practical solution for CPath.

</details>


### [32] [Making Pose Representations More Expressive and Disentangled via Residual Vector Quantization](https://arxiv.org/abs/2508.14561)
*Sukhyun Jeong,Hong-Gi Shin,Yong-Hoon Choi*

Main category: cs.CV

TL;DR: 이 논문은 포즈 코드의 해석 가능성과 조작성을 유지하면서 잔차 벡터 양자화(RVQ)를 사용해 연속 모션 특징을 결합하여 텍스트-투-모션의 세밀한 동작을 더 잘 캡처하도록 제안한다. HumanML3D에서 FID와 R-Precision이 개선되었음을 보고한다.


<details>
  <summary>Details</summary>
Motivation: 기존의 제어 가능한 모션 생성은 포즈 코드 기반 이산 표현에 의존하나, 이산 포즈 코드만으로는 고주파수 등 세밀한 모션 특성을 포착하기 어렵다. 따라서 표현력 향상이 필요하다.

Method: 포즈 코드 기반 잠재 표현에 RVQ로 연속 모션 특징을 잔차 형태로 추가한다. 이로써 포즈 코드의 해석 가능성과 조작성을 유지하면서 세밀한 모션을 포착한다.

Result: HumanML3D 데이터셋에서 FID가 0.041에서 0.015로 감소하고 Top-1 R-Precision이 0.508에서 0.510으로 소폭 개선되었다. 포즈 코드의 pairwise direction similarity 분석으로 편집 가능성도 확인했다.

Conclusion: RVQ를 통해 이산 포즈 코드의 한계를 보완해 세밀한 모션을 더 잘 생성하고 제어 가능성을 유지한다. 실험은 지표 개선과 질적 분석으로 이를 뒷받침한다.

Abstract: Recent progress in text-to-motion has advanced both 3D human motion
generation and text-based motion control. Controllable motion generation
(CoMo), which enables intuitive control, typically relies on pose code
representations, but discrete pose codes alone cannot capture fine-grained
motion details, limiting expressiveness. To overcome this, we propose a method
that augments pose code-based latent representations with continuous motion
features using residual vector quantization (RVQ). This design preserves the
interpretability and manipulability of pose codes while effectively capturing
subtle motion characteristics such as high-frequency details. Experiments on
the HumanML3D dataset show that our model reduces Frechet inception distance
(FID) from 0.041 to 0.015 and improves Top-1 R-Precision from 0.508 to 0.510.
Qualitative analysis of pairwise direction similarity between pose codes
further confirms the model's controllability for motion editing.

</details>


### [33] [Reliable Smoke Detection via Optical Flow-Guided Feature Fusion and Transformer-Based Uncertainty Modeling](https://arxiv.org/abs/2508.14597)
*Nitish Kumar Mahala,Muzammil Khan,Pushpendra Kumar*

Main category: cs.CV

TL;DR: 단안 영상에서 광류 기반 모션 인코딩을 이용해 연기 세그멘테이션 마스크를 생성하고, 이를 외관 단서와 결합해 불리한 조명·유동 조건에서도 강건하게 동작하는 Two-Phase Uncertainty-Aware Shifted-Windows Transformer로 연기(화재 전조) 탐지를 수행함.


<details>
  <summary>Details</summary>
Motivation: 연기는 조명·유동·환경 잡음에 따라 복잡한 시공간 특성을 보이므로 전통적 검출기가 신뢰성 있게 동작하지 못하며, 다중 센서 구성이 어려운 환경에서 단안 영상만으로도 높은 신뢰도의 조기 경보 시스템을 만들 필요가 있음.

Method: (1) 네 가지 색 이론에서 영감을 받은 이중 위상 레벨셋 분수차 변분 모델로 광류(optical flow)를 추정해 모션 불연속을 보존, (2) 색 인코딩된 광류 맵과 외관 단서를 가우시안 혼합모형(GMM)으로 융합해 이진 연기 세그멘테이션 마스크 생성, (3) 생성된 표현을 입력으로 하는 Shifted-Windows Transformer 설계 및 멀티스케일 불확실성 추정 헤드 추가, (4) 2단계 학습: 1단계는 탐지 정확도 최적화, 2단계는 동시적 알레아토릭/에피스테믹 불확실성 모델링으로 예측 신뢰도 학습.

Result: 다중 평가 지표와 SOTA 기법들과의 비교 실험에서 우수한 일반화 능력과 강건성을 보였으며, 다양한 감시·산업 안전·자율 모니터링 적용에서 신뢰도 높은 조기 화재 탐지 가능성을 입증.

Conclusion: 단일 카메라 영상만으로도 모션-외관 융합 및 불확실성 학습을 통해 실용적이고 신뢰성 높은 연기 탐지 시스템을 제안함.

Abstract: Fire outbreaks pose critical threats to human life and infrastructure,
necessitating high-fidelity early-warning systems that detect combustion
precursors such as smoke. However, smoke plumes exhibit complex spatiotemporal
dynamics influenced by illumination variability, flow kinematics, and
environmental noise, undermining the reliability of traditional detectors. To
address these challenges without the logistical complexity of multi-sensor
arrays, we propose an information-fusion framework by integrating smoke feature
representations extracted from monocular imagery. Specifically, a Two-Phase
Uncertainty-Aware Shifted Windows Transformer for robust and reliable smoke
detection, leveraging a novel smoke segmentation dataset, constructed via
optical flow-based motion encoding, is proposed. The optical flow estimation is
performed with a four-color-theorem-inspired dual-phase level-set
fractional-order variational model, which preserves motion discontinuities. The
resulting color-encoded optical flow maps are fused with appearance cues via a
Gaussian Mixture Model to generate binary segmentation masks of the smoke
regions. These fused representations are fed into the novel Shifted-Windows
Transformer, which is augmented with a multi-scale uncertainty estimation head
and trained under a two-phase learning regimen. First learning phase optimizes
smoke detection accuracy, while during the second phase, the model learns to
estimate plausibility confidence in its predictions by jointly modeling
aleatoric and epistemic uncertainties. Extensive experiments using multiple
evaluation metrics and comparative analysis with state-of-the-art approaches
demonstrate superior generalization and robustness, offering a reliable
solution for early fire detection in surveillance, industrial safety, and
autonomous monitoring applications.

</details>


### [34] [Incremental Object Detection with Prompt-based Methods](https://arxiv.org/abs/2508.14599)
*Matthias Neuwirth-Trapp,Maarten Bieshaar,Danda Pani Paudel,Luc Van Gool*

Main category: cs.CV

TL;DR: 이 논문은 증분 객체 검출(Incremental Object Detection, IOD)에 비주얼 프롬프트 기반 방법을 적용하고 평가한다. 세 가지 프롬프트 기법을 복잡한 도메인 증분 학습 설정에서 분석하고, 여러 기준선과 비교했으며, 프롬프트만으로는 성능이 떨어지지만 이전 데이터 일부를 리플레이하는 방법을 결합하면 실용적이고 우수한 결과를 얻음을 보였다.


<details>
  <summary>Details</summary>
Motivation: 프롬프트 기반 시각 기법이 이미지 분류의 증분 학습에서 효율적으로 사용되어 왔지만, 증분 객체 검출에의 적용 여부와 일반화 가능성은 불분명하다. 이 갭을 메우고자 IOD에 프롬프트 방법들을 적용·분석하려 함.

Method: 도메인 증분 학습 설정에서 세 가지 비주얼 프롬프트 방법을 평가하고, 다양한 기준선과 비교 실험을 수행. 또한 프롬프트 길이와 초기화 방식에 대한 추가 실험을 진행. 리플레이(이전 데이터 일부 재사용)를 결합한 방법도 제안하여 성능을 비교.

Result: 순수 프롬프트 기반 방법들은 복잡한 IOD 설정에서 성능이 낮았음. 하지만 비주얼 프롬프트에 소량의 이전 데이터 리플레이를 결합하면 가장 좋은 성능을 달성했고, 프롬프트 길이·초기화에 대한 실험을 통해 관련 인사이트를 도출함.

Conclusion: 프롬프트 기반 증분 학습 방법은 IOD에 바로 적용하기에는 한계가 있으나, 이전 데이터 리플레이를 결합하면 실용적이고 효과적인 방법이 될 수 있다. 프롬프트 설계(길이·초기화 등)가 성능에 영향을 미치므로 추가 연구가 필요하다.

Abstract: Visual prompt-based methods have seen growing interest in incremental
learning (IL) for image classification. These approaches learn additional
embedding vectors while keeping the model frozen, making them efficient to
train. However, no prior work has applied such methods to incremental object
detection (IOD), leaving their generalizability unclear. In this paper, we
analyze three different prompt-based methods under a complex domain-incremental
learning setting. We additionally provide a wide range of reference baselines
for comparison. Empirically, we show that the prompt-based approaches we tested
underperform in this setting. However, a strong yet practical method, combining
visual prompts with replaying a small portion of previous data, achieves the
best results. Together with additional experiments on prompt length and
initialization, our findings offer valuable insights for advancing prompt-based
IL in IOD.

</details>


### [35] [AnchorSync: Global Consistency Optimization for Long Video Editing](https://arxiv.org/abs/2508.14609)
*Zichi Liu,Yinggui Wang,Tao Wei,Chao Ma*

Main category: cs.CV

TL;DR: AnchorSync은 장시간 비디오 편집을 위해 앵커 프레임 편집과 중간 프레임 보간을 분리하는 확산 기반 프레임워크로, 점진적 노이즈 제거로 구조적 일관성을 유지하고 멀티모달 가이던스로 시간적 역학을 보존한다. 실험에서 기존 기법보다 화질과 시간적 안정성에서 우수함을 보였다.


<details>
  <summary>Details</summary>
Motivation: 수천 프레임에 걸친 장시간 비디오 편집은 전역적 일관성과 시간적 연속성을 유지해야 하며, 기존 방법은 구조적 드리프트나 시간적 아티팩트에 취약하다.

Method: 희소 앵커 프레임 편집과 부드러운 중간 프레임 보간으로 작업을 분리하고, 확산 기반의 점진적 디노이징(progressive denoising)으로 구조적 일관성을 강제하며, 멀티모달(예: 텍스트·비디오) 가이던스로 시간적 동역학을 보존한다.

Result: 광범위한 실험에서 AnchorSync는 일관성 있고 고품질의 편집 결과를 생성했으며, 시각적 품질과 시간적 안정성에서 기존 방법을 능가했다.

Conclusion: 앵커 기반 편집과 보간을 결합한 확산 프레임워크와 멀티모달 가이던스는 장시간 비디오 편집에서 구조적·시간적 일관성을 효과적으로 개선한다.

Abstract: Editing long videos remains a challenging task due to the need for
maintaining both global consistency and temporal coherence across thousands of
frames. Existing methods often suffer from structural drift or temporal
artifacts, particularly in minute-long sequences. We introduce AnchorSync, a
novel diffusion-based framework that enables high-quality, long-term video
editing by decoupling the task into sparse anchor frame editing and smooth
intermediate frame interpolation. Our approach enforces structural consistency
through a progressive denoising process and preserves temporal dynamics via
multimodal guidance. Extensive experiments show that AnchorSync produces
coherent, high-fidelity edits, surpassing prior methods in visual quality and
temporal stability.

</details>


### [36] [Seeing Further on the Shoulders of Giants: Knowledge Inheritance for Vision Foundation Models](https://arxiv.org/abs/2508.14707)
*Jiabo Huang,Chen Chen,Lingjuan Lyu*

Main category: cs.CV

TL;DR: 여러 도메인 특화로 사전학습된 공개 비전 모델들을 통합해 지식 전이와 보존을 통해 일반목적 비전 파운데이션 모델(VFM)을 구축하는 모델 주도 방식. 분포 격차를 줄이기 위해 공통 잠재 공간에서 교사 모델들을 통합하고, 일반 목적 교사를 지식 기반으로 삼아 어댑터로 목적 특화 교사의 지식을 병합함. 라벨 대규모 데이터 없이도 이미지 분류·객체 검출·시맨틱·인스턴스 분할 등에서 기존 데이터 중심 모델들을 능가.


<details>
  <summary>Details</summary>
Motivation: 데이터 중심 접근법은 대규모 고품질 라벨과 고성능 GPU를 요구해 많은 기관에 장벽이 되며, 반면 도메인 특화로 사전학습된 공개 비전 모델들은 핵심 지식을 담고 있어 이를 일반 목적 VFM 개발에 적극 활용할 필요가 있다.

Method: 여러 사전학습 교사 모델을 공통 잠재 공간으로 정렬해 분포 차이로 인한 '불균형 전이' 문제를 완화하고, 일반 목적 교사를 지식 기반으로 설정해 어댑터 모듈로 다른 목적 특화 교사들의 지식을 통합 및 보존하는 전략을 제시. 모델 통합·집계로 대량 라벨 데이터 없이 VFM 학습을 수행.

Result: 제안된 VFM이 이미지 분류, 객체 검출, 시맨틱 분할, 인스턴스 분할의 네 가지 핵심 비전 과제에서 기존 데이터 중심 모델들보다 우수한 성능을 보임.

Conclusion: 기존 공개 사전학습 모델들을 통합·보존하는 모델 중심 접근은 대규모 라벨 데이터와 연산 자원에 대한 의존을 줄이면서도 범용적이고 다중 작업을 지원하는 VFM을 효과적으로 구축할 수 있음을 입증한다.

Abstract: Vision foundation models (VFMs) are predominantly developed using
data-centric methods. These methods require training on vast amounts of data
usually with high-quality labels, which poses a bottleneck for most
institutions that lack both large-scale data and high-end GPUs. On the other
hand, many open-source vision models have been pretrained on domain-specific
data, enabling them to distill and represent core knowledge in a form that is
transferable across diverse applications. Even though these models are highly
valuable assets, they remain largely under-explored in empowering the
development of a general-purpose VFM. In this paper, we presents a new
model-driven approach for training VFMs through joint knowledge transfer and
preservation. Our method unifies multiple pre-trained teacher models in a
shared latent space to mitigate the ``imbalanced transfer'' issue caused by
their distributional gaps. Besides, we introduce a knowledge preservation
strategy to take a general-purpose teacher as a knowledge base for integrating
knowledge from the remaining purpose-specific teachers using an adapter module.
By unifying and aggregating existing models, we build a powerful VFM to inherit
teachers' expertise without needing to train on a large amount of labeled data.
Our model not only provides generalizable visual features, but also inherently
supports multiple downstream tasks. Extensive experiments demonstrate that our
VFM outperforms existing data-centric models across four fundamental vision
tasks, including image classification, object detection, semantic and instance
segmentation.

</details>


### [37] [Multiscale Video Transformers for Class Agnostic Segmentation in Autonomous Driving](https://arxiv.org/abs/2508.14729)
*Leila Cheshmi,Mennatullah Siam*

Main category: cs.CV

TL;DR: They introduce an efficient multiscale video transformer for class-agnostic segmentation using only motion cues (no optical flow). Key ideas: multi-stage multiscale query-memory decoding, scale-specific random drop-token, and a shared learnable memory to preserve high-resolution spatiotemporal features. Evaluated on DAVIS'16, KITTI, Cityscapes, it outperforms multiscale baselines while being GPU- and runtime-efficient.


<details>
  <summary>Details</summary>
Motivation: Safety-critical autonomous driving requires detecting unknown objects and unforeseen scenarios; existing video segmentation focuses on known classes and pixel-level visual grounding with LLMs is computationally costly. The paper aims to detect unknown object instances efficiently using motion cues without heavy per-pixel grounding.

Method: End-to-end multiscale video transformer that avoids optical flow. Uses multi-stage multiscale query-memory decoding with a shared learnable memory module that preserves high-resolution information across scales. Introduces scale-specific random drop-token for efficiency and maintains detailed spatiotemporal features rather than compressing them in the decoder.

Result: Consistent outperforming of multiscale baselines on DAVIS'16, KITTI, and Cityscapes, with improved GPU memory usage and runtime efficiency. Demonstrates capability for class-agnostic segmentation relying on motion cues and suitability for real-time dense prediction.

Conclusion: The memory-centric, multiscale transformer is a promising direction for efficient, real-time class-agnostic segmentation in safety-critical robotics, enabling detection of unknown objects with lower computational cost. It provides a practical trade-off between accuracy and efficiency for dense video prediction.

Abstract: Ensuring safety in autonomous driving is a complex challenge requiring
handling unknown objects and unforeseen driving scenarios. We develop
multiscale video transformers capable of detecting unknown objects using only
motion cues. Video semantic and panoptic segmentation often relies on known
classes seen during training, overlooking novel categories. Recent visual
grounding with large language models is computationally expensive, especially
for pixel-level output. We propose an efficient video transformer trained
end-to-end for class-agnostic segmentation without optical flow. Our method
uses multi-stage multiscale query-memory decoding and a scale-specific random
drop-token to ensure efficiency and accuracy, maintaining detailed
spatiotemporal features with a shared, learnable memory module. Unlike
conventional decoders that compress features, our memory-centric design
preserves high-resolution information at multiple scales. We evaluate on
DAVIS'16, KITTI, and Cityscapes. Our method consistently outperforms multiscale
baselines while being efficient in GPU memory and run-time, demonstrating a
promising direction for real-time, robust dense prediction in safety-critical
robotics.

</details>


### [38] [Improved Mapping Between Illuminations and Sensors for RAW Images](https://arxiv.org/abs/2508.14730)
*Abhijith Punnappurath,Luxi Zhao,Hoang Le,Abdelrahman Abdelhamed,SaiKiran Kumar Tedla,Michael S. Brown*

Main category: cs.CV

TL;DR: 이 논문은 다양한 조명 스펙트럼과 여러 카메라 센서에서 촬영한 RAW 이미지 데이터셋(390가지 조명, 4개 카메라, 18개 장면)을 소개하고, 조명 및 센서 매핑을 수행하는 경량 신경망을 제안하여 기존 방법보다 성능이 우수하며, 이를 통해 신경 ISP 교육에 활용함을 보인다.


<details>
  <summary>Details</summary>
Motivation: RAW 이미지가 센서 및 조명 특성에 따라 강한 색 편향을 가지며, 센서별·조명별로 데이터 수집이 어려워 데이터셋 구축 부담을 줄이고자 함. 특정 센서에 대한 조명 증강과 센서 간 매핑 방법이 필요함.

Method: 튜너블 조명 스펙트럼을 갖춘 맞춤형 라이트박스로 다양한 조명 하에서 동일 장면을 여러 카메라로 촬영하여 대규모 매핑 데이터셋을 구축(390 조명, 4 카메라, 18 장면). 이 데이터로 경량 신경망을 학습시켜 조명 및 센서 매핑을 수행하고 경쟁 기법보다 우수한 성능을 보임. 신경 ISP 학습에의 활용성을 검증.

Result: 제작한 데이터셋과 제안한 경량 모델이 기존 방법들을 능가하는 매핑 성능을 보였으며, 신경 ISP 훈련 시 유용함을 실험으로 보임.

Conclusion: 광범위한 조명 및 센서 매핑 데이터셋과 경량 모델은 RAW 이미지의 조명 편향 문제 해결에 기여하며, 데이터 수집 부담을 줄이고 신경 ISP 등의 다운스트림 작업에 도움을 줌.

Abstract: RAW images are unprocessed camera sensor output with sensor-specific RGB
values based on the sensor's color filter spectral sensitivities. RAW images
also incur strong color casts due to the sensor's response to the spectral
properties of scene illumination. The sensor- and illumination-specific nature
of RAW images makes it challenging to capture RAW datasets for deep learning
methods, as scenes need to be captured for each sensor and under a wide range
of illumination. Methods for illumination augmentation for a given sensor and
the ability to map RAW images between sensors are important for reducing the
burden of data capture. To explore this problem, we introduce the
first-of-its-kind dataset comprising carefully captured scenes under a wide
range of illumination. Specifically, we use a customized lightbox with tunable
illumination spectra to capture several scenes with different cameras. Our
illumination and sensor mapping dataset has 390 illuminations, four cameras,
and 18 scenes. Using this dataset, we introduce a lightweight neural network
approach for illumination and sensor mapping that outperforms competing
methods. We demonstrate the utility of our approach on the downstream task of
training a neural ISP. Link to project page:
https://github.com/SamsungLabs/illum-sensor-mapping.

</details>


### [39] [Adversarial Hospital-Invariant Feature Learning for WSI Patch Classification](https://arxiv.org/abs/2508.14779)
*Mengliang Zhang,Jacob M. Luber*

Main category: cs.CV

TL;DR: 병원별 스캐너·전처리 차이로 생기는 도메인 편향이 병리 기반 파운데이션 모델(PFMs)에 영향을 주는지 정량화하고, 고정된 인코더의 표현에서 병원 특이 특징을 제거하는 경량 적대적 어댑터 방법을 제안하여 도메인 예측 가능성을 낮추고 질병 분류 성능은 유지하거나 향상시킨 논문.


<details>
  <summary>Details</summary>
Motivation: 병리 전체 슬라이드 이미지(WSI)는 병원별 스캐너와 전처리 차이로 분포가 달라 PFMs가 병원 특이적 특징을 학습할 위험이 있으며, 이는 임상 배포 시 편향·안전성 문제를 유발한다. 따라서 도메인 편향을 정량화하고 완화하는 방법이 필요하다.

Method: (1) PFMs의 도메인 편향을 정량화하는 파이프라인을 설계하고, (2) 여러 모델의 성능을 비교 평가하며, (3) 인코더를 변경하지 않고 고정 표현에 연결하는 학습 가능한 어댑터 + 도메인 분류기 + gradient reversal layer(GRL)를 이용한 경량 적대적 프레임워크를 제안해 도메인 불변이면서 태스크 판별적인 표현을 학습한다.

Result: 다기관 병리 데이터셋 실험에서 제안 방법은 도메인(병원) 예측 가능성을 크게 낮추고, 특히 미발견 병원(Out-of-domain) 조건에서 질병 분류 성능을 유지하거나 오히려 개선했다. 병원 감지 성능 저하와 특징 공간 시각화로 효과를 추가 확인했다.

Conclusion: 제안한 경량 적대적 어댑터는 인코더를 수정하지 않고도 병원 소스 기반 편향을 완화해 PFMs의 일반화와 임상 배포 가능성을 높이며, 코드 공개 예정.

Abstract: Pathology foundation models (PFMs) have demonstrated remarkable potential in
whole-slide image (WSI) diagnosis. However, pathology images from different
hospitals often vary due to differences in scanning hardware and preprocessing
styles, which may lead PFMs to inadvertently learn hospital-specific features,
posing risks for clinical deployment. In this work, we present the first
systematic study of domain bias in PFMs arising from hospital source
characteristics. Specifically, we (1) construct a pipeline for quantifying
domain bias in PFMs, (2) evaluate and compare the performance of multiple
models, and (3) propose a lightweight adversarial framework that removes latent
hospital-specific features from frozen representations without modifying the
encoder itself. By introducing a trainable adapter and a domain classifier
connected through a gradient reversal layer (GRL), our method learns
task-discriminative yet domain-invariant representations. Experiments on
multi-center histopathology datasets demonstrate that our approach
substantially reduces domain predictability while maintaining or even improving
disease classification performance, particularly in out-of-domain (unseen
hospital) scenarios. Further analyses, including hospital detection and feature
space visualization, confirm the effectiveness of our method in mitigating
hospital bias. We will provide our code based on acceptance.

</details>


### [40] [Tinker: Diffusion's Gift to 3D--Multi-View Consistent Editing From Sparse Inputs without Per-Scene Optimization](https://arxiv.org/abs/2508.14811)
*Canyu Zhao,Xiaoman Li,Tianjian Feng,Zhiyue Zhao,Hao Chen,Chunhua Shen*

Main category: cs.CV

TL;DR: Tinker is a zero-/few-shot 3D editing framework that uses pretrained diffusion models to produce multi-view consistent edits from as few as one or two images, plus a large multi-view editing dataset and novel modules (referring multi-view editor and any-view-to-video synthesizer).


<details>
  <summary>Details</summary>
Motivation: Existing 3D editing methods require expensive per-scene finetuning or many consistent edited views; the authors aim to enable scalable, generalizable 3D edits without per-scene optimization, leveraging pretrained diffusion models' latent 3D awareness.

Method: They collect the first large-scale multi-view editing dataset and build a pipeline. Tinker repurposes pretrained diffusion models and introduces two components: (1) a referring multi-view editor for precise, reference-driven, multi-view-coherent edits, and (2) an any-view-to-video synthesizer that uses spatial-temporal priors from video diffusion to complete scenes and synthesize novel views from sparse inputs.

Result: Tinker produces robust multi-view consistent edits from one or two images without per-scene finetuning and achieves state-of-the-art results on editing, novel-view synthesis, and rendering enhancement tasks. The system lowers the barrier to generalizable 3D content creation.

Conclusion: Tinker demonstrates that pretrained diffusion models can be repurposed for scalable, zero-shot or few-shot multi-view 3D editing, supported by a new large-scale dataset and novel editing/synthesis modules, marking progress toward practical, generalizable 3D editing workflows.

Abstract: We introduce Tinker, a versatile framework for high-fidelity 3D editing that
operates in both one-shot and few-shot regimes without any per-scene
finetuning. Unlike prior techniques that demand extensive per-scene
optimization to ensure multi-view consistency or to produce dozens of
consistent edited input views, Tinker delivers robust, multi-view consistent
edits from as few as one or two images. This capability stems from repurposing
pretrained diffusion models, which unlocks their latent 3D awareness. To drive
research in this space, we curate the first large-scale multi-view editing
dataset and data pipeline, spanning diverse scenes and styles. Building on this
dataset, we develop our framework capable of generating multi-view consistent
edited views without per-scene training, which consists of two novel
components: (1) Referring multi-view editor: Enables precise, reference-driven
edits that remain coherent across all viewpoints. (2) Any-view-to-video
synthesizer: Leverages spatial-temporal priors from video diffusion to perform
high-quality scene completion and novel-view generation even from sparse
inputs. Through extensive experiments, Tinker significantly reduces the barrier
to generalizable 3D content creation, achieving state-of-the-art performance on
editing, novel-view synthesis, and rendering enhancement tasks. We believe that
Tinker represents a key step towards truly scalable, zero-shot 3D editing.
Project webpage: https://aim-uofa.github.io/Tinker

</details>


### [41] [Repeating Words for Video-Language Retrieval with Coarse-to-Fine Objectives](https://arxiv.org/abs/2508.14812)
*Haoyu Zhao,Jiaxi Gu,Shicong Wang,Xing Zhang,Hang Xu,Zuxuan Wu,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: 비디오-텍스트 검색에서 대규모 사전학습 부담을 줄이기 위해 프레임-단어 유사도를 활용한 Granularity-Aware Representation로 미세 및 거시 정보 정렬을 학습하고, 반복 키워드 투표와 Matching Entropy를 쓰는 추론 파이프라인으로 추가 학습 없이 성능을 향상시킴.


<details>
  <summary>Details</summary>
Motivation: 기존 방법들은 성능 향상을 위해 대규모 사전학습에 의존해 계산비용이 크고, 비디오와 텍스트의 세부 정보(프레임-단어 수준)가 충분히 활용되지 않음.

Method: coarse-to-fine 목표(contrastive 및 matching 학습)로 영상-텍스트 의미를 학습. Granularity-Aware Representation 모듈은 캡션 단어와 영상 프레임 간 유사도 분석으로 미세 데이터 생성. 추론단에서는 캡션 내 반복 키워드(Repetition)를 활용한 투표 메커니즘과 Matching Entropy 지표를 도입해 추가 학습 없이 검색 성능 개선.

Result: 네 개 벤치마크에서 기존 기법보다 우수한 성능을 보고. 특히 제안된 추론 파이프라인만으로 MSR-VTT에서 Recall@1이 2.1% 향상, DiDeMo에서 1.6% 향상.

Conclusion: 미세-거시 수준의 정렬 학습과 반복 기반 추론 기법을 결합하면 대규모 추가 사전학습 없이도 비디오-텍스트 검색 성능을 유의미하게 개선할 수 있음.

Abstract: The explosive growth of video streaming presents challenges in achieving high
accuracy and low training costs for video-language retrieval. However, existing
methods rely on large-scale pre-training to improve video retrieval
performance, resulting in significant computational demands. Additionally, the
fine-grained information in videos and texts remains underexplored. To
alleviate these problems, we propose a novel framework to learn fine-grained
features for better alignment and introduce an inference pipeline to improve
performance without additional training. Specifically, we employ coarse-to-fine
objectives to understand the semantic information of video-text pairs,
including contrastive and matching learning. The fine-grained data used for
training is obtained through the Granularity-Aware Representation module, which
is designed based on similarity analysis between video frames and words in
captions. Furthermore, we observe that the repetition of keywords in the
original captions, referred to as "Repetition", can enhance retrieval
performance and improve alignment between video and text. Based on this
insight, we propose a novel and effective inference pipeline that incorporates
a voting mechanism and a new Matching Entropy metric to achieve better
retrieval performance without requiring additional pre-training. Experimental
results on four benchmarks demonstrate that the proposed method outperforms
previous approaches. Additionally, our inference pipeline achieves significant
performance improvements, with a 2.1% increase in Recall@1 on the MSR-VTT
dataset and a 1.6% increase on the DiDeMo dataset.

</details>


### [42] [MS-CLR: Multi-Skeleton Contrastive Learning for Human Action Recognition](https://arxiv.org/abs/2508.14889)
*Mert Kiray,Alvaro Ritter,Nassir Navab,Benjamin Busam*

Main category: cs.CV

TL;DR: Proposes Multi-Skeleton Contrastive Learning (MS-CLR) to align pose representations across multiple skeleton conventions from the same sequence, improving generalization and setting SOTA on NTU RGB+D 60/120.


<details>
  <summary>Details</summary>
Motivation: Existing contrastive methods for skeleton-based action recognition use a single skeleton convention, limiting generalization across datasets with different joint layouts and anatomical coverage.

Method: Introduce MS-CLR: a self-supervised contrastive framework that aligns representations across multiple skeleton conventions extracted from the same sequence. Adapt ST-GCN to a unified representation to handle varying joint layouts and scales. Use multi-skeleton ensemble at inference.

Result: MS-CLR improves performance over strong single-skeleton contrastive baselines on NTU RGB+D 60 and 120. Multi-skeleton ensemble achieves new state-of-the-art on both datasets.

Conclusion: Aligning multiple skeleton conventions in contrastive learning yields more expressive, generalizable pose features; the approach is effective across standard skeleton action datasets.

Abstract: Contrastive learning has gained significant attention in skeleton-based
action recognition for its ability to learn robust representations from
unlabeled data. However, existing methods rely on a single skeleton convention,
which limits their ability to generalize across datasets with diverse joint
structures and anatomical coverage. We propose Multi-Skeleton Contrastive
Learning (MS-CLR), a general self-supervised framework that aligns pose
representations across multiple skeleton conventions extracted from the same
sequence. This encourages the model to learn structural invariances and capture
diverse anatomical cues, resulting in more expressive and generalizable
features. To support this, we adapt the ST-GCN architecture to handle skeletons
with varying joint layouts and scales through a unified representation scheme.
Experiments on the NTU RGB+D 60 and 120 datasets demonstrate that MS-CLR
consistently improves performance over strong single-skeleton contrastive
learning baselines. A multi-skeleton ensemble further boosts performance,
setting new state-of-the-art results on both datasets.

</details>


### [43] [Local Scale Equivariance with Latent Deep Equilibrium Canonicalizer](https://arxiv.org/abs/2508.14187)
*Md Ashiqur Rahman,Chiao-An Yang,Michael N. Cheng,Lim Jun Hao,Jeremiah Jiang,Teck-Yian Lim,Raymond A. Yeh*

Main category: cs.CV

TL;DR: Proposes Deep Equilibrium Canonicalizer (DEC) to improve local scale equivariance in vision models; can be integrated into existing architectures and pre-trained models; improves ImageNet performance and local scale consistency on ViT, DeiT, Swin, BEiT.


<details>
  <summary>Details</summary>
Motivation: Scale variation within images (objects of same class appearing at different sizes and distances) hurts model consistency and performance; local scale changes require models to be equivariant to local scaling.

Method: Introduce DEC, a deep equilibrium canonicalizer module that can be plugged into existing networks and applied to pre-trained models to enhance local scale equivariance.

Result: On ImageNet, integrating DEC into four popular pre-trained networks (ViT, DeiT, Swin, BEiT) improves both classification performance and local scale consistency.

Conclusion: DEC is an effective, easy-to-integrate method to boost local scale equivariance and performance in modern vision architectures; code is released.

Abstract: Scale variation is a fundamental challenge in computer vision. Objects of the
same class can have different sizes, and their perceived size is further
affected by the distance from the camera. These variations are local to the
objects, i.e., different object sizes may change differently within the same
image. To effectively handle scale variations, we present a deep equilibrium
canonicalizer (DEC) to improve the local scale equivariance of a model. DEC can
be easily incorporated into existing network architectures and can be adapted
to a pre-trained model. Notably, we show that on the competitive ImageNet
benchmark, DEC improves both model performance and local scale consistency
across four popular pre-trained deep-nets, e.g., ViT, DeiT, Swin, and BEiT. Our
code is available at https://github.com/ashiq24/local-scale-equivariance.

</details>


### [44] [TCFNet: Bidirectional face-bone transformation via a Transformer-based coarse-to-fine point movement network](https://arxiv.org/abs/2508.14373)
*Runshi Zhang,Bimeng Jie,Yang He,Junchen Wang*

Main category: cs.CV

TL;DR: 본 논문은 Transformer 기반의 coarse-to-fine 포인트 이동 네트워크(TCFNet)를 제안하여 얼굴-골격 포인트 클라우드 변환을 정확하게 수행한다.


<details>
  <summary>Details</summary>
Motivation: 전통적 생체역학 시뮬레이션은 계산 비용과 수작업 전처리/후처리, 낮은 정확도 문제가 있으며, 기존 딥러닝 기반 방법은 대규모 포인트를 처리하지 못하고 수용영역 제약으로 노이즈가 발생하며 복잡한 등록 기반 전후처리가 필요해 실용성이 떨어진다.

Method: TCFNet은 2단계로 구성된다. 1단계는 Transformer 기반 네트워크로 전역 특성 및 패치 수준 대응을 학습하고 2단계는 LIA-Net(Local Information Aggregation Network)로 국소 기하학 구조(엣지, 방향, 상대 위치)를 모델링해 국소 정밀도를 보완한다. 이전 전역 특성은 GRU로 로컬 변위 안내에 사용된다. 또한 변형 가능한 의료 영상 등록에서 영감을 받은 보조 손실을 도입해 의료 전문가 지식을 활용한 중요한 기관 재구성을 돕는다.

Result: 수집한 데이터셋에서 기존 SOTA 방법들과 비교해 TCFNet이 우수한 평가 지표와 가시화 결과를 보였다. 코드 공개.

Conclusion: Transformer와 로컬 정보 집계를 결합한 coarse-to-fine 구조와 전문가 지식을 활용한 보조 손실로 얼굴-골격 포인트 클라우드 변환 정확성을 크게 향상시켜 임상적 적용 가능성을 높였다.

Abstract: Computer-aided surgical simulation is a critical component of orthognathic
surgical planning, where accurately simulating face-bone shape transformations
is significant. The traditional biomechanical simulation methods are limited by
their computational time consumption levels, labor-intensive data processing
strategies and low accuracy. Recently, deep learning-based simulation methods
have been proposed to view this problem as a point-to-point transformation
between skeletal and facial point clouds. However, these approaches cannot
process large-scale points, have limited receptive fields that lead to noisy
points, and employ complex preprocessing and postprocessing operations based on
registration. These shortcomings limit the performance and widespread
applicability of such methods. Therefore, we propose a Transformer-based
coarse-to-fine point movement network (TCFNet) to learn unique, complicated
correspondences at the patch and point levels for dense face-bone point cloud
transformations. This end-to-end framework adopts a Transformer-based network
and a local information aggregation network (LIA-Net) in the first and second
stages, respectively, which reinforce each other to generate precise point
movement paths. LIA-Net can effectively compensate for the neighborhood
precision loss of the Transformer-based network by modeling local geometric
structures (edges, orientations and relative position features). The previous
global features are employed to guide the local displacement using a gated
recurrent unit. Inspired by deformable medical image registration, we propose
an auxiliary loss that can utilize expert knowledge for reconstructing critical
organs.Compared with the existing state-of-the-art (SOTA) methods on gathered
datasets, TCFNet achieves outstanding evaluation metrics and visualization
results. The code is available at https://github.com/Runshi-Zhang/TCFNet.

</details>


### [45] [QuadINR: Hardware-Efficient Implicit Neural Representations Through Quadratic Activation](https://arxiv.org/abs/2508.14374)
*Wenyong Zhou,Boyu Li,Jiachen Ren,Taiqiang Wu,Zhilin Ai,Zhengwu Liu,Ngai Wong*

Main category: cs.CV

TL;DR: QuadINR proposes piecewise quadratic activation functions for implicit neural representations to improve high-frequency expressivity while being hardware-efficient; demonstrates NTK analysis, an N-stage pipeline for hardware implementation, FPGA and ASIC realizations, and significant gains in PSNR, area, power, and latency on image/video tasks.


<details>
  <summary>Details</summary>
Motivation: Existing INRs suffer from spectral bias and prior fixes use complex activation functions that increase hardware cost; need a method that improves high-frequency representation while remaining resource- and power-efficient for practical deployment.

Method: Introduce QuadINR using piecewise quadratic activation functions with rich harmonic content; perform NTK analysis to justify expressivity; design a unified N-stage pipeline for efficient hardware implementation of various AFs; implement on FPGA (VCU128) and ASIC (28nm) to evaluate real hardware benefits.

Result: On image and video benchmarks, QuadINR yields up to 2.06 dB PSNR improvement over prior work; ASIC area of 1914 μm^2 and dynamic power 6.14 mW; achieves up to 97% reduction in resource and power consumption and up to 93% latency improvement compared to baselines.

Conclusion: Piecewise quadratic AFs provide a practical, hardware-efficient way to mitigate spectral bias in INRs, offering strong empirical performance and substantial hardware savings, making INRs more feasible for embedded/video applications.

Abstract: Implicit Neural Representations (INRs) encode discrete signals continuously
while addressing spectral bias through activation functions (AFs). Previous
approaches mitigate this bias by employing complex AFs, which often incur
significant hardware overhead. To tackle this challenge, we introduce QuadINR,
a hardware-efficient INR that utilizes piecewise quadratic AFs to achieve
superior performance with dramatic reductions in hardware consumption. The
quadratic functions encompass rich harmonic content in their Fourier series,
delivering enhanced expressivity for high-frequency signals, as verified
through Neural Tangent Kernel (NTK) analysis. We develop a unified $N$-stage
pipeline framework that facilitates efficient hardware implementation of
various AFs in INRs. We demonstrate FPGA implementations on the VCU128 platform
and an ASIC implementation in a 28nm process. Experiments across images and
videos show that QuadINR achieves up to 2.06dB PSNR improvement over prior
work, with an area of only 1914$\mu$m$^2$ and a dynamic power of 6.14mW,
reducing resource and power consumption by up to 97\% and improving latency by
up to 93\% vs existing baselines.

</details>


### [46] [HyperDiff: Hypergraph Guided Diffusion Model for 3D Human Pose Estimation](https://arxiv.org/abs/2508.14431)
*Bing Han,Yuhua Huang,Pan Gao*

Main category: cs.CV

TL;DR: 이 논문은 확산 모델과 HyperGCN을 결합한 HyperDiff를 제시해 단일 카메라 3D 인간 자세 추정의 깊이 모호성·가림 문제를 완화하고 멀티-스케일 골격 특징을 활용해 고차 상관관계를 모델링함으로써 Human3.6M과 MPI-INF-3DHP에서 SOTA 성능을 달성한다고 주장한다.


<details>
  <summary>Details</summary>
Motivation: 단일 뷰 2D→3D 리프팅에서 깊이 모호성과 가림(occlusion) 문제 및 전통적 방법들이 멀티-스케일 골격 정보를 충분히 활용하지 못해 정확도 저하를 유발하는 문제를 해결하기 위함.

Method: 확산 모델을 통해 데이터 불확실성을 포착하여 깊이 모호성과 가림 문제를 완화하고, HyperGCN을 디노이저로 사용해 멀티-그래뉼러리(다중해상도) 구조로 관절 간의 고차 상관관계를 정확히 모델링하여 디노이징 성능을 향상시킴. 계산 자원에 따라 유연하게 성능·효율 균형 조절 가능.

Result: Human3.6M 및 MPI-INF-3DHP 데이터셋에서 SOTA 성능을 달성했다고 보고. 또한 계산 자원에 맞춰 성능과 효율을 조절할 수 있음을 언급.

Conclusion: 확산 모델과 HyperGCN의 결합으로 단안 3D HPE에서 깊이 모호성·가림 문제와 멀티-스케일 골격 특징 미반영 문제를 효과적으로 완화하여 성능 개선을 이룸.

Abstract: Monocular 3D human pose estimation (HPE) often encounters challenges such as
depth ambiguity and occlusion during the 2D-to-3D lifting process.
Additionally, traditional methods may overlook multi-scale skeleton features
when utilizing skeleton structure information, which can negatively impact the
accuracy of pose estimation. To address these challenges, this paper introduces
a novel 3D pose estimation method, HyperDiff, which integrates diffusion models
with HyperGCN. The diffusion model effectively captures data uncertainty,
alleviating depth ambiguity and occlusion. Meanwhile, HyperGCN, serving as a
denoiser, employs multi-granularity structures to accurately model high-order
correlations between joints. This improves the model's denoising capability
especially for complex poses. Experimental results demonstrate that HyperDiff
achieves state-of-the-art performance on the Human3.6M and MPI-INF-3DHP
datasets and can flexibly adapt to varying computational resources to balance
performance and efficiency.

</details>


### [47] [FOCUS: Frequency-Optimized Conditioning of DiffUSion Models for mitigating catastrophic forgetting during Test-Time Adaptation](https://arxiv.org/abs/2508.14437)
*Gabriel Tjio,Jie Zhang,Xulei Yang,Yun Xing,Nhat Chung,Xiaofeng Cao,Ivor W. Tsang,Chee Keong Kwoh,Qing Guo*

Main category: cs.CV

TL;DR: 이 논문은 테스트 시점 적응(Test-time adaptation)에서 도메인 변화에 적응하면서도 중요한 태스크 지식을 유지하기 위해, 확산 기반(denoising diffusion) 입력 적응 프레임워크 내에서 주파수 기반 조건화(FOCUS)를 제안한다. Y자 형태의 경량 Frequency Prediction Network(Y-FPN)과 주파수 혼합 데이터 증강(FrequencyMix)을 사용해 고·저주파 정보를 분리·보존하고, 세그멘테이션 및 단안 깊이 추정에서 SOTA 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 도메인 변화에 적응하려다 기존의 태스크 관련 지식이 망각되어 성능이 저하되는 문제를 해결하고자 함. 테스트 시점에서 입력을 조정해 도메인 적응과 지식 보존을 동시에 달성하려 함.

Method: 확산 기반 역노이즈화(reverse denoising) 과정에서 학습된 공간적 적응 주파수 프라이어를 조건으로 사용해 의미적 정보 보존을 유도. 경량 Y자 Frequency Prediction Network(Y-FPN)로 노이즈 이미지에서 고·저주파를 분리하고, FrequencyMix라는 주파수 대역 교란 증강 기법으로 Y-FPN을 학습시킴. FOCUS로 복원한 이미지에서 pseudo label을 추출해 기존 적응 방법을 보완 가능.

Result: Semantic segmentation과 monocular depth estimation에서 15종의 오염(corruption)과 3개 데이터셋에 대해 평균적으로 SOTA 성능을 달성. FOCUS 기반의 의사라벨로 제한적·간헐적 감독 하에서도 catastrophic forgetting을 완화함.

Conclusion: 주파수 기반 조건화를 통해 확산 기반 입력 적응이 도메인 적응 시 태스크 관련 정보를 보존하도록 개선되며, 기존 모델적응 기법들과 상호보완적으로 활용 가능하다.

Abstract: Test-time adaptation enables models to adapt to evolving domains. However,
balancing the tradeoff between preserving knowledge and adapting to domain
shifts remains challenging for model adaptation methods, since adapting to
domain shifts can induce forgetting of task-relevant knowledge. To address this
problem, we propose FOCUS, a novel frequency-based conditioning approach within
a diffusion-driven input-adaptation framework. Utilising learned, spatially
adaptive frequency priors, our approach conditions the reverse steps during
diffusion-driven denoising to preserve task-relevant semantic information for
dense prediction.
  FOCUS leverages a trained, lightweight, Y-shaped Frequency Prediction Network
(Y-FPN) that disentangles high and low frequency information from noisy images.
This minimizes the computational costs involved in implementing our approach in
a diffusion-driven framework. We train Y-FPN with FrequencyMix, a novel data
augmentation method that perturbs the images across diverse frequency bands,
which improves the robustness of our approach to diverse corruptions.
  We demonstrate the effectiveness of FOCUS for semantic segmentation and
monocular depth estimation across 15 corruption types and three datasets,
achieving state-of-the-art averaged performance. In addition to improving
standalone performance, FOCUS complements existing model adaptation methods
since we can derive pseudo labels from FOCUS-denoised images for additional
supervision. Even under limited, intermittent supervision with the pseudo
labels derived from the FOCUS denoised images, we show that FOCUS mitigates
catastrophic forgetting for recent model adaptation methods.

</details>


### [48] [Reconstruction Using the Invisible: Intuition from NIR and Metadata for Enhanced 3D Gaussian Splatting](https://arxiv.org/abs/2508.14443)
*Gyusam Chang,Tuan-Anh Vu,Vivek Alumootil,Harris Song,Deanna Pham,Sangpil Kim,M. Khalid Jawed*

Main category: cs.CV

TL;DR: NIRPlant은 NIR, RGB, 텍스트 메타데이터, Depth, LiDAR를 포함한 농업 멀티모달 데이터셋이며, NIRSplat은 교차-어텐션과 3D 포인트 기반 위치 인코딩을 사용하는 멀티모달 Gaussian splatting 아키텍처로 기존 3D 재구성 기법들을 능가한다.


<details>
  <summary>Details</summary>
Motivation: 농업 장면은 조명 불균형, 가림(occlusion), 제한된 시야 등으로 3D 재구성에 어려움이 있어, 가시광선 밖 정보를 포함한 멀티모달 데이터와 새로운 모델 설계가 필요하다.

Method: Near-Infrared(NIR) 데이터와 텍스트 형태의 식생지수(예: NDVI, NDWI, chlorophyll index)를 포함하는 NIRPlant 데이터셋을 구축하고, 교차-어텐션과 3D 포인트 기반 위치 인코딩을 결합한 NIRSplat 멀티모달 Gaussian splatting 아키텍처를 제안했다.

Result: 다양한 실내·야외 조명 조건에서 수행한 실험에서 NIRSplat은 기존의 3DGS, CoR-GS, InstantSplat 등을 능가하는 성능을 보였으며, 데이터와 코드가 공개되었다.

Conclusion: NIR 및 텍스트 기반 식생 지수를 포함한 멀티모달 접근과 제안된 NIRSplat 구조는 농업 환경에서의 3D 재구성 품질과 강건성을 유의미하게 향상시킨다.

Abstract: While 3D Gaussian Splatting (3DGS) has rapidly advanced, its application in
agriculture remains underexplored. Agricultural scenes present unique
challenges for 3D reconstruction methods, particularly due to uneven
illumination, occlusions, and a limited field of view. To address these
limitations, we introduce \textbf{NIRPlant}, a novel multimodal dataset
encompassing Near-Infrared (NIR) imagery, RGB imagery, textual metadata, Depth,
and LiDAR data collected under varied indoor and outdoor lighting conditions.
By integrating NIR data, our approach enhances robustness and provides crucial
botanical insights that extend beyond the visible spectrum. Additionally, we
leverage text-based metadata derived from vegetation indices, such as NDVI,
NDWI, and the chlorophyll index, which significantly enriches the contextual
understanding of complex agricultural environments. To fully exploit these
modalities, we propose \textbf{NIRSplat}, an effective multimodal Gaussian
splatting architecture employing a cross-attention mechanism combined with 3D
point-based positional encoding, providing robust geometric priors.
Comprehensive experiments demonstrate that \textbf{NIRSplat} outperforms
existing landmark methods, including 3DGS, CoR-GS, and InstantSplat,
highlighting its effectiveness in challenging agricultural scenarios. The code
and dataset are publicly available at:
https://github.com/StructuresComp/3D-Reconstruction-NIR

</details>


### [49] [TransLight: Image-Guided Customized Lighting Control with Generative Decoupling](https://arxiv.org/abs/2508.14814)
*Zongming Li,Lianghui Zhu,Haocheng Shen,Longjin Ran,Wenyu Liu,Xinggang Wang*

Main category: cs.CV

TL;DR: TransLight는 참조 이미지의 복잡한 조명 효과를 대상 이미지로 고충실도·고자유도로 전송하는 프레임워크로, 생성적 분리(Generative Decoupling)를 통해 조명과 콘텐츠를 분리하고, 이를 이용해 IC-Light 기반 모델을 학습해 맞춤형 조명 전송을 가능하게 한다.


<details>
  <summary>Details</summary>
Motivation: 기존 조명 편집 기법들은 조명 효과의 맞춤형 제어와 콘텐츠 보존을 동시에 만족하지 못하며, 특히 참조 이미지의 복잡한 조명 효과를 다른 이미지에 자연스럽게 전이하는 작업에서 한계가 있다.

Method: 두 개의 파인튜닝된 확산 모델을 이용한 '생성적 분리'로 이미지의 콘텐츠와 조명 효과를 정확히 분리하여 이미지-콘텐츠-조명 삼중 데이터(백만 규모)를 생성한다. 이후 IC-Light을 생성 모델로 사용해 이 삼중 데이터로 모델을 학습하고, 참조 조명 이미지를 추가 조건(signal)으로 주입하여 조명 전송을 수행한다.

Result: TransLight는 서로 다른 이미지 간에도 조명 효과를 성공적으로 전이하며, 기존 기법보다 더 세밀하고 사용자 맞춤형 조명 제어를 제공한다는 실험적 증거를 제시한다.

Conclusion: 조명과 콘텐츠의 철저한 분리를 통한 생성적 분리 전략이 고유한 조명 제어 능력을 부여하며, 조명 조화(illumination harmonization)와 조명 편집 연구에 새로운 방향을 제시한다.

Abstract: Most existing illumination-editing approaches fail to simultaneously provide
customized control of light effects and preserve content integrity. This makes
them less effective for practical lighting stylization requirements, especially
in the challenging task of transferring complex light effects from a reference
image to a user-specified target image. To address this problem, we propose
TransLight, a novel framework that enables high-fidelity and high-freedom
transfer of light effects. Extracting the light effect from the reference image
is the most critical and challenging step in our method. The difficulty lies in
the complex geometric structure features embedded in light effects that are
highly coupled with content in real-world scenarios. To achieve this, we first
present Generative Decoupling, where two fine-tuned diffusion models are used
to accurately separate image content and light effects, generating a newly
curated, million-scale dataset of image-content-light triplets. Then, we employ
IC-Light as the generative model and train our model with our triplets,
injecting the reference lighting image as an additional conditioning signal.
The resulting TransLight model enables customized and natural transfer of
diverse light effects. Notably, by thoroughly disentangling light effects from
reference images, our generative decoupling strategy endows TransLight with
highly flexible illumination control. Experimental results establish TransLight
as the first method to successfully transfer light effects across disparate
images, delivering more customized illumination control than existing
techniques and charting new directions for research in illumination
harmonization and editing.

</details>


### [50] [Locality-aware Concept Bottleneck Model](https://arxiv.org/abs/2508.14562)
*Sujin Jeon,Hyundo Lee,Eungseo Kim,Sanghack Lee,Byoung-Tak Zhang,Inwoo Hwang*

Main category: cs.CV

TL;DR: LCBM은 foundation models의 정보를 활용하고 프로토타입 학습을 도입해 각 개념의 공간적 위치(locality)를 정확히 파악하도록 하는 개념 병목 모델. 프로토타입 하나를 개념당 할당하고 관련 로컬 특징을 인코딩하도록 학습하여 개념 존재 예측과 더불어 개선된 지역화 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 인간이 이해 가능한 시각적 개념(Concept)을 기반으로 예측하는 개념 병목 모델(CBM)은 해석성이 뛰어나지만, 밀도 높은 개념 라벨을 수작업으로 얻는 것은 비용이 크다. 라벨 없는 CBM들은 foundation models를 이용해 개념을 추정하더라도, 종종 관련 없는 이미지 영역을 참조해 개념을 잘못 지역화하는 문제가 있다.

Method: Locality-aware Concept Bottleneck Model(LCBM)을 제안. 각 개념에 하나의 프로토타입을 배정하고, 이 프로토타입이 해당 개념의 전형적 이미지 특징을 대표하도록 학습한다. 학습 과정에서 foundation models가 제공하는 정보를 활용해 프로토타입이 관련 로컬 영역과 유사성을 갖도록 유도하고, 이를 통해 각 개념을 예측할 적절한 로컬 영역을 식별하도록 한다.

Result: 실험에서 LCBM은 이미지 내 존재하는 개념을 효과적으로 식별하며, 지역화(localization) 성능이 향상되었음. 분류(개념 예측) 성능은 유지하면서 더 정확한 공간적 근거를 제공함을 보였다.

Conclusion: LCBM은 라벨 없는 CBM의 약점인 잘못된 지역화 문제를 foundation models와 프로토타입 기반 학습으로 개선하여, 해석 가능성을 유지하면서 지역화 성능을 향상시킨다.

Abstract: Concept bottleneck models (CBMs) are inherently interpretable models that
make predictions based on human-understandable visual cues, referred to as
concepts. As obtaining dense concept annotations with human labeling is
demanding and costly, recent approaches utilize foundation models to determine
the concepts existing in the images. However, such label-free CBMs often fail
to localize concepts in relevant regions, attending to visually unrelated
regions when predicting concept presence. To this end, we propose a framework,
coined Locality-aware Concept Bottleneck Model (LCBM), which utilizes rich
information from foundation models and adopts prototype learning to ensure
accurate spatial localization of the concepts. Specifically, we assign one
prototype to each concept, promoted to represent a prototypical image feature
of that concept. These prototypes are learned by encouraging them to encode
similar local regions, leveraging foundation models to assure the relevance of
each prototype to its associated concept. Then we use the prototypes to
facilitate the learning process of identifying the proper local region from
which each concept should be predicted. Experimental results demonstrate that
LCBM effectively identifies present concepts in the images and exhibits
improved localization while maintaining comparable classification performance.

</details>


### [51] [GOGS: High-Fidelity Geometry and Relighting for Glossy Objects via Gaussian Surfels](https://arxiv.org/abs/2508.14563)
*Xingyuan Yang,Min Wei*

Main category: cs.CV

TL;DR: GOGS는 2단계 2D Gaussian surfel 기반 프레임워크로, 물리 기반 렌더링과 기하학적 프라이어(파운데이션 모델 활용)를 통해 반사체의 표면을 견고하게 복원하고, 몬테카를로 중요도 샘플링과 미분 가능한 2D Gaussian 레이 트레이싱으로 재료 분해 및 실시간에 가까운 리라이팅을 달성한다.


<details>
  <summary>Details</summary>
Motivation: 광택 물체의 RGB 이미지만으로 역렌더링할 때 본질적 모호성과 NeRF 계열의 높은 계산 비용, 3D Gaussian Splatting의 반사 문제로 인한 표면 노이즈 및 재질 표현 한계를 해결하려 함.

Method: 두 단계: (1) split-sum 근사를 사용하는 물리 기반 렌더링과 파운데이션 모델로부터의 기하학적 프라이어를 결합해 견고한 표면 복원; (2) 전체 렌더링 방정식의 몬테카를로 중요도 샘플링으로 재료 분해, 미분 가능한 2D Gaussian 레이 트레이싱으로 간접광 모델링, 구면 mipmap 기반 방향 인코딩으로 고주파 스페큘러 디테일 정제.

Result: 기하 복원, 재질 분해, 새로운 조명에서의 포토리얼리스틱 리라이팅 분야에서 기존 역렌더링 방법들을 능가하는 성능을 보임.

Conclusion: GOGS는 2D Gaussian surfel과 물리 기반 렌더링 기법, 파운데이션 모델 프라이어의 결합으로 광택 객체의 효율적이고 정확한 역렌더링을 실현하며, 스페큘러와 간접광을 효과적으로 처리해 재조명 품질을 향상시킴.

Abstract: Inverse rendering of glossy objects from RGB imagery remains fundamentally
limited by inherent ambiguity. Although NeRF-based methods achieve
high-fidelity reconstruction via dense-ray sampling, their computational cost
is prohibitive. Recent 3D Gaussian Splatting achieves high reconstruction
efficiency but exhibits limitations under specular reflections. Multi-view
inconsistencies introduce high-frequency surface noise and structural
artifacts, while simplified rendering equations obscure material properties,
leading to implausible relighting results. To address these issues, we propose
GOGS, a novel two-stage framework based on 2D Gaussian surfels. First, we
establish robust surface reconstruction through physics-based rendering with
split-sum approximation, enhanced by geometric priors from foundation models.
Second, we perform material decomposition by leveraging Monte Carlo importance
sampling of the full rendering equation, modeling indirect illumination via
differentiable 2D Gaussian ray tracing and refining high-frequency specular
details through spherical mipmap-based directional encoding that captures
anisotropic highlights. Extensive experiments demonstrate state-of-the-art
performance in geometry reconstruction, material separation, and photorealistic
relighting under novel illuminations, outperforming existing inverse rendering
approaches.

</details>


### [52] [GeMS: Efficient Gaussian Splatting for Extreme Motion Blur](https://arxiv.org/abs/2508.14682)
*Gopi Raju Matta,Trisha Reddypalli,Vemunuri Divya Madhuri,Kaushik Mitra*

Main category: cs.CV

TL;DR: GeMS는 심하게 모션 블러된 이미지로부터 직접 3D Gaussian Splatting(3DGS) 구성을 수행하는 프레임워크로, 블러 전용 SfM(VGGSfM), 확률적 가우시안 초기화(3DGS-MCMC), 카메라 경로와 가우시안의 공동 최적화, 그리고 이벤트 기반 EDI 정제를 결합하여 극심한 블러에서도 안정적 재구성을 달성한다.


<details>
  <summary>Details</summary>
Motivation: 기존 극심한 블러 처리 및 3DGS 기반 방법들은 카메라 자세 추정이나 포인트클라우드 생성을 위해 선명한 입력을 필요로 하거나 COLMAP 같은 기존 SfM에 의존하는데, 심한 블러에서는 특징 대응이 불안정하여 실패한다. 이를 해소해 실제 블러 영상에서 직접 3D 재구성을 가능하게 하는 방법이 필요하다.

Method: (1) VGGSfM: 심하게 블러된 입력에서 직접 자세와 포인트클라우드를 추정하는 딥러닝 기반 SfM 파이프라인. (2) 3DGS-MCMC: 가우시안을 확률 분포 샘플로 간주하여 초기화를 안정화하고 휴리스틱한 조밀화/가지치기 제거. (3) 카메라 궤적과 가우시안 파라미터의 공동 최적화로 재구성 안정성 향상. (4) GeMS-E: 이벤트 기반 EDI(deblurring)를 통한 점진적 정제 단계로 더 선명한 이미지 생성 후 파이프라인에 재투입하여 성능 향상.

Result: 합성 및 실제 데이터셋에서 SOTA 성능을 달성했으며, 심하게 블러된 입력만으로도 3DGS 재구성이 가능함을 보였다. GeMS-E는 이벤트 데이터 통합으로 자세 추정·포인트클라우드 생성·전반적 재구성을 추가 개선한다.

Conclusion: 심한 모션 블러 상태에서 직접 3D Gaussian Splatting을 수행하는 최초의 프레임워크로서, 블러 전용 SfM과 확률적 초기화, 이벤트 기반 정제를 결합해 기존 방법들이 실패하던 상황에서 안정적 재구성을 제공한다.

Abstract: We introduce GeMS, a framework for 3D Gaussian Splatting (3DGS) designed to
handle severely motion-blurred images. State-of-the-art deblurring methods for
extreme blur, such as ExBluRF, as well as Gaussian Splatting-based approaches
like Deblur-GS, typically assume access to sharp images for camera pose
estimation and point cloud generation, an unrealistic assumption. Methods
relying on COLMAP initialization, such as BAD-Gaussians, also fail due to
unreliable feature correspondences under severe blur. To address these
challenges, we propose GeMS, a 3DGS framework that reconstructs scenes directly
from extremely blurred images. GeMS integrates: (1) VGGSfM, a deep
learning-based Structure-from-Motion pipeline that estimates poses and
generates point clouds directly from blurred inputs; (2) 3DGS-MCMC, which
enables robust scene initialization by treating Gaussians as samples from a
probability distribution, eliminating heuristic densification and pruning; and
(3) joint optimization of camera trajectories and Gaussian parameters for
stable reconstruction. While this pipeline produces strong results,
inaccuracies may remain when all inputs are severely blurred. To mitigate this,
we propose GeMS-E, which integrates a progressive refinement step using events:
(4) Event-based Double Integral (EDI) deblurring restores sharper images that
are then fed into GeMS, improving pose estimation, point cloud generation, and
overall reconstruction. Both GeMS and GeMS-E achieve state-of-the-art
performance on synthetic and real-world datasets. To our knowledge, this is the
first framework to address extreme motion blur within 3DGS directly from
severely blurred inputs.

</details>


### [53] [GSFix3D: Diffusion-Guided Repair of Novel Views in Gaussian Splatting](https://arxiv.org/abs/2508.14717)
*Jiaxin Wei,Stefan Leutenegger,Simon Schaefer*

Main category: cs.CV

TL;DR: GSFix3D는 3D Gaussian Splatting으로 생성된 장면의 미관정(under-constrained) 영역을 개선하기 위해, diffusion 모델의 사전지식을 3D 표현으로 증류하는 프레임워크다. GSFixer라는 latent diffusion 모델을 장면 특화 미세조정으로 얻어 mesh와 3D Gaussian을 활용해 보이지 않는 관점에서의 복원과 인페인팅을 수행한다.


<details>
  <summary>Details</summary>
Motivation: 3D Gaussian Splatting은 새로운 시점 합성에서 성능이 좋지만, 극단적 신규 시점이나 부분적으로 관찰된 영역에서 고품질 렌더링을 생성하기 어렵다. 반면 diffusion 모델은 강력한 생성 능력이 있으나 특정 장면 정보를 반영한 3D 재구성에는 한계가 있다.

Method: GSFix3D는 사전학습된 diffusion 모델을 장면-일관성 유지와 시각 품질 향상을 위해 미세조정하는 GSFixer를 도입한다. GSFixer는 mesh와 3D Gaussian을 모두 활용하도록 맞춤 미세조정 프로토콜을 적용하며, 무작위 마스크 증강 전략으로 결손 영역의 인페인팅 역량을 강화한다.

Result: 벤치마크 실험에서 GSFix3D와 GSFixer는 최소한의 장면 특화 미세조정만으로 최첨단 성능을 달성했으며, 실제 데이터 테스트에서도 포즈 오차에 대해 강건함을 보였다.

Conclusion: 제안한 방법은 diffusion 기반 사전지식을 3D 표현으로 효과적으로 통합하여 관찰이 부족한 영역의 시각적 충실도를 개선하고, 다양한 재구성 방법에서 발생하는 아티팩트에 대해 견고한 복원을 가능하게 한다.

Abstract: Recent developments in 3D Gaussian Splatting have significantly enhanced
novel view synthesis, yet generating high-quality renderings from extreme novel
viewpoints or partially observed regions remains challenging. Meanwhile,
diffusion models exhibit strong generative capabilities, but their reliance on
text prompts and lack of awareness of specific scene information hinder
accurate 3D reconstruction tasks. To address these limitations, we introduce
GSFix3D, a novel framework that improves the visual fidelity in
under-constrained regions by distilling prior knowledge from diffusion models
into 3D representations, while preserving consistency with observed scene
details. At its core is GSFixer, a latent diffusion model obtained via our
customized fine-tuning protocol that can leverage both mesh and 3D Gaussians to
adapt pretrained generative models to a variety of environments and artifact
types from different reconstruction methods, enabling robust novel view repair
for unseen camera poses. Moreover, we propose a random mask augmentation
strategy that empowers GSFixer to plausibly inpaint missing regions.
Experiments on challenging benchmarks demonstrate that our GSFix3D and GSFixer
achieve state-of-the-art performance, requiring only minimal scene-specific
fine-tuning on captured data. Real-world test further confirms its resilience
to potential pose errors. Our code and data will be made publicly available.
Project page: https://gsfix3d.github.io.

</details>


### [54] [Fusing Monocular RGB Images with AIS Data to Create a 6D Pose Estimation Dataset for Marine Vessels](https://arxiv.org/abs/2508.14767)
*Fabian Holst,Emre Gülsoylu,Simone Frintrop*

Main category: cs.CV

TL;DR: 본 논문은 단안 RGB 이미지와 AIS(자동식별시스템) 데이터를 융합해 선박의 6D 포즈(3D 위치 + 회전)를 자동으로 생성하는 데이터셋 생성 기법과 공개 데이터셋(BONK-pose)을 제안한다.


<details>
  <summary>Details</summary>
Motivation: AIS만으로 위치/자세 정보를 얻을 때 장비 신뢰성, 데이터 위조, 전송 지연 등으로 인한 한계가 존재하므로, 이미지 기반 선박 검출과 AIS를 결합해 수동 주석 없이 정확한 6D 포즈 데이터를 만들고자 함.

Method: YOLOX-X 등 객체 검출 네트워크로 단안 RGB 이미지에서 선박을 검출하고, AIS 메시지와의 정합을 위해 호모그래피와 PnP(포인트 집합 대응 기반) 두 가지 변환 방식을 비교하여 이미지 좌표계와 AIS 좌표를 정렬함. 3D 바운딩 박스를 생성해 6D 포즈 라벨을 자동으로 산출.

Result: PnP 방법이 호모그래피 기반 접근보다 투영 오류가 현저히 낮았고, YOLOX-X는 관련 선박 클래스에 대해 IoU 0.5에서 mAP 0.80을 달성함. 수동 주석이 필요 없는 6D 포즈 데이터셋 생성이 가능함을 보여줌.

Conclusion: 단안 이미지와 AIS 데이터 융합을 통해 대규모 6D 포즈 추정용 라벨을 자동 생성할 수 있으며, BONK-pose(3753장 3D 바운딩 박스, 추가 1000장 2D 바운딩 박스)라는 공개 데이터셋을 제공하여 6D 포즈 네트워크의 학습·평가에 기여함.

Abstract: The paper presents a novel technique for creating a 6D pose estimation
dataset for marine vessels by fusing monocular RGB images with Automatic
Identification System (AIS) data. The proposed technique addresses the
limitations of relying purely on AIS for location information, caused by issues
like equipment reliability, data manipulation, and transmission delays. By
combining vessel detections from monocular RGB images, obtained using an object
detection network (YOLOX-X), with AIS messages, the technique generates 3D
bounding boxes that represent the vessels' 6D poses, i.e. spatial and
rotational dimensions. The paper evaluates different object detection models to
locate vessels in image space. We also compare two transformation methods
(homography and Perspective-n-Point) for aligning AIS data with image
coordinates. The results of our work demonstrate that the Perspective-n-Point
(PnP) method achieves a significantly lower projection error compared to
homography-based approaches used before, and the YOLOX-X model achieves a mean
Average Precision (mAP) of 0.80 at an Intersection over Union (IoU) threshold
of 0.5 for relevant vessel classes. We show indication that our approach allows
the creation of a 6D pose estimation dataset without needing manual annotation.
Additionally, we introduce the Boats on Nordelbe Kehrwieder (BONK-pose), a
publicly available dataset comprising 3753 images with 3D bounding box
annotations for pose estimation, created by our data fusion approach. This
dataset can be used for training and evaluating 6D pose estimation networks. In
addition we introduce a set of 1000 images with 2D bounding box annotations for
ship detection from the same scene.

</details>


### [55] [6-DoF Object Tracking with Event-based Optical Flow and Frames](https://arxiv.org/abs/2508.14776)
*Zhichao Li,Arren Glover,Chiara Bartolozzi,Lorenzo Natale*

Main category: cs.CV

TL;DR: Combine event-camera optical flow with an RGB global pose estimator to track 6-DoF object pose at high speeds: event-based optical flow yields a 6-DoF velocity tracker that is integrated with low-frequency RGB pose estimates for continuous high-speed tracking; validated on synthetic and real data.


<details>
  <summary>Details</summary>
Motivation: High-speed object pose tracking is limited by frame rates and motion blur in conventional RGB cameras. Event cameras offer high temporal resolution and low latency that can address these limitations, while RGB provides rich visual information for accurate pose estimation. Combining both can exploit complementary strengths.

Method: Develop an event-based optical flow algorithm to measure object motion and produce a 6-DoF velocity tracker. Fuse the high-frequency velocity updates from events with low-frequency 6-DoF poses from an RGB-based global pose estimator to maintain continuous pose tracking during high-speed motion.

Result: Validated on synthetic and real-world datasets; demonstrates effective 6-DoF pose tracking especially in high-speed scenarios where RGB-only methods degrade. Shows robustness to motion blur and improved temporal continuity of pose estimates (abstract lacks detailed quantitative metrics).

Conclusion: Fusing event-camera motion cues (via optical flow) with RGB-based global pose estimation enables robust real-time 6-DoF tracking for fast-moving objects, leveraging complementary sensor advantages.

Abstract: Tracking the position and orientation of objects in space (i.e., in 6-DoF) in
real time is a fundamental problem in robotics for environment interaction. It
becomes more challenging when objects move at high-speed due to frame rate
limitations in conventional cameras and motion blur. Event cameras are
characterized by high temporal resolution, low latency and high dynamic range,
that can potentially overcome the impacts of motion blur. Traditional RGB
cameras provide rich visual information that is more suitable for the
challenging task of single-shot object pose estimation. In this work, we
propose using event-based optical flow combined with an RGB based global object
pose estimator for 6-DoF pose tracking of objects at high-speed, exploiting the
core advantages of both types of vision sensors. Specifically, we propose an
event-based optical flow algorithm for object motion measurement to implement
an object 6-DoF velocity tracker. By integrating the tracked object 6-DoF
velocity with low frequency estimated pose from the global pose estimator, the
method can track pose when objects move at high-speed. The proposed algorithm
is tested and validated on both synthetic and real world data, demonstrating
its effectiveness, especially in high-speed motion scenarios.

</details>


### [56] [EventSSEG: Event-driven Self-Supervised Segmentation with Probabilistic Attention](https://arxiv.org/abs/2508.14856)
*Lakshmi Annamalai,Chetan Singh Thakur*

Main category: cs.CV

TL;DR: 이 논문은 이벤트 카메라만을 사용해 저지연·저연산으로 도로 분할을 수행하는 EventSSEG을 제안한다. 이벤트 기반의 자기지도 학습과 확률적 어텐션을 도입해 라벨이 거의 없는 상황에서도 SOTA 성능을 달성한다.


<details>
  <summary>Details</summary>
Motivation: 프레임 기반 카메라로는 자율주행에서 저지연·저연산을 동시에 만족하기 어렵고, 이벤트 카메라가 유망하지만 이벤트 도메인으로의 사전학습 전이와 라벨 부족 문제가 존재한다.

Method: 이벤트 전용 계산을 수행하는 EventSSEG을 제안한다. 확률적 어텐션 메커니즘을 사용하고, 라벨이 적은 상황을 극복하기 위해 이벤트 기반 자기지도 학습을 적용하여 대량의 라벨 데이터를 필요로 하지 않는다.

Result: DSEC-Semantic과 DDD17 데이터셋에서 소량의 라벨만으로 SOTA 성능을 달성했다는 결과를 보고한다.

Conclusion: 이 접근법은 이벤트 카메라의 장점을 극대화하고 라벨 부족 문제를 완화하여 이벤트 전용 도로 분할에 실용적인 해법을 제시한다.

Abstract: Road segmentation is pivotal for autonomous vehicles, yet achieving low
latency and low compute solutions using frame based cameras remains a
challenge. Event cameras offer a promising alternative. To leverage their low
power sensing, we introduce EventSSEG, a method for road segmentation that uses
event only computing and a probabilistic attention mechanism. Event only
computing poses a challenge in transferring pretrained weights from the
conventional camera domain, requiring abundant labeled data, which is scarce.
To overcome this, EventSSEG employs event-based self supervised learning,
eliminating the need for extensive labeled data. Experiments on DSEC-Semantic
and DDD17 show that EventSSEG achieves state of the art performance with
minimal labeled events. This approach maximizes event cameras capabilities and
addresses the lack of labeled events.

</details>


### [57] [GaussianArt: Unified Modeling of Geometry and Motion for Articulated Objects](https://arxiv.org/abs/2508.14891)
*Licheng Shen,Saining Zhang,Honghan Li,Peilin Yang,Zihao Huang,Zongzheng Zhang,Hao Zhao*

Main category: cs.CV

TL;DR: Unified representation using articulated 3D Gaussians jointly models geometry and motion for reconstructing articulated objects, scales to ~20 parts, and is evaluated on a new MPArt-90 benchmark showing superior part-level geometry and motion estimation and applicability to robotics and human-scene interaction.


<details>
  <summary>Details</summary>
Motivation: 기존 방법들은 물체 형태와 동작을 분리하여(서로 다른 상태에서 형태 복원 후 정렬) 파이프라인이 복잡하고 초기화에 취약해 복잡한 다중 부품 관절을 다루기 어렵다. 더 확장 가능하고 견고한 통합 표현이 필요하다.

Method: 형태와 동작을 동시에 모델링하는 관절화된(articulated) 3D Gaussian 표현을 제안하여 모션 분해의 강건성을 개선하고 최대 약 20개 부품을 지원한다. 또한 다양한 부품 수와 동작 구성을 포함한 MPArt-90 벤치마크를 제시하여 확장성과 일반화 성능을 체계적으로 평가한다.

Result: 제안 방법은 부품 수준의 기하학 복원 및 모션 추정에서 기존 접근들을 일관되게 능가하며, 특히 2–3부품 이상일 때 기존 방법들이 실패하는 상황에서도 우수한 성능을 보인다. 또한 로봇 시뮬레이션 및 인간-장면 상호작용 모델링 같은 다운스트림 작업에 적용 가능함을 보였다.

Conclusion: 형태와 동작을 통합하여 표현하는 접근은 관절화된 물체의 확장 가능한 물리 모델링에 유리하며, 복잡한 다중 부품 관절을 보다 견고하게 복원하고 다양한 응용에 활용될 수 있다.

Abstract: Reconstructing articulated objects is essential for building digital twins of
interactive environments. However, prior methods typically decouple geometry
and motion by first reconstructing object shape in distinct states and then
estimating articulation through post-hoc alignment. This separation complicates
the reconstruction pipeline and restricts scalability, especially for objects
with complex, multi-part articulation. We introduce a unified representation
that jointly models geometry and motion using articulated 3D Gaussians. This
formulation improves robustness in motion decomposition and supports
articulated objects with up to 20 parts, significantly outperforming prior
approaches that often struggle beyond 2--3 parts due to brittle initialization.
To systematically assess scalability and generalization, we propose MPArt-90, a
new benchmark consisting of 90 articulated objects across 20 categories, each
with diverse part counts and motion configurations. Extensive experiments show
that our method consistently achieves superior accuracy in part-level geometry
reconstruction and motion estimation across a broad range of object types. We
further demonstrate applicability to downstream tasks such as robotic
simulation and human-scene interaction modeling, highlighting the potential of
unified articulated representations in scalable physical modeling.

</details>


### [58] [SMTrack: End-to-End Trained Spiking Neural Networks for Multi-Object Tracking in RGB Videos](https://arxiv.org/abs/2508.14607)
*Pengzhi Zhong,Xinzhe Wang,Dan Zeng,Qihua Zhou,Feixiang He,Shuiwang Li*

Main category: cs.CV

TL;DR: No AI result


<details>
  <summary>Details</summary>
Motivation: No AI result

Method: No AI result

Result: No AI result

Conclusion: No AI result

Abstract: Brain-inspired Spiking Neural Networks (SNNs) exhibit significant potential
for low-power computation, yet their application in visual tasks remains
largely confined to image classification, object detection, and event-based
tracking. In contrast, real-world vision systems still widely use conventional
RGB video streams, where the potential of directly-trained SNNs for complex
temporal tasks such as multi-object tracking (MOT) remains underexplored. To
address this challenge, we propose SMTrack-the first directly trained deep SNN
framework for end-to-end multi-object tracking on standard RGB videos. SMTrack
introduces an adaptive and scale-aware Normalized Wasserstein Distance loss
(Asa-NWDLoss) to improve detection and localization performance under varying
object scales and densities. Specifically, the method computes the average
object size within each training batch and dynamically adjusts the
normalization factor, thereby enhancing sensitivity to small objects. For the
association stage, we incorporate the TrackTrack identity module to maintain
robust and consistent object trajectories. Extensive evaluations on BEE24,
MOT17, MOT20, and DanceTrack show that SMTrack achieves performance on par with
leading ANN-based MOT methods, advancing robust and accurate SNN-based tracking
in complex scenarios.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [59] [Beyond Semantic Similarity: Reducing Unnecessary API Calls via Behavior-Aligned Retriever](https://arxiv.org/abs/2508.14323)
*Yixin Chen,Ying Xiong,Shangyu Wu,Yufei Cui,Xue Liu,Nan Guan,Chun Jason Xue*

Main category: cs.CL

TL;DR: 도구 보조 LLM의 잘못된 함수 호출을 줄이기 위해 행동 일치 검색기(BAR)를 학습하여, 행동적으로 일관된 데모를 검색해 LLM의 도구 사용 결정을 개선한다. 대조 학습과 맞춤형 양/음성 쌍 및 이중 음성 대조 손실을 사용해 강건한 검색을 달성하며, 오류 호출을 크게 줄이면서 과제 성능을 유지한다.


<details>
  <summary>Details</summary>
Motivation: 도구를 사용하는 LLM이 외부 함수 호출을 잘못 수행하면 비효율성과 비용 상승이 발생한다. 기존의 파인튜닝이나 데모 기반 프롬프트는 훈련 부담이 크고, 불일치하는 데모 샘플이 모델의 호출 행동을 잘못 유도하는 문제가 있다.

Method: 행동(호출/비호출)별로 라벨링된 코퍼스를 구축하고, 행동적으로 일관된 데모를 반환하는 행동 일치 검색기(BAR)를 학습한다. 대조 학습 프레임워크를 사용해 맞춤형 양성/음성 쌍과 이중-음성(dual-negative) 대조 손실을 도입하여, 행동 일관성에 초점을 맞춘 강건한 검색을 구현한다.

Result: 제안 방법은 잘못된 함수 호출을 유의미하게 감소시키면서도 과제 성능을 유지했다. 비용 효율적이고 학습/추론 측면에서 효율적인 솔루션임을 실험으로 입증했다.

Conclusion: 행동 일치 검색기를 통해 LLM의 도구 호출 결정을 개선하면 오류 호출과 비용을 줄일 수 있으며, 데모의 일관성 문제를 해결하는 실용적 접근을 제시한다.

Abstract: Tool-augmented large language models (LLMs) leverage external functions to
extend their capabilities, but inaccurate function calls can lead to
inefficiencies and increased costs.Existing methods address this challenge by
fine-tuning LLMs or using demonstration-based prompting, yet they often suffer
from high training overhead and fail to account for inconsistent demonstration
samples, which misguide the model's invocation behavior. In this paper, we
trained a behavior-aligned retriever (BAR), which provides behaviorally
consistent demonstrations to help LLMs make more accurate tool-using decisions.
To train the BAR, we construct a corpus including different function-calling
behaviors, i.e., calling or non-calling.We use the contrastive learning
framework to train the BAR with customized positive/negative pairs and a
dual-negative contrastive loss, ensuring robust retrieval of behaviorally
consistent examples.Experiments demonstrate that our approach significantly
reduces erroneous function calls while maintaining high task performance,
offering a cost-effective and efficient solution for tool-augmented LLMs.

</details>


### [60] [Credence Calibration Game? Calibrating Large Language Models through Structured Play](https://arxiv.org/abs/2508.14390)
*Ke Fang,Tianyi Zhao,Lu Cheng*

Main category: cs.CL

TL;DR: 이 논문은 게임 기반의 프롬프트 루프를 통해 LLM의 신뢰도(확신도) 출력을 교정하는 새로운 방법을 제안한다. 추가 파라미터 업데이트나 외부 감독 없이 피드백 드리븐 프롬프트와 자연어 성능 요약을 이용해 모델의 캘리브레이션을 동적으로 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: LLM이 의사결정이 중요한 영역에 배치될수록 확신도(모델의 confidence)가 실제 정답률과 잘 맞아야 한다. 기존 방법들은 주로 사후 보정이나 보조 모델 학습에 의존했고, 많은 경우 추가 감독 데이터나 파라미터 업데이트가 필요했다.

Method: Credence Calibration Game에서 영감을 얻어, LLM과의 구조화된 상호작용 루프를 설계한다. 모델의 예측 확신도와 실제 정답 여부의 정렬(align)을 기반으로 피드백을 제공하고, 이전 성능의 자연어 요약을 포함한 피드백 기반 프롬프트를 반복적으로 입력해 캘리브레이션을 개선한다. 추가 학습 없이 프롬프트 조작만으로 동작한다.

Result: 다수의 모델과 게임 구성에서 평가 지표들(캘리브레이션 관련 메트릭)이 일관되게 향상되었다고 보고한다. 코드와 데이터도 공개되어 재현 가능하다.

Conclusion: 게임 기반 프롬프트-피드백 루프는 LLM 캘리브레이션을 향상시키는 효과적인 전략임을 보여주며, 사후 학습이나 별도 모델 없이도 실용적인 개선을 제공한다.

Abstract: As Large Language Models (LLMs) are increasingly deployed in
decision-critical domains, it becomes essential to ensure that their confidence
estimates faithfully correspond to their actual correctness. Existing
calibration methods have primarily focused on post-hoc adjustments or auxiliary
model training; however, many of these approaches necessitate additional
supervision or parameter updates. In this work, we propose a novel prompt-based
calibration framework inspired by the Credence Calibration Game. Our method
establishes a structured interaction loop wherein LLMs receive feedback based
on the alignment of their predicted confidence with correctness. Through
feedback-driven prompting and natural language summaries of prior performance,
our framework dynamically improves model calibration. Extensive experiments
across models and game configurations demonstrate consistent improvements in
evaluation metrics. Our results highlight the potential of game-based prompting
as an effective strategy for LLM calibration. Code and data are available at
https://anonymous.4open.science/r/LLM-Calibration/.

</details>


### [61] [From Image Captioning to Visual Storytelling](https://arxiv.org/abs/2508.14045)
*Admitos Passadakis,Yingjin Song,Albert Gatt*

Main category: cs.CL

TL;DR: They treat Visual Storytelling as a superset of Image Captioning: first generate captions for each image (vision-to-language), then transform captions into coherent narratives using language-to-language models. This unified pipeline improves story quality, speeds training, increases reusability/reproducibility, and introduces a new metric "ideality" to measure closeness to an oracle/human-likeness.


<details>
  <summary>Details</summary>
Motivation: Visual Storytelling requires both grounding in input images and narrative coherence; existing approaches struggle to balance these. The authors aim to balance groundedness and narrative quality by leveraging image captioning as an intermediate representation.

Method: A two-stage unified framework: (1) use a vision-to-language model to produce captions for each image in the sequence, (2) apply language-to-language transformation to convert the sequence of captions into a coherent story. They evaluate multifariously and propose a novel metric called 'ideality' to simulate distance from an oracle/human baseline.

Result: Integrating captioning and storytelling improves produced story quality in their evaluations, reduces training time compared to many prior works, and yields a reusable, reproducible framework. The 'ideality' metric is applied to emulate human-likeness in visual storytelling.

Conclusion: Treating storytelling as an extension of captioning is effective: it enhances quality and efficiency and provides a practical, reproducible pipeline; the proposed ideality metric offers a way to quantify proximity to an oracle/human output.

Abstract: Visual Storytelling is a challenging multimodal task between Vision &
Language, where the purpose is to generate a story for a stream of images. Its
difficulty lies on the fact that the story should be both grounded to the image
sequence but also narrative and coherent. The aim of this work is to balance
between these aspects, by treating Visual Storytelling as a superset of Image
Captioning, an approach quite different compared to most of prior relevant
studies. This means that we firstly employ a vision-to-language model for
obtaining captions of the input images, and then, these captions are
transformed into coherent narratives using language-to-language methods. Our
multifarious evaluation shows that integrating captioning and storytelling
under a unified framework, has a positive impact on the quality of the produced
stories. In addition, compared to numerous previous studies, this approach
accelerates training time and makes our framework readily reusable and
reproducible by anyone interested. Lastly, we propose a new metric/tool, named
ideality, that can be used to simulate how far some results are from an oracle
model, and we apply it to emulate human-likeness in visual storytelling.

</details>


### [62] [T-REX: Table -- Refute or Entail eXplainer](https://arxiv.org/abs/2508.14055)
*Tim Luka Horstmann,Baptiste Geisenberger,Mehwish Alam*

Main category: cs.CL

TL;DR: T-REX는 멀티모달·다국어 표 데이터를 대상으로 명제를 검증하는 실시간 대화형 도구로, 지시어-튜닝된 추론형 LLM을 활용해 비전문가도 표 사실검증과 그 근거를 확인할 수 있게 한다. 공개 서비스로 제공된다.


<details>
  <summary>Details</summary>
Motivation: 표 형식의 구조화 데이터에 대한 텍스트 주장 검증은 실무적 중요성이 크지만 어려움이 많고, 최근 LLM 발전에도 불구하고 비전문가가 활용하기 어려운 점을 해결하려 함.

Method: 인터랙티브 웹 도구 T-REX를 제안. 입력된 주장과 멀티모달·다국어 표를 연동해 지시어-튜닝된 추론형 LLM으로 검증을 수행하고, 결과와 근거·설명을 투명하게 제시하도록 설계됨.

Result: 최초의 라이브 공개 시스템으로 배포되어 비전문가 접근성 및 투명성을 개선. 초록에는 정량적 성능 지표는 명시되어 있지 않음.

Conclusion: T-REX는 표 기반 사실검증 기술을 비전문가에게 개방하고, 설명 가능한 검증 결과를 제공함으로써 실용적 활용 가능성을 보였음.

Abstract: Verifying textual claims against structured tabular data is a critical yet
challenging task in Natural Language Processing with broad real-world impact.
While recent advances in Large Language Models (LLMs) have enabled significant
progress in table fact-checking, current solutions remain inaccessible to
non-experts. We introduce T-REX (T-REX: Table -- Refute or Entail eXplainer),
the first live, interactive tool for claim verification over multimodal,
multilingual tables using state-of-the-art instruction-tuned reasoning LLMs.
Designed for accuracy and transparency, T-REX empowers non-experts by providing
access to advanced fact-checking technology. The system is openly available
online.

</details>


### [63] [Assessing and Mitigating Data Memorization Risks in Fine-Tuned Large Language Models](https://arxiv.org/abs/2508.14062)
*Badrinath Ramakrishnan,Akshaya Balaji*

Main category: cs.CL

TL;DR: 파인튜닝된 대형언어모델(LLM)의 데이터 암기 현상과 프라이버시 침해를 실험적으로 분석하고, 이를 완화하기 위한 다층적 보호 기법을 제안·평가한 연구.


<details>
  <summary>Details</summary>
Motivation: LLM이 파인튜닝 과정에서 훈련 데이터를 암기해 민감정보 유출 위험을 크게 높이는 문제를 규명하고, 실용적인 보호 방법을 찾기 위함.

Method: GPT-2, Phi-3, Gemma-2 등 최신 LLM 아키텍처에 대해 통제된 실험을 수행해 반복된 민감 데이터가 암기·유출에 미치는 영향을 측정하고, 네 가지 보호 기법(의미 기반 데이터 중복제거, 생성 시 차등프라이버시 적용, 엔트로피 기반 필터링, 패턴 기반 콘텐츠 필터링)을 설계·평가함.

Result: 반복된 민감 데이터로 파인튜닝하면 유출률이 베이스라인 0–5%에서 60–75%로 상승(평균 증가 64.2%)함을 보였고, 제안한 기법들을 적용하면 데이터 유출을 0%로 낮추면서 모델 성능(유틸리티)의 94.7%를 유지할 수 있었음.

Conclusion: 파인튜닝된 LLM에서의 데이터 암기는 심각한 프라이버시 위험을 초래하며, 제안한 다층적 보호 전략들이 실용적 대안이 될 수 있음을 실증적으로 입증함.

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across
diverse natural language processing tasks, but their tendency to memorize
training data poses significant privacy risks, particularly during fine-tuning
processes. This paper presents a comprehensive empirical analysis of data
memorization in fine-tuned LLMs and introduces a novel multi-layered privacy
protection framework. Through controlled experiments on modern LLM
architectures including GPT-2, Phi-3, and Gemma-2, we demonstrate that
fine-tuning with repeated sensitive data increases privacy leakage rates from
baseline levels of 0-5% to 60-75%, representing a 64.2% average increase across
tested models. We propose and rigorously evaluate four complementary privacy
protection methods: semantic data deduplication, differential privacy during
generation, entropy-based filtering, and pattern-based content filtering. Our
experimental results show that these techniques can reduce data leakage to 0%
while maintaining 94.7% of original model utility.

</details>


### [64] [Punctuation and Predicates in Language Models](https://arxiv.org/abs/2508.14067)
*Sonakshi Chauhan,Maheep Chaudhary,Koby Choy,Samuel Nellessen,Nandi Schoots*

Main category: cs.CL

TL;DR: This paper analyzes where and how punctuation and other input components are represented and propagated across layers in LLMs (GPT-2, DeepSeek, Gemma). Using intervention-based methods, necessity/sufficiency tests, interchange interventions, and layer-swapping, it finds model-specific differences: punctuation is necessary and sufficient in multiple layers for GPT-2, less so for DeepSeek, and not for Gemma. Conditional statements and universal quantification are processed differently. Results inform interpretability of LLMs.


<details>
  <summary>Details</summary>
Motivation: Understand the internal mechanisms by which LLMs collect and propagate information — specifically punctuation and reasoning constructs — and whether models form early static summaries or remain sensitive to input-component changes across layers.

Method: Intervention-based experiments including necessity/sufficiency tests for punctuation tokens across layers, interchange interventions, and layer-swapping on different input components (subjects, adjectives, punctuation, full sentences) and reasoning rules (conditional, universal quantification) applied to GPT-2, DeepSeek, and Gemma.

Result: Punctuation acts as an attention sink and memory aid with stark differences across models: necessary and sufficient in multiple GPT-2 layers, far less in DeepSeek, and not in Gemma. Different input components show variable processing dynamics across layers. Conditional and universal quantifiers are processed very differently, indicating non-uniform handling of reasoning rules.

Conclusion: The paper reveals model-specific internal representations and propagation patterns for punctuation and reasoning constructs, challenging simple universal hypotheses (e.g., early static summaries reused across layers) and providing implications for interpretability research.

Abstract: In this paper we explore where information is collected and how it is
propagated throughout layers in large language models (LLMs). We begin by
examining the surprising computational importance of punctuation tokens which
previous work has identified as attention sinks and memory aids. Using
intervention-based techniques, we evaluate the necessity and sufficiency (for
preserving model performance) of punctuation tokens across layers in GPT-2,
DeepSeek, and Gemma. Our results show stark model-specific differences: for
GPT-2, punctuation is both necessary and sufficient in multiple layers, while
this holds far less in DeepSeek and not at all in Gemma. Extending beyond
punctuation, we ask whether LLMs process different components of input (e.g.,
subjects, adjectives, punctuation, full sentences) by forming early static
summaries reused across the network, or if the model remains sensitive to
changes in these components across layers. Extending beyond punctuation, we
investigate whether different reasoning rules are processed differently by
LLMs. In particular, through interchange intervention and layer-swapping
experiments, we find that conditional statements (if, then), and universal
quantification (for all) are processed very differently. Our findings offer new
insight into the internal mechanisms of punctuation usage and reasoning in LLMs
and have implications for interpretability.

</details>


### [65] [DLLMQuant: Quantizing Diffusion-based Large Language Models](https://arxiv.org/abs/2508.14090)
*Chen Xu,Dawei Yang*

Main category: cs.CL

TL;DR: DLLM(확산 기반 대형 언어 모델)의 PTQ 적용 시 발생하는 성능 저하 문제를 분석하고, 시간 및 마스크 상태를 고려한 새로운 PTQ 프레임워크(DLLMQuant)를 제안한다. 핵심 기법은 TMAS, IA-AQ, CGQ이며, 실험에서 양호한 성능 향상과 효율 개선을 보인다.


<details>
  <summary>Details</summary>
Motivation: DLLM은 비자기회귀 텍스트 생성에서 유망하지만 모델 크기·연산 비용이 커 실제 배포가 어렵다. 기존 PTQ를 DLLM에 그대로 적용하면 정확도와 일반화 성능이 크게 떨어진다(예: W4A4에서 AWQ는 LLADA 기준 16% 감소). DLLM의 동적 마스킹, 반복 생성, 양방향 어텐션 등이 정량화와 충돌한다는 것이 문제의 핵심이다.

Method: DLLM의 특성 때문에 발생하는 문제를 세 가지로 규정하고, 이를 해결하기 위해 DLLMQuant를 제안: 1) TMAS(Temporal-Mask Adaptive Sampling): 시간(디코딩 스텝)과 마스크 비율을 고려한 보정 샘플링으로 각 시점의 토큰 분포를 캡처; 2) IA-AQ(Interaction-Aware Activation Quantization): 양방향 어텐션의 상호작용 신호를 이용해 활성화 정량화 자원 배분을 동적으로 조정; 3) CGQ(Certainty-Guided Quantization): 마스크 상태와 토큰의 확신도(score)를 가중치로 활용해 가중치 정량화의 오차 보상을 수행.

Result: 제안한 DLLMQuant는 기존 PTQ 방법들보다 DLLM에서 성능 손실을 크게 줄이며 효율성을 향상시킨다(논문은 정량적 실험으로 유의미한 성능 향상을 보고함). 예시로 기존 AWQ의 큰 정확도 하락을 완화하는 결과를 제시.

Conclusion: DLLM의 반복적 생성과 동적 마스킹, 양방향 어텐션으로 인한 분포 변화와 오차 누적 문제를 문제 정의하고, 시간·마스크·상호작용·확신도를 반영한 PTQ 기법들을 통해 정량화된 DLLM의 성능을 회복·개선할 수 있음을 보였다.

Abstract: Diffusion-based large language models (DLLMs) have shown promise for
non-autoregressive text generation, but their deployment is constrained by
large model sizes and heavy computational costs. Post-training quantization
(PTQ), a widely used method for compressing and accelerating Large Language
Models (LLMs), suffers from severe accuracy degradation and reduced
generalization performance when directly applied to DLLMs (e.g., AWQ suffers a
16% accuracy drop on LLADA under W4A4). This paper explores how DLLMs' key
mechanisms - dynamic masking, iterative generation, bidirectional attention -
clash with quantization. We identify three core issues: 1) Iterative generation
and dynamic masking ratios lead to distinct token distributions across decoding
steps, which are not adequately captured by existing PTQ calibration methods;
2) Quantization errors are accumulated and amplified progressively during
iteration in DLLMs, causing quantized models to perform worse as decoding steps
progress; 3) Unmasked tokens stabilize while masked remain probabilistic,
making overall feature distribution incompatible with existing PTQ methods. To
address these issues, we propose DLLMQuant, a PTQ framework tailored for DLLMs,
which incorporates three novel techniques: 1) Temporal-Mask Adaptive Sampling
(TMAS), a calibration method that accounts for both time and mask factors, with
the capacity to capture distributions across timesteps. 2) Interaction-Aware
Activation Quantization (IA-AQ), which utilizes bidirectional attention's
interaction signals to dynamically allocate quantization resources. 3)
Certainty-Guided Quantization (CGQ), which integrates mask status and token
scores as key weighting criteria into error compensation, making weight
quantization more suitable for DLLMs. Experiments show that DLLMQuant achieves
significant performance gains while enhancing efficiency.

</details>


### [66] [SurveyGen-I: Consistent Scientific Survey Generation with Evolving Plans and Memory-Guided Writing](https://arxiv.org/abs/2508.14317)
*Jing Chen,Zhiheng Yang,Yixian Shen,Jie Liu,Adam Belloum,Chrysa Papagainni,Paola Grosso*

Main category: cs.CL

TL;DR: SurveyGen-I is an LLM-based framework for automatic survey generation that uses coarse-to-fine retrieval, adaptive planning, and a memory mechanism to maintain coherence and citation coverage across long, multi-section surveys.


<details>
  <summary>Details</summary>
Motivation: Existing LLM approaches can automate retrieval, structuring, and summarization but struggle with coherence across long surveys and comprehensive citation coverage.

Method: SurveyGen-I performs survey-level retrieval to build an initial outline and writing plan, uses a memory mechanism to store preceding content and terminology for coherence, and triggers fine-grained subsection-level retrieval when context is insufficient; it employs adaptive planning and memory-guided generation to refine outline and text dynamically.

Result: Across four scientific domains, SurveyGen-I outperforms previous methods in content quality, consistency, and citation coverage.

Conclusion: Memory-guided, coarse-to-fine retrieval with adaptive planning improves automated survey generation, addressing coherence and citation completeness issues in long, multi-section surveys.

Abstract: Survey papers play a critical role in scientific communication by
consolidating progress across a field. Recent advances in Large Language Models
(LLMs) offer a promising solution by automating key steps in the
survey-generation pipeline, such as retrieval, structuring, and summarization.
However, existing LLM-based approaches often struggle with maintaining
coherence across long, multi-section surveys and providing comprehensive
citation coverage. To address these limitations, we introduce SurveyGen-I, an
automatic survey generation framework that combines coarse-to-fine retrieval,
adaptive planning, and memory-guided generation. SurveyGen-I first performs
survey-level retrieval to construct the initial outline and writing plan, and
then dynamically refines both during generation through a memory mechanism that
stores previously written content and terminology, ensuring coherence across
subsections. When the system detects insufficient context, it triggers
fine-grained subsection-level retrieval. During generation, SurveyGen-I
leverages this memory mechanism to maintain coherence across subsections.
Experiments across four scientific domains demonstrate that SurveyGen-I
consistently outperforms previous works in content quality, consistency, and
citation coverage.

</details>


### [67] [MMReview: A Multidisciplinary and Multimodal Benchmark for LLM-Based Peer Review Automation](https://arxiv.org/abs/2508.14146)
*Xian Gao,Jiacheng Ruan,Zongyun Zhang,Jingsheng Gao,Ting Liu,Yuzhuo Fu*

Main category: cs.CL

TL;DR: MMReview는 멀티모달 학술 논문 리뷰 생성을 평가하기 위한 종합 벤치마크로, 4개 학문 분야 17개 도메인에 걸쳐 240편의 논문과 전문가 작성 리뷰를 포함하고 13개 과제를 통해 LLM/MLLM의 리뷰 능력을 평가한다.


<details>
  <summary>Details</summary>
Motivation: LLM 기반 논문 리뷰 자동화가 증가하는 가운데, 특히 그림·표 같은 멀티모달 콘텐츠를 포함한 경우 모델 성능을 엄격히 평가할 통합된 벤치마크가 부재함.

Method: 240편의 논문(멀티모달 포함)과 전문가 리뷰 코멘트를 수집하고, 단계별 리뷰 생성·결론 도출·인간 선호 정렬·적대적 입력에 대한 견고성 등 13개 과제를 설계하여 16개 오픈 소스 모델과 5개 폐쇄형 모델에서 광범위한 실험을 수행.

Result: 벤치마크를 통해 다양한 모델의 성능 차이와 취약점을 규명했으며, 멀티모달 입력 처리 및 인간 정렬 측면에서 표준화의 필요성을 제시.

Conclusion: MMReview는 자동화된 피어리뷰 시스템 개발을 위한 표준화된 평가 기반으로 기능할 수 있으며, LLM/MLLM 연구 및 모델 개선을 촉진할 것으로 기대된다.

Abstract: With the rapid growth of academic publications, peer review has become an
essential yet time-consuming responsibility within the research community.
Large Language Models (LLMs) have increasingly been adopted to assist in the
generation of review comments; however, current LLM-based review tasks lack a
unified evaluation benchmark to rigorously assess the models' ability to
produce comprehensive, accurate, and human-aligned assessments, particularly in
scenarios involving multimodal content such as figures and tables. To address
this gap, we propose \textbf{MMReview}, a comprehensive benchmark that spans
multiple disciplines and modalities. MMReview includes multimodal content and
expert-written review comments for 240 papers across 17 research domains within
four major academic disciplines: Artificial Intelligence, Natural Sciences,
Engineering Sciences, and Social Sciences. We design a total of 13 tasks
grouped into four core categories, aimed at evaluating the performance of LLMs
and Multimodal LLMs (MLLMs) in step-wise review generation, outcome
formulation, alignment with human preferences, and robustness to adversarial
input manipulation. Extensive experiments conducted on 16 open-source models
and 5 advanced closed-source models demonstrate the thoroughness of the
benchmark. We envision MMReview as a critical step toward establishing a
standardized foundation for the development of automated peer review systems.

</details>


### [68] [DPad: Efficient Diffusion Language Models with Suffix Dropout](https://arxiv.org/abs/2508.14148)
*Xinhua Chen,Sitao Huang,Cong Guo,Chiyue Wei,Yintao He,Jianyi Zhang,Hai "Hellen" Li,Yiran Chen*

Main category: cs.CL

TL;DR: Diffusion Scratchpad (DPad)는 디퓨전 기반 대형 언어모델(dLLMs)에서 모든 미래 suffix 토큰을 매 step 예측하는 비효율을 해소하기 위해, attention을 근처의 소수 suffix 토큰으로 제한하는 훈련 불필요한 기법이다. 슬라이딩 윈도우와 distance-decay dropout을 결합해 무분별한 계산을 제거하고, 기존 최적화(프리픽스 캐싱 등)와 호환되며 구현이 간단하다. LLaDA-1.5 및 Dream에서 최대 61.4배 속도 향상과 유사한 정확도를 보였다.


<details>
  <summary>Details</summary>
Motivation: 디퓨전 기반 LLM은 디노이징 방식으로 병렬 텍스트 생성을 수행하나, 매 스텝마다 모든 미래 suffix 토큰을 예측하면서 대부분은 버려져 계산 낭비와 높은 오버헤드가 발생한다. 계산 효율을 개선하면서도 정확도를 유지하는 간단한 방법이 필요했다.

Method: DPad는 (1) 고정 길이의 슬라이딩 윈도우로 suffix의 범위를 제한하고, (2) distance-decay dropout으로 먼 suffix 토큰을 결정론적으로 제거해 attention 연산을 줄인다. 훈련을 필요로 하지 않으며 기존 기법(프리픽스 캐시 등)과 함께 적용할 수 있다.

Result: LLaDA-1.5 및 Dream 모델 기반의 여러 벤치마크에서 DPad는 vanilla dLLM 대비 최대 61.4배의 추론 속도 향상을 달성했고, 대체로 비교 가능한 정확도를 유지했다.

Conclusion: 단순한 attention 제한 전략만으로도 디퓨전 기반 LLM의 추론 효율을 극적으로 향상시킬 수 있으며, 구현이 쉽고 기존 최적화와 호환되어 장거리 시퀀스 추론에 유용하다.

Abstract: Diffusion-based Large Language Models (dLLMs) parallelize text generation by
framing decoding as a denoising process, but suffer from high computational
overhead since they predict all future suffix tokens at each step while
retaining only a small fraction. We propose Diffusion Scratchpad (DPad), a
training-free method that restricts attention to a small set of nearby suffix
tokens, preserving fidelity while eliminating redundancy. DPad integrates two
strategies: (i) a sliding window, which maintains a fixed-length suffix window,
and (ii) distance-decay dropout, which deterministically removes distant suffix
tokens before attention computation. This simple design is compatible with
existing optimizations such as prefix caching and can be implemented with only
a few lines of code. Comprehensive evaluations across multiple benchmarks on
LLaDA-1.5 and Dream models demonstrate that DPad delivers up to
$\mathbf{61.4\times}$ speedup over vanilla dLLMs while maintaining comparable
accuracy, highlighting its potential for efficient and scalable long-sequence
inference. Our code is available at https://github.com/Crys-Chen/DPad.

</details>


### [69] [Comparing energy consumption and accuracy in text classification inference](https://arxiv.org/abs/2508.14170)
*Johannes Zschache,Tilman Hartwig*

Main category: cs.CL

TL;DR: 이 논문은 텍스트 분류 추론 단계에서 모델 정확도와 에너지 소비 사이의 상충 관계를 체계적으로 분석해, 추론 시간(runtime)이 에너지 사용의 실용적 대리 변수(prox y)가 될 수 있음을 보인다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어모델(LLM)의 보급으로 에너지 효율과 지속가능성 문제가 부각되었으나, 기존 연구는 주로 학습 단계의 에너지에 집중했고 추론 단계는 상대적으로 덜 연구되었다. 따라서 추론에서의 정확도-에너지 균형을 규명하려는 목적이 있다.

Method: 여러 모델 아키텍처와 하드웨어 구성에서 텍스트 분류 추론을 수행하며 정확도와 에너지 소비를 계량적으로 비교했다. 모델 유형·크기·하드웨어 변수에 따라 에너지 사용량과 런타임을 측정하고 이들 간의 상관관계를 분석했다.

Result: 정확도 측면에서 최고 성능을 보이는 모델이 에너지 효율적일 수도 있었으나, 일반적으로 큰 LLM들은 더 많은 에너지를 소비하면서 분류 정확도는 낮은 경우가 있었다. 추론 에너지 소비는 mWh 수준에서 kWh 이상으로 큰 편차를 보였고, 에너지 소비와 런타임 사이에 강한 상관관계가 관찰되어 런타임이 에너지 사용의 실용적 대리 지표가 될 수 있음을 확인했다.

Conclusion: 추론 단계의 에너지-성능 트레이드오프에 대한 실증적 통찰을 제공하며, 연구자·기업·정책입안자가 성능과 자원 효율성 사이의 균형을 맞출 때 참고할 수 있는 실무적 시사점을 제시한다.

Abstract: The increasing deployment of large language models (LLMs) in natural language
processing (NLP) tasks raises concerns about energy efficiency and
sustainability. While prior research has largely focused on energy consumption
during model training, the inference phase has received comparatively less
attention. This study systematically evaluates the trade-offs between model
accuracy and energy consumption in text classification inference across various
model architectures and hardware configurations. Our empirical analysis shows
that the best-performing model in terms of accuracy can also be
energy-efficient, while larger LLMs tend to consume significantly more energy
with lower classification accuracy. We observe substantial variability in
inference energy consumption ($<$mWh to $>$kWh), influenced by model type,
model size, and hardware specifications. Additionally, we find a strong
correlation between inference energy consumption and model runtime, indicating
that execution time can serve as a practical proxy for energy usage in settings
where direct measurement is not feasible. These findings have implications for
sustainable AI development, providing actionable insights for researchers,
industry practitioners, and policymakers seeking to balance performance and
resource efficiency in NLP applications.

</details>


### [70] [Let's Use ChatGPT To Write Our Paper! Benchmarking LLMs To Write the Introduction of a Research Paper](https://arxiv.org/abs/2508.14273)
*Krishna Garg,Firoz Shaikh,Sambaran Bandyopadhyay,Cornelia Caragea*

Main category: cs.CL

TL;DR: This paper defines SciIG, a task to evaluate LLMs' ability to generate research paper introductions from title/abstract/related-works, provides datasets from NAACL/ICLR 2025, evaluates five SOTA models (open and closed), and analyzes performance with automated metrics and LLM-as-judge; LLaMA-4 Maverick performs best and three-shot prompting helps.


<details>
  <summary>Details</summary>
Motivation: Researchers increasingly use LLMs for academic writing but coherent, faithful research introductions remain hard to generate; a standardized task and dataset are needed to benchmark model capabilities and inform writing-assistant development.

Method: Define the SciIG task; curate datasets from NAACL 2025 and ICLR 2025 papers; evaluate five models (DeepSeek-v3, Gemma-3-12B, LLaMA 4-Maverick, MistralAI Small 3.1, GPT-4o) using metrics like lexical overlap, semantic similarity, content coverage, faithfulness, consistency, citation correctness, and narrative quality; combine automated metrics with LLM-as-a-judge evaluations; test different prompting shots (one-, three-shot).

Result: LLaMA-4 Maverick ranks highest on most metrics, especially semantic similarity and faithfulness; three-shot prompting yields consistently better outputs than fewer shots; mixed performance across citation correctness and narrative quality among models.

Conclusion: SciIG provides a practical benchmark and datasets for LLM-assisted academic writing, suggesting best practices (e.g., few-shot prompting) and realistic expectations; authors will release code and data to support reproducibility and future work.

Abstract: As researchers increasingly adopt LLMs as writing assistants, generating
high-quality research paper introductions remains both challenging and
essential. We introduce Scientific Introduction Generation (SciIG), a task that
evaluates LLMs' ability to produce coherent introductions from titles,
abstracts, and related works. Curating new datasets from NAACL 2025 and ICLR
2025 papers, we assess five state-of-the-art models, including both open-source
(DeepSeek-v3, Gemma-3-12B, LLaMA 4-Maverick, MistralAI Small 3.1) and
closed-source GPT-4o systems, across multiple dimensions: lexical overlap,
semantic similarity, content coverage, faithfulness, consistency, citation
correctness, and narrative quality. Our comprehensive framework combines
automated metrics with LLM-as-a-judge evaluations. Results demonstrate LLaMA-4
Maverick's superior performance on most metrics, particularly in semantic
similarity and faithfulness. Moreover, three-shot prompting consistently
outperforms fewer-shot approaches. These findings provide practical insights
into developing effective research writing assistants and set realistic
expectations for LLM-assisted academic writing. To foster reproducibility and
future research, we will publicly release all code and datasets.

</details>


### [71] [Disentangling concept semantics via multilingual averaging in Sparse Autoencoders](https://arxiv.org/abs/2508.14275)
*Cliff O'Reilly,Ernesto Jimenez-Ruiz,Tillman Weyde*

Main category: cs.CL

TL;DR: Authors propose isolating concept semantics in LLMs by averaging sparse-autoencoder-derived concept activations across multiple language prompts (English, French, Chinese) for OWL ontology classes using Gemma 2B and Gemma Scope; the multilingual averaged activations better align with ground-truth ontology mappings than single-language activations.


<details>
  <summary>Details</summary>
Motivation: LLM semantics are entangled with syntax and language-specific features; connecting LLMs with formal knowledge representations (ontologies) and achieving mechanistic interpretability requires isolating pure concept semantics.

Method: Generate English textual descriptions from OWL ontology classes, translate to French and Chinese, feed prompts to Gemma 2B LLM, extract concept activations using Gemma Scope sparse autoencoders for each language-version of each class, compute the average activation across languages ('conceptual average'), then correlate these averages with ground-truth ontology class mappings.

Result: The conceptual averages (multilingual activation averages) show stronger alignment with the ground-truth ontology relationships than activations from a single language alone.

Conclusion: Averaging sparse-autoencoder-derived activations across languages can better isolate concept semantics inside LLM internals and may enable more accurate mechanistic interpretation of network states; suggests a new technique for linking LLM internal representations to formal knowledge.

Abstract: Connecting LLMs with formal knowledge representation and reasoning is a
promising approach to address their shortcomings. Embeddings and sparse
autoencoders are widely used to represent textual content, but the semantics
are entangled with syntactic and language-specific information. We propose a
method that isolates concept semantics in Large Langue Models by averaging
concept activations derived via Sparse Autoencoders. We create English text
representations from OWL ontology classes, translate the English into French
and Chinese and then pass these texts as prompts to the Gemma 2B LLM. Using the
open source Gemma Scope suite of Sparse Autoencoders, we obtain concept
activations for each class and language version. We average the different
language activations to derive a conceptual average. We then correlate the
conceptual averages with a ground truth mapping between ontology classes. Our
results give a strong indication that the conceptual average aligns to the true
relationship between classes when compared with a single language by itself.
The result hints at a new technique which enables mechanistic interpretation of
internal network states with higher accuracy.

</details>


### [72] [Tokens with Meaning: A Hybrid Tokenization Approach for NLP](https://arxiv.org/abs/2508.14292)
*M. Ali Bayram,Ali Arda Fincan,Ahmet Semih Gümüş,Sercan Karakaş,Banu Diri,Savaş Yıldırım,Demircan Çelik*

Main category: cs.CL

TL;DR: Hybrid tokenization that combines rule-based morphological analysis and statistical subword segmentation (BPE) for morphologically rich languages, demonstrated on Turkish with strong token metrics and better linguistic coherence than LLaMA/GPT tokenizers.


<details>
  <summary>Details</summary>
Motivation: Subword methods (BPE, WordPiece) rely on frequency and fail to capture morphological structure in agglutinative/morphologically rich languages, causing redundancy and loss of semantic integrity.

Method: Introduce a hybrid framework: phonological normalization, root-affix dictionaries, shared identifiers for phonological variants and altered root forms, special tokens for whitespace/case (UPPERCASE marker), and BPE for OOV coverage. Balances morpheme preservation with vocabulary efficiency via a novel algorithm.

Result: On TR-MMLU benchmark achieved Turkish Token Percentage 90.29% and Pure Token Percentage 85.8%. Produces more linguistically meaningful/coherent tokens compared to tokenizers from LLaMA, Gemma, and GPT.

Conclusion: Language-independent, adaptable approach that reduces redundancy and improves interpretability for multilingual NLP and foundation models targeting morphologically complex languages.

Abstract: Tokenization plays a pivotal role in natural language processing (NLP),
shaping how text is segmented and interpreted by language models. While subword
methods such as Byte Pair Encoding (BPE) and WordPiece have been effective,
they often struggle with morphologically rich and agglutinative languages
because they rely on frequency rather than linguistic structure. We introduce a
hybrid tokenization framework that combines rule-based morphological analysis
with statistical subword segmentation. The method uses phonological
normalization, root-affix dictionaries, and a novel algorithm that balances
morpheme preservation with vocabulary efficiency. It assigns shared identifiers
to phonologically variant affixes (e.g., -ler and -lar) and altered root forms
(e.g., kitap vs. kitab{\i}), reducing redundancy while maintaining semantic
integrity. Special tokens are added for whitespace and case, including an
UPPERCASE marker to avoid vocabulary inflation from capitalization. BPE is
integrated for out-of-vocabulary coverage without harming morphological
coherence. On the TR-MMLU benchmark, the tokenizer achieves the highest Turkish
Token Percentage (90.29\%) and Pure Token Percentage (85.8\%). Comparisons with
tokenizers from LLaMA, Gemma, and GPT show more linguistically meaningful and
coherent tokens. Although demonstrated on Turkish, the approach is
language-independent and adaptable to other languages, offering a practical
path toward more interpretable and effective multilingual NLP systems.

</details>


### [73] [Zero-knowledge LLM hallucination detection and mitigation through fine-grained cross-model consistency](https://arxiv.org/abs/2508.14314)
*Aman Goel,Daniel Schwartz,Yanjun Qi*

Main category: cs.CL

TL;DR: Finch-Zk는 외부 지식 없이도 다양한 모델의 응답 일관성 비교를 통해 LLM의 환각을 탐지하고, 오류가 있는 세그먼트만 정교하게 수정해 정확도를 높이는 블랙박스 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어모델(LLM)이 다양한 작업에서 우수하지만 여전히 사실과 다른 내용을 생성하는 '환각(hallucination)' 문제가 있어, 이를 외부 지식 없이 검출·완화할 실용적 방법이 필요하다.

Method: 1) 의미상 동등한 프롬프트로 다양한 모델의 응답을 비교하는 세밀한 크로스-모델 일관성 검증; 2) 오류가 발견된 세그먼트만 표적 식으로 수정하는 완화 기법—모두 블랙박스 접근으로 외부 지식 불요.

Result: FELM 데이터셋에서 환각 탐지 F1이 기존 방법 대비 6–39% 증가. GPQA-diamond에서 Llama 4 Maverick와 Claude 4 Sonnet 같은 최신 모델에 적용 시 정답 정확도가 절대값 기준 7–8%p 향상. 여러 모델에 대한 광범위한 평가에서 배포 가능한 수준의 사실성 개선을 확인.

Conclusion: Finch-Zk는 외부 지식 없이도 다양한 모델의 응답을 교차검증해 환각을 효과적으로 탐지·완화할 수 있는 실무적 솔루션으로, LLM의 사실성 강화를 위한 실용적 방안이다.

Abstract: Large language models (LLMs) have demonstrated impressive capabilities across
diverse tasks, but they remain susceptible to hallucinations--generating
content that appears plausible but contains factual inaccuracies. We present
Finch-Zk, a black-box framework that leverages FINe-grained Cross-model
consistency to detect and mitigate Hallucinations in LLM outputs without
requiring external knowledge sources. Finch-Zk introduces two key innovations:
1) a cross-model consistency checking strategy that reveals fine-grained
inaccuracies by comparing responses generated by diverse models from
semantically-equivalent prompts, and 2) a targeted mitigation technique that
applies precise corrections to problematic segments while preserving accurate
content. Experiments on the FELM dataset show Finch-Zk improves hallucination
detection F1 scores by 6-39\% compared to existing approaches. For mitigation,
Finch-Zk achieves 7-8 absolute percentage points improvement in answer accuracy
on the GPQA-diamond dataset when applied to state-of-the-art models like Llama
4 Maverick and Claude 4 Sonnet. Extensive evaluation across multiple models
demonstrates that Finch-Zk provides a practical, deployment-ready safeguard for
enhancing factual reliability in production LLM systems.

</details>


### [74] [ZPD-SCA: Unveiling the Blind Spots of LLMs in Assessing Students' Cognitive Abilities](https://arxiv.org/abs/2508.14377)
*Wenhan Dong,Zhen Sun,Yuemeng Zhao,Zifan Peng,Jun Wu,Jingyi Zheng,Yule Liu,Xinlei He,Yu Wang,Ruiming Wang,Xinyi Huang,Lei Mo*

Main category: cs.CL

TL;DR: 제안된 ZPD-SCA 벤치마크는 중국어 읽기 자료의 학생 발달 단계(Zone of Proximal Development, SCA)에 맞춘 난이도 평가를 위해 60명의 최상위 교사 주석으로 구성됨. 실험에서 LLM들은 제로샷에서 낮은 성능을 보였고, 인컨텍스트 예시 제공 시 성능이 크게 향상되었으나 편향과 장르별 성능 차이가 존재함.


<details>
  <summary>Details</summary>
Motivation: LLM이 교육적 맥락에서 학생 발달 단계에 맞는 읽기 자료 난이도(Zone of Proximal Development 기준)를 정확히 판단할 수 있는지에 대한 체계적 평가 부족을 해결하기 위함.

Method: ZPD-SCA라는 새 벤치마크 구축(중국어 읽기, 60명의 Special Grade 교사 주석). 다양한 LLM(예: Qwen-max, GLM 등)을 제로샷과 인컨텍스트 러닝 환경에서 평가하고 장르별 성능과 편향(방향성 오류)을 분석.

Result: 제로샷에서 LLM들 성능이 매우 낮았고 일부 모델은 무작위 추측 수준 이하. 인컨텍스트 예시 제공으로 정확도가 크게 향상되었으며 일부 모델은 제로샷 대비 거의 두 배 수준의 성능을 보임. 그러나 방향성 편향과 장르별 성능 변동 등 한계 존재.

Conclusion: LLM은 교육용 난이도 평가에서 잠재력을 보이지만 현재 학습·평가 방식에는 한계가 있어 추가 연구와 벤치마크 기반 개선이 필요. ZPD-SCA는 이 분야 평가와 개선의 기초로 활용될 수 있음.

Abstract: Large language models (LLMs) have demonstrated potential in educational
applications, yet their capacity to accurately assess the cognitive alignment
of reading materials with students' developmental stages remains insufficiently
explored. This gap is particularly critical given the foundational educational
principle of the Zone of Proximal Development (ZPD), which emphasizes the need
to match learning resources with Students' Cognitive Abilities (SCA). Despite
the importance of this alignment, there is a notable absence of comprehensive
studies investigating LLMs' ability to evaluate reading comprehension
difficulty across different student age groups, especially in the context of
Chinese language education. To fill this gap, we introduce ZPD-SCA, a novel
benchmark specifically designed to assess stage-level Chinese reading
comprehension difficulty. The benchmark is annotated by 60 Special Grade
teachers, a group that represents the top 0.15% of all in-service teachers
nationwide. Experimental results reveal that LLMs perform poorly in zero-shot
learning scenarios, with Qwen-max and GLM even falling below the probability of
random guessing. When provided with in-context examples, LLMs performance
improves substantially, with some models achieving nearly double the accuracy
of their zero-shot baselines. These results reveal that LLMs possess emerging
abilities to assess reading difficulty, while also exposing limitations in
their current training for educationally aligned judgment. Notably, even the
best-performing models display systematic directional biases, suggesting
difficulties in accurately aligning material difficulty with SCA. Furthermore,
significant variations in model performance across different genres underscore
the complexity of task. We envision that ZPD-SCA can provide a foundation for
evaluating and improving LLMs in cognitively aligned educational applications.

</details>


### [75] [DEPTH: Hallucination-Free Relation Extraction via Dependency-Aware Sentence Simplification and Two-tiered Hierarchical Refinement](https://arxiv.org/abs/2508.14391)
*Yupei Yang,Fan Feng,Lin Yang,Wanxi Deng,Lin Qu,Biwei Huang,Shikui Tu,Lei Xu*

Main category: cs.CL

TL;DR: Proposes DEPTH: dependency-aware sentence simplification and two-tiered hierarchical refinement for relation extraction with LLMs to reduce hallucinations and improve F1 by using shortest dependency paths, holistic refinement, and a causality-driven RLHF reward model.


<details>
  <summary>Details</summary>
Motivation: LLMs often hallucinate in relation extraction by failing to decide whether a relation exists, especially with complex syntax/semantics, causing noisy edges in knowledge graphs and reduced downstream reliability.

Method: DEPTH has two stages: Grounding module extracts relations per entity pair using shortest dependency path to distill minimal relational context; Refinement module aggregates local predictions and revises them with a sentence-level holistic review to fix omissions/inconsistencies. Additionally, a causality-driven reward model disentangles spurious correlations to enable robust RL fine-tuning with human feedback.

Result: On six benchmarks, DEPTH lowers average hallucination rate to 7.0% and improves average F1 by 17.2% over SOTA baselines.

Conclusion: Dependency-aware simplification plus two-tiered refinement and causality-driven RLHF effectively reduce hallucinations and substantially improve relation extraction performance with LLMs.

Abstract: Relation extraction enables the construction of structured knowledge for many
downstream applications. While large language models (LLMs) have shown great
promise in this domain, most existing methods concentrate on relation
classification, which predicts the semantic relation type between a related
entity pair. However, we observe that LLMs often struggle to reliably determine
whether a relation exists, especially in cases involving complex sentence
structures or intricate semantics, which leads to spurious predictions. Such
hallucinations can introduce noisy edges in knowledge graphs, compromising the
integrity of structured knowledge and downstream reliability. To address these
challenges, we propose DEPTH, a framework that integrates Dependency-aware
sEntence simPlification and Two-tiered Hierarchical refinement into the
relation extraction pipeline. Given a sentence and its candidate entity pairs,
DEPTH operates in two stages: (1) the Grounding module extracts relations for
each pair by leveraging their shortest dependency path, distilling the sentence
into a minimal yet coherent relational context that reduces syntactic noise
while preserving key semantics; (2) the Refinement module aggregates all local
predictions and revises them based on a holistic understanding of the sentence,
correcting omissions and inconsistencies. We further introduce a
causality-driven reward model that mitigates reward hacking by disentangling
spurious correlations, enabling robust fine-tuning via reinforcement learning
with human feedback. Experiments on six benchmarks demonstrate that DEPTH
reduces the average hallucination rate to 7.0\% while achieving a 17.2\%
improvement in average F1 score over state-of-the-art baselines.

</details>


### [76] [Cognitive Surgery: The Awakening of Implicit Territorial Awareness in LLMs](https://arxiv.org/abs/2508.14408)
*Yinghan Zhou,Weifeng Zhu,Juan Wen,Wanli Peng,Zhengxian Wu,Yiming Xue*

Main category: cs.CL

TL;DR: LLM들은 두 텍스트를 비교하는 PPP에서는 자신이 생성한 텍스트를 잘 식별하지만, 단일 텍스트를 판단하는 IPP에서는 성능이 크게 떨어진다. 저자들은 이 원인을 모델의 표현 공간에서의 잠재적 구분 능력(Implicit Territorial Awareness, ITA)이 출력 행동으로 드러나지 않기 때문이라고 규정하고, 이를 활성화하는 Cognitive Surgery(CoSur) 프레임워크를 제안하여 IPP 성능을 크게 향상시켰다.


<details>
  <summary>Details</summary>
Motivation: 왜 LLM들이 단일 문서 IPP 상황에서 자신이 생성했는지 판단하지 못하는지 체계적으로 분석하고, 표현 공간에 존재하는 잠재적 구분 능력을 출력으로 끌어내는 방법을 찾기 위함.

Method: 기존 재현을 통해 IPP 실패를 확인한 뒤, 표현 추출, 영역(territory) 구성, 저자 판별, 인지 편집의 네 모듈로 구성된 CoSur 프레임워크를 제안하여 모델의 암묵적 영역 인식을 깨어나게 함.

Result: 세 가지 LLM에 대해 IPP 성능을 개선했으며, 각각 평균 정확도 83.25%, 66.19%, 88.01%를 달성함.

Conclusion: LLM은 표현 공간 내에 자기·타자 텍스트를 구분하는 능력(ITA)을 갖고 있으나 이를 출력으로 표현하지 못한다. CoSur는 ITA를 활성화시켜 IPP 상황에서 유의미한 개선을 제공한다.

Abstract: Large language models (LLMs) have been shown to possess a degree of
self-recognition capability-the ability to identify whether a given text was
generated by themselves. Prior work has demonstrated that this capability is
reliably expressed under the Pair Presentation Paradigm (PPP), where the model
is presented with two texts and asked to choose which one it authored. However,
performance deteriorates sharply under the Individual Presentation Paradigm
(IPP), where the model is given a single text to judge authorship. Although
this phenomenon has been observed, its underlying causes have not been
systematically analyzed. In this paper, we first replicate existing findings to
confirm that LLMs struggle to distinguish self- from other-generated text under
IPP. We then investigate the reasons for this failure and attribute it to a
phenomenon we term Implicit Territorial Awareness (ITA)-the model's latent
ability to distinguish self- and other-texts in representational space, which
remains unexpressed in its output behavior. To awaken the ITA of LLMs, we
propose Cognitive Surgery (CoSur), a novel framework comprising four main
modules: representation extraction, territory construction, authorship
discrimination and cognitive editing. Experimental results demonstrate that our
proposed method improves the performance of three different LLMs in the IPP
scenario, achieving average accuracies of 83.25%, 66.19%, and 88.01%,
respectively.

</details>


### [77] [Knowledge Graph-Infused Fine-Tuning for Structured Reasoning in Large Language Models](https://arxiv.org/abs/2508.14427)
*Wuyang Zhang,Yexin Tian,Xiandong Meng,Mengjie Wang,Junliang Du*

Main category: cs.CL

TL;DR: Proposes a structure-aware fine-tuning framework that injects knowledge graph information into pretrained language models via a GNN encoder, fusion and gating mechanisms, and joint loss, improving entity prediction and structured reasoning across tasks.


<details>
  <summary>Details</summary>
Motivation: Large language models lack explicit entity-level semantics and reasoning chains for structured-knowledge tasks, leading to weak entity prediction and inconsistent semantic reasoning.

Method: Encode entities and relations with a graph neural network to create KG embeddings; fuse these embeddings with LM contextual representations using a designed fusion mechanism; use a gating mechanism to balance linguistic and structural signals; train with a joint loss combining task objectives and structural alignment.

Result: Systematic experiments (entity recognition, QA, generation) show improved entity prediction accuracy, semantic consistency, and robustness to structural perturbations; sensitivity analyses on learning rate, graph coverage, and perturbations validate stability.

Conclusion: The proposed KG-injection fine-tuning framework enhances pretrained LMs' ability to represent complex semantic units and improves structured reasoning, offering a stable method to integrate symbolic graph knowledge with neural language representations.

Abstract: This paper addresses the problems of missing reasoning chains and
insufficient entity-level semantic understanding in large language models when
dealing with tasks that require structured knowledge. It proposes a fine-tuning
algorithm framework based on knowledge graph injection. The method builds on
pretrained language models and introduces structured graph information for
auxiliary learning. A graph neural network is used to encode entities and their
relations, constructing a graph-based semantic representation. A fusion
mechanism is then designed to jointly model the knowledge graph embeddings with
the contextual representations from the language model. To enhance the
robustness of knowledge integration, a gating mechanism is introduced to
dynamically balance the contributions of linguistic semantics and structural
knowledge. This effectively mitigates conflicts between different
representational spaces. During training, a joint loss function is constructed
to account for both task performance and structural alignment objectives. This
helps improve the accuracy of entity prediction and semantic reasoning. The
study also includes a series of systematic sensitivity experiments. It
evaluates the effects of learning rate, graph coverage, and structural
perturbations on model performance. The results further validate the
effectiveness and stability of the proposed method across tasks such as entity
recognition, question answering, and language generation. Experimental findings
show that the proposed structure-aware fine-tuning framework significantly
enhances the model's ability to represent complex semantic units. It
demonstrates better semantic consistency and contextual logic modeling in
scenarios involving structural reasoning and entity extraction.

</details>


### [78] [NVIDIA Nemotron Nano 2: An Accurate and Efficient Hybrid Mamba-Transformer Reasoning Model](https://arxiv.org/abs/2508.14444)
*NVIDIA,:,Aarti Basant,Abhijit Khairnar,Abhijit Paithankar,Abhinav Khattar,Adi Renduchintala,Adithya Renduchintala,Aditya Malte,Akhiad Bercovich,Akshay Hazare,Alejandra Rico,Aleksander Ficek,Alex Kondratenko,Alex Shaposhnikov,Ali Taghibakhshi,Amelia Barton,Ameya Sunil Mahabaleshwarkar,Amy Shen,Andrew Tao,Ann Guan,Anna Shors,Anubhav Mandarwal,Arham Mehta,Arun Venkatesan,Ashton Sharabiani,Ashwath Aithal,Ashwin Poojary,Ayush Dattagupta,Balaram Buddharaju,Banghua Zhu,Barnaby Simkin,Bilal Kartal,Bita Darvish Rouhani,Bobby Chen,Boris Ginsburg,Brandon Norick,Brian Yu,Bryan Catanzaro,Charles Wang,Charlie Truong,Chetan Mungekar,Chintan Patel,Chris Alexiuk,Christian Munley,Christopher Parisien,Dan Su,Daniel Afrimi,Daniel Korzekwa,Daniel Rohrer,Daria Gitman,David Mosallanezhad,Deepak Narayanan,Dima Rekesh,Dina Yared,Dmytro Pykhtar,Dong Ahn,Duncan Riach,Eileen Long,Elliott Ning,Eric Chung,Erick Galinkin,Evelina Bakhturina,Gargi Prasad,Gerald Shen,Haim Elisha,Harsh Sharma,Hayley Ross,Helen Ngo,Herman Sahota,Hexin Wang,Hoo Chang Shin,Hua Huang,Iain Cunningham,Igor Gitman,Ivan Moshkov,Jaehun Jung,Jan Kautz,Jane Polak Scowcroft,Jared Casper,Jimmy Zhang,Jinze Xue,Jocelyn Huang,Joey Conway,John Kamalu,Jonathan Cohen,Joseph Jennings,Julien Veron Vialard,Junkeun Yi,Jupinder Parmar,Kari Briski,Katherine Cheung,Katherine Luna,Keith Wyss,Keshav Santhanam,Kezhi Kong,Krzysztof Pawelec,Kumar Anik,Kunlun Li,Kushan Ahmadian,Lawrence McAfee,Laya Sleiman,Leon Derczynski,Luis Vega,Maer Rodrigues de Melo,Makesh Narsimhan Sreedhar,Marcin Chochowski,Mark Cai,Markus Kliegl,Marta Stepniewska-Dziubinska,Matvei Novikov,Mehrzad Samadi,Meredith Price,Meriem Boubdir,Michael Boone,Michael Evans,Michal Bien,Michal Zawalski,Miguel Martinez,Mike Chrzanowski,Mohammad Shoeybi,Mostofa Patwary,Namit Dhameja,Nave Assaf,Negar Habibi,Nidhi Bhatia,Nikki Pope,Nima Tajbakhsh,Nirmal Kumar Juluru,Oleg Rybakov,Oleksii Hrinchuk,Oleksii Kuchaiev,Oluwatobi Olabiyi,Pablo Ribalta,Padmavathy Subramanian,Parth Chadha,Pavlo Molchanov,Peter Dykas,Peter Jin,Piotr Bialecki,Piotr Januszewski,Pradeep Thalasta,Prashant Gaikwad,Prasoon Varshney,Pritam Gundecha,Przemek Tredak,Rabeeh Karimi Mahabadi,Rajen Patel,Ran El-Yaniv,Ranjit Rajan,Ria Cheruvu,Rima Shahbazyan,Ritika Borkar,Ritu Gala,Roger Waleffe,Ruoxi Zhang,Russell J. Hewett,Ryan Prenger,Sahil Jain,Samuel Kriman,Sanjeev Satheesh,Saori Kaji,Sarah Yurick,Saurav Muralidharan,Sean Narenthiran,Seonmyeong Bak,Sepehr Sameni,Seungju Han,Shanmugam Ramasamy,Shaona Ghosh,Sharath Turuvekere Sreenivas,Shelby Thomas,Shizhe Diao,Shreya Gopal,Shrimai Prabhumoye,Shubham Toshniwal,Shuoyang Ding,Siddharth Singh,Siddhartha Jain,Somshubra Majumdar,Stefania Alborghetti,Syeda Nahida Akter,Terry Kong,Tim Moon,Tomasz Hliwiak,Tomer Asida,Tony Wang,Twinkle Vashishth,Tyler Poon,Udi Karpas,Vahid Noroozi,Venkat Srinivasan,Vijay Korthikanti,Vikram Fugro,Vineeth Kalluru,Vitaly Kurin,Vitaly Lavrukhin,Wasi Uddin Ahmad,Wei Du,Wonmin Byeon,Ximing Lu,Xin Dong,Yashaswi Karnati,Yejin Choi,Yian Zhang,Ying Lin,Yonggan Fu,Yoshi Suhara,Zhen Dong,Zhiyu Li,Zhongbo Zhu,Zijia Chen*

Main category: cs.CL

TL;DR: Nemotron-Nano-9B-v2는 Mamba-Transformer 하이브리드 구조로 추론 처리량을 크게 높이면서 유사 규모 모델과 동등하거나 더 나은 추론 성능(추론 정확도)을 달성하는 9B급 언어 모델이다.


<details>
  <summary>Details</summary>
Motivation: 긴 사고(trace) 생성이 필요한 추론 작업에서 추론 처리량(throughput) 향상과 동시에 정확도를 유지하거나 개선하는 경량화된 대형 언어모델을 만들기 위함.

Method: Nemotron-H 아키텍처 기반으로 다수의 self-attention 레이어를 Mamba-2 레이어로 대체해 추론 속도를 개선. 12B 모델(Nemotron-Nano-12B-v2-Base)을 20조 토큰으로 FP8 트레이닝 레시피로 사전학습하고, 정렬(align) 후 Minitron 전략으로 압축·증류하여 9B급 Nemotron-Nano-9B-v2를 생성. 단일 A10G(22GiB) GPU에서 bfloat16으로 최대 128k 토큰 추론을 목표로 함.

Result: Qwen3-8B 등 유사 규모 모델과 비교해 추론 기반 추론 과제(예: 8k 입력, 16k 출력)에서 동등하거나 우수한 정확도를 유지하면서 최대 6배 높은 추론 처리량을 달성했다고 보고. 모델 및 주요 데이터셋과 체크포인트를 Hugging Face에 공개.

Conclusion: Mamba-Transformer 혼합 구조와 Minitron 압축·증류 파이프라인을 통해 장문 추론에서 처리량을 크게 높이면서도 성능을 유지하는 실용적 LLM을 제시하고 모델·데이터 공개로 재현성을 지원함.

Abstract: We introduce Nemotron-Nano-9B-v2, a hybrid Mamba-Transformer language model
designed to increase throughput for reasoning workloads while achieving
state-of-the-art accuracy compared to similarly-sized models.
Nemotron-Nano-9B-v2 builds on the Nemotron-H architecture, in which the
majority of the self-attention layers in the common Transformer architecture
are replaced with Mamba-2 layers, to achieve improved inference speed when
generating the long thinking traces needed for reasoning. We create
Nemotron-Nano-9B-v2 by first pre-training a 12-billion-parameter model
(Nemotron-Nano-12B-v2-Base) on 20 trillion tokens using an FP8 training recipe.
After aligning Nemotron-Nano-12B-v2-Base, we employ the Minitron strategy to
compress and distill the model with the goal of enabling inference on up to
128k tokens on a single NVIDIA A10G GPU (22GiB of memory, bfloat16 precision).
Compared to existing similarly-sized models (e.g., Qwen3-8B), we show that
Nemotron-Nano-9B-v2 achieves on-par or better accuracy on reasoning benchmarks
while achieving up to 6x higher inference throughput in reasoning settings like
8k input and 16k output tokens. We are releasing Nemotron-Nano-9B-v2,
Nemotron-Nano12B-v2-Base, and Nemotron-Nano-9B-v2-Base checkpoints along with
the majority of our pre- and post-training datasets on Hugging Face.

</details>


### [79] [In2x at WMT25 Translation Task](https://arxiv.org/abs/2508.14472)
*Lei Pang,Hanyi Mao,Quanjia Xiao,HaiXiao Liu,Xiangyi Li*

Main category: cs.CL

TL;DR: WMT25에 제출된 논문으로, 일본어 관련 기계번역을 중심으로 LLM을 다른 언어로 확장하기 위한 범용적 패러다임(데이터 구성 및 보상모델 설계)을 제안·탐색한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어 모델을 저자원·비주류 언어에서도 높은 성능을 발휘하도록 확장하는 방법을 탐구하려는 목적이다. 특히 일본어 관련 번역 작업을 통해 일반화 가능한 절차를 규명하려 한다.

Method: WMT25 일반 기계번역 태스크에 대한 오픈 시스템 제출로서, 데이터 구성 방법과 보상 모델 설계를 포함하는 패러다임을 제안·실행한다. 구체적 방법론(데이터 수집, 정제, 보상 학습 등)에 초점을 둔다고 서술되어 있다.

Result: 초록에는 구체적 실험 결과나 수치적 성능 결과가 제시되어 있지 않다. 다만 목표는 저자원 언어에서 우수한 성능을 달성하는 것이다.

Conclusion: 제안한 패러다임이 LLM 기반 시스템을 다른 언어로 일반화하는 데 기여할 수 있음을 주장한다. 구체적 검증·성능 세부사항은 본문에 있을 것으로 보인다.

Abstract: This paper presents the open-system submission by the In2x research team for
the WMT25 General Machine Translation Shared Task. Our submission focuses on
Japanese-related translation tasks, aiming to explore a generalizable paradigm
for extending large language models (LLMs) to other languages. This paradigm
encompasses aspects such as data construction methods and reward model design.
The ultimate goal is to enable large language model systems to achieve
exceptional performance in low-resource or less commonly spoken languages.

</details>


### [80] [Reasoning is about giving reasons](https://arxiv.org/abs/2508.14488)
*Krunal Shah,Dan Roth*

Main category: cs.CL

TL;DR: The paper proposes an intermediate Representation of the Logical Structure (RLS) for natural-language arguments: identify logical atoms and rules, then perform deterministic reasoning on that structure to support various reasoning modes (deduction, abduction, contradiction detection), explanation generation, mistake rectification, and interactive discussion.


<details>
  <summary>Details</summary>
Motivation: Current transformer-based chain-of-thought approaches can chain rules but lack interpretable representations of the underlying 'reasons' (logical atoms and rules). They are limited in flexibility and cannot readily support related reasoning tasks like abduction or contradiction identification.

Method: Define and extract an intermediate representation called RLS that captures logical atoms and rules in an argument. Given RLS, perform deterministic reasoning over the structure, enabling arbitrary reasoning depth, on-the-fly correction, and interactive discourse. Evaluate extraction accuracy on three popular reasoning datasets.

Result: The authors can identify and extract logical structure from natural-language arguments in three reasoning datasets with high accuracy. The extracted RLS supports explanation generation and significantly extends reasoning capabilities (including abduction and contradiction detection).

Conclusion: RLS provides an interpretable, generalizable intermediate representation that makes reasoning deterministic and flexible across multiple reasoning modes, improving explainability and extensibility over current chain-of-thought methods.

Abstract: Convincing someone of the truth value of a premise requires understanding and
articulating the core logical structure of the argument which proves or
disproves the premise. Understanding the logical structure of an argument
refers to understanding the underlying "reasons" which make up the proof or
disproof of the premise - as a function of the "logical atoms" in the argument.
While it has been shown that transformers can "chain" rules to derive simple
arguments, the challenge of articulating the "reasons" remains. Not only do
current approaches to chaining rules suffer in terms of their interpretability,
they are also quite constrained in their ability to accommodate extensions to
theoretically equivalent reasoning tasks - a model trained to chain rules
cannot support abduction or identify contradictions. In this work we suggest
addressing these shortcomings by identifying an intermediate representation
(which we call the Representation of the Logical Structure (RLS) of the
argument) that possesses an understanding of the logical structure of a natural
language argument - the logical atoms in the argument and the rules
incorporating them. Given the logical structure, reasoning is deterministic and
easy to compute. Therefore, our approach supports all forms of reasoning that
depend on the logical structure of the natural language argument, including
arbitrary depths of reasoning, on-the-fly mistake rectification and interactive
discussion with respect to an argument. We show that we can identify and
extract the logical structure of natural language arguments in three popular
reasoning datasets with high accuracies, thus supporting explanation generation
and extending the reasoning capabilities significantly.

</details>


### [81] [Towards Skeletal and Signer Noise Reduction in Sign Language Production via Quaternion-Based Pose Encoding and Contrastive Learning](https://arxiv.org/abs/2508.14574)
*Guilhem Fauré,Mostafa Sadeghi,Sam Bigeard,Slim Ouni*

Main category: cs.CL

TL;DR: Sign language production에서 서명자 간의 신체·스타일 차이를 줄이기 위해 뼈 회전을 쿼터니언으로 인코딩하고 지오데식 손실을 적용하며, 디코더 임베딩에 의미 기반 대조 손실을 도입해 성능을 개선한다.


<details>
  <summary>Details</summary>
Motivation: SLP(신경망 기반 수어 생성)는 서명자 신체 형태와 스타일의 높은 클래스 내 변이성 때문에 정확하고 명료한 관절 움직임 생성이 어렵다. 이러한 변이성에 강인한 모델이 필요하다.

Method: 기존 Progressive Transformers에 두 가지 개선을 제안: (1) 관절 각도 표현을 쿼터니언(뼈 회전)으로 인코딩하고 지오데식 손실로 각도 정확성 향상, (2) 디코더 임베딩에 대조적 손실을 추가해 의미적으로 유사한 입력들이 임베딩 공간에서 가깝게 위치하도록 학습(글로스 중첩 또는 SBERT 문장 유사도 사용).

Result: Phoenix14T 데이터셋에서 대조 손실만으로 PT 기준선 대비 PCK(Probability of Correct Keypoint)에서 16% 향상. 쿼터니언 인코딩과 결합 시 Mean Bone Angle Error가 6% 감소.

Conclusion: 스켈레탈 구조(뼈 회전) 모델링과 의미 기반 대조 목적함수를 SLP 트랜스포머 학습에 도입하면 포즈 표현의 정확성과 명료성이 향상되어 수어 생성 성능 개선에 유의미한 이점이 있다.

Abstract: One of the main challenges in neural sign language production (SLP) lies in
the high intra-class variability of signs, arising from signer morphology and
stylistic variety in the training data. To improve robustness to such
variations, we propose two enhancements to the standard Progressive
Transformers (PT) architecture (Saunders et al., 2020). First, we encode poses
using bone rotations in quaternion space and train with a geodesic loss to
improve the accuracy and clarity of angular joint movements. Second, we
introduce a contrastive loss to structure decoder embeddings by semantic
similarity, using either gloss overlap or SBERT-based sentence similarity,
aiming to filter out anatomical and stylistic features that do not convey
relevant semantic information. On the Phoenix14T dataset, the contrastive loss
alone yields a 16% improvement in Probability of Correct Keypoint over the PT
baseline. When combined with quaternion-based pose encoding, the model achieves
a 6% reduction in Mean Bone Angle Error. These results point to the benefit of
incorporating skeletal structure modeling and semantically guided contrastive
objectives on sign pose representations into the training of Transformer-based
SLP models.

</details>


### [82] [Improving in-context learning with a better scoring function](https://arxiv.org/abs/2508.14685)
*Omar Naim,Swarnadeep Bhar,Jérôme Bolte,Nicholas Asher*

Main category: cs.CL

TL;DR: LLMs show limits in in-context learning for first-order quantifiers and linear functions; the authors identify Softmax in attention as a contributing cause and propose scaled signed averaging (SSA) as an alternative, which substantially improves performance and matches/exceeds Softmax models on various linguistic probing tasks for both encoder-only and decoder-only transformers.


<details>
  <summary>Details</summary>
Motivation: Investigate and mitigate observed failures of in-context learning (ICL) in LLMs on tasks involving first-order quantifiers (e.g., "all", "some") and linear functions, by identifying underlying architectural causes.

Method: Analyze the role of the Softmax scoring function in attention as a constraint on ICL; introduce a novel attention scoring alternative called scaled signed averaging (SSA); empirically evaluate SSA versus Softmax across target ICL tasks and a range of linguistic probing tasks on encoder-only and decoder-only transformer models.

Result: SSA dramatically improves performance on the targeted ICL tasks (quantifiers and linear functions). Models using SSA match or outperform Softmax-based counterparts across diverse linguistic probing evaluations for both encoder-only and decoder-only architectures.

Conclusion: Replacing Softmax with SSA alleviates identified limitations of ICL in LLMs and provides a promising alternative attention scoring mechanism with broad improvements on linguistic tasks.

Abstract: Large language models (LLMs) exhibit a remarkable capacity to learn by
analogy, known as in-context learning (ICL). However, recent studies have
revealed limitations in this ability. In this paper, we examine these
limitations on tasks involving first-order quantifiers such as {\em all} and
{\em some}, as well as on ICL with linear functions. We identify Softmax, the
scoring function in attention mechanism, as a contributing factor to these
constraints. To address this, we propose \textbf{scaled signed averaging
(SSA)}, a novel alternative to Softmax. Empirical results show that SSA
dramatically improves performance on our target tasks. Furthermore, we evaluate
both encoder-only and decoder-only transformers models with SSA, demonstrating
that they match or exceed their Softmax-based counterparts across a variety of
linguistic probing tasks.

</details>


### [83] [ShizhenGPT: Towards Multimodal LLMs for Traditional Chinese Medicine](https://arxiv.org/abs/2508.14706)
*Junying Chen,Zhenyang Cai,Zhiheng Liu,Yunjin Yang,Rongsheng Wang,Qingying Xiao,Xiangyi Feng,Zhan Su,Jing Guo,Xiang Wan,Guangjun Yu,Haizhou Li,Benyou Wang*

Main category: cs.CL

TL;DR: ShizhenGPT는 한약(중의학)을 위해 제작된 최초의 멀티모달 대형언어모델로, 텍스트·이미지·음성·생체신호를 포함한 대규모(TCM 전용 100GB+ 텍스트, 200GB+ 멀티모달) 데이터로 사전학습 및 지시어 튜닝을 거쳐 멀티모달 추론과 시각 진단에서 우수한 성능을 보였다.


<details>
  <summary>Details</summary>
Motivation: 전통중의학 분야는 고품질 데이터의 부족과 ‘시청후촉(보는 것·듣는 것·냄새 맡기·맥진)’처럼 본질적으로 멀티모달적인 진단 특성으로 인해 기존 LLM 적용이 제한적이었다.

Method: 100GB 이상의 텍스트와 1.2M 이미지·200시간 음성·생체신호 등 200GB+ 멀티모달 데이터를 수집해 대규모 TCM 코퍼스를 구축하고, 이를 바탕으로 멀티모달 LLM(ShizhenGPT)을 사전학습 및 지시어(Instruction) 튜닝하여 시청후촉을 아우르는 통합 인식·추론 능력을 학습시켰다.

Result: 국가 TCM 자격시험 데이터 및 약재 인식·시각 진단 벤치마크에서 동급 규모 LLM들을 능가하고, 일부 상용 대형 모델과 경쟁 가능한 성능을 보였다. 기존 멀티모달 LLM들 대비 TCM 시각 이해 능력에서 선도적이며 소리·맥·냄새·시각 등 여러 감각을 통합한 인식 성능을 보였다.

Conclusion: 대규모 전용 데이터와 멀티모달 학습을 통해 전통중의학 분야에서 실용 가능하고 통합적인 멀티모달 LLM을 제시했으며, 데이터·모델·코드를 공개하여 후속 연구를 촉진하고자 한다.

Abstract: Despite the success of large language models (LLMs) in various domains, their
potential in Traditional Chinese Medicine (TCM) remains largely underexplored
due to two critical barriers: (1) the scarcity of high-quality TCM data and (2)
the inherently multimodal nature of TCM diagnostics, which involve looking,
listening, smelling, and pulse-taking. These sensory-rich modalities are beyond
the scope of conventional LLMs. To address these challenges, we present
ShizhenGPT, the first multimodal LLM tailored for TCM. To overcome data
scarcity, we curate the largest TCM dataset to date, comprising 100GB+ of text
and 200GB+ of multimodal data, including 1.2M images, 200 hours of audio, and
physiological signals. ShizhenGPT is pretrained and instruction-tuned to
achieve deep TCM knowledge and multimodal reasoning. For evaluation, we collect
recent national TCM qualification exams and build a visual benchmark for
Medicinal Recognition and Visual Diagnosis. Experiments demonstrate that
ShizhenGPT outperforms comparable-scale LLMs and competes with larger
proprietary models. Moreover, it leads in TCM visual understanding among
existing multimodal LLMs and demonstrates unified perception across modalities
like sound, pulse, smell, and vision, paving the way toward holistic multimodal
perception and diagnosis in TCM. Datasets, models, and code are publicly
available. We hope this work will inspire further exploration in this field.

</details>


### [84] [The Digital Sous Chef -- A Comparative Study on Fine-Tuning Language Models for Recipe Generation](https://arxiv.org/abs/2508.14718)
*Shubham Pundhir,Ganesh Bagler*

Main category: cs.CL

TL;DR: Fine-tuned GPT-2 large (774M) significantly outperforms smaller GPT-2 and LSTM/RNN baselines on text-based recipe generation (RecipeDB 5-cuisine), aided by a custom tokenization that adds 23 fraction tokens and structural markers to better preserve quantities and structure.


<details>
  <summary>Details</summary>
Motivation: Current generic tokenizers lose recipe-specific structures and numerical precision (fractions/quantities), hindering high-quality recipe generation; the authors aim to create a rigorous benchmark and improve domain-specific modeling.

Method: Compare GPT-2 large (774M) fine-tuned vs GPT-2 small (124M) and LSTM/RNN baselines on RecipeDB 5-cuisine corpus; introduce targeted tokenization with 23 fraction tokens and structural markers; evaluate with seven automatic metrics (BLEU-4, METEOR, ROUGE-L, BERTScore, diversity, perplexity-related measures).

Result: GPT-2 large yields >20% relative improvement in BERTScore (F1 0.92 vs 0.72) over best recurrent baseline and reduces perplexity by 69.8%; overall stronger fluency, coherence, semantic relevance and diversity compared to baselines.

Conclusion: Domain-aware tokenization plus large transformer fine-tuning substantially improves recipe generation; remaining challenges include factual accuracy and integrating real-world constraints and multimodal inputs for future work.

Abstract: We established a rigorous benchmark for text-based recipe generation, a
fundamental task in natural language generation. We present a comprehensive
comparative study contrasting a fine-tuned GPT-2 large (774M) model against the
GPT-2 small (124M) model and traditional LSTM/RNN baselines on the 5-cuisine
corpus from RecipeDB. Our key contribution is a targeted tokenization strategy
that augments the vocabulary with 23 common fraction tokens and custom
structural markers. This approach addresses a critical limitation of generic
tokenizers by preserving essential recipe structures and precise numerical
quantities, thereby enhancing domain specificity. Performance is evaluated
using a comprehensive suite of seven automatic metrics spanning fluency
(BLEU-4, METEOR), coherence (ROUGE-L), semantic relevance (BERTScore), and
diversity. Our experiments show that the large transformer-based approach
yields a >20% relative improvement in BERTScore (F1) (0.92 vs 0.72) over the
best recurrent baseline, while reducing perplexity by 69.8%. We conclude with a
discussion of remaining challenges, particularly regarding factual accuracy,
and outline how this foundational study paves the way for integrating
real-world constraints and multi-modal inputs in advanced recipe generation
research.

</details>


### [85] [Transplant Then Regenerate: A New Paradigm for Text Data Augmentation](https://arxiv.org/abs/2508.14723)
*Guangzhan Wang,Hongyu Zhang,Beijun Shen,Xiaodong Gu*

Main category: cs.CL

TL;DR: LMTransplant은 LLM을 이용한 텍스트 증강 기법으로, 원문을 LLM이 확장한 문맥에 '이식'한 뒤 재생성하여 의미는 유지하면서 더 다양하고 창의적인 콘텐츠 변형을 생성한다.


<details>
  <summary>Details</summary>
Motivation: 기존 백번역 등 전통적 텍스트 증강은 어휘 수준의 재표현에 그쳐 다양성이 제한되고, LLM은 지식 기반의 더 창의적 변형을 만들 수 있으나 스타일·구조 제어가 어렵고 프롬프트 공학이 필요하다.

Method: 'transplant-then-regenerate' 전략: 시드 텍스트를 LLM이 확장한 문맥에 통합(이식)하고, 확장된 문맥을 바탕으로 LLM에게 변형 문장을 재생성하도록 요청한다. 이를 통해 핵심 속성은 보존하면서 내용 수준의 다양한 변형을 얻음.

Result: 여러 텍스트 관련 작업에서 기존 증강법보다 우수한 성능을 보였으며, 증강 데이터 규모가 커질수록 성능이 잘 확장되는 특성을 보였다.

Conclusion: LMTransplant는 LLM의 지식을 활용해 보다 다양하고 스케일러블한 텍스트 증강을 제공하며, 프롬프트 의존도를 낮추고 원문 속성 보존과 창의적 변형의 균형을 이룬다.

Abstract: Data augmentation is a critical technique in deep learning. Traditional
methods like Back-translation typically focus on lexical-level rephrasing,
which primarily produces variations with the same semantics. While large
language models (LLMs) have enhanced text augmentation by their "knowledge
emergence" capability, controlling the style and structure of these outputs
remains challenging and requires meticulous prompt engineering. In this paper,
we propose LMTransplant, a novel text augmentation paradigm leveraging LLMs.
The core idea of LMTransplant is transplant-then-regenerate: incorporating seed
text into a context expanded by LLM, and asking the LLM to regenerate a variant
based on the expanded context. This strategy allows the model to create more
diverse and creative content-level variants by fully leveraging the knowledge
embedded in LLMs, while preserving the core attributes of the original text. We
evaluate LMTransplant across various text-related tasks, demonstrating its
superior performance over existing text augmentation methods. Moreover,
LMTransplant demonstrates exceptional scalability as the size of augmented data
grows.

</details>


### [86] [Evaluating Multilingual and Code-Switched Alignment in LLMs via Synthetic Natural Language Inference](https://arxiv.org/abs/2508.14735)
*Samir Abdaljalil,Erchin Serpedin,Khalid Qaraqe,Hasan Kurban*

Main category: cs.CL

TL;DR: 논문은 합성된 논리 기반 전제-가설 쌍을 생성해 다양한 언어로 번역한 통제된 다국어 NLI 평가 프레임워크를 제안한다. 모노링구얼과 코드스위칭 조건에서 LLM의 추론을 평가하고 번역의 의미 보존을 임베딩 유사도와 교차언어 정렬 시각화로 검증한다. 코드스위칭은 성능을 저해하지 않으며 때로 개선 효과를 보였고, 번역으로 유도된 어휘 변이가 정규화 효과를 줄 수 있음을 시사한다.


<details>
  <summary>Details</summary>
Motivation: 대형언어모델이 다국어 환경에서 널리 쓰이지만 언어 간 일관성 있는 논리적 정렬 능력을 체계적으로 평가하는 연구가 부족하기 때문에, 통제된 환경에서 다국어 NLI 성능을 엄밀히 시험할 필요가 있다.

Method: 논리 규칙에 기반한 합성 전제-가설 쌍을 생성하고 이를 유형학적으로 다양한 언어들로 번역해 데이터셋을 구성한다. 모노링구얼 및 코드스위칭(혼합 언어) 조건에서 LLM 성능을 평가하고, 임베딩 기반 유사도 분석과 교차언어 정렬 시각화를 통해 번역된 쌍의 의미 보존을 검증한다.

Result: 코드스위칭은 성능 저하를 초래하지 않았고, 일부 경우 성능을 향상시키는 효과를 보였다. 이는 번역으로 인한 어휘 다양성이 모델에게 정규화 신호를 제공할 수 있음을 시사한다. 동시에 현재 LLM의 교차언어 추론은 잠재력과 취약성(특정 언어 조합에서의 약점)을 모두 드러냈다.

Conclusion: 제안된 프레임워크는 다국어 NLI의 세밀한 스트레스 테스트를 가능하게 하며, 코드스위칭이 다국어 견고성을 개선할 수 있는 유망한 수단임을 제시한다. 연구 코드는 공개되어 있다.

Abstract: Large language models (LLMs) are increasingly applied in multilingual
contexts, yet their capacity for consistent, logically grounded alignment
across languages remains underexplored. We present a controlled evaluation
framework for multilingual natural language inference (NLI) that generates
synthetic, logic-based premise-hypothesis pairs and translates them into a
typologically diverse set of languages. This design enables precise control
over semantic relations and allows testing in both monolingual and
mixed-language (code-switched) conditions. Surprisingly, code-switching does
not degrade, and can even improve, performance, suggesting that
translation-induced lexical variation may serve as a regularization signal. We
validate semantic preservation through embedding-based similarity analyses and
cross-lingual alignment visualizations, confirming the fidelity of translated
pairs. Our findings expose both the potential and the brittleness of current
LLM cross-lingual reasoning, and identify code-switching as a promising lever
for improving multilingual robustness. Code available at:
https://github.com/KurbanIntelligenceLab/nli-stress-testing

</details>


### [87] [TransLLM: A Unified Multi-Task Foundation Framework for Urban Transportation via Learnable Prompting](https://arxiv.org/abs/2508.14782)
*Jiaming Leng,Yunying Bi,Chuan Qin,Bing Yin,Yanyong Zhang,Chao Wang*

Main category: cs.CL

TL;DR: 제안된 TransLLM은 경량 시공간 인코더와 LLM을 연동한 통합 파운데이션 프레임워크로, 강화학습 기반 인스턴스 수준 프롬프트 라우팅을 통해 교통 예측 및 계획 작업에서 우수한 성능과 제로샷 일반화를 보인다.


<details>
  <summary>Details</summary>
Motivation: 기존의 소규모 딥러닝 모델은 작업별 특화에 따른 일반화 한계와 데이터 의존성 문제를 가지며, LLM은 구조화된 시공간 데이터와 수치적 추론에 약점을 보인다. 이를 결합해 두 접근의 장점을 살린 통합 모델 필요.

Method: 경량 시공간 인코더(확장 시간 컨볼루션, 이중 인접 행렬 기반 그래프 어텐션), 구조화 임베딩을 통한 LLM 인터페이스, 인스턴스 수준 프롬프트 라우팅(강화학습으로 학습) 및 특화 출력층으로 구성된 프레임워크.

Result: 7개 데이터셋과 3개 작업(회귀 및 계획 문제)에서 10개 베이스라인 대비 경쟁력 있는 성능을 보였고, 감독 및 제로샷 설정 모두에서 강한 일반화와 교차 작업 적응성을 확인.

Conclusion: TransLLM은 시공간 패턴을 LLM이 활용할 수 있는 형식으로 변환하고, 동적 프롬프트 조합으로 개인화된 추론을 가능케 하여 교통 도메인 전반에서 유용한 파운데이션 모델 솔루션을 제시한다.

Abstract: Urban transportation systems encounter diverse challenges across multiple
tasks, such as traffic forecasting, electric vehicle (EV) charging demand
prediction, and taxi dispatch. Existing approaches suffer from two key
limitations: small-scale deep learning models are task-specific and
data-hungry, limiting their generalizability across diverse scenarios, while
large language models (LLMs), despite offering flexibility through natural
language interfaces, struggle with structured spatiotemporal data and numerical
reasoning in transportation domains. To address these limitations, we propose
TransLLM, a unified foundation framework that integrates spatiotemporal
modeling with large language models through learnable prompt composition. Our
approach features a lightweight spatiotemporal encoder that captures complex
dependencies via dilated temporal convolutions and dual-adjacency graph
attention networks, seamlessly interfacing with LLMs through structured
embeddings. A novel instance-level prompt routing mechanism, trained via
reinforcement learning, dynamically personalizes prompts based on input
characteristics, moving beyond fixed task-specific templates. The framework
operates by encoding spatiotemporal patterns into contextual representations,
dynamically composing personalized prompts to guide LLM reasoning, and
projecting the resulting representations through specialized output layers to
generate task-specific predictions. Experiments across seven datasets and three
tasks demonstrate the exceptional effectiveness of TransLLM in both supervised
and zero-shot settings. Compared to ten baseline models, it delivers
competitive performance on both regression and planning problems, showing
strong generalization and cross-task adaptability. Our code is available at
https://github.com/BiYunying/TransLLM.

</details>


### [88] [Evaluating Retrieval-Augmented Generation vs. Long-Context Input for Clinical Reasoning over EHRs](https://arxiv.org/abs/2508.14817)
*Skatje Myers,Dmitriy Dligach,Timothy A. Miller,Samantha Barr,Yanjun Gao,Matthew Churpek,Anoop Mayampurath,Majid Afshar*

Main category: cs.CL

TL;DR: 저자는 장문의 임상 전자건강기록(EHR)을 LLM으로 처리할 때 발생하는 입력 길이 문제를 해결하기 위해 RAG(검색-증강 생성)를 평가한다. 세 가지 재현 가능한 임상 태스크(영상시술 추출, 항생제 사용 타임라인 생성, 주요 진단 식별)를 실제 입원 환자 EHR로 실험하여, RAG가 최근 임상노트만 사용하는 방법과 비교해 유사하거나 더 나은 성능을 적은 토큰으로 달성함을 보였다.


<details>
  <summary>Details</summary>
Motivation: 임상 노트가 매우 길고 중복·잡음이 많아 LLM의 컨텍스트 창을 초과하는 경우가 많다. 전체 EHR에서 관련 문단을 검색해 입력 토큰을 줄이는 RAG의 실효성을 확인하려는 필요성.

Method: 세 가지 임상 태스크를 정의하고 실제 입원 환자 EHR를 사용해 실험. 세 가지 최신 LLM을 선택해 제공 컨텍스트 양을 달리하며(타깃 텍스트 검색 기반 RAG vs 최근 노트 전체) 성능 비교. 모델의 전체 컨텍스트 사용과의 비교도 수행.

Result: RAG는 최근 노트만 사용하는 접근법과 성능이 비슷하거나 우수했고, 모델의 전체 컨텍스트를 사용하는 성능에 근접하면서 요구되는 입력 토큰 수는 크게 줄였다.

Conclusion: 컨텍스트 창이 점점 커지는 최신 모델 시대에도 RAG는 여전히 경쟁력 있고 효율적인 접근법으로 남아 있으며, 임상 EHR 처리에 실용적 대안이 될 수 있다.

Abstract: Electronic health records (EHRs) are long, noisy, and often redundant, posing
a major challenge for the clinicians who must navigate them. Large language
models (LLMs) offer a promising solution for extracting and reasoning over this
unstructured text, but the length of clinical notes often exceeds even
state-of-the-art models' extended context windows. Retrieval-augmented
generation (RAG) offers an alternative by retrieving task-relevant passages
from across the entire EHR, potentially reducing the amount of required input
tokens. In this work, we propose three clinical tasks designed to be replicable
across health systems with minimal effort: 1) extracting imaging procedures, 2)
generating timelines of antibiotic use, and 3) identifying key diagnoses. Using
EHRs from actual hospitalized patients, we test three state-of-the-art LLMs
with varying amounts of provided context, using either targeted text retrieval
or the most recent clinical notes. We find that RAG closely matches or exceeds
the performance of using recent notes, and approaches the performance of using
the models' full context while requiring drastically fewer input tokens. Our
results suggest that RAG remains a competitive and efficient approach even as
newer models become capable of handling increasingly longer amounts of text.

</details>


### [89] [Long Chain-of-Thought Reasoning Across Languages](https://arxiv.org/abs/2508.14828)
*Josh Barua,Seun Eisape,Kayo Yin,Alane Suhr*

Main category: cs.CL

TL;DR: The paper studies long chain-of-thought (CoT) reasoning across French, Japanese, Latvian, and Swahili by translating two English reasoning datasets and fine-tuning Qwen 2.5 and Qwen 3. It finds language-dependent transfer from English pivoting, partial mitigation by multilingual pretraining in Qwen 3, and varying data quality/scale trade-offs across languages.


<details>
  <summary>Details</summary>
Motivation: Current CoT reasoning successes are English-centric; the paper aims to understand cross-lingual transfer of long CoTs and provide resources for multilingual reasoning.

Method: Translate two English reasoning datasets into French, Japanese, Latvian, and Swahili; fine-tune Qwen 2.5 (7B) and Qwen 3 (8B); run systematic experiments comparing English-pivot reasoning vs. native-language reasoning and evaluate effects of multilingual pretraining and fine-tuning data size/quality.

Result: Three main findings: (1) English pivoting helps variably — no benefit for French, helpful for Japanese/Latvian, insufficient for Swahili; (2) Qwen 3's multilingual pretraining reduces but doesn't eliminate gaps; lightweight fine-tuning (1k traces) can improve Swahili by >30%; (3) data quality vs. scale trade-offs differ by language: small curated sets work for English/French, larger noisier corpora better for Swahili/Latvian.

Conclusion: The study clarifies when long CoTs transfer across languages and supplies translated datasets to support equitable multilingual reasoning research.

Abstract: Scaling inference through long chains-of-thought (CoTs) has unlocked
impressive reasoning capabilities in large language models (LLMs), yet the
reasoning process remains almost exclusively English-centric. We construct
translated versions of two popular English reasoning datasets, fine-tune Qwen
2.5 (7B) and Qwen 3 (8B) models, and present a systematic study of long CoT
generation across French, Japanese, Latvian, and Swahili. Our experiments
reveal three key findings. First, the efficacy of using English as a pivot
language varies by language: it provides no benefit for French, improves
performance when used as the reasoning language for Japanese and Latvian, and
proves insufficient for Swahili where both task comprehension and reasoning
remain poor. Second, extensive multilingual pretraining in Qwen 3 narrows but
does not eliminate the cross-lingual performance gap. A lightweight fine-tune
using only 1k traces still improves performance by over 30\% in Swahili. Third,
data quality versus scale trade-offs are language dependent: small, carefully
curated datasets suffice for English and French, whereas larger but noisier
corpora prove more effective for Swahili and Latvian. Together, these results
clarify when and why long CoTs transfer across languages and provide translated
datasets to foster equitable multilingual reasoning research.

</details>


### [90] [MedReseacher-R1: Expert-Level Medical Deep Researcher via A Knowledge-Informed Trajectory Synthesis Framework](https://arxiv.org/abs/2508.14880)
*Ailing Yu,Lan Yao,Jingnan Liu,Zhe Chen,Jiajun Yin,Yuan Wang,Xinhao Liao,Zhiling Ye,Ji Li,Yun Yue,Hansong Xiao,Hualei Zhou,Chunxiao Guo,Peng Wei,Jinjie Gu*

Main category: cs.CL

TL;DR: 이 논문은 의료 분야에 특화된 LLM 기반 연구 에이전트( MedResearcher-R1-32B )를 제안한다. 핵심은 의료 지식 그래프로부터 희소 엔티티의 장(長) 체인을 추출해 복잡한 다중-홉 QA를 합성하고, 전용 의료 검색 엔진을 통합해 정확한 정보 검색과 종합을 가능하게 한 것이다. 두 단계(SFT + 온라인 RL) 훈련으로 의료 벤치마크에서 SOTA 성능을 달성했다.


<details>
  <summary>Details</summary>
Motivation: 일반 목적의 LLM 기반 에이전트는 복잡한 의료 추론에 필요한 촘촘한(밀도 높은) 의료 지식과 의료 맥락에 맞춘 전문 검색 도구가 부족해 성능이 낮다는 문제를 해결하려 함.

Method: (1) 의료 지식 그래프에서 희귀 의료 엔티티 주변의 서브그래프에서 가장 긴 경로를 추출해 다중-홉 질문-답변 쌍을 합성하는 데이터 합성 프레임워크 개발, (2) 범용 도구와 함께 작동하는 사설 의료 검색 엔진 통합, (3) 감독 미세조정과 온라인 강화학습을 결합한 2단계 훈련(복합 보상) 수행.

Result: 12개 의료 전문 분야에서 평균 4.2회의 도구 상호작용을 포함한 2100+ 다양한 궤적을 생성했으며, MedResearcher-R1-32B(32B)는 의료 벤치마크에서 새로운 SOTA를 수립했고 일반 연구 과제에서도 경쟁력 있는 성능을 보였음.

Conclusion: 도메인 특화된 데이터 생성, 도구 설계, 아키텍처 및 훈련 전략을 결합하면 규모가 큰 독점 모델보다 작은 오픈소스 모델이 특정 분야에서 더 우수한 성능을 낼 수 있음을 보여줌.

Abstract: Recent developments in Large Language Model (LLM)-based agents have shown
impressive capabilities spanning multiple domains, exemplified by deep research
systems that demonstrate superior performance on complex information-seeking
and synthesis tasks. While general-purpose deep research agents have shown
impressive capabilities, they struggle significantly with medical domain
challenges, as evidenced by leading proprietary systems achieving limited
accuracy on complex medical benchmarks. The key limitations are: (1) the model
lacks sufficient dense medical knowledge for clinical reasoning, and (2) the
framework is constrained by the absence of specialized retrieval tools tailored
for medical contexts.We present a medical deep research agent that addresses
these challenges through two core innovations. First, we develop a novel data
synthesis framework using medical knowledge graphs, extracting the longest
chains from subgraphs around rare medical entities to generate complex
multi-hop question-answer pairs. Second, we integrate a custom-built private
medical retrieval engine alongside general-purpose tools, enabling accurate
medical information synthesis. Our approach generates 2100+ diverse
trajectories across 12 medical specialties, each averaging 4.2 tool
interactions.Through a two-stage training paradigm combining supervised
fine-tuning and online reinforcement learning with composite rewards, our
MedResearcher-R1-32B model demonstrates exceptional performance, establishing
new state-of-the-art results on medical benchmarks while maintaining
competitive performance on general deep research tasks. Our work demonstrates
that strategic domain-specific innovations in architecture, tool design, and
training data construction can enable smaller open-source models to outperform
much larger proprietary systems in specialized domains.

</details>


### [91] [Quantization Meets dLLMs: A Systematic Study of Post-training Quantization for Diffusion LLMs](https://arxiv.org/abs/2508.14896)
*Haokun Lin,Haobo Xu,Yichen Wu,Ziyu Guo,Renrui Zhang,Zhichao Lu,Ying Wei,Qingfu Zhang,Zhenan Sun*

Main category: cs.CL

TL;DR: This paper is the first systematic study on post-training quantization (PTQ) for diffusion-based large language models (dLLMs). It identifies activation outliers as a key challenge for low-bit quantization, implements state-of-the-art PTQ methods, and evaluates quantization across bit-width, method, task, and model type to give practical insights for efficient dLLM deployment.


<details>
  <summary>Details</summary>
Motivation: Diffusion LLMs offer an alternative to autoregressive LLMs with full attention and denoising decoding, but are too large for edge deployment. PTQ has successfully compressed AR LLMs, yet its applicability to dLLMs is unexplored. The paper aims to fill this gap and enable efficient deployment of dLLMs.

Method: Analyze activation distributions to find outliers, implement current PTQ techniques on dLLMs, and run comprehensive evaluations across four dimensions: bit-width, quantization method, task category, and model variant. Provide empirical analysis of quantization behavior and challenges.

Result: Found activation outliers that dominate dynamic range and hinder low-bit quantization. Evaluations across tasks and models reveal how different PTQ methods and bit-widths affect performance, yielding practical insights for quantizing dLLMs. Code and setups will be released.

Conclusion: Activation outliers are a major barrier to low-bit PTQ for diffusion LLMs. The paper delivers the first systematic quantization study for dLLMs and provides guidelines and empirical data to guide future efficient deployment work.

Abstract: Recent advances in diffusion large language models (dLLMs) have introduced a
promising alternative to autoregressive (AR) LLMs for natural language
generation tasks, leveraging full attention and denoising-based decoding
strategies. However, the deployment of these models on edge devices remains
challenging due to their massive parameter scale and high resource demands.
While post-training quantization (PTQ) has emerged as a widely adopted
technique for compressing AR LLMs, its applicability to dLLMs remains largely
unexplored. In this work, we present the first systematic study on quantizing
diffusion-based language models. We begin by identifying the presence of
activation outliers, characterized by abnormally large activation values that
dominate the dynamic range. These outliers pose a key challenge to low-bit
quantization, as they make it difficult to preserve precision for the majority
of values. More importantly, we implement state-of-the-art PTQ methods and
conduct a comprehensive evaluation across multiple task types and model
variants. Our analysis is structured along four key dimensions: bit-width,
quantization method, task category, and model type. Through this
multi-perspective evaluation, we offer practical insights into the quantization
behavior of dLLMs under different configurations. We hope our findings provide
a foundation for future research in efficient dLLM deployment. All codes and
experimental setups will be released to support the community.

</details>


### [92] [Benchmarking Sociolinguistic Diversity in Swahili NLP: A Taxonomy-Guided Approach](https://arxiv.org/abs/2508.14051)
*Kezia Oketch,John P. Lalor,Ahmed Abbasi*

Main category: cs.CL

TL;DR: This paper presents a taxonomy-guided evaluation of Swahili NLP using 2,170 health-related free-text responses from Kenyan speakers, analyzing sociolinguistic variation and model errors across pre-trained and instruction-tuned language models.


<details>
  <summary>Details</summary>
Motivation: Address gaps in sociolinguistic diversity in Swahili NLP and provide culturally grounded evaluation methods to reveal how sociolinguistic variation (tribal influences, urban vernacular, code-mixing, loanwords) affects model performance.

Method: Collected 2,170 free-text health-related responses from Kenyan Swahili speakers; constructed a structured taxonomy capturing sociolinguistic phenomena; evaluated model predictions from pre-trained and instruction-tuned language models through the taxonomy to analyze error patterns.

Result: Data shows strong tribal influences, urban vernacular, code-mixing, and loanwords; taxonomy-guided analysis reveals specific failure modes and performance disparities in both pre-trained and instruction-tuned models.

Conclusion: The taxonomy and dataset advance culturally grounded evaluation frameworks for Swahili NLP and highlight that sociolinguistic variation materially shapes model performance, implying the need for more diverse evaluation and datasets.

Abstract: We introduce the first taxonomy-guided evaluation of Swahili NLP, addressing
gaps in sociolinguistic diversity. Drawing on health-related psychometric
tasks, we collect a dataset of 2,170 free-text responses from Kenyan speakers.
The data exhibits tribal influences, urban vernacular, code-mixing, and
loanwords. We develop a structured taxonomy and use it as a lens for examining
model prediction errors across pre-trained and instruction-tuned language
models. Our findings advance culturally grounded evaluation frameworks and
highlight the role of sociolinguistic variation in shaping model performance.

</details>


### [93] [Contrastive Analysis of Constituent Order Preferences Within Adverbial Roles in English and Chinese News: A Large-Language-Model-Driven Approach](https://arxiv.org/abs/2508.14054)
*Yiran Rex Ma*

Main category: cs.CL

TL;DR: LLM로 주석된 영중(英中) 뉴스 코퍼스를 바탕으로, 부사구 등 기능적 청크의 위치 선호와 분포 패턴을 비교 분석해 영어는 기능 청크의 후치 경향, 중국어는 전치 경향을 보이며 정보 구조에 따라 유연하게 순서가 조정된다는 결론을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 영어와 중국어 뉴스의 구성 순서(특히 부사역할을 하는 기능적 청크)의 차이를 실증적으로 밝히고, 정보 구조와 화용 목적이 어순에 미치는 영향을 탐구하기 위함.

Method: LLM으로 주석된 비교 가능한 영어-중국어 뉴스 코퍼스를 사용해 기능적 청크의 위치(전/후치)와 분포를 통계적으로 분석하고, SVO 구조 및 공출현 사례에서의 순서 조정 양상을 조사함.

Result: (1) 영어 뉴스는 핵심 정보의 선형 서술을 선호해 기능 청크가 주로 후치되고, 중국어 뉴스는 배경 중심의 제시를 선호해 기능 청크가 주로 전치됨. (2) SVO 구조에서도 두 언어 모두 기능 청크 분포 차이를 보이나 중국어의 전치 성향이 더 뚜렷하고 영어의 후치 성향은 더 완만함. (3) 기능 블록이 공출현할 때 양 언어 모두 높은 유연성을 보이며 정보·화용 목적에 따라 순서가 조정됨.

Conclusion: 어순은 체계적 선호와 동적 적응성을 동시에 지니며, 본 연구 결과는 영중 정보 구조의 대조 연구에 대한 새로운 실증적 근거를 제공한다.

Abstract: Based on comparable English-Chinese news corpora annotated by Large Language
Model (LLM), this paper attempts to explore the differences in constituent
order of English-Chinese news from the perspective of functional chunks with
adverbial roles, and analyze their typical positional preferences and
distribution patterns. It is found that: (1) English news prefers linear
narrative of core information first, and functional chunks are mostly
post-positioned, while Chinese news prefers overall presentation mode of
background first, and functional chunks are often pre-positioned; (2) In SVO
structure, both English and Chinese news show differences in the distribution
of functional chunks, but the tendency of Chinese pre-positioning is more
significant, while that of English post-positioning is relatively mild; (3)
When function blocks are co-occurring, both English and Chinese news show high
flexibility, and the order adjustment is driven by information and pragmatic
purposes. The study reveals that word order has both systematic preference and
dynamic adaptability, providing new empirical support for contrastive study of
English-Chinese information structure.

</details>


### [94] [Confidence Estimation for Text-to-SQL in Large Language Models](https://arxiv.org/abs/2508.14056)
*Sepideh Entezari Maleki,Mohammadreza Pourreza,Davood Rafiei*

Main category: cs.CL

TL;DR: 본 논문은 LLM 기반 text-to-SQL 출력의 신뢰도(Confidence)를 평가하는 방법을 연구한다. 블랙박스와 화이트박스 전략을 비교하고, 일관성 기반 방법(블랙박스)과 SQL 문법을 활용한 로그해석(화이트박스)이 효과적임을 보인다. 쿼리 실행(execution) 정보를 보강 신호로 사용하면 성능이 향상된다.


<details>
  <summary>Details</summary>
Motivation: LLM으로 생성된 SQL의 신뢰도를 외부 정답 없이 평가하는 것이 중요하며, 모델 내부 접근성이 제한된 상황(블랙박스 vs 화이트박스)에서도 신뢰도 추정 방법이 필요하다.

Method: 블랙박스: 일관성(Consistency) 기반 방법 등 다양한 black-box 전략을 평가. 화이트박스: LLM의 로짓(logit)을 SQL 문법 인지 방식으로 해석하는 기법을 적용. 추가적으로 쿼리 실행 기반 근거(execution grounding)를 결합하여 신호를 보강.

Result: 평가 결과, 블랙박스에서는 consistency 기반 방법이 우수했고, 화이트박스에서는 SQL 문법을 반영한 로그해석이 우수했다. 또한 쿼리 실행 정보를 보강 신호로 사용하면 두 접근 모두 성능이 개선되었다.

Conclusion: LLM 환경에서 text-to-SQL 신뢰도 추정은 접근성에 따라 적절한 방법을 선택할 수 있으며, 실행 기반 보강은 양쪽 접근 모두에 유의미한 성능 향상을 제공한다.

Abstract: Confidence estimation for text-to-SQL aims to assess the reliability of
model-generated SQL queries without having access to gold answers. We study
this problem in the context of large language models (LLMs), where access to
model weights and gradients is often constrained. We explore both black-box and
white-box confidence estimation strategies, evaluating their effectiveness on
cross-domain text-to-SQL benchmarks. Our evaluation highlights the superior
performance of consistency-based methods among black-box models and the
advantage of SQL-syntax-aware approaches for interpreting LLM logits in
white-box settings. Furthermore, we show that execution-based grounding of
queries provides a valuable supplementary signal, improving the effectiveness
of both approaches.

</details>


### [95] [GRILE: A Benchmark for Grammar Reasoning and Explanation in Romanian LLMs](https://arxiv.org/abs/2508.14279)
*Adrian-Marius Dumitran,Alexandra-Mihaela Danila,Angela-Liliana Dumitran*

Main category: cs.CL

TL;DR: GRILE은 루마니아의 고등학교·대학 입시 문제로 구성된 1,151개의 객관식 문항 벤치마크로, LLM의 정답 선택 능력과 설명 생성 능력을 평가한다. Gemini 2.5 Pro가 최고 성능(83%)을 보였지만 다수의 오픈모델은 65% 미만이며, 생성된 설명의 48%는 사실·교육적 오류를 포함한다.


<details>
  <summary>Details</summary>
Motivation: 저자들은 LLM이 저자원 언어(루마니아어) 교육에서 얼마나 신뢰할 수 있는지 평가하기 위해 실제 시험 문제를 활용한 벤치마크가 필요하다고 판단했다.

Method: National Evaluation, Baccalaureate, 대학입시 등 루마니아 고사에서 1,151개의 객관식 문제를 수집해 GRILE 벤치마크를 구성하고, 7개의 최신 다국어 및 루마니아 특화 모델을 대상으로 정답 선택과 설명 생성 두 가지 능력을 평가했다. 전문가 리뷰를 통해 설명의 사실성·교육적 적합성도 평가했다.

Result: Gemini 2.5 Pro가 83% 정확도로 최고 성능을 보였고 대부분의 오픈소스 모델은 65% 미만이었다. 생성된 설명의 48%가 사실적 또는 교육적 결함을 포함했고, 형태론과 DOOM3 맞춤법 규칙 적용에서 체계적 약점이 드러났다.

Conclusion: GRILE은 저자원 언어의 교육적 응용에서 LLM의 신뢰성 문제와 설명 제어의 필요성을 부각시키며, 향후 연구를 위한 데이터·코드·웹 데모를 공개한다.

Abstract: LLMs (Large language models) have revolutionized NLP (Natural Language
Processing), yet their pedagogical value for low-resource languages remains
unclear. We present GRILE (Grammar Romanian Inference and Language
Explanations) , the first open benchmark of 1,151 multiple-choice questions
harvested from Romanian high-stakes exams (National Evaluation, Baccalaureate,
university admissions). GRILE enables us to probe two complementary abilities
of seven state-of-the-art multilingual and Romanian-specific LLMs: (i)
selecting the correct answer, and (ii) producing linguistically accurate
explanations. While Gemini 2.5 Pro reaches 83% accuracy, most open-weight
models stay below 65%, and 48% of their explanations contain factual or
pedagogical flaws according to expert review. A detailed error analysis
pinpoints systematic weaknesses in morphology and in applying the latest DOOM3
orthographic norms. All data, code and a public web demo are released to
catalyze future research. Our findings expose open challenges for trustworthy
educational NLP in low-resource settings and establish GRILE as a new test-bed
for controllable explanation generation and evaluation.

</details>


### [96] [EmoTale: An Enacted Speech-emotion Dataset in Danish](https://arxiv.org/abs/2508.14548)
*Maja J. Hjuler,Harald V. Skat-Rørdam,Line H. Clemmensen,Sneha Das*

Main category: cs.CL

TL;DR: 새로 만든 EmoTale 코퍼스는 덴마크어와 영어로 된 연기된 감정 음성 데이터로, SSLM 임베딩을 이용한 음성 감정 인식(SER) 실험에서 최대 UAR 64.1%를 기록해 기존 덴마크 데이터셋(DES)과 유사한 성능을 보였다.


<details>
  <summary>Details</summary>
Motivation: 작고 자주 사용되지 않는 언어(예: 덴마크어)에 대해 기능적(감정) 음성 데이터셋이 부족하므로, 덴마크어 및 영어 감정 음성 코퍼스를 구축해 감정 인식 연구를 지원하려는 목적.

Method: 연기된 감정 레이블이 부착된 덴마크어·영어 음성 데이터셋(EmoTale)을 수집·구성하고, self-supervised speech model(SSLM) 임베딩과 openSMILE의 핸드크래프트 특성 둘 다를 사용해 SER 모델을 학습·평가(leave-one-speaker-out 교차검증 포함).

Result: SSLM 임베딩이 openSMILE보다 우수했으며, 최고 모델은 EmoTale에서 UAR 64.1%를 달성. 이 성능은 기존 덴마크 감정 음성 데이터셋(DES)과 비교해 유사한 수준임.

Conclusion: EmoTale은 덴마크어 감정 음성 데이터의 공백을 메우며, SSLM 기반 피처가 감정 인식에 효과적임을 보였다. 데이터셋은 향후 SER 연구 및 낮은 자원 언어 연구에 유용할 것으로 기대됨.

Abstract: While multiple emotional speech corpora exist for commonly spoken languages,
there is a lack of functional datasets for smaller (spoken) languages, such as
Danish. To our knowledge, Danish Emotional Speech (DES), published in 1997, is
the only other database of Danish emotional speech. We present EmoTale; a
corpus comprising Danish and English speech recordings with their associated
enacted emotion annotations. We demonstrate the validity of the dataset by
investigating and presenting its predictive power using speech emotion
recognition (SER) models. We develop SER models for EmoTale and the reference
datasets using self-supervised speech model (SSLM) embeddings and the openSMILE
feature extractor. We find the embeddings superior to the hand-crafted
features. The best model achieves an unweighted average recall (UAR) of 64.1%
on the EmoTale corpus using leave-one-speaker-out cross-validation, comparable
to the performance on DES.

</details>


### [97] [Filling the Gap for Uzbek: Creating Translation Resources for Southern Uzbek](https://arxiv.org/abs/2508.14586)
*Mukhammadsaid Mamasaidov,Azizullah Aral,Abror Shopulatov,Mironshoh Inomjonov*

Main category: cs.CL

TL;DR: Southern Uzbek (uzs)를 위한 병렬 데이터셋(약 39.9k 문장)과 997문장 FLORES+ 개발셋, NLLB-200 기반 파인튜닝 모델(lutfiy), 아랍 문자 반공백(half-space) 복원 후처리 기법을 제시하고 공개함.


<details>
  <summary>Details</summary>
Motivation: Southern Uzbek은 약 500만 화자가 있으나 음운·어휘·정서법 차이로 북부 우즈벡과 많이 달라 NLP 자원이 부족함. 이를 해결하기 위해 번역 자원과 모델을 제공하려 함.

Method: 사전, 문학, 웹에서 39,994개 병렬문장 수집 및 997문장 FLORES+ 개발셋 제작; NLLB-200 모델 파인튜닝으로 'lutfiy' 모델 생성; 아랍 문자 스크립트의 반공백 문자를 복원하는 후처리 기법 제안하여 형태소 경계 처리 개선.

Result: 데이터셋, 모델, 후처리 도구를 공개하고, 반공백 복원으로 형태소 경계 처리 성능 향상 보고. Southern Uzbek 및 다른 저자원 언어 연구 촉진 목적의 자원 배포.

Conclusion: 저자원 언어(Southern Uzbek)에 실용적인 번역 데이터와 파인튜닝된 모델을 제공하여 연구·응용 접근성을 높이며, 스크립트 관련 전처리 문제를 후처리로 개선해 언어 처리 품질을 향상시킴.

Abstract: Southern Uzbek (uzs) is a Turkic language variety spoken by around 5 million
people in Afghanistan and differs significantly from Northern Uzbek (uzn) in
phonology, lexicon, and orthography. Despite the large number of speakers,
Southern Uzbek is underrepresented in natural language processing. We present
new resources for Southern Uzbek machine translation, including a 997-sentence
FLORES+ dev set, 39,994 parallel sentences from dictionary, literary, and web
sources, and a fine-tuned NLLB-200 model (lutfiy). We also propose a
post-processing method for restoring Arabic-script half-space characters, which
improves handling of morphological boundaries. All datasets, models, and tools
are released publicly to support future work on Southern Uzbek and other
low-resource languages.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [98] [FinAgentBench: A Benchmark Dataset for Agentic Retrieval in Financial Question Answering](https://arxiv.org/abs/2508.14052)
*Chanyeol Choi,Jihoon Kwon,Alejandro Lopez-Lira,Chaewoon Kim,Minjae Kim,Juneha Hwang,Jaeseon Ha,Hojun Choi,Suyeol Yun,Yongjin Kim,Yongjae Lee*

Main category: cs.IR

TL;DR: 금융 도메인에서 LLM 기반의 다단계 추론을 통한 정보 검색(‘agentic retrieval’) 성능을 평가하기 위해 S&P-100 기업을 대상으로 한 3,429개 전문가 주석 예제의 대규모 벤치마크 FinAgentBench를 제시한다. 문서 유형 선별과 핵심 문단 지정의 두 단계를 분리해 평가하며, SOTA 모델들의 성능과 미세조정의 효과를 분석한다.


<details>
  <summary>Details</summary>
Motivation: 금융 분야는 도메인 지식과 문서 구조에 대한 정교한 추론이 필요한 정보 검색이 필수적이나, 기존 희소/밀집 검색 기법은 정확도가 부족하다. LLM을 이용한 다단계(reasoning) 기반의 검색이 유망하지만, 이를 금융 도메인에서 평가할 벤치마크가 없다.

Method: FinAgentBench를 구축(3,429개 전문가 주석, S&P-100 상장사 대상). 평가를 문서 유형 선택(step1)과 해당 문서 내 핵심 문단 지정(step2)으로 분리하여 LLM 에이전트의 추론·검색 능력을 측정. 여러 최첨단 모델을 시험하고, 타깃 미세조정(targeted fine-tuning)의 효과를 확인.

Result: 분리된 평가 설계로 문맥 길이 제한 문제를 완화하고, 모델들이 문서 유형 판별과 핵심 문단 식별에서 보이는 행동을 정량적으로 분석. 타깃 미세조정을 통해 에이전트식 검색 성능이 유의미하게 향상됨을 보였다.

Conclusion: FinAgentBench는 금융 특화의 검색 중심 LLM 행동 연구를 위한 첫 대규모 벤치마크로서 기초를 제공하며, 데이터셋 공개 및 S&P 500으로의 확장 계획을 통해 연구 촉진을 목표로 한다.

Abstract: Accurate information retrieval (IR) is critical in the financial domain,
where investors must identify relevant information from large collections of
documents. Traditional IR methods-whether sparse or dense-often fall short in
retrieval accuracy, as it requires not only capturing semantic similarity but
also performing fine-grained reasoning over document structure and
domain-specific knowledge. Recent advances in large language models (LLMs) have
opened up new opportunities for retrieval with multi-step reasoning, where the
model ranks passages through iterative reasoning about which information is
most relevant to a given query. However, there exists no benchmark to evaluate
such capabilities in the financial domain. To address this gap, we introduce
FinAgentBench, the first large-scale benchmark for evaluating retrieval with
multi-step reasoning in finance -- a setting we term agentic retrieval. The
benchmark consists of 3,429 expert-annotated examples on S&P-100 listed firms
and assesses whether LLM agents can (1) identify the most relevant document
type among candidates, and (2) pinpoint the key passage within the selected
document. Our evaluation framework explicitly separates these two reasoning
steps to address context limitations. This design enables to provide a
quantitative basis for understanding retrieval-centric LLM behavior in finance.
We evaluate a suite of state-of-the-art models and further demonstrated how
targeted fine-tuning can significantly improve agentic retrieval performance.
Our benchmark provides a foundation for studying retrieval-centric LLM behavior
in complex, domain-specific tasks for finance. We will release the dataset
publicly upon acceptance of the paper and plan to expand and share dataset for
the full S&P 500 and beyond.

</details>


### [99] [A Multi-Agent Approach to Neurological Clinical Reasoning](https://arxiv.org/abs/2508.14063)
*Moran Sorka,Alon Gorenshtein,Dvir Aran,Shahar Shelly*

Main category: cs.IR

TL;DR: LLM들이 신경학적 전문 추론을 수행하는 능력을 평가하기 위해 305문항의 신경학 전문시험 기반 벤치마크를 만들고, 10개 LLM(기본 모델·RAG·다중 에이전트 시스템)을 비교했다. 다중 에이전트 접근이 중간급 모델에서 특히 복잡한 추론 성능을 크게 개선함을 보였다.


<details>
  <summary>Details</summary>
Motivation: LLM의 의료 분야 적용이 늘지만, 신경과학 같은 전문적·추론 중심 영역에서의 체계적 성능 평가와 개선 방법이 부족하여 이를 보완하기 위함.

Method: 이스라엘 신경학 자격시험에서 305문항을 수집해 난이도·개념 통합·추론 복잡도 등 3축으로 분류. 10개 LLM을 기본 모델, RAG(검색 기반 보강), 그리고 새로운 다중 에이전트(질문분석·지식검색·답안합성·검증 등 역할 분리)로 실험 비교. 추가로 MedQA의 155사례로 검증.

Result: OpenAI-o1이 기본 모델 중 최고(90.9%), 전문 의료 모델은 저조(예: Meditron-70B 52.9%). RAG는 일부 향상 제공했으나 복잡 추론에는 제한적. 다중 에이전트 시스템은 특히 중간급 모델에서 큰 폭의 성능 향상(LLaMA 3.3-70B 에이전트: 89.2% vs 기본 69.5%)을 보였고, 레벨3 복잡도 문제에서 유의미한 개선을 이끌어냈다.

Conclusion: 신경학적 복잡 추론 문제는 단순한 RAG로는 한계가 있으며, 전문적 인지 기능을 모사하는 구조화된 다중 에이전트 접근이 복잡한 의료 추론을 크게 향상시켜 임상보조 가능성을 제시한다.

Abstract: Large language models (LLMs) have shown promise in medical domains, but their
ability to handle specialized neurological reasoning requires systematic
evaluation. We developed a comprehensive benchmark using 305 questions from
Israeli Board Certification Exams in Neurology, classified along three
complexity dimensions: factual knowledge depth, clinical concept integration,
and reasoning complexity. We evaluated ten LLMs using base models,
retrieval-augmented generation (RAG), and a novel multi-agent system. Results
showed significant performance variation. OpenAI-o1 achieved the highest base
performance (90.9% accuracy), while specialized medical models performed poorly
(52.9% for Meditron-70B). RAG provided modest benefits but limited
effectiveness on complex reasoning questions. In contrast, our multi-agent
framework, decomposing neurological reasoning into specialized cognitive
functions including question analysis, knowledge retrieval, answer synthesis,
and validation, achieved dramatic improvements, especially for mid-range
models. The LLaMA 3.3-70B-based agentic system reached 89.2% accuracy versus
69.5% for its base model, with substantial gains on level 3 complexity
questions. The multi-agent approach transformed inconsistent subspecialty
performance into uniform excellence, addressing neurological reasoning
challenges that persisted with RAG enhancement. We validated our approach using
an independent dataset of 155 neurological cases from MedQA. Results confirm
that structured multi-agent approaches designed to emulate specialized
cognitive processes significantly enhance complex medical reasoning, offering
promising directions for AI assistance in challenging clinical contexts.

</details>


### [100] [An automatic patent literature retrieval system based on LLM-RAG](https://arxiv.org/abs/2508.14064)
*Yao Ding,Yuqing Wu,Ziyang Ding*

Main category: cs.IR

TL;DR: 이 논문은 대형 언어모델(LLM)과 Retrieval-Augmented Generation(RAG)을 결합한 자동화된 특허 검색 프레임워크를 제안한다. 전처리 모듈, LLM 생성 임베딩 기반 고효율 벡터 검색 엔진, 그리고 RAG 기반 질의 모듈로 구성되며, Google Patents(2006–2024)에서 평가해 우수한 성능을 보였다.


<details>
  <summary>Details</summary>
Motivation: 기존의 키워드/규칙 기반 특허 검색은 복잡한 질의 의도와 도메인 간 의미적 연관을 포착하지 못해 낮은 결과 관련성과 불완전한 검색을 야기하므로 LLM과 RAG를 활용한 지능형 검색 필요성이 제기됨.

Method: (1) 특허 데이터 표준화 전처리, (2) LLM이 생성한 임베딩을 활용한 고효율 벡터 검색 엔진, (3) 외부 문서 검색과 컨텍스트 인식 응답 생성을 결합한 RAG 강화 질의 모듈로 시스템 구성. 평가에선 gpt-3.5-turbo-0125-RAG 설정 사용.

Result: Google Patents 데이터셋에서 제안된 구성은 80.5%의 의미 매칭 정확도와 92.1%의 재현율을 달성해 기존 LLM 기반 베이스라인 대비 약 28%p 향상. 교차 도메인 분류 및 의미적 클러스터링에서도 강한 일반화 성능을 보임.

Conclusion: LLM과 RAG의 통합은 지능형 특허 검색에 효과적이며, 차세대 AI 기반 지식재산 분석 플랫폼 개발을 위한 실용적 토대를 제공함.

Abstract: With the acceleration of technological innovation efficient retrieval and
classification of patent literature have become essential for intellectual
property management and enterprise RD Traditional keyword and rulebased
retrieval methods often fail to address complex query intents or capture
semantic associations across technical domains resulting in incomplete and
lowrelevance results This study presents an automated patent retrieval
framework integrating Large Language Models LLMs with RetrievalAugmented
Generation RAG technology The system comprises three components: 1) a
preprocessing module for patent data standardization, 2) a highefficiency
vector retrieval engine leveraging LLMgenerated embeddings, and 3) a
RAGenhanced query module that combines external document retrieval with
contextaware response generation Evaluations were conducted on the Google
Patents dataset 20062024 containing millions of global patent records with
metadata such as filing date domain and status The proposed gpt35turbo0125RAG
configuration achieved 805 semantic matching accuracy and 92.1% recall
surpassing baseline LLM methods by 28 percentage points The framework also
demonstrated strong generalization in crossdomain classification and semantic
clustering tasks These results validate the effectiveness of LLMRAG integration
for intelligent patent retrieval providing a foundation for nextgeneration
AIdriven intellectual property analysis platforms

</details>


### [101] [Retrieval-Augmented Generation in Industry: An Interview Study on Use Cases, Requirements, Challenges, and Evaluation](https://arxiv.org/abs/2508.14066)
*Lorenz Brehme,Benedikt Dornauer,Thomas Ströhle,Maximilian Ehrhart,Ruth Breu*

Main category: cs.IR

TL;DR: 산업 현장에서 RAG(Retrieval-Augmented Generation) 도입 실태를 13명의 실무자 반구조화 인터뷰로 조사하여 사용 사례, 시스템 요구사항, 실무 과제 및 평가 방법을 정리한 연구.


<details>
  <summary>Details</summary>
Motivation: RAG가 LLM 출력 향상에 널리 주목받고 있으나, 산업 현장에서의 실제 적용 및 과제에 대한 실증적 연구가 부족함.

Method: 반구조화 인터뷰(13명의 산업 실무자)를 통해 RAG의 실제 적용 사례, 요구사항, 도전과제 및 평가 관행을 수집·분석.

Result: 주요 결과로는 RAG의 상용 적용이 주로 도메인 특화된 QA에 국한되고 시스템은 프로토타입 수준임, 데이터 보호·보안·품질이 핵심 요구사항이며 윤리·편향·확장성 문제는 상대적으로 덜 고려됨, 데이터 전처리가 주요 기술적 장애물이고 평가는 주로 인간 중심으로 수행됨.

Conclusion: 산업 적용을 확장하려면 데이터 전처리, 자동화된 평가, 윤리·편향·확장성 대응 등 실무적 과제를 해결해야 하며, 학계·산업 간 추가 연구 및 표준화가 필요함.

Abstract: Retrieval-Augmented Generation (RAG) is a well-established and rapidly
evolving field within AI that enhances the outputs of large language models by
integrating relevant information retrieved from external knowledge sources.
While industry adoption of RAG is now beginning, there is a significant lack of
research on its practical application in industrial contexts. To address this
gap, we conducted a semistructured interview study with 13 industry
practitioners to explore the current state of RAG adoption in real-world
settings. Our study investigates how companies apply RAG in practice, providing
(1) an overview of industry use cases, (2) a consolidated list of system
requirements, (3) key challenges and lessons learned from practical
experiences, and (4) an analysis of current industry evaluation methods. Our
main findings show that current RAG applications are mostly limited to
domain-specific QA tasks, with systems still in prototype stages; industry
requirements focus primarily on data protection, security, and quality, while
issues such as ethics, bias, and scalability receive less attention; data
preprocessing remains a key challenge, and system evaluation is predominantly
conducted by humans rather than automated methods.

</details>


### [102] [OneLoc: Geo-Aware Generative Recommender Systems for Local Life Service](https://arxiv.org/abs/2508.14646)
*Zhipeng Wei,Kuo Cai,Junda She,Jie Chen,Minghao Chen,Yang Zeng,Qiang Luo,Wencong Zeng,Ruiming Tang,Kun Gai,Guorui Zhou*

Main category: cs.IR

TL;DR: OneLoc: an end-to-end generative recommendation model for local life service in Kuaishou that integrates geographic information into tokenization, encoder self-attention, and prompt design, and uses reinforcement learning with geographic and GMV rewards; deployed to 400M daily users with large GMV and order improvements.


<details>
  <summary>Details</summary>
Motivation: Local life recommendations must account for both user interest and real-time user-store geographic relationships; existing generative recommendation models for other scenarios don’t address geo-specific challenges like location-aware tokenization and multi-objective trade-offs (user interest, distance, business metrics).

Method: Introduce geo-aware semantic ID (video+geo tokenization), geo-aware self-attention in encoder (uses video location similarity and user real-time location), neighbor-aware prompt (context from surrounding users/stores); use reinforcement learning with two reward functions (geographic reward and GMV reward) to balance multiple objectives.

Result: Offline and online gains; deployed in Kuaishou local life service serving 400M daily users; reported improvements: +21.016% GMV and +17.891% order numbers.

Conclusion: OneLoc successfully integrates geographic signals into an end-to-end generative recommender and balances multiple objectives via RL, demonstrating strong business impact at scale.

Abstract: Local life service is a vital scenario in Kuaishou App, where video
recommendation is intrinsically linked with store's location information. Thus,
recommendation in our scenario is challenging because we should take into
account user's interest and real-time location at the same time. In the face of
such complex scenarios, end-to-end generative recommendation has emerged as a
new paradigm, such as OneRec in the short video scenario, OneSug in the search
scenario, and EGA in the advertising scenario. However, in local life service,
an end-to-end generative recommendation model has not yet been developed as
there are some key challenges to be solved. The first challenge is how to make
full use of geographic information. The second challenge is how to balance
multiple objectives, including user interests, the distance between user and
stores, and some other business objectives. To address the challenges, we
propose OneLoc. Specifically, we leverage geographic information from different
perspectives: (1) geo-aware semantic ID incorporates both video and geographic
information for tokenization, (2) geo-aware self-attention in the encoder
leverages both video location similarity and user's real-time location, and (3)
neighbor-aware prompt captures rich context information surrounding users for
generation. To balance multiple objectives, we use reinforcement learning and
propose two reward functions, i.e., geographic reward and GMV reward. With the
above design, OneLoc achieves outstanding offline and online performance. In
fact, OneLoc has been deployed in local life service of Kuaishou App. It serves
400 million active users daily, achieving 21.016% and 17.891% improvements in
terms of gross merchandise value (GMV) and orders numbers.

</details>


### [103] [GPT-2 as a Compression Preprocessor: Improving Gzip for Structured Text Domains](https://arxiv.org/abs/2508.14061)
*Anurag Kumar Ojha*

Main category: cs.IR

TL;DR: 도메인 특화 텍스트 포맷(JSON, HTML, 로그 등)은 구문 반복은 적지만 의미적 반복이 있어 일반 패턴 기반 압축기(gzip)가 취약하다. 본 논문은 GPT-2를 이용해 그런 파일들을 사전처리하여 gzip이 더 잘 압축하도록 하는 파이프라인을 제안한다. 실험에서 HTML 파일에서 압축률이 최대 5.8% 향상되었고, 국방 로그에서는 0.34% 향상을 보였다.


<details>
  <summary>Details</summary>
Motivation: 대량의 도메인 특화 데이터(의료 기록, 로그, HTML 등)는 저장·전송을 위해 압축이 필요하나, 기존 패턴 기반 압축기는 의미적 반복을 포착하지 못해 압축 효율이 낮다. 이를 개선하기 위해 언어 모델을 활용한 사전처리 접근을 제안한다.

Method: GPT-2를 도메인 특화 파일의 사전처리기(프리프로세서)로 사용해 파일을 재표현한 뒤, 그 결과물을 gzip과 같은 기존 패턴 기반 압축기에 넘겨 압축한다. 실험은 실제 및 합성 로그, HTML 파일 등 다양한 데이터셋에서 수행되었다.

Result: 제안한 파이프라인 적용 시 HTML 파일에서 최대 약 5.8% 압축률 향상, 국방 로그에서 0.34% 향상을 관찰했다. 다른 데이터 유형에 대해서는 가변적인 개선 결과를 보고한다.

Conclusion: LLM 기반 사전처리는 특정 도메인 포맷에서 기존 압축기의 성능을 일부 개선할 수 있음을 보였다. 개선폭은 데이터 유형에 따라 제한적이며, 실제 적용을 위해선 모델 크기, 처리 비용, 실시간성 등 실용성 고려가 필요하다.

Abstract: In the modern era, large volumes of data are being produced continuously,
especially in domain-specific fields such as medical records and clinical
files, defence logs and HTML-based web traffic. Data with such volume and
complexity needs to be compressed before storing and transmitting efficiently.
Data compression has gained significant attention from modern researchers,
resulting in the development of fast and efficient compression algorithms such
as Gzip. However, since gzip works on the principle of repetition of binary
patterns, one of the limitations of gzip is that domain-specific formats like
JSON, XML, HTML, and log files, while structured, may have semantic repetition
but not syntactic repetition, which gzip finds difficult to compress. In this
article, we propose a GPT-based preprocessor for such domain-specific files. We
propose a pipeline made up of GPT-2 taking domain-specific files as input,
which pattern-based compressors like gzip find difficult to work on. The
preprocessor results are output in a file that is designed for compressors like
gzip. After preprocessing, the gzip works on the other end of the pipeline and
compresses the data as usual. We used different types of both real-world and
synthetically generated data, such as logs and HTML files, for the experiment
of the proposed model. We found promising results and an improvement of the
Defence logs by 0.34 per cent and HTML files by 5.8 per cent.

</details>


### [104] [RewardRank: Optimizing True Learning-to-Rank Utility](https://arxiv.org/abs/2508.14180)
*Gaurav Bhatt,Kiran Koshy Thekumparampil,Tanmay Gangwani,Tesi Xiao,Leonid Sigal*

Main category: cs.IR

TL;DR: 사용자 행동의 복잡한 편향을 학습해 순위의 실제 유틸리티(클릭/구매 확률)를 최적화하는 데이터 기반 랭킹 프레임워크 RewardRank를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 전통적 순위 학습은 단순화된 손실(예: 항목별 관련도 정렬)을 가정해 실제 사용자 편향(위치 편향, 브랜드 선호, 유사성 회피 등)을 반영하지 못해 실제 유틸리티와 불일치한다는 문제의식에서 출발.

Method: 로그 데이터로 전체 순열에 대한 사용자 참여를 추정하는 딥 유틸리티 모델을 학습하고, 미분 가능한 소프트 퍼뮤테이션 연산자를 통해 예측 유틸리티를 극대화하도록 순위 정책을 엔드투엔드로 최적화한다. 평가를 위해 위치 인지 오라클 기반 KD-Eval과 LLM을 이용한 LLM-Eval 두 자동화 프로토콜을 제안.

Result: Baidu-ULTR와 Amazon KDD Cup 등 대규모 벤치마크에서 강력한 베이스라인들을 일관되게 능가함을 보였음.

Conclusion: 사용자 행동 역학을 모델링하고 카운터팩추얼 순위를 고려한 보상 학습이 실제 유틸리티 최적화에 효과적임을 입증.

Abstract: Traditional ranking systems rely on proxy loss functions that assume
simplistic user behavior, such as users preferring a rank list where items are
sorted by hand-crafted relevance. However, real-world user interactions are
influenced by complex behavioral biases, including position bias, brand
affinity, decoy effects, and similarity aversion, which these objectives fail
to capture. As a result, models trained on such losses often misalign with
actual user utility, such as the probability of any click or purchase across
the ranked list. In this work, we propose a data-driven framework for modeling
user behavior through counterfactual reward learning. Our method, RewardRank,
first trains a deep utility model to estimate user engagement for entire item
permutations using logged data. Then, a ranking policy is optimized to maximize
predicted utility via differentiable soft permutation operators, enabling
end-to-end training over the space of factual and counterfactual rankings. To
address the challenge of evaluation without ground-truth for unseen
permutations, we introduce two automated protocols: (i) $\textit{KD-Eval}$,
using a position-aware oracle for counterfactual reward estimation, and (ii)
$\textit{LLM-Eval}$, which simulates user preferences via large language
models. Experiments on large-scale benchmarks, including Baidu-ULTR and the
Amazon KDD Cup datasets, demonstrate that our approach consistently outperforms
strong baselines, highlighting the effectiveness of modeling user behavior
dynamics for utility-optimized ranking. Our code is available at:
https://github.com/GauravBh1010tt/RewardRank

</details>


### [105] [Global-Distribution Aware Scenario-Specific Variational Representation Learning Framework](https://arxiv.org/abs/2508.14493)
*Moyu Zhang,Yujun Jin,Jinxin Hu,Yu Zhang*

Main category: cs.IR

TL;DR: 이 논문은 다중 시나리오 추천에서 시나리오별 고유 표현 학습을 위해 변분 추론 기반의 확률적 모델(GSVR)을 제안한다. 글로벌 분포 기반 다항 분포를 사전 지식으로 사용해 데이터 희소성 상황에서도 견고한 시나리오별 사용자·아이템 분포를 학습한다. 기존 다중 시나리오 방법에 쉽게 적용 가능하며 실험에서 성능 향상을 보였다.


<details>
  <summary>Details</summary>
Motivation: 다중 시나리오 전자상거래 추천에서 사용자와 아이템이 시나리오별로 다른 특성을 갖기 때문에 시나리오 특화 표현이 필요하지만, 시나리오 간 상호작용의 차이로 데이터 희소성 문제가 발생해 시나리오별 표현 학습이 어렵다.

Method: 시나리오별 사용자·아이템에 대해 확률적 분포를 생성하는 변분 추론(VI) 기반 모델을 도입한다. 글로벌 지식 기반의 다항 분포를 사전(prior)로 활용해 유사한 관심의 사용자 및 유사한 사이드 정보를 가진 아이템의 분포들이 유사하도록 규제한다. 이 방법은 기존 다중 시나리오 추천 모델에 쉽게 적용 가능하다.

Result: 다양한 실험에서 GSVR을 기존 다중 시나리오 추천 방법과 결합했을 때 더 견고한 표현 학습과 추천 성능 향상을 확인했다.

Conclusion: GSVR은 데이터 희소성이 심한 시나리오에서도 글로벌 분포 기반 사전을 통해 시나리오 특화 확률적 표현을 안정적으로 학습하게 해, 다중 시나리오 추천의 성능을 향상시킨다.

Abstract: With the emergence of e-commerce, the recommendations provided by commercial
platforms must adapt to diverse scenarios to accommodate users' varying
shopping preferences. Current methods typically use a unified framework to
offer personalized recommendations for different scenarios. However, they often
employ shared bottom representations, which partially hinders the model's
capacity to capture scenario uniqueness. Ideally, users and items should
exhibit specific characteristics in different scenarios, prompting the need to
learn scenario-specific representations to differentiate scenarios. Yet,
variations in user and item interactions across scenarios lead to data sparsity
issues, impeding the acquisition of scenario-specific representations. To learn
robust scenario-specific representations, we introduce a Global-Distribution
Aware Scenario-Specific Variational Representation Learning Framework (GSVR)
that can be directly applied to existing multi-scenario methods. Specifically,
considering the uncertainty stemming from limited samples, our approach employs
a probabilistic model to generate scenario-specific distributions for each user
and item in each scenario, estimated through variational inference (VI).
Additionally, we introduce the global knowledge-aware multinomial distributions
as prior knowledge to regulate the learning of the posterior user and item
distributions, ensuring similarities among distributions for users with akin
interests and items with similar side information. This mitigates the risk of
users or items with fewer records being overwhelmed in sparse scenarios.
Extensive experimental results affirm the efficacy of GSVR in assisting
existing multi-scenario recommendation methods in learning more robust
representations.

</details>


### [106] [DGenCTR: Towards a Universal Generative Paradigm for Click-Through Rate Prediction via Discrete Diffusion](https://arxiv.org/abs/2508.14500)
*Moyu Zhang,Yun Chen,Yujun Jin,Jinxin Hu,Yu Zhang*

Main category: cs.IR

TL;DR: 추천 시스템의 클릭률(CTR) 예측을 위해 시퀀스 생성 대신 샘플 수준의 이산 확산 기반 생성(pretraining)과 감독 미세조정(fine-tuning)을 결합한 DGenCTR 프레임워크를 제안하며, 오프라인 실험과 온라인 A/B 테스트에서 유효성을 검증함.


<details>
  <summary>Details</summary>
Motivation: 기존 생성 모델 기반 연구는 주로 시퀀스(아이템) 생성에 초점을 맞추며, CTR 예측에 필수적인 사용자-아이템 간 교차 특성을 무시해 성능 저하가 발생한다. 생성 모델의 데이터 분포 이해 능력을 활용하되 CTR 특성(교차 특성 보존)에 맞춘 새로운 생성 패러다임이 필요하다.

Method: 샘플 수준의 생성 패러다임을 도입한 두 단계 프레임워크 DGenCTR: (1) 이산 확산 기반 생성형 사전학습 단계로 데이터 분포를 학습하고, (2) CTR 목표의 감독 미세조정 단계로 실제 클릭 예측 성능을 향상시키는 구조.

Result: 다양한 오프라인 실험과 온라인 A/B 테스트에서 제안한 프레임워크의 효과를 확인했다(구체적 수치는 초록에 없음).

Conclusion: 시퀀스 생성 기반 방법 대신 샘플 수준의 이산 확산 생성 프레임워크는 CTR 예측에서 교차 특성 보존 문제를 해결하고 성능 향상을 달성할 수 있다.

Abstract: Recent advances in generative models have inspired the field of recommender
systems to explore generative approaches, but most existing research focuses on
sequence generation, a paradigm ill-suited for click-through rate (CTR)
prediction. CTR models critically depend on a large number of cross-features
between the target item and the user to estimate the probability of clicking on
the item, and discarding these cross-features will significantly impair model
performance. Therefore, to harness the ability of generative models to
understand data distributions and thereby alleviate the constraints of
traditional discriminative models in label-scarce space, diverging from the
item-generation paradigm of sequence generation methods, we propose a novel
sample-level generation paradigm specifically designed for the CTR task: a
two-stage Discrete Diffusion-Based Generative CTR training framework (DGenCTR).
This two-stage framework comprises a diffusion-based generative pre-training
stage and a CTR-targeted supervised fine-tuning stage for CTR. Finally,
extensive offline experiments and online A/B testing conclusively validate the
effectiveness of our framework.

</details>


### [107] [MISS: Multi-Modal Tree Indexing and Searching with Lifelong Sequential Behavior for Retrieval Recommendation](https://arxiv.org/abs/2508.14515)
*Chengcheng Guo,Junda She,Kuo Cai,Shiyao Wang,Qigen Hu,Qiang Luo,Kun Gai,Guorui Zhou*

Main category: cs.IR

TL;DR: Proposes MISS, a tree-based retrieval framework that integrates multi-modal embeddings and lifelong user sequence modeling (Co-GSU, MM-GSU) to improve retrieval in large-scale recommendation systems.


<details>
  <summary>Details</summary>
Motivation: Retrieval stage in large-scale recommender systems rarely exploits users' lifelong sequential behavior due to corpus size, and most methods rely on interaction signals while ignoring multi-modal item information—limiting retrieval accuracy.

Method: Introduce a multi-modal index tree built from multi-modal embeddings to represent item similarity, and two lifelong-sequence search units—Collaborative General Search Unit (Co-GSU) and Multi-Modal General Search Unit (MM-GSU)—to capture diverse user interests for searching within the index.

Result: Abstract claims improved ability to represent item similarity and capture multi-perspective user interests in retrieval, implying better retrieval performance, though no quantitative results are provided in the abstract.

Conclusion: Integrating multi-modal information and lifelong sequence modeling into tree-based retrieval is a promising direction to enhance large-scale recommendation retrieval.

Abstract: Large-scale industrial recommendation systems typically employ a two-stage
paradigm of retrieval and ranking to handle huge amounts of information. Recent
research focuses on improving the performance of retrieval model. A promising
way is to introduce extensive information about users and items. On one hand,
lifelong sequential behavior is valuable. Existing lifelong behavior modeling
methods in ranking stage focus on the interaction of lifelong behavior and
candidate items from retrieval stage. In retrieval stage, it is difficult to
utilize lifelong behavior because of a large corpus of candidate items. On the
other hand, existing retrieval methods mostly relay on interaction information,
potentially disregarding valuable multi-modal information. To solve these
problems, we represent the pioneering exploration of leveraging multi-modal
information and lifelong sequence model within the advanced tree-based
retrieval model. We propose Multi-modal Indexing and Searching with lifelong
Sequence (MISS), which contains a multi-modal index tree and a multi-modal
lifelong sequence modeling module. Specifically, for better index structure, we
propose multi-modal index tree, which is built using the multi-modal embedding
to precisely represent item similarity. To precisely capture diverse user
interests in user lifelong sequence, we propose collaborative general search
unit (Co-GSU) and multi-modal general search unit (MM-GSU) for
multi-perspective interests searching.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [108] [Cooperative SGD with Dynamic Mixing Matrices](https://arxiv.org/abs/2508.14565)
*Soumya Sarkar,Shweta Jain*

Main category: cs.LG

TL;DR: 분산 환경에서 로컬 업데이트 기반 SGD 알고리즘들을 통합한 프레임워크를 제시하여 동적 토폴로지와 비균등 집계를 허용하고, 기존 연구와 비교해 수렴 이론을 개선하거나 동등한 보장을 제공한다.


<details>
  <summary>Details</summary>
Motivation: 기존 분산 SGD 연구들은 고정 토폴로지와 균등한 노드 기여를 가정하는 경우가 많으나, 실험적으로는 비균등 집계와 동적 토폴로지, 클라이언트 선택이 성능을 크게 향상시킴이 관찰되어 이를 이론적으로 뒷받침할 필요가 있다.

Method: 로컬 업데이트 기반의 여러 분산 SGD 알고리즘을 하나의 통일된 수학적 프레임워크로 제시하고, 동적 토폴로지와 비균등 가중치(aggregation) 및 클라이언트 선택을 포함하는 설정에서 수렴 분석을 수행한다.

Result: 제시한 프레임워크 하에서 주요 알고리즘들에 대해 기존 결과보다 개선되거나 동등한 수렴 보장을 증명했으며, 동적 토폴로지와 비균등 집계가 이론적으로 유효함을 보였다.

Conclusion: 동적 네트워크 구성과 비균등 집계 전략을 허용하는 통합 프레임워크는 분산 로컬 업데이트 SGD의 성능 향상 가능성을 이론적으로 뒷받침하며, 실제 엣지/혼합 환경에서의 분산 학습 설계에 유용하다.

Abstract: One of the most common methods to train machine learning algorithms today is
the stochastic gradient descent (SGD). In a distributed setting, SGD-based
algorithms have been shown to converge theoretically under specific
circumstances. A substantial number of works in the distributed SGD setting
assume a fixed topology for the edge devices. These papers also assume that the
contribution of nodes to the global model is uniform. However, experiments have
shown that such assumptions are suboptimal and a non uniform aggregation
strategy coupled with a dynamically shifting topology and client selection can
significantly improve the performance of such models. This paper details a
unified framework that covers several Local-Update SGD-based distributed
algorithms with dynamic topologies and provides improved or matching
theoretical guarantees on convergence compared to existing work.

</details>


### [109] [Your Reward Function for RL is Your Best PRM for Search: Unifying RL and Search-Based TTS](https://arxiv.org/abs/2508.14313)
*Can Jin,Yang Zhou,Qixin Zhang,Hongwu Peng,Di Zhang,Marco Pavone,Ligong Han,Zhang-Wei Hong,Tong Che,Dimitris N. Metaxas*

Main category: cs.LG

TL;DR: AIRL-S unifies RL-based and search-based test-time scaling for LLMs by learning a dense, dynamic process reward model (PRM) via adversarial inverse reinforcement learning (AIRL) combined with group relative policy optimization (GRPO). The learned PRM serves both as an RL critic and as a heuristic for search, removing the need for labeled intermediate process data and improving robustness and generalization.


<details>
  <summary>Details</summary>
Motivation: Current TTS approaches split into RL with sparse rewards (unstable, low sample efficiency) and search guided by static, labeled PRMs (expensive labels, brittle under distribution shift). The paper aims to unify both paradigms and eliminate dependence on labeled intermediate data.

Method: Use AIRL + GRPO to learn a dense PRM directly from correct reasoning traces. At inference, use this PRM for RL rollout criticism and to guide various search algorithms, enabling chain-of-thought extension and mitigating reward hacking.

Result: Across eight benchmarks (mathematics, scientific reasoning, code generation, etc.), AIRL-S improves average performance by ~9% over the base model, matches GPT-4o, and outperforms baseline PRMs trained with labeled data when integrated into multiple search algorithms.

Conclusion: The reward function learned during RL training is an effective, cost-saving PRM for search. AIRL-S provides a robust, unified TTS approach that enhances reasoning, generalization, and mitigates reward-hacking without requiring labeled process data.

Abstract: Test-time scaling (TTS) for large language models (LLMs) has thus far fallen
into two largely separate paradigms: (1) reinforcement learning (RL) methods
that optimize sparse outcome-based rewards, yet suffer from instability and low
sample efficiency; and (2) search-based techniques guided by independently
trained, static process reward models (PRMs), which require expensive human- or
LLM-generated labels and often degrade under distribution shifts. In this
paper, we introduce AIRL-S, the first natural unification of RL-based and
search-based TTS. Central to AIRL-S is the insight that the reward function
learned during RL training inherently represents the ideal PRM for guiding
downstream search. Specifically, we leverage adversarial inverse reinforcement
learning (AIRL) combined with group relative policy optimization (GRPO) to
learn a dense, dynamic PRM directly from correct reasoning traces, entirely
eliminating the need for labeled intermediate process data. At inference, the
resulting PRM simultaneously serves as the critic for RL rollouts and as a
heuristic to effectively guide search procedures, facilitating robust reasoning
chain extension, mitigating reward hacking, and enhancing cross-task
generalization. Experimental results across eight benchmarks, including
mathematics, scientific reasoning, and code generation, demonstrate that our
unified approach improves performance by 9 % on average over the base model,
matching GPT-4o. Furthermore, when integrated into multiple search algorithms,
our PRM consistently outperforms all baseline PRMs trained with labeled data.
These results underscore that, indeed, your reward function for RL is your best
PRM for search, providing a robust and cost-effective solution to complex
reasoning tasks in LLMs.

</details>


### [110] [PersRM-R1: Enhance Personalized Reward Modeling with Reinforcement Learning](https://arxiv.org/abs/2508.14076)
*Mengdi Li,Guanqiao Chen,Xufeng Zhao,Haochen Wen,Shu Yang,Di Wang*

Main category: cs.LG

TL;DR: PersRM-R1은 1~소수의 개인 예시만으로 개인화된 선호를 식별·표현하는 추론 기반 보상 모델 프레임워크다. 합성 데이터 생성과 지도학습 미세조정 후 강화학습 미세조정의 2단계 학습을 결합해 적은 데이터에서도 강건하게 일반화하며, 유사한 크기의 기존 모델보다 성능이 우수하고 더 큰 모델과 동등한 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 기존 보상 모델(RM)은 미세조정 중 인간 가치에 맞추기 위해 사용되지만, 특히 데이터가 제한적이고 도메인이 다양할 때 세밀하고 사용자별 선호를 포착하지 못한다.

Method: 개인 예시가 1개 또는 소수인 상황에서도 개인적 요인을 식별할 수 있도록 추론 기반의 보상 모델을 설계하고, 합성 데이터 생성을 통해 데이터 부족 문제를 보완한 뒤 두 단계(지도학습 미세조정 -> 강화학습 미세조정) 파이프라인으로 학습한다.

Result: 실험에서 PersRM-R1은 같은 규모의 기존 모델을 능가하고, 정확도와 일반화 측면에서 훨씬 큰 모델과 동등한 성능을 달성했다.

Conclusion: 소수의 개인 예시만으로도 효과적인 개인화 보상 모델을 만들 수 있음을 보이며, 개인화된 LLM 개발에 기여할 수 있다.

Abstract: Reward models (RMs), which are central to existing post-training methods, aim
to align LLM outputs with human values by providing feedback signals during
fine-tuning. However, existing RMs struggle to capture nuanced, user-specific
preferences, especially under limited data and across diverse domains. Thus, we
introduce PersRM-R1, the first reasoning-based reward modeling framework
specifically designed to identify and represent personal factors from only one
or a few personal exemplars. To address challenges including limited data
availability and the requirement for robust generalization, our approach
combines synthetic data generation with a two-stage training pipeline
consisting of supervised fine-tuning followed by reinforcement fine-tuning.
Experimental results demonstrate that PersRM-R1 outperforms existing models of
similar size and matches the performance of much larger models in both accuracy
and generalizability, paving the way for more effective personalized LLMs.

</details>


### [111] [KnowDR-REC: A Benchmark for Referring Expression Comprehension with Real-World Knowledge](https://arxiv.org/abs/2508.14080)
*Guanghao Jin,Jingpei Wu,Tianpei Guo,Yiyi Niu,Weidong Zhou,Guoyang Liu*

Main category: cs.LG

TL;DR: This paper introduces KnowDR-REC, a benchmark for referring expression comprehension requiring real-world knowledge and fine-grained multimodal reasoning, includes adversarial negative samples and three new metrics, and shows existing MLLMs struggle on knowledge-driven visual grounding.


<details>
  <summary>Details</summary>
Motivation: Existing REC benchmarks lack real-world knowledge requirements and fine-grained instance annotations, preventing proper evaluation of MLLMs' reasoning, robustness, and anti-hallucination capabilities.

Method: Create KnowDR-REC dataset with real-world knowledge-based expressions, construct negative samples via fine-grained expression editing, and define three new evaluation metrics to probe internal reasoning. Evaluate 16 state-of-the-art multimodal models on this benchmark.

Result: Experiments show current MLLMs perform poorly on knowledge-driven visual grounding. Many models rely on memorized shortcut correlations, leading to decoupling between textual understanding and visual grounding and poor robustness to negative samples.

Conclusion: KnowDR-REC reveals limitations of existing MLLMs and aims to stimulate research on robust, interpretable, knowledge-intensive visual grounding for real-world multimodal systems.

Abstract: Referring Expression Comprehension (REC) is a popular multimodal task that
aims to accurately detect target objects within a single image based on a given
textual expression. However, due to the limitations of earlier models,
traditional REC benchmarks either rely solely on intra-image cues or lack
sufficiently fine-grained instance annotations, making them inadequate for
evaluating the reasoning capabilities of Multi-modal Large Language Models
(MLLMs). To address this gap, we propose a new benchmark, KnowDR-REC,
characterized by three key features: Firstly, it is built upon real-world
knowledge, requiring fine-grained multimodal reasoning across text and image.
Secondly, the dataset includes elaborately constructed negative samples via
fine-grained expression editing, designed to evaluate a model's robustness and
anti-hallucination ability. Lastly, we introduce three novel evaluation metrics
to systematically explore the model's internal reasoning process. We evaluate
16 state-of-the-art multimodal models on KnowDR-REC, with experimental results
showing that existing MLLMs still struggle with knowledge-driven visual
grounding tasks. Furthermore, we observe a decoupling between textual
understanding and visual grounding in MLLMs, where many models are
significantly influenced by memorized shortcut correlations, which severely
affect their behavior on our benchmark and hinder genuine multimodal reasoning.
We anticipate that the proposed benchmark will inspire future research towards
developing more robust, interpretable, and knowledge-intensive visual grounding
frameworks, driving the development of more reliable and robust multimodal
systems for complex real-world scenarios.

</details>


### [112] [Hard Examples Are All You Need: Maximizing GRPO Post-Training Under Annotation Budgets](https://arxiv.org/abs/2508.14094)
*Benjamin Pikus,Pratyush Ranjan Tiwari,Burton Ye*

Main category: cs.LG

TL;DR: Under a fixed labeling budget, selecting the hardest examples from an unlabeled pool for GRPO fine-tuning yields the largest performance gains (up to 47%), while easy examples give the smallest gains.


<details>
  <summary>Details</summary>
Motivation: When acquisition budgets limit the amount of labeled data for aligning/fine-tuning language models, practitioners need guidance on whether to prioritize easy, medium, hard, or random examples to maximize effectiveness.

Method: Evaluate Group Relative Policy Optimization (GRPO) across multiple model sizes and families. Select four subsets (easy, medium, hard, random) from the same unlabeled pool using difficulty estimates from a base model via multi-sample evaluation, then compare downstream performance.

Result: Training on hardest examples produced the largest performance improvements (up to 47%); easy examples produced the smallest improvements. Analysis indicates harder examples offer more learnable opportunities during GRPO.

Conclusion: For budget-constrained post-training with GRPO—especially on reasoning tasks—prioritizing hard examples is the most effective strategy.

Abstract: Collecting high-quality training examples for language model fine-tuning is
expensive, with practical budgets limiting the amount of data that can be
procured. We investigate a critical question for resource-constrained
alignment: under a fixed acquisition budget, should practitioners prioritize
examples that are easy, medium, hard, or of random difficulty? We study Group
Relative Policy Optimization (GRPO) fine-tuning across different model sizes
and families, comparing four subset selection policies chosen from the same
unlabeled pool using base-model difficulty estimates obtained via multi-sample
evaluation. Our experiments reveal that training on the hardest examples yields
the largest performance gains, up to 47%, while training on easy examples yield
the smallest gains. Analysis reveals that this effect arises from harder
examples providing more learnable opportunities during GRPO training. These
findings provide practical guidance for budget-constrained post-training:
prioritizing hard examples yields substantial performance gains on reasoning
tasks when using GRPO.

</details>


### [113] [From AI for Science to Agentic Science: A Survey on Autonomous Scientific Discovery](https://arxiv.org/abs/2508.14111)
*Jiaqi Wei,Yuejin Yang,Xiang Zhang,Yuhan Chen,Xiang Zhuang,Zhangyang Gao,Dongzhan Zhou,Guangshuai Wang,Zhiqiang Gao,Juntai Cao,Zijie Qiu,Xuming He,Qiang Zhang,Chenyu You,Shuangjia Zheng,Ning Ding,Wanli Ouyang,Nanqing Dong,Yu Cheng,Siqi Sun,Lei Bai,Bowen Zhou*

Main category: cs.LG

TL;DR: 이 논문은 대규모 언어모델(LLM)과 멀티모달 시스템을 기반으로 한 자율적 과학 연구(Agentic Science)를 탐구하는 종합 서베이다. 과학적 에이전시를 구성하는 핵심 능력들을 정리하고, 발견 과정을 네 단계 워크플로우로 모델링하며, 생명과학·화학·재료·물리학 분야의 적용 사례와 도전 과제를 통합적으로 제시한다.


<details>
  <summary>Details</summary>
Motivation: AI가 단순한 보조 도구를 넘어 자율적 연구 파트너로 진화하고 있으며, 관련 연구가 분야별로 분산되어 있어 이를 체계적으로 통합·정리할 필요가 있다.

Method: 과정(process)-지향, 자율성(autonomy)-지향, 메커니즘(mechanism)-지향의 세 관점을 통합한 프레임워크를 제안하고, 문헌 리뷰를 통해 AI for Science의 진화, 핵심 능력 5개 도출, 발견의 4단계 워크플로우 모델화, 도메인별 적용 사례 검토, 도전과제 및 향후 기회 정리를 수행함.

Result: Agentic Science 프레임워크 제시, 과학적 에이전시를 뒷받침하는 5가지 핵심 능력 규정(예: 가설 생성, 실험 설계·실행·분석 등), 발견을 4단계로 모델링, 주요 분야별 적용 사례 및 기술·윤리·인프라적 과제 도출.

Conclusion: Agentic Science를 AI-driven 연구의 구조적 패러다임으로 위치시키며, 향후 연구 방향과 해결해야 할 기술·사회적 이슈를 제시한다. 특히 LLM·멀티모달·통합 연구 플랫폼이 자율 과학 실현의 핵심임을 강조한다.

Abstract: Artificial intelligence (AI) is reshaping scientific discovery, evolving from
specialized computational tools into autonomous research partners. We position
Agentic Science as a pivotal stage within the broader AI for Science paradigm,
where AI systems progress from partial assistance to full scientific agency.
Enabled by large language models (LLMs), multimodal systems, and integrated
research platforms, agentic AI shows capabilities in hypothesis generation,
experimental design, execution, analysis, and iterative refinement -- behaviors
once regarded as uniquely human. This survey provides a domain-oriented review
of autonomous scientific discovery across life sciences, chemistry, materials
science, and physics. We unify three previously fragmented perspectives --
process-oriented, autonomy-oriented, and mechanism-oriented -- through a
comprehensive framework that connects foundational capabilities, core
processes, and domain-specific realizations. Building on this framework, we (i)
trace the evolution of AI for Science, (ii) identify five core capabilities
underpinning scientific agency, (iii) model discovery as a dynamic four-stage
workflow, (iv) review applications across the above domains, and (v) synthesize
key challenges and future opportunities. This work establishes a
domain-oriented synthesis of autonomous scientific discovery and positions
Agentic Science as a structured paradigm for advancing AI-driven research.

</details>


### [114] [FedEve: On Bridging the Client Drift and Period Drift for Cross-device Federated Learning](https://arxiv.org/abs/2508.14539)
*Tao Shen,Zexi Li,Didi Zhu,Ziyu Zhao,Chao Wu,Fei Wu*

Main category: cs.LG

TL;DR: FedEve는 교차-디바이스 연합학습에서 부분 참여로 인해 발생하는 'period drift'를 규명하고, client drift와의 상호작용을 이용해 두 가지 드리프트가 서로 보완하도록 하는 predict-observe 프레임워크와 그 실체화된 방법을 제안한다. 이론적으로 업데이트 분산을 줄임을 보이고, 비IID 데이터 실험에서 기존 방법들보다 성능이 우수함을 보인다.


<details>
  <summary>Details</summary>
Motivation: 연합학습(FL)에서 데이터 이질성은 수렴성 저하의 핵심 문제다. 기존 연구는 로컬 업데이트로 인한 client drift에 주목했지만, 교차-디바이스 환경에서는 매 라운드 일부 클라이언트만 참여하면서 발생하는 'period drift'라는 다른 형태의 드리프트가 존재하며, 이는 매 라운드마다 최적화 목표가 바뀌어 더 해로울 수 있다.

Method: 논문은 predict-observe 프레임워크를 제안하고, 이를 구체화한 FedEve 방법을 소개한다. FedEve는 참여 클라이언트의 분포 변화(period drift)와 로컬 업데이트로 인한 client drift를 상호 보완하도록 설계되어, 모델 업데이트의 분산을 줄이는 방향으로 동작한다. 또한 이 접근에 대한 이론적 근거(분산 감소 증명)를 제시한다.

Result: 이론적 분석은 제안 방법이 모델 업데이트 분산을 줄일 수 있음을 보여주며, 다수의 교차-디바이스 비IID 실험에서 FedEve가 기존 대안들보다 더 나은 성능(수렴 및 최종 정확도)을 보임을 보고한다.

Conclusion: period drift는 교차-디바이스 FL에서 심각한 성능 저하 요인이며, predict-observe 프레임워크와 FedEve는 period drift와 client drift를 상호 보완시켜 전반적인 영향력을 줄일 수 있다. 실험과 이론 모두에서 제안 방법의 유효성이 확인된다.

Abstract: Federated learning (FL) is a machine learning paradigm that allows multiple
clients to collaboratively train a shared model without exposing their private
data. Data heterogeneity is a fundamental challenge in FL, which can result in
poor convergence and performance degradation. Client drift has been recognized
as one of the factors contributing to this issue resulting from the multiple
local updates in FedAvg. However, in cross-device FL, a different form of drift
arises due to the partial client participation, but it has not been studied
well. This drift, we referred as period drift, occurs as participating clients
at each communication round may exhibit distinct data distribution that
deviates from that of all clients. It could be more harmful than client drift
since the optimization objective shifts with every round.
  In this paper, we investigate the interaction between period drift and client
drift, finding that period drift can have a particularly detrimental effect on
cross-device FL as the degree of data heterogeneity increases. To tackle these
issues, we propose a predict-observe framework and present an instantiated
method, FedEve, where these two types of drift can compensate each other to
mitigate their overall impact. We provide theoretical evidence that our
approach can reduce the variance of model updates. Extensive experiments
demonstrate that our method outperforms alternatives on non-iid data in
cross-device settings.

</details>


### [115] [Federated Distillation on Edge Devices: Efficient Client-Side Filtering for Non-IID Data](https://arxiv.org/abs/2508.14769)
*Ahmed Mujtaba,Gleb Radchenko,Radu Prodan,Marc Masana*

Main category: cs.LG

TL;DR: EdgeFD는 연합 증류(federated distillation)의 클라이언트-사이드 복잡성을 줄이고 서버 필터링을 제거하기 위해 KMeans 기반의 효율적 밀도비(density ratio) 추정기를 도입한 방법이다. 경량화된 추정기로 엣지 장치에서 인-분포 및 아웃-오브-분포 프록시 데이터를 효과적으로 필터링하여 지식 공유 품질을 높이고, 다양한 비IID 조건에서도 IID에 가까운 정확도를 달성한다.


<details>
  <summary>Details</summary>
Motivation: 기존 연합 증류 방식은 클라이언트가 밀도비 추정기를 통해 인-분포 프록시 데이터를 찾아야 하고, 서버는 불명확한 지식을 필터링하는데 추가 지연과 계산 비용이 발생한다. 또한 복잡한 통계적 추정은 엣지 장치에 비실용적이다.

Method: EdgeFD는 KMeans 기반의 경량 밀도비 추정기를 클라이언트에 도입하여 인-분포 및 아웃-오브-분포 프록시 데이터를 효율적으로 판별한다. 서버 측의 별도 필터링 단계를 제거하고, 사전학습된 교사 모델 없이도 분산된 클라이언트 간의 소프트 로그트 전달로 증류를 수행한다.

Result: 강한 비IID, 약한 비IID, IID 등 다양한 분포 시나리오에서 기존 최첨단 방법보다 우수한 성능을 보였고, 특히 이질적인 환경에서도 IID에 근접한 정확도를 달성했다. KMeans 추정기는 계산 오버헤드가 낮아 엣지 장치에 적합하다.

Conclusion: EdgeFD는 계산 자원이 제한된 엣지 환경에서 연합 증류의 실용성과 확장성을 높이는 실용적 대안이다. 서버-클라이언트 구조에서 복잡한 통계적 추정을 단순화하여 지연과 부하를 줄이고, 재현 가능한 코드도 공개되었다.

Abstract: Federated distillation has emerged as a promising collaborative machine
learning approach, offering enhanced privacy protection and reduced
communication compared to traditional federated learning by exchanging model
outputs (soft logits) rather than full model parameters. However, existing
methods employ complex selective knowledge-sharing strategies that require
clients to identify in-distribution proxy data through computationally
expensive statistical density ratio estimators. Additionally, server-side
filtering of ambiguous knowledge introduces latency to the process. To address
these challenges, we propose a robust, resource-efficient EdgeFD method that
reduces the complexity of the client-side density ratio estimation and removes
the need for server-side filtering. EdgeFD introduces an efficient KMeans-based
density ratio estimator for effectively filtering both in-distribution and
out-of-distribution proxy data on clients, significantly improving the quality
of knowledge sharing. We evaluate EdgeFD across diverse practical scenarios,
including strong non-IID, weak non-IID, and IID data distributions on clients,
without requiring a pre-trained teacher model on the server for knowledge
distillation. Experimental results demonstrate that EdgeFD outperforms
state-of-the-art methods, consistently achieving accuracy levels close to IID
scenarios even under heterogeneous and challenging conditions. The
significantly reduced computational overhead of the KMeans-based estimator is
suitable for deployment on resource-constrained edge devices, thereby enhancing
the scalability and real-world applicability of federated distillation. The
code is available online for reproducibility.

</details>


### [116] [Amortized Bayesian Meta-Learning for Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2508.14285)
*Liyi Zhang,Jake Snell,Thomas L. Griffiths*

Main category: cs.LG

TL;DR: Proposes ABMLL (Amortized Bayesian Meta-Learning for LoRA) to improve generalization of LoRA fine-tuned LLMs by adapting amortized Bayesian meta-learning to LoRA, balancing task-specific and global parameters, scaling to Llama3-8B and improving uncertainty calibration on QA benchmarks.


<details>
  <summary>Details</summary>
Motivation: LoRA fine-tuning is cost-effective but generalization to unseen datasets is unclear; existing generalization methods (in-context prompting, meta-learning) are expensive in memory or compute. A need exists for an efficient meta-learning approach applicable to large LLMs that also provides uncertainty estimates.

Method: Adapt amortized Bayesian meta-learning to LoRA by reframing task-specific and global parameters in LoRA terms, introduce new hyperparameters to trade off reconstruction accuracy vs fidelity to global parameters, enabling efficient meta-learning without second-order updates or long-context prompts; designed to scale to large models.

Result: ABMLL scales to Llama3-8B and outperforms existing methods on Unified-QA and CrossFit in accuracy and expected calibration error, while providing improved uncertainty quantification.

Conclusion: ABMLL offers a computationally efficient Bayesian meta-learning method for LoRA fine-tuning that improves generalization and calibration for LLMs at large scale, though evaluation is focused on QA benchmarks.

Abstract: Fine-tuning large language models (LLMs) with low-rank adaptaion (LoRA) is a
cost-effective way to incorporate information from a specific dataset. However,
it is often unclear how well the fine-tuned LLM will generalize, i.e., how well
it will perform on unseen datasets. Methods have been proposed to improve
generalization by optimizing with in-context prompts, or by using meta-learning
to fine-tune LLMs. However, these methods are expensive in memory and
computation, requiring either long-context prompts or saving copies of
parameters and using second-order gradient updates. To address these
challenges, we propose Amortized Bayesian Meta-Learning for LoRA (ABMLL). This
method builds on amortized Bayesian meta-learning for smaller models, adapting
this approach to LLMs while maintaining its computational efficiency. We
reframe task-specific and global parameters in the context of LoRA and use a
set of new hyperparameters to balance reconstruction accuracy and the fidelity
of task-specific parameters to the global ones. ABMLL provides effective
generalization and scales to large models such as Llama3-8B. Furthermore, as a
result of using a Bayesian framework, ABMLL provides improved uncertainty
quantification. We test ABMLL on Unified-QA and CrossFit datasets and find that
it outperforms existing methods on these benchmarks in terms of both accuracy
and expected calibration error.

</details>


### [117] [GLASS: Test-Time Acceleration for LLMs via Global-Local Neural Importance Aggregation](https://arxiv.org/abs/2508.14302)
*Amirmohsen Sattarifard,Sepehr Lavasani,Ehsan Imani,Kunlin Zhang,Hanlin Xu,Fengyu Sun,Negar Hassanpour,Chao Gao*

Main category: cs.LG

TL;DR: LLM의 FFN 유닛을 훈련 없이 동적으로 선택하는 A/I-GLASS(활성화 및 영향 기반의 글로벌-로컬 중요도 집계)를 제안한다. 프롬프트-민감한 동적 소거로 긴 생성 시나리오에서도 기존 무훈련 방법을 능가하며 추가 추론 오버헤드 없이 엣지 배포에 적합하다.


<details>
  <summary>Details</summary>
Motivation: 엣지 하드웨어에서 LLM을 실행하려면 계산을 크게 줄이되 품질 저하를 막는 프롬프트 인지형 동적 소거가 필요하다. 기존의 정적 패턴이나 예측기 기반 방식은 유연성이 떨어지거나 런타임 오버헤드를 초래하고, 단일 프롬프트 통계에 의존한 제로샷 방법은 짧은 프롬프트나 긴 생성에서 실패한다.

Method: A/I-GLASS는 두 가지 무훈련 방식으로, 프롬프트-로컬(activation)과 모델-내재적 글로벌(impact) 뉴런 통계의 순위 집계를 통해 FFN 유닛을 동적으로 선택한다. 보조 예측기나 추가 추론 비용 없이 전역·지역 중요도를 통합한 랭크 집계로 희소화 결정을 내린다.

Result: 여러 LLM과 벤치마크에서 평가한 결과, GLASS는 특히 장문 생성 시나리오에서 기존 무훈련 방법보다 우수한 성능을 보였고, 추론 오버헤드를 추가하지 않으면서 품질을 유지하며 계산을 절감했다.

Conclusion: GLASS는 훈련 없이도 프롬프트 민감한 동적 희소화를 효과적으로 달성하므로, 엣지에서의 대형 언어모델 배포에 실용적인 솔루션을 제공한다.

Abstract: Deploying Large Language Models (LLMs) on edge hardware demands aggressive,
prompt-aware dynamic pruning to reduce computation without degrading quality.
Static or predictor-based schemes either lock in a single sparsity pattern or
incur extra runtime overhead, and recent zero-shot methods that rely on
statistics from a single prompt fail on short prompt and/or long generation
scenarios. We introduce A/I-GLASS: Activation- and Impact-based Global-Local
neural importance Aggregation for feed-forward network SparSification, two
training-free methods that dynamically select FFN units using a
rank-aggregation of prompt local and model-intrinsic global neuron statistics.
Empirical results across multiple LLMs and benchmarks demonstrate that GLASS
significantly outperforms prior training-free methods, particularly in
challenging long-form generation scenarios, without relying on auxiliary
predictors or adding any inference overhead.

</details>


### [118] [Organ-Agents: Virtual Human Physiology Simulator via LLMs](https://arxiv.org/abs/2508.14357)
*Rihao Chang,He Jiao,Weizhi Nie,Honglin Guo,Keliang Xie,Zhenhua Wu,Lina Zhao,Yunpeng Bai,Yongtao Ma,Lanjun Wang,Yuting Su,Xi Gao,Weijie Wang,Nicu Sebe,Bruno Lepri,Bingwei Sun*

Main category: cs.LG

TL;DR: Organ-Agents는 LLM 기반의 다중 에이전트 프레임워크로, 각 에이전트가 심혈관·신장·면역 등 특정 생리 시스템을 시뮬레이션하여 중환자(특히 패혈증) 환자의 고해상도 시계열을 생성·재현한다. 대규모 환자 데이터로 지도학습 후 강화학습식 조정으로 시스템 간 협력을 유도하며, 보류 환자 테스트와 외부 검증에서 높은 정확도와 현실성을 보였다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델의 시뮬레이션 능력을 활용해 복잡한 인간 생리 시스템의 디지털 트윈을 구축하고, 진단·치료 시뮬레이션·가설 검증에 활용 가능한 신뢰성 있는 플랫폼을 만들기 위함.

Method: 각 생리 시스템을 LLM 기반의 개별 에이전트로 모델링. 시스템별 시계열 데이터로 지도 미세조정(fine-tuning)을 수행한 뒤, 동적 참조 선택과 오류 보정이 포함된 강화학습 기반의 조정 메커니즘으로 에이전트 간 협업을 최적화. 7,134명의 패혈증 환자와 7,895명의 대조군에서 9개 시스템·125개 변수의 고해상도 궤적을 구축.

Result: 4,509명의 보류 환자에서 시스템별 MSE < 0.16로 높은 시뮬레이션 정확도를 달성. SOFA 중증도 층별로도 견고함을 보였고, 두 병원의 22,689명 ICU 외부 검증에서는 분포 이동에도 안정적 성능 유지. 저혈압·고유산혈증·저산소증 같은 다기관 사건의 시점 및 경과를 타당하게 재현. 15명의 중환자의가 평가한 현실성·생리적 타당도 평균 Likert 3.9·3.7. 처치 대안에 대한 반사실적 시뮬레이션과 APACHE II 점수 생성이 실제 환자와 정렬. 합성 데이터로 학습한 조기 경보 분류기의 AUROC 저하는 <0.04로 낮음.

Conclusion: Organ-Agents는 해석 가능하고 일반화 가능한 중환자 디지털 트윈으로 작동하며, 정밀 진단·치료 시뮬레이션 및 가설 검증에 유용한 도구로 제시됨.

Abstract: Recent advances in large language models (LLMs) have enabled new
possibilities in simulating complex physiological systems. We introduce
Organ-Agents, a multi-agent framework that simulates human physiology via
LLM-driven agents. Each Simulator models a specific system (e.g.,
cardiovascular, renal, immune). Training consists of supervised fine-tuning on
system-specific time-series data, followed by reinforcement-guided coordination
using dynamic reference selection and error correction. We curated data from
7,134 sepsis patients and 7,895 controls, generating high-resolution
trajectories across 9 systems and 125 variables. Organ-Agents achieved high
simulation accuracy on 4,509 held-out patients, with per-system MSEs <0.16 and
robustness across SOFA-based severity strata. External validation on 22,689 ICU
patients from two hospitals showed moderate degradation under distribution
shifts with stable simulation. Organ-Agents faithfully reproduces critical
multi-system events (e.g., hypotension, hyperlactatemia, hypoxemia) with
coherent timing and phase progression. Evaluation by 15 critical care
physicians confirmed realism and physiological plausibility (mean Likert
ratings 3.9 and 3.7). Organ-Agents also enables counterfactual simulations
under alternative sepsis treatment strategies, generating trajectories and
APACHE II scores aligned with matched real-world patients. In downstream early
warning tasks, classifiers trained on synthetic data showed minimal AUROC drops
(<0.04), indicating preserved decision-relevant patterns. These results
position Organ-Agents as a credible, interpretable, and generalizable digital
twin for precision diagnosis, treatment simulation, and hypothesis testing in
critical care.

</details>


### [119] [Adaptively Robust LLM Inference Optimization under Prediction Uncertainty](https://arxiv.org/abs/2508.14544)
*Zixi Chen,Yinyu Ye,Zijie Zhou*

Main category: cs.LG

TL;DR: This paper addresses online LLM inference scheduling under unknown output lengths by using ML-predicted length intervals. It proposes a conservative scheduler A_max (uses upper bound) and an adaptive scheduler A_min (starts with lower bound and refines during inference). A_min achieves a logarithmic competitive ratio and performs near-optimal in simulations, relying mainly on lower-bound predictions.


<details>
  <summary>Details</summary>
Motivation: LLM inference is an online, multi-task, and energy-intensive process where unknown output length causes memory and latency management challenges. Efficient scheduling is needed to minimize total latency and prevent memory overflow when many prompt requests arrive.

Method: Use machine learning to predict an interval (min–max) for each request's output length. Design two algorithms: A_max that schedules using the predicted upper bound to avoid memory overflow, and A_min that assumes the lower bound initially and adaptively refines the estimate during inference. Provide theoretical analysis (competitive ratio) for A_min.

Result: Theoretical guarantee: A_min achieves a log-scale competitive ratio. Empirical simulations show A_min often performs nearly as well as a hindsight/offline scheduler, demonstrating efficiency and robustness even with prediction uncertainty. A_min only requires the lower bound of the interval, which is easier to predict reliably.

Conclusion: Adaptive, lower-bound-based scheduling (A_min) offers a practical, robust approach to LLM inference scheduling, reducing latency and managing memory without heavy reliance on accurate upper-bound predictions.

Abstract: We study the problem of optimizing Large Language Model (LLM) inference
scheduling to minimize total latency. LLM inference is an online and multi-task
service process and also heavily energy consuming by which a pre-trained LLM
processes input requests and generates output tokens sequentially. Therefore,
it is vital to improve its scheduling efficiency and reduce the power
consumption while a great amount of prompt requests are arriving. A key
challenge in LLM inference scheduling is that while the prompt length is known
upon arrival, the output length, which critically impacts memory usage and
processing time, is unknown. To address this uncertainty, we propose algorithms
that leverage machine learning to predict output lengths, assuming the
prediction provides an interval classification (min-max range) for each
request.
  We first design a conservative algorithm, $\mathcal{A}_{\max}$, which
schedules requests based on the upper bound of predicted output lengths to
prevent memory overflow. However, this approach is overly conservative: as
prediction accuracy decreases, performance degrades significantly due to
potential overestimation. To overcome this limitation, we propose
$\mathcal{A}_{\min}$, an adaptive algorithm that initially treats the predicted
lower bound as the output length and dynamically refines this estimate during
inferencing. We prove that $\mathcal{A}_{\min}$ achieves a log-scale
competitive ratio. Through numerical simulations, we demonstrate that
$\mathcal{A}_{\min}$ often performs nearly as well as the hindsight scheduler,
highlighting both its efficiency and robustness in practical scenarios.
Moreover, $\mathcal{A}_{\min}$ relies solely on the lower bound of the
prediction interval--an advantageous design choice since upper bounds on output
length are typically more challenging to predict accurately.

</details>


### [120] [DuPO: Enabling Reliable LLM Self-Verification via Dual Preference Optimization](https://arxiv.org/abs/2508.14460)
*Shuaijie She,Yu Bao,Yu Lu,Lu Xu,Tao Li,Wenhao Zhu,Shujian Huang,Shanbo Cheng,Lu Lu,Yuxuan Wang*

Main category: cs.LG

TL;DR: DuPO는 주석 없이 자기지도적 피드백을 생성해 LLM을 최적화하는 듀얼 학습 기반 프레임워크로, 비가역적 과제까지 적용 범위를 넓히며 번역·수학 추론 등에서 성능 향상을 보인다.


<details>
  <summary>Details</summary>
Motivation: 강화학습(RLVR)은 검증 가능한 보상과 레이블 집약성 문제를 가지며, 기존 듀얼 학습은 엄격한 쌍(예: 번역↔역번역)에만 적용 가능해 범용성이 제한된다. 따라서 주석 없이 보상을 생성하고 비가역 작업에도 적용 가능한 일반화된 방법이 필요하다.

Method: 입력을 알려진 요소와 알려지지 않은 요소로 분해하고, 원시(primal) 작업의 출력을 사용해 알려진 정보로부터 알려지지 않은 부분을 복원하는 듀얼 작업을 구성한다. 복원의 품질을 자기지도 보상으로 사용해 원시 작업을 최적화하며, LLM이 단일 모델로 두 작업을 모두 수행하도록 한다.

Result: 평가에서 756개 번역 방향에서 평균 COMET +2.13, 수학 추론 챌린지 3개에서 평균 정확도 +6.4점, 추론 시 재순위기로 사용하면 +9.3점 향상 등 다양한 과제에서 유의한 성능 개선을 보였다.

Conclusion: DuPO는 주석이 필요 없는 확장 가능한 LLM 최적화 패러다임을 제시하며, 비가역 과제로까지 적용성을 넓혀 일반적이고 실용적인 대안이 된다.

Abstract: We present DuPO, a dual learning-based preference optimization framework that
generates annotation-free feedback via a generalized duality. DuPO addresses
two key limitations: Reinforcement Learning with Verifiable Rewards (RLVR)'s
reliance on costly labels and applicability restricted to verifiable tasks, and
traditional dual learning's restriction to strictly dual task pairs (e.g.,
translation and back-translation). Specifically, DuPO decomposes a primal
task's input into known and unknown components, then constructs its dual task
to reconstruct the unknown part using the primal output and known information
(e.g., reversing math solutions to recover hidden variables), broadening
applicability to non-invertible tasks. The quality of this reconstruction
serves as a self-supervised reward to optimize the primal task, synergizing
with LLMs' ability to instantiate both tasks via a single model. Empirically,
DuPO achieves substantial gains across diverse tasks: it enhances the average
translation quality by 2.13 COMET over 756 directions, boosts the mathematical
reasoning accuracy by an average of 6.4 points on three challenge benchmarks,
and enhances performance by 9.3 points as an inference-time reranker (trading
computation for accuracy). These results position DuPO as a scalable, general,
and annotation-free paradigm for LLM optimization.

</details>


### [121] [ELATE: Evolutionary Language model for Automated Time-series Engineering](https://arxiv.org/abs/2508.14667)
*Andrew Murray,Danial Dervovic,Michael Cashmore*

Main category: cs.LG

TL;DR: ELATE는 언어 모델을 진화 알고리즘과 결합하여 시계열 데이터의 피처 엔지니어링을 자동화한다. 통계적 측정치와 피처 중요도를 사용해 후보를 탐색·가지치기하고, 언어 모델은 문맥적으로 관련 있는 변환을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 피처 엔지니어링은 시계열 예측 성능 향상에 중요하지만 수작업으로 시간이 많이 걸리고 기존 자동화는 무차별 열거에 의존해 계산 비용이 크고 도메인 특화 통찰이 부족하다.

Method: 진화 알고리즘 프레임워크 안에 언어 모델을 통합해 새로운 피처 변형을 제안하도록 하고, 시계열 통계 지표와 피처 중요도 기반의 가이드·가지치기를 통해 탐색 공간을 줄인다.

Result: 다양한 도메인에서 평균 8.4%의 예측 정확도 향상을 보였다.

Conclusion: 언어 모델과 진화적 탐색을 결합한 자동 피처 엔지니어링(ELATE)은 수작업을 줄이면서 시계열 예측 성능을 향상시킬 수 있음을 보인다.

Abstract: Time-series prediction involves forecasting future values using machine
learning models. Feature engineering, whereby existing features are transformed
to make new ones, is critical for enhancing model performance, but is often
manual and time-intensive. Existing automation attempts rely on exhaustive
enumeration, which can be computationally costly and lacks domain-specific
insights. We introduce ELATE (Evolutionary Language model for Automated
Time-series Engineering), which leverages a language model within an
evolutionary framework to automate feature engineering for time-series data.
ELATE employs time-series statistical measures and feature importance metrics
to guide and prune features, while the language model proposes new,
contextually relevant feature transformations. Our experiments demonstrate that
ELATE improves forecasting accuracy by an average of 8.4% across various
domains.

</details>


### [122] [Semantic Energy: Detecting LLM Hallucination Beyond Entropy](https://arxiv.org/abs/2508.14496)
*Huan Ma,Jiadong Pan,Jing Liu,Yan Chen,Joey Tianyi Zhou,Guangyu Wang,Qinghua Hu,Hua Wu,Changqing Zhang,Haifeng Wang*

Main category: cs.LG

TL;DR: 논문은 LLM의 환각(거짓 응답) 탐지를 위해 로그잇(logits) 기반의 새로운 불확실성 추정 방식인 'Semantic Energy'를 제안한다. 기존의 semantic entropy가 softmax 후 확률에 의존해 모델의 내재적 불확실성을 포착하지 못하는 문제를 해결하기 위해, penultimate layer의 logits과 의미적 클러스터링, 볼츠만(Boltzmann) 영감을 받은 에너지 분포를 결합한다. 여러 벤치마크에서 환각 탐지 성능이 향상됨을 보였다.


<details>
  <summary>Details</summary>
Motivation: LLM은 환각 문제로 인해 실제 응용에서 위험을 초래하므로, 이를 탐지할 수 있는 신뢰성 있는 불확실성 측정 방법 필요. 기존 semantic entropy는 post-softmax 확률만 사용해 내재적 불확실성을 제대로 포착하지 못함.

Method: penultimate layer의 logits을 직접 사용하여 의미적 클러스터링을 수행하고, 볼츠만 영감을 받은 에너지 분포로 확률을 설계하여 불확실성(semantic energy)을 계산함. 이를 통해 semantic entropy가 실패하는 경우에서도 더 나은 불확실성 추정이 가능하도록 함.

Result: 다수의 벤치마크에서 대조군 대비 환각 탐지 성능과 불확실성 추정 품질이 유의미하게 향상됨. downstream 응용(환각 탐지 등)에 더 신뢰할 수 있는 신호를 제공함.

Conclusion: Semantic Energy는 logits 기반의 불확실성 측정으로 semantic entropy의 한계를 극복하며, LLM의 환각 탐지에 효과적이다.

Abstract: Large Language Models (LLMs) are being increasingly deployed in real-world
applications, but they remain susceptible to hallucinations, which produce
fluent yet incorrect responses and lead to erroneous decision-making.
Uncertainty estimation is a feasible approach to detect such hallucinations.
For example, semantic entropy estimates uncertainty by considering the semantic
diversity across multiple sampled responses, thus identifying hallucinations.
However, semantic entropy relies on post-softmax probabilities and fails to
capture the model's inherent uncertainty, causing it to be ineffective in
certain scenarios. To address this issue, we introduce Semantic Energy, a novel
uncertainty estimation framework that leverages the inherent confidence of LLMs
by operating directly on logits of penultimate layer. By combining semantic
clustering with a Boltzmann-inspired energy distribution, our method better
captures uncertainty in cases where semantic entropy fails. Experiments across
multiple benchmarks show that Semantic Energy significantly improves
hallucination detection and uncertainty estimation, offering more reliable
signals for downstream applications such as hallucination detection.

</details>


### [123] [PepThink-R1: LLM for Interpretable Cyclic Peptide Optimization with CoT SFT and Reinforcement Learning](https://arxiv.org/abs/2508.14765)
*Ruheng Wang,Hang Zhang,Trieu Nguyen,Shasha Feng,Hao-Wei Pang,Xiang Yu,Li Xiao,Peter Zhiping Zhang*

Main category: cs.LG

TL;DR: PepThink-R1은 LLM에 chain-of-thought 감독 파인튜닝과 강화학습을 결합해 단량체(모노머) 수준의 수정을 명시적으로 추론하며 치료용 펩타이드를 생성·최적화하는 프레임워크이다. 화학적 타당성과 약리학적 특성 향상을 균형잡는 보상함수로 다양한 서열 변이를 탐색해, 순환 펩타이드의 지질친화성, 안정성, 노출도를 유의하게 향상시켰고 GPT-5 및 도메인 특화 베이스라인을 능가했다.


<details>
  <summary>Details</summary>
Motivation: 펩타이드 설계는 거대한 서열 공간, 제한된 실험 데이터, 기존 생성모델의 낮은 해석성 때문에 어려움이 있다. 명시적 추론과 다목적 최적화를 결합한 접근이 필요하다.

Method: 대형 언어모델에 CoT(사고과정) 감독 파인튜닝을 적용하고, 맞춤형 보상함수를 사용하는 강화학습으로 학습한다. 생성 과정에서 단량체 수준의 변경을 명시적으로 추론하도록 설계해 해석 가능성과 다중 속성 최적화를 동시에 달성한다.

Result: 제안한 PepThink-R1은 순환 펩타이드에서 지질친화성, 안정성, 노출도가 크게 향상된 서열을 생성했으며, 일반 LLM(예: GPT-5) 및 도메인 특화 모델보다 최적화 성공률과 해석성에서 우수했다.

Conclusion: 명시적 추론과 RL 기반 속성 제어를 결합한 최초의 LLM 기반 펩타이드 설계 프레임워크로서, 치료법 탐색을 위한 신뢰성 있고 투명한 펩타이드 최적화에 기여한다.

Abstract: Designing therapeutic peptides with tailored properties is hindered by the
vastness of sequence space, limited experimental data, and poor
interpretability of current generative models. To address these challenges, we
introduce PepThink-R1, a generative framework that integrates large language
models (LLMs) with chain-of-thought (CoT) supervised fine-tuning and
reinforcement learning (RL). Unlike prior approaches, PepThink-R1 explicitly
reasons about monomer-level modifications during sequence generation, enabling
interpretable design choices while optimizing for multiple pharmacological
properties. Guided by a tailored reward function balancing chemical validity
and property improvements, the model autonomously explores diverse sequence
variants. We demonstrate that PepThink-R1 generates cyclic peptides with
significantly enhanced lipophilicity, stability, and exposure, outperforming
existing general LLMs (e.g., GPT-5) and domain-specific baseline in both
optimization success and interpretability. To our knowledge, this is the first
LLM-based peptide design framework that combines explicit reasoning with
RL-driven property control, marking a step toward reliable and transparent
peptide optimization for therapeutic discovery.

</details>


### [124] [Understanding Data Influence with Differential Approximation](https://arxiv.org/abs/2508.14648)
*Haoru Tan,Sitong Wu,Xiuzhe Wu,Wang Wang,Bo Zhao,Zeke Xie,Gui-Song Xia,Xiaojuan Qi*

Main category: cs.LG

TL;DR: Proposes Diff-In, a method to approximate sample influence by summing differences in influence across training steps using second-order approximations without requiring model convexity; computes Hessian-gradient products via finite differences of gradients to remain computationally efficient and scalable.


<details>
  <summary>Details</summary>
Motivation: Existing influence estimation tools are inaccurate and often assume convex loss, limiting effectiveness for modern nonconvex neural networks and large-scale data-centric tasks.

Method: Define sample-wise influence as cumulative differences across successive iterations (Diff-In). Use second-order approximation to estimate each difference term; approximate Hessian-vector products via finite differences of first-order gradients to avoid high overhead while removing convexity assumptions.

Result: Theoretical analysis shows lower approximation error than prior estimators. Empirically, Diff-In outperforms baselines on data cleaning, data deletion, and coreset selection across benchmarks, and scales to millions of samples for large-scale vision-language pretraining data pruning.

Conclusion: Diff-In provides a more accurate and scalable influence estimator for nonconvex models, enabling effective large-scale data-centric operations (cleaning, deletion, pruning) and improving over existing methods without convexity assumptions.

Abstract: Data plays a pivotal role in the groundbreaking advancements in artificial
intelligence. The quantitative analysis of data significantly contributes to
model training, enhancing both the efficiency and quality of data utilization.
However, existing data analysis tools often lag in accuracy. For instance, many
of these tools even assume that the loss function of neural networks is convex.
These limitations make it challenging to implement current methods effectively.
In this paper, we introduce a new formulation to approximate a sample's
influence by accumulating the differences in influence between consecutive
learning steps, which we term Diff-In. Specifically, we formulate the
sample-wise influence as the cumulative sum of its changes/differences across
successive training iterations. By employing second-order approximations, we
approximate these difference terms with high accuracy while eliminating the
need for model convexity required by existing methods. Despite being a
second-order method, Diff-In maintains computational complexity comparable to
that of first-order methods and remains scalable. This efficiency is achieved
by computing the product of the Hessian and gradient, which can be efficiently
approximated using finite differences of first-order gradients. We assess the
approximation accuracy of Diff-In both theoretically and empirically. Our
theoretical analysis demonstrates that Diff-In achieves significantly lower
approximation error compared to existing influence estimators. Extensive
experiments further confirm its superior performance across multiple benchmark
datasets in three data-centric tasks: data cleaning, data deletion, and coreset
selection. Notably, our experiments on data pruning for large-scale
vision-language pre-training show that Diff-In can scale to millions of data
points and outperforms strong baselines.

</details>


### [125] [CaTE Data Curation for Trustworthy AI](https://arxiv.org/abs/2508.14741)
*Mary Versa Clemens-Sewall,Christopher Cervantes,Emma Rafkin,J. Neil Otte,Tom Magelinski,Libby Lewis,Michelle Liu,Dana Udwin,Monique Kirkman-Bey*

Main category: cs.LG

TL;DR: 이 보고서는 AI 시스템의 데이터 큐레이션 단계에서 신뢰성(trustworthiness)을 높이기 위한 실무적 가이드를 제공한다. 핵심 단계, 대안 경로, 각 단계의 강점·약점·전제조건·결과, 오픈소스 도구 구현 사례를 체계적으로 정리한 문헌·도구 종합 보고서다.


<details>
  <summary>Details</summary>
Motivation: AI 시스템의 성능과 윤리성·안전성은 데이터 품질과 큐레이션 과정에 크게 좌우되므로, 개발팀(특히 데이터 과학자)이 데이터 단계에서 신뢰성을 체계적으로 확보할 수 있는 실무 지침이 필요하다.

Method: 데이터 정의와 큐레이션 단계, 신뢰성 개념을 명확히 한 뒤, 실무 팀이 따를 수 있는 일련의 핵심 단계(및 대안 경로)를 제시하고 각 단계에 대해 강점·약점·전제조건·성과물을 기술하고, 관련 오픈소스 도구들을 연결하여 실제 적용 가능성을 높였다.

Result: 체계화된 데이터 큐레이션 절차와 도구 목록을 통해 개발팀이 신뢰성 향상에 기여할 수 있는 실질적 실무 지침을 제공함. 문헌·도구의 종합으로 다양한 상황에 맞는 대안 경로도 제시됨.

Conclusion: 데이터 큐레이션 단계에서의 표준화된 실천 항목과 도구 활용은 AI 시스템의 신뢰성 제고에 기여하며, 이 보고서는 개발팀이 적용 가능한 다양한 관행과 구현 예시를 제시한다.

Abstract: This report provides practical guidance to teams designing or developing
AI-enabled systems for how to promote trustworthiness during the data curation
phase of development. In this report, the authors first define data, the data
curation phase, and trustworthiness. We then describe a series of steps that
the development team, especially data scientists, can take to build a
trustworthy AI-enabled system. We enumerate the sequence of core steps and
trace parallel paths where alternatives exist. The descriptions of these steps
include strengths, weaknesses, preconditions, outcomes, and relevant
open-source software tool implementations. In total, this report is a synthesis
of data curation tools and approaches from relevant academic literature, and
our goal is to equip readers with a diverse yet coherent set of practices for
improving AI trustworthiness.

</details>


### [126] [MissionHD: Data-Driven Refinement of Reasoning Graph Structure through Hyperdimensional Causal Path Encoding and Decoding](https://arxiv.org/abs/2508.14746)
*Sanggeon Yun,Raheeb Hassan,Ryozo Masukawa,Mohsen Imani*

Main category: cs.LG

TL;DR: LLM-derived reasoning graphs are often misaligned with visual downstream tasks like video anomaly detection. The paper proposes Data-driven GSR (D-GSR) and MissionHD (a hyperdimensional computing framework) to refine graph structure directly using downstream task data via an encode-decode process. Experiments on VAD/VAR benchmarks show significant performance gains, validating the approach as an effective pre-processing step.


<details>
  <summary>Details</summary>
Motivation: Reasoning graphs generated from LLMs do not match the requirements of visual tasks (e.g., VAD). Existing graph refinement methods assume different conditions and fail on novel, dataset-less graphs, so a task-driven refinement is needed.

Method: Introduce D-GSR that optimizes graph structure using downstream task signals. Implement it with MissionHD, which leverages hyperdimensional computing and an efficient encode-decode pipeline to refine graphs guided by task performance.

Result: Refined graphs produced by MissionHD yield significant improvements on challenging video anomaly detection (VAD) and video action recognition (VAR) benchmarks compared to using unrefined LLM graphs, demonstrating effectiveness as a pre-processing step.

Conclusion: Task-driven graph refinement via MissionHD effectively aligns LLM-derived reasoning graphs with downstream video tasks and improves performance; it is recommended as a pre-processing module.

Abstract: Reasoning graphs from Large Language Models (LLMs) are often misaligned with
downstream visual tasks such as video anomaly detection (VAD). Existing Graph
Structure Refinement (GSR) methods are ill-suited for these novel, dataset-less
graphs. We introduce Data-driven GSR (D-GSR), a new paradigm that directly
optimizes graph structure using downstream task data, and propose MissionHD, a
hyperdimensional computing (HDC) framework to operationalize it. MissionHD uses
an efficient encode-decode process to refine the graph, guided by the
downstream task signal. Experiments on challenging VAD and VAR benchmarks show
significant performance improvements when using our refined graphs, validating
our approach as an effective pre-processing step.

</details>


### [127] [HERAKLES: Hierarchical Skill Compilation for Open-ended LLM Agents](https://arxiv.org/abs/2508.14751)
*Thomas Carta,Clément Romac,Loris Gaven,Pierre-Yves Oudeyer,Olivier Sigaud,Sylvain Lamprier*

Main category: cs.LG

TL;DR: HERAKLES는 계층적 자가목표(autotelic) 에이전트로, 마스터한 목표들을 저수준 정책으로 컴파일하여 서브골(subgoal) 집합을 동적으로 확장하고, 고수준 제어기로 대형 언어모델(LLM)을 활용해 복잡해지는 목표들을 효율적으로 다루는 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 오픈엔디드 자가학습 환경에서 목표들이 점점 복잡해지고 이질적으로 변할 때 샘플 및 계산 복잡도 증가를 제어하고, 재사용 가능한 장시간 행동을 효율적으로 습득·관리할 방법이 필요하다. 기존 HRL 접근법은 전문가가 정의한 서브골 공간과 사전학습된 저수준 정책에 의존해 확장성과 개방형 상황에 취약하다.

Method: 두 수준의 계층 구조: (1) 소형·고속 신경망 저수준 정책은 마스터한 목표들을 컴파일하여 수행하고 서브골 집합을 확장; (2) LLM을 고수준 컨트롤러로 학습시켜 목표 분해와 일반화 능력을 활용해 진화하는 서브골 공간 위에서 행동 결정을 수행. HERAKLES는 스킬 컴파일(skill compilation)을 통해 샘플 효율을 개선한다.

Result: Crafter 환경에서 평가하여 목표 복잡도에 따라 확장 가능함을 보였고, 스킬 컴파일을 통한 샘플 효율성 향상 및 시간이 지남에 따른 새로운 도전과제에 대한 적응성 향상을 확인했다.

Conclusion: LLM 기반 고수준 제어와 동적 스킬 컴파일을 결합하면 오픈엔디드 상황에서 계층적 자가목표 에이전트의 확장성·샘플 효율·적응성을 개선할 수 있다.

Abstract: Open-ended AI agents need to be able to learn efficiently goals of increasing
complexity, abstraction and heterogeneity over their lifetime. Beyond sampling
efficiently their own goals, autotelic agents specifically need to be able to
keep the growing complexity of goals under control, limiting the associated
growth in sample and computational complexity. To adress this challenge, recent
approaches have leveraged hierarchical reinforcement learning (HRL) and
language, capitalizing on its compositional and combinatorial generalization
capabilities to acquire temporally extended reusable behaviours. Existing
approaches use expert defined spaces of subgoals over which they instantiate a
hierarchy, and often assume pre-trained associated low-level policies. Such
designs are inadequate in open-ended scenarios, where goal spaces naturally
diversify across a broad spectrum of difficulties. We introduce HERAKLES, a
framework that enables a two-level hierarchical autotelic agent to continuously
compile mastered goals into the low-level policy, executed by a small, fast
neural network, dynamically expanding the set of subgoals available to the
high-level policy. We train a Large Language Model (LLM) to serve as the
high-level controller, exploiting its strengths in goal decomposition and
generalization to operate effectively over this evolving subgoal space. We
evaluate HERAKLES in the open-ended Crafter environment and show that it scales
effectively with goal complexity, improves sample efficiency through skill
compilation, and enables the agent to adapt robustly to novel challenges over
time.

</details>


### [128] [Synthetic Adaptive Guided Embeddings (SAGE): A Novel Knowledge Distillation Method](https://arxiv.org/abs/2508.14783)
*Suleyman Olcay Polat,Poli A. Nemkova,Mark V. Albert*

Main category: cs.LG

TL;DR: 모델 증류의 계산 부담과 일반화 한계를 해결하기 위해, 학생 모델의 손실이 높은 임베딩 공간 영역을 찾아 표적 합성 데이터를 생성하고 벡터화된 표현으로 직접 증류하는 적응형 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기존 증류 방법은 계산 비용이 높고 범용성이 제한적이다. 특히 학생 모델이 약한 영역에 대한 표적 학습이 부족하여 효율적이고 효과적인 압축이 어려움.

Method: UMAP으로 차원 축소 후 최근접 이웃 샘플링을 통해 임베딩 공간에서 학생 손실이 높은 영역을 식별하고, 해당 영역을 증강해 표적 합성 예제를 생성한다. 또한 교사 모델의 입력 계층을 우회해 벡터화된 표현에서 직접 증류할 수 있는 경량 교사-학생 인터페이스를 도입한다.

Result: 66M 파라미터 학생 모델이 QNLI에서 91.2%, SST-2에서 92.3%를 달성하며 기존 기준과 동등하거나 상회하는 성능을 보였고, 더 적은 에폭으로 학습을 마쳤다.

Conclusion: 손실 인지형 데이터 증강과 벡터화 증류는 효율적이고 효과적인 모델 압축법으로 유망하며, 계산 비용 절감과 성능 향상을 동시에 달성할 수 있다.

Abstract: Model distillation enables the transfer of knowledge from large-scale models
to compact student models, facilitating deployment in resource-constrained
environments. However, conventional distillation approaches often suffer from
computational overhead and limited generalization. We propose a novel adaptive
distillation framework that dynamically augments training data in regions of
high student model loss. Using UMAP-based dimensionality reduction and nearest
neighbor sampling, our method identifies underperforming regions in the
embedding space and generates targeted synthetic examples to guide student
learning. To further improve efficiency, we introduce a lightweight
teacher-student interface that bypasses the teacher's input layer, enabling
direct distillation on vectorized representations. Experiments across standard
NLP benchmarks demonstrate that our 66M-parameter student model consistently
matches or surpasses established baselines, achieving 91.2% on QNLI and 92.3%
on SST-2, while training with fewer epochs. These results highlight the promise
of loss-aware data augmentation and vectorized distillation for efficient and
effective model compression.

</details>


### [129] [On Defining Neural Averaging](https://arxiv.org/abs/2508.14832)
*Su Hyeong Lee,Richard Ngo*

Main category: cs.LG

TL;DR: 데이터 없이 여러 사전학습 모델의 최종 가중치만으로 단일 신경망을 합성하는 문제를 다루며, model soup를 일반화한 Amortized Model Ensembling(AME)을 제안해 모델 차이를 의사그래디언트로 해석하여 가중치 업데이트를 수행한다. AME는 개별 모델과 model soup보다 특히 OOD에서 더 우수한 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 분산 학습(혹은 서로 다른 데이터 샤드에서 학습된 모델들) 환경에서 훈련 데이터에 접근하지 못하는 상황에서도 여러 모델을 하나로 합성해야 하는 실용적 필요성과, 기존의 model soup 현상을 이론적·일반적인 틀로 정립하려는 목적.

Method: 데이터 프리 메타-최적화 프레임워크인 AME를 도입한다. 모델들 간의 차이를 pseudogradient로 간주해 이를 통해 가중치를 갱신하는 방식으로, model soup를 특수 사례로 복원하면서 더 표현력 있고 적응적인 앙상블 전략을 가능하게 한다.

Result: AME로 합성한 모델이 개별 전문가 모델들 및 model soup 기준치보다 전반적으로 우수한 성능을 보였고, 특히 분포 밖(Out-of-Distribution) 상황에서 성능 향상이 두드러졌다.

Conclusion: 데이터 접근 없이도 모델 가중치를 원리적으로 통합할 수 있는 일반화된 방법을 제시하며, 신경망 평균화에 대한 실용적 정의를 제공한다.

Abstract: What does it even mean to average neural networks? We investigate the problem
of synthesizing a single neural network from a collection of pretrained models,
each trained on disjoint data shards, using only their final weights and no
access to training data. In forming a definition of neural averaging, we take
insight from model soup, which appears to aggregate multiple models into a
singular model while enhancing generalization performance. In this work, we
reinterpret model souping as a special case of a broader framework: Amortized
Model Ensembling (AME) for neural averaging, a data-free meta-optimization
approach that treats model differences as pseudogradients to guide neural
weight updates. We show that this perspective not only recovers model soup but
enables more expressive and adaptive ensembling strategies. Empirically, AME
produces averaged neural solutions that outperform both individual experts and
model soup baselines, especially in out-of-distribution settings. Our results
suggest a principled and generalizable notion of data-free model weight
aggregation and defines, in one sense, how to perform neural averaging.

</details>


### [130] [Universal and Transferable Adversarial Attack on Large Language Models Using Exponentiated Gradient Descent](https://arxiv.org/abs/2508.14853)
*Sajib Biswas,Mao Nishino,Samuel Jacob Chacko,Xiuwen Liu*

Main category: cs.LG

TL;DR: 새로운 공격 방법은 이산 토큰의 완화된 원-핫 인코딩을 지수적 그래디언트 하강 및 브레그만 사영으로 직접 최적화해 LLM의 jailbreak(우회) 입력을 생성한다. 이론적 수렴성을 증명하고, 여러 오픈소스 LLM 및 어드버서리얼 데이터셋에서 기존 기법들보다 성공률과 수렴 속도 면에서 우수함을 보였다. 또한 범용 접미사(universal suffix) 생성 및 모델 간 전이 가능성을 입증한다.


<details>
  <summary>Details</summary>
Motivation: RLHF 등 정렬 기법에도 불구하고 LLM은 악의적 트리거(우회 토큰)에 취약하며, 기존 공격은 이산 토큰 탐색이 비효율적이거나 연속 임베딩 최적화가 폐쇄형 모델에는 적용 불가해 한계가 있다.

Method: 각 토큰을 확률 단순체 내에 유지하는 완화된 원-핫 인코딩을 대상으로 지수적 그래디언트 하강법을 적용하고 브레그만 사영으로 제약을 유지하는 내재적 최적화 기법을 제안. 이론적 수렴성 증명과 함께 효율적 알고리즘을 구현. 개별/범용 접미사 생성 및 다른 LLM으로의 전이 실험 수행.

Result: 5개 오픈소스 LLM과 4개 어드버서리얼 행동 데이터셋에서 기존 3개 최첨단 기법 대비 더 높은 공격 성공률과 빠른 수렴을 달성. 또한 여러 프롬프트에 대해 범용 접미사를 생성하고, 최적화된 접미사가 다른 모델로 전이됨을 확인.

Conclusion: 제안 기법은 실제적이고 효율적인 LLM 우회 공격 방법으로, 폐쇄형 모델에도 적용 가능한 이점과 이론적 근거를 모두 제공한다. 이는 LLM 안전성·정렬 연구 및 방어 기법 설계에 중요한 시사점을 준다.

Abstract: As large language models (LLMs) are increasingly deployed in critical
applications, ensuring their robustness and safety alignment remains a major
challenge. Despite the overall success of alignment techniques such as
reinforcement learning from human feedback (RLHF) on typical prompts, LLMs
remain vulnerable to jailbreak attacks enabled by crafted adversarial triggers
appended to user prompts. Most existing jailbreak methods either rely on
inefficient searches over discrete token spaces or direct optimization of
continuous embeddings. While continuous embeddings can be given directly to
selected open-source models as input, doing so is not feasible for proprietary
models. On the other hand, projecting these embeddings back into valid discrete
tokens introduces additional complexity and often reduces attack effectiveness.
We propose an intrinsic optimization method which directly optimizes relaxed
one-hot encodings of the adversarial suffix tokens using exponentiated gradient
descent coupled with Bregman projection, ensuring that the optimized one-hot
encoding of each token always remains within the probability simplex. We
provide theoretical proof of convergence for our proposed method and implement
an efficient algorithm that effectively jailbreaks several widely used LLMs.
Our method achieves higher success rates and faster convergence compared to
three state-of-the-art baselines, evaluated on five open-source LLMs and four
adversarial behavior datasets curated for evaluating jailbreak methods. In
addition to individual prompt attacks, we also generate universal adversarial
suffixes effective across multiple prompts and demonstrate transferability of
optimized suffixes to different LLMs.

</details>


### [131] [Compute-Optimal Scaling for Value-Based Deep RL](https://arxiv.org/abs/2508.14881)
*Preston Fu,Oleh Rybkin,Zhiyuan Zhou,Michal Nauman,Pieter Abbeel,Sergey Levine,Aviral Kumar*

Main category: cs.LG

TL;DR: 논문은 온라인 값 기반 심층 강화학습(특히 TD 학습)에서 주어진 계산 예산 하에 모델 용량과 업데이트-대-데이터(UTD) 비율을 어떻게 최적 분배할지 연구한다. TD-overfitting 현상을 발견하여 작은 모델에서는 큰 배치가 Q-함수 정확도를 악화시키지만 큰 모델에서는 이 현상이 사라져 대규모 배치 사용이 가능함을 보인다. 배치 크기와 UTD 선택을 위한 가이드라인을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 대형 모델과 데이터에서 계산 자원을 효율적으로 사용해 단위 계산당 성능을 극대화하는 'compute-optimal' 학습 전략 연구를 강화학습 영역에 확장하기 위함. 언어 모델링은 잘 연구됐지만 온라인 값 기반 심층 RL의 계산 스케일링은 덜 다뤄졌음.

Method: 모델 용량(크기)과 UTD 비율을 주요 자원 배분 축으로 설정하고, 고정된 계산 예산 하에서 배치 크기, 모델 크기, UTD의 조합이 샘플 효율성과 Q-함수 정확도에 미치는 영향을 실험적으로 분석. TD-overfitting 현상을 정의하고 이를 설명하는 정신적 모델을 제시.

Result: 작은 모델에서는 큰 배치가 Q-함수 정확도를 급격히 손상시키는 TD-overfitting 발생. 큰 모델에서는 TD-overfitting이 나타나지 않아 대규모 배치 및 높은 UTD를 효과적으로 활용 가능. 이를 바탕으로 배치 크기와 UTD 선택을 위한 실용적 가이드를 제공.

Conclusion: TD 학습의 계산-최적 스케일링은 모델 크기와 배치/UTD 간 상호작용을 고려해야 하며, 제시된 가이드라인이 deep RL에서 compute-optimal 학습 전략의 출발점을 제공함.

Abstract: As models grow larger and training them becomes expensive, it becomes
increasingly important to scale training recipes not just to larger models and
more data, but to do so in a compute-optimal manner that extracts maximal
performance per unit of compute. While such scaling has been well studied for
language modeling, reinforcement learning (RL) has received less attention in
this regard. In this paper, we investigate compute scaling for online,
value-based deep RL. These methods present two primary axes for compute
allocation: model capacity and the update-to-data (UTD) ratio. Given a fixed
compute budget, we ask: how should resources be partitioned across these axes
to maximize sample efficiency? Our analysis reveals a nuanced interplay between
model size, batch size, and UTD. In particular, we identify a phenomenon we
call TD-overfitting: increasing the batch quickly harms Q-function accuracy for
small models, but this effect is absent in large models, enabling effective use
of large batch size at scale. We provide a mental model for understanding this
phenomenon and build guidelines for choosing batch size and UTD to optimize
compute usage. Our findings provide a grounded starting point for
compute-optimal scaling in deep RL, mirroring studies in supervised learning
but adapted to TD learning.

</details>


### [132] [Label Smoothing is a Pragmatic Information Bottleneck](https://arxiv.org/abs/2508.14077)
*Sota Kudo*

Main category: cs.LG

TL;DR: 라벨 스무딩(label smoothing)이 정보 병목(Information Bottleneck, IB) 관점에서 해석될 수 있으며, 충분한 모델 유연성과 동일 입력에 대한 충돌하는 라벨이 없다는 가정 하에서 이 방법이 IB의 최적 해를 탐색함을 이론적·실험적으로 보였다.


<details>
  <summary>Details</summary>
Motivation: 라벨 스무딩의 경험적 효용을 이론적으로 설명하고, 그것이 정보 병목 관점에서 어떤 역할을 하는지 밝힘으로써 간단한 구현으로도 유용한 일반화·잡음 불변성 특성을 얻을 수 있음을 제시하려 함.

Method: 충분히 유연한 모델과 충돌 라벨 부재 가정을 두고 라벨 스무딩을 적용한 모델 출력을 정보 병목 문제의 해와 비교하는 이론적 분석과 이를 뒷받침하는 실험적 검증을 수행함.

Result: 라벨 스무딩으로 얻은 모델 출력이 정보 병목의 최적 해를 탐색함을 확인했으며, 타깃과 무관한 요인(또는 다른 변수 조건에서 추가 정보를 제공하지 않는 요인)에 대해 둔감한 특성을 보임.

Conclusion: 라벨 스무딩은 실용적인 정보 병목 방법으로 해석 가능하며, 단순한 구현만으로도 정보 병목이 의도한 일반화 및 불변성 효과를 얻을 수 있음을 보여준다.

Abstract: This study revisits label smoothing via a form of information bottleneck.
Under the assumption of sufficient model flexibility and no conflicting labels
for the same input, we theoretically and experimentally demonstrate that the
model output obtained through label smoothing explores the optimal solution of
the information bottleneck. Based on this, label smoothing can be interpreted
as a practical approach to the information bottleneck, enabling simple
implementation. As an information bottleneck method, we experimentally show
that label smoothing also exhibits the property of being insensitive to factors
that do not contain information about the target, or to factors that provide no
additional information about it when conditioned on another variable.

</details>


### [133] [A Guide to Robust Generalization: The Impact of Architecture, Pre-training, and Optimization Strategy](https://arxiv.org/abs/2508.14079)
*Maxime Heuillet,Rishika Bhagwatkar,Jonas Ngnawé,Yann Pequignot,Alexandre Larouche,Christian Gagné,Irina Rish,Ola Ahmad,Audrey Durand*

Main category: cs.LG

TL;DR: 대규모 실험을 통해 'robust fine-tuning'의 설계 선택(사전학습 표현, 아키텍처, 업데이트 프로토콜, 특수 손실)이 테스트 시 보정(perturbations)에 대한 일반화 성능에 미치는 영향을 분석한 벤치마크 연구.


<details>
  <summary>Details</summary>
Motivation: 이미지 도메인 딥러닝 모델은 작은 입력 교란에 취약하며, 사전학습 모델을 활용해 효율적으로 강건성을 얻는 'robust fine-tuning'이 주목받고 있다. 하지만 아키텍처, 사전학습 방식, 업데이트 프로토콜, 손실 함수 등 설계 선택이 강건한 일반화에 어떻게 영향을 미치는지는 명확하지 않다.

Method: 6개 데이터셋, 40개 사전학습 아키텍처, 2종 특수 손실, 3종 적응(업데이트) 프로토콜을 조합해 총 1,440개의 학습 설정과 5종 교란 유형에 대해 7,200개의 강건성 측정을 수행한 대규모 실험적 벤치마크를 구축하고 분석.

Result: 일부 기대와 달리 대규모 감독학습으로 사전학습된 컨볼루션 신경망(CNN)이 종종 최상 성능을 보였고, 주목받는 어텐션 기반 아키텍처나 'robust' 사전학습 표현이 항상 우수하지는 않았다. 여러 설계 가정이 확인되기도 하고 반박되기도 했으며, 실무적 가이드라인과 향후 연구 방향을 제시.

Conclusion: robust fine-tuning을 설계할 때 아키텍처 유형과 사전학습 방식이 성능에 큰 영향을 미치며, 넓은 범위의 조합 실험이 필요하다. 본 벤치마크는 실무자와 연구자에게 실용적 지침과 추가 연구 포인트를 제공한다.

Abstract: Deep learning models operating in the image domain are vulnerable to small
input perturbations. For years, robustness to such perturbations was pursued by
training models from scratch (i.e., with random initializations) using
specialized loss objectives. Recently, robust fine-tuning has emerged as a more
efficient alternative: instead of training from scratch, pretrained models are
adapted to maximize predictive performance and robustness. To conduct robust
fine-tuning, practitioners design an optimization strategy that includes the
model update protocol (e.g., full or partial) and the specialized loss
objective. Additional design choices include the architecture type and size,
and the pretrained representation. These design choices affect robust
generalization, which is the model's ability to maintain performance when
exposed to new and unseen perturbations at test time. Understanding how these
design choices influence generalization remains an open question with
significant practical implications. In response, we present an empirical study
spanning 6 datasets, 40 pretrained architectures, 2 specialized losses, and 3
adaptation protocols, yielding 1,440 training configurations and 7,200
robustness measurements across five perturbation types. To our knowledge, this
is the most diverse and comprehensive benchmark of robust fine-tuning to date.
While attention-based architectures and robust pretrained representations are
increasingly popular, we find that convolutional neural networks pretrained in
a supervised manner on large datasets often perform best. Our analysis both
confirms and challenges prior design assumptions, highlighting promising
research directions and offering practical guidance.

</details>


### [134] [Toward Generalist Semi-supervised Regression via Decoupled Representation Distillation](https://arxiv.org/abs/2508.14082)
*Ye Su,Hezhe Qiao,Wei Huang,Lin Chen*

Main category: cs.LG

TL;DR: The paper proposes DRILL, a semi-supervised regression framework that converts regression into a discrete distribution estimation over buckets and uses decoupled distribution alignment between teacher and student to improve robustness and reduce overfitting.


<details>
  <summary>Details</summary>
Motivation: Existing semi-supervised regression methods rely on pseudo-labels and direct regression, which are sensitive to pseudo-label quality and prone to overfitting; need to better capture label distribution.

Method: Introduce DRILL: (1) transform continuous regression into Discrete Distribution Estimation (DDE) across multiple buckets to model label distribution; (2) apply Decoupled Distribution Alignment (DDA) to align target and non-target bucket distributions between teacher and student, encouraging robust knowledge transfer.

Result: Extensive experiments across diverse-domain datasets demonstrate that DRILL generalizes well and outperforms competing semi-supervised regression methods.

Conclusion: DRILL effectively mitigates pseudo-label sensitivity and overfitting in semi-supervised regression by modeling label distributions and using decoupled alignment, yielding strong empirical performance.

Abstract: Semi-supervised regression (SSR), which aims to predict continuous scores of
samples while reducing reliance on a large amount of labeled data, has recently
received considerable attention across various applications, including computer
vision, natural language processing, and audio and medical analysis. Existing
semi-supervised methods typically apply consistency regularization on the
general regression task by generating pseudo-labels. However, these methods
heavily rely on the quality of pseudo-labels, and direct regression fails to
learn the label distribution and can easily lead to overfitting. To address
these challenges, we introduce an end-to-end Decoupled Representation
distillation framework (DRILL) which is specially designed for the
semi-supervised regression task where we transform the general regression task
into a Discrete Distribution Estimation (DDE) task over multiple buckets to
better capture the underlying label distribution and mitigate the risk of
overfitting associated with direct regression. Then we employ the Decoupled
Distribution Alignment (DDA) to align the target bucket and non-target bucket
between teacher and student on the distribution of buckets, encouraging the
student to learn more robust and generalized knowledge from the teacher.
Extensive experiments conducted on datasets from diverse domains demonstrate
that the proposed DRILL has strong generalization and outperforms the competing
methods.

</details>


### [135] [GeoMAE: Masking Representation Learning for Spatio-Temporal Graph Forecasting with Missing Values](https://arxiv.org/abs/2508.14083)
*Songyu Ke,Chenyu Wu,Yuxuan Liang,Xiuwen Yi,Yanping Sun,Junbo Zhang,Yu Zheng*

Main category: cs.LG

TL;DR: 이 논문은 POI(관심 지점)의 군중 흐름을 저품질 도시 센서 데이터에서 추론하기 위해, 자기지도 대조 학습 기반의 시공간 그래프 표현학습 프레임워크(CSST)를 제안한다. 거리 기반 인접 그래프를 구성하고, 스왑 예측 대조학습으로 타깃 서브그래프 표현을 예측한 뒤 정밀 라벨로 미세조정하여 소음 많은 데이터로 사전학습한 모델이 처음부터 학습한 모델보다 우수함을 보였다.


<details>
  <summary>Details</summary>
Motivation: 도시 센싱 데이터의 품질 부족으로 POI별 정확한 군중 흐름 추정이 어려우며, 라벨 데이터 희소성, POI 간 복잡한 시공간 의존성, 정확한 군중 흐름과 GPS 리포트 간의 다양한 상관관계 때문에 문제 해결이 어렵다.

Method: POI들의 거리에 기반해 공간 인접 그래프를 구성하고, 대량의 레이블 없는 시공간 데이터를 활용한 대조학습(self-supervised contrastive learning) 실시. 스왑 예측(swapped prediction) 기법으로 유사한 인스턴스에서 타깃 서브그래프의 표현을 예측함. 사전학습 후 정확한 군중 흐름 라벨로 미세조정(fine-tuning).

Result: 두 개의 실제 데이터셋에서 실험하여, 노이즈가 많은 대규모 데이터로 사전학습한 CSST가 처음부터 학습한 모델을 일관되게 능가함을 보였다.

Conclusion: 자기지도 대조 학습을 통한 시공간 그래프 사전학습은 라벨이 희소하고 관측이 noisy한 도시 군중 흐름 추론에 효과적이며, 미세조정으로 성능 향상이 가능하다.

Abstract: Accurate acquisition of crowd flow at Points of Interest (POIs) is pivotal
for effective traffic management, public service, and urban planning. Despite
this importance, due to the limitations of urban sensing techniques, the data
quality from most sources is inadequate for monitoring crowd flow at each POI.
This renders the inference of accurate crowd flow from low-quality data a
critical and challenging task. The complexity is heightened by three key
factors: 1) \emph{The scarcity and rarity of labeled data}, 2) \emph{The
intricate spatio-temporal dependencies among POIs}, and 3) \emph{The myriad
correlations between precise crowd flow and GPS reports}.
  To address these challenges, we recast the crowd flow inference problem as a
self-supervised attributed graph representation learning task and introduce a
novel \underline{C}ontrastive \underline{S}elf-learning framework for
\underline{S}patio-\underline{T}emporal data (\model). Our approach initiates
with the construction of a spatial adjacency graph founded on the POIs and
their respective distances. We then employ a contrastive learning technique to
exploit large volumes of unlabeled spatio-temporal data. We adopt a swapped
prediction approach to anticipate the representation of the target subgraph
from similar instances. Following the pre-training phase, the model is
fine-tuned with accurate crowd flow data. Our experiments, conducted on two
real-world datasets, demonstrate that the \model pre-trained on extensive noisy
data consistently outperforms models trained from scratch.

</details>


### [136] [EEGDM: EEG Representation Learning via Generative Diffusion Model](https://arxiv.org/abs/2508.14086)
*Jia Hong Puah,Sim Kuan Goh,Ziwei Zhang,Zixuan Ye,Chow Khuen Chan,Kheng Seang Lim,Si Lei Fong,Kok Sin Woon*

Main category: cs.LG

TL;DR: EEGDM은 생성 확산모델 기반의 EEG 표현학습 프레임워크로, 구조화된 상태-공간 모델(SSMDP)을 확산 사전학습에 적용하고, 얻은 잠재 표현을 Latent Fusion Transformer(LFT)로 downstream 분류에 활용한다. Temple University EEG Event Corpus에서 기존 EEG FMs와 SOTA 방법들을 능가하면서 약 19배 가볍다는 점을 보였다.


<details>
  <summary>Details</summary>
Motivation: EEG는 주석 부족과 높은 신호 변동성 때문에 의미 있는 표현 학습이 어려우며, 최근의 EEG 기반 파운데이션 모델들은 트랜스포머와 자기지도학습을 사용하지만 모델 규모 증가에 따른 계산 비용만 커지고 성능 향상은 미미한 문제를 가졌다. 이 문제를 해결할 경량이면서 효과적인 대안이 필요하다.

Method: Denoising Diffusion Probabilistic Model(DDPM)에 기반한 확산 사전학습을 사용하며, EEG의 시간 역학을 더 잘 포착하기 위해 구조화된 상태-공간 모델(SSMDP)을 설계했다. 사전학습으로 얻은 잠재 표현은 Latent Fusion Transformer(LFT)를 통해 downstream 분류에 활용된다.

Result: Temple University EEG Event Corpus에서 실험한 결과, EEGDM은 기존 방법들(EEG FMs 포함)보다 우수한 성능을 보였고 모델 크기 측면에서 약 19배 가벼운 것으로 보고되었다.

Conclusion: EEGDM은 기존 EEG 파운데이션 모델에 대한 유망한 대안으로서, 계산 효율성과 성능을 동시에 개선할 수 있음을 시사한다.

Abstract: While electroencephalogram (EEG) has been a crucial tool for monitoring the
brain and diagnosing neurological disorders (e.g., epilepsy), learning
meaningful representations from raw EEG signals remains challenging due to
limited annotations and high signal variability. Recently, EEG foundation
models (FMs) have shown promising potential by adopting transformer
architectures and self-supervised pre-training methods from large language
models (e.g., masked prediction) to learn representations from diverse EEG
data, followed by fine-tuning on specific EEG tasks. Nonetheless, these large
models often incurred high computational costs during both training and
inference, with only marginal performance improvements as model size increases.
In this work, we proposed EEG representation learning framework building upon
Generative Diffusion Model (EEGDM). Specifically, we developed structured
state-space model for diffusion pretraining (SSMDP) to better capture the
temporal dynamics of EEG signals and trained the architecture using a Denoising
Diffusion Probabilistic Model. The resulting latent EEG representations were
then used for downstream classification tasks via our proposed latent fusion
transformer (LFT). To evaluate our method, we used the multi-event Temple
University EEG Event Corpus and compared EEGDM with current state-of-the-art
approaches, including EEG FMs. Empirical results showed that our method
outperformed existing methods while being approximately 19x more lightweight.
These findings suggested that EEGDM offered a promising alternative to current
FMs. Our code is available at: https://github.com/jhpuah/EEGDM.

</details>


### [137] [FM4NPP: A Scaling Foundation Model for Nuclear and Particle Physics](https://arxiv.org/abs/2508.14087)
*David Park,Shuhang Li,Yi Huang,Xihaier Luo,Haiwang Yu,Yeonju Go,Christopher Pinkenburg,Yuewei Lin,Shinjae Yoo,Joseph Osborn,Jin Huang,Yihui Ren*

Main category: cs.LG

TL;DR: 이 논문은 입자 물리학 분야에서 실험 검출기 데이터를 위한 대규모 자기지도 학습 기반의 기초 모델(FM)을 제안하고, 1,100만 개 이상의 충돌 이벤트 데이터셋과 다운스트림 과제들을 통해 모델 확장성과 일반화 능력을 평가한다. 1.88억 파라미터 모델까지 학습하여 동결 가중치와 태스크별 어댑터로 다양한 작업에서 기존 모델을 능가하며, 적은 데이터로도 빠르게 적응함을 보인다.


<details>
  <summary>Details</summary>
Motivation: 자연어에서 성공한 자기지도 학습 기반의 대규모 기초 모델(FMs)을 입자 물리학의 실험 검출기 데이터에 적용하려는 동기. 검출기 데이터는 희박하고 공간적으로 분포되어 있어 자연어와 큰 차이가 있으므로, 스케일과 일반화 가능성 검증이 필요.

Method: 새로운 1,100만 건 이상의 충돌 이벤트 데이터셋과 평가용 다운스트림 태스크 라벨을 구성하고, 검출기 데이터에 특화된 새로운 자기지도 학습 방법을 제안. 모델은 최대 1.88억 파라미터 규모로 확장했고, 파라미터 동결 + 태스크별 어댑터 방식으로 전이 학습을 수행.

Result: 동결된 FM과 어댑터 조합이 모든 다운스트림 태스크에서 기준선(베이스라인) 모델을 지속적으로 능가함. 또한 데이터 효율적인 적응을 보여 소량의 라벨 데이터로도 좋은 성능을 유지. 추출된 표현은 태스크에 무관한 일반적 특성을 지니며, 단일 선형 매핑으로 다양한 다운스트림 태스크에 특화될 수 있음.

Conclusion: 검출기 데이터에 대한 자기지도 기반의 기초 모델은 스케일링과 일반화가 가능하며, 태스크별 어댑터를 통해 실험 물리학의 다양한 과제에 효과적으로 적용될 수 있다. 표현학습 결과는 범용적이며 적은 자원으로도 적응 가능함.

Abstract: Large language models have revolutionized artificial intelligence by enabling
large, generalizable models trained through self-supervision. This paradigm has
inspired the development of scientific foundation models (FMs). However,
applying this capability to experimental particle physics is challenging due to
the sparse, spatially distributed nature of detector data, which differs
dramatically from natural language. This work addresses if an FM for particle
physics can scale and generalize across diverse tasks. We introduce a new
dataset with more than 11 million particle collision events and a suite of
downstream tasks and labeled data for evaluation. We propose a novel
self-supervised training method for detector data and demonstrate its neural
scalability with models that feature up to 188 million parameters. With frozen
weights and task-specific adapters, this FM consistently outperforms baseline
models across all downstream tasks. The performance also exhibits robust
data-efficient adaptation. Further analysis reveals that the representations
extracted by the FM are task-agnostic but can be specialized via a single
linear mapping for different downstream tasks.

</details>


### [138] [Neuro-inspired Ensemble-to-Ensemble Communication Primitives for Sparse and Efficient ANNs](https://arxiv.org/abs/2508.14140)
*Orestis Konstantaropoulos,Stelios Manolis Smirnakis,Maria Papadopouli*

Main category: cs.LG

TL;DR: Introduce G2GNet, a biologically inspired sparse, modular feedforward architecture using ensemble-to-ensemble connectivity and dynamic sparse training with Hebbian-like rewiring; achieves up to 75% sparsity and improves accuracy on standard vision benchmarks despite fewer parameters.


<details>
  <summary>Details</summary>
Motivation: Biological neural circuits are modular, hierarchical, and sparsely connected, offering efficient trade-offs; authors aim to transfer ensemble-to-ensemble functional connectivity patterns from mouse visual cortex to ANN design to reduce cost and improve performance.

Method: Propose G2GNet that imposes sparse, modular connectivity across feedforward layers reflecting ensemble-to-ensemble communication; complement with Dynamic Sparse Training (DST) that prunes and regrows edges during training using a Hebbian-inspired rewiring rule based on activation correlations.

Result: G2GNet attains up to 75% sparsity while improving accuracy by up to 4.3% on Fashion-MNIST, CIFAR-10, and CIFAR-100, outperforming dense baselines with fewer parameters and computations.

Conclusion: Incorporating biologically observed functional connectivity as a structural bias, combined with activity-driven DST, yields more efficient and sometimes more accurate vision models; suggests biological connectivity patterns are useful priors for ANN architecture design.

Abstract: The structure of biological neural circuits-modular, hierarchical, and
sparsely interconnected-reflects an efficient trade-off between wiring cost,
functional specialization, and robustness. These principles offer valuable
insights for artificial neural network (ANN) design, especially as networks
grow in depth and scale. Sparsity, in particular, has been widely explored for
reducing memory and computation, improving speed, and enhancing generalization.
Motivated by systems neuroscience findings, we explore how patterns of
functional connectivity in the mouse visual cortex-specifically,
ensemble-to-ensemble communication, can inform ANN design. We introduce G2GNet,
a novel architecture that imposes sparse, modular connectivity across
feedforward layers. Despite having significantly fewer parameters than fully
connected models, G2GNet achieves superior accuracy on standard vision
benchmarks. To our knowledge, this is the first architecture to incorporate
biologically observed functional connectivity patterns as a structural bias in
ANN design. We complement this static bias with a dynamic sparse training (DST)
mechanism that prunes and regrows edges during training. We also propose a
Hebbian-inspired rewiring rule based on activation correlations, drawing on
principles of biological plasticity. G2GNet achieves up to 75% sparsity while
improving accuracy by up to 4.3% on benchmarks, including Fashion-MNIST,
CIFAR-10, and CIFAR-100, outperforming dense baselines with far fewer
computations.

</details>


### [139] [A Non-Asymptotic Convergent Analysis for Scored-Based Graph Generative Model via a System of Stochastic Differential Equations](https://arxiv.org/abs/2508.14351)
*Junwei Su,Chuan Wu*

Main category: cs.LG

TL;DR: 이 논문은 그래프용 SDE 기반 확률적(score-based) 생성모델(SGGM)의 수렴성에 대한 최초의 비점근적(non-asymptotic) 이론적 분석을 제시한다. 그래프 구조와 노드 특징이 서로 연관된 복수의 coupled SDE로 기술되므로 기존 SGM 수렴 분석을 직접 적용할 수 없음을 지적하고, 세 가지 그래프 생성 시나리오(고정 그래프에서의 특징 생성, 고정 특징에서의 그래프 생성, 두 요소의 동시 생성)에 대해 수렴 상한(생성 오차 리스크)을 유도한다. 분석 결과는 그래프 토폴로지 등 SGGMs에 특유한 요인들이 수렴에 영향을 미친다는 점과 샘플링 스텝, 확산 길이 같은 하이퍼파라미터 선택에 대한 이론적 가이드를 제공하며, 정규화 등 기법을 권장한다. 합성 데이터 실험으로 이론을 검증한다.


<details>
  <summary>Details</summary>
Motivation: SGGM은 약물발견, 단백질 합성 등 중요한 응용에서 유용하지만, 그래프 구조와 노드 특징을 동시에 다루는 복합성 때문에 기존 SGM의 수렴성 이론이 적용되지 않아 이론적 이해가 부족했다. 이에 SGGMs의 수렴성을 엄격히 분석할 필요가 있다.

Method: SGGM을 복수의 연관된 SDE 시스템으로 수학적으로 모델링하고, 세 가지 생성 시나리오별로 비점근적 수렴 상한을 도출한다. 분석 과정에서 그래프 토폴로지, 하이퍼파라미터(샘플링 스텝, 확산 길이) 영향 등을 정량화하며 정규화 같은 개선 기법의 이론적 이점을 제시한다. 합성 그래프 데이터 실험으로 이론적 결과를 검증한다.

Result: 세 가지 생성 설정에서 생성 오차의 비점근적 수렴 상한을 얻었고, 그래프 특이성(예: 토폴로지)이 수렴성에 영향을 미침을 보였다. 하이퍼파라미터와 정규화가 수렴 개선에 유리하다는 이론적/실험적 증거를 제공했다.

Conclusion: SGGMs의 수렴성에 대한 최초의 비점근적 분석을 통해 그래프 생성 모델 설계와 하이퍼파라미터 선택에 대한 이론적 가이드를 제시하며, 향후 그래프 생성 모델의 안정성과 효율성 향상에 기여한다.

Abstract: Score-based graph generative models (SGGMs) have proven effective in critical
applications such as drug discovery and protein synthesis. However, their
theoretical behavior, particularly regarding convergence, remains
underexplored. Unlike common score-based generative models (SGMs), which are
governed by a single stochastic differential equation (SDE), SGGMs involve a
system of coupled SDEs. In SGGMs, the graph structure and node features are
governed by separate but interdependent SDEs. This distinction makes existing
convergence analyses from SGMs inapplicable for SGGMs. In this work, we present
the first non-asymptotic convergence analysis for SGGMs, focusing on the
convergence bound (the risk of generative error) across three key graph
generation paradigms: (1) feature generation with a fixed graph structure, (2)
graph structure generation with fixed node features, and (3) joint generation
of both graph structure and node features. Our analysis reveals several unique
factors specific to SGGMs (e.g., the topological properties of the graph
structure) which affect the convergence bound. Additionally, we offer
theoretical insights into the selection of hyperparameters (e.g., sampling
steps and diffusion length) and advocate for techniques like normalization to
improve convergence. To validate our theoretical findings, we conduct a
controlled empirical study using synthetic graph models, and the results align
with our theoretical predictions. This work deepens the theoretical
understanding of SGGMs, demonstrates their applicability in critical domains,
and provides practical guidance for designing effective models.

</details>


### [140] [Exact Shapley Attributions in Quadratic-time for FANOVA Gaussian Processes](https://arxiv.org/abs/2508.14499)
*Majid Mohammadi,Krikamol Muandet,Ilaria Tiddi,Annette Ten Teije,Siu Lun Chau*

Main category: cs.LG

TL;DR: 이 논문은 FANOVA 구조를 가진 가우시안 프로세스(GP)에 대해 정확한 Shapley 값(국소 및 전역 해석)을 이차 시간(quadratic time)에 계산하는 알고리즘을 제안한다. 확률적 출력의 기여도와 불확실성까지 포착하며, M"obius 표현과 뉴턴의 항등식에 영감을 받은 재귀 알고리즘을 활용한다.


<details>
  <summary>Details</summary>
Motivation: Shapley 값은 입력 특징의 중요도를 원칙적으로 분배하는 방법이지만, 특징 수에 대해 지수적으로 확장되어 실제 적용이 어려움. 특히 예측 모델이 확률적(예: GP)일 경우 출력이 확률변수여서 고차 모멘트 계산이 필요해 추가 계산 부담이 큼.

Method: FANOVA GP에 대해 함수 성분 위의 확률적 협동게임을 정의하여 국소 설명을 위한 확률적 Shapley 값을 도입하고, 전역 설명을 위해 분산 기반 결정론적 가치 함수를 사용. M"obius 표현의 닫힌형 표현을 이용하고 뉴턴 항등식에서 영감을 받은 재귀 알고리즘으로 Shapley 값의 평균과 분산을 효율적으로 계산함.

Result: 국소 및 전역 Shapley 값의 정확한 계산을 이차 시간에 달성. 확률적 Shapley는 기대 기여도와 불확실성을 모두 캡처하며, 분산 기반 전역값 함수는 모델의 전반적 민감도에 대한 특징 기여도를 정량화함. 실험적으로 더 확장 가능하고 공리적으로 타당하며 불확실성을 고려한 설명 제공이 입증됨.

Conclusion: FANOVA GP 구조를 활용하면 구조화된 확률적 모델에 대해 효율적이고 불확실성 인식이 가능한 정확한 Shapley 기반 설명을 제공할 수 있으며, 이는 XAI의 실용성을 향상시킴.

Abstract: Shapley values are widely recognized as a principled method for attributing
importance to input features in machine learning. However, the exact
computation of Shapley values scales exponentially with the number of features,
severely limiting the practical application of this powerful approach. The
challenge is further compounded when the predictive model is probabilistic - as
in Gaussian processes (GPs) - where the outputs are random variables rather
than point estimates, necessitating additional computational effort in modeling
higher-order moments. In this work, we demonstrate that for an important class
of GPs known as FANOVA GP, which explicitly models all main effects and
interactions, *exact* Shapley attributions for both local and global
explanations can be computed in *quadratic time*. For local, instance-wise
explanations, we define a stochastic cooperative game over function components
and compute the exact stochastic Shapley value in quadratic time only,
capturing both the expected contribution and uncertainty. For global
explanations, we introduce a deterministic, variance-based value function and
compute exact Shapley values that quantify each feature's contribution to the
model's overall sensitivity. Our methods leverage a closed-form (stochastic)
M\"{o}bius representation of the FANOVA decomposition and introduce recursive
algorithms, inspired by Newton's identities, to efficiently compute the mean
and variance of Shapley values. Our work enhances the utility of explainable
AI, as demonstrated by empirical studies, by providing more scalable,
axiomatically sound, and uncertainty-aware explanations for predictions
generated by structured probabilistic models.

</details>


### [141] [Disentanglement in T-space for Faster and Distributed Training of Diffusion Models with Fewer Latent-states](https://arxiv.org/abs/2508.14413)
*Samarth Gupta,Raghudeep Gadde,Rui Chen,Aleix M. Martinez*

Main category: cs.LG

TL;DR: The paper shows diffusion models can be trained with very few latent-states (T≈32) and even a single latent-state via a disentangled T-space approach, matching performance of large-T models and achieving 4–6× faster convergence by combining independently trained single-state models.


<details>
  <summary>Details</summary>
Motivation: Challenge the common assumption that diffusion models require many time-steps/latent-states so the reverse process approximates a Gaussian, aiming to improve training efficiency.

Method: Design careful noise schedules to enable training with small T (≈32); push to complete disentanglement in T-space using single latent-state models and generate samples by combining several independently trained single-state models.

Result: Models trained with small T match performance of models with large T (≈1000). The disentangled single-state approach yields high-quality samples when combined and achieves 4–6× faster convergence across multiple metrics on two datasets.

Conclusion: Diffusion training does not inherently require many latent-states; with proper noise scheduling and disentanglement in T-space, training can be made much more efficient without performance loss.

Abstract: We challenge a fundamental assumption of diffusion models, namely, that a
large number of latent-states or time-steps is required for training so that
the reverse generative process is close to a Gaussian. We first show that with
careful selection of a noise schedule, diffusion models trained over a small
number of latent states (i.e. $T \sim 32$) match the performance of models
trained over a much large number of latent states ($T \sim 1,000$). Second, we
push this limit (on the minimum number of latent states required) to a single
latent-state, which we refer to as complete disentanglement in T-space. We show
that high quality samples can be easily generated by the disentangled model
obtained by combining several independently trained single latent-state models.
We provide extensive experiments to show that the proposed disentangled model
provides 4-6$\times$ faster convergence measured across a variety of metrics on
two different datasets.

</details>


### [142] [Personalized Counterfactual Framework: Generating Potential Outcomes from Wearable Data](https://arxiv.org/abs/2508.14432)
*Ajan Subramanian,Amir M. Rahmani*

Main category: cs.LG

TL;DR: 개인화 웨어러블 센서 데이터를 이용해 다변량 시계열에서 개인별 반사실적(counterfactual) 모델을 학습하는 프레임워크를 제시한다. 유사 환자 데이터로 보강하고 시간적 PC 알고리즘 변형으로 인과적 예측 관계를 발견한 뒤 GBM으로 개인별 효과를 추정해 가정적 개입에 따른 생리학적 궤적을 예측한다.


<details>
  <summary>Details</summary>
Motivation: 웨어러블 센서의 복잡하고 장기간 누적된 데이터에서 개인별 행동 변화가 생리적 결과에 미치는 영향을 이해하고, 개인화된 가설을 생성하기 위함.

Method: 유사 환자 멀티모달 유사성 분석으로 데이터 보강 → 시간적 PC 알고리즘 변형으로 t-1 변수가 t에 미치는 예측 관계 탐색 → 발견된 관계에 대해 Gradient Boosting Machines 학습 → 학습된 모델로 반사실 엔진 구현해 개입 시나리오(활동·수면 변화 등) 결과 예측.

Result: 1-step ahead 예측(심박수 MAE 4.71 bpm 등)에서 합리적 정확도를 보였고, 반사실적 예측의 타당성(median 0.9643)도 높게 평가됨. 개입에 대한 개인 간 반응 차이가 큼.

Conclusion: 제안 프레임워크는 개인별 건강 역학을 탐색하고 생활습관 변화에 대한 개인 반응 가설을 생성하는 유용한 도구로 작동할 수 있음.

Abstract: Wearable sensor data offer opportunities for personalized health monitoring,
yet deriving actionable insights from their complex, longitudinal data streams
is challenging. This paper introduces a framework to learn personalized
counterfactual models from multivariate wearable data. This enables exploring
what-if scenarios to understand potential individual-specific outcomes of
lifestyle choices. Our approach first augments individual datasets with data
from similar patients via multi-modal similarity analysis. We then use a
temporal PC (Peter-Clark) algorithm adaptation to discover predictive
relationships, modeling how variables at time t-1 influence physiological
changes at time t. Gradient Boosting Machines are trained on these discovered
relationships to quantify individual-specific effects. These models drive a
counterfactual engine projecting physiological trajectories under hypothetical
interventions (e.g., activity or sleep changes). We evaluate the framework via
one-step-ahead predictive validation and by assessing the plausibility and
impact of interventions. Evaluation showed reasonable predictive accuracy
(e.g., mean heart rate MAE 4.71 bpm) and high counterfactual plausibility
(median 0.9643). Crucially, these interventions highlighted significant
inter-individual variability in response to hypothetical lifestyle changes,
showing the framework's potential for personalized insights. This work provides
a tool to explore personalized health dynamics and generate hypotheses on
individual responses to lifestyle changes.

</details>


### [143] [Artificial Intelligence-Based Multiscale Temporal Modeling for Anomaly Detection in Cloud Services](https://arxiv.org/abs/2508.14503)
*Lian Lian,Yilin Li,Song Han,Renzi Meng,Sibo Wang,Ming Wang*

Main category: cs.LG

TL;DR: Transformer 기반 멀티스케일 시계열 이상탐지 방법 제안. 개선된 Transformer로 장기 종속성 포착, 다중 스케일 경로와 어텐션 가중치 융합으로 스케일 민감성 보완. 표준화된 다차원 시계열 입력과 위치 인코딩 사용. 다양한 조건에서 베이스라인보다 우수한 정밀도·재현율·AUC·F1 성능 및 안정성 보고.


<details>
  <summary>Details</summary>
Motivation: 클라우드 서비스 모니터링 데이터에서 기존 기법들이 시간적 모델링과 스케일에 민감한 특징 표현에 한계가 있어, 이를 개선할 수 있는 구조가 필요함.

Method: 개선된 Transformer 모듈로 고차원 모니터링 데이터의 시간적 모델링 수행. 다운샘플링과 병렬 인코더로 멀티스케일 특징을 구성하고, 어텐션-가중치 융합 모듈로 각 스케일 기여도를 동적으로 조정. 입력 단계에서 CPU·메모리·스케줄링 상태를 포함한 표준화된 다차원 시계열을 구성하고 위치 인코딩 적용. 실험은 비교실험과 하이퍼파라미터 민감도 분석으로 구성.

Result: 제안 기법이 정밀도, 재현율, AUC, F1에서 주요 베이스라인을 능가하며 다양한 노이즈·비율 조건에서도 안정적인 성능을 보임.

Conclusion: 멀티스케일 인식과 어텐션 기반 융합을 통해 클라우드 환경의 복잡한 이상 패턴을 효과적으로 모델링하여 이상탐지 성능과 안정성을 향상시킴.

Abstract: This study proposes an anomaly detection method based on the Transformer
architecture with integrated multiscale feature perception, aiming to address
the limitations of temporal modeling and scale-aware feature representation in
cloud service environments. The method first employs an improved Transformer
module to perform temporal modeling on high-dimensional monitoring data, using
a self-attention mechanism to capture long-range dependencies and contextual
semantics. Then, a multiscale feature construction path is introduced to
extract temporal features at different granularities through downsampling and
parallel encoding. An attention-weighted fusion module is designed to
dynamically adjust the contribution of each scale to the final decision,
enhancing the model's robustness in anomaly pattern modeling. In the input
modeling stage, standardized multidimensional time series are constructed,
covering core signals such as CPU utilization, memory usage, and task
scheduling states, while positional encoding is used to strengthen the model's
temporal awareness. A systematic experimental setup is designed to evaluate
performance, including comparative experiments and hyperparameter sensitivity
analysis, focusing on the impact of optimizers, learning rates, anomaly ratios,
and noise levels. Experimental results show that the proposed method
outperforms mainstream baseline models in key metrics, including precision,
recall, AUC, and F1-score, and maintains strong stability and detection
performance under various perturbation conditions, demonstrating its superior
capability in complex cloud environments.

</details>


### [144] [AFABench: A Generic Framework for Benchmarking Active Feature Acquisition](https://arxiv.org/abs/2508.14734)
*Valter Schütz,Han Wu,Reza Rezvan,Linus Aronsson,Morteza Haghir Chehreghani*

Main category: cs.LG

TL;DR: 논문은 Active Feature Acquisition(AFA) 문제를 위한 최초의 벤치마크 AFABench를 제안한다. 다양한 합성 및 실제 데이터셋, 여러 획득 정책(정적, 탐욕적, 강화학습 기반)을 포함하고 모듈식 설계를 제공하며, AFA의 탐색 능력을 시험하기 위한 새로운 합성 데이터셋 AFAContext를 소개한다. 구현과 평가 결과는 다양한 전략 간의 상충관계를 보여준다.


<details>
  <summary>Details</summary>
Motivation: 실제 환경에서 모든 피처를 수집하는 비용·지연·프라이버시 문제가 있어, 각 인스턴스별로 정보가 많은 피처만 선택해 예측 성능과 획득 비용을 절충하는 AFA의 중요성이 증가했으나, 해당 분야의 공정하고 체계적인 평가를 위한 표준화된 벤치마크가 부재함.

Method: AFABench라는 벤치마크 프레임워크를 설계·구현. 합성 및 실제 데이터셋을 포함하고, 다양한 획득 정책(정적, 탐욕적, 강화학습)을 통합 및 비교 가능하게 모듈식으로 구성. 또한 탐욕적 선택의 한계를 드러내기 위한 합성 데이터셋 AFAContext를 새로 제안.

Result: 대표적 알고리즘들을 구현·평가해 각 접근법 간의 성능-비용 트레이드오프를 규명. AFAContext를 통해 탐욕적 정책의 한계(lookahead 능력 부족)를 드러내는 사례를 제시.

Conclusion: AFABench는 AFA 연구를 위한 첫 포괄적 벤치마크로, 향후 방법 개발과 공정 비교를 촉진할 수 있으며, AFAContext는 비탐욕적 전략 필요성을 강조한다.

Abstract: In many real-world scenarios, acquiring all features of a data instance can
be expensive or impractical due to monetary cost, latency, or privacy concerns.
Active Feature Acquisition (AFA) addresses this challenge by dynamically
selecting a subset of informative features for each data instance, trading
predictive performance against acquisition cost. While numerous methods have
been proposed for AFA, ranging from greedy information-theoretic strategies to
non-myopic reinforcement learning approaches, fair and systematic evaluation of
these methods has been hindered by the lack of standardized benchmarks. In this
paper, we introduce AFABench, the first benchmark framework for AFA. Our
benchmark includes a diverse set of synthetic and real-world datasets, supports
a wide range of acquisition policies, and provides a modular design that
enables easy integration of new methods and tasks. We implement and evaluate
representative algorithms from all major categories, including static, greedy,
and reinforcement learning-based approaches. To test the lookahead capabilities
of AFA policies, we introduce a novel synthetic dataset, AFAContext, designed
to expose the limitations of greedy selection. Our results highlight key
trade-offs between different AFA strategies and provide actionable insights for
future research. The benchmark code is available at:
https://github.com/Linusaronsson/AFA-Benchmark.

</details>


### [145] [Great GATsBi: Hybrid, Multimodal, Trajectory Forecasting for Bicycles using Anticipation Mechanism](https://arxiv.org/abs/2508.14523)
*Kevin Riehl,Shaimaa K. El-Baklish,Anastasios Kouvelas,Michail A. Makridis*

Main category: cs.LG

TL;DR: Bicycle-specific hybrid trajectory prediction (Great GATsBi) combining physics-based ensemble and social graph-attention models that use decayed historical and anticipated future neighbor trajectories; outperforms state-of-the-art and validated with a controlled mass-cycling experiment.


<details>
  <summary>Details</summary>
Motivation: 자전거 관련 교통사고 사망률이 높지만 기존 연구는 보행자·차량에 집중되어 있어 자전거 움직임을 정확히 예측하는 모델이 필요함.

Method: 도메인 지식 기반 하이브리드 멀티모달 프레임워크(Great GATsBi). 물리 기반 모델(짧은 시점 예측에 강함)과 사회적 상호작용 모델(그래프 어텐션 네트워크)을 앙상블. 이웃 자전거의 감쇠된 과거 및 예상 미래 궤적을 입력으로 사용.

Result: 제안한 물리·사회 모델 앙상블이 단기·장기 예측 모두에서 성능 향상, 기존 최첨단 기법들보다 우수한 성능을 보임. 통제된 집단 사이클링 실험으로 성능 및 상호작용 모델링 검증.

Conclusion: 자전거의 이중적 이동 특성을 반영한 하이브리드 접근이 궤적 예측에 효과적이며, 도로 안전 예측에 기여할 수 있음.

Abstract: Accurate prediction of road user movement is increasingly required by many
applications ranging from advanced driver assistance systems to autonomous
driving, and especially crucial for road safety. Even though most traffic
accident fatalities account to bicycles, they have received little attention,
as previous work focused mainly on pedestrians and motorized vehicles. In this
work, we present the Great GATsBi, a domain-knowledge-based, hybrid, multimodal
trajectory prediction framework for bicycles. The model incorporates both
physics-based modeling (inspired by motorized vehicles) and social-based
modeling (inspired by pedestrian movements) to explicitly account for the dual
nature of bicycle movement. The social interactions are modeled with a graph
attention network, and include decayed historical, but also anticipated, future
trajectory data of a bicycles neighborhood, following recent insights from
psychological and social studies. The results indicate that the proposed
ensemble of physics models -- performing well in the short-term predictions --
and social models -- performing well in the long-term predictions -- exceeds
state-of-the-art performance. We also conducted a controlled mass-cycling
experiment to demonstrate the framework's performance when forecasting bicycle
trajectories and modeling social interactions with road users.

</details>


### [146] [Improving Fairness in Graph Neural Networks via Counterfactual Debiasing](https://arxiv.org/abs/2508.14683)
*Zengyi Wo,Chang Liu,Yumeng Wang,Minglai Shao,Wenjun Wang*

Main category: cs.LG

TL;DR: 이 논문은 그래프 신경망(GNN)의 편향을 완화하기 위해 counterfactual 데이터 증강과 적대적 판별기를 결합한 Fair-ICD를 제안한다.


<details>
  <summary>Details</summary>
Motivation: GNN은 그래프 구조와 메시지 패싱으로 인해 인종·성별 등 민감 속성에 따른 편향을 보일 수 있고, 기존의 편향 완화 기법(엣지 드롭, 특징 마스킹)은 민감하지 않은 유용한 특징까지 제거해 정확도-공정성 균형을 손상시킬 수 있다.

Method: 메시지 패싱 전에 카운터팩추얼(counterfactual)로 다양한 이웃을 생성하는 데이터 증강을 수행하고, 증강된 그래프에서 편향없는 노드 표현을 학습한다. 이후 적대적 판별기를 사용해 일반적인 GNN 분류기의 예측에서 편향을 줄인다. 방법은 Fair-ICD라 명명됨.

Result: 표준 데이터셋과 세 가지 GNN 백본에서 실험한 결과 Fair-ICD는 예측 성능을 유지하면서 공정성 지표를 크게 향상시켰다.

Conclusion: Fair-ICD는 적당한 조건 하에서 GNN의 공정성을 보장하며, 기존 민감 정보 제거 방식보다 유리하다.

Abstract: Graph Neural Networks (GNNs) have been successful in modeling
graph-structured data. However, similar to other machine learning models, GNNs
can exhibit bias in predictions based on attributes like race and gender.
Moreover, bias in GNNs can be exacerbated by the graph structure and
message-passing mechanisms. Recent cutting-edge methods propose mitigating bias
by filtering out sensitive information from input or representations, like edge
dropping or feature masking. Yet, we argue that such strategies may
unintentionally eliminate non-sensitive features, leading to a compromised
balance between predictive accuracy and fairness. To tackle this challenge, we
present a novel approach utilizing counterfactual data augmentation for bias
mitigation. This method involves creating diverse neighborhoods using
counterfactuals before message passing, facilitating unbiased node
representations learning from the augmented graph. Subsequently, an adversarial
discriminator is employed to diminish bias in predictions by conventional GNN
classifiers. Our proposed technique, Fair-ICD, ensures the fairness of GNNs
under moderate conditions. Experiments on standard datasets using three GNN
backbones demonstrate that Fair-ICD notably enhances fairness metrics while
preserving high predictive performance.

</details>


### [147] [Context Steering: A New Paradigm for Compression-based Embeddings by Synthesizing Relevant Information Features](https://arxiv.org/abs/2508.14780)
*Guillermo Sarasa Durán,Ana Granados Fontecha,Francisco de Borja Rodríguez Ortíz*

Main category: cs.LG

TL;DR: 데이터 간 중복(압축 기반 거리)을 이용한 유연한 유사도 측정은 도메인 불문 장점이 있으나, 자동으로 생성되는 특징이 과제에 맞지 않을 수 있다. 본 논문은 각 객체가 군집 문맥에 미치는 영향을 분석해 클래스 식별 정보를 증폭하는 'context steering' 기법을 제안하여 NCD/NRC 기반 계층적 군집에서 맞춤형 임베딩을 생성하고, 텍스트부터 오디오까지 다양한 데이터에서 그 유효성을 실증했다.


<details>
  <summary>Details</summary>
Motivation: 압축 기반 거리(Compression-based distances)는 도메인 독립적으로 유사도를 측정하지만, 특징이 데이터에서 도출되므로 특정 분류/군집 과제에 맞게 정렬되지 않는 문제가 있다. 이를 해결해 과제에 특화된 표현을 얻으려는 필요성.

Method: 'context steering'이라는 절차적 접근을 제안. 각 객체가 군집 내 관계적 문맥에 미치는 영향을 체계적으로 분석하여, 계층적 군집(주로 NCD/NRC 사용)에서 emergent 구조를 수동적으로 수용하는 대신 개별 객체 기반의 문맥 영향도를 반영해 클래스 판별성 정보를 분리·증폭하는 맞춤형 임베딩을 생성.

Result: 제안 기법을 NCD와 NRC에 적용해 전통적 전이적(혹은 transductive) 방법에 대한 효과적인 대안임을 보였다. 텍스트부터 실제 음성 데이터까지 이질적 데이터셋에서 실험을 통해 견고성과 일반성을 확인했다.

Conclusion: context steering은 압축 기반 거리의 활용을 '내재 구조 발견'에서 '목표에 맞춘 특징 공간 형성'으로 전환시키며, 다양한 데이터 도메인에 적용 가능한 일반적 방법임을 주장한다.

Abstract: Compression-based distances (CD) offer a flexible and domain-agnostic means
of measuring similarity by identifying implicit information through
redundancies between data objects. However, as similarity features are derived
from the data, rather than defined as an input, it often proves difficult to
align with the task at hand, particularly in complex clustering or
classification settings. To address this issue, we introduce "context
steering," a novel methodology that actively guides the feature-shaping
process. Instead of passively accepting the emergent data structure (typically
a hierarchy derived from clustering CDs), our approach "steers" the process by
systematically analyzing how each object influences the relational context
within a clustering framework. This process generates a custom-tailored
embedding that isolates and amplifies class-distinctive information. We
validate the capabilities of this strategy using Normalized Compression
Distance (NCD) and Relative Compression Distance (NRC) with common hierarchical
clustering, providing an effective alternative to common transductive methods.
Experimental results across heterogeneous datasets-from text to real-world
audio-validate the robustness and generality of context steering, marking a
fundamental shift in their application: from merely discovering inherent data
structures to actively shaping a feature space tailored to a specific
objective.

</details>


### [148] [A Guide for Manual Annotation of Scientific Imagery: How to Prepare for Large Projects](https://arxiv.org/abs/2508.14801)
*Azim Ahmadzadeh,Rohan Adhyapak,Armin Iraji,Kartik Chaurasiya,V Aparna,Petrus C. Martens*

Main category: cs.LG

TL;DR: 과학적 이미지 수동 어노테이션 프로젝트를 위한 도메인 불문 준비 가이드로, 성공 지표, 어노테이션 대상과 목표, 데이터 가용성, 팀 역할, 인간 편향 완화, 도구·기술 권장 등을 다루며 비용 절감과 지식 기반 구축을 목표로 함.


<details>
  <summary>Details</summary>
Motivation: 수동 어노테이션 프로젝트는 비용·복잡성이 높고 다양한 전문성을 요구하나 실무 지침이 부족해, 프로젝트 준비 전반에 대한 실용적 가이드가 필요함.

Method: 저자들의 대규모 수동 어노테이션 프로젝트 경험을 바탕으로 핵심 개념(성공 측정, 대상·목표 설정, 데이터 가용성, 팀 구성)과 편향·품질 향상 도구를 정리하여 도메인 불문 지침으로 제시.

Result: 프로젝트 준비 과정에서 고려해야 할 요소들(리소스·모집·편향·교육 등)과 활용 가능한 도구·기술을 체계화하여 실무자가 참고할 수 있는 가이드라인을 제공함.

Conclusion: 포괄적 지식 기반과 프레임워크 개발을 촉진하여 수동 어노테이션 비용을 낮추고, 다양한 분야에서의 데이터 구축 효율을 높이는 것을 목표로 함.

Abstract: Despite the high demand for manually annotated image data, managing complex
and costly annotation projects remains under-discussed. This is partly due to
the fact that leading such projects requires dealing with a set of diverse and
interconnected challenges which often fall outside the expertise of specific
domain experts, leaving practical guidelines scarce. These challenges range
widely from data collection to resource allocation and recruitment, from
mitigation of biases to effective training of the annotators. This paper
provides a domain-agnostic preparation guide for annotation projects, with a
focus on scientific imagery. Drawing from the authors' extensive experience in
managing a large manual annotation project, it addresses fundamental concepts
including success measures, annotation subjects, project goals, data
availability, and essential team roles. Additionally, it discusses various
human biases and recommends tools and technologies to improve annotation
quality and efficiency. The goal is to encourage further research and
frameworks for creating a comprehensive knowledge base to reduce the costs of
manual annotation projects across various fields.

</details>


### [149] [Source-Guided Flow Matching](https://arxiv.org/abs/2508.14807)
*Zifan Wang,Alice Harting,Matthieu Barreau,Michael M. Zavlanos,Karl H. Johansson*

Main category: cs.LG

TL;DR: 이 논문은 사전 학습된 확률 흐름 벡터 필드를 변경하지 않고 소스 분포를 직접 수정하는 Source-Guided Flow Matching(SGFM) 프레임워크를 제안한다. SGFM은 목표 분포를 정확히 복원하며 근사 샘플러와 근사 벡터 필드를 사용할 때 Wasserstein 오차 경계를 제공한다. 샘플링 방법을 유연하게 선택할 수 있고, 최적 흐름 매칭 모델과 잘 통합된다. 2D 합성 벤치마크, 이미지 데이터셋, 물리 기반 생성 작업에서 유효성을 보였다.


<details>
  <summary>Details</summary>
Motivation: 생성 모델의 안내(guidance)를 기존의 벡터 필드 변경 방식 대신에 소스 분포를 직접 조절하여 보다 명확하고 유연한 샘플링 문제로 환원하려는 것.

Method: 사전 학습된 벡터 필드를 유지한 채 소스 분포를 변경하는 SGFM 프레임워크를 제안. 이론적으로 목표 분포를 정확히 복원함을 증명하고, 근사 샘플러 및 근사 벡터 필드 사용 시 Wasserstein 오차 경계를 도출. 다양한 샘플링 기법을 비교하며 최적의 플로우 매칭 모델과의 통합을 논의.

Result: 이론적 보장(정확한 복원, 오차 경계)과 함께, 합성 2D, 이미지, 물리 기반 생성 과제에서 실험적으로 SGFM의 효과성과 유연성을 입증.

Conclusion: SGFM은 벡터 필드를 변경하지 않고 소스 분포 샘플링을 조절함으로써 안내 문제를 샘플링 문제로 환원하며, 다양한 샘플링 전략과 통합되어 실무적 유연성과 이론적 보장을 제공한다.

Abstract: Guidance of generative models is typically achieved by modifying the
probability flow vector field through the addition of a guidance field. In this
paper, we instead propose the Source-Guided Flow Matching (SGFM) framework,
which modifies the source distribution directly while keeping the pre-trained
vector field intact. This reduces the guidance problem to a well-defined
problem of sampling from the source distribution. We theoretically show that
SGFM recovers the desired target distribution exactly. Furthermore, we provide
bounds on the Wasserstein error for the generated distribution when using an
approximate sampler of the source distribution and an approximate vector field.
The key benefit of our approach is that it allows the user to flexibly choose
the sampling method depending on their specific problem. To illustrate this, we
systematically compare different sampling methods and discuss conditions for
asymptotically exact guidance. Moreover, our framework integrates well with
optimal flow matching models since the straight transport map generated by the
vector field is preserved. Experimental results on synthetic 2D benchmarks,
image datasets, and physics-informed generative tasks demonstrate the
effectiveness and flexibility of the proposed framework.

</details>


### [150] [Enhancing Contrastive Link Prediction With Edge Balancing Augmentation](https://arxiv.org/abs/2508.14808)
*Chen-Hao Chang,Hui-Ju Hung,Chia-Hsun Lu,Chih-Ya Shen*

Main category: cs.LG

TL;DR: 이 논문은 링크 예측에서 대조 학습의 이론적 기반이 부족하고 노드 차수 고려가 미흡하다는 문제를 지적하고, 이를 해결하기 위해 대조 학습의 이론 분석을 제시하고 노드 차수를 조절하는 엣지 균형 증강(EBA)을 제안한다. EBA와 새로운 대조 손실을 통합한 CoEBA를 개발해 8개 벤치마크에서 기존 기법 대비 성능 향상을 보인다.


<details>
  <summary>Details</summary>
Motivation: 기존 링크 예측 연구에서 대조 학습 적용 시 이론적 정당성이 부족하고, 그래프 증강에서 노드 차수(연결수)에 대한 고려가 부족해 성능에 제한이 있음을 해결하려 함.

Method: 대조 학습이 링크 예측에 미치는 영향을 이론적으로 분석(오토인코더 기반 링크 예측 모델에 일반화 가능한 결과 도출). 이를 바탕으로 노드 차수를 조정하는 그래프 증강 기법 EBA를 제안하고, EBA와 새로 설계한 대조 손실을 결합한 CoEBA 프레임워크를 구성.

Result: 8개 벤치마크 데이터셋에서 CoEBA가 기존 최첨단(link prediction) 모델들보다 유의미하게 우수한 성능을 보임.

Conclusion: 이론적 분석과 엣지 균형 증강을 통한 대조 학습 기법은 링크 예측 성능을 향상시키며, 노드 차수 조절이 증강 설계에서 중요한 요소임을 시사한다.

Abstract: Link prediction is one of the most fundamental tasks in graph mining, which
motivates the recent studies of leveraging contrastive learning to enhance the
performance. However, we observe two major weaknesses of these studies: i) the
lack of theoretical analysis for contrastive learning on link prediction, and
ii) inadequate consideration of node degrees in contrastive learning. To
address the above weaknesses, we provide the first formal theoretical analysis
for contrastive learning on link prediction, where our analysis results can
generalize to the autoencoder-based link prediction models with contrastive
learning. Motivated by our analysis results, we propose a new graph
augmentation approach, Edge Balancing Augmentation (EBA), which adjusts the
node degrees in the graph as the augmentation. We then propose a new approach,
named Contrastive Link Prediction with Edge Balancing Augmentation (CoEBA),
that integrates the proposed EBA and the proposed new contrastive losses to
improve the model performance. We conduct experiments on 8 benchmark datasets.
The results demonstrate that our proposed CoEBA significantly outperforms the
other state-of-the-art link prediction models.

</details>


### [151] [Successive Halving with Learning Curve Prediction via Latent Kronecker Gaussian Processes](https://arxiv.org/abs/2508.14818)
*Jihao Andreas Lin,Nicolas Mayoraz,Steffen Rendle,Dima Kuzmin,Emil Praun,Berivan Isik*

Main category: cs.LG

TL;DR: 이 논문은 Successive Halving(SH) 하이퍼파라미터 최적화의 조기 중단 문제를 학습 곡선 예측(Latent Kronecker Gaussian Processes)으로 완화하려 시도한다. 대규모 실험에서 예측 기반 접근은 경쟁력 있는 성능을 보였지만, 학습 곡선을 완전 관찰한 훈련 데이터가 필요해 표준 SH에 추가 자원을 투입하는 것보다 비용-효율적 우위를 점하지 못했다. 기존 학습 곡선 데이터 활용으로 이 한계를 줄일 수 있다.


<details>
  <summary>Details</summary>
Motivation: SH는 유망한 후보에게 자원을 집중하는데, 느리게 학습하지만 최종적으로 좋은 후보를 조기 제거할 위험이 있다. 이를 개선하기 위해 학습 곡선 예측으로 조기 중단 결정을 안내하려는 동기가 있다.

Method: Latent Kronecker Gaussian Processes를 사용해 학습 곡선을 예측하고, 예측된 장기 성능을 바탕으로 Successive Halving의 자원 배분을 결정하는 접근을 기존의 현재 성능 기반 SH와 대규모 실험(다양한 신경망 아키텍처와 클릭 예측 데이터셋)에서 비교했다.

Result: 예측 기반 SH는 경쟁력 있는 성능을 보였지만, Pareto 최적성이 없었다. 주된 이유는 예측 모델 학습에 완전 관찰된 학습 곡선이 필요해 추가 데이터 수집 비용이 발생하기 때문이었다.

Conclusion: 학습 곡선 예측은 SH의 조기 중단 한계를 완화할 잠재력이 있으나, 실무 적용에서는 학습 곡선 데이터 확보 비용을 고려해야 한다. 기존 학습 곡선 데이터 활용으로 이 문제를 일부 완화할 수 있다.

Abstract: Successive Halving is a popular algorithm for hyperparameter optimization
which allocates exponentially more resources to promising candidates. However,
the algorithm typically relies on intermediate performance values to make
resource allocation decisions, which can cause it to prematurely prune slow
starters that would eventually become the best candidate. We investigate
whether guiding Successive Halving with learning curve predictions based on
Latent Kronecker Gaussian Processes can overcome this limitation. In a
large-scale empirical study involving different neural network architectures
and a click prediction dataset, we compare this predictive approach to the
standard approach based on current performance values. Our experiments show
that, although the predictive approach achieves competitive performance, it is
not Pareto optimal compared to investing more resources into the standard
approach, because it requires fully observed learning curves as training data.
However, this downside could be mitigated by leveraging existing learning curve
data.

</details>


### [152] [Out-of-Sample Hydrocarbon Production Forecasting: Time Series Machine Learning using Productivity Index-Driven Features and Inductive Conformal Prediction](https://arxiv.org/abs/2508.14078)
*Mohamed Hassan Abdalla Idris,Jakub Marek Cebula,Jebraeel Gholinezhad,Shamsul Masum,Hongjie Ma*

Main category: cs.LG

TL;DR: 


<details>
  <summary>Details</summary>
Motivation: 

Method: 

Result: 

Conclusion: 

Abstract: This research introduces a new ML framework designed to enhance the
robustness of out-of-sample hydrocarbon production forecasting, specifically
addressing multivariate time series analysis. The proposed methodology
integrates Productivity Index (PI)-driven feature selection, a concept derived
from reservoir engineering, with Inductive Conformal Prediction (ICP) for
rigorous uncertainty quantification. Utilizing historical data from the Volve
(wells PF14, PF12) and Norne (well E1H) oil fields, this study investigates the
efficacy of various predictive algorithms-namely Long Short-Term Memory (LSTM),
Bidirectional LSTM (BiLSTM), Gated Recurrent Unit (GRU), and eXtreme Gradient
Boosting (XGBoost) - in forecasting historical oil production rates (OPR_H).
All the models achieved "out-of-sample" production forecasts for an upcoming
future timeframe. Model performance was comprehensively evaluated using
traditional error metrics (e.g., MAE) supplemented by Forecast Bias and
Prediction Direction Accuracy (PDA) to assess bias and trend-capturing
capabilities. The PI-based feature selection effectively reduced input
dimensionality compared to conventional numerical simulation workflows. The
uncertainty quantification was addressed using the ICP framework, a
distribution-free approach that guarantees valid prediction intervals (e.g.,
95% coverage) without reliance on distributional assumptions, offering a
distinct advantage over traditional confidence intervals, particularly for
complex, non-normal data. Results demonstrated the superior performance of the
LSTM model, achieving the lowest MAE on test (19.468) and genuine out-of-sample
forecast data (29.638) for well PF14, with subsequent validation on Norne well
E1H. These findings highlight the significant potential of combining
domain-specific knowledge with advanced ML techniques to improve the
reliability of hydrocarbon production forecasts.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [153] [Large Language Models are Highly Aligned with Human Ratings of Emotional Stimuli](https://arxiv.org/abs/2508.14214)
*Mattson Ogg,Chace Ashcraft,Ritwik Bose,Raphael Norman-Tenazas,Michael Wolmetz*

Main category: cs.AI

TL;DR: LLM들이 인간의 정서 자극을 평가하는 방식을 조사함. GPT-4o는 이미지와 단어에 대한 감정 평가에서 인간과 높은 상관(r≈0.9)을 보였으나 각성(arousal) 평가는 덜 일치했고, 감정 5분류 체계에서는 2차원(감정의 각성·쾌/불쾌)보다 더 잘 정렬되며, LLM 평가는 인간보다 더 균질적이었다.


<details>
  <summary>Details</summary>
Motivation: LLM을 일상적 역할(대리인, 상호작용자 등)로 통합할 때, 감정적으로 민감한 자극을 LLM이 어떻게 평가하는지 이해하면 인간과의 정렬도 및 상호작용 적합성을 판단하는 데 도움됨.

Method: 이미 인간이 감정 평정을 한 단어 및 이미지 데이터셋에 대해 여러 인기 LLM(예: GPT-4o)에 동일한 평정 과제를 수행하도록 하여 LLM 평가를 수집하고 인간 평가와 비교.

Result: GPT-4o는 대부분의 평정 척도와 자극 유형에서 인간과 높은 상관(많은 경우 r≥0.9)을 보였음. 그러나 각성 평가는 인간-LLM 간 정렬이 낮았고, 행복 평정은 가장 높은 정렬을 보였음. 감정 5분류(행복, 분노, 슬픔, 공포, 혐오)에서의 정렬이 2차원(arousal, valence)보다 우수. 또한 LLM 평정은 인간보다 더 동질적(동일한 응답 경향)였음.

Conclusion: LLM 에이전트는 정서적 자극을 해석하는 방식에서 인간과 유사한 점과 다른 점을 모두 보이며, 특히 복수 감정 범주에서는 높은 정렬을 보이나 각성 측면과 다양성에서는 차이를 보임. 이는 LLM을 감정 관련 역할에 배치할 때의 장·단점을 설명하고 후속 연구 필요성을 제시함.

Abstract: Emotions exert an immense influence over human behavior and cognition in both
commonplace and high-stress tasks. Discussions of whether or how to integrate
large language models (LLMs) into everyday life (e.g., acting as proxies for,
or interacting with, human agents), should be informed by an understanding of
how these tools evaluate emotionally loaded stimuli or situations. A model's
alignment with human behavior in these cases can inform the effectiveness of
LLMs for certain roles or interactions. To help build this understanding, we
elicited ratings from multiple popular LLMs for datasets of words and images
that were previously rated for their emotional content by humans. We found that
when performing the same rating tasks, GPT-4o responded very similarly to human
participants across modalities, stimuli and most rating scales (r = 0.9 or
higher in many cases). However, arousal ratings were less well aligned between
human and LLM raters, while happiness ratings were most highly aligned. Overall
LLMs aligned better within a five-category (happiness, anger, sadness, fear,
disgust) emotion framework than within a two-dimensional (arousal and valence)
organization. Finally, LLM ratings were substantially more homogenous than
human ratings. Together these results begin to describe how LLM agents
interpret emotional stimuli and highlight similarities and differences among
biological and artificial intelligence in key behavioral domains.

</details>


### [154] [Explaining Hitori Puzzles: Neurosymbolic Proof Staging for Sequential Decisions](https://arxiv.org/abs/2508.14294)
*Maria Leonor Pacheco,Fabio Somenzi,Dananjay Srinivas,Ashutosh Trivedi*

Main category: cs.AI

TL;DR: Neurosymbolic 방식으로 SAT 기반 결정 절차와 LLM을 결합해 Hitori 퍼즐 해법의 설명을 생성. 로컬 제약은 증명으로, 연결성 제약은 시각적 설명으로 처리하여 도구를 구현하고 사용자 보조 실험에서 효과를 보였음.


<details>
  <summary>Details</summary>
Motivation: 복잡한 의사결정 시퀀스의 설명을 자동으로 생성하려는 목적. 로컬 규칙은 기호적 증명(결정 절차)에 적합하지만, 연결성 같은 전역·시각적 제약은 자연어/시각적 설명(LLM)에 더 적합하므로 두 접근을 결합하려 함.

Method: SAT/결정 절차로 로컬 제약을 해석하고 짧은 해석(해결) 증명을 생성하며, LLM을 사용해 연결성 등 시각적·서술적 부분을 자연어·시각적 설명으로 생성하는 neurosymbolic 파이프라인을 구현. Hitori 퍼즐 해결 보조 도구로 통합하여 사용자 인터랙션을 지원.

Result: 구현된 도구가 인간의 Hitori 퍼즐 해결을 보조하며, 실험 결과 도구의 설명이 유용함을 보여줌(실험적 증거 제시).

Conclusion: 결정 절차와 LLM의 장점을 상호 보완적으로 활용한 neurosymbolic 설명 생성이 특정 퍼즐(및 유사한 문제)에 효과적이며, 향후 확장 가능성이 있음.

Abstract: We propose a neurosymbolic approach to the explanation of complex sequences
of decisions that combines the strengths of decision procedures and Large
Language Models (LLMs). We demonstrate this approach by producing explanations
for the solutions of Hitori puzzles. The rules of Hitori include local
constraints that are effectively explained by short resolution proofs. However,
they also include a connectivity constraint that is more suitable for visual
explanations. Hence, Hitori provides an excellent testing ground for a flexible
combination of SAT solvers and LLMs. We have implemented a tool that assists
humans in solving Hitori puzzles, and we present experimental evidence of its
effectiveness.

</details>


### [155] [Automated Optimization Modeling through Expert-Guided Large Language Model Reasoning](https://arxiv.org/abs/2508.14410)
*Beinuo Yang,Qishen Zhou,Junyi Li,Xingchen Su,Simon Hu*

Main category: cs.AI

TL;DR: 본 논문은 최적화 모델링(OM)의 자동화를 목표로, 기존 데이터셋 오류를 정정하고 물류 도메인의 새로운 벤치마크 LogiOR을 제시하며, 체인-오브-생각(chain-of-thought)을 활용한 ORThought 프레임워크로 LLM 기반 OM 성능을 크게 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: OM은 복잡한 의사결정 문제 해결에 필수적이나 전문가 의존적·시간 소모적이며 오류가 많음. 기존 LLM 기반 접근은 라벨링 오류, 평가 범위 제한(최적값만 고려), 계산 효율성 문제(다중 에이전트·파인튜닝 의존) 등의 한계가 있음.

Method: 기존 데이터셋을 체계적으로 오류 수정 및 주석 보강, 물류 도메인의 복잡한 문제를 포함한 LogiOR 벤치마크 도입, 전문가 수준의 OM 원칙을 체인-오브-생각으로 구현한 ORThought 프레임워크 제안으로 자동화 수행.

Result: ORThought는 광범위한 실험에서 기존 접근법(다중 에이전트 포함)보다 우수한 성능을 보였으며, 특히 복잡한 최적화 문제에서 큰 이득을 보임. 또한 주요 성공 요인과 실패 모드를 체계적으로 분석함.

Conclusion: 체계적 데이터셋 개선과 LogiOR 벤치마크, 그리고 체인-오브-생각 기반 ORThought는 LLM 기반 최적화 모델링의 실용성과 효율성을 높이며 향후 연구 방향(성공 인자·실패 원인 분석)에 유용한 통찰을 제공한다.

Abstract: Optimization Modeling (OM) is essential for solving complex decision-making
problems. However, the process remains time-consuming and error-prone, heavily
relying on domain experts. While Large Language Models (LLMs) show promise in
addressing these challenges through their natural language understanding and
reasoning capabilities, current approaches face three critical limitations:
high benchmark labeling error rates reaching up to 42\%, narrow evaluation
scope that only considers optimal values, and computational inefficiency due to
heavy reliance on multi-agent systems or model fine-tuning. In this work, we
first enhance existing datasets through systematic error correction and more
comprehensive annotation. Additionally, we introduce LogiOR, a new optimization
modeling benchmark from the logistics domain, containing more complex problems
with standardized annotations. Furthermore, we present ORThought, a novel
framework that leverages expert-level optimization modeling principles through
chain-of-thought reasoning to automate the OM process. Through extensive
empirical evaluation, we demonstrate that ORThought outperforms existing
approaches, including multi-agent frameworks, with particularly significant
advantages on complex optimization problems. Finally, we provide a systematic
analysis of our method, identifying critical success factors and failure modes,
providing valuable insights for future research on LLM-based optimization
modeling.

</details>


### [156] [Who Sees What? Structured Thought-Action Sequences for Epistemic Reasoning in LLMs](https://arxiv.org/abs/2508.14564)
*Luca Annese,Sabrina Patania,Silvia Serino,Tom Foulsham,Silvia Rossi,Azzurra Ruggeri,Dimitri Ognibene*

Main category: cs.AI

TL;DR: LLM 기반 에이전트의 관점 취하기(perspective-taking) 능력을 향상하기 위해, Fast Downward 플래너로 생성한 구조화된 솔루션 그래프를 변환해 ReAct 프레임워크의 '사고-행동(thought-action)' 예제로 제시했다. 세 가지 예제 유형(G-type, E-type, L-type)을 만들고 LLM으로 각 결정의 추론을 명시하게 하였으나, 구조화된 예제만으로는 폐쇄된 공간의 정신화(mentalising)나 인식 행동의 비용 고려 등 복잡한 관점취득 문제를 일관되게 해결하지 못했다.


<details>
  <summary>Details</summary>
Motivation: LLM과 추론 프레임워크 발전으로 자율 에이전트의 관점 취하기 능력 개선 가능성이 제기되었으나, 능동적 지각·협력적 추론·상대 시야·지식 추정 등 과제에서 한계가 있어 이를 개선할 방법을 탐구하려는 동기.

Method: Fast Downward 플래너로부터 변환한 솔루션 그래프를 세 가지 유형으로 분류(G-type: 최적 목표 경로, E-type: 정보성 노드 경로, L-type: 대안 행동 대비 단계별 최적 결정순서). 각 솔루션을 LLM 프롬프트로 '사고-행동' 예제로 변환하여 ReAct 기반 에이전트에 주입해 행동·질의 빈도·단계 수 등을 평가.

Result: L-type은 약간의 질의(clarification) 감소와 행동 단계 감소를 보였지만 일관된 성능 향상은 없었음. 기본적 주의 필터링 과제는 성공했으나 가려진 공간의 정신화나 인식 행동의 비용 평가에는 실패하여 전반적 한계가 드러남.

Conclusion: 구조화된 예제만으로는 강건한 관점 취하기 능력을 얻기 어렵고, 명시적 신념 추적(belief tracking), 비용 모델링, 더 풍부한 환경 설계가 필요하다는 결론.

Abstract: Recent advances in large language models (LLMs) and reasoning frameworks have
opened new possibilities for improving the perspective -taking capabilities of
autonomous agents. However, tasks that involve active perception, collaborative
reasoning, and perspective taking (understanding what another agent can see or
knows) pose persistent challenges for current LLM-based systems. This study
investigates the potential of structured examples derived from transformed
solution graphs generated by the Fast Downward planner to improve the
performance of LLM-based agents within a ReAct framework. We propose a
structured solution-processing pipeline that generates three distinct
categories of examples: optimal goal paths (G-type), informative node paths
(E-type), and step-by-step optimal decision sequences contrasting alternative
actions (L-type). These solutions are further converted into ``thought-action''
examples by prompting an LLM to explicitly articulate the reasoning behind each
decision. While L-type examples slightly reduce clarification requests and
overall action steps, they do not yield consistent improvements. Agents are
successful in tasks requiring basic attentional filtering but struggle in
scenarios that required mentalising about occluded spaces or weighing the costs
of epistemic actions. These findings suggest that structured examples alone are
insufficient for robust perspective-taking, underscoring the need for explicit
belief tracking, cost modelling, and richer environments to enable socially
grounded collaboration in LLM-based agents.

</details>


### [157] [LeanGeo: Formalizing Competitional Geometry problems in Lean](https://arxiv.org/abs/2508.14644)
*Chendong Song,Zihan Wang,Frederick Pu,Haiming Wang,Xiaohan Lin,Junqi Liu,Jia Li,Zhengying Liu*

Main category: cs.AI

TL;DR: LeanGeo는 Lean 4 정리 증명기 위에 구축된 통합 기하학 형식화 및 해결 시스템으로, 고수준의 기하 정리를 포함하는 라이브러리와 IMO 문제 등을 모은 LeanGeo-Bench 벤치마크를 제공하며, SOTA 대형 언어 모델들의 성능을 평가하여 자동화된 기하 추론의 한계를 제시한다.


<details>
  <summary>Details</summary>
Motivation: 기하 문제는 AI의 추론 능력을 시험하는 중요한 분야이나 기존 시스템들은 통합된 프레임워크가 부족하고 직관적 도형에 의존하는 증명의 검증이 어려워 수학적 통합과 검증에 한계가 있다.

Method: Lean 4 정리 증명기(Lean 4) 위에 고수준 기하 정리 라이브러리를 구축하고 Mathlib과 연동 가능한 형식 체계를 도입했다. 또한 IMO 등에서 문제를 모아 LeanGeo-Bench라는 형식화된 벤치마크를 구성하고, 최신 대형 언어 모델들을 이 벤치마크에서 평가했다.

Result: 고수준 정리 라이브러리와 벤치마크가 구축되었고, LLM들의 성능 평가를 통해 현재 자동 기하 추론의 능력과 한계를 규명했다. 코드와 데이터는 공개되었다.

Conclusion: LeanGeo는 기하 문제의 형식화와 검증을 위한 통합적 기반을 제공하며, LLM을 포함한 자동화 도구의 발전이 필요함을 강조한다. 공개된 라이브러리와 벤치마크는 후속 연구에 유용하다.

Abstract: Geometry problems are a crucial testbed for AI reasoning capabilities. Most
existing geometry solving systems cannot express problems within a unified
framework, thus are difficult to integrate with other mathematical fields.
Besides, since most geometric proofs rely on intuitive diagrams, verifying
geometry problems is particularly challenging. To address these gaps, we
introduce LeanGeo, a unified formal system for formalizing and solving
competition-level geometry problems within the Lean 4 theorem prover. LeanGeo
features a comprehensive library of high-level geometric theorems with Lean's
foundational logic, enabling rigorous proof verification and seamless
integration with Mathlib. We also present LeanGeo-Bench, a formal geometry
benchmark in LeanGeo, comprising problems from the International Mathematical
Olympiad (IMO) and other advanced sources. Our evaluation demonstrates the
capabilities and limitations of state-of-the-art Large Language Models on this
benchmark, highlighting the need for further advancements in automated
geometric reasoning. We open source the theorem library and the benchmark of
LeanGeo at https://github.com/project-numina/LeanGeo/tree/master.

</details>


### [158] [Entropy-Constrained Strategy Optimization in Urban Floods: A Multi-Agent Framework with LLM and Knowledge Graph Integration](https://arxiv.org/abs/2508.14654)
*Peilin Ji,Xiao Xue,Simeng Wang,Wenhao Yan*

Main category: cs.AI

TL;DR: 이 논문은 LLM 기반의 계층적 다중 에이전트 프레임워크(H-J)를 제안하여 도시 홍수 상황에서 응급 스케줄링 문제를 해결한다. 지식 기반 프롬프트, 엔트로피 제약 생성 및 피드백 기반 최적화를 결합해 인지에서 실행까지의 폐쇄루프 파이프라인을 구축하고, 실제 도시 토폴로지와 강우 데이터에서 기존 규칙/강화학습 방법보다 우수한 성능을 보였다.


<details>
  <summary>Details</summary>
Motivation: 극단적 도시 강우에 따른 교통 혼잡·서비스 중단 등 응급 대응에서 복수 목표(교통흐름, 업무완료, 위험완화) 간의 동적 트레이드오프와 빠르게 변하는 환경에 대응하기 위한 정적 규칙의 한계, 그리고 LLM 생성 전략의 의미적 불안정성 문제를 해결하려 함.

Method: H-J라는 계층적 다중 에이전트 프레임워크를 제안. 지식 유도 프롬프트, 엔트로피 제약 생성(불확실성 제어), 피드백 기반 최적화를 결합해 멀티소스 인지→전략 생성→실행→정제의 폐쇄루프를 구성.

Result: 실세계 도시 토폴로지와 강우 데이터를 사용한 실험(극단적 강우, 간헐적 폭우, 일상적 약한 비)에서 규칙 기반 및 강화학습 기반 기준선보다 교통 흐름, 업무 성공률, 시스템 강건성 면에서 우수한 성능을 보임.

Conclusion: 불확실성 인지 및 지식 제약을 갖춘 LLM 기반 접근법이 도시 홍수 대응의 복합 다중 에이전트 의사결정에 유망하며, 인식·전역 최적화·다중 에이전트 조정을 통합하는 효과적인 프레임워크를 제시한다.

Abstract: In recent years, the increasing frequency of extreme urban rainfall events
has posed significant challenges to emergency scheduling systems. Urban
flooding often leads to severe traffic congestion and service disruptions,
threatening public safety and mobility. However, effective decision making
remains hindered by three key challenges: (1) managing trade-offs among
competing goals (e.g., traffic flow, task completion, and risk mitigation)
requires dynamic, context-aware strategies; (2) rapidly evolving environmental
conditions render static rules inadequate; and (3) LLM-generated strategies
frequently suffer from semantic instability and execution inconsistency.
Existing methods fail to align perception, global optimization, and multi-agent
coordination within a unified framework. To tackle these challenges, we
introduce H-J, a hierarchical multi-agent framework that integrates
knowledge-guided prompting, entropy-constrained generation, and feedback-driven
optimization. The framework establishes a closed-loop pipeline spanning from
multi-source perception to strategic execution and continuous refinement. We
evaluate H-J on real-world urban topology and rainfall data under three
representative conditions: extreme rainfall, intermittent bursts, and daily
light rain. Experiments show that H-J outperforms rule-based and
reinforcement-learning baselines in traffic smoothness, task success rate, and
system robustness. These findings highlight the promise of uncertainty-aware,
knowledge-constrained LLM-based approaches for enhancing resilience in urban
flood response.

</details>


### [159] [MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers](https://arxiv.org/abs/2508.14704)
*Ziyang Luo,Zhiqi Shen,Wenzhuo Yang,Zirui Zhao,Prathyusha Jwalapuram,Amrita Saha,Doyen Sahoo,Silvio Savarese,Caiming Xiong,Junnan Li*

Main category: cs.AI

TL;DR: Introduces MCP-Universe, a benchmark for evaluating LLM agents interacting with real Model Context Protocol (MCP) servers across diverse realistic tasks; finds SOTA LLMs still perform poorly and highlights long-context and unknown-tool challenges; provides open-source evaluation framework.


<details>
  <summary>Details</summary>
Motivation: Existing MCP benchmarks are too simple and don't reflect real application challenges like long-horizon reasoning and unfamiliar tool spaces; need realistic, execution-based evaluation with real MCP servers.

Method: Built MCP-Universe covering 6 domains and 11 MCP servers (Location Navigation, Repository Management, Financial Analysis, 3D Design, Browser Automation, Web Searching); implemented execution-based evaluators (format, static, dynamic) and measured LLM agent performance interacting with real servers.

Result: SOTA models have limited performance (GPT-5: 43.72%, Grok-4: 33.33%, Claude-4.0-Sonnet: 29.44%); long interaction increases input tokens causing long-context challenges; unknown-tools hinder agents; enterprise agents not outperforming ReAct baselines.

Conclusion: MCP-Universe reveals substantial gaps in LLM agents' real-world tool-use capabilities; provides an extensible open-source evaluation framework with UI to foster research in MCP ecosystems.

Abstract: The Model Context Protocol has emerged as a transformative standard for
connecting large language models to external data sources and tools, rapidly
gaining adoption across major AI providers and development platforms. However,
existing benchmarks are overly simplistic and fail to capture real application
challenges such as long-horizon reasoning and large, unfamiliar tool spaces. To
address this critical gap, we introduce MCP-Universe, the first comprehensive
benchmark specifically designed to evaluate LLMs in realistic and hard tasks
through interaction with real-world MCP servers. Our benchmark encompasses 6
core domains spanning 11 different MCP servers: Location Navigation, Repository
Management, Financial Analysis, 3D Design, Browser Automation, and Web
Searching. To ensure rigorous evaluation, we implement execution-based
evaluators, including format evaluators for agent format compliance, static
evaluators for time-invariant content matching, and dynamic evaluators that
automatically retrieve real-time ground truth for temporally sensitive tasks.
Through extensive evaluation of leading LLMs, we find that even SOTA models
such as GPT-5 (43.72%), Grok-4 (33.33%) and Claude-4.0-Sonnet (29.44%) exhibit
significant performance limitations. In addition, our benchmark poses a
significant long-context challenge for LLM agents, as the number of input
tokens increases rapidly with the number of interaction steps. Moreover, it
introduces an unknown-tools challenge, as LLM agents often lack familiarity
with the precise usage of the MCP servers. Notably, enterprise-level agents
like Cursor cannot achieve better performance than standard ReAct frameworks.
Beyond evaluation, we open-source our extensible evaluation framework with UI
support, enabling researchers and practitioners to seamlessly integrate new
agents and MCP servers while fostering innovation in the rapidly evolving MCP
ecosystem.

</details>


### [160] [Privileged Self-Access Matters for Introspection in AI](https://arxiv.org/abs/2508.14802)
*Siyuan Song,Harvey Lederman,Jennifer Hu,Kyle Mahowald*

Main category: cs.AI

TL;DR: Authors propose a stronger ("thicker") definition of AI introspection than a recent lightweight one, defining introspection as any process that yields information about internal states more reliably than third-party methods of equal or lower computational cost. They test this by having LLMs reason about their internal temperature parameters and show LLMs may appear introspective under the lightweight definition but fail under the thicker definition.


<details>
  <summary>Details</summary>
Motivation: Existing ambiguity in defining AI introspection; need for a more robust definition to evaluate whether models truly report on internal states rather than producing plausible outputs.

Method: Propose a thicker formal definition of introspection based on reliability vs third-party methods with equal or lower computation; run experiments where LLMs reason about/internalize their temperature parameters to test whether apparent introspection holds under the new definition.

Result: LLMs can produce outputs that mimic introspective reports (lightweight), but these reports do not reliably convey true internal state information according to the thicker definition.

Conclusion: The lightweight notion of introspection can be misleading; a stronger reliability-based definition better distinguishes true introspective capability and shows current LLMs fall short.

Abstract: Whether AI models can introspect is an increasingly important practical
question. But there is no consensus on how introspection is to be defined.
Beginning from a recently proposed ''lightweight'' definition, we argue instead
for a thicker one. According to our proposal, introspection in AI is any
process which yields information about internal states through a process more
reliable than one with equal or lower computational cost available to a third
party. Using experiments where LLMs reason about their internal temperature
parameters, we show they can appear to have lightweight introspection while
failing to meaningfully introspect per our proposed definition.

</details>


### [161] [The Agent Behavior: Model, Governance and Challenges in the AI Digital Age](https://arxiv.org/abs/2508.14415)
*Qiang Zhang,Pei Yan,Yijia Xu,Chuanpo Fu,Yong Fang,Yang Liu*

Main category: cs.AI

TL;DR: 네트워크 환경에서 인간과 에이전트 행동의 경계가 흐려짐에 따른 신뢰·책임·보안 문제를 해결하기 위해, 논문은 ‘Network Behavior Lifecycle’(6단계)과 ‘Agent for Agent(A4A)’·‘Human-Agent Behavioral Disparity(HABD)’ 모델(5개 차원)을 제안하고, 레드팀/블루팀 사례로 유효성을 검증하며 거버넌스 및 향후 연구 로드맵을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 네트워크화된 환경에서 에이전트가 인간과 유사한 행동을 보이며 발생하는 감독의 어려움, 데이터 오염, 책임 불명확성, 윤리·보안 문제 등을 체계적으로 다루려는 필요성.

Method: 네트워크 행동을 6단계로 나누는 'Network Behavior Lifecycle'을 제시하고, 인간과 에이전트의 행동 차이를 5개 차원(결정 메커니즘, 실행 효율, 의도-행동 일관성, 행동 관성, 비합리성 패턴)으로 분석하는 'HABD' 모델 및 'A4A' 패러다임을 도입. 실제 레드팀(공격)·블루팀(방어) 사례로 모델을 검증하고 거버넌스 아키텍처·정량화·프로토콜 스택을 논의.

Result: HABD와 A4A를 통한 분석이 실제 사례에서 인간-에이전트 행동 차이를 식별하고 거버넌스 설계에 유용함을 보였으며, 동적 인지 거버넌스, 행동 격차 정량화, 메타 거버넌스 프로토콜 등 향후 연구 방향을 도출함.

Conclusion: 제안된 이론적 모델과 기술 로드맵은 신뢰할 수 있는 인간-에이전트 협업을 위한 기초를 제공하며, 보안·책임·윤리 문제 해결을 위한 연구 및 시스템 설계의 출발점을 마련한다.

Abstract: Advancements in AI have led to agents in networked environments increasingly
mirroring human behavior, thereby blurring the boundary between artificial and
human actors in specific contexts. This shift brings about significant
challenges in trust, responsibility, ethics, security and etc. The difficulty
in supervising of agent behaviors may lead to issues such as data contamination
and unclear accountability. To address these challenges, this paper proposes
the "Network Behavior Lifecycle" model, which divides network behavior into 6
stages and systematically analyzes the behavioral differences between humans
and agents at each stage. Based on these insights, the paper further introduces
the "Agent for Agent (A4A)" paradigm and the "Human-Agent Behavioral Disparity
(HABD)" model, which examine the fundamental distinctions between human and
agent behaviors across 5 dimensions: decision mechanism, execution efficiency,
intention-behavior consistency, behavioral inertia, and irrational patterns.
The effectiveness of the model is verified through real-world cases such as red
team penetration and blue team defense. Finally, the paper discusses future
research directions in dynamic cognitive governance architecture, behavioral
disparity quantification, and meta-governance protocol stacks, aiming to
provide a theoretical foundation and technical roadmap for secure and
trustworthy human-agent collaboration.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [162] [Leveraging Hardware-Aware Computation in Mixed-Precision Matrix Multiply: A Tile-Centric Approach](https://arxiv.org/abs/2508.14848)
*Qiao Zhang,Rabab Alomairy,Dali Wang,Zhuowei Gu,Qinglei Cao*

Main category: cs.DC

TL;DR: Adaptive mixed-precision GEMM framework that assigns precision at fine-grained tile/block levels and uses the PaRSEC runtime to balance workloads across heterogeneous HPC architectures, demonstrating good scaling on Fugaku (ARM), A100 DGX (NVIDIA), and Frontier (AMD).


<details>
  <summary>Details</summary>
Motivation: Hardware trends favor low-precision arithmetic for performance/energy gains; existing numerical algorithms need reevaluation to exploit mixed-precision capabilities for HPC and AI workloads.

Method: Introduce an adaptive mixed-precision GEMM supporting multiple precision formats at tile/block granularity; integrate with the PaRSEC runtime to schedule and balance mixed-precision tasks across diverse architectures (ARM CPUs, NVIDIA GPUs, AMD GPUs).

Result: Reported good performance scaling across Fugaku, A100 DGX, and Frontier supercomputers, showing improved computational efficiency while maintaining accuracy through adaptive precision choices.

Conclusion: The framework bridges algorithmic mixed-precision strategies and hardware innovations, enhancing GEMM efficiency for a range of applications and suggesting value for large-scale AI/HPC workloads.

Abstract: General Matrix Multiplication (GEMM) is a critical operation underpinning a
wide range of applications in high-performance computing (HPC) and artificial
intelligence (AI). The emergence of hardware optimized for low-precision
arithmetic necessitates a reevaluation of numerical algorithms to leverage
mixed-precision computations, achieving improved performance and energy
efficiency. This research introduces an adaptive mixed-precision GEMM framework
that supports different precision formats at fine-grained tile/block levels. We
utilize the PaRSEC runtime system to balance workloads across various
architectures. The performance scales well on ARM CPU-based Fugaku
supercomputer, Nvidia GPU-based A100 DGX, and AMD GPU-based Frontier
supercomputer. This research aims to enhance computational efficiency and
accuracy by bridging algorithmic advancements and hardware innovations, driving
transformative progress in various applications.

</details>
